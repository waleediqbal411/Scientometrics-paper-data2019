Authors,No. of Authors,Title,Year,Cited by,Affiliations,Institutes,No. of Institutes,Countries,No. of Countries,Number of references,Last 10 years,Abstract,Author Keywords,Index Keywords
"Jonker M., Pras A., Dainotti A., Sperotto A.",4,A first joint look at DoS attacks and BGP blackholing in the wild,2018,0,"University of Twente, Netherlands; CAIDA / UC San Diego, United States",University of California San Diego;University of Twente,2,Netherlands;USA,2,29,20,"BGP blackholing is an operational countermeasure that builds upon the capabilities of BGP to achieve DoS mitigation. Although empirical evidence of blackholing activities are documented in literature, a clear understanding of how blackholing is used in practice when attacks occur is still missing. This paper presents a first joint look at DoS attacks and BGP blackholing in the wild. We do this on the basis of two complementary data sets of DoS attacks, inferred from a large network telescope and DoS honeypots, and on a data set of blackholing events. All data sets span a period of three years, thus providing a longitudinal overview of operational deployment of blackholing during DoS attacks. © 2018 Association for Computing Machinery.",BGP; Blackholing; DDoS Mitigation; Denial-of-Service,Border Gateway Protocol; Blackholing; Complementary data; Ddos mitigations; Denial of Service; Honeypots; Large networks; Operational deployments; Still missing; Denial-of-service attack
"Weinberg Z., Cho S., Christin N., Sekar V., Gill P.",5,How to catch when proxies lie :Verifying the physical locations of network proxies with active geolocation,2018,0,"Carnegie Mellon University, United States; Stony Brook University, United States; University of Massachusetts, United States",Carnegie Mellon University;Stony Brook University;University of Massachusetts Amherst,3,USA,1,46,39,"Internet users worldwide rely on commercial network proxies both to conceal their true location and identity, and to control their apparent location. Their reasons range from mundane to security-critical. Proxy operators offer no proof that their advertised server locations are accurate. IP-to-location databases tend to agree with the advertised locations, but there have been many reports of serious errors in such databases. In this study we estimate the locations of 2269 proxy servers from ping-time measurements to hosts in known locations, combined with AS and network information. These servers are operated by seven proxy services, and, according to the operators, spread over 222 countries and territories. Our measurements show that one-third of them are definitely not located in the advertised countries, and another third might not be. Instead, they are concentrated in countries where server hosting is cheap and reliable (e.g. Czech Republic, Germany, Netherlands, UK, USA). In the process, we address a number of technical challenges with applying active geolocation to proxy servers, which may not be directly pingable, and may restrict the types of packets that can be sent through them, e.g. forbidding traceroute. We also test three geolocation algorithms from previous literature, plus two variations of our own design, at the scale of the whole world. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Active geolocation; Network proxies; Virtual private networks,Measurement; Virtual private networks; Commercial networks; Geolocation algorithm; Geolocations; Location database; Network information; Physical locations; Security-critical; Technical challenges; Location
"Dasari M., Vargas S., Bhattacharya A., Balasubramanian A., Das S.R., Ferdman M.",6,Impact of device performance on mobile internet QoE,2018,0,"Department of Computer Science, Stony Brook University, United States",Stony Brook University,1,USA,1,39,25,"A large fraction of users in developing regions use relatively inexpensive, low-end smartphones. However, the impact of device capabilities on the performance of mobile Internet applications has not been explored. To bridge this gap, we study the QoE of three popular applications - Web browsing, video streaming, and video telephony - for different device parameters. Our results demonstrate that the performance of Web browsing is much more sensitive to low-end hardware than that of video applications, especially video streaming. This is because the video applications exploit specialized coprocessors/accelerators and thread-level parallelism on multi-core mobile devices. Even low-end devices are equipped with needed coprocessors and multiple cores. In contrast, Web browsing is largely influenced by clock frequency, but it uses no more than two cores. This makes the performance of Web browsing more vulnerable on low-end smartphones. Based on the lessons learned from studying video applications, we explore offloading Web computation to a coprocessor. Specifically, we explore the offloading of regular expression computation to a DSP coprocessor and show an improvement of 18% in page load time while saving energy by a factor of four. © 2018 Association for Computing Machinery.",Hardware Accelerators; Mobile Applications; Quality of Experience,Coprocessor; Hardware; Mobile devices; Smartphones; Video streaming; Developing regions; Device capabilities; Hardware accelerators; Mobile applications; Mobile internet applications; Quality of experience (QoE); Regular expressions; Thread level parallelism; Quality of service
"Yadav T.K., Sinha A., Gosain D., Sharma P.K., Chakravarty S.",5,Where the light gets in: Analyzing web censorship mechanisms in India,2018,0,"IIT Delhi, India",IIT Delhi,1,India,1,55,36,"In this work we present a detailed study of the Internet censorship mechanism in India. We consolidated a list of potentially blocked websites from various public sources to assess censorship mechanisms used by nine major ISPs. To begin with, we demonstrate that existing censorship detection tools like OONI are grossly inaccurate. We thus developed various techniques and heuristics to correctly assess censorship and study the underlying mechanism used by these ISPs. At every step we corroborated our finding manually to test the efficacy of our approach, an exercise largely ignored by several others. We fortify our findings by adjudging the coverage and consistency of censorship infrastructure, broadly in terms of average number of network paths and requested domains the infrastructure censors. Our results indicate a clear disparity among the ISPs, on how they install censorship infrastructure. For instance, in Idea network we observed the censorious middleboxes in over 90% of our tested intra-AS paths, whereas for Vodafone, it is as low as 2.5%. We conclude our research by devising our own novel anti-censorship strategies, that does not depend on third party tools (like proxies, Tor and VPNs etc.). We managed to access all blocked websites in all ISPs under test. © 2018 Association for Computing Machinery.",Censorship; India; OONI,Websites; Average numbers; Censorship; Detection tools; India; Internet censorship; Network paths; OONI; Third-party tools; Internet service providers
"Fukuda K., Heidemann J.",2,Who knocks at the iPv6 door? Detecting IPv6 scanning,2018,0,"National Institute of Informatics/Sokendai, Japan; USC/Information Sciences Institute, United States",National Institute of Informatics;University of Southern California,2,Japan;USA,2,26,20,"DNS backscatter detects internet-wide activity by looking for common reverse DNS lookups at authoritative DNS servers that are high in the DNS hierarchy. Both DNS backscatter and monitoring unused address space (darknets or network telescopes) can detect scanning in IPv4, but with IPv6's vastly larger address space, darknets become much less effective. This paper shows how to adapt DNS backscatter to IPv6. IPv6 requires new classification rules, but these reveal large network services, from cloud providers and CDNs to specific services such as NTP and mail. DNS backscatter also identifies router interfaces suggesting traceroute-based topology studies. We identify 16 scanners per week from DNS backscatter using observations from the B-root DNS server, with confirmation from backbone traffic observations or blacklists. After eliminating benign services, we classify another 95 originators in DNS backscatter as potential abuse. Our work also confirms that IPv6 appears to be less carefully monitored than IPv4. © 2018 Association for Computing Machinery.",DNS backscatter; IPv6; Scanning,Backscattering; Routers; Scanning; Address space; Classification rules; Cloud providers; Dns lookups; IPv6; Large networks; OR-networks; Traffic observations; Internet protocols
"Moura G.C.M., Heidemann J., MŸller M., De Schmidt R.O., Davids M.",5,When the dike breaks: Dissecting DNS defenses during DDos,2018,0,"SIDN Labs and, TU Delft, United States; USC/Information Sciences Institute, United States; SIDN Labs, University of Twente, Netherlands; University of Passo Fundo, Brazil; SIDN Labs, United States",TU Delft;University of Southern California;University of Passo Fundo;University of Twente,4,Brazil;Netherlands;USA,3,53,49,"The Internet's Domain Name System (DNS) is a frequent target of Distributed Denial-of-Service (DDoS) attacks, but such attacks have had very different outcomes_some attacks have disabled major public websites, while the external effects of other attacks have been minimal. While on one hand the DNS protocol is relatively simple, the system has many moving parts, with multiple levels of caching and retries and replicated servers. This paper uses controlled experiments to examine how these mechanisms affect DNS resilience and latency, exploring both the client side's DNS user experience, and server-side traffic. We find that, for about 30% of clients, caching is not effective. However, when caches are full they allow about half of clients to ride out server outages that last less than cache lifetimes, caching and retries together allow up to half of the clients to tolerate DDoS attacks longer than cache lifetimes, with 90% query loss, and almost all clients to tolerate attacks resulting in 50% packet loss. While clients may get service during an attack, tail-latency increases for clients. For servers, retries during DDoS attacks increase normal traffic up to 8_. Our findings about caching and retries help explain why users see service outages from some real-world DDoS events, but minimal visible effects from others. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Authoritative servers; Caching; DDoS attacks; DNS; Recursive DNS servers,Hydraulic structures; Internet protocols; Network security; Caching; Controlled experiment; DDoS Attack; Distributed denial of service attack; DNS server; Domain name system; Latency increase; User experience; Denial-of-service attack
"Sarabi A., Liu M.",2,Characterizing the internet host population using deep learning: A universal and lightweight numerical embedding,2018,0,"University of Michigan, Ann Arbor, MI, United States; University of Michigan, Ann Arbor, MI, United States",University of Michigan at Ann Arbor,1,USA,1,42,24,"In this paper, we present a framework to characterize Internet hosts using deep learning, using Internet scan data to produce numerical and lightweight (low-dimensional) representations of hosts. To do so we first develop a novel method for extracting binary tags from structured texts, the format of the scan data. We then use a variational autoencoder, an unsupervised neural network model, to construct low-dimensional embeddings of our high-dimensional binary representations. We show that these lightweight embeddings retain most of the information in our binary representations, while drastically reducing memory and computational requirements for large-scale analysis. These embeddings are also universal, in that the process used to generate them is unsupervised and does not rely on specific applications. This universality makes the embeddings broadly applicable to a variety of learning tasks whereby they can be used as input features. We present two such examples, (1) detecting and predicting malicious hosts, and (2) unmasking hidden host attributes, and compare the trained models in their performance, speed, robustness, and interpretability. We show that our embeddings can achieve high accuracy (>95%) for these learning tasks, while being fast enough to enable host-level analysis at scale. © 2018 Association for Computing Machinery.",Host Embedding; Machine Learning; Network Measurement,Learning systems; Population statistics; Binary representations; Computational requirements; High-dimensional; Host Embedding; Interpretability; Large-scale analysis; Network measurement; Unsupervised neural networks; Deep learning
"Streibelt F., Feldmann A., Lichtblau F., Pelsser C., Bush R., Beverly R., Smaragdakis G.",7,BGP communities: Even more worms in the routing can,2018,0,"Max Planck Institute for Informatics, Germany; University of Strasbourg, France; Internet Initiative Japan, Japan; Naval Postgraduate School, United States; TU Berlin, Germany","Max Planck Institute,Germany;Naval Postgraduate School;TU Berlin;University of Strasbourg",4,France;Germany;Japan;USA,4,58,27,"BGP communities are a mechanism widely used by operators to manage policy, mitigate attacks, and engineer traffic; e.g., to drop unwanted traffic, filter announcements, adjust local preference, and prepend paths to influence peer selection. Unfortunately, we show that BGP communities can be exploited by remote parties to influence routing in unintended ways. The BGP community-based vulnerabilities we expose are enabled by a combination of complex policies, error-prone configurations, a lack of cryptographic integrity and authenticity over communities, and the wide extent of community propagation. Due in part to their ill-defined semantics, BGP communities are often propagated far further than a single routing hop, even though their intended scope is typically limited to nearby ASes. Indeed, we find 14% of transit ASes forward received BGP communities onward. Given the rich inter-connectivity of transit ASes, this means that communities effectively propagate globally. As a consequence, remote adversaries can use BGP communities to trigger remote blackholing, steer traffic, and manipulate routes even without prefix hijacking. We highlight examples of these attacks via scenarios that we tested and measured both in the lab as well as in the wild. While we suggest what can be done to mitigate such ill effects, it is up to the Internet operations community whether to take up the suggestions. © 2018 Association for Computing Machinery.",BGP; Communities; Exploits,Ecosystems; Semantics; Community-based; Error prones; Exploits; Peer selection; Prefix hijacking; Unwanted traffic; Border Gateway Protocol
"Meza J., Veeraraghavan K., Xu T., Mutlu O.",4,A large scale study of data center network reliability,2018,0,"Carnegie Mellon University, Facebook, Inc., United States; Facebook, Inc., United States; University of Illinois Urbana-Champaign, Facebook, Inc, United States; ETH ZŸrich, Switzerland; Carnegie Mellon University, United States",Carnegie Mellon University;ETH Zurich;Facebook;UIUC,4,Switzerland;USA,2,83,73,"The ability to tolerate, remediate, and recover from network incidents (caused by device failures and fiber cuts, for example) is critical for building and operating highly-available web services. Achieving fault tolerance and failure preparedness requires system architects, software developers, and site operators to have a deep understanding of network reliability at scale, along with its implications on the software systems that run in data centers. Unfortunately, little has been reported on the reliability characteristics of large scale data center network infrastructure, let alone its impact on the availability of services powered by software running on that network infrastructure. This paper fills the gap by presenting a large scale, longitudinal study of data center network reliability based on operational data collected from the production network infrastructure at Facebook, one of the largest web service providers in the world. Our study covers reliability characteristics of both intra and inter data center networks. For intra data center networks, we study seven years of operation data comprising thousands of network incidents across two different data center network designs, a cluster network design and a state-of-the-art fabric network design. For inter data center networks, we study eighteen months of recent repair tickets from the field to understand reliability of Wide Area Network (WAN) backbones. In contrast to prior work, we study the effects of network reliability on software systems, and how these reliability characteristics evolve over time. We discuss the implications of network reliability on the design, implementation, and operation of large scale data center systems and how it affects highly-available web services. We hope our study forms a foundation for understanding the reliability of large scale network infrastructure, and inspires new reliability solutions to network incidents. © 2018 Copyright held by the owner/author(s).",Data centers; Fault tolerance; Networks; Reliability,Availability; Fault tolerance; Networks (circuits); Reliability; Software reliability; Web services; Websites; Data center networks; Data centers; Large-scale network; Large-scale studies; Network infrastructure; Network reliability; Reliability characteristics; Web service providers; Wide area networks
Allman M.,1,Comments on DNS robustness,2018,1,"International Computer Science Institute, United States",University of California Berkeley,1,USA,1,12,5,"The Domain Name System (DNS) maps human-friendly names into the network addresses necessary for network communication. Therefore, the robustness of the DNS is crucial to the general operation of the Internet. As such, the DNS protocol and architecture were designed to facilitate structural robustness within system. For instance, a domain can depend on authoritative nameservers in several topologically disparate datacenters to aid robustness. However, the actual operation of the system need not utilize these robustness tools. In this paper we provide an initial analysis of the structural robustness of the DNS ecosystem over the last nine years. © 2018 Association for Computing Machinery.",DNS; Nameserver; Robustness; Structure,Network architecture; Robustness (control systems); Structure (composition); Actual operation; Data centers; Domain name system; Human-friendly; Nameserver; Network address; Network communications; Structural robustness; Internet protocols
"Scheitle Q., Gasser O., Nolte T., Amann J., Brent L., Carle G., Holz R., Schmidt T.C., WŠhlisch M.",9,The rise of certificate transparency and its implications on the internet ecosystem,2018,0,"TUM, Germany; HAW Hamburg, Germany; ICSI, Corelight/LBNL, Australia; University of Sydney, Australia; FU Berlin, China",University of Sydney,1,Australia;China;Germany,3,42,42,"In this paper, we analyze the evolution of Certificate Transparency (CT) over time and explore the implications of exposing certificate DNS names from the perspective of security and privacy. We find that certificates in CT logs have seen exponential growth. Website support for CT has also constantly increased, with now 33% of established connections supporting CT. With the increasing deployment of CT, there are also concerns of information leakage due to all certificates being visible in CT logs. To understand this threat, we introduce a CT honeypot and show that data from CT logs is being used to identify targets for scanning campaigns only minutes after certificate issuance. We present and evaluate a methodology to learn and validate new subdomains from the vast number of domains extracted from CT logged certificates. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Certificate Transparency; Honeypot; Phishing,Network security; Transparency; Exponential growth; Honeypots; Information leakage; Phishing; Security and privacy; Sub-domains; Computerized tomography
"Richter P., Padmanabhan R., Spring N., Berger A., Clark D.",5,Advancing the art of internet edge outage detection,2018,0,"MIT / Akamai, United States; University of Maryland, United States; Akamai, MIT, United States; MIT, United States",MIT;University of Maryland College Park,2,USA,1,60,38,"Measuring reliability of edge networks in the Internet is difficult due to the size and heterogeneity of networks, the rarity of outages, and the difficulty of finding vantage points that can accurately capture such events at scale. In this paper, we use logs from a major CDN, detailing hourly request counts from address blocks. We discovered that in many edge address blocks, devices, collectively, contact the CDN every hour over weeks and months. We establish that a sudden temporary absence of these requests indicates a loss of Internet connectivity of those address blocks, events we call disruptions. We develop a disruption detection technique and present broad and detailed statistics on 1.5M disruption events over the course of a year. Our approach reveals that disruptions do not necessarily reflect actual service outages, but can be the result of prefix migrations. Major natural disasters are clearly represented in our data as expected; however, a large share of detected disruptions correlate well with planned human intervention during scheduled maintenance intervals, and are thus unlikely to be caused by external factors. Cross-evaluating our results we find that current state-of-the-art active outage detection over-estimates the occurrence of disruptions in some address blocks. Our observations of disruptions, service outages, and different causes for such events yield implications for the design of outage detection systems, as well as for policymakers seeking to establish reporting requirements for Internet services. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Internet outages; Internet reliability,Disasters; Detection techniques; Human intervention; Internet connectivity; Internet reliabilities; Internet services; Major natural disasters; Scheduled maintenance; State of the art; Arts computing
"Beverly R., Plonka D., Durairajan R., Rohrer J.P.",4,In the IP of the Beholder: Strategies for active IPv6 topology discovery,2018,1,"Naval Postgraduate School, United States; Akamai Technologies, United States; University of Oregon, United States",Naval Postgraduate School;University of Oregon,2,USA,1,59,48,"Existing methods for active topology discovery within the IPv6 Internet largely mirror those of IPv4. In light of the large and sparsely populated address space, in conjunction with aggressive ICMPv6 rate limiting by routers, this work develops a different approach to Internet-wide IPv6 topology mapping. We adopt randomized probing techniques in order to distribute probing load, minimize the effects of rate limiting, and probe at higher rates. Second, we extensively analyze the efficiency and efficacy of various IPv6 hitlists and target generation methods when used for topology discovery, and synthesize new target lists based on our empirical results to provide both breadth (coverage across networks) and depth (to find potential subnetting). Employing our probing strategy, we discover more than 1.3M IPv6 router interface addresses from a single vantage point. Finally, we share our prober implementation, synthesized target lists, and discovered IPv6 topology results. © 2018 Association for Computing Machinery.",Hitlists; IPv6; Topology,Routers; Topology; Address space; Generation method; Hitlists; IPv6; Probing strategies; Probing techniques; Topology discovery; Topology mapping; Internet protocols
"RŸth J., Zimmermann T., Wolsing K., Hohlfeld O.",4,Digging into Browser-based Crypto Mining,2018,2,"Communication and Distributed Systems, RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,30,25,"Mining is the foundation of blockchain-based cryptocurrencies such as Bitcoin rewarding the miner for finding blocks for new transactions. The Monero currency enables mining with standard hardware in contrast to special hardware (ASICs) as often used in Bitcoin, paving the way for in-browser mining as a new revenue model for website operators. In this work, we study the prevalence of this new phenomenon. We identify and classify mining websites in 138M domains and present a new fingerprinting method which finds up to a factor of 5.7 more miners than publicly available block lists. Our work identifies and dissects Coinhive as the major browser-mining stakeholder. Further, we present a new method to associate mined blocks in the Monero blockchain to mining pools and uncover that Coinhive currently contributes 1.18% of mined blocks having turned over 1293 Moneros in June 2018. © 2018 Association for Computing Machinery.",Blockchain; Cryptocurrency; Cryptojacking; Malware; Mining; Monero; Wasm; Webassembly,Blockchain; Hardware; Malware; Miners; Mining; Websites; Cryptojacking; Fingerprinting methods; Monero; Revenue models; Special hardware; Standard hardware; Wasm; Webassembly; Electronic money
"Kim S.K., Mason J., Ma Z., Miller A., Murali S., Bailey M.",6,Measuring ethereum network peers,2018,0,"University of Illinois at Urbana-Champaign, United States",UIUC,1,USA,1,59,54,"Ethereum, the second-largest cryptocurrency valued at a peak of $138 billion in 2018, is a decentralized, Turing-complete computing platform. Although the stability and security of Ethereum-and blockchain systems in general-have been widely-studied, most analysis has focused on application level features of these systems such as cryptographic mining challenges, smart contract semantics, or block mining operators. Little attention has been paid to the underlying peer-to-peer (P2P) networks that are responsible for information propagation and that enable blockchain consensus. In this work, we develop NodeFinder to measure this previously opaque network at scale and illuminate the properties of its nodes. We analyze the Ethereum network from two vantage points: a three-month long view of nodes on the P2P network, and a single day snapshot of the Ethereum Mainnet peers. We uncover a noisy DEVp2p ecosystem in which fewer than half of all nodes contribute to the Ethereum Mainnet. Through a comparison with other previously studied P2P networks including BitTorrent, Gnutella, and Bitcoin, we find that Ethereum differs in both network size and geographical distribution. © 2018 Copyright held by the owner/author(s).",DEVp2p; Ethereum; Network measurement; Peer-to-peer computing,Blockchain; Distributed computer systems; Electronic money; Geographical distribution; Information dissemination; Semantics; Application level; Computing platform; DEVp2p; Ethereum; Information propagation; Network measurement; Peer to Peer (P2P) network; Peer-to-peer computing; Peer to peer networks
"Lauinger T., Buyukkayhan A.S., Chaabane A., Robertson W., Kirda E.",5,From deletion to re-registration in zero seconds: Domain registrar behaviour during the drop,2018,0,"Northeastern University, United States; Nokia Bell Labs, United States",Nokia;Northeastern University,2,USA,1,18,13,"When desirable Internet domain names expire, they are often re-registered in the very moment the old registration is deleted, in a highly competitive and resource-intensive practice called domain drop-catching. To date, there has been little insight into the daily time period when expired domain names are deleted, and the race to re-registration that takes place. In this paper, we show that .com domains are deleted in a predictable order, and propose a model to infer the earliest possible time a domain could have been re-registered. We leverage this model to characterise at a precision of seconds how fast certain types of domain names are re-registered. We show that 9.5 % of deleted domains are re-registered with a delay of zero seconds. Domains not taken immediately by the drop-catch services are often re-registered later, with different behaviours over the following seconds, minutes and hours. Since these behaviours imply different effort and price points, our methodology can be useful for future work to explain the uses of re-registered domains. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Deletion time; Domain name; Domain Name System (DNS); Drop-catch; Expiration; Pending delete; Re-registration delay; Registrar,Measurement; Deletion time; Domain name system; Domain names; Expiration; Pending delete; Registrar; Drops
"Akhtar Z., Govindan R., Nam Y.S., Katz-Bassett E., Chen J., Rao S., Zhan J., Zhang H.",8,Understanding video management planes,2018,0,"University of Southern California, United States; Purdue University, United States; Columbia University, United States; University of Windsor, Canada; Conviva, United States",Columbia University;Purdue University;University of Southern California;University of Windsor,4,Canada;USA,2,81,55,"While Internet video control and data planes have received much research attention, little is known about the video management plane. In this paper, using data from more than a hundred video publishers spanning two years, we characterize the video management plane and its evolution. The management plane shows significant diversity with respect to video packaging, playback device support, and CDN use, and current trends suggest increasing diversity in some of these dimensions. This diversity adds complexity to management, and we show that the complexity of many management tasks is sub-linearly correlated with the number of hours a publisher's content is viewed. Moreover, today each publisher runs an independent management plane, and this practice can lead to sub-optimal outcomes for syndicated content, such as redundancies in CDN storage and loss of control for content owners over delivery quality. © 2018 Association for Computing Machinery.",Video Delivery; Video Management Plane,Digital storage; Data planes; Internet video; Loss of control; Management planes; Management tasks; Video delivery; Video management; Quality control
"Vermeulen K., Fourmaux O., Strowes S.D., Friedman T.",4,Multilevel MDA-lite Paris traceroute,2018,0,"Sorbonne UniversitŽ, Spain; RIPE NCC, Spain",UPMC Sorbonne UniversitŽ,1,Spain,1,48,31,"Since its introduction in 2006-2007, Paris Traceroute and its Multipath Detection Algorithm (MDA) have been used to conduct well over a billion IP level multipath route traces from platforms such as M-Lab. Unfortunately, the MDA requires a large number of packets in order to trace an entire topology of load balanced paths between a source and a destination, which makes it undesirable for platforms that otherwise deploy Paris Traceroute, such as RIPE Atlas. In this paper we present a major update to the Paris Traceroute tool. Our contributions are: (1) MDA-Lite, an alternative to the MDA that significantly cuts overhead while maintaining a low failure probability; (2) Fakeroute, a simulator that enables validation of a multipath route tracing tool's adherence to its claimed failure probability bounds; (3) multilevel multipath route tracing, with, for the first time, a Traceroute tool that provides a router-level view of multipath routes; and (4) surveys at both the IP and router levels of multipath routing in the Internet, showing, among other things, that load balancing topologies have increased in size well beyond what has been previously reported as recently as 2016. The data and the software underlying these results are publicly available. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Active Internet Measurements; Alias Resolution; Traceroute,Topology; Failure Probability; Internet measurement; Load-balanced; Multi path routing; Multi-path routes; Multipath detection; Traceroute; Traceroute tools; Internet protocols
"Zannettou S., Cauleld T., Blackburn J., De Cristofaro E., Sirivianos M., Stringhini G., Suarez-Tangil G.",7,On the origins of memes by means of fringe web communities,2018,1,"Cyprus University of Technology, Cyprus; University College London, United Kingdom; University of Alabama at Birmingham, Boston University, United States; King's College London, United Kingdom",Boston University;Cyprus University of Technology; Kings College London;University College London;University of Alabama at Birmingham,5,Cyprus;UK;USA,3,75,66,"Internet memes are increasingly used to sway and manipulate public opinion. This prompts the need to study their propagation, evolution, and influence across the Web. In this paper, we detect and measure the propagation of memes across multiple Web communities, using a processing pipeline based on perceptual hashing and clustering techniques, and a dataset of 160M images from 2.6B posts gathered from Twitter, Reddit, 4chan's Politically Incorrect board (/pol/), and Gab, over the course of 13 months. We group the images posted on fringe Web communities (/pol/, Gab, and The_Donald subreddit) into clusters, annotate them using meme metadata obtained from Know Your Meme, and also map images from mainstream communities (Twitter and Reddit) to the clusters. Our analysis provides an assessment of the popularity and diversity of memes in the context of each community, showing, e.g., that racist memes are extremely common in fringe Web communities. We also find a substantial number of politics-related memes on both mainstream and fringe Web communities, supporting media reports that memes might be used to enhance or harm politicians. Finally, we use Hawkes processes to model the interplay between Web communities and quantify their reciprocal influence, finding that /pol/ substantially influences the meme ecosystem with the number of memes it produces, while The_Donald has a higher success rate in pushing them to other communities. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",4chan; Gab; Influence; Memes; Reddit; Twitter,Social aspects; 4chan; Influence; Memes; Reddit; Twitter; Social networking (online)
"Li Z., Zhao B.Y., Zheng H., Ge Z., Mahimkar A., Wang J., Emmons J., Ogden L.",8,Predictive analysis in network function virtualization,2018,0,"UC Santa Barbara, United States; University of Chicago, United States; AT and T Labs Research, United States; AT and T, United States","AT and T Labs;University of California Santa Barbara;University of Illinois, Chicago",3,USA,1,37,24,"Recent deployments of Network Function Virtualization (NFV) architectures have gained tremendous traction. While virtualization introduces benefits such as lower costs and easier deployment of network functions, it adds additional layers that reduce transparency into faults at lower layers. To improve fault analysis and prediction for virtualized network functions (VNF), we envision a run-time predictive analysis system that runs in parallel with existing reactive monitoring systems to provide network operators timely warnings against faulty conditions. In this paper, we propose a deep learning based approach to reliably identify anomaly events from NFV system logs, and perform an empirical study using 18 consecutive months in 2016-2018 of real-world deployment data on virtualized provider edge routers. Our deep learning models, combined with customization and adaptation mechanisms, can successfully identify anomalous conditions that correlate with network trouble tickets. Analyzing these anomalies can help operators to optimize trouble ticket generation and processing rules in order to enable fast, or even proactive actions against faulty conditions. © 2018 Association for Computing Machinery.",Machine Learning; Network Function Virtualization,Deep learning; Learning algorithms; Learning systems; Predictive analytics; Transfer functions; Virtual reality; Adaptation mechanism; Empirical studies; Faulty condition; Learning-based approach; Network functions; Network operator; Reactive monitoring; Real world deployment; Network function virtualization
"Kolamunna H., Leontiadis I., Perino D., Seneviratne S., Thilakarathna K., Seneviratne A.",6,A first look at SIM-enabled wearables in the wild,2018,0,"University of New South Wales, Sydney, Australia; Telefonica Research, Spain; University of Sydney, Sydney, Australia; Data61-CSIRO, Australia",Telefonica Research;University of New South Wales;University of Sydney,3,Australia;Spain,2,20,20,"Recent advances are driving wearables towards stand-alone devices with cellular network support (e.g. SIM-enabled Apple Watch series-3). Nonetheless, a little has been studied on SIM-enabled wearable traffic in ISP networks to gain customer insights and to understand traffic characteristics. In this paper, we characterize the network traffic of several thousand SIM-enabled wearable users in a large European mobile ISP. We present insights on user behavior, application characteristics such as popularity and usage, and wearable traffic patterns. We observed a 9% increase in SIM-enabled wearable users over a five month observation period. However, only 34% of such users actually generate any network transaction. Our analysis also indicates that SIM-enabled wearable users are significantly more active in terms of mobility, data consumption and frequency of app usage compared to the remaining customers of the ISP who are mostly equipped with a smartphone. Finally, wearable apps directly communicate with third parties such as advertisement and analytics networks similarly to smartphone apps. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",IoT; Mobile Networks; Wearables,Behavioral research; Internet service providers; Mobile telecommunication systems; Smartphones; Wireless networks; Cellular network; Customer insights; Network transactions; Observation Period; Smartphone apps; Stand-alone devices; Traffic characteristics; Wearables; Wearable technology
"Deng H., Peng C., Fida A., Meng J., Charlie Hu Y.",5,Mobility support in cellular networks: A measurement study on its configurations and implications,2018,0,"Purdue University, United States",Purdue University,1,USA,1,34,25,"In this paper, we conduct the first global-scale measurement study to unveil how 30 mobile operators manage mobility support in their carrier networks. Using a novel, device-centric tool, MMLab, we are able to crawl runtime configurations without the assistance from operators. Using handoff configurations from 32,000+ cells and > 18, 700 handoff instances, we uncover how policy-based handoffs work in practice. We further study how the configuration parameters affect the handoff performance and user data access. Our study exhibits three main points regarding handoff configurations. 1) Operators deploy extremely complex and diverse configurations to control how handoff is performed. 2) The setting of handoff configuration values affect data performance in a rational way. 3) While giving better control granularity over handoff procedures, such diverse configurations also lead to unexpected negative compound effects to performance and efficiency. Moreover, our study of mobility support through a device-side approach gives valuable insights to network operators, mobile users and the research community. © 2018 Association for Computing Machinery.",Cellular network; Handoff configuration; Measurement; Mobility management,Lead compounds; Measurement; Wireless networks; Cellular network; Configuration parameters; Handoff configuration; Handoff performance; Handoff procedures; Mobility management; Research communities; Run-time configuration; Mobile telecommunication systems
"Chung T., Choffnes D., Mislove A., Lok J., Levin D., Rula J., Wilson C., Chandrasekaran B., Maggs B.M., Sullivan N.",10,Is the web ready for OCSP must-staple?,2018,0,"Rochester Institute of Technology, United States; Northeastern University, United States; University of Maryland, United States; Akamai Technologies, United States; Max Planck Institute for Informatics, United States; Duke University, United States; Cloudflare, United States","Duke University;Max Planck Institute,Germany;Northeastern University;Rochester Institute of Technology;University of Maryland College Park",5,USA,1,41,31,"TLS, the de facto standard protocol for securing communications over the Internet, relies on a hierarchy of certificates that bind names to public keys. Naturally, ensuring that the communicating parties are using only valid certificates is a necessary first step in order to benefit from the security of TLS. To this end, most certificates and clients support OCSP, a protocol for querying a certificate's revocation status and confirming that it is still valid. Unfortunately, however, OCSP has been criticized for its slow performance, unreliability, soft-failures, and privacy issues. To address these issues, the OCSP Must-Staple certificate extension was introduced, which requires web servers to provide OCSP responses to clients during the TLS handshake, making revocation checks low-cost for clients. Whether all of the players in the web's PKI are ready to support OCSP Must-Staple, however, remains still an open question. In this paper, we take a broad look at the web's PKI and determine if all components involved-namely, certificate authorities, web server administrators, and web browsers-are ready to support OCSP Must-Staple. We find that each component does not yet fully support OCSP Must-Staple: OCSP responders are still not fully reliable, and most major web browsers and web server implementations do not fully support OCSP Must-Staple. On the bright side, only a few players need to take action to make it possible for web server administrators to begin relying on certificates with OCSP Must-Staple. Thus, we believe a much wider deployment of OCSP Must-Staple is an realistic and achievable goal. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",HTTPS; OCSP; PKI; Public Key Infrastructure,HTTP; Public key cryptography; Seebeck effect; Web services; Certificate authority; De facto standard; HTTPS; OCSP; Privacy issue; Public key infrastructure; Revocation checks; Revocation status; Web browsers
"Wang H., Liu Z., Liang J., Vallina-Rodriguez N., Guo Y., Li L., Tapiador J., Cao J., Xu G.",9,Beyond Google play: A large-scale comparative study of Chinese android app markets,2018,0,"Beijing University of Posts and Telecommunications, China; Key Laboratory of High-Confidence Software Technologies (MOE), Peking University, 3 IMDEA Networks, 4 ICSI, China; Monash University, Australia; Universidad Carlos III de Madrid, Spain; Indiana University, Bloomington, United States",Beijing University of Posts and Telecommunications;Indiana University;Monash University;Peking University;Universidad Carlos III de Madrid,5,Australia;China;India;Spain;USA,5,103,98,"China is one of the largest Android markets in the world. As Chinese users cannot access Google Play to buy and install Android apps, a number of independent app stores have emerged and compete in the Chinese app market. Some of the Chinese app stores are pre-installed vendor-specific app markets (e.g., Huawei, Xiaomi and OPPO), whereas others are maintained by large tech companies (e.g., Baidu, Qihoo 360 and Tencent). The nature of these app stores and the content available through them vary greatly, including their trustworthiness and security guarantees. As of today, the research community has not studied the Chinese Android ecosystem in depth. To fill this gap, we present the first large-scale comparative study that covers more than 6 million Android apps downloaded from 16 Chinese app markets and Google Play. We focus our study on catalog similarity across app stores, their features, publishing dynamics, and the prevalence of various forms of misbehavior (including the presence of fake, cloned and malicious apps). Our findings also suggest heterogeneous developer behavior across app stores, in terms of code maintenance, use of third-party services, and so forth. Overall, Chinese app markets perform substantially worse when taking active measures to protect mobile users and legit developers from deceptive and abusive actors, showing a significantly higher prevalence of malware, fake, and cloned apps than Google Play. © 2018 Association for Computing Machinery.",Android market; App ecosystem; Cloned app; Google Play; Malware; Permission; Third-party library,Cloning; Commerce; Computer crime; Ecosystems; FORTH (programming language); Malware; Network security; Android markets; Comparative studies; Developer behavior; Google plays; Permission; Research communities; Third parties; Third party services; Android (operating system)
"Gasser O., Lone Q., Scheitle Q., Korczy_ski M., Foremski P., Strowes S.D., Hendriks L., Carle G.",8,Clusters in the expanse: Understanding and unbiasing IPv6 Hitlists,2018,1,"Technical University of Munich, Germany; Grenoble Alps University, France; IITiS PAN, Poland; RIPE NCC, United States; University of Twente, Netherlands",Grenoble Alps University;TU Munich;University of Twente,3,France;Germany;Netherlands;Poland;USA,5,79,44,"Network measurements are an important tool in understanding the Internet. Due to the expanse of the IPv6 address space, exhaustive scans as in IPv4 are not possible for IPv6. In recent years, several studies have proposed the use of target lists of IPv6 addresses, called IPv6 hitlists. In this paper, we show that addresses in IPv6 hitlists are heavily clustered. We present novel techniques that allow IPv6 hitlists to be pushed from quantity to quality. We perform a longitudinal active measurement study over 6 months, targeting more than 50 M addresses. We develop a rigorous method to detect aliased prefixes, which identifies 1.5 % of our prefixes as aliased, pertaining to about half of our target addresses. Using entropy clustering, we group the entire hitlist into just 6 distinct addressing schemes. Furthermore, we perform client measurements by leveraging crowdsourcing. To encourage reproducibility in network measurement research and to serve as a starting point for future IPv6 studies, we publish source code, analysis tools, and data. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Aliasing; Clustering; Entropy; Hitlist; IPv6,Entropy; Active measurement; Addressing scheme; Aliasing; Clustering; Hitlist; IPv6; Network measurement; Reproducibilities; Internet protocols
"Hoang N.P., Antonakakis M., Kintis P., Polychronakis M.",4,An empirical study of the i2P anonymity network and its censorship resistance,2018,0,"Stony Brook University, Stony Brook, NY, United States; Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech;Stony Brook University,2,USA,1,75,65,"Tor and I2P are well-known anonymity networks used by many individuals to protect their online privacy and anonymity. Tor's centralized directory services facilitate the understanding of the Tor network, as well as the measurement and visualization of its structure through the Tor Metrics project. In contrast, I2P does not rely on centralized directory servers, and thus obtaining a complete view of the network is challenging. In this work, we conduct an empirical study of the I2P network, in which we measure properties including population, churn rate, router type, and the geographic distribution of I2P peers. We find that there are currently around 32K active I2P peers in the network on a daily basis. Of these peers, 14K are located behind NAT or firewalls. Using the collected network data, we examine the blocking resistance of I2P against a censor that wants to prevent access to I2P using address-based blocking techniques. Despite the decentralized characteristics of I2P, we discover that a censor can block more than 95% of peer IP addresses known by a stable I2P client by operating only 10 routers in the network. This amounts to severe network impairment: a blocking rate of more than 70% is enough to cause significant latency in web browsing activities, while blocking more than 90% of peer IP addresses can make the network unusable. Finally, we discuss the security consequences of the network being blocked, and directions for potential approaches to make I2P more resistant to blocking. © 2018 Association for Computing Machinery.",Blocking resistance; I2P anonymity network; Internet censorship; Network metrics,Geographical distribution; Network security; Anonymity networks; Blocking resistance; Blocking technique; Directory service; Empirical studies; Internet censorship; Network impairments; Network metrics; Internet protocols
"Zhu L., Heidemann J.",2,LDPlayer: DNS experimentation at scale,2018,0,"USC/Information Sciences Institute, United States",University of Southern California,1,USA,1,34,14,"DNS has evolved over the last 20 years, improving in security and privacy and broadening the kinds of applications it supports. However, this evolution has been slowed by the large installed base and the wide range of implementations. The impact of changes is difficult to model due to complex interactions between DNS optimizations, caching, and distributed operation. We suggest that experimentation at scale is needed to evaluate changes and facilitate DNS evolution. This paper presents LDplayer, a configurable, general-purpose DNS experimental framework that enables DNS experiments to scale in several dimensions: many zones, multiple levels of DNS hierarchy, high query rates, and diverse query sources. LDplayer provides high fidelity experiments while meeting these requirements through its distributed DNS query replay system, methods to rebuild the relevant DNS hierarchy from traces, and efficient emulation of this hierarchy on minimal hardware. We show that a single DNS server can correctly emulate multiple independent levels of the DNS hierarchy while providing correct responses as if they were independent. We validate that our system can replay a DNS root traffic with tiny error (± 8ms quartiles in query timing and ± 0.1% difference in query rate). We show that our system can replay queries at 87k queries/s while using only one CPU, more than twice of a normal DNS Root traffic rate. LDplayer's trace replay has the unique ability to evaluate important design questions with confidence that we capture the interplay of caching, timeouts, and resource constraints. As an example, we demonstrate the memory requirements of a DNS root server with all traffic running over TCP and TLS, and identify performance discontinuities in latency as a function of client RTT. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Domain Name System (DNS); Experiments; Performance; Trace replay,Experiments; Measurement; Distributed operations; Domain name system; Impact of changes; Memory requirements; Performance; Resource Constraint; Security and privacy; Trace replay; Internet protocols
Hohlfeld O.,1,Operating a DNS-based active internet observatory,2018,1,"RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,14,8,"The Internet is subject to constant evolution. Its improvement requires understanding its current properties, a perspective provided by measurement studies. A key challenge in broadly studying evolution is to i) cover multiple protocols ii) with longitudinal measurements. In this poster, we present an Internet observatory that performs active measurements of multiple protocols (e.g., DNS, HTTP2, QUIC) regularly since 2016. Its measurements cover both i) the entire IPv4 address space and ii) > 50% of the domain name space to provide a new perspective on Internet evolution. The goal of this poster is to present its extensible architecture and capabilities, thereby aiming to foster collaboration. © 2018 Association for Computing Machinery.",Active measurements; CDN; Cloud; DNS; HTTP2; QUIC,Clouds; Observatories; Active measurement; Address space; Current properties; Domain names; HTTP2; Internet evolutions; Measurement study; QUIC; Internet protocols
"Alasmar M., Parisis G., Crowcroft J.",3,Polyraptor: Embracing path and data redundancy in data centres for efficient data transport,2018,0,"Department of Informatics, University of Sussex, United Kingdom; Computer Laboratory, University of Cambridge, United Kingdom",University of Cambridge;University of Sussex,2,UK,1,9,8,"In this paper, we introduce Polyraptor, a novel data transport protocol that uses RaptorQ (RQ) codes and is tailored for one-to-many and many-to-one data transfer patterns, which are extremely common in modern data centres. Polyraptor builds on previous work on fountain coding-based transport and provides excellent performance, by exploiting native support for multicasting in data centres and data resilience provided by data replication. © 2018 Association for Computing Machinery.",Data transport; Datacenter storage; Fountain coding,Codes (symbols); Data transfer; Fountains; Multicasting; Data centres; Data redundancy; Data replication; Data transport; Data transport protocols; Datacenter; Many-to-one; Transfer patterns; Digital storage
"Zeljkovic E., Marquez-Barja J.M., LatrŽ S.",3,A large-scale demonstration of SDN-based handover management in IEEE 802.11 networks,2018,0,"University of Antwerp - Imec, IDLab research group, Antwerp, Belgium",University of Antwerp - Imec,1,Belgium,1,5,5,"The density of Wi-Fi at professional environments, such as offices, is resulting in increased strain on the management of Wi-Fi networks, of which handovers are an essential part of. The centralized approach of SDN allows taking more intelligent decisions, as opposed to per device optimizations. There is thus an increased interest in SDN-based Wi-Fi management, especially for handovers. Several proposals for SDNbased handover algorithms are being investigated and there is a need for actually validating them. In this demo, we will showcase a Wi-Fi SDN framework, on top of which a number of decision-making handover algorithms can be used. This framework is used in a real-life, large scale Wi-Fi testbed. The framework allows for different decision-making handover algorithms to be created and validated on large scale. © 2018 Association for Computing Machinery.",Algorithm; Framework; Handover; IEEE 802.11; SDN,Algorithms; Decision making; Wi-Fi; Wireless local area networks (WLAN); Centralized approaches; Framework; Handover; Handover algorithms; IEEE 802.11 networks; IEEE 802.11s; Intelligent decisions; Professional environments; IEEE Standards
"Blenk A., Basta A., Henkel L., Zerwas J., Kellerer W., Schmid S.",6,Perfbench: A tool for predictability analysis in multi-tenant software-defined networks,2018,0,"Technical University of Munich, Germany; University of Vienna, Austria",TU Munich;University of Vienna,2,Austria;Germany,2,7,7,"Network Virtualization (NV) provides low resource costs and high utilization, while ensuring bandwidth isolation in the data plane. Software-Defined Networks (SDNs) are a particularly interesting technology to implement NV, as tenants maintain control over their virtual Software-Defined Networks (vSDNs). However, bandwidth isolation alone may not be enough to provide a predictable application performance in virtual networks, as the virtualization layer itself is another source of potential performance interference. Today, we lack tools that help reveal and investigate such sources of interference and identify performance inefficiencies. In order to fill this gap, we developed a new tool - perfbench. We report on the tool design and our initial findings. © 2018 Association for Computing Machinery.",Measurements; Multi-tenancy; Network slicing; Openflow; Performance; Virtual networks,Bandwidth; Measurement; Virtual reality; Virtualization; Multi tenancies; Network slicing; Openflow; Performance; Virtual networks; Software defined networking
"Jog S., Wang J., Hassanieh H., Choudhury R.R.",4,Enabling dense spatial reuse in mmWave networks,2018,0,"University of Illinois at Urbana Champaign, United States",UIUC,1,USA,1,7,6,"Millimeter Wave (mmWave) networks can deliver multi- Gbps wireless links that use extremely narrow directional beams. This provides us with a new way to exploit spatial reuse in order to scale network throughput. In this work, we present MilliNet, the first millimeter wave network that can exploit dense spatial reuse to allow many links to operate in parallel in a confined space and scale the wireless throughput with the number of clients. Results from a 60 GHz testbed show that MilliNet can deliver a total wireless network data rate of more than 38 Gbps for 10 clients which is 5.8_ higher than current 802.11 mmWave standards. © 2018 Association for Computing Machinery.",Beam alignment; Millimeter wave; Spatial reuse; VR,IEEE Standards; Beam alignments; Confined space; Millimeter waves (mmwave); Multi-Gbps; Network data rates; Network throughput; Spatial reuse; Wireless link; Millimeter waves
"Kalmbach P., Gleiter L., Zerwas J., Blenk A., Kellerer W., Schmid S.",6,Modeling IP-to-IP communication using the weighted stochastic block model,2018,0,"Technical University of Munich, Germany; University of Vienna, Austria",TU Munich;University of Vienna,2,Austria;Germany,2,8,8,"The vision of self-driving networks integrates network measurements with network control. Processing data for each of the network control tasks separately might be prohibitive due to the large volume and waste of computational resources. In this work we make the case of using theWeighted Stochastic Block Model (WSBM), a probabilistic model, to learn a task independent representation. In particular, we consider a case study of real-world IP-to-IP communication. The learned representation provides higher level-features for traffic engineering, anomaly detection, or other tasks, and reduces their computational effort. We find that the WSBM is able to accurately model traffic and structure of communication in the considered trace. © 2018 Association for Computing Machinery.",Data analysis; Network monitoring; Stochastic block model,Data handling; Data reduction; Internet protocols; Stochastic systems; Anomaly detection; Computational effort; Computational resources; Network measurement; Network Monitoring; Probabilistic modeling; Stochastic block models; Traffic Engineering; Stochastic models
"Rodriguez F., Patra P.G.K., Csikor L., Rothenberg C., Všršs P., Laki S., Pongr‡cz G.",7,BB-Gen: A packet crafter for P4 target evaluation,2018,1,"University of Campinas, Brazil; ELTE Eštvšs Lor‡nd University, Brazil; Ericsson Research, Brazil",Eotvos Lorand University;Ericsson Research;University of Campinas,3,Brazil,1,14,13,"With P4 gaining traction to define datapath pipelines along auto-generated control plane APIs, the protocol-independence and increased flexibility add non-trivial hazards when it comes to functional and in-depth performance evaluation. P4-dependent workload traces are needed along automated methods to populate the tables of the datapath under test accordingly. Without proper tools, manual efforts are required for tedious tasks such as creating appropriate PCAP traces, defining the distribution of field values, and inserting entries in the pipeline tables. To this end, we present BB-Gen, a packet crafter and table generator tool that given a P4 application and a corresponding user configuration results in packet and table traces to carry automated performance evaluation tasks.We demonstrate BB-Gen with P4 applications of increasing complexity (from L2 to VXLAN-based Data Center Gateway), using two different multi-architecture backend compilers (MACSAD, T4P4S) and different targets. © 2018 Association for Computing Machinery.",P4; Performance analysis; Software defined networking,Pipelines; Software defined networking; Traction control; Automated methods; Control planes; Data centers; Field values; Generator tool; Increased flexibility; Performance analysis; Performance evaluations; Gateways (computer networks)
"Xiang Q., Guok C., Le F., MacAuley J., Newman H., Yang Y.R.",6,SFP: Toward interdomain routing for SDN networks,2018,0,"Tongji/Yale, China; LBNL, United States; IBM, United States; Caltech, United States",IBM,1,China;USA,2,5,2,"Interdomain routing using BGP is widely deployed and well understood. The deployment of SDN in BGP domain networks, however, has not been systematically studied. In this paper, we? rst show that the use-announcement inconsistency is a fundamental mismatch in such a deployment, leading to serious issues including unnecessary blackholes, unnecessary reduced reachability, and permanent forwarding loops.We then design SFP, the? rst? ne-grained interdomain routing protocol that extends BGP with? ne-grained routing, eliminating the aforementioned mismatch. We develop two novel techniques, automatic receiver? ltering and ondemand information dissemination, to address the scalability issue brought by? ne-grained routing. Evaluating SFP using real network topologies and traces for intended settings, which are not global Internet but tens of collaborative domains, we show that SFP can reduce the amount of tra?c a?ected by blackholes and loops by more than 50%, and that our proposed techniques can reduce the amount of signaling between ASes by 3 orders of magnitude compared with naive ?ne-grained routing. © 2018 Association for Computing Machinery.",Interdomain routing; On-demand information dissemination; SDN,Distributed computer systems; Information dissemination; Black holes; Global Internet; Interdomain Routing; Novel techniques; Orders of magnitude; Reachability; Real networks; Scalability issue; Network routing
"Mar’n G., Casas P., Capdehourat G.",3,RawPower: Deep learning based anomaly detection from raw network traffic measurements,2018,0,"AIT Austrian Institute of Technology, IIE-FING, UDELAR, Uruguay; AIT Austrian Institute of Technology, Austria; IIE-FING, UDELAR, Uruguay",AIT Austrian Institute of Technology,1,Austria;Uruguay,2,6,6,"Machine learning models using deep architectures (i.e., deep learning) have gained path in recent years and have become state-of-the-art in many fields, including computer vision, speech recognition and natural language processing. However, when it comes to network measurement and analysis, classic machine learning approaches are commonly used, heavily relying on domain expert knowledge. In this work, we explore the power of deep learning models to perform anomaly detection on network traffic data, taking as input raw measurements coming directly from the stream of monitored bytes. Our initial results suggest that deep learning can enhance anomaly detection without requiring expert domain knowledge to handcraft input features. © 2018 Association for Computing Machinery.",Anomaly detection; Deep learning; Network traffic measurements and analysis,Artificial intelligence; Learning algorithms; Natural language processing systems; Speech recognition; Anomaly detection; Deep architectures; Domain expert knowledge; Machine learning approaches; Machine learning models; Network measurement; Network traffic measurement; Raw measurements; Deep learning
"Bressana P., Zilberman N., SoulŽ R.",3,A programmable framework for validating data planes,2018,0,"Universitˆ della Svizzera italiana, Italy; University of Cambridge, United Kingdom",University of Cambridge;Universitˆ della Svizzera italiana,2,Italy;UK,2,11,11,"Due to the emerging trend of programmable network hardware, developers have begun to explore ways to accelerate various applications and services. As a result, there is a pressing need for newtools and techniques for debugging network devices. This paper presents NetDebug, a fully programmable hardware-software framework for validating and real-time debugging of programmable data planes. We describe validation use cases, compare our design to alternative solutions, and present a preliminary evaluation using a prototype implementation. © 2018 Association for Computing Machinery.",Data plane validation; Networking hardware; Programmable networks,Computer debugging; Hardware; Programmed control systems; Alternative solutions; Data planes; Emerging trends; Fully programmables; Programmable network; Prototype implementations; Real time debugging; Software frameworks; Program debugging
"Junior B., Ferreira R.A., Cunha I., Schlinker B., Katz-Bassett E.",5,High-fidelity interdomain routing experiments,2018,0,"UFMS, Brazil; UFMG, Brazil; USC, United States; Columbia, United States","UFMG, Brazil;University of Southern California;UFMS, Brazil",3,Brazil;USA,2,5,4,"The PEERING research platform lets researchers exchange actual BGP routes and traffic with hundreds of networks. To date, several researchers have used PEERING to perform interdomain routing experiments. However, PEERING's original design sends experiment data-plane traffic through a VPN, introducing latency and jitter, hindering the applicability of the platform to performance-sensitive experiments. In this work, we propose extensions to PEERING to allow researchers to run applications inside containers on PEERING routers, mitigating performance degradation on dataplane traffic and empowering new classes of experiments. Our goals include strong isolation between experiments and flexible routing to steer traffic in and out of containers. © 2018 Association for Computing Machinery.",BGP; Experimentation; Interdomain routing; Testbed,Testbeds; Experiment data; Experimentation; Flexible routing; High-fidelity; Interdomain Routing; Original design; Performance degradation; Research platforms; Containers
"Arnold T., Schlinker B., Cunha I., Katz-Bassett E.",4,Controlling real cloud experiments from BGP to the server (and back),2018,0,"Columbia University, United States; University of Southern California, United States; Universidade Federal De Minas Gerais, Brazil",Columbia University;Universidade Federal De Minas Gerais;University of Southern California,3,Brazil;USA,2,22,18,"One of the impediments in performing Internet routing research is the lack of infrastructure capable of supporting experiments with both control and realism. Measurement and experimentation platforms provide minimal control over routing, limited connectivity, and restrict what operations are available. Meanwhile, the proprietary nature of routing policies stymies simulations from providing realism. To address these deficiencies, we present the Peering Testbed, which is capable of safely providing both realism and control. Peering has a dozen PoPs on three continents, each participating in BGP sessions on the Internet. The system's novel approach to support experiments allows each experiment to quickly and easily customize its interaction with the Internet. We will demonstrate new features of the testbed: federating with other testbeds to enable experiments that span the network edge, WAN, and data center network in a unified manner without the need for traversing the public Internet. This allows researchers to create their own global network, with data centers, similar to that of cloud providers, with control over how traffic is delivered to and from services on the real Internet. © 2018 Association for Computing Machinery.",Border gateway protocol; Internet routing; Testbeds; Traffic engineering,Gateways (computer networks); Testbeds; Cloud providers; Data center networks; Experimentation platforms; Global networks; Internet routing; Public internet; Routing policies; Traffic Engineering; Border Gateway Protocol
"Czentye J., D—ka J., Nagy A., Toka L., Sonkoly B., Szab— R.",6,Controlling drones from 5G networks,2018,0,"MTA-BME Network Softwarization Research Group, Hungary; Ericsson Research, Hungary",Ericsson Research;MTA-BME,2,Hungary,1,2,2,"Envisioned 5G applications are key drivers of the evolution of network and cloud architectures. These novel services pose several challenges on the underlying infrastructure in terms of latency, reliability or capacity, just to mention a few. Controlling or coordinating both indoor and outdoor drones from future networks is a potential application with significant importance. Today's technologies addressing network softwarization, such as Software Defined Networking (SDN) and Network Function Virtualization (NFV), enable a novel way to create and provision such services. In this demonstration, we showcase an Industry 4.0 use-case including a local factory equipped with drones and local cloud and network facilities connecting to remote cloud resources. The envisioned service is realized by a Service Function Chain (SFC) consisting of network functions and logical connections between them with special requirements. In addition, the envisioned service is integrated with our multi-domain resource orchestration system and as a result, it can be controlled, deployed and monitored from that framework. The use-case and the demo well illustrate several aspects and challenges which should be addressed by future 5G systems. © 2018 Association for Computing Machinery.",5G; Drones; Multi-domain orchestration; NFV; SDN; SFC,Aircraft control; Drones; Network function virtualization; Queueing networks; Transfer functions; 5g networks; Cloud architectures; Future networks; Logical connections; Multi domains; Network functions; Service functions; Software defined networking (SDN); 5G mobile communication systems
"Wang S., Zhao Y., Xie H.",3,SN-FFC: Improving survivability of LEO satellite network with forward fault correction,2018,0,"Department of Computer Science and Technology, Tsinghua University, China",Tsinghua University,1,China,1,2,2,"Low Earth Orbit (LEO) Satellite network will suffer from heavy congestion under network faults such as node failure, which affects its survivability. Traffic engineering is the mechanism to solve such problem. In data-center wide area networks (DCWAN), Forward Fault Correction (FFC), a proactive traffic engineering system, can ensure that the network is free from congestion as long as the number of faults is up to k. Inspired by FFC, we implement SN-FFC in LEO satellite network. We show how SN-FFC can transmit data flows normally in the case of node failures. Our simulation results show that the LEO satellite network and the DCWAN have certain similarities in the fault-tolerance mechanism based on traffic engineering with FFC. Therefore, it can guide us to do more in-depth research in this area. © 2018 Association for Computing Machinery.",Fault-tolerant; Forward fault correction; LEO satellite network; Traffic engineering,Fault tolerance; Satellites; Traffic congestion; Wide area networks; Fault corrections; Fault tolerance mechanisms; Fault-tolerant; LEO satellite networks; Low earth orbit satellites; Network faults; Traffic Engineering; Transmit data; Orbits
"Bianchi G., Welzl M., Tulumello A., Belocchi G., Faltelli M., Pontarelli S.",6,A fully portable TCP implementation using XFSMs,2018,0,"CNIT, University of Rome Tor Vergata, Italy; University of Oslo, Norway",University of Oslo;University of Rome Tor Vergata,2,Italy;Norway,2,9,7,"XTRA (XFSM for TRAnsport) is a first step towards ""codeonce- port-everywhere"" transport protocols. XTRA's platformagnostic programming abstraction, based on an extended finite state machine formalization of a desired transport layer task, is amenable not only to SW engines, but can be directly executed in CPU-less custom HW, thus permits to harness FPGA-based NICs' offloading opportunities without any re-coding effort. We experimentally demonstrate that XTRA enables us to port a customized TCP implementation across three completely different environments (HW proofof- concept on a NetFPGA board, User-space SW over Linux' Open Data Plane, and NS3 emulator). © 2018 Association for Computing Machinery.",Data plane programmability; Hardware acceleration; Offloading; TCP,Computer aided software engineering; Computer operating systems; Computer programming; Field programmable gate arrays (FPGA); Extended finite state machine; Hardware acceleration; Offloading; Programmability; Programming abstractions; Proof of concept; Transport layers; Transport protocols; Transmission control protocol
"Csikor L., Rothenberg C., Pezaros D.P., Schmid S., Toka L., RŽtv‡ri G.",6,Policy injection: A cloud dataplane DoS attack,2018,0,"University of Campinas, Brazil; University of Glasgow, United Kingdom; University of Vienna, Austria; Budapest Univ. of Techn. and Economics, Hungary",University of Campinas;University of Glasgow;University of Vienna,3,Austria;Brazil;Hungary;UK,4,9,6,"Enterprises continue to migrate their services to the cloud on a massive scale, but the increasing attack surface has become a natural target for malevolent actors. We show policy injection, a novel algorithmic complexity attack that enables a tenant to add specially tailored ACLs into the data center fabric to mount a denial-of-service attack through exploiting the built-in security mechanisms of the cloud management systems (CMS) . Our insight is that certain ACLs, when fed with special covert packets by an attacker, may be very difficult to evaluate, leading to an exhaustion of cloud resources. We show how a tenant can inject seemingly harmless ACLs into the cloud data plane to abuse an algorithmic deficiency in the most popular cloud hypervisor switch, Open vSwitch, and reduce its effective peak performance by 80-90%, and, in certain cases, denying network access altogether. © 2018 Association for Computing Machinery.",Cloud security; DoS; OVS; Policy injection,Computational complexity; DOS; Information management; Parallel processing systems; Algorithmic complexity; Cloud hypervisor; Cloud managements; Cloud securities; Natural targets; Network access; Peak performance; Security mechanism; Denial-of-service attack
"Saidi S.J., Foucard D., Smaragdakis G., Feldmann A.",4,Flowtree: Enabling distributed flow summarization at scale,2018,0,"MPI-Informatics, Germany; TU Berlin, Germany; TU Berlin, MIT, Germany; MPI-Informatics, UDS, Germany",MIT;TU Berlin,2,Germany,1,5,1,"NetFlow and IPFIX raw flow captures are insightful yet, due to their large volume, challenging to timely analyze and query. In particular, if these captures span long time periods or are collected at remote locations, storing or transferring them for analysis becomes increasingly expensive. Enabling efficient execution of a large range of queries over flow captures while reducing storage and transfer volume requires working with mergeable succinct summaries that capture the most essential features of flows dynamically. However, the problem of building such structures is yet unmet. In this work, we introduce a self-adjusting data structure of generalized flows, called Flowtree, that (1) reduces the storage requirements by more than 95% while providing highly accurate answers for popular hierarchical flows, (2) minimizes transfer cost of flow summaries, and (3) supports several operators with distributed execution and summarization across time and multiple sites. The evaluation of our solution on different network traces confirms that Flowtree can accurately and promptly answer questions about flows using different feature sets. © 2018 Association for Computing Machinery.",Flow summarization; Network monitoring,Distributed flow; Essential features; Flow summarization; Hierarchical flow; Network Monitoring; Self-adjusting data structures; Storage requirements; Transfer volumes; Digital storage
"Varga D., Laki S.",2,Scalable surface reconstruction in the mobile edge,2018,0,"ELTE Eštvšs Lor‡nd University, Budapest, Hungary",Eotvos Lorand University,1,Hungary,1,3,3,"Various augmented and virtual reality (AR/VR) applications have emerged in the past years and their popularity are still increasing. Most of these applications work near real-time, posing low-latency requirements against the algorithms to be used. The high computational complexity of 3D mesh generation from continuous 3D point cloud streams provided by depth cameras requires strong processors that have high energy consumption, leading to low battery life of mobile devices. By moving the processing to mobile edge computing (MEC) servers, the smart phones can be offloaded and thus their battery life can be extended. In this paper, we propose a highly-scalable method for near real-time 3D mesh generation by exploiting the advances of MEC. © 2018 Association for Computing Machinery.",Mobile edge cloud; Parallel computing; Surface reconstruction,Electric batteries; Energy utilization; Green computing; Mesh generation; Parallel processing systems; Scalability; Smartphones; Virtual reality; 3d mesh generations; 3D point cloud; Augmented and virtual realities; Edge clouds; High energy consumption; Mobile Edge Computing; Near-real time; Scalable methods; Surface reconstruction
"Deng B., Wu W.",2,Redundant logic elimination in network functions,2018,0,"Tsinghua University, China",Tsinghua University,1,China,1,5,3,"In current NFV ecosystem, most software NFs delivered by NF vendors tend to be monolithic with multiple features. In runtime, an NF is configured with a subset of its features turned on/off. By our code analysis and primary test, we find that some of the (runtime) unused features are executed silently, which wastes CPU cycles and memory. We propose to use program analysis techniques to eliminate runtime redundant logic in NF code so that the NF performance can be accelerated. We prototype our idea and test it on Snort to show the feasibility. © 2018 Association for Computing Machinery.",Network functions; Redundant logic elimination,Network function virtualization; Transfer functions; Code analysis; CPU cycles; In networks; Multiple features; Network functions; Program analysis; Redundant logic elimination; Runtimes; Computer circuits
"Mulinka P., Casas P.",2,Adaptive network security through stream machine learning,2018,0,"CTU Czech Technical University in Prague, AIT Austrian Institute of Technology, Austria; AIT Austrian Institute of Technology, Austria",AIT Austrian Institute of Technology;Czech Technical University,2,Austria,1,3,2,"Stream Machine Learning is rapidly gaining popularity within the network monitoring community as the big data produced by network devices and end-user terminals goes beyond the memory constraints of standard monitoring equipment. We consider a stream-based machine learning approach to network security, conceiving adaptive machine learning algorithms for the analysis of continuously evolving network data streams. Using a sliding-windowadaptive-size approach, we show that adaptive random forests models are able to keep up with important concept drifts in the underlying network data streams, by keeping high accuracy with continuous re-training at concept drift detection times. © 2018 Association for Computing Machinery.",Data stream mining; Machine learning; Network attacks,Artificial intelligence; Big data; Decision trees; Learning algorithms; Learning systems; Adaptive machine learning; Data stream mining; End user terminals; Machine learning approaches; Monitoring equipment; Network attack; Network Monitoring; Underlying networks; Network security
"Dšpmann C., Tschorsch F.",2,CircuitStart: A slow start for multi-hop anonymity systems,2018,0,"Technische UniversitŠt Berlin, Berlin, Germany",TU Berlin,1,Germany,1,5,2,"In order to improve the performance of anonymity networks like Tor, custom transport protocols have been proposed to efficiently deal with the multi-hop nature of such overlay networks. In this work, we tackle the issue of quickly, but safely, ramping up the congestion window during the initial phase of a circuit's lifetime. We propose a tailored startup mechanism called CircuitStart that transfers the idea of a traditional slow start to the multi-hop scenario by effectively compensating potential overshooting, improving performance compared to existing approaches. © 2018 Association for Computing Machinery.",Multi-hop communication; Slow start algorithm; Tor,Congestion window; Improving performance; Multi hop communication; Multihop; Performance of anonymities; Slow start; Start-up mechanism; Transport protocols; Timing circuits
"Addanki V., Linguaglossa L., Roberts J., Rossi D.",4,Fair dropping for multi-resource fairness in software routers,2018,0,"Telecom ParisTech, Paris, France",Telecom ParisTech,1,France,1,10,9,We demonstrate that fair dropping is an effective means to realize fair sharing of bandwidth and CPU in a software router. Analysis underpinning the effectiveness of the proposed approach is presented elsewhere [1]. © 2018 Association for Computing Machinery.,Fair dropping; Linux Foundation FD.io project; Multi-resource fairness; Vector packet processing (VPP),Computer operating systems; Fair dropping; Fair sharing; Multi-resource; Packet processing; Software routers; Routers
"Xiang Q., Zhang J.J., Wang X.T., Liu Y.J., Guok C., Le F., MacAuley J., Newman H., Yang Y.R.",9,"Fine-grained, multi-domain network resource abstraction as a fundamental primitive to enable high-performance, collaborative data sciences",2018,0,"Tongji/Yale, China; Tongji, China; LBNL, United States; IBM, United States; Caltech, United States",IBM,1,China;USA,2,3,0,"Recently, a number of multi-domain network resource information and reservation systems have been developed and deployed, driven by the demand and substantial bene ?ts of providing predictable network resources. A major lacking of such systems, however, is that they are based on coarse-grained or localized information, resulting in substantial ine?ciencies. In this paper, we present Explorer, a simple, novel, highly e?cient multi-domain network resource discovery system to provide ?ne-grained, global network resource information, to support high-performance, collaborative data sciences. The core component of Explorer is the use of linear inequalities, referred to as resource state abstraction (ReSA), as a compact, unifying representation of multi-domain network available bandwidth, which simpli?es applications without exposing network details. We develop a ReSA obfuscating protocol and a proactive full-mesh ReSA discovery mechanism to ensure the privacy-preserving and scalability of Explorer. We fully implement Explorer and demonstrate its e?ciency and e?cacy through extensive experiments using real network topologies and traces. © 2018 Association for Computing Machinery.",Collaborative data sciences; Interdomain; Resource discovery; Resource state abstraction,Bandwidth; Data privacy; Reservation systems; Available bandwidth; Collaborative data sciences; Inter-domain; Linear inequalities; Multidomain networks; Privacy preserving; Resource discovery; State abstraction; Abstracting
"Liu H.H., Wu X., Zhou W., Chen W., Wang T., Xu H., Zhou L., Ma Q., Zhang M.",9,Automatic life cycle management of network configurations,2018,0,"Alibaba Group, China",Alibaba Group,1,China,1,18,14,"Managing the life cycle of network configurations, including the generation, update, transition and diagnosis of the configurations, is the primary task of network operators and a critical process for the reliability and efficiency of the networks. This paper presents NetCraft, a framework which automates the life cycle management of network configurations with a unified network model. Designed for life cycle automation, NetCraft's network model can expressively encode all parts and protocols in the network; It can be converted to or constructed from configurations with interoperability; It is able to perform fine-grained configurations with flexibility to deactivate or undo any configurations for safe configuration updates; And it can work without cooperations from device vendors. We have built and deployed an initial version of NetCraft in Alibaba's global WAN. Evaluations in real environments show that NetCraft can reduce the network incidents caused by configurations by 95% and cut the average time to plan and execute a network update by up to 93%. © 2018 Association for Computing Machinery.",Automation; Configuration; Lifecycle; Self-driving network,Automation; Network management; Configuration; Life-cycle management; Network configuration; Network incidents; Network modeling; Real environments; Self drivings; Unified networks; Life cycle
"Kalmbach P., Zerwas J., Babarczi P., Blenk A., Kellerer W., Schmid S.",6,Empowering self-driving networks,2018,0,"Technical University of Munich, Germany; University of Vienna, Austria",TU Munich;University of Vienna,2,Austria;Germany,2,21,18,"As emerging network technologies and softwareization render networks more flexible, the question arises of how to exploit these flexibilities for optimization. Given the complexity of the involved network protocols and the context in which networks are operating, such optimizations are increasingly difficult to perform. An interesting vision in this regard are ""self-driving"" networks: networks which measure, analyze and control themselves in an automated manner, reacting to changes in the environment (e.g., demand), while exploiting existing flexibilities to optimize themselves. A fundamental challenge faced by any (self-)optimizing network concerns the limited knowledge about future changes in the demand and environment in which the network is operating. Indeed, given that reconfigurations entail resource costs and may take time, an ""optimal"" network configuration for the current demand and environment may not necessarily be optimal also in the near future. Thus, it is desirable that (self-)optimizations also prepare the network for possibly unexpected events. This paper makes the case for empowering self-driving networks: empowerment is an information-centric measure which accounts for how ""prepared"" a network is and how much flexibility is preserved over time. While empowerment has been successfully employed in other domains such as robotics, we are not aware of any applications in networking. As a case study for the use of empowerment in networks, we consider self-driving networks offering topological flexibilities, i.e., reconfigurable edges. © 2018 Copyright held by the owner/author(s).",Network intelligence; Optimization; Self-driving networks,Computer networks; Information systems; Optimization; Current demands; Information-centric; Network configuration; Network intelligence; Network technologies; Resource costs; Self drivings; Unexpected events; Network protocols
"Chen L., Lingys J., Chen K., Liu F.",4,Auto: Scaling deep reinforcement learning for datacenter-scale automatic traffic optimization,2018,0,"SING Lab, Hong Kong University of Science and Technology, United States; SAIC Motors, United States",Hong Kong University of Science and Technology,1,Hong Kong;USA,2,61,24,"Traffic optimizations (TO, e.g. flow scheduling, load balancing) in datacenters are difficult online decision-making problems. Previously, they are done with heuristics relying on operators' understanding of the workload and environment. Designing and implementing proper TO algorithms thus take at least weeks. Encouraged by recent successes in applying deep reinforcement learning (DRL) techniques to solve complex online control problems, we study if DRL can be used for automatic TO without human-intervention. However, our experiments show that the latency of current DRL systems cannot handle flow-level TO at the scale of current datacenters, because short flows (which constitute the majority of traffic) are usually gone before decisions can be made. Leveraging the long-tail distribution of datacenter traffic, we develop a two-level DRL system, AuTO, mimicking the Peripheral & Central Nervous Systems in animals, to solve the scalability problem. Peripheral Systems (PS) reside on end-hosts, collect flow information, and make TO decisions locally with minimal delay for short flows. PS's decisions are informed by a Central System (CS), where global traffic information is aggregated and processed. CS further makes individual TO decisions for long flows. With CS&PS, AuTO is an end-to-end automatic TO system that can collect network information, learn from past decisions, and perform actions to achieve operator-defined goals. We implement AuTO with popular machine learning frameworks and commodity servers, and deploy it on a 32-server testbed. Compared to existing approaches, AuTO reduces the TO turn-around time from weeks to ~100 milliseconds while achieving superior performance. For example, it demonstrates up to 48.14% reduction in average flow completion time (FCT) over existing solutions. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.",Datacenter Networks; Reinforcement Learning; Traffic Optimization,Balancing; Convolutional codes; Decision making; Optimization; Problem solving; Reinforcement learning; Central nervous systems; Data center networks; Long-tail distribution; Network information; On-line decision makings; Scalability problems; Traffic information; Traffic optimization; Deep learning
"Choi S., Kazemkhani S., Burkov B., Sherwood R., Eckert A., Zhang Y., Fang T., Zeng H.",8,FBOSS: Building switch software at scale,2018,0,"Stanford University, United States; Facebook, Inc., United States",Facebook;Stanford University,2,USA,1,53,32,"The conventional software running on network devices, such as switches and routers, is typically vendor-supplied, proprietary and closed-source; as a result, it tends to contain extraneous features that a single operator will not most likely fully utilize. Furthermore, cloud-scale data center networks often times have software and operational requirements that may not be well addressed by the switch vendors. In this paper, we present our ongoing experiences on overcoming the complexity and scaling issues that we face when designing, developing, deploying and operating an in-house software built to manage and support a set of features required for data center switches of a large scale Internet content provider. We present FBOSS, our own data center switch software, that is designed with the basis on our switch-as-a-server and deploy-early-and-iterate principles. We treat software running on data center switches as any other software services that run on a commodity server. We also build and deploy only a minimal number of features and iterate on it. These principles allow us to rapidly iterate, test, deploy and manage FBOSS at scale. Over the last five years, our experiences show that FBOSS's design principles allow us to quickly build a stable and scalable network. As evidence, we have successfully grown the number of FBOSS instances running in our data center by over 30x over a two year period. © 2018 Copyright held by the owner/author(s).",Data Center Networks; Facebook; FBOSS; Network Management; Network Monitoring; Switch Software Design,Convolutional codes; Network management; Software design; Data center networks; Facebook; FBOSS; In-house software; Large scale Internet; Network Monitoring; Operational requirements; Scalable networks; Information management
"Mittal R., Shpiner A., Panda A., Zahavi E., Krishnamurthy A., Ratnasamy S., Shenker S.",7,Revisiting network support for RDMA,2018,1,"UC Berkeley, United States; ICSI, United States; Mellanox Technologies, United States; NYU, United States; Univ. of Washington, United States",NYU;University of California Berkeley,2,USA,1,38,32,"The advent of RoCE (RDMA over Converged Ethernet) has led to a significant increase in the use of RDMA in datacenter networks. To achieve good performance, RoCE requires a lossless network which is in turn achieved by enabling Priority Flow Control (PFC) within the network. However, PFC brings with it a host of problems such as head-of-the-line blocking, congestion spreading, and occasional deadlocks. Rather than seek to fix these issues, we instead ask: is PFC fundamentally required to support RDMA over Ethernet? We show that the need for PFC is an artifact of current RoCE NIC designs rather than a fundamental requirement. We propose an improved RoCE NIC (IRN) design that makes a few simple changes to the RoCE NIC for better handling of packet losses. We show that IRN (without PFC) outperforms RoCE (with PFC) by 6-83% for typical network scenarios. Thus not only does IRN eliminate the need for PFC, it improves performance in the process! We further show that the changes that IRN introduces can be implemented with modest overheads of about 3-10% to NIC resources. Based on our results, we argue that research and industry should rethink the current trajectory of network support for RDMA. © 2018 Copyright held by the owner/author(s).",Datacenter transport; IWARP; PFC; RDMA; RoCE,Convolutional codes; Ethernet; Industrial research; Data center networks; Datacenter; IWARP; Lossless networks; Network scenario; Network support; RDMA; RoCE; Negative impedance converters
"Shen S., Roy N., Guan J., Hassanieh H., Choudhury R.R.",5,MutE: Bringing IoT to noise cancellation,2018,1,"University of Illinois at Urbana-Champaign, United States",UIUC,1,USA,1,51,36,"Active Noise Cancellation (ANC) is a classical area where noise in the environment is canceled by producing anti-noise signals near the human ears (e.g., in Bose's noise cancellation headphones). This paper brings IoT to active noise cancellation by combining wireless communication with acoustics. The core idea is to place an IoT device in the environment that listens to ambient sounds and forwards the sound over its wireless radio. Since wireless signals travel much faster than sound, our ear-device receives the sound in advance of its actual arrival. This serves as a glimpse into the future, that we call lookahead, and proves crucial for real-time noise cancellation, especially for unpredictable, wide-band sounds like music and speech. Using custom IoT hardware, as well as lookahead-aware cancellation algorithms, we demonstrate MUTE, a fully functional noise cancellation prototype that outperforms Bose's latest ANC headphone. Importantly, our design does not need to block the ear - the ear canal remains open, making it comfortable (and healthier) for continuous use. © 2018 Association for Computing Machinery.",Acoustics; Adaptive Filter; Earphone; Edge Computing; Internet of Things; Noise Cancellation; Smart Home; Wearables,Acoustic noise; Acoustics; Adaptive filtering; Adaptive filters; Automation; Convolutional codes; Earphones; Edge computing; Intelligent buildings; Spurious signal noise; Wireless telecommunication systems; Active noise cancellation; Cancellation algorithms; Noise cancellation; Smart homes; Wearables; Wireless communications; Wireless radios; Wireless signals; Internet of things
"Giesen H., Shi L., Sonchack J., Chelluri A., Prabhu N., Sultana N., Kant L., McAuley A.J., Poylisher A., DeHon A., Loo B.T.",11,In-network computing to the rescue of faulty links,2018,0,"University of Pennsylvania, United States; Perspecta Labs, United States",University of Pennsylvania,1,USA,1,15,13,"Failing network links are usually disabled, and packets are routed around them until the links are repaired. While it is often possible to utilize some of a failing link's capacity, losing what remains of a link's capacity is typically deemed preferable to the erratic effect that unreliable links can have on application-level behavior. We describe a new network function that relies on in-network computing to limit the erratic effect of failing network links, to enable the continued use of those links until they can be repaired. We explore the design space using ns-3, and evaluate our implementation on a physical test-bed that includes programmable switches and reconfigurable hardware. Our current hardware prototype can almost saturate a 10GbE link while using around 10% of our FPGA's resources. © 2018 Copyright held by the owner/author(s).",Fault mitigation; FPGA; In-network computing; P4,Computer hardware; Field programmable gate arrays (FPGA); Hardware; Application level; Fault mitigations; Hardware prototype; In networks; Network functions; Physical tests; Programmable switches; Unreliable links; Reconfigurable hardware
"Neugebauer R., Audzevich Y., Antichi G., L—pez-Buedo S., Zazo J.F., Moore A.W.",6,Understanding PCIe performance for end host networking,2018,0,"Independent Researcher, United States; University of Cambridge, United States; University of London, United States; Universidad Aut—noma de Madrid, United States; Naudit HPCN, United States",Universidad Aut—noma de Madrid;University of Cambridge;University of London,3,USA,1,64,54,"In recent years, spurred on by the development and availability of programmable NICs, end hosts have increasingly become the enforcement point for core network functions such as load balancing, congestion control, and application specific network offloads. However, implementing custom designs on programmable NICs is not easy: many potential bottlenecks can impact performance. This paper focuses on the performance implication of PCIe, the de-facto I/O interconnect in contemporary servers, when interacting with the host architecture and device drivers. We present a theoretical model for PCIe and pcie-bench, an open-source suite, that allows developers to gain an accurate and deep understanding of the PCIe substrate. Using pcie-bench, we characterize the PCIe subsystem in modern servers. We highlight surprising differences in PCIe implementations, evaluate the undesirable impact of PCIe features such as IOMMUs, and show the practical limits for common network cards operating at 40Gb/s and beyond. Furthermore, through pcie-bench we gained insights which guided software and future hardware architectures for both commercial and research oriented network cards and DMA engines. © 2018 Copyright held by the owner/author(s).",Operating System; PCIe; Reconfigurable hardware,Balancing; Computer hardware; Convolutional codes; Hardware; Open source software; Reconfigurable hardware; Application-specific network; Common networks; Device Driver; Hardware architecture; Impact performance; Operating System; PCIe; Theoretical modeling; Network architecture
"Hassanieh H., Abdelghany M., Abari O., Katabi D., Rodriguez M., Indyk P.",6,Fast millimeter wave beam alignment,2018,2,"UIUC, United States; UCSB, United States; University of Waterloo, Canada; MIT, United States",MIT;UIUC;University of Waterloo,3,Canada;USA,2,47,34,"There is much interest in integrating millimeter wave radios (mmWave) into wireless LANs and 5G cellular networks to benefit from their multi-GHz of available spectrum. Yet, unlike existing technologies, e.g., WiFi, mmWave radios require highly directional antennas. Since the antennas have pencil-beams, the transmitter and receiver need to align their beams before they can communicate. Existing systems scan the space to find the best alignment. Such a process has been shown to introduce up to seconds of delay, and is unsuitable for wireless networks where an access point has to quickly switch between users and accommodate mobile clients. This paper presents Agile-Link, a new protocol that can find the best mmWave beam alignment without scanning the space. Given all possible directions for setting the antenna beam, Agile-Link provably finds the optimal direction in logarithmic number of measurements. Further, Agile-Link works within the existing 802.11ad standard for mmWave LAN, and can support both clients and access points. We have implemented Agile-Link in a mmWave radio and evaluated it empirically. Our results show that it reduces beam alignment delay by orders of magnitude. In particular, for highly directional mmWave devices operating under 802.11ad, the delay drops from over a second to 2.5 ms. © 2018 Copyright held by the owner/author(s).",5G; Beam Alignment; Millimeter Wave; Sparse Recovery,5G mobile communication systems; Convolutional codes; Directive antennas; IEEE Standards; Millimeter wave devices; Wireless local area networks (WLAN); Beam alignments; Directional Antenna; Millimeter-wave beams; Millimeter-wave radio; Optimal direction; Orders of magnitude; Sparse recovery; Transmitter and receiver; Millimeter waves
"Jacobs A.S., Pfitscher R.J., Ferreira R.A., Granville L.Z.",4,Refining network intents for self-driving networks,2018,0,"UFRGS, Brazil; UFMS, Brazil","UFMS, Brazil;UFRGS",2,Brazil,1,21,20,"Recent advances in artificial intelligence (AI) offer an opportunity for the adoption of self-driving networks. However, network operators or home-network users still do not have the right tools to exploit these new advancements in AI, since they have to rely on low-level languages to specify network policies. Intent-based networking (IBN) allows operators to specify high-level policies that dictate how the network should behave without worrying how they are translated into conFiguration commands in the network devices. However, the existing research proposals for IBN fail to exploit the knowledge and feedback of the network operator to validate or improve the translation of intents. In this paper, we introduce a novel intent-refinement process that uses machine learning and feedback from the operator to translate the operator's utterances into network configurations. Our refinement process uses a sequence-to-sequence learning model to extract intents from natural language and the feedback from the operator to improve learning. .e key insight of our process is an intermediate representation that resembles natural language that is suitable to collect feedback from the operator but is structured enough to facilitate precise translations. Our prototype interacts with a network operator using natural language and translates the operator input to the intermediate representation before translating to SDN rules. Our experimental results show that our process achieves a correlation coefficient squared (i.e., R-squared) of 0.99 for a dataset with 5000 entries and the operator feedback significantly improves the accuracy of our model. © 2018 ACM.",Intent-based networking; Machine learning; Self-driving networks,Artificial intelligence; Learning systems; Personal communication systems; Correlation coefficient; High level policies; Intent-based networking; Intermediate representations; Network configuration; Refinement process; Research proposals; Self drivings; Translation (languages)
"Kastanakis S., Sermpezis P., Kotronis V., Dimitropoulos X.",4,CABaRet: Leveraging recommendation systems for mobile edge caching,2018,0,"University of Crete, Greece; FORTH, Greece",University of Crete,1,Greece,1,14,14,"Joint caching and recommendation has been recently proposed for increasing the efficiency of mobile edge caching. While previous works assume collaboration between mobile network operators and content providers (who control the recommendation systems), this might be challenging in today's economic ecosystem, with existing protocols and architectures. In this paper, we propose an approach that enables cache-aware recommendations without requiring a network and content provider collaboration. We leverage information provided publicly by the recommendation system, and build a system that provides cache-friendly and high-quality recommendations. We apply our approach to the YouTube service, and conduct measurements on YouTube video recommendations and experiments with video requests, to evaluate the potential gains in the cache hit ratio. Finally, we analytically study the problem of caching optimization under our approach. Our results show that significant caching gains can be achieved in practice; 8 to 10 times increase in the cache hit ratio from cache-aware recommendations, and an extra 2 times increase from caching optimization. © 2018 Association for Computing Machinery.",Joint caching and recommendation; Mobile edge networks; Recommendation systems,Network architecture; Cache friendly; Cache hit ratio; Content providers; Edge caching; EDGE Networks; High quality; Mobile network operators; YouTube; Recommender systems
"Hamed E., Rahul H., Partov B.",3,Chorus: Truly distributed distributed-MIMO,2018,0,"Microsoft, United States; MIT, CSAIL, United States; Wavelite, United States",MIT;Microsoft,2,USA,1,64,32,"Distributed MIMO has long been known theoretically to bring large throughput gains to wireless networks. Recent years have seen significant interest and progress in developing practical distributed MIMO systems. However, these systems only distribute the transmission function across the multiple nodes. The control fabric that synchronizes the nodes to a common reference phase still fundamentally requires a single leader that all nodes in the network are capable of hearing. This paper presents Chorus, a truly distributed distributed-MIMO system. Chorus is leaderless - all nodes are peers, and jointly transmit the synchronization signal used by other nodes to synchronize to a common reference phase. The participation of all nodes in the network in the synchronization signal enables Chorus to scale to large networks, while being resilient to node failures or changes in network connectivity, and without imposing onerous management burdens on network administrators. We implement and evaluate Chorus and demonstrate that it can synchronize effectively without the need for a single leader, scale to large networks where no leader node can be heard by all others, and provide 2.7_ throughput improvement over traditional leader-based systems. © 2018 Copyright held by the owner/author(s).",Distributed MIMO; LTE; Multi-user MIMO; Synchronization; Wireless Networks,Audition; Convolutional codes; MIMO systems; Synchronization; Wireless networks; Distributed MIMO; Large networks; Multi-user MIMO; Multiple nodes; Network administrator; Synchronization signals; Throughput improvement; Transmission function; Wireless telecommunication systems
"Zhang B., Jin X., Ratnasamy S., Wawrzynek J., Lee E.A.",5,Awstream: Adaptive wide-area streaming analytics,2018,0,"UC Berkeley, United States; Johns Hopkins University, United States",Johns Hopkins University;University of California Berkeley,2,USA,1,98,81,"The emerging class of wide-area streaming analytics faces the challenge of scarce and variable WAN bandwidth. Non-adaptive applications built with TCP or UDP suffer from increased latency or degraded accuracy. State-of-the-art approaches that adapt to network changes require developer writing sub-optimal manual policies or are limited to application-specific optimizations. We present AWStream, a stream processing system that simultaneously achieves low latency and high accuracy in the wide area, requiring minimal developer efforts. To realize this, AWStream uses three ideas: (i) it integrates application adaptation as a first-class programming abstraction in the stream processing model; (ii) with a combination of offline and online profiling, it automatically learns an accurate profile that models accuracy and bandwidth trade-off; and (iii) at runtime, it carefully adjusts the application data rate to match the available bandwidth while maximizing the achievable accuracy. We evaluate AWStream with three real-world applications: augmented reality, pedestrian detection, and monitoring log analysis. Our experiments show that AWStream achieves sub-second latency with only nominal accuracy drop (2-6%). © 2018 Association for Computing Machinery.",Adaptation; Learning; Profiling; Wide Area Network,Augmented reality; Bandwidth; Computer programming; Convolutional codes; Economic and social effects; Adaptation; Application adaptation; Application-specific optimizations; Learning; Profiling; Programming abstractions; State-of-the-art approach; Stream processing systems; Wide area networks
"Ardi C., Heidemann J.",2,Leveraging controlled information sharing for botnet activity detection,2018,0,"USC, Information Sciences Institute, United States",University of Southern California,1,USA,1,20,14,"Today's malware often relies on DNS to enable communication with command-and-control (C&C). As defenses that block C&C traffic improve, malware use sophisticated techniques to hide this traffic, including ""fast flux"" names and Domain-Generation Algorithms (DGAs). Detecting this kind of activity requires analysis of DNS queries in network traffic, yet these signals are sparse. As bot countermeasures grow in sophistication, detecting these signals increasingly requires the synthesis of information from multiple sites. Yet sharing security information across organizational boundaries to date has been infrequent and ad hoc because of unknown risks and uncertain benefits. In this paper, we take steps towards formalizing cross-site information sharing and quantifying the ben-efits of data sharing. We use a case study on DGA-based botnet detection to evaluate how sharing cybersecurity data can improve detection sensitivity and allow the discovery of malicious activity with greater precision. © 2018 Copyright held by the owner/author(s).",Botnet detection; Cybersecurity; Data sharing; Information sharing,Botnet; Command and control systems; Computer crime; Information analysis; Internet protocols; Malware; Traffic signals; Botnet detections; Cyber security; Data Sharing; Detection sensitivity; Generation algorithm; Information sharing; Malicious activities; Organizational boundaries; Information dissemination
"Syamkumar M., Barford P., Durairajan R.",3,"Deployment characteristics of ""The edge"" in mobile edge computing",2018,1,"University of Wisconsin-Madison, United States; University of Oregon, United States",University of Oregon;;University of Wisconsin-Madison,3,USA,1,28,28,"The envisioned capabilities of mobile edge computing are predicated on a delivery infrastructure with capacity, ubiquity, robustness, and capabilities to serve a country-wide user base. In this paper, we present an empirical study of key aspects of mobile edge infrastructure toward the goal of understanding their current characteristics and identifying future deployments. We start by analyzing a dataset of over 4M cell tower locations in the US. We evaluate the geographic characteristics of deployments and highlight how locations correspond to population density in major metropolitan areas and in rural areas. We also show how deployments have been arranged along highways throughout the US. Our analysis highlight areas where new deployments would be warranted. Finally, we analyze how cell tower deployments correspond to current major data center locations and assess how micro servers might be deployed to improve response times and to better serve customers. © 2018 Association for Computing Machinery.",Cellular infrastructure; Data centers; MEC; Population analysis,Location; Population statistics; Ubiquitous computing; Cellular infrastructure; Current characteristic; Data center locations; Data centers; Deployment characteristics; Geographic characteristics; Mobile Edge Computing; Population analysis; Edge computing
"Montazeri B., Li Y., Alizadeh M., Ousterhout J.",4,HOMA: A receiver-driven low-latency transport protocol using network priorities,2018,0,"Stanford University, United States; MIT, United States",MIT;Stanford University,2,USA,1,34,30,"Homa is a new transport protocol for datacenter networks. It provides exceptionally low latency, especially for workloads with a high volume of very short messages, and it also supports large messages and high network utilization. Homa uses in-network priority queues to ensure low latency for short messages; priority allocation is managed dynamically by each receiver and integrated with a receiver-driven flow control mechanism. Homa also uses controlled overcommitment of receiver downlinks to ensure efficient bandwidth utilization at high load. Our implementation of Homa delivers 99th percentile round-trip times less than 15 µs for short messages on a 10 Gbps network running at 80% load. These latencies are almost 100x lower than the best published measurements of an implementation. In simulations, Homa's latency is roughly equal to pFabric and significantly better than pHost, PIAS, and NDP for almost all message sizes and workloads. Homa can also sustain higher network loads than pFabric, pHost, or PIAS. © 2018 Association for Computing Machinery.",Data centers; Low latency; Network stacks; Transport protocols,Convolutional codes; Flow control; Control mechanism; Data center networks; Data centers; Efficient bandwidth; Low latency; Net work utilization; Network stack; Transport protocols; Internet protocols
"Ma Y., Luo Z., Steiger C., Traverso G., Adib F.",5,Enabling deep-tissue networking for miniature medical devices,2018,2,"MIT Media Lab, United States; MIT Koch Institute, United States; Harvard Medical School, United States; Brigham and Women's Hospital, United States",MIT,1,USA,1,72,50,"We present IVN (In-Vivo Networking), a system that enables powering up and communicating with miniature sensors implanted or injected in deep tissues. IVN overcomes fundamental challenges which have prevented past systems from powering up miniature sensors beyond superficial depths. These challenges include the significant signal attenuation caused by bodily tissues and the miniature antennas of the implantable sensors. IVN's key contribution is a novel beamforming algorithm that can focus its energy toward an implantable device, despite its inability to estimate its channel or its location. We implement a multi-antenna prototype of IVN, and perform extensive evaluations via in-vitro, ex-vivo, and in-vivo tests in a pig. Our results demonstrate that it can power up and communicate with millimeter-sized sensors at over 10 cm depths in fluids, as well as battery-free tags placed in a central organ of a swine. The implications of our new beamforming technology extend beyond miniature implantables. In particular, our results demonstrate that IVN can power up off-the-shelf passive RFIDs at distances of 38 m, i.e., 7.6_ larger than the operation range of the same RFIDs. © 2018 Copyright held by the owner/author(s).",Battery-free; Deep-tissues; Medical Implants; Power Delivery; RFID; Wireless Sensors,Antennas; Beamforming; Biomedical equipment; Convolutional codes; Electric power transmission; Histology; Implants (surgical); Mammals; Radio frequency identification (RFID); Battery-free; Beamforming algorithms; Implantable devices; Implantable sensors; Medical implants; Power delivery; Signal attenuation; Wireless sensor; Tissue
"Benet C.H., Kassler A.J., Benson T., Pongracz G.",4,MP-HULA: Multipath transport aware load balancing using programmable data planes,2018,0,"Karlstad University, Sweden; Brown University, United States; Networking Research - Ericsson, United States",Brown University;Karlstad University;Ericsson Research,3,Sweden;USA,2,28,28,"Datacenter networks ofer a large degree of multipath in order to provide large bisectional bandwidth. The end-to-end performance is determined by the load-balancing strategy which needs to be designed to efectively manage congestion. Consequently, congestion aware load-balancing strategies such as CONGA or HULA have been designed. Recently, more and more applications that are hosted on cloud servers use multipath transport protocols such as MPTCP. However, in the presence of MPTCP, existing load-balancing schemes including ECMP, HULA or CONGA may lead to suboptimal forwarding decisions where multiple MPTCP subfows of one connection are pinned on the same bottleneck link. In this paper, we present MP-HULA, a transport layer multi-path aware load-balancing scheme using Programmable Data Planes. First, instead of tracking congestion information for the best path towards the destination, each MP-HULA switch tracks congestion information for the best-k paths to a destination through the neighbor switches. Second, we design MP-HULA using Programmable Data Planes, where each leaf switch can identify, using P4, which MPTCP subfow belongs to which connection. MP-HULA then load-balances diferent MPTCP subfows of a MPTCP connection on diferent next hops considering congestion state while aggregating bandwidth. Our evaluation shows that MP-HULA with MPTCP outperforms HULA in average flow completion time (2.1x at 50% load, 1.7x at 80% load). © 2018 Association for Computing Machinery.",In-network load balancing; Multipath; Network congestion; Programmable switches,Bandwidth; End-to-end performance; In networks; Load balancing strategy; Load-balancing schemes; Multipath; Multipath transport protocols; Network congestions; Programmable switches; Traffic congestion
"Pedrosa L., Iyer R., Zaostrovnykh A., Fietz J., Argyraki K.",5,Automated synthesis of adversarial workloads for network functions,2018,0,"EPFL, United States","EPFL, Switzerland",1,USA,1,44,32,"Software network functions promise to simplify the deployment of network services and reduce network operation cost. However, they face the challenge of unpredictable performance. Given this performance variability, it is imperative that during deployment, network operators consider the performance of the NF not only for typical but also adversarial workloads. We contribute a tool that helps solve this challenge: it takes as input the LLVM code of a network function and outputs packet sequences that trigger slow execution paths. Under the covers, it combines directed symbolic execution with a sophisticated cache model to look for execution paths that incur many CPU cycles and involve adversarial memory-access patterns. We used our tool on 11 network functions that implement a variety of data structures and discovered workloads that can in some cases triple latency and cut throughput by 19% relative to typical testing workloads. © 2018 Copyright held by the owner/author(s).",Adversarial Inputs; Network Function Performance,Convolutional codes; Adversarial Inputs; Automated synthesis; Memory access patterns; Network functions; Network operations; Performance variability; Software network; Symbolic execution; Transfer functions
"Huang Q., Lee P.P.C., Bao Y.",3,SketChlearn: Relieving user burdens in approximate measurement with automated statistical inference,2018,1,"State Key Lab of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, United States; Department of Computer Science and Engineering, Chinese University of Hong Kong, United States",Chinese University of Hong Kong;Chinese Academy of Sciences,2,Hong Kong;USA,2,70,49,"Network measurement is challenged to fulfill stringent resource requirements in the face of massive network traffic. While approximate measurement can trade accuracy for resource savings, it demands intensive manual efforts to configure the right resource-accuracy trade-offs in real deployment. Such user burdens are caused by how existing approximate measurement approaches inherently deal with resource conflicts when tracking massive network traffic with limited resources. In particular, they tightly couple resource configurations with accuracy parameters, so as to provision sufficient resources to bound the measurement errors. We design SketchLearn, a novel sketch-based measurement framework that resolves resource conflicts by learning their statistical properties to eliminate conflicting traffic components. We prototype SketchLearn on OpenVSwitch and P4, and our testbed experiments and stress-test simulation show that SketchLearn accurately and automatically monitors various traffic statistics and effectively supports network-wide measurement with limited resources. © 2018 Copyright held by the owner/author(s).",Network measurement; Sketch,Commerce; Convolutional codes; Economic and social effects; Traffic surveys; Accuracy parameters; Network measurement; Resource configurations; Resource requirements; Sketch; Statistical inference; Statistical properties; Traffic statistics; Statistical methods
"Kogias M., Bugnion E.",2,Flow control for latency-critical RPCs,2018,0,"EPFL, Germany","EPFL, Switzerland",1,Germany,1,47,29,"In todayÕs modern datacenters, the waiting time spent within a serverÕs queue is a major contributor of the end-to-end tail latency of µs-scale remote procedure calls. In traditional TCP, congestion control handles in-network congestion, while flow control was designed to avoid memory overruns in streaming scenarios. The latter is unfortunately oblivious to the load on the server when processing short requests from multiple clients at very high rates. Acknowledging flow control as the mechanism that controls queuing on the end-host, we propose a different flow control mechanism that depends on the application-specific service-level objectives and controls the waiting time in the receivers queue by adjusting the incoming load accordingly. We design this latency-aware flow control mechanism as part of TCP by maintaining a wire-compatible header format without introducing extra messages. We implement a proof-of-concept userspace TCP stack on top of DPDK and we show that the new flow control mechanism prevents applications from violating service-level objectives in a single-server environment by throttling the incoming requests. We demonstrate the true benefit of the approach in a replicated, multi-server scenario, where independent clients leverage the flow-control signal to avoid directing requests to the overloaded servers. © 2018 Association for Computing Machinery.",Flow control; Latency-critical; Remote Procedure Call; TCP,Distributed computer systems; Network architecture; Queueing theory; Transmission control protocol; Application specific; Control mechanism; Latency-critical; Multiple clients; Proof of concept; Remote Procedure Call; Service level objective; Single-server environment; Flow control
"Akhtar Z., Rao S., Ribeiro B., Nam Y.S., Chen J., Zhan J., Govindan R., Katz-Bassett E., Zhang H.",9,OBoe: Auto-tuning video ABR algorithms to network conditions,2018,1,"University of Southern California, United States; Purdue University, United States; University of Windsor, United States; Conviva, United States; Columbia University, United States",Columbia University;Purdue University;University of Southern California;University of Windsor,4,USA,1,60,32,"Most content providers are interested in providing good video delivery QoE for all users, not just on average. State-of-the-art ABR algorithms like BOLA and MPC rely on parameters that are sensitive to network conditions, so may perform poorly for some users and/or videos. In this paper, we propose a technique called Oboe to auto-tune these parameters to different network conditions. Oboe pre-computes, for a given ABR algorithm, the best possible parameters for different network conditions, then dynamically adapts the parameters at run-time for the current network conditions. Using testbed experiments, we show that Oboe significantly improves BOLA, MPC, and a commercially deployed ABR. Oboe also betters a recently proposed reinforcement learning based ABR, Pensieve, by 24% on average on a composite QoE metric, in part because it is able to better specialize ABR behavior across different network states. © 2018 Association for Computing Machinery.",Adaptive bitrate algorithms; Video delivery,Convolutional codes; Reinforcement learning; Auto-tune; Autotuning; Bit rates; Content providers; Network condition; Network state; State of the art; Video delivery; Parameter estimation
"Zhao M., Tian Y., Zhao H., Alsheikh M.A., Li T., Hristov R., Kabelac Z., Katabi D., Torralba A.",9,RF-based 3D skeletons,2018,1,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,41,36,"This paper introduces RF-Pose3D, the first system that infers 3D human skeletons from RF signals. It requires no sensors on the body, and works with multiple people and across walls and occlusions. Further, it generates dynamic skeletons that follow the people as they move, walk or sit. As such, RF-Pose3D provides a significant leap in RF-based sensing and enables new applications in gaming, healthcare, and smart homes. RF-Pose3D is based on a novel convolutional neural network (CNN) architecture that performs high-dimensional convolutions by decomposing them into low-dimensional operations. This property allows the network to efficiently condense the spatio-temporal information in RF signals. The network first zooms in on the individuals in the scene, and crops the RF signals reflected off each person. For each individual, it localizes and tracks their body parts - head, shoulders, arms, wrists, hip, knees, and feet. Our evaluation results show that RF-Pose3D tracks each keypoint on the human body with an average error of 4.2 cm, 4.0 cm, and 4.9 cm along the X, Y, and Z axes respectively. It maintains this accuracy even in the presence of multiple people, and in new environments that it has not seen in the training set. Demo videos are available at our website: http://rfpose3d.csail.mit.edu. © 2018 Association for Computing Machinery.",3D Human Pose Estimation; Localization; Machine Learning; Neural Networks; RF Sensing; Smart Homes,Automation; Convolution; Convolutional codes; Intelligent buildings; Learning systems; Neural networks; 3D human pose estimation; Convolutional Neural Networks (CNN); Evaluation results; Localization; New applications; RF Sensing; Smart homes; Spatiotemporal information; Musculoskeletal system
"Narayan A., Cangialosi F., Raghavan D., Narayana P.G.S., Mittal R., Alizadeh M., Balakrishnan H.",7,Restructuring endpoint congestion control,2018,0,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,45,26,"This paper describes the implementation and evaluation of a system to implement complex congestion control functions by placing them in a separate agent outside the datapath. Each datapath'such as the Linux kernel TCP, UDP-based QUIC, or kernel-bypass transports like mTCP-on-DPDK'summarizes information about packet round-trip times, receptions, losses, and ECN via a well-defined interface to algorithms running in the off-datapath Congestion Control Plane (CCP). The algorithms use this information to control the datapath's congestion window or pacing rate. Algorithms written in CCP can run on multiple datapaths. CCP improves both the pace of development and ease of maintenance of congestion control algorithms by providing better, modular abstractions, and supports aggregation capabilities of the Congestion Manager, all with one-time changes to datapaths. CCP also enables new capabilities, such as Copa in Linux TCP, several algorithms running on QUIC and mTCP/DPDK, and the use of signal processing algorithms to detect whether cross-traffic is ACK-clocked. Experiments with our user-level Linux CCP implementation show that CCP algorithms behave similarly to kernel algorithms, and incur modest CPU overhead of a few percent. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.",Congestion control; Operating systems,Computer operating systems; Congestion control (communication); Convolutional codes; Signal processing; Transmission control protocol; Congestion window; Cross-traffic; Kernel algorithms; Kernel bypass; Linux kernel; Pacing rate; Round trip time; Signal processing algorithms; Linux
"Pirelli S., Zaostrovnykh A., Candea G.",3,A formally verified NAT stack,2018,0,"EPFL, Switzerland","EPFL, Switzerland",1,Switzerland,1,29,24,"Prior work proved a stateful NAT network function to be semantically correct, crash-free, and memory safe [29]. Their toolchain verifies the network function code while assuming the underlying kernel-bypass framework, drivers, operating system, and hardware to be correct. We extend the toolchain to verify the kernel-bypass framework and a NIC driver in the context of the NAT. We uncover bugs in both the framework and the driver. Our code is publicly available [28]. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.",Kernel bypass; Network functions; Software verification,Verification; Kernel bypass; Network functions; NIC drivers; Software verification; Transfer functions
"Yang T., Huang Q., Miao R., Jiang J., Gong J., Li X., Liu P., Zhou Y., Uhlig S.",9,Elastic sketch: Adaptive and fast network-wide measurements,2018,2,"Peking University, United States; Institute Of Computing Technology, CAS, United States; Alibaba Group, United States; Queen Mary University of London, United States",Peking University;Queen Mary University of London,2,USA,1,70,45,"When network is undergoing problems such as congestion, scan attack, DDoS attack, etc., measurements are much more important than usual. In this case, traffic characteristics including available bandwidth, packet rate, and flow size distribution vary drastically, significantly degrading the performance of measurements. To address this issue, we propose the Elastic sketch. It is adaptive to currently traffic characteristics. Besides, it is generic to measurement tasks and platforms. We implement the Elastic sketch on six platforms: P4, FPGA, GPU, CPU, multi-core CPU, and OVS, to process six typical measurement tasks. Experimental results and theoretical analysis show that the Elastic sketch can adapt well to traffic characteristics. Compared to the state-of-the-art, the Elastic sketch achieves 44.6 ~ 45.2 times faster speed and 2.0 ~ 273.7 smaller error rate. © 2018 Copyright held by the owner/author(s).",Compression; Elastic; Generic; Network measurements; Sketches,Bandwidth; Compaction; Denial-of-service attack; Available bandwidth; Elastic; Generic; Network measurement; Sketches; State of the art; Traffic characteristics; Wide measurement; Convolutional codes
"Krude J., Stoffers M., Wehrle K.",3,Circuit switched VM networks for zero-copy IO,2018,0,"Communication and Distributed Systems, RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,26,17,"Although applications are nowadays often executed in virtual machines (VMs) to isolate applications or consolidate physical machines, VM network performance is still challenging. Packetization, encapsulation, congestion control, preparations for loss, and copying of data introduce unnecessary performance degradation within a system where VMs communicate over abundant and reliable shared-memory. Although protocols like TCP are therefore not well suited for kernel network stack in VMs, preexisting applications require the kernel socket interface to keep functioning. In eliminating the unnecessary overhead for inter-VM communication and shifting it to the host operating system for communication over a physical NIC, our approach increases performance for both cases of communicating with another VM on the same host and for communicating with external hosts. Instead of multiplexing multiple connections over a single virtual Ethernet link, we use a separate shared-memory connection for each VM application socket. Our approach improves the stream and datagram performance of existing applications over an unmodied socket interface and brings the benets of memory-mapped zero-copy IO to modied applications without sacricing isolation between sockets. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Interface Compatibility; VM Network Architecture; Zero-Copy IO,Data encapsulation; Memory architecture; Network architecture; Timing circuits; Ethernet link; Interface compatibilities; Multiple connections; Network stack; Packetization; Performance degradation; Shared memory; Zero copy; Virtual machine
"Liu J., SoulŽ R., Hallahan W., Wang H., Schlesinger C., Cascaval C., Sharif M., McKeown N., Lee J., Foster N.",10,P4V: Practical verification for programmable data planes,2018,2,"University of Lugano Lugano, Switzerland; Yale University, New Haven, CT, United States; Barefoot Networks, Santa Clara, CA, United States; Stanford University, Stanford, CA, United States; Cornell University, Ithaca, NY, United States",Cornell University;Stanford University;University of Lugano;Yale University,4,Switzerland;USA,2,56,44,"We present the design and implementation of p4v, a practical tool for verifying data planes described using the P4 programming language. The design of p4v is based on classic verification techniques but adds several key innovations including a novel mechanism for incorporating assumptions about the control plane and domain-specific optimizations which are needed to scale to large programs. We present case studies showing that p4v verifies important properties and finds bugs in real-world programs. We conduct experiments to quantify the scalability of p4v on a wide range of additional examples. We show that with just a few hundred lines of control-plane annotations, p4v is able to verify critical safety properties for switch.p4, a program that implements the functionality of on a modern data center switch, in under three minutes. © 2018 Copyright held by the owner/author(s).",P4; Programmable data planes; Verification,Convolutional codes; Verification; Control planes; Data planes; Design and implementations; Domain specific; Large programs; Real world projects; Safety property; Verification techniques; Program debugging
"Singh R., Ghobadi M., Foerster K.-T., Filer M., Gill P.",5,Radwan: Rate adaptive wide area network,2018,1,"University of Massachusetts, Amherst, United States; Microsoft Research, United States; University of Vienna, United States; Microsoft, United States",Microsoft;University of Massachusetts Amherst;University of Vienna,3,USA,1,32,29,"Fiber optic cables connecting data centers are an expensive but important resource for large organizations. Their importance has driven a conservative deployment approach, with redundancy and reliability baked in at multiple layers. In this work, we take a more aggressive approach and argue for adapting the capacity of fiber optic links based on their signal-to-noise ratio (SNR). We investigate this idea by analyzing the SNR of over 8,000 links in an optical backbone for a period of three years. We show that the capacity of 64% of 100 Gbps IP links can be augmented by at least 75 Gbps, leading to an overall capacity gain of over 134 Tbps. Moreover, adapting link capacity to a lower rate can prevent up to 25% of link failures. Our analysis shows that using the same links, we get higher capacity, better availability, and 32% lower cost per gigabit per second. To accomplish this, we propose RADWAN, a traffic engineering system that allows optical links to adapt their rate based on the observed SNR to achieve higher throughput and availability while minimizing the churn during capacity reconfigurations. We evaluate RADWAN using a testbed consisting of 1,540 km fiber with 16 amplifiers and attenuators. We then simulate the throughput gains of RADWAN at scale and compare them to the gains of state-of-the-art traffic engineering systems. Our data-driven simulations show that RADWAN improves the overall network throughput by 40% while also improving the average link availability. © 2018 Copyright held by the owner/author(s).",Optical Backbone; Traffic Engineering; Wide Area Networks,Adaptive optics; Convolutional codes; Fiber amplifiers; Fiber optics; Optical links; Redundancy; Signal to noise ratio; Throughput; Data-driven simulation; Fiber optic links; Large organizations; Link availability; Optical backbone; Overall networks; State of the art; Traffic Engineering; Wide area networks
"Jo_ilo S., D‡n G.",2,Joint allocation of computing and wireless resources to autonomous devices in mobile edge computing,2018,0,"KTH, Royal Institute of Technology, Stockholm, Sweden",KTH Royal Institute of Technology,1,Sweden,1,28,23,"We consider the interaction between mobile edge computing (MEC) resource management and wireless devices that offload computationally intensive tasks through shared wireless links to edge cloud servers, so as to minimize their completion times. We model the interaction between the devices and the operator that optimizes the allocation of the wireless and computing resources as a Stackelberg game. We show that a pure strategy Stackelberg equilibrium exists, and we provide an efficient algorithm for computing equilibrium allocations. Our simulation results show that joint optimization of the wireless and computing resources can provide a significant reduction of completion times at little increase in computational complexity compared to a system where resource allocation is not optimized. © 2018 Association for Computing Machinery.",Computation offloading; Edge computing; Game theory,Edge computing; Game theory; Resource allocation; Computation offloading; Computing equilibria; Computing resource; Joint optimization; Mobile Edge Computing; Resource management; Stackelberg equilibrium; Wireless resources; Computer games
"Abhishta, Van Rijswijk-Deij R., Nieuwenhuis L.J.M.",3,Measuring the impact of a successful DDoS atack on the customer behaviour of managed DNS service providers,2018,0,"University of Twente, Enschede, Netherlands; University of Twente, SURFnet BV, Enschede, Netherlands",University of Twente,1,Netherlands,1,26,19,"Distributed Denial-of-Service (DDoS) attacks continue to pose a serious threat to the availability of Internet services. The Domain Name System (DNS) is part of the core of the Internet and a crucial factor in the successful delivery of Internet services. Because of the importance of DNS, specialist service providers have sprung up in the market, that provide managed DNS services. One of their key selling points is that they protect DNS for a domain against DDoS attacks. But what if such a service becomes the target of a DDoS attack, and that attack succeeds? In this paper we analyse two such events, an attack on NS1 in May 2016, and an attack on Dyn in October 2016. We do this by analysing the change in the behaviour of the service's customers. For our analysis we leverage data from the OpenINTEL active DNS measurement system, which covers large parts of the global DNS over time. Our results show an almost immediate and statistically significant change in the behaviour of domains that use NS1 or Dyn as a DNS service provider. We observe a decline in the number of domains that exclusively use NS1 or Dyn as a managed DNS service provider, and see a shift toward risk spreading by using multiple providers. While a large managed DNS provider may be better equipped to protect against attacks, these two case studies show they are not impervious to them. This calls into question the wisdom of using a single provider for managed DNS. Our results show that spreading risk by using multiple providers is an effective countermeasure, albeit probably at a higher cost. © 2018 Copyright held by the owner/author(s).",Customer behaviour; DDoS attacks; Domain name system; Dyn; Economic impact; NS1,Internet protocols; Internet service providers; Network security; Sales; Web services; Customer behaviour; DDoS Attack; Distributed denial of service attack; Domain name system; Economic impacts; Internet services; Measurement system; Service provider; Denial-of-service attack
"Yaseen N., Sonchack J., Liu V.",3,Synchronized network snapshots,2018,0,"University of Pennsylvania, United States",University of Pennsylvania,1,USA,1,42,32,"When monitoring a network, operators rarely have a fine-grained and complete view of the network's state. Instead, today's network monitoring tools generally only measure a single device or path at a time; whole-network metrics are a composition of these independent measurements, i.e., an afterthought. Such tools fail to fully answer a wide range of questions. Is my load balancing algorithm taking advantage of all available paths evenly? How much of my network is concurrently loaded? Is application traffic synchronized? These types of concurrent network behavior are challenging to capture at fine granularity as they involve coordination across the entire network. At the same time, understanding them is essential to the design of network switches, architectures, and protocols. This paper presents the design of a Synchronized Network Snapshot protocol. The goal of our primitive is the collection of a network-wide set of measurements. To ensure that the measurements are meaningful, our design guarantees they are both causally consistent and approximately synchronous. We demonstrate with a Wedge100BF implementation the feasibility of our approach as well as its many potential uses. © 2018 Copyright held by the owner/author(s).",Network snapshots; Whole-network measurement,Computer supported cooperative work; Convolutional codes; Network architecture; Synchronization; Time switches; All available paths; Fine granularity; Independent measurement; Load balancing algorithms; Network behaviors; Network measurement; Network monitoring tools; Network switches; Internet protocols
"Kim D., Memaripour A., Badam A., Zhu Y., Liu H.H., Padhye J., Raindel S., Swanson S., Sekar V., Seshan S.",10,HyperLoop: Group-based NiC-offloading to accelerate replicated transactions in multi-tenant storage systems,2018,1,"Carnegie Mellon University, United States; UC San Diego, United States; Microsoft, United States",Carnegie Mellon University;Microsoft;University of California San Diego,3,USA,1,101,96,"Storage systems in data centers are an important component of large-scale online services. They typically perform replicated transactional operations for high data availability and integrity. Today, however, such operations suffer from high tail latency even with recent kernel bypass and storage optimizations, and thus affect the predictability of end-to-end performance of these services. We observe that the root cause of the problem is the involvement of the CPU, a precious commodity in multi-tenant settings, in the critical path of replicated transactions. In this paper, we present HyperLoop, a new framework that removes CPU from the critical path of replicated transactions in storage systems by offloading them to commodity RDMA NICs, with non-volatile memory as the storage medium. To achieve this, we develop new and general NIC offloading primitives that can perform memory operations on all nodes in a replication group while guaranteeing ACID properties without CPU involvement. We demonstrate that popular storage applications can be easily optimized using our primitives. Our evaluation results with microbenchmarks and application benchmarks show that HyperLoop can reduce 99th percentile latency ÷ 800_ with close to 0% CPU consumption on replicas. © 2018 Copyright held by the owner/author(s).",Distributed storage systems; NIC-offloading; RDMA; Replicated transactions,Benchmarking; Convolutional codes; Multiprocessing systems; Negative impedance converters; Online systems; Distributed storage system; End-to-end performance; Evaluation results; NIC-offloading; Non-volatile memory; RDMA; Replicated transactions; Storage optimization; Digital storage
"Li E., Zhou Z., Chen X.",3,Edge intelligence: On-demand deep learning model co-inference with device-edge synergy,2018,2,"School of Data and Computer Science, Sun Yat-Sen University, China",Sun Yat-Sen University,1,China,1,16,15,"As the backbone technology of machine learning, deep neural networks (DNNs) have have quickly ascended to the spotlight. Running DNNs on resource-constrained mobile devices is, however, by no means trivial, since it incurs high performance and energy overhead. While offloading DNNs to the cloud for execution suffers unpredictable performance, due to the uncontrolled long wide-area network latency. To address these challenges, in this paper, we propose Edgent, a collaborative and on-demand DNN co-inference framework with device-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that adaptively partitions DNN computation between device and edge, in order to leverage hybrid computation resources in proximity for real-time DNN inference. (2) DNN right-sizing that accelerates DNN inference through early-exit at a proper intermediate DNN layer to further reduce the computation latency. The prototype implementation and extensive evaluations based on Raspberry Pi demonstrate Edgent's effectiveness in enabling on-demand low-latency edge intelligence. © 2018 Association for Computing Machinery.",Computation offloading; Deep learning; Edge computing; Edge intelligence,Deep learning; Edge computing; Wide area networks; Computation offloading; Edge intelligence; Energy overheads; Hybrid computation; Learning models; Low latency; Prototype implementations; Raspberry pi; Deep neural networks
"Wohlfart F., Chatzis N., Dabanoglu C., Carle G., Willinger W.",5,Leveraging interconnections for performance:The serving infrastructure of a large CDN,2018,0,"Akamai Technologies, United States; Technical University of Munich, United States; NIKSUN, Inc., United States",NIKSUN Inc.;TU Munich,2,USA,1,49,35,"Today's large content providers (CP) are busy building out their service infrastructures or lpeering edges_ to satisfy the insatiable demand for content created by an ever-expanding Internet edge. One component of these serving infrastructures that features prominently in this build-out is their connectivity fabric; i.e., the set of all Internet interconnections that content has to traverse en route from the CP's various ldeployments_ or lserving sites_ to end users. However, these connectivity fabrics have received little attention in the past and remain largely ill-understood. In this paper, we describe the results of an in-depth study of the connectivity fabric of Akamai. Our study reveals that Akamai's connectivity fabric consists of some 6,100 different lexplicit_ peerings (i.e., Akamai is one of the two involved peers) and about 28,500 different limplicit_ peerings (i.e., Akamai is neither of the two peers). Our work contributes to a better understanding of real-world serving infrastructures by providing an original account of implicit peerings and demonstrating the performance benefits that Akamai can reap from leveraging its rich connectivity fabric for serving its customers' content to end users. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Content Delivery Networks; Content Providers; Peering,Convolutional codes; Content delivery network; Content providers; End users; In-depth study; Peering; Performance benefits; Real-world; Service infrastructure; Human computer interaction
"Gao K., Nojima T., Yang Y.R.",3,Trident: Toward a unified SDN programming framework with automatic updates,2018,0,"Tsinghua, China; Yale, United States; Tongji, China",Yale University;Tsinghua University,2,China;USA,2,60,53,"Software-defined networking (SDN) and network functions (NF) are two essential technologies that need to work together to achieve the goal of highly programmable networking. Unified SDN programming, which integrates states of network functions into SDN control plane programming, brings these two technologies together. In this paper, we conduct the first systematic study of unified SDN programming. We first show that integrating asynchronous, continuously changing states of network functions into SDN can introduce basic complexities. We then present Trident, a novel, unified SDN programming framework that introduces programming primitives including stream attributes, route algebra and live variables to remove these complexities. We demonstrate the expressiveness of Trident using realistic use cases and conduct an extensive evaluation of its efficiency. © 2018 Copyright held by the owner/author(s).",Live variables; Network functions; Network programming; Route Algebra; SDN; Stream attributes,Algebra; Convolutional codes; Transfer functions; Automatic updates; Live variables; Network functions; Network programming; Programmable networkings; Programming framework; Software defined networking (SDN); Stream attributes; Computer programming
"Gupta A., Feamster N., Harrison R., Rexford J., Canini M., Willinger W.",6,Sonata: Query-driven streaming network telemetry,2018,0,"Princeton University, United States; KAUST, United States; NIKSUN Inc, United States",Princeton University,1,USA,1,60,35,"Managing and securing networks requires collecting and analyzing network traffic data in real time. Existing telemetry systems do not allow operators to express the range of queries needed to perform management or scale to large traffic volumes and rates. We present Sonata, an expressive and scalable telemetry system that coordinates joint collection and analysis of network traffic. Sonata provides a declarative interface to express queries for a wide range of common telemetry tasks; to enable real-time execution, Sonata partitions each query across the stream processor and the data plane, running as much of the query as it can on the network switch, at line rate. To optimize the use of limited switch memory, Sonata dynamically refines each query to ensure that available resources focus only on traffic that satisfies the query. Our evaluation shows that Sonata can support a wide range of telemetry tasks while reducing the workload for the stream processor by as much as seven orders of magnitude compared to existing telemetry systems. © 2018 Copyright held by the owner/author(s).",Analytics; Programmable switches; Stream processing,Convolutional codes; Analytics; Orders of magnitude; Programmable switches; Real time execution; Stream processing; Stream processor; Streaming networks; Telemetry systems; Telemetering equipment
"Hasumi D., Shima S., Takakura H.",3,Speculating incident zone system on local area networks,2018,0,"NEC Corporation, Japan; National Institute of Informatics, Japan",National Institute of Informatics,1,Japan,1,22,17,"Triage process in the incident handling lacks the ability to assess overall risks to modern cyber attacks. Zoning of local area networks by measuring internal network traffic in response to such risks is important. Therefore, we propose a SPeculating INcident Zone (SPINZ) system for supporting the triage process. The SPINZ analyzes internal network flows and outputs an incident zone, which is composed of devices related to the incident. We evaluate the performance of the SPINZ through simulations using incident flow datasets generated from internal traffic open data and lateral movement traffic. As a result, we confirm that the SPINZ has the capability to detect an incident zone, but removing unrelated devices from an incident zone is an issue to be further investigated. © 2018 Association for Computing Machinery.",Anomaly detection; Cyber security; Incident handling; Triage,Network security; Risk assessment; Anomaly detection; Cyber security; Cyber-attacks; Incident flow; Incident handling; Internal network; Lateral movement; Triage; Local area networks
"Beckett R., Gupta A., Mahajan R., Walker D.",4,Control plane compression,2018,0,"Princeton University, United States; Intentionet, United States",Princeton University,1,USA,1,44,23,"We develop an algorithm capable of compressing large networks into smaller ones with similar control plane behavior: For every stable routing solution in the large, original network, there exists a corresponding solution in the compressed network, and vice versa. Our compression algorithm preserves a wide variety of network properties including reachability, loop freedom, and path length. Consequently, operators may speed up network analysis, based on simulation, emulation, or verification, by analyzing only the compressed network. Our approach is based on a new theory of control plane equivalence. We implement these ideas in a tool called Bonsai and apply it to real and synthetic networks. Bonsai can shrink real networks by over a factor of 5 and speed up analysis by several orders of magnitude. © 2018 Copyright held by the owner/author(s).",Network Verification; Stable Routing Problem,Convolutional codes; Compression algorithms; Control planes; Corresponding solutions; Large networks; Network properties; Orders of magnitude; Stable routing; Synthetic networks; Network routing
"Liu G., Ren Y., Yurchenko M., Ramakrishnan K.K., Wood T.",5,"Microboxes: High performance NFV with customizable, asynchronous TCP stacks and dynamic subscriptions",2018,0,"George Washington University, United States; University of California, Riverside, United States",George Washington University;University of California Riverside,2,USA,1,30,23,"Existing network service chaining frameworks are based on a Òpacket-centricÓ model where each NF in a chain is given every packet for processing. This approach becomes both inefficient and inconvenient for more complex network functions that operate at higher levels of the protocol stack. We propose Microboxes, a novel service chaining abstraction designed to support transport- and application-layer middleboxes, or even end-system like services. Simply including a TCP stack in an NFV platform is insufficient because there is a wide spectrum of middlebox types-from NFs requiring only simple TCP bytestream reconstruction to full endpoint termination. By exposing a publish/subscribe-based API for NFs to access packets or protocol events as needed, Microboxes eliminates redundant processing across a chain and enables a modular design. Our implementation on a DPDK-based NFV framework can double throughput by consolidating stack operations and provide a 51% throughput gain by customizing TCP processing to the appropriate level. © 2018 Copyright held by the owner/author(s).",Middleboxes; Networking Stack; NFV; Service Chain,Chains; Complex networks; Convolutional codes; Transmission control protocol; Application layers; Middleboxes; Modular designs; Network functions; Network services; Networking Stack; Packet-centric; Service chain; Network function virtualization
"Zhou P., Zhang W., Braud T., Hui P., Kangasharju J.",5,ARVE: Augmented reality applications in vehicle to edge networks,2018,0,"University of Helsinki, Finland; Hong Kong University of Science and Technology, Hong Kong, Hong Kong",Hong Kong University of Science and Technology;University of Helsinki,2,Finland;Hong Kong,2,22,17,"Vehicular communication applications, be it for driver-assisting augmented reality systems or fully driverless vehicles, require an efficient communication infrastructure for timely information delivery. Centralized, cloud-based infrastructures present latencies too high to satisfy the requirements of emergency information processing and transmission. In this paper, we present a novel Vehicle-to-Edge (ARVE) infrastructure, with computational units co-located with the base stations and aggregation points. Embedding computation at the edge of the network allows to reduce the overall latency compared to vehicle-to-cloud and significantly trim the complexity of vehicle-to-vehicle communication. To demonstrate the efficiency of our solution, we apply these principles on an augmented reality head-up display. In this use case, vehicular communication is exploited to connect vehicle's vision, and quickly propagate emergency information. ARVE is a general system framework, applicable to many practical scenarios. Our preliminary evaluation shows that ARVE noticeably decreases transmission latency with reasonable capital expenditure. © 2018 Association for Computing Machinery.",Augmented reality; Edge computing; Vehicle network,Augmented reality; Distributed computer systems; Edge computing; Vehicles; Augmented reality applications; Augmented reality systems; Capital expenditures; Efficient communications; Emergency information; Information delivery; Vehicle network; Vehicular communications; Vehicle to vehicle communications
"Wu D., Huang X.S., Xia Y., Dzinamarira S., Sun X.S., Eugene Ng T.S.",6,Masking failures from application performance in data center networks with shareable backup,2018,0,"Rice University, United States; Facebook, Inc., United States",Facebook;Rice University,2,USA,1,52,41,"Shareable backup is an economical and effective way to mask failures from application performance. A small number of backup switches are shared network-wide for repairing failures on demand so that the network quickly recovers to its full capacity without applications noticing the failures. This approach avoids complications and ineffectiveness of rerouting. We propose ShareBackup as a prototype architecture to realize this concept and present the detailed design. We implement ShareBackup on a hardware testbed. Its failure recovery takes merely 0.73ms, causing no disruption to routing; and it accelerates Spark and Tez jobs by up to 4.1_ under failures. Large-scale simulations with real data center traffic and failure model show that ShareBackup reduces the percentage of job flows prolonged by failures from 47.2% to as little as 0.78%. In all our experiments, the results for ShareBackup have little difference from the no-failure case. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Circuit Switching; Data Center Network; Failure Recovery,Convolutional codes; Application performance; Circuit switching; Data center networks; Detailed design; Failure recovery; Hardware testbeds; Large scale simulations; Prototype architecture; Computer system recovery
"Peng Y., Shangguan L., Hu Y., Qian Y., Lin X., Chen X., Fang D., Jamieson K.",8,PlorA: A passive long-range data network from ambient Lora transmissions,2018,2,"Princeton University, United States; Northwest University, United States",Northwest University;Princeton University,2,USA,1,51,26,"This paper presents PLoRa, an ambient backscatter design that enables long-range wireless connectivity for batteryless IoT devices. PLoRa takes ambient LoRa transmissions as the excitation signals, conveys data by modulating an excitation signal into a new standard LoRa ÒchirpÓ signal, and shifts this new signal to a dierent LoRa channel to be received at a gateway faraway. PLoRa achieves this by a holistic RF front-end hardware and software design, including a low-power packet detection circuit, a blind chirp modulation algorithm and a low-power energy management circuit. To form a complete ambient LoRa backscatter network, we integrate a light-weight backscatter signal decoding algorithm with a MAC-layer protocol that work together to make coexistence of PLoRa tags and active LoRa nodes possible in the network. We prototype PLoRa on a four-layer printed circuit board, and test it in various outdoor and indoor environments. Our experimental results demonstrate that our prototype PCB PLoRa tag can backscatter an ambient LoRa transmission sent from a nearby LoRa node (20 cm away) to a gateway up to 1.1 km away, and deliver 284 bytes data every 24 minutes indoors, or every 17 minutes outdoors. We also simulate a 28-nm low-power FPGA based prototype whose digital baseband processor achieves 220 µW power consumption. © 2018 Association for Computing Machinery.",Backscatter; Long-range; LoRa; Wireless networks,Backscattering; Chirp modulation; Convolutional codes; Integrated circuit design; Low power electronics; Printed circuit boards; Software design; Wireless networks; Backscatter signals; Digital baseband processors; Hardware and software designs; Long ranges; LoRa; MAC layer protocols; Modulation algorithm; Wireless connectivities; Gateways (computer networks)
"Wassermann S., Casas P.",2,BIGMOMAL - Big data analytics for mobile malware detection,2018,0,"Inria Paris, France; AIT Austrian Institute of Technology, Austria",AIT Austrian Institute of Technology,1,Austria;France,2,25,20,"Mobile malware is on the rise. Indeed, due to their popularity, smartphones represent an attractive target for cybercriminals, especially because of private user data, as these devices incorporate a lot of sensitive information about users, even more than a personal computer. As a matter of fact, besides personal information such as documents, accounts, passwords, and contacts, smartphone sensors centralise other sensitive data including user location and physical activities. In this paper, we study the problem of malware detection in smartphones, relying on supervised-machine-learning models and big-data analytics frameworks. Using the SherLock dataset, a large, publicly available dataset for smartphone-data analysis, we train and benchmark tree-based models to identify running applications and to detect malware activity. We verify their accuracy, and initial results suggest that decision trees are capable of identifying running apps and malware activity with high accuracy. © 2018 Association for Computing Machinery.",Big-data analytics; High-dimensional data; Machine learning; Mobile-malware detection,Artificial intelligence; Benchmarking; Clustering algorithms; Computer crime; Decision trees; Learning systems; Malware; Personal computers; Smartphones; Supervised learning; Trees (mathematics); Big Data Analytics; High dimensional data; Mobile malware; Personal information; Running applications; Sensitive informations; Smartphone sensors; Supervised machine learning; Big data
"Hong C.-Y., Mandal S., Al-Fares M., Zhu M., Alimi R., Kondapa Naidu B., Bhagat C., Jain S., Kaimal J., Liang S., Mendelev K., Padgett S., Rabe F., Ray S., Tewari M., Tierney M., Zahn M., Zolla J., Ong J., Vahdat A.",20,"B4 and after: Managing hierarchy, partitioning, and asymmetry for availability and scale in Google's software-defined WAN",2018,2,"Google, United States",Google,1,USA,1,34,29,"Private WANs are increasingly important to the operation of enterprises, telecoms, and cloud providers. For example, B4, Google's private software-defined WAN, is larger and growing faster than our connectivity to the public Internet. In this paper, we present the five-year evolution of B4. We describe the techniques we employed to incrementally move from offering best-effort content-copy services to carrier-grade availability, while concurrently scaling B4 to accommodate 100x more traffic. Our key challenge is balancing the tension introduced by hierarchy required for scalability, the partitioning required for availability, and the capacity asymmetry inherent to the construction and operation of any large-scale network. We discuss our approach to managing this tension: i) we design a custom hierarchical network topology for both horizontal and vertical software scaling, ii) we manage inherent capacity asymmetry in hierarchical topologies using a novel traffic engineering algorithm without packet encapsulation, and iii) we re-architect switch forwarding rules via two-stage matching/hashing to deal with asymmetric network failures at scale. © 2018 Association for Computing Machinery.",Software-Defined WAN; Traffic Engineering,Availability; Balancing; Convolutional codes; Topology; Asymmetric networks; Carrier grades; Cloud providers; Hierarchical network; Hierarchical topology; Large-scale network; Public internet; Traffic Engineering; Wide area networks
"Tonolini F., Adib F.",2,Networking across boundaries: Enabling wireless communication through the water-air interface,2018,0,"MIT Media Lab, United States",MIT Media Lab,1,USA,1,60,24,"We consider the problem of wireless communication across medium boundaries, specifically across the water-air interface. In particular, we are interested in enabling a submerged underwater sensor to directly communicate with an airborne node. Today's communication technologies cannot enable such a communication link. This is because no single type of wireless signal can operate well across different media and most wireless signals reflect back at media boundaries. We present a new communication technology, translational acoustic-RF communication (TARF). TARF enables underwater nodes to directly communicate with airborne nodes by transmitting standard acoustic signals. TARF exploits the fact that underwater acoustic signals travel as pressure waves, and that these waves cause displacements of the water surface when they impinge on the water-air boundary. To decode the transmitted signals, TARF leverages an airborne radar which measures and decodes these surface displacements. We built a prototype of TARF that incorporates algorithms for dealing with the constraints of this new communication modality. We evaluated TARF in controlled and uncontrolled environments and demonstrated that it enables the first practical communication link across the water-air interface. Our results show that TARF can achieve standard underwater bitrates up to 400bps, and that it can operate correctly in the presence of surface waves with amplitudes up to 16 cm peak-to-peak, i.e., 100, 000_ larger than the surface perturbations caused by TARF's underwater acoustic transmitter. © 2018 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.",Cross-Medium Communications; Subsea Internet of Things; Wireless,Acoustic waves; Convolutional codes; Decoding; Phase interfaces; Radio; Surface waves; Wireless telecommunication systems; Acoustic transmitters; Communication modalities; Communication technologies; Surface displacement; Surface perturbations; Underwater acoustic signal; Water-air interface; Wireless communications; Underwater acoustics
"Jiang J., Ananthanarayanan G., Bodik P., Sen S., Stoica I.",5,Chameleon: Scalable adaptation of video analytics,2018,1,"University of Chicago, United States; Microsoft Research, United States; UC Berkeley, Databricks Inc, United States",Microsoft;University of California Berkeley;University of Chicago,3,USA,1,34,23,"Applying deep convolutional neural networks (NN) to video data at scale poses a substantial systems challenge, as improving inference accuracy often requires a prohibitive cost in computational resources. While it is promising to balance resource and accuracy by selecting a suitable NN configuration (e.g., the resolution and frame rate of the input video), one must also address the significant dynamics of the NN configuration's impact on video analytics accuracy. We present Chameleon, a controller that dynamically picks the best configurations for existing NN-based video analytics pipelines. The key challenge in Chameleon is that in theory, adapting configurations frequently can reduce resource consumption with little degradation in accuracy, but searching a large space of configurations periodically incurs an overwhelming resource overhead that negates the gains of adaptation. The insight behind Chameleon is that the underlying characteristics (e.g., the velocity and sizes of objects) that affect the best configuration have enough temporal and spatial correlation to allow the search cost to be amortized over time and across multiple video feeds. For example, using the video feeds of five traffic cameras, we demonstrate that compared to a baseline that picks a single optimal configuration offline, Chameleon can achieve 20-50% higher accuracy with the same amount of resources, or achieve the same accuracy with only 30-50% of the resources (a 2-3_ speedup). © 2018 Association for Computing Machinery.",Deep neural networks; Object detection; Video analytics,Computation theory; Convolutional codes; Neural networks; Object detection; Computational resources; Deep convolutional neural networks; Multiple videos; Resource consumption; Search costs; Temporal and spatial correlation; Traffic camera; Video analytics; Deep neural networks
"Mohan N., Zavodovski A., Zhou P., Kangasharju J.",4,Anveshak: Placing edge servers in the wild,2018,0,"University of Helsinki, Finland",University of Helsinki,1,Finland,1,23,16,"Edge computing provides an attractive platform for bringing data and processing closer to users in networked environments. Several edge proposals aim to place the edge servers at a couple hop distance from the client to ensure lowest possible compute and network delay. An attractive edge server placement is to co-locate it with existing (cellular) base stations to avoid additional infrastructure establishment costs. However, determining the exact locations for edge servers is an important question that must be resolved for optimal placement. In this paper, we present Anveshak1, a framework that solves the problem of placing edge servers in a geographical topology and provides the optimal solution for edge providers. Our proposed solution considers both end-user application requirements as well as deployment and operating costs incurred by edge platform providers. The placement optimization metric of Anveshak considers the request pattern of users and existing user-established edge servers. In our evaluation based on real datasets, we show that Anveshak achieves 67% increase in user satisfaction while maintaining high server utilization. © 2018 Association for Computing Machinery.",Deployment framework; Edge clouds; Fog clouds; Server placement,Data handling; Human computer interaction; Deployment framework; Edge clouds; End-user applications; Geographical topology; Networked environments; Optimal placements; Placement optimization; Server placements; Operating costs
"Ghi‘tte V., Doerr C.",2,How media reports trigger copycats: An analysis of the brewing of the largest packet storm to date,2018,0,"TU Delft, Cyber Security Group, Delft, Netherlands",TU Delft,1,Netherlands,1,10,8,"In late February 2018, news spread through the mainstream media about a massive distributed denial-of-service attack on the popular software collaboration website github.com. Estimated at a rate of 1.3 Terrabit per second, this massive packet flood was the largest DDoS attack by volume to date, surpassing previous records set by the first IoT-based DDoS attacks in 2017. In this paper, we analyze the behavior of the actors scanning and probing the Internet for presence of exploitable memcached servers that were the root cause of this attack, both before and after the media coverage. We find that the attacks of late February were preceeded by a large scale reconnaissance action a month before, and that the attacks were the result of an extended evolution of methods to find a suitable attack strategy. Furthermore, we see that the coverage about the massive DDoS attack actually triggered another wave of DDoS attacks, resulting in the large influx of new, previously unseen users who seem to be leveraging ready-made tools. © 2018 Copyright held by the owner/author(s).",Denial-of-service attacks; Memcached; Threat intelligence,Network security; Attack strategies; DDoS Attack; Distributed denial of service attack; Mainstream media; Media coverage; Memcached; Packet floods; Threat intelligence; Denial-of-service attack
"Dhamdhere A., Clark D.D., Matthew Luckie A.G.-G., Mok R.K.P., Akiwate G., Gogia K., Bajpai V., Snoeren A.C., Claffy K.",9,Inferring persistent interdomain congestion,2018,0,"CAIDA/UC San Diego, United States; MIT, United States; University of Waikato, United States; TU Munich, United States",University of California San Diego;MIT;TU Munich;University of Waikato,4,USA,1,71,62,"There is significant interest in the technical and policy communities regarding the extent, scope, and consumer harm of persistent interdomain congestion. We provide empirical grounding for discussions of interdomain congestion by developing a system and method to measure congestion on thousands of interdomain links without direct access to them. We implement a system based on the Time Series Latency Probes (TSLP) technique that identifies links with evidence of recurring congestion suggestive of an under-provisioned link. We deploy our system at 86 vantage points worldwide and show that congestion inferred using our lightweight TSLP method correlates with other metrics of interconnection performance impairment. We use our method to study interdomain links of eight large U.S. broadband access providers from March 2016 to December 2017, and validate our inferences against ground-truth traffic statistics from two of the providers. For the period of time over which we gathered measurements, we did not find evidence of widespread endemic congestion on interdomain links between access ISPs and directly connected transit and content providers, although some such links exhibited recurring congestion patterns. We describe limitations, open challenges, and a path toward the use of this method for large-scale third-party monitoring of the Internet interconnection ecosystem. © 2018 Association for Computing Machinery.",Internet congestion; Internet topology; Performance,Traffic surveys; Broadband access; Content providers; Internet congestion; Internet topologies; Performance; Policy community; Third-party monitoring; Traffic statistics; Convolutional codes
"Metongnon L., Sadre R.",2,Beyond telnet: Prevalence of IoT protocols in telescope and honeypot measurements,2018,0,"UniversitŽ Catholique de Louvain, UniversitŽ d'Abomey-Calavi, ICTEAM/INGI, ED-SPI/IFRI, Louvain-la-Neuve, Belgium; Abomey-Calavi, Benin; UniversitŽ Catholique de Louvain, ICTEAM-INGI, Louvain-la-Neuve, Belgium",Universite Catholique de Louvain;UniversitŽ dAbomey-Calavi,2,Belgium;Benin,2,19,14,"With the arrival of the Internet of Things (IoT), more devices appear online with default credentials or lacking proper security protocols. Consequently, we have seen a rise of powerful DDoS attacks originating from IoT devices in the last years. In most cases the devices were infected by bot malware through the telnet protocol. This has lead to several honeypot studies on telnet-based attacks. However, IoT installations also involve other protocols, for example for Machine-to-Machine communication. Those protocols often provide by default only little security. In this paper, we present a measurement study on attacks against or based on those protocols. To this end, we use data obtained from a/15 network telescope and three honey-pots with 15 IPv4 addresses. We find that telnet-based malware is still widely used and that infected devices are employed not only for DDoS attacks but also for crypto-currency mining. We also see, although at a much lesser frequency, that attackers are looking for IoT-specific services using MQTT, CoAP, UPnP, and HNAP, and that they target vulnerabilities of routers and cameras with HTTP. © 2018 Copyright held by the owner/author(s).",Internet measurement; IoT; IoT attacks; IoT protocols,Denial-of-service attack; HTTP; Internet protocols; Machine-to-machine communication; Malware; Network security; Telescopes; DDoS Attack; Internet measurement; Internet of thing (IOT); IoT attacks; Iot devices; Measurement study; Network telescopes; Security protocols; Internet of things
"Agarwal S., Agarwal R., Rajakrishnan S., Shmoys D., Narayan A., Vahdat A.",6,Sincronia: Near-optimal network design for coflows,2018,0,"Cornell University, United States; MIT, United States; Google, United States",Cornell University;Google;MIT,3,USA,1,29,23,"We present Sincronia, a near-optimal network design for coflows that can be implemented on top on any transport layer (for flows) that supports priority scheduling. Sincronia achieves this using a key technical result ' we show that given a ÒrightÓ ordering of coflows, any per-flow rate allocation mechanism achieves average coflow completion time within 4_ of the optimal as long as (co)flows are prioritized with respect to the ordering. Sincronia uses a simple greedy mechanism to periodically order all unfinished coflows; each host sets priorities for its flows using corresponding coflow order and offloads the flow scheduling and rate allocation to the underlying priority-enabled transport layer. We evaluate Sincronia over a real testbed comprising 16-servers and commodity switches, and using simulations across a variety of workloads. Evaluation results suggest that Sincronia not only admits a practical, near-optimal design but also improves upon state-of-the-art network designs for coflows (sometimes by as much as 8_). © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Approximation Algorithms; Coflow; Datacenter Networks,Convolutional codes; Scheduling; Co-flow; Commodity switches; Data center networks; Evaluation results; Flow scheduling; Priority scheduling; State of the art; Transport layers; Approximation algorithms
"Jepsen T., De Sousa L.P., Moshref M., Pedone F., SoulŽ R.",5,Infinite resources for optimistic concurrency control,2018,1,"Universitˆ della Svizzera Italiana, Italy; Barefoot Networks, Italy",Universitˆ della Svizzera Italiana,1,Italy,1,33,13,"Optimistic concurrency control (OCC) is inefficient for highcontention workloads. When concurrent transactions conflict, an OCC system wastes CPU resources verifying transactions, only to abort them. This paper presents a new system, called Network Optimistic Concurrency Control (NOCC), which reduces load on storage servers by identifying transactions that will abort as early as possible, and aborting them before they reach the store. NOCC leverages recent advances in network data plane programmability to speculatively execute transaction verification logic directly in network devices. NOCC examines network traffic to observe and log transaction requests. If NOCC suspects that a transaction is likely to be aborted at the store, it aborts the transaction early by re-writing the packet header, and routing the packets back to the client. For high-contention workloads, NOCC improves transaction throughput, and reduces server load. © 2018 Association for Computing Machinery.",Optimistic concurrency control; Programmable switches,Computation theory; Digital storage; Concurrent transactions; High contentions; Optimistic concurrency controls; Programmability; Programmable switches; Storage servers; Transaction throughput; Verification logic; Concurrency control
"Li L., Xu K., Li T., Zheng K., Peng C., Wang D., Wang X., Shen M., Mijumbi R.",9,A Measurement study on multi-path TCP with multiple cellular carriers on high speed rails,2018,1,"Beijing National Research Center for Information Science and Technology, China; Tsinghua University, China; Huawei Technologies, China; Purdue University, United States; Hong Kong Polytechnic University, China; Beijing Institute of Technology, China; Nokia Bell Labs, Ireland",Beijing Institute of Technology;Tsinghua University;Hong Kong Polytechnic University;Nokia;Purdue University,5,China;Hong Kong;Ireland;USA,4,39,32,"Recent advances in high speed rails (HSRs) are propelling the need for acceptable network service in high speed mobility environments. However, previous studies show that the performance of traditional single-path transmission degrades significantly during high speed mobility due to frequent handoff. Multi-path transmission with multiple carriers is a promising way to enhance the performance, because at any time, there is possibly at least one path not suffering a handoff. In this paper, for the first time, we measure multi-path TCP (MPTCP) with two cellular carriers on HSRs with a peak speed of 310km/h. We find a significant difference in handoff time between the two carriers. Moreover, we observe that MPTCP can provide much better performance than TCP in the poorer of the two paths. This indicates that MPTCP's robustness to handoff is much higher than TCP's. However, the efficiency of MPTCP is far from satisfactory. MPTCP performs worse than TCP in the better path most of the time. We find that the low efficiency can be attributed to poor adaptability to frequent handoff by MPTCP's key operations in sub-flow establishment, congestion control and scheduling. Finally, we discuss possible directions for improving MPTCP for such scenarios. © 2018 Association for Computing Machinery.",Cellular Networks; High Speed Rails; Measurement; Multi-path TCP,Convolutional codes; Efficiency; Measurement; Speed; Cellular network; High speed rail; Key operations; Measurement study; Multi-path transmission; Multipaths; Multiple carriers; Network services; Transmission control protocol
"Kohler T., Mayer R., DŸrr F., Maa§ M., Bhowmik S., Rothermel K.",6,P4CEP: Towards in-network Complex Event Processing,2018,1,"Institute of Parallel and Distributed Systems (IPVS), University of Stuttgart, Stuttgart, Germany",University of Stuttgart,1,Germany,1,17,17,"In-network computing using programmable networking hardware is a strong trend in networking that promises to reduce latency and consumption of server resources through offloading to network elements (programmable switches and smart NICs). In particular, the data plane programming language P4 together with powerful P4 networking hardware has spawned projects offloading services into the network, e.g., consensus services or caching services. In this paper, we present a novel case for in-network computing, namely, Complex Event Processing (CEP). CEP processes streams of basic events, e.g., stemming from networked sensors, into meaningful complex events. Traditionally, CEP processing has been performed on servers or overlay networks. However, we argue in this paper that CEP is a good candidate for in-network computing along the communication path avoiding detouring streams to distant servers to minimize communication latency while also exploiting processing capabilities of novel networking hardware. We show that it is feasible to express CEP operations in P4 and also present a tool to compile CEP operations, formulated in our P4CEP rule specification language, to P4 code. Moreover, we identify challenges and problems that we have encountered to show future research directions for implementing full-fledged in-network CEP systems. © 2018 Association for Computing Machinery.",Complex Event Processing (CEP); Data plane programming; In-network computing; P4,Computer hardware; Computer hardware description languages; Distributed computer systems; Hardware; Specification languages; Complex event processing; Complex event processing (CEP); Data planes; Future research directions; In networks; Processing capability; Programmable networkings; Programmable switches; Complex networks
"Datta T., Apthorpe N., Feamster N.",3,A developer-friendly library for smart home iot privacy-preserving traffic obfuscation,2018,1,"Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,9,7,"The number and variety of Internet-connected devices have grown enormously in the past few years, presenting new challenges to security and privacy. Research has shown that network adversaries can use traffic rate metadata from consumer IoT devices to infer sensitive user activities. Shaping traffic flows to fit distributions independent of user activities can protect privacy, but this approach has seen little adoption due to required developer effort and overhead bandwidth costs. Here, we present a Python library for IoT developers to easily integrate privacy-preserving traffic shaping into their products. The library replaces standard networking functions with versions that automatically obfuscate device traffic patterns through a combination of payload padding, fragmentation, and randomized cover traffic. Our library successfully preserves user privacy and requires approximately 4 KB/s overhead bandwidth for IoT devices with low send rates or high latency tolerances. This overhead is reasonable given normal Internet speeds in American homes and is an improvement on the bandwidth requirements of existing solutions. © 2018 Copyright held by the owner/author(s).",Independent link padding; Internet of Things; Privacy; Traffic shaping,Automation; Bandwidth; Data privacy; Intelligent buildings; Bandwidth requirement; Connected Devices; Developer efforts; Link padding; Privacy preserving; Security and privacy; Traffic obfuscations; Traffic-shaping; Internet of things
"Thimmaraju K., RŽtv‡ri G., Schmid S.",3,Virtual network isolation: Are we there yet?,2018,0,"Security in Telecommunications, TU Berlin, Berlin, Germany; MTA-BME Information Systems, Research Group, Budapest, Hungary; Faculty of Computer Science, University of Vienna, Vienna, Austria; Internet Network Architectures, TU Berlin, Germany; Dept. of Computer Science, Aalborg University, Denmark",Aalborg University;TU Berlin;University of Vienna,3,Austria;Denmark;Germany;Hungary,4,38,33,"While multi-tenant cloud computing provides great benefits in terms of resource sharing, it introduces a new security landscape and requires strong network isolation guarantees between the tenants. Such network isolation is typically implemented using network virtualization: Virtual switches residing in the virtualization layer enforce isolation, e.g., via tunnel protocols and per-tenant flow rules. The design of such switches is a very active topic: Since 2009 alone, at least 22 different designs have been introduced. Our systematic analysis of 22 virtual switches uncovers 4 security weaknesses: Colocation, single point of failure, privileged packet processing and manual packet parsing. An attacker can easily undermine network isolation by exploiting those weaknesses. Hence, we introduce 3 secure design principles to build a resilient virtual switch, thereby offering strong virtual network isolation. © 2018 Copyright held by the owner/author(s).",Cloud security; Co-location; Data plane security; Disaggregation; Network isolation; Network virtualization; NFV; Open vSwitch; Packet parsing; SDN; Smart NIC; SR-IOV; Virtual switches,Distributed computer systems; Network function virtualization; Packet switching; Virtual reality; Cloud securities; Co-locations; Data planes; Disaggregation; Network isolation; Network virtualization; Open vswitch; Packet parsing; Smart NIC; Virtual switches; Network security
"Narayanan A., Verma S., Ramadan E., Babaie P., Zhang Z.-L.",5,DEEPCACHE: A deep learning based framework for content caching,2018,0,"University of Minnesota, Minneapolis, MN, United States",University of Minnesota,1,USA,1,20,18,"In this paper, we present DEEPCACHE a novel Framework for content caching, which can significantly boost cache performance. Our Framework is based on powerful deep recurrent neural network models. It comprises of two main components: i) Object Characteristics Predictor, which builds upon deep LSTM Encoder-Decoder model to predict the future characteristics of an object (such as object popularity) - to the best of our knowledge, we are the first to propose LSTM Encoder-Decoder model for content caching; ii) a caching policy component, which accounts for predicted information of objects to make smart caching decisions. In our thorough experiments, we show that applying DEEPCACHE Framework to existing cache policies, such as LRU and k-LRU, significantly boosts the number of cache hits. © 2018 Association for Computing Machinery.",Cache hit; Caching; Deep learning; DeepCache; Fake requests; Lstm; Machine learning; Popularity prediction; Prefetching; Proactive caching; Seq2seq; Smart caching policies; Video object caches,Decoding; Learning systems; Long short-term memory; Signal encoding; Cache hits; Caching; Caching policy; DeepCache; Fake requests; Lstm; Popularity predictions; Prefetching; Proactive caching; Seq2seq; Video objects; Deep learning
"Yang T., Wang L., Shen Y., Shahzad M., Huang Q., Jiang X., Tan K., Li X.",8,Empowering sketches with machine learning for network measurements,2018,3,"Peking University, China; North Carolina State University, United States; Xidian University, China; Institute of Computing Technology, Chinese Academy of Sciences, China; Future University Hakodate, Japan; HUAWEI Technologies, Co. LTD, United States",Future University Hakodate;Chinese Academy of Sciences;North Carolina State University;Peking University;Xidian University,5,China;Japan;USA,3,28,19,"Network monitoring and management require accurate statistics of a variety of flow-level metrics, such as flow sizes, top-k flows, and number of flows. Arguably, the most commonly used data structure to record and measure these metrics is the sketch. While a significant amount of work has already been done on sketching techniques, there is still a lot of room for improvement because the accuracy of existing sketches depends a lot on the nature of network traffic and varies significantly as the network traffic characteristics change. In this paper, we propose the idea of employing machine learning to reduce this dependence of the accuracy of sketches on network traffic characteristics and present a generalized machine learning framework that increases the accuracy of sketches significantly. We further present three case studies, where we applied our framework on sketches for measuring three well-known flow-level network metrics. Experimental results show that machine learning helps decrease the error rates of existing sketches by up to 202 times. © 2018 Association for Computing Machinery.",Machine Learning; Network Monitoring,Artificial intelligence; Case-studies; Error rate; Flow level; Flow sizes; Network measurement; Network metrics; Network Monitoring; Network traffic; Learning systems
"Li R., Clemm A., Chunduri U., Dong L., Makhijani K.",5,A new framework and protocol for future networking applications,2018,3,"Future Networks, America Research Center, Santa Clara, CA, United States",America Research Center,1,USA,1,15,12,"Future networking applications place demands on networking services that become increasingly difficult to address using existing internetworking technology. This paper presents a new framework and protocol that is designed to meet this challenge, BPP (Big Packet Protocol). BPP is intended as an enabler for a new generation of networking services that depend on the ability to provide precise service level guarantees while facilitating operations. In addition, BPP allows users to define and customize networking behavior from the network edge for their flows in isolation from other users and without needing to rely on lengthy vendor or network operator product cycles. © 2018 Copyright held by the owner/author(s).",Big packet protocol; BPP; Future internet; High-precision networking; Programmable networks; SLAs,Future internet; High-precision; Packet protocols; Programmable network; SLAs; Internet protocols
"Doan T.T., Safavi-Naini R., Li S., Avizheh S., Muni Venkateswarlu K., Fong P.W.L.",6,Towards a resilient smart home,2018,0,"University of Calgary, Canada",University of Calgary,1,Canada,1,24,19,"Today's Smart Home platforms such as Samsung SmartThings and Amazon AWS IoT are primarily cloud based: devices in the home sense the environment and send the collected data, directly or through a hub, to the cloud. Cloud runs various applications and analytics on the collected data, and generates commands according to the users' specifications that are sent to the actuators to control the environment. The role of the hub in this setup is effectively message passing between the devices and the cloud, while the required analytics, computation, and control are all performed by the cloud. We ask the following question: what if the cloud is not available? This can happen not only by accident or natural causes, but also due to targeted attacks. We discuss possible effects of such unavailability on the functionalities that are commonly available in smart homes, including security and safety related services as well as support for health and well-being of home users, and propose RES-Hub, a hub that can provide the required functionalities when the cloud is unavailable. During the normal functioning of the system, RES-Hub will receive regular status updates from cloud, and will use this information to continue to provide the user specified services when it detects the cloud is down.We describe an IoTivitybased software architecture that is used to implement RES-Hub in a flexible and expendable way and discuss our implementation. © 2018 Association for Computing Machinery.",IoT Security; Smart home resiliency; Smart home security,Automation; Intelligent buildings; Message passing; Cloud-based; IoT Security; Required functionalities; Safety-Related; Smart homes; Status updates; Targeted attacks; Well being; Internet of things
"Hamza A., Ranathunga D., Gharakheili H.H., Roughan M., Sivaraman V.",5,"Clear as MUD: Generating, validating and applying IoT behavioral profiles",2018,1,"UNSW, Sydney, Australia; ACEMS, University of Adelaide, Australia",University of Adelaide,1,Australia,1,29,26,"IoT devices are increasingly being implicated in cyber-attacks, raising community concern about the risks they pose to critical infrastructure, corporations, and citizens. In order to reduce this risk, the IETF is pushing IoT vendors to develop formal specifications of the intended purpose of their IoT devices, in the form of a Manufacturer Usage Description (MUD), so that their network behavior in any operating environment can be locked down and verified rigorously. This paper aims to assist IoT manufacturers in developing and verifying MUD profiles, while also helping adopters of these devices to ensure they are compatible with their organizational policies. Our first contribution is to develop a tool that takes the traffic trace of an arbitrary IoT device as input and automatically generates the MUD profile for it. We contribute our tool as open source, apply it to 28 consumer IoT devices, and highlight insights and challenges encountered in the process. Our second contribution is to apply a formal semantic framework that not only validates a given MUD profile for consistency, but also checks its compatibility with a given organizational policy. Finally, we apply our framework to representative organizations and selected devices, to demonstrate how MUD can reduce the effort needed for IoT acceptance testing. © 2018 Association for Computing Machinery.",IoT; MUD; Policy Verification,Acceptance tests; Manufacture; Network security; Semantics; Acceptance testing; Behavioral profiles; Formal Semantics; Network behaviors; Operating environment; Organizational policies; Policy verification; Traffic traces; Internet of things
"Garcia J., Korhonen T.",2,Efficient distribution-derived features for high-speed encrypted flow classification,2018,0,"Karlstad University, Karlstad, Sweden",Karlstad University,1,Sweden,1,31,18,"Flow classification is an important tool to enable efficient network resource usage, support traffic engineering, and aid QoS mechanisms. As traffic is increasingly becoming encrypted by default, flow classification is turning towards the use of machine learning methods employing features that are also available for encrypted traffic. In this work we evaluate flow features that capture the distributional properties of in-flow per-packet metrics such as packet size and inter-arrival time. The characteristics of such distributions are often captured with general statistical measures such as standard deviation, variance, etc. We instead propose a Kolmogorov-Smirnov discretization (KSD) algorithm to perform histogram bin construction based on the distributional properties observed in the data. This allows for a richer, histogram based, representation which also requires less resources for feature computation than higher order statistical moments. A comprehensive evaluation using synthetic data from Gaussian and Beta mixtures show that the KSD approach provides Jensen-Shannon distance results surpassing those of uniform binning and probabilistic binning. An empirical evaluation using live traffic traces from a cellular network further shows that when coupled with a random forest classifier the KSD-constructed features improve classification performance compared to general statistical features based on higher order moments, or alternative bin placement approaches. © 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Discretization; Machine learning; Traffic classification,Artificial intelligence; Cryptography; Decision trees; Graphic methods; Learning systems; Classification performance; Comprehensive evaluation; Discretizations; Distributional property; Empirical evaluations; Machine learning methods; Random forest classifier; Traffic classification; Classification (of information)
"Sedar R., Borokhovich M., Chiesa M., Antichi G., Schmid S.",5,Supporting emerging applications with low-latency failover in P4,2018,0,"UniversitŽ Catholique de Louvain, Belgium; Independent Researcher, United States; KTH Royal Institute of Technology, Sweden; Queen Mary University of London, United Kingdom; University of Vienna, Austria",KTH Royal Institute of Technology;Queen Mary University of London;University of Vienna;Universite Catholique de Louvain,4,Austria;Belgium;Sweden;UK;USA,5,20,19,"Emerging applications expect fast turn-around from in-network failover mechanisms. This paper starts exploring the design space for supporting high availability and low latency using fast reroute in programmable data planes. In particular, we present a primitive for supporting well-known fast reroute mechanisms that is both efficient in terms of packet processing latency, memory requirements, and switch throughput. © 2018 Copyright held by the owner/author(s).",Fast failover; High availability; Low latency; Programmable data planes,Data planes; Emerging applications; Failover; Failover mechanism; High availability; Low latency; Memory requirements; Packet processing
"Tu K., Swami A., Ribeiro B., Towsley D.",4,Tracking groups in mobile network traces,2018,0,"University of Massachusetts Amherst, United States; Army Research Lab, United States; Purdue University, United States","Army Research Lab, Adlephi;Purdue University;University of Massachusetts Amherst",3,USA,1,26,19,"Detecting and tracking groups in mobility network traces is critical for developing accurate mobility models, which in turn are needed for mobile/wireless network design. One approach is to represent mobility traces as a temporal network and apply group (community) detection algorithms to it. However, observing detailed changes in a group over time requires analyzing group dynamics at small time scales and introduces two challenges: (a) group connectivity may be too sparse for group detection; and (b) tracking evolving groups and their lifetimes is difficult. We proposes a group detection framework to address these time scale challenges. For the time-dependent aspect of the groups, we propose a time series segmentation algorithm to detect their formations, dissolutions, and lifetimes. We generate synthetic datasets for mobile networks and use real-world datasets to test our method against state-of-the-art. The results show that our proposed approach achieves more accurate fine-grained group detection than competing methods. © 2018 Association for Computing Machinery.",Clustering; Community detection; Temporal network,Mobile telecommunication systems; Clustering; Community detection; Detection algorithm; Group connectivity; Real-world datasets; Synthetic datasets; Temporal networks; Time-series segmentation; Wireless networks
"Lei K., Bai B., Qin M., Zhang G.",4,Adaptive multiple non-negative matrix factorization for temporal link prediction in dynamic networks,2018,0,"Shenzhen Key Lab for Cloud Computing Technology and Applications (SPCCTA), School of Electronic and Computer Engineering, Peking University, Shenzhen, China; Future Network Theory Lab, 2012 Labs, Huawei Technologies, Co. Ltd., Shatin, N.T., Hong Kong",Peking University,1,China;Hong Kong,2,18,14,"The prediction of mobility, topology and traffic is an effective technique to improve the performance of various network systems, which can be generally represented as the temporal link prediction problem. In this paper, we propose a novel adaptive multiple nonnegative matrix factorization (AM-NMF) method from the view of network embedding to cope with such problem. Under the framework of non-negative matrix factorization (NMF), the proposed method embeds the dynamic network into a low-dimensional hidden space, where the characteristics of different network snapshots are comprehensively preserved. Especially, our new method can effectively incorporate the hidden information of different time slices, because we introduce a novel adaptive parameter to automatically adjust the relative contribution of different terms in the uniform model. Accordingly, the prediction result of future network topology can be generated by conducting the inverse process of NMF form the shared hidden space. Moreover, we also derive the corresponding solving strategy whose convergence can be ensured. As an illustration, the new model will be applied to various network datasets such as human mobility networks, vehicle mobility networks, wireless mesh networks and data center networks. Experimental results show that our method outperforms some other state-of-the-art methods for the temporal link prediction of both unweighted and weighted networks. © 2018 Association for Computing Machinery.",Dynamic networks; Network embedding; Non-negative matrix factorization; Temporal link prediction,Factorization; Forecasting; Inverse problems; MESH networking; Topology; Data center networks; Dynamic network; Link prediction; Network embedding; Nonnegative matrix factorization; Relative contribution; Shared hidden spaces; State-of-the-art methods; Matrix algebra
"Cho J.Y., Szyrkowiec T.",2,Practical authentication and access control for software-defined networking over optical networks,2018,0,"ADVA Optical Networking SE, Fraunhoferstrasse 9a, Martinsried, 82152, Germany","ADVA Optical Networking, Germany",1,Germany,1,33,27,"A framework of Software-Defined Networking (SDN) provides a centralized and integrated method to manage and control modern optical networks. Unfortunately, the centralized and programmable structure of SDN introduces several new security threats, which may allow an adversary to take over the entire operation of the network. In this paper, we investigate the potential security threats of SDN over optical networks and propose a mutual authentication and a fine-grained access control mechanism, which are essential to avoid an unauthorized access to the network. The proposed schemes are based only on cryptographic hash functions and do not require an installation of the complicated cryptographic library such as SSL. Unlike conventional authentication and access control schemes, the proposed schemes are flexible, compact and, in addition, are resistant to quantum computer attacks, which may become critical in the near future. © 2018 ACM.",Access control; Authentication; Merkle signature; Optical networks; SDN,Access control; Authentication; Fiber optic networks; Hash functions; Quantum computers; Security systems; Software defined networking; Access control mechanism; Access control schemes; Cryptographic hash functions; Integrated method; Merkle signatures; Mutual authentication; Software defined networking (SDN); Unauthorized access; Network security
"Shannigrahi S., Fan C., White G.",3,Bridging the ICN deployment gap with IPoC: An IP-over-ICN protocol for 5G networks,2018,0,"Colorado State University, United States; CableLabs, United States",Colorado State University,1,USA,1,28,26,"Information-centric networking (ICN) is a new networking model that addresses content directly rather than addressing end-hosts. An ICN-based networking layer aligns better with application needs; it provides content-centric security, caching, and intelligent packet forwarding making it useful to both users and service providers alike in terms of efficiency, security, and mobility. ICN has recently received considerable attention; researchers have explored its bene-fits for diverse use cases such as large-data applications, building automation systems, vehicular networks, and IoT applications. While ICN provides significant benefits to all these application areas, one significant challenge that remains to be addressed is real-world deployment. An ICN-only network will require all IP applications to be rewritten to use ICN natively, a tall order in a world with millions of applications connected to the Internet. Though this problem affects all IP applications, we use mobile applications as the driving example for this work. An ICN based network can benefit smartphone users with higher throughput and lower service interruptions and at the same time, allow mobile service providers to utilize their network better and reduce protocol complexity. In this paper, we propose IPoC, a general purpose tunneling protocol that enables all IP applications to utilize ICN networks. We implement the IPoC protocol using Named Data Networking (NDN) semantics and using mobile communication as the driving example, compare our protocol performance with native IP. We show that the protocol overhead and performance degradation of IPoC is minimal which makes it suitable for immediate deployment. In return, we show how NDN and IPoC can bring ICN benefits to 5G mobile networks by simplifying the mobility plane, introducing intelligent functionality, and reducing network complexity. © 2018 Copyright held by the owner/author(s).",5G mobility plane; Dual connectivity; ICN deployment; ICN for 5G networks; Information centric networking; IP over ICN tunneling protocol; Mobile Handover; Named data networking,5G mobile communication systems; Automation; Complex networks; Intelligent buildings; Internet service providers; Mobile security; Mobile telecommunication systems; Network layers; Queueing networks; Semantics; 5G mobility plane; 5g networks; Dual connectivity; ICN deployment; Information-centric networkings; Mobile handover; Named data networkings; Tunneling protocols; Internet protocols
"Prabhu S., Chaudhry G.I., Godfrey B., Caesar M.",4,High-coverage testing of softwarized networks,2018,0,"University of Illinois, Urbana-Champaign, United States",UIUC,1,USA,1,18,18,"Network operators face a challenge of ensuring correctness as networks grow more complex, in terms of scale and increasingly in terms of diversity of software components. Network-wide verification approaches can spot errors, but assume a simplified abstraction of the functionality of individual network devices, which may deviate from the real implementation. In this paper, we propose a technique for high-coverage testing of end-to-end network correctness using the real software that is deployed in these networks. Our design is effectively a hybrid, using an explicit-state model checker to explore all network-wide execution paths and event orderings, but executing real software as subroutines for each device. We show that this approach can detect correctness issues that would be missed both by existing verification and testing approaches, and a prototype implementation suggests the technique can scale to larger networks with reasonable performance. © 2018 Copyright held by the owner/author(s).",Correctness; Network verification,Model checking; Subroutines; Correctness; End-to-end network; Explicit-state model; Individual network; Network operator; Prototype implementations; Software component; Verification and testing; Software testing
"Hamza A., Gharakheili H.H., Sivaraman V.",3,Combining MUD policies with SDN for IoT intrusion detection,2018,0,"University of New South Wales, Sydney, Australia",University of New South Wales,1,Australia,1,19,18,"The IETF's push towards standardizing the Manufacturer Usage Description (MUD) grammar and mechanism for specifying IoT device behavior is gaining increasing interest from industry. The ability to control inappropriate communication between devices in the form of access control lists (ACLs) is expected to limit the attack surface on IoT devices; however, little is known about how MUD policies will get enforced in operational networks, and how they will interact with current and future intrusion detection systems (IDS). We believe this paper is the first attempt to translate MUD policies into flow rules that can be enforced using SDN, and in relating exception behavior to attacks that can be detected via off-the-shelf IDS. Our first contribution develops and implements a system that translates MUD policies to flow rules that are proactively configured into network switches, as well as reactively inserted based on run-time bindings of DNS. We use traces of 28 consumer IoT devices taken over several months to evaluate the performance of our system in terms of switch flow-table size and fraction of exception traffic that needs software inspection. Our second contribution identifies the limitations of flow-rules derived from MUD in protecting IoT devices from internal and external network attacks, and we show how our system is able to detect such volumetric attacks (including port scanning, TCP/UDP/ICMP flooding, ARP spoofing, and TCP/SSDP/SNMP reflection) by sending only a very small fraction of exception packets to off-the-shelf IDS. © 2018 Association for Computing Machinery.",Intrusion Detection; IoT; MUD; SDN,Access control; Computer crime; Computer software selection and evaluation; Internet protocols; Intrusion detection; Network security; Time switches; Transmission control protocol; Access control lists; ARP Spoofing; External network; Intrusion Detection Systems; Network switches; Operational network; Port scanning; Software inspection; Internet of things
"Cano C., Neu G.",2,Wireless optimisation via convex bandits: Unlicensed LTE/WiFi coexistence,2018,0,"Universitat Oberta de Catalunya, Castelldefels, Spain; Uiversitat Pompeu Fabra, Barcelona, Spain",Universitat Oberta de Catalunya,1,Spain,1,24,20,"Bandit Convex Optimisation (BCO) is a powerful framework for sequential decision-making in non-stationary and partially observable environments. In a BCO problem, a decision-maker sequentially picks actions to minimize the cumulative cost associated with these decisions, all while receiving partial feedback about the state of the environment. This formulation is a very natural it for wireless-network optimisation problems and has great application potential since: i) instead of assuming full observability of the network state, it only requires the metric to optimise as input, and ii) it provides strong performance guarantees while making only minimal assumptions about the network dynamics. Despite these advantages, BCO has not yet been explored in the context of wireless-network optimisation. In this paper, we make the irst steps to demonstrate the potential of BCO techniques by formulating an unlicensed LTE/WiFi fair coexistence use case in the framework, and providing empirical results in a simulated environment. On the algorithmic front, we propose a simple and natural sequential multi-point BCO algorithm amenable to wireless networking optimisation, and provide its theoretical analysis. We expect the contributions of this paper to pave the way to further research on the application of online convex methods in the bandit setting. © 2018 Association for Computing Machinery.",Bandit convex optimisation; Coexistence; Spectrum sharing; Unlicensed LTE,Convex optimization; Decision making; Wireless networks; Coexistence; Convex optimisation; Partially observable environments; Performance guarantees; Sequential decision making; Spectrum sharing; Unlicensed LTE; Wireless network optimisation; Wireless telecommunication systems
"Park T., Xu Z., Shin S.",3,HEX switch: Hardware-assisted security extensions of OpenFlow,2018,0,"KAIST, South Korea; StackRox Inc., South Korea",KAIST;StackRox Inc.,2,South Korea,1,18,17,"Software-defined networking (SDN) and Network Function Virtualization (NFV) have inspired security researchers to devise new security applications for these new network technology. However, since SDN and NFV are basically faithful to operating a network, they only focus on providing features related to network control. Therefore, it is challenging to implement complex security functions such as packet payload inspection. Several studies have addressed this challenge through an SDN data plane extension, but there were problems with performance and control interfaces. In this paper, we introduce a new data plane architecture, HEX which leverages existing data plane architectures for SDN to enable network security applications in an SDN environment efficiently and effectively. HEX provides security services as a set of OpenFlow actions ensuring high performance and a function of handling multiple SDN actions with a simple control command. We implemented a DoS detector and Deep Packet Inspection (DPI) as the prototype features of HEX using the NetFPGA-1G-CML, and our evaluation results demonstrate that HEX can provide security services as a line-rate performance. © 2018 Association for Computing Machinery.",NetFPGA; SDN; Security,Application programs; Field programmable gate arrays (FPGA); Hardware security; Network function virtualization; Control interfaces; Deep packet inspection (DPI); Evaluation results; NetFPGA; Network technologies; Security; Security application; Software defined networking (SDN); Network security
"Surridge M., Correndo G., Meacham K., Papay J., Phillips S.C., Wiegand S., Wilkinson T.",7,Trust modelling in 5G mobile networks,2018,0,"IT Innovation Centre, Southampton, United Kingdom","IT Innovation Centre,UK",1,UK,1,13,11,"5G technologies will change the business landscape for mobile network operation. The use of virtualization through SDN, NFV and Cloud computing offer significant savings of CAPEX and OPEX, but they also allow new stakeholders to rent infrastructure capacity and operate mobile networks, including specialized networks supporting so-called vertical applications serving specific business sectors. In the resulting diverse stakeholder communities, the old trust assumptions between network operators will no longer apply. There is a pressing need for a far broader understanding of trust in such networks if they are to operate safely and securely for the engaged stakeholder communities. This paper describes the work carried out in the 5G-ENSURE project to address this need. © 2018 Association for Computing Machinery.",5G; Security; Telecommunications networks; Trust,5G mobile communication systems; Distributed computer systems; Mobile security; Mobile telecommunication systems; Wireless networks; Network operations; Network operator; Security; Specialized networks; Telecommunications networks; Trust; Trust assumptions; Trust Modelling; Network security
"Zhang Y., Xu K., Bai B., Lei K.",4,IFS-RL: An intelligent forwarding strategy based on reinforcement learning in named-data networking,2018,0,"Shenzhen Key Lab for Cloud Computing Technology and Applications, School of Electronic and Computer Engineering, Peking University, Shenzhen, China; School of Mathematical and Natural Sciences, Arizona State University Arizona, United States; Future Network Theory Lab, 2012 Labs, Huawei Technologies, Co. Ltd., Shatin, N.T., Hong Kong",Arizona State University;Peking University,2,China;Hong Kong;USA,3,16,15,"Named-Data Networking (NDN) is a new communication paradigm where network primitives are based on named-data rather than host identifiers. Compared with IP, NDN has a unique feature that forwarding plane enables each router to select the next forwarding hop independently without relying on routing. Therefore, forwarding strategies play a significant role for adaptive and efficient data transmission in NDN. Most of the existing forwarding strategies use fixed control rules based on simplified or inaccurate models of the deployment environment. As a result, existing schemes inevitably fail to achieve optimal performance across a broad set of network conditions and application demands. In this paper, We propose IFS-RL, an intelligent forwarding strategy based on reinforcement learning. IFS-RL trains a neural network model which chooses appropriate interfaces for the forwarding of Interest based on observations collected by routing node. Not relying on pre-programmed models, IFS-RL learns to make decisions solely through observations of the resulting performance of past decisions. Therefore, IFS-RL can implement intelligent forwrarding which adapt to a wide range of network conditions. Besides, we also researches the learning granularity and the enhancement for network topology change. We compare IFS-RL to state-of-the-art forwarding strategies in ndnSIM. Experimental results show that IFS-RL can achieve higher throughput and lower packet drop rates. © 2018 Association for Computing Machinery.",Forwarding strategy; Learning granularity; Named-Data Networking; Network topology; Reinforcement learning,Distributed computer systems; Topology; Communication paradigm; Forwarding strategies; Intelligent forwarding; Learning granularity; Named data networkings; Network topology; Neural network model; Optimal performance; Reinforcement learning
"Kong Y., Zang H., Ma X.",3,Improving TCP congestion control with machine intelligence,2018,0,"School of ECE, Georgia Tech Atlanta, GA, Georgia; Futurewei Technologies, Inc., Santa Clara, CA, United States",Futurewei Technologies Inc.;Georgia Tech,2,USA,1,32,13,"In a TCP/IP network, a key to ensure efficient and fair sharing of network resources among its users is the TCP congestion control (CC) scheme. Previously, the design of TCP CC schemes is based on hard-wiring of predefined actions to specific feedback signals from the network. However, as networks become more complex and dynamic, it becomes harder to design the optimal feedback-action mapping. Recently, learning-based TCP CC schemes have attracted much attention due to their strong capabilities to learn the actions from interacting with the network. In this paper, we design two learning-based TCP CC schemes for wired networks with under-buffered bottleneck links, a loss predictor (LP) based TCP CC (LP-TCP), and a reinforcement learning (RL) based TCP CC (RL-TCP). We implement both LP-TCP and RL-TCP in NS2. Compared to the existing NewReno and Q-learning based TCP, LP-TCP and RL-TCP both achieve a better tradeoff between throughput and delay, under various simulated network scenarios. © 2018 Association for Computing Machinery.",Machine learning; Packet loss prediction; Reinforcement learning; TCP congestion control,Artificial intelligence; Feedback; Learning algorithms; Learning systems; Reinforcement learning; Traffic congestion; Bottleneck link; Loss prediction; Machine intelligence; Network resource; Optimal Feedback; Simulated networks; TCP congestion control; TCP/IP networks; Transmission control protocol
"Kang H., Shin S., Yegneswaran V., Ghosh S., Porras P.",5,AEGIS: An automated permission generation and verification system for SDNs,2018,0,"KAIST, South Korea; SRI International, South Korea",KAIST,1,South Korea,1,29,25,"An important consideration in Software-defined Networks (SDNs), is that one SDN application, through a bug or API misuse, can break an entire SDN. While previous works have tried to mitigate such concerns by implementing access control mechanisms (permission models) for an SDN controller, they commonly require serious manual efforts in creating a permission model. Moreover, they do not support flexible permission models, and they are often tightly coupled with a specific SDN controller. To address such limitations, we introduce an automated permission generation and verification system called AEGIS. A distinguishing aspect of AEGIS is that it automatically generates flexible permission models and yet is completely separated from an SDN controller implementation. To demonstrate the feasibility of our approach, we implement a prototype, evaluate its completeness and soundness, and examine its usability in the context of popular SDN controllers. © 2018 Association for Computing Machinery.",Automation; Permission system; SDN security,Access control; Application programming interfaces (API); Application programs; Automation; Controllers; Access control mechanism; Permission system; Sdn applications; Sdn controllers; Sdn securities; Tightly-coupled; Verification systems; Network security
"Turkovic B., Kuipers F., Van Adrichem N., Langendoen K.",4,Fast network congestion detection and avoidance using P4,2018,0,"Delft University of Technology, Netherlands; TNO, Netherlands",TU Delft,1,Netherlands,1,12,11,"Along with exciting visions for 5G communications and the Tactile Internet, the networking requirement of attaining extremely low end-to-end latency has appeared. While network devices are typically equipped with buffers to counteract packet loss caused by short-lived traffic bursts, the more those buffers get filled, the more delay is added to every packet passing through. In this paper, we develop congestion avoidance methods that harness the power of fully programmable data-planes. The corresponding programmable switches, through languages such as P4, can be programmed to gather and react to important packet meta-data, such as queue load, while the data packets are being processed. In particular, we enable P4 switches to (1) track processing and queuing delays of latency-critical flows and (2) react immediately in the data-plane to congestion by rerouting the affected flows. Through a proof-of-concept implementation in emulation and on real hardware, we demonstrate that a data-plane approach reduces average and maximum delay, as well as jitter, when compared to non-programmable approaches. © 2018 Copyright held by the owner/author(s).",5G; Low latency; Programmable data-planes; Tactile internet,5G mobile communication systems; Congestion avoidance; Data planes; End to end latencies; Fully programmables; Low latency; Network congestions; Programmable switches; Short-lived traffic; Packet networks
"Acar G., Huang D.Y., Li F., Narayanan A., Feamster N.",5,Web-based attacks to discover and control local IoT devices,2018,0,"Princeton University, United States; UC Berkeley, United States",Princeton University;University of California Berkeley,2,USA,1,49,41,"In this paper, we present two web-based attacks against local IoT devices that any malicious web page or third-party script can perform, even when the devices are behind NATs. In our attack scenario, a victim visits the attacker's website, which contains a malicious script that communicates with IoT devices on the local network that have open HTTP servers. We show how the malicious script can circumvent the same-origin policy by exploiting error messages on the HTML5 MediaError interface or by carrying out DNS rebinding attacks.We demonstrate that the attacker can gather sensitive information from the devices (e.g., unique device identifiers and precise geolocation), track and profile the owners to serve ads, or control the devices by playing arbitrary videos and rebooting. We propose potential countermeasures to our attacks that users, browsers, DNS providers, and IoT vendors can implement. © 2018 Association for Computing Machinery.",DNS rebinding; Internet of Things; JavaScript; Privacy,Data privacy; HTTP; Internet protocols; Websites; Attack scenarios; DNS rebinding; Error messages; Javascript; Malicious web pages; Same-origin policy; Sensitive informations; Web-based attacks; Internet of things
"Salman S., Streiffer C., Chen H., Benson T., Kadav A.",5,DeepConf: Automating data center network topologies management with machine learning,2018,0,"Brown University, United States; Duke University, United States; UESTC, China; NEC Labs, United States",Brown University;Duke University,2,China;USA,2,39,30,"In recent years, many techniques have been developed to improve the performance and efficiency of data center networks. While these techniques provide high accuracy, they are often designed using heuristics that leverage domain-specific properties of the workload or hardware. In this vision paper, we argue that many data center networking techniques, e.g., routing, topology augmentation, energy savings, with diverse goals share design and architectural similarities. We present a framework for developing general intermediate representations of network topologies using deep learning that is amenable to solving a large class of data center problems. We develop a framework, DeepConf, that simplifies the process of configuring and training deep learning agents by using our intermediate representation to learn different tasks. To illustrate the strength of our approach, we implemented and evaluated a DeepConf-agent that tackles the data center topology augmentation problem. Our initial results are promising - DeepConf performs comparably to the optimal solution. © 2018 Association for Computing Machinery.",Data center networks; Deep reinforcement learning; Topology management,Deep learning; Energy conservation; Intelligent agents; Reinforcement learning; Topology; Augmentation problems; Data center networkings; Data center networks; Intermediate representations; Learning agents; Network topology; Optimal solutions; Topology management; Information management
"Venkataraman S., Wang J.",2,Assessing the impact of network events with user feedback,2018,0,"AT and T Labs - Research, United States",AT and T Labs,1,USA,1,16,12,"User feedback data, generated when users call customer care agents with problems, is a valuable source of data for understanding network problems from users' perspectives. However, this data is extremely noisy. In this paper, we design a framework, LOTUS, to assess the user impact of network events from the user feedback, through a novel algorithmic composition of co-training and spatial scan statistics. Through experimental analysis on synthetic and real data, we show the accuracy and practical nature of LOTUS. © 2018 Association for Computing Machinery.",Cellular networks; Machine learning,Algorithmic compositions; Cellular network; Customer care; Experimental analysis; Network problems; Spatial scan statistics; Synthetic and real data; User feedback; Learning systems
"Kšrner M., Runge T.M., Panda A., Ratnasamy S., Shenker S.",5,Open carrier interface: An open source edge computing framework,2018,1,"ICSI, United States; NYU, United States; UC Berkeley, United States",NYU;University of California Berkeley,2,USA,1,18,18,"Edge computing is an emerging technology, which offers manifold performance improvements for applications with low-latency and high-bandwidth requirements. In order to lower the burden for the Network Service Provider to support edge computing, we introduce a generic and platform-agnostic open source edge computing framework implementation called Open Carrier Interface. The implemented prototype provides Application Service Providers with the opportunity to deploy software components directly at the edge of the network and without any operator intervention. We will elaborate and demonstrate that the developed framework and its interfaces (i) are easy to use for all involved parties, (ii) present a unifying abstraction layer for edge-based resource management systems and edge service architectures, (iii) and can deliver a significant performance impact on applications implementing the edge service paradigm. © 2018 Association for Computing Machinery.",Computation offloading; Edge computing,Abstracting; Application programs; Edge computing; Internet service providers; Open source software; Application service provider; Computation offloading; Computing frameworks; Emerging technologies; Network service providers; Operator interventions; Performance improvements; Resource management systems; Open systems
"Xiao S., He D., Gong Z.",3,Deep-Q: Traffic-driven qos inference using deep generative network,2018,0,"Network Technology Lab, Huawei Technologies Co., Ltd., Beijing, China",University of California Berkeley;NYU,2,China,1,20,19,"In today's IP network, it is important to provide the Quality of Service (QoS) guarantee for network services. However, in real networks with highly dynamic traffic demands, it is difficult to build an accurate QoS model even with a high cost of human expert analysis. In this paper, we present Deep-Q, a data-driven system to learn the QoS model directly from traffic data without human analysis. This function is achieved by utilizing the power of state-of-the-art deep generative networks in the deep learning area. Deep-Q provides a novel inference structure of a variational auto-encoder (VAE) enhanced by the long short-term memory (LSTM). A specially-designed module named Cinfer-loss is further applied to improve the QoS inference accuracy. By training with real traffic data, Deep-Q can infer a variety of QoS metrics over different networks given traffic conditions in real-time. We build testbeds for both the data center network and overlay IP network. Extensive experiments with 5.7TB traffic traces demonstrate that Deep-Q can achieve on average 3x higher inference accuracy than traditional queuing-theory-based solution in real networks while keeping inference time within 100ms. © 2018 Association for Computing Machinery.",Deep generative network; QoS model; Traffic-driven,Deep learning; Long short-term memory; Quality of service; Queueing theory; Data center networks; Dynamic traffic; Network services; QoS modeling; Quality of service (QoS) guarantees; State of the art; Traffic conditions; Traffic traces; Internet protocols
"Gao C., Chandrasekaran V., Fawaz K., Banerjee S.",4,Traversing the quagmire that is privacy in your smart home,2018,0,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,36,31,"Voice has become an increasingly popular User Interaction (UI) channel, with voice-activated devices becoming regular fixtures in our homes. The popularity of voice-based assistants (VAs), however, have brought along significant privacy and security threats to their users. Recent revelations have indicated that some VAs record user's private conversations continuously and innocuously. With the VAs being connected to the Internet, they can leak the recorded content without the user's authorization. Moreover, these devices often do not pack authentication mechanisms to check if the voice commands are issued by authorized users. To address both shortcomings, we propose a framework to impose a security and privacy perimeter around the user's VA. Our proposed framework continuously jams the VA to prevent it from innocuously recording the user's speech, unless the user issues a voice command. To prevent unauthorized voice commands, our framework provides a scheme similar to two-factor authentication to only grant access when the authorized user is in its vicinity. Our proposed framework achieves both objectives through a combination of several techniques to (a) continuously jam one (or many) VA's microphones in a manner inaudible to the user, and (b) provide only authenticated users easy access to VAs. © 2018 Copyright held by the owner/author(s).",Authentication; Privacy; Smart home; Ultrasound jamming; Voice assistant,Automation; Data privacy; Intelligent buildings; Internet of things; Activated devices; Authentication mechanisms; Authorized users; Privacy and security; Security and privacy; Smart homes; Two factor authentication; User interaction; Authentication
"Li G., Shen Q., Liu Y., Cao H., Han Z., Li F., Li J.",7,Data-driven approaches to edge caching,2018,0,"New York University, Brooklyn, NY, United States; New York Institute of Technology, New York, NY, United States; Huawei Technologies, Nanjing, China",New York Institute of Technology;NYU,2,China;USA,2,17,12,"Content caching at network edge is a promising solution for serving emerging high-throughput low-delay applications, such as virtual reality, augmented reality and Internet-of-Things. The traditional caching algorithms need to adapt to the edge networking environment since old traffic assumptions may no longer hold. Meanwhile, user/group content interest as a new important element should be considered to improve the caching performance. In this work, we propose two novel caching strategies that mine user/group interests to improve caching performance at network edge. The static user-group interest patterns are handled by the Matrix Factorization method and the temporal content request patterns are handled by the Least-Recently-Used or Nearest-Neighbor algorithms. Through empirical experiments with a large-scale real IPTV user traces, we demonstrate that the proposed caching algorithms outperform the existing caching algorithms and approach the caching performance upper bound in the large cache size regime. Leveraging on offline computation, we can limit the online computation cost and achieve good caching performance in realtime. © 2018 Association for Computing Machinery.",Data-driven; Edge caching,Augmented reality; Virtual reality; Data driven; Data-driven approach; Edge caching; Empirical experiments; Matrix factorizations; Nearest neighbor algorithm; Off-line computation; Online computations; Factorization
"He D., Westphal C., Garcia-Luna-Aceves J.J.",3,Joint rate and FoV adaptation in immersive video streaming,2018,0,"Tsinghua University, Beijing, China; University of California, Santa Cruz, Santa Cruz, CA, United States",Tsinghua University;University of California Santa Cruz,2,China;USA,2,19,19,"The responsiveness of the network is critical when the application is immersive video streaming or 360 degree video streaming. The users look at the video stream on a display that can only show a fraction of the full video stream, and the time that the information spend in transit dramatically impacts the QoE of the end user. Further, transmitting a 360 degree video stream significantly increases the bandwidth usage and the impact on the already strained network. We propose a mechanism to use the responsiveness of the network to perform a Field of View (FoV) adaptation, so as to reduce the bandwidth consumption while at the same time enhancing the QoE of the user. In our simulation, such mechanism significantly improves the resolution seen by the end user, by selecting a higher bit rate. This translates to an improvement of up to 1.34 x better resolution when compared with the full spherical 360 degree video stream. Further, when rate adaption is used, it ensures the QoE of end users evolves according to the changes in the network conditions. This means that our proposed rate and FoV adaptation based upon the network responsiveness achieves both the apprently contradictory goals of increasing the end-user QoE and reducing the overall bandwidth consumption at the network layer. © 2018 Association for Computing Machinery.",360 degree video streaming; AR/VR; Field of view; Rate adaptation,Augmented reality; Bandwidth; Network layers; Virtual reality; Bandwidth consumption; Bandwidth usage; Contradictory goals; Field of views; Immersive; Network condition; Rate adaptation; Rate adaptions; Video streaming
"Mestres A., Alarc—n E., Ji Y., Cabellos-Aparicio A.",4,Understanding the modeling of computer network delays using neural networks,2018,0,"Universitat Politcnica de Catalunya, Spain; NII, Japan",Universitat Politcnica de Catalunya,1,Japan;Spain,2,17,11,"Recent trends in networking are proposing the use of Machine Learning (ML) techniques for the control and operation of the network. In this context, ML can be used as a computer network modeling technique to build models that estimate the network performance. Indeed, network modeling is a central technique to many networking functions, for instance in the field of optimization, in which the model is used to search a configuration that satisfies the target policy. In this paper, we aim to provide an answer to the following question: Can neural networks accurately model the delay of a computer network as a function of the input traffic? For this, we assume the network as a black-box that has as input a traffic matrix and as output delays. Then we train different neural networks models and evaluate its accuracy under different fundamental network characteristics: topology, size, traffic intensity and routing. With this, we aim to have a better understanding of computer network modeling with neural nets and ultimately provide practical guidelines on how such models need to be trained. © 2018 Copyright held by the owner/author(s).",KDN; ML; Modeling; Networking; SDN,Artificial intelligence; Big data; Computer networks; Convolutional codes; Learning systems; Models; Network characteristics; Network modeling; Networking; Neural networks model; Practical guidelines; Recent trends; Traffic intensity; Traffic matrices; Data communication systems
"Geyer F., Carle G.",2,Learning and generating distributed routing protocols using graph-based deep learning,2018,1,"Technical University of Munich, Garching b. MŸnchen, Germany",TU Munich,1,Germany,1,28,20,"Automated network control and management has been a long standing target of network protocols. We address in this paper the question of automated protocol design, where distributed networked nodes have to cooperate to achieve a common goal without a priori knowledge on which information to exchange or the network topology. While reinforcement learning has often been proposed for this task, we propose here to apply recent methods from semi-supervised deep neural networks which are focused on graphs. Our main contribution is an approach for applying graph-based deep learning on distributed routing protocols via a novel neural network architecture named Graph-Query Neural Network. We apply our approach to the tasks of shortest path and max-min routing. We evaluate the learned protocols in cold-start and also in case of topology changes. Numerical results show that our approach is able to automatically develop efficient routing protocols for those two use-cases with accuracies larger than 95 %. We also show that specific properties of network protocols, such as resilience to packet loss, can be explicitly included in the learned protocol. © 2018 Copyright held by the owner/author(s).",Deep learning; Graph neural network; Routing,Big data; Convolutional codes; Data communication systems; Deep learning; Deep neural networks; Graphic methods; Knowledge management; Network architecture; Network protocols; Network routing; Neural networks; Reinforcement learning; Routing protocols; Topology; Distributed routing protocols; Efficient routing; Graph neural networks; Network topology; Novel neural network; Numerical results; Routing; Specific properties; Internet protocols
"Li M., Lumezanu C., Zong B., Chen H.",4,Deep learning IP network representations,2018,0,"University of California, Los Angeles, CA, United States; NEC Laboratories America, Princeton, NJ, United States",NEC;University of California Los Angeles,2,USA,1,24,13,"We present DIP, a deep learning based framework to learn structural properties of the Internet, such as node clustering or distance between nodes. Existing embedding-based approaches use linear algorithms on a single source of data, such as latency or hop count information, to approximate the position of a node in the Internet. In contrast, DIP computes low-dimensional representations of nodes that preserve structural properties and non-linear relationships across multiple, heterogeneous sources of structural information, such as IP, routing, and distance information. Using a large real-world data set, we show that DIP learns representations that preserve the real-world clustering of the associated nodes and predicts distance between them more than 30% better than a mean-based approach. Furthermore, DIP accurately imputes hop count distance to unknown hosts (i.e., not used in training) given only their IP addresses and routable prefixes. Our framework is extensible to new data sources and applicable to a wide range of problems in network monitoring and security. © 2018 Association for Computing Machinery.",Deep learning; Embedding; Network; Neural networks; Structure,Artificial intelligence; Big data; Convolutional codes; Data communication systems; Deep learning; Networks (circuits); Neural networks; Structural properties; Structure (composition); Distance information; Embedding; Heterogeneous sources; Linear algorithms; Low-dimensional representation; Node clustering; Non-linear relationships; Structural information; Internet protocols
"Otomo K., Kobayashi S., Fukuda K., Esaki H.",4,Finding anomalies in network system logs with latent variables,2018,0,"University of Tokyo, Japan; NII, Japan; Sokendai, Japan",University of Tokyo,1,Japan,1,18,15,"System logs are useful to understand the status of and detect faults in large scale networks. However, due to their diversity and volume of these logs, log analysis requires much time and effort. In this paper, we propose a log event anomaly detection method for large-scale networks without pre-processing and feature extraction. The key idea is to embed a large amount of diverse data into hidden states by using latent variables. We evaluate our method with 15 months of system logs obtained from a nation-wide academic network in Japan. Through comparisons with Kleinberg's univariate burst detection and a traditional multivariate analysis (i.e., PCA), we demonstrate that our proposed method detects anomalies and ease troubleshooting of network system faults. © 2018 Association for Computing Machinery.",Latent variable analysis; Network log analysis; Variational autoen-coder,Artificial intelligence; Big data; Convolutional codes; Equivalence classes; Fault detection; Fault tolerant computer systems; Feature extraction; Learning systems; Multivariant analysis; Anomaly detection methods; Burst detection; Large-scale network; Latent variable; Log analysis; Multi variate analysis; Network systems; Variational autoen-coder; Data communication systems
"Hou X., Dey S., Zhang J., Budagavi M.",4,Predictive view generation to enable mobile 360-degree and VR experiences,2018,0,"University of California, San Diego, United States",University of California San Diego,1,USA,1,42,35,"As 360-degree videos and virtual reality (VR) applications become popular for consumer and enterprise use cases, the desire to enable truly mobile experiences also increases. Delivering 360-degree videos and cloud/edge-based VR applications require ultra-high bandwidth and ultra-low latency [22], challenging to achieve with mobile networks. A common approach to reduce bandwidth is streaming only the field of view (FOV). However, extracting and transmitting the FOV in response to user head motion can add high latency, adversely affecting user experience. In this paper, we propose a predictive view generation approach, where only the predicted view is extracted (for 360-degree video) or rendered (in case of VR) and transmitted in advance, leading to a simultaneous reduction in bandwidth and latency. The view generation method is based on a deep-learning-based viewpoint prediction model we develop, which uses past head motions to predict where a user will be looking in the 360-degree view. Using a very large dataset consisting of head motion traces from over 36,000 viewers for nineteen 360-degree/VR videos, we validate the ability of our viewpoint prediction model and predictive view generation method to offer very high accuracy while simultaneously significantly reducing bandwidth. © 2018 ACM.",360-degree video; Video streaming; Virtual reality,Augmented reality; Bandwidth; Deep learning; Forecasting; Video streaming; 360-degree video; Field of views; Prediction model; Simultaneous reduction; Ultra-high bandwidth; User experience; View generation; VR applications; Virtual reality
"Mulinka P., Casas P.",2,Stream-based machine learning for network security and anomaly detection,2018,0,"CTU Czech Technical University, Prague, Czech Republic; AIT Austrian Institute of Technology, Austria",AIT Austrian Institute of Technology;Czech Technical University,2,Austria;Czech Republic,2,27,20,"Data Stream Machine Learning is rapidly gaining popularity within the network monitoring community as the big data produced by network devices and end-user terminals goes beyond the memory constraints of standard monitoring equipment. Critical network monitoring applications such as the detection of anomalies, network attacks and intrusions, require fast and continuous mechanisms for on-line analysis of data streams. In this paper we consider a stream-based machine learning approach for network security and anomaly detection, applying and evaluating multiple machine learning algorithms in the analysis of continuously evolving network data streams. The continuous evolution of the data stream analysis algorithms coming from the data stream mining domain, as well as the multiple evaluation approaches conceived for benchmarking such kind of algorithms makes it difficult to choose the appropriate machine learning model. Results of the different approaches may significantly differ and it is crucial to determine which approach reflects the algorithm performance the best. We therefore compare and analyze the results from the most recent evaluation approaches for sequential data on commonly used batch-based machine learning algorithms and their corresponding stream-based extensions, for the specific problem of on-line network security and anomaly detection. Similar to our previous findings when dealing with off-line machine learning approaches for network security and anomaly detection, our results suggest that adaptive random forests and stochastic gradient descent models are able to keep up with important concept drifts in the underlying network data streams, by keeping high accuracy with continuous re-training at concept drift detection times. © 2018 Association for Computing Machinery.",Data stream mining; High-dimensional data; Machine learning; Network attacks,Artificial intelligence; Big data; Clustering algorithms; Computer crime; Convolutional codes; Data communication systems; Data mining; Decision trees; Evolutionary algorithms; Learning algorithms; Learning systems; Petroleum reservoir evaluation; Stochastic models; Stochastic systems; Algorithm performance; Data stream mining; High dimensional data; Machine learning approaches; Machine learning models; Monitoring equipment; Network attack; Stochastic gradient descent; Network security
"Schiff L., Ziv O., Jaeger M., Schmid S.",4,NetSlicer: Automated and traffic-pattern based application clustering in datacenters,2018,0,"GuardiCore Labs, Israel; Aalborg University, Denmark; University of Vienna, Austria",Aalborg University;University of Vienna,2,Austria;Denmark;Israel,3,15,11,"Companies often have very limited information about the appli tions running in their datacenter or public/private cloud enviro ments. As this can harm efficiency, performance, and security, ma network administrators work hard to manually assign actiona description to (virtual) machines. This paper presents and evaluates NetSlicer, a machine-learni approach that enables an automated grouping of nodes into app cations and their tiers. Our solution is based solely on the availa network layer data which is used as part of a novel graph clusteri algorithm, tailored toward the datacenter use case and accounti also for observed port numbers. For the sake of this paper, we al performed an extensive empirical measurement study, collecti actual workloads from different production datacenters (data be released together with this paper). We find that our approa features a high accuracy. © 2018 Copyright held by the owner/author(s).",Big data; Computer networks; Machine learning,Artificial intelligence; Computer networks; Convolutional codes; Data communication systems; Learning systems; Network layers; Data centers; Empirical measurement; High-accuracy; Limited information; Machine learni; Network administrator; Port numbers; Traffic pattern; Big data
"Ma H., Jiang X., Ma R., Ma Z., Cai Y., Chiu D.M.",6,Smart streaming of panoramic videos,2018,0,"Chinese University of Hong Kong, Hong Kong; Kandao Technology, Hong Kong",Chinese University of Hong Kong,1,Hong Kong,1,18,17,"The streaming of panoramic videos comes with a new challenge: adapting the streamed content to user attention. In this paper, by making some abstraction we study the key issues of the problem: (1) online content switching strategies, and (2) offline segmentation in preparation for adaptive streaming. Our work demonstrates how the problem depends fundamentally on user behavior, represented by user attention trajectories. Although we only relied on a typical real-world measured trajectory and two artificially generated benchmark trajectories, we point out how more knowledge of user attention can help optimize both the online and offline strategies. © 2018 Copyright held by the owner/author(s).",Bandwidth adaptation; Video streaming; Virtual reality,Augmented reality; Trajectories; Video streaming; Virtual reality; Adaptive streaming; Bandwidth adaptation; On-line contents; Panoramic video; Real-world; Switching strategies; User attention; User behaviors; Behavioral research
"Ahn S., Gorlatova M., Naghizadeh P., Chiang M., Mittal P.",5,Adaptive fog-based output security for augmented reality,2018,0,"Department of Electrical Engineering, Princeton University, Princeton, NJ, United States; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States",Princeton University;Purdue University,2,USA,1,20,20,"Augmented reality (AR) technologies are rapidly being adopted across multiple sectors, but little work has been done to ensure the security of such systems against potentially harmful or distracting visual output produced by malicious or bug-ridden applications. Past research has proposed to incorporate manually specified policies into AR devices to constrain their visual output. However, these policies can be cumbersome to specify and implement, and may not generalize well to complex and unpredictable environmental conditions. We propose a method for generating adaptive policies to secure visual output in AR systems using deep reinforcement learning. This approach utilizes a local fog computing node, which runs training simulations to automatically learn an appropriate policy for filtering potentially malicious or distracting content produced by an application. Through empirical evaluations, we show that these policies are able to intelligently displace AR content to reduce obstruction of real-world objects, while maintaining a favorable user experience. © 2018 Copyright held by the owner/author(s).",Augmented reality; Edge computing; Fog computing; Policy optimization; Reinforcement learning; Visual output security,Augmented reality; Deep learning; Edge computing; Fog; Reinforcement learning; Virtual reality; Adaptive policy; Empirical evaluations; Environmental conditions; Policy optimization; Real-world objects; Training simulation; User experience; Visual outputs; Fog computing
"Soh L., Burke J., Zhang L.",3,Supporting augmented reality: Looking beyond performance,2018,0,"University of California, Los Angeles, United States",University of California Los Angeles,1,USA,1,26,23,"Recent years have witnessed a surge in augmented reality (AR) applications in various markets and verticals, together with emerging toolkits and platforms to support new developments. However, the vision of a pervasive augmented reality held by many still seems a distance away. Notwithstanding the many ongoing efforts to tackle AR performance challenges, we argue that much attention is needed to other research areas including network architecture, security, privacy, and the development of business cases. Similar to the Web, existing AR applications are built upon TCP/IP protocol stack and rely on cloud computation. To enable pervasive AR applications, we believe that new computing paradigms, new approaches to network communications, and new business models need to be explored. Edge computing paradigms, which utilize performance advantage of server class hardware within physical vicinity, could achieve the required low latency while protecting user privacy. We further argue that Named Data Networking (NDN), a proposed new internet architecture, can be an enabler for pervasive AR by supporting local resource discovery, offering built-in communication security, and enabling experimentation with new business models. We hope that this position paper spurs greater thinking beyond performance improvements to push AR forward. © 2018 Copyright held by the owner/author(s).",Information centric networking; Named data networking; Pervasive augmented reality,Augmented reality; Virtual reality; Computing paradigm; Information-centric networkings; Internet architecture; Named data networkings; Network communications; New business models; Performance challenges; Performance improvements; Network architecture
"Goodchild B.J., Chiu Y.-C., Hansen O., Lu H., Calder M., Luckie M., Lloyd W., Choffnes D., Katz-Bassett E.",9,The record route option is an option!,2017,1,"USC, United States; Rutgers, Camden, Australia; Columbia, United States; Northeastern, United States; Microsoft, United States; University of Waikato, New Zealand",Microsoft;University of Waikato,2,Australia;New Zealand;USA,3,23,15,"The IPv4 Record Route (RR) Option instructs routers to record their IP addresses in a packet. RR is subject to a nine hop limit and, traditionally, inconsistent support from routers. Recent changes in interdomain connectivity-the so-called ""flattening Internet""- and new best practices for how routers should handle RR packets suggest that now is a good time to reassess the potential of the RR Option. We quantify the current utility of RR by issuing RR measurements from PlanetLab and M-Lab to every advertised BGP prefix. We find that 75% of addresses that respond to ping without RR also respond to ping with RR, and 66% of these RR-responsive addresses are within the nine hop limit of at least one vantage point. These numbers suggest the RR Option is a useful measurement primitive on today's Internet. © 2017 Copyright held by the owner/author(s).",IP options; Record Route; Routing; Topology; Traceroute,Measurements; Topology; Best practices; Inter-domain; IP addresss; IP option; PlanetLab; Record Route; Routing; Traceroute; Internet protocols
"De Vries W.B., Heidemann J., De Schmidt O.R., De Boer P.-T., Hardaker W., Pras A.",6,Broad and load-aware anycast mapping with Verfploeter,2017,2,"University of Twente, Netherlands; USC, ISI, United States",University of Twente,1,Netherlands;USA,2,50,39,"IP anycast provides DNS operators and CDNs with automatic failover and reduced latency by breaking the Internet into catchments, each served by a different anycast site. Unfortunately understanding and predicting changes to catchments as anycast sites are added or removed has been challenging. Current tools such as RIPE Atlas or commercial equivalents map from thousands of vantage points (VPs), but their coverage can be inconsistent around the globe. This paper proposes Verfploeter, a new method that maps anycast catchments using active probing. Verfploeter provides around 3.8M passive VPs, 430_ the 9k physical VPs in RIPE Atlas, providing coverage of the vast majority of networks around the globe. We then add load information from prior service logs to provide calibrated predictions of anycast changes. Verfploeter has been used to evaluate the new anycast deployment for B-Root, and we also report its use of a nine-site anycast testbed. We show that the greater coverage made possible by Verfploeter's active probing is necessary to see routing differences in regions that have sparse coverage from RIPE Atlas, like South America and China. © 2017 Association for Computing Machinery.",Catchments; DNS; Internet mapping; IP anycast; Service provisioning,Catchments; Mapping; Maps; Runoff; Active probing; Anycast; Calibrated prediction; Internet mapping; Load information; Reduced latencies; Service provisioning; South America; Internet protocols
"Chung T., Levin D., Van Rijswijk-Deij R., Maggs B.M., Wilson C., Choffnes D., Mislove A.",7,Understanding the role of registrars in DNSSEC deployment,2017,1,"Northeastern University, United States; University of Maryland, United States; University of Twente, SURFnet, Netherlands; Duke University and Akamai Technologies, United States",Duke University;Northeastern University;University of Maryland College Park;University of Twente,4,Netherlands;USA,2,51,26,"The Domain Name System (DNS) provides a scalable, flexible name resolution service. Unfortunately, its unauthenticated architecture has become the basis for many security attacks. To address this, DNS Security Extensions (DNSSEC) were introduced in 1997. DNSSEC's deployment requires support from the top-level domain (TLD) registries and registrars, as well as participation by the organization that serves as the DNS operator. Unfortunately, DNSSEC has seen poor deployment thus far: despite being proposed nearly two decades ago, only 1% of.com,.net, and.org domains are properly signed. In this paper, we investigate the underlying reasons why DNSSEC adoption has been remarkably slow. We focus on registrars, as most TLD registries already support DNSSEC and registrars often serve as DNS operators for their customers. Our study uses large-scale, longitudinal DNS measurements to study DNSSEC adoption, coupled with experiences collected by trying to deploy DNSSEC on domains we purchased from leading domain name registrars and resellers. Overall, we find that a select few registrars are responsible for the (small) DNSSEC deployment today, and that many leading registrars do not support DNSSEC at all, or require customers to take cumbersome steps to deploy DNSSEC. Further frustrating deployment, many of the mechanisms for conveying DNSSEC information to registrars are error-prone or present security vulnerabilities. Finally, we find that using DNSSEC with third-party DNS operators such as Cloudfare requires the domain owner to take a number of steps that 40% of domain owners do not complete. Having identified several operational challenges for full DNSSEC deployment, we make recommendations to improve adoption. © 2017 Copyright held by the owner/author(s).",DNS; DNS operator; DNS Security Extension; DNSSEC; Pki; Public key infrastructure; Registrar,Internet protocols; Public key cryptography; Sales; Servers; DNS operator; DNS securities; DNSSEC; Public key infrastructure; Registrar; Intrusion detection
"Sundaresan S., Dhamdhere A., Allman M., Claffy K.",4,TCP congestion signatures,2017,5,"Princeton University, United States; CAIDA, UCSD, United States; ICSI, United States",Princeton University,1,USA,1,52,24,"We develop and validate Internet path measurement techniques to distinguish congestion experienced when a flow self-induces congestion in the path from when a flow is affected by an already congested path. One application of this technique is for speed tests, when the user is affected by congestion either in the last mile or in an interconnect link. This difference is important because in the latter case, the user is constrained by their service plan (i.e., what they are paying for), and in the former case, they are constrained by forces outside of their control. We exploit TCP congestion control dynamics to distinguish these cases for Internet paths that are predominantly TCP traffic. In TCP terms, we re-articulate the question: was a TCP flow bottlenecked by an already congested (possibly interconnect) link, or did it induce congestion in an otherwise idle (possibly a last-mile) link? TCP congestion control affects the round-trip time (RTT) of packets within the flow (i.e., the flow RTT): an endpoint sends packets at higher throughput, increasing the occupancy of the bottleneck buffer, thereby increasing the RTT of packets in the flow. We show that two simple, statistical metrics derived from the flow RTT during the slow start period-its coefficient of variation, and the normalized difference between the maximum and minimum RTT-can robustly identify which type of congestion the flow encounters. We use extensive controlled experiments to demonstrate that our technique works with up to 90% accuracy. We also evaluate our techniques using two unique real-world datasets of TCP throughput measurements using Measurement Lab data and the Ark platform. We find up to 99% accuracy in detecting self-induced congestion, and up to 85% accuracy in detecting external congestion. Our results can benefit regulators of interconnection markets, content providers trying to improve customer service, and users trying to understand whether poor performance is something they can fix by upgrading their service tier. © 2017 Association for Computing Machinery.",Internet congestion; TCP; Throughput,Throughput; Transmission control protocol; Coefficient of variation; Content providers; Controlled experiment; Customer services; Internet congestion; Normalized differences; Real-world datasets; TCP congestion control; Traffic congestion
"Sommers J., Durairajan R., Barford P.",3,Automatic metadata generation for active measurement,2017,1,"Colgate University, United States; University of Oregon, United States; University of Wisconsin-Madison, ComScore Inc., United States",Colgate University;ComScore Inc.;University of Oregon;;University of Wisconsin-Madison,5,USA,1,30,23,"Empirical research in the Internet is fraught with challenges. Among these is the possibility that local environmental conditions (e.g., CPU load or network load) introduce unexpected bias or artifacts in measurements that lead to erroneous conclusions. In this paper, we describe a framework for local environment monitoring that is designed to be used during Internet measurement experiments. The goals of our work are to provide a critical, expanded perspective on measurement results and to improve the opportunity for reproducibility of results. We instantiate our framework in a tool we call SoMeta, which monitors the local environment during active probe-based measurement experiments. We evaluate the runtime costs of SoMeta and conduct a series of experiments in which we intentionally perturb different aspects of the local environment during active probe-based measurements. Our experiments show how simple local monitoring can readily expose conditions that bias active probe-based measurement results. We conclude with a discussion of how our framework can be expanded to provide metadata for a broad range of Internet measurement experiments. © 2017 Association for Computing Machinery.",Metadata; Network measurement,Probes; Active measurement; Empirical research; Environmental conditions; Internet measurement; Local environments; Measurement experiments; Metadata generation; Network measurement; Metadata
"Kline J., Cahn A., Barford P., Sommers J.",4,On the structure and characteristics of user agent string,2017,1,"University of Wisconsin-Madison, ComScore, Inc., United States; Colgate University, United States",Colgate University;ComScore Inc.;;University of Wisconsin-Madison,4,USA,1,27,19,"User agent (UA) strings transmitted during HTTP transactions convey client system configuration details to ensure that content returned by a server is appropriate for the requesting host. As such, analysis of UA strings and their structure offers a unique perspective on active client systems in the Internet and when tracked longitudinally, offers a perspective on the nature of system and configuration dynamics. In this paper, we describe our study of UA string characteristics. Our work is based on analyzing a unique corpus of over 1B UA strings collected over a period of 2 years by comScore. We begin by analyzing the general characteristics of UA strings, focusing on the most prevalent strings and dynamic behaviors. We identify the top 10 most popular User Agents, which account for 26% of total daily volume. These strings describe the expected instances of popular platforms such as Microsoft, Apple and Google. We then report on the characteristics of low-volume UA strings, which has important implications for unique device identification. We show that this class of user agent generates the overwhelming majority of traffic, with between 2M and 10M instances observed each day. We show that the distribution of UA strings has temporal dependence and we show the distribution measured depends on the type of content served. Finally, we report on two large-scale UA anomalies characterized by web browsers sending false and misleading UAs in their web requests. © 2017 Association for Computing Machinery.",Character entropy matrix; Internet measurement; User agent strings,HTTP; Mobile telecommunication systems; Dynamic behaviors; HTTP transaction; Internet measurement; Popular platform; System configurations; Temporal dependence; User agents; Web requests; Web browsers
"Giotsas V., Smaragdakis G., Dietzel C., Richter P., Feldmann A., Berger A.",6,Inferring BGP blackholing activity in the internet,2017,3,"CAIDA, TU Berlin, Germany; MIT, TU Berlin, Germany; TU Berlin, DE-CIX, Germany; MIT, Akamai, United States",MIT;TU Berlin,2,Germany;USA,2,71,66,"The Border Gateway Protocol (BGP) has been used for decades as the de facto protocol to exchange reachability information among networks in the Internet. However, little is known about how this protocol is used to restrict reachability to selected destinations, e.g., that are under attack. While such a feature, BGP blackholing, has been available for some time, we lack a systematic study of its Internet-wide adoption, practices, and network efficacy, as well as the profile of blackholed destinations. In this paper, we develop and evaluate a methodology to automatically detect BGP blackholing activity in the wild. We apply our method to both public and private BGP datasets. We find that hundreds of networks, including large transit providers, as well as about 50 Internet exchange points (IXPs) offer blackholing service to their customers, peers, and members. Between 2014-2017, the number of blackholed prefixes increased by a factor of 6, peaking at 5K concurrently blackholed prefixes by up to 400 Autonomous Systems. We assess the effect of blackholing on the data plane using both targeted active measurements as well as passive datasets, finding that blackholing is indeed highly effective in dropping traffic before it reaches its destination, though it also discards legitimate traffic. We augment our findings with an analysis of the target IP addresses of blackholing. Our tools and insights are relevant for operators considering offering or using BGP blackholing services as well as for researchers studying DDoS mitigation in the Internet. © 2017 Copyright held by the owner/author(s).",BGP; Blackholing; DDoS mitigation,Internet; Active measurement; Autonomous systems; Blackholing; Border gateway protocol; Ddos mitigations; Internet exchange points; Reachability; Systematic study; Gateways (computer networks)
"Xu S., Morley Mao Z., Sen S., Jia Y.",4,"Dissecting VOD services for cellular: Performance, root causes and best practices",2017,1,"University of Michigan, United States; ATandT Labs - Research, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,54,49,"HTTP Adaptive Streaming (HAS) has emerged as the predominant technique for transmitting video over cellular for most content providers today. While mobile video streaming is extremely popular, delivering good streaming experience over cellular networks is technically very challenging, and involves complex interacting factors. We conduct a detailed measurement study of a wide crosssection of popular streaming video-on-demand (VOD) services to develop a holistic understanding of these services' design and performance. We identify performance issues and develop effective practical best practice solutions to mitigate these challenges. By extending the understanding of how different, potentially interacting components of service design impact performance, our findings can help developers build streaming services with better performance. © 2017 Association for Computing Machinery.",Adaptive Streaming; Cellular; Video streaming; VOD,HTTP; Video streaming; Adaptive streaming; Cellular; Content providers; Measurement study; Mobile video streaming; Performance issues; Streaming service; Streaming videos; Video on demand
"Fanou R., Valera F., Dhamdhere A.",3,Investigating the causes of congestion on the African IXP substrate,2017,3,"IMDEA Networks Institute, Universidad Carlos III de Madrid, Spain; Universidad Carlos III de Madrid, Spain; CAIDA, UC San Diego, United States",IMDEA Networks;Universidad Carlos III de Madrid;University of California San Diego,3,Spain;USA,2,42,41,"The goal of this work is to investigate the prevalence, causes, and impact of congestion on the African IXP substrate. Towards this end, we deployed Ark probes (within networks peering) at six African IXPs and ran the time-sequence latency probes (TSLP) algorithm, thereby collecting latency measurements to both ends of each mapped AS link for a whole year. We were able to detect congestion events and quantify their periods and magnitudes at four IXPs. We then verified the events and investigated the causes by interviewing the IXP operators. Our results show that only 2.2% of the discovered IP links experienced (sustained or transient) congestion during our measurement period. Our findings suggest the need for ISPs to carefully monitor the provision of their peering links, so as to avoid or quickly mitigate the occurrence of congestion. Regulators may also define the maximum level of packet loss in those links to provide some protection to communications routed through local IXPs. © 2017 Association for Computing Machinery.",Congestion; IXP; Performance,Measurements; AS-links; Congestion; Congestion events; Latency measurements; Maximum levels; Performance; Time sequences; Probes
"Jonker M., King A., Krupp J., Rossow C., Sperotto A., Dainotti A.",6,Millions of targets under atack: A macroscopic characterization of the DoS ecosystem,2017,7,"University of Twente, Netherlands; CAIDA, UC San Diego, United States; CISPA, Saarland University, Germany",Saarland University;University of California San Diego;University of Twente,3,Germany;Netherlands;USA,3,40,37,"Denial-of-Service attacks have rapidly increased in terms of frequency and intensity, steadily becoming one of the biggest threats to Internet stability and reliability. However, a rigorous comprehensive characterization of this phenomenon, and of countermeasures to mitigate the associated risks, faces many infrastructure and analytic challenges. We make progress toward this goal, by introducing and applying a new framework to enable a macroscopic characterization of attacks, attack targets, and DDoS Protection Services (DPSs). Our analysis leverages data from four independent global Internet measurement infrastructures over the last two years: backscatter traffic to a large network telescope; logs from amplification honeypots; a DNS measurement platform covering 60% of the current namespace; and a DNS-based data set focusing on DPS adoption. Our results reveal the massive scale of the DoS problem, including an eye-opening statistic that one-third of all/24 networks recently estimated to be active on the Internet have suffered at least one DoS attack over the last two years. We also discovered that often targets are simultaneously hit by different types of attacks. In our data, Web servers were the most prominent attack target; an average of 3% of the Web sites in.com,.net, and.org were involved with attacks, daily. Finally, we shed light on factors influencing migration to a DPS. © 2017 Association for Computing Machinery.",Cloud-based mitigation; DDoS; Reflection attacks; Spoofed attacks,Characterization; Computer crime; Internet protocols; Cloud-based; DDoS; Global Internet; Internet stability; Large networks; Macroscopic characterization; Reflection attacks; Spoofed attacks; Denial-of-service attack
"Levchenko K., Dhamdhere A., Huffaker B., Claffy K., Allman M., Paxson V.",6,PacketLab: A universal measurement endpoint interface,2017,3,"UC San Diego, United States; CAIDA, United States; ICSI, United States; UC Berkeley, ICSI, United States",University of California Berkeley;University of California San Diego,2,USA,1,33,16,"The right vantage point is critical to the success of any active measurement. However, most research groups cannot afford to design, deploy, and maintain their own network of measurement endpoints, and thus rely measurement infrastructure shared by others. Unfortunately, the mechanism by which we share access to measurement endpoints today is not frictionless; indeed, issues of compatibility, trust, and a lack of incentives get in the way of efficiently sharing measurement infrastructure. We propose PacketLab, a universal measurement endpoint interface that lowers the barriers faced by experimenters and measurement endpoint operators. PacketLab is built on two key ideas: It moves the measurement logic out of the endpoint to a separate experiment control server, making each endpoint a lightweight packet source/sink. At the same time, it provides a way to delegate access to measurement endpoints while retaining fine-grained control over how one's endpoints are used by others, allowing research groups to share measurement infrastructure with each other with little overhead. By making the endpoint interface simple, we also make it easier to deploy measurement endpoints on any device anywhere, for any period of time the owner chooses. We offer PacketLab as a candidate measurement interface that can accommodate the research community's demand for future global-scale Internet measurement. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",Network measurement; PacketLab,Active measurement; Fine-grained control; Global scale; Internet measurement; Network measurement; PacketLab; Research communities; Research groups; Measurements
"Li F., Razaghpanah A., Kakhki A.M., Niaki A.A., Choffnes D., Gill P., Mislove A.",7,"Libáerate, (n): A library for exposing (traffic-classification) rules and avoiding them efficiently",2017,3,"Northeastern University, United States; Stony Brook University, United States; University of Massachusetts, Amherst, United States",Northeastern University;Stony Brook University;University of Massachusetts Amherst,3,USA,1,52,44,"Middleboxes implement a variety of network management policies (e.g., prioritizing or blocking traffic) in their networks. While such policies can be beneficial (e.g., blocking malware) they also raise issues of network neutrality and freedom of speech when used for application-specific differentiation and censorship. There is a poor understanding of how such policies are implemented in practice, and how they can be evaded efficiently. As a result, most circumvention solutions are brittle, point solutions based on manual analysis. This paper presents the design and implementation of libáerate, a tool for automatically identifying middlebox policies, reverseengineering their implementations, and adaptively deploying custom circumvention techniques. Unlike previous work, our approach is application-agnostic, can be deployed unilaterally (i.e., only at one endpoint) on unmodified applications via a linked library or transparent proxy, and can adapt to changes to classifiers at runtime. We implemented a libáerate prototype as a transparent proxy and evaluate it both in a testbed environment and in operational networks that throttle or block traffic based on DPI-based classifier rules, and show that our approach is effective across a wide range of middlebox deployments. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",Network neutrality; Traffic differentiation,Measurements; Application specific; Design and implementations; Freedom of speech; Management policy; Manual analysis; Network neutralities; Operational network; Traffic classification; Telecommunication traffic
"Thomas D.R., Pastrana S., Hutchings A., Clayton R., Beresford A.R.",5,Ethical issues in research using datasets of illicit origin,2017,0,"Cambridge Cybercrime Centre, Computer Laboratory, University of Cambridge, United Kingdom",University of Cambridge,1,UK,1,125,120,"We evaluate the use of data obtained by illicit means against a broad set of ethical and legal issues. Our analysis covers both the direct collection, and secondary uses of, data obtained via illicit means such as exploiting a vulnerability, or unauthorized disclosure. We extract ethical principles from existing advice and guidance and analyse how they have been applied within more than 20 recent peer reviewed papers that deal with illicitly obtained datasets. We find that existing advice and guidance does not address all of the problems that researchers have faced and explain how the papers tackle ethical issues inconsistently, and sometimes not at all. Our analysis reveals not only a lack of application of safeguards but also that legitimate ethical justifications for research are being overlooked. In many cases positive benefits, as well as potential harms, remain entirely unidentified. Few papers record explicit Research Ethics Board (REB) approval for the activity that is described and the justifications given for exemption suggest deficiencies in the REB process. © 2017 Copyright held by the owner/author(s).",Cybercrime; Data of illicit origin; Ethics; Found data; Law; Leaked data; Menlo report; Unintentionally public data,Measurements; Cybercrime; Data of illicit origin; Ethics; Found data; Leaked data; Menlo report; Public data; Philosophical aspects
"Zhang Q., Liu V., Zeng H., Krishnamurthy A.",4,High-resolution measurement of data center microbursts,2017,10,"University of Washington, United States; University of Pennsylvania, United States; Facebook, Inc., United States",Facebook;University of Pennsylvania;University of Washington at Seattle,3,USA,1,20,17,"Data centers house some of the largest, fastest networks in the world. In contrast to and as a result of their speed, these networks operate on very small timescales-a 100 Gbps port processes a single packet in at most 500ns with end-to-end network latencies of under a millisecond. In this study, we explore the fine-grained behaviors of a large production data center using extremely highresolution measurements (10s to 100s of microsecond) of rack-level traffic. Our results show that characterizing network events like congestion and synchronized behavior in data centers does indeed require the use of such measurements. In fact, we observe that more than 70% of bursts on the racks we measured are sustained for at most tens of microseconds: a range that is orders of magnitude higher-resolution than most deployed measurement frameworks. Congestion events observed by less granular measurements are likely collections of smaller _bursts. Thus, we find that traffic at the edge is significantly less balanced than other metrics might suggest. Beyond the implications for measurement granularity, we hope these results will inform future data center load balancing and congestion control protocols. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",Data center traffic; Microbursts,Congestion control protocols; Congestion events; Data centers; End-to-end network; Granular measurements; High-resolution measurements; Microbursts; Orders of magnitude; Measurements
"Snyder P., Kanich C., Doerfler P., McCoy D.",4,Fifteen minutes of unwanted fame: Detecting and characterizing doxing,2017,3,"University of Illinois at Chicago, Chicago, IL, United States; New York University, Brooklyn, NY, United States","NYU;University of Illinois, Chicago",2,USA,1,47,46,"Doxing is online abuse where a malicious party harms another by releasing identifying or sensitive information. Motivations for doxing include personal, competitive, and political reasons, and web users of all ages, genders and internet experience have been targeted. Existing research on doxing is primarily qualitative. This work improves our understanding of doxing by being the first to take a quantitative approach. We do so by designing and deploying a tool which can detect dox files and measure the frequency, content, targets, and effects of doxing on popular dox-posting sites. This work analyzes over 1.7 million text files posted to pastebin.com, 4chan.org and 8ch.net, sites frequently used to share doxes online, over a combined period of approximately thirteen weeks. Notable findings in this work include that approximately 0.3% of shared files are doxes, that online social networking accounts mentioned in these dox files are more likely to close than typical accounts, that justice and revenge are the most often cited motivations for doxing, and that dox files target males more frequently than females. We also find that recent anti-abuse efforts by social networks have reduced how frequently these doxing victims closed or restricted their accounts after being attacked. We also propose mitigation steps, such a service that can inform people when their accounts have been shared in a dox file, or law enforcement notification tools to inform authorities when individuals are at heightened risk of abuse. © 2017 Copyright held by the owner/author(s).",Doxing; Identity theft; Online abuse,Motivation; Doxing; Identity theft; Online abuse; Online social networkings; Quantitative approach; Sensitive informations; Text file; Web users; Social networking (online)
"Zannettou S., Caulfield T., De Cristofaro E., Kourtellis N., Leontiadis I., Sirivianos M., Stringhini G., Blackburn J.",8,The web centipede: Understanding how web communities influence each other through the lens of mainstream and alternative news sources,2017,3,"Cyprus University of Technology, Cyprus; University College London, United Kingdom; Telefonica Research, United States; University of Alabama, Birmingham, United States",Cyprus University of Technology;Telefonica Research;University College London;University of Alabama,4,Cyprus;UK;USA,3,35,30,"As the number and the diversity of news outlets on the Web grows, so does the opportunity for ""alternative"" sources of information to emerge. Using large social networks like Twitter and Facebook, misleading, false, or agenda-driven information can quickly and seamlessly spread online, deceiving people or influencing their opinions. Also, the increased engagement of tightly knit communities, such as Reddit and 4chan, further compounds the problem, as their users initiate and propagate alternative information, not only within their own communities, but also to different ones as well as various social media. In fact, these platforms have become an important piece of the modern information ecosystem, which, thus far, has not been studied as a whole. In this paper, we begin to fill this gap by studying mainstream and alternative news shared on Twitter, Reddit, and 4chan. By analyzing millions of posts around several axes, we measure how mainstream and alternative news flows between these platforms. Our results indicate that alt-right communities within 4chan and Reddit can have a surprising level of influence on Twitter, providing evidence that ""fringe"" communities often succeed in spreading alternative news to mainstream social networks and the greater Web. © 2017 Association for Computing Machinery.",4chan; Fake news; Influence; Reddit; Social networks; Twitter,Measurements; 4chan; Fake news; Influence; Reddit; Twitter; Social networking (online)
"Andrade C.E., Byers S.D., Gopalakrishnan V., Halepovic E., Poole D.J., Tran L.K., Volinsky C.T.",7,Connected cars in cellular network: A measurement study,2017,3,"ATandT Labs - Research, Bedminster, NJ, United States",AT and T Labs,1,USA,1,17,17,"Connected cars are a rapidly growing segment of Internet of Things (IoT). While they already use cellular networks to support emergency response, in-car WiFi hotspots and infotainment, there is also a push towards updating their firmware over-the-air (FOTA). With millions of connected cars expected to be deployed over the next several years, and more importantly persist in the network for a long time, it is important to understand their behavior, usage patterns, and impact D both in terms of their experience, as well as other users. Using one million connected cars on a production cellular network, we conduct network-scale measurements of over one billion radio connections to understand various aspects including their spatial and temporal connectivity patterns, the network conditions they face, use and handovers across various radio frequencies and mobility patterns. Our measurement study reveals that connected cars have distinct sets of characteristics, including those similar to regular smartphones (e.g. overall diurnal pattern), those similar to IoT devices (e.g. mostly short network sessions), but also some that belong to neither type (e.g. high mobility). These insights are invaluable in understanding and modeling connected cars in a cellular network and in designing strategies to manage their data demand. © 2017 Association for Computing Machinery.",Cellular; Connected car; IoT,Firmware; Information management; Internet of things; Mobile telecommunication systems; Wireless networks; Cellular; Cellular network; Connectivity pattern; Emergency response; Internet of Things (IOT); Measurement study; Network condition; Radio frequencies; Wi-Fi
"Rula J.P., Bustamante F.E., Steiner M.",3,Cell spoting: Studying the role of cellular networks in the internet,2017,0,"Northwestern University, Akamai, United States",Northwestern University,1,USA,1,41,32,"The impressive growth of the mobile Internet has motivated several industry reports retelling the story in terms of number of devices or subscriptions sold per regions, or the increase in mobile traffic, both WiFi and cellular. Yet, despite the abundance of such reports, we still lack an understanding of the impact of cellular networks around the world. We present the first comprehensive analysis of global cellular networks. We describe an approach to accurately identify cellular network IP addresses using the Network Information API, a non-standard Javascript API in several mobile browsers, and show its effectiveness in a range cellular network configurations. We combine this approach with the vantage point of one of the world's largest CDNs, with servers located in 1,450 networks and clients distributed across across 245 countries, to characterize cellular access around the globe. We find that the majority of cellular networks exist as mixed networks (i.e., networks that share both fixed-line and cellular devices), requiring prefix - not ASN - level identification. We discover over 350 thousand/24 and 23 thousand/48 cellular IPv4 and IPv6 prefixes respectively. By utilizing addresses level traffic from the same CDN, we calculate the fraction of traffic coming from cellular addresses. Overall we find that cellular traffic comprises 16.2% of the CDN's global traffic, and that cellular traffic ranges widely in importance between countries, from capturing nearly 96% of all traffic in Ghana to just 12.1% in France. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",Cellular identification; Cellular networks; Internet census,Mobile telecommunication systems; Wireless networks; Cellular network; Comprehensive analysis; IP addresss; Mixed network; Mobile Browsers; Mobile Internet; Mobile traffic; Network information; Internet protocols
"Vanaubel Y., MŽrindol P., Pansiot J.-J., Donnet B.",4,Through the wormhole: Tracking invisible MPLS tunnels,2017,1,"Montefiore Institute, UniversitŽ de Lige, Belgium; Icube, UniversitŽ de Strasbourg, France",Montefiore Institute;UniversitŽ de Lige;UniversitŽ de Strasbourg,3,Belgium;France,2,42,22,"For years, Internet topology research has been conducted through active measurement. For instance, Caida builds router level topologies on top of IP level traces obtained with traceroute. The resulting graphs contain a significant amount of nodes with a very large degree, often exceeding the actual number of interfaces of a router. Although this property may result from inaccurate alias resolution, we believe that opaque MPLS clouds made of invisible tunnels are the main cause. Using Layer-2 technologies such as MPLS, routers can be configured to hide internal IP hops from traceroute. Consequently, an entry point of an MPLS network appears as the neighbor of all exit points and the whole Layer-3 network turns into a dense mesh of high degree nodes. This paper tackles three problems: the revelation of IP hops hidden by MPLS tunnels, the MPLS deployment underestimation, and the overestimation of high degree nodes. We develop new measurement techniques able to reveal the presence and content of invisible MPLS tunnels. We assess them through emulation and cross-validation and perform a large-scale measurement campaign targeting suspicious networks on which we apply statistical analysis. Finally, based on our dataset, we look at basic graph properties impacted by invisible tunnels. © 2017 Association for Computing Machinery.",Fingerprinting; Internet modeling; MPLS; Network discovery; Traceroute,Internet protocols; Network layers; Routers; Topology; Fingerprinting; Internet modeling; MPLS; Network discovery; Traceroute; multi-protocol label switching
"MŸller M., De Schmidt O.R., Moura G.C.M., Heidemann J.",4,Recursives in the wild: Engineering authoritative DNS servers,2017,3,"SIDN Labs, University of Twente, Netherlands; USC, Information Sciences Institute, United States",University of Twente,1,Netherlands;USA,2,33,27,"In Internet Domain Name System (DNS), services operate authoritative name servers that individuals query through recursive resolvers. Operators strive to provide reliability by operating multiple name servers (NS), each on a separate IP address, and by using IP anycast to allow NSes to provide service from many physical locations. To meet their goals of minimizing latency and balancing load across NSes and anycast, operators need to know how recursive resolvers select an NS, and how that interacts with their NS deployments. Prior work has shown some recursives search for low latency, while others pick an NS at random or round robin, but did not examine how prevalent each choice was. This paper provides the first analysis of how recursives select between name servers in the wild, and from that we provide guidance to operators how to engineer their name servers to reach their goals. We conclude that all NSes need to be equally strong and therefore we recommend to deploy IP anycast at every single authoritative. © 2017 Copyright held by the owner/author(s).",Anycast; Authoritative dns servers; DNS; Recursive dns servers,Routers; Technology transfer; Anycast; Balancing loads; DNS server; Internet domains; Multiple name servers; Name servers; Physical locations; Provide guidances; Internet protocols
"Gharaibeh M., Zhang H., Shah A., Ensafi R., Huffaker B., Papadopoulos C.",6,A look at router geolocation in public and commercial databases,2017,6,"Colorado State University, United States; University of Michigan, United States; CAIDA, UC, San Diego, United States",Colorado State University;University of California San Diego;University of Michigan at Ann Arbor,3,USA,1,33,30,"Internet measurement research frequently needs to map infrastructure components, such as routers, to their physical locations. Although public and commercial geolocation services are often used for this purpose, their accuracy when applied to network infrastructure has not been sufficiently assessed. Prior work focused on evaluating the overall accuracy of geolocation databases, which is dominated by their performance on end-user IP addresses. In this work, we evaluate the reliability of router geolocation in databases. We use a dataset of about 1.64M router interface IP addresses extracted from the CAIDA Ark dataset to examine the country- and city-level coverage and consistency of popular public and commercial geolocation databases. We also create and provide a ground-truth dataset of 16,586 router interface IP addresses and their city-level locations, and use it to evaluate the databases' accuracy with a regional breakdown analysis. Our results show that the databases are not reliable for geolocating routers and that there is room to improve their country- and city-level accuracy. Based on our results, we present a set of recommendations to researchers concerning the use of geolocation databases to geolocate routers. © 2017 Copyright held by the owner/author(s).",Geolocation databases; IP geolocation; Router geolocation,Database systems; Internet protocols; Breakdown analysis; Geo-location database; Geolocations; Ground-truth dataset; Internet measurement; Ip geolocation; Network infrastructure; Overall accuracies; Routers
"Anderson D., Liberty E., Bevan P., Rhodes L., Lang K., Thaler J.",6,A high-performance algorithm for identifying frequent items in data streams,2017,2,"Georgetown University, United States; Amazon, United States; Oath, United States; Oath Research, United States",Georgetown University;Oath Research,2,USA,1,48,18,"Estimating frequencies of items over data streams is a common building block in streaming data measurement and analysis. Misra and Gries introduced their seminal algorithm for the problem in 1982, and the problem has since been revisited many times due its practicality and applicability. We describe a highly optimized version of Misra and Gries' algorithm that is suitable for deployment in industrial settings. Our code is made public via an open source library called Data Sketches that is already used by several companies and production systems. Our algorithm improves on two theoretical and practical aspects of prior work. First, it handles weighted updates in amortized constant time, a common requirement in practice. Second, it uses a simple and fast method for merging summaries that asymptotically improves on prior work even for unweighted streams. We describe experiments confirming that our algorithms are more efficient than prior proposals. © 2017 Association for Computing Machinery.",Frequent items; Mergeable summaries; Streaming algorithms,Measurements; Building blockes; Frequent items; High performance algorithms; Industrial settings; Mergeable summaries; Open-source libraries; Production system; Streaming algorithm; Open systems
"Wang Z., Cao Y., Qian Z., Song C., Krishnamurthy S.V.",5,Your state is not mine: A closer look at evading stateful internet censorship,2017,4,"University of California, Riverside, United States",University of California Riverside,1,USA,1,34,34,"Understanding the behaviors of, and evading state-level Internetscale censorship systems such as the Great Firewall (GFW) of China, has emerged as a research problem of great interest. One line of evasion is the development of techniques that leverage the possibility that the TCP state maintained on the GFW may not represent the state at end-hosts. In this paper we undertake, arguably, the most extensive measurement study on TCP-level GFW evasion techniques, with several vantage points within and outside China, and with clients subscribed to multiple ISPs. We find that the state-of-the art evasion techniques are no longer very effective on the GFW. Our study further reveals that the primary reason that causes these failures is the evolution of GFW over time. In addition, other factors such as the presence of middleboxes on the route from the client to the server also contribute to previously unexpected behaviors. Our measurement study leads us to new understandings of the GFW and new evasion techniques. Evaluations of our new evasion strategies show that our new techniques provide much higher success rates of (compared to prior schemes) Å 90 % or higher. Our results further validate our new understandings of the GFW's evolved behaviors. We also develop a measurement-driven tool INTANG, that systematically looks for and finds the best strategy that works with a server and network path. Our measurements show that INTANG can yield near perfect evasion rates and is extremely effective in aiding various protocols such as HTTP, DNS over TCP, and Tor in evading the GFW. © 2017 Association for Computing Machinery.",Censorship circumvention; INTANG; TCP; The great firewall of China; Traffic manipulation,Computer system firewalls; Transmission control protocol; Censorship circumvention; Evasion strategy; INTANG; Internet censorship; Measurement study; Research problems; State of the art; The great firewall of China; HTTP
"Szurdi J., Christin N.",2,Email typosquating,2017,1,"Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,31,18,"While website domain typosquatting is highly annoying for legitimate domain operators, research has found that it relatively rarely presents a great risk to individual users. However, any application (e.g., email, ftp,...) relying on the domain name system for name resolution is equally vulnerable to domain typosquatting, and consequences may be more dire than with website typosquatting. This paper presents the first in-depth measurement study of email typosquatting. Working in concert with our IRB, we registered76 typosquatting domain names to studya wide variety of user mistakes, while minimizing the amount of personal information exposed to us. In the span of over seven months, we received millions of emails at our registered domains. While most of these emails are spam, we infer, from our measurements, that every year, three of our domains should receive approximately 3,585 ""legitimate"" emails meant for somebody else. Worse, we find, by examining a small sample of all emails, that these emails may contain sensitive information (e.g., visa documents or medical records). We then project from our measurements that 1,211 typosquatting domains registered by unknown entities receive in the vicinity of 800,000 emails a year. Furthermore, we find that millions of registered typosquatting domains have MX records pointing to only a handful of mail servers. However, a second experiment in which we send ""honey emails"" to typosquatting domains only shows very limited evidence of attempts at credential theft (despite some emails being read), meaning that the threat, for now, appears to remain theoretical. © 2017 Association for Computing Machinery.",Abuse; Domain name; Ethics; Measurement; Typosquatting,Measurements; Websites; Abuse; Domain name system; Domain names; Ethics; Personal information; Sensitive informations; Typosquatting; Unknown entities; Electronic mail
"Pujol E.E.P., Wustrow E., Scott W., Halderman J.A.",4,Initial measurements of the cuban street network,2017,1,"Universidad de las Ciencias Inform‡ticas, Cuba; University of Colorado, United States; University of Michigan, United States",Universidad de las Ciencias Inform‡ticas;University of Colorado Boulder;University of Michigan at Ann Arbor,3,Cuba;USA,2,24,14,"Internet access in Cuba is severely constrained, due to limited availability, slow speeds, and high cost. Within this isolated environment, technology enthusiasts have constructed a disconnected but vibrant IP network that has grown organically to reach tens of thousands of households across Havana. We present the first detailed characterization of this deployment, which is known as the SNET, or Street Network. Working in collaboration with SNET operators, we describe the network's infrastructure and map its topology, and we measure bandwidth, available services, usage patterns, and user demographics. Qualitatively, we attempt to answer why the SNET exists and what benefts it has afforded its users. We go on to discuss technical challenges the network faces, including scalability, security, and organizational issues. To our knowledge, the SNET is the largest isolated community-driven network in existence, and its structure, successes, and obstacles show fascinating contrasts and similarities to those of the Internet at large. © 2017 Copyright held by the owner/author(s).",Community network; Cuba; Isolated network; SNET,Community networks; Cuba; Internet access; Isolated community; Isolated networks; Organizational issues; SNET; Technical challenges; Measurements
"Papadopoulos P., Kourtellis N., Rodriguez P.R., Laoutaris N.",4,"If you are not paying for it, you are the product: How much do advertisers pay to reach you?",2017,1,"FORTH-ICS, Greece; Telefonica Research, Spain; Telefonica Alpha, Spain; Data Transparency Lab, Spain",Telefonica Research,1,Greece;Spain,2,83,81,"Online advertising is progressively moving towards a programmatic model in which ads are matched to actual interests of individuals collected as they browse the web. Leting the huge debate around privacy aside, a very important question in this area, for which litle is known, is: How much do advertisers pay to reach an individual? In this study, we develop a first of its kind methodology for computing exactly that - the price paid for a web user by the ad ecosystem - and we do that in real time. Our approach is based on tapping on the Real Time Bidding (RTB) protocol to collect cleartext and encrypted prices for winning bids paid by advertisers in order to place targeted ads. Our main technical contribution is a method for tallying winning bids even when they are encrypted. We achieve this by training a model using as ground truth prices obtained by running our own ""probe"" ad-campaigns. We design our methodology through a browser extension and a back-end server that provides it with fresh models for encrypted bids. We validate our methodology using a one year long trace of 1600 mobile users and demonstrate that it can estimate a user's advertising worth with more than 82% accuracy. © 2017 ACM.",Ad transparency; Cost of advertising; Pricing dynamics; RTB auctions; User privacy,Cryptography; Marketing; Back-end servers; Ground truth; Mobile users; Online advertising; RTB auctions; Technical contribution; User privacy; Winning bids; Costs
"Fontugne R., Aben E., Pelsser C., Bush R.",4,Pinpointing delay and forwarding anomalies using large-scale traceroute measurements,2017,5,"IIJ Research Lab, Japan; RIPE, NCC, Australia; University of Strasbourg, CNRS, France",IIJ Research Laboratory;University of Strasbourg,2,Australia;France;Japan,3,60,45,"Understanding data plane health is essential to improving Internet reliability and usability. For instance, detecting disruptions in distant networks can identify repairable connectivity problems. Currently this task is difficult and time consuming as operators have poor visibility beyond their network's border. In this paper we leverage the diversity of RIPE Atlas traceroute measurements to solve the classic problem of monitoring in-network delays and get credible delay change estimations to monitor network conditions in the wild. We demonstrate a set of complementary methods to detect network disruptions and report them in near real time. The first method detects delay changes for intermediate links in traceroutes. Second, a packet forwarding model predicts traffic paths and identifies faulty routers and links in cases of packet loss. In addition, we define an alarm score that aggregates changes into a single value per AS in order to easily monitor its sanity, reducing the effect of uninteresting alarms. Using only existing public data we monitor hundreds of thousands of link delays while adding no burden to the network. We present three cases demonstrating that the proposed methods detect real disruptions and provide valuable insights, as well as surprising findings, on the location and impact of the identified events. © 2017 Association for Computing Machinery.",Congestion; Internet delay; Outage; Routing anomaly; Statistical analysis; Traceroute,Measurements; Outages; Statistical methods; Complementary methods; Congestion; Connectivity problems; Internet delay; Internet reliabilities; Network disruptions; Routing anomalies; Traceroute; Packet networks
"Kakhki A.M., Jero S., Choffnes D., Nita-Rotaru C., Mislove A.",5,Taking a long look at quic: An approach for rigorous evaluation of rapidly evolving transport protocols,2017,6,"Northeastern University, United States; Purdue University, United States",Northeastern University;Purdue University,2,USA,1,41,26,"Google's QUIC protocol, which implements TCP-like properties at the application layer atop a UDP transport, is now used by the vast majority of Chrome clients accessing Google properties but has no formal state machine specification, limited analysis, and ad-hoc evaluations based on snapshots of the protocol implementation in a small number of environments. Further frustrating attempts to evaluate QUIC is the fact that the protocol is under rapid development, with extensive rewriting of the protocol occurring over the scale of months, making individual studies of the protocol obsolete before publication. Given this unique scenario, there is a need for alternative techniques for understanding and evaluating QUIC when compared with previous transport-layer protocols. First, we develop an approach that allows us to conduct analysis across multiple versions of QUIC to understand how code changes impact protocol effectiveness. Next, we instrument the source code to infer QUIC's state machine from execution traces. With this model, we run QUIC in a large number of environments that include desktop and mobile, wired and wireless environments and use the state machine to understand differences in transport- and application-layer performance across multiple versions of QUIC and in different environments. QUIC generally outperforms TCP, but we also identified performance issues related to window sizes, re-ordered packets, and multiplexing large number of small objects; further, we identify that QUIC's performance diminishes on mobile devices and over cellular networks. © 2017 Copyright held by the owner/author(s).",QUIC; Transport-layer performance,Measurements; Performance issues; Protocol implementation; QUIC; Rigorous evaluation; Transport layer protocols; Transport layers; Transport protocols; Wired and wireless; Transmission control protocol
"Amann J., Gasser O., Scheitle Q., Brent L., Carle G., Holz R.",6,Mission accomplished? HTTPS security after diginotar,2017,9,"ICSI, Corelight, LBNL, United States; Technical University of Munich, Germany; University of Sydney, Australia",TU Munich;University of Sydney,2,Australia;Germany;USA,3,83,82,"Driven by CA compromises and the risk of man-in-the-middle attacks, new security features have been added to TLS, HTTPS, and the web PKI over the past five years. These include Certificate Transparency (CT), for making the CA system auditable; HSTS and HPKP headers, to harden the HTTPS posture of a domain; the DNS-based extensions CAA and TLSA, for control over certificate issuance and pinning; and SCSV, for protocol downgrade protection. This paper presents the first large scale investigation of these improvements to the HTTPS ecosystem, explicitly accounting for their combined usage. In addition to collecting passive measurements at the Internet uplinks of large University networks on three continents, we perform the largest domain-based active Internet scan to date, covering 193M domains. Furthermore, we track the long-term deployment history of new TLS security features by leveraging passive observations dating back to 2012. We find that while deployment of new security features has picked up in general, only SCSV (49M domains) and CT (7M domains) have gained enough momentum to improve the overall security of HTTPS. Features with higher complexity, such as HPKP, are deployed scarcely and often incorrectly. Our empirical findings are placed in the context of risk, deployment effort, and benefit of these new technologies, and actionable steps for improvement are proposed. We cross-correlate use of features and find some techniques with significant correlation in deployment. We support reproducible research and publicly release data and code. © 2017 Copyright held by the owner/author(s).",CAA; CT; HPKP; HSTS; HTTPS; PKI; SCSV; TLS; X.509,Computerized tomography; Network security; Security systems; Seebeck effect; Thallium; HPKP; HSTS; HTTPS; SCSV; X.509; HTTP
"Mi X., Zhang Y., Qian F., Wang X.",4,"An empirical characterization of IFTTT: Ecosystem, usage, and performance",2017,3,"Indiana University, Bloomington, United States; Facebook Inc., United States",Facebook;Indiana University,2,India;USA,2,30,15,"IFTTT is a popular trigger-action programming platform whose applets can automate more than 400 services of IoT devices and web applications. We conduct an empirical study of IFTTT using a combined approach of analyzing data collected for 6 months and performing controlled experiments using a custom testbed. We profile the interactions among different entities, measure how applets are used by end users, and test the performance of applet execution. Overall we observe the fast growth of the IFTTT ecosystem and its increasing usage for automating IoT-related tasks, which correspond to 52% of all services and 16% of the applet usage. We also observe several performance inefficiencies and identify their causes. © 2017 Association for Computing Machinery.",IFTTT; IoT; Measurement,Ecology; Ecosystems; Measurements; Applets; Controlled experiment; Empirical studies; End users; Fast growths; IFTTT; WEB application; Internet of things
"Murdock A., Li F., Bramsen P., Durumeric Z., Paxson V.",5,Target generation for internet-wide IPv6 scanning,2017,6,"University of California, Berkeley, United States; International Computer Science Institute, United States",University of California Berkeley,1,USA,1,31,15,"Fast IPv4 scanning has enabled researchers to answer a wealth of new security and measurement questions. However, while increased network speeds and computational power have enabled comprehensive scans of the IPv4 address space, a brute-force approach does not scale to IPv6. Systems are limited to scanning a small fraction of the IPv6 address space and require an algorithmic approach to determine a small set of candidate addresses to probe. In this paper, we first explore the considerations that guide designing such algorithms. We introduce a new approach that identifies dense address space regions from a set of known ""seed"" addresses and generates a set of candidates to scan. Wecompare our algorithm 6Gen against Entropy/IP-the current state of the art-finding that we can recover between 1-8 times as many addresses for the five candidate datasets considered in the prior work. However, during our analysis, we uncover widespread IP aliasing in IPv6 networks. We discuss its effect on target generation and explore preliminary approaches for detecting aliased regions. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",IPv6; Network measurement; Scanning,Scanning; Algorithmic approach; Brute-force approach; Computational power; IPv6; Network measurement; New approaches; Preliminary approach; State of the art; Internet protocols
Cho K.,1,Recursive latice search: Hierarchical heavy hiters revisited,2017,1,"IIJ Research Laboratory, Tokyo, Japan",IIJ Research Laboratory,1,Japan,1,24,9,"The multidimensional Hierarchical Heavy Hitter (HHH) problem identifies significant clusters in traffic across multiple planes such as source and destination addresses, and has been widely studied in the literature. A compact summary of HHHs provides an overview on complex traffic behavior and is a powerful means for traffic monitoring and anomaly detection. In this paper, we present a new efficient HHH algorithm which fits operational needs. Our key insight is to revisit the commonly accepted definition of HHH, and apply the Z-ordering to make use of a recursive partitioning algorithm. The proposed algorithm produces summary outputs comparable to or even better in practice than the existing algorithms, and runs orders of magnitude faster for bitwise aggregation. We have implemented the algorithm into our open-source tool and have made longitudinal datasets of backbone traffic openly available. © 2017 Association for Computing Machinery.",Flow aggregation algorithm; Hierarchical heavy hitters; Z-order,Regression analysis; Anomaly detection; Flow aggregation; Hierarchical heavy hitters; Operational needs; Orders of magnitude; Recursive Partitioning; Traffic monitoring; Z-order; Telecommunication traffic
"Yao Y., Viswanath B., Xiao Z., Zheng H., Wang B., Zhao B.Y.",6,Complexity vs. Performance: Empirical analysis of machine learning as a service,2017,1,"UCSB, University of Chicago, United States",University of Chicago,1,USA,1,78,50,"Machine learning classifiers are basic research tools used in numerous types of network analysis and modeling. To reduce the need for domain expertise and costs of running local ML classifiers, network researchers can instead rely on centralized Machine Learning as a Service (MLaaS) platforms. In this paper, we evaluate the effectiveness of MLaaS systems ranging from fully-automated, turnkey systems to fully-customizable systems, and find that with more user control comes greater risk. Good decisions produce even higher performance, and poor decisions result in harsher performance penalties. We also find that server side optimizations help fully-automated systems outperform default settings on competitors, but still lag far behind well-tuned MLaaS systems which compare favorably to standaloneML libraries. Finally, we find classifier choice is the dominating factor in determining model performance, and that users can approximate the performance of an optimal classifier choice by experimenting with a small subset of random classifiers. While network researchers should approach MLaaS systems with caution, they can achieve results comparable to standalone classifiers if they have sufficient insight into key decisions like classifiers and feature selection. © 2017 Association for Computing Machinery.",Cloud computing; Machine learning,Artificial intelligence; Automation; Cloud computing; Analysis and modeling; Domain expertise; Dominating factors; Empirical analysis; Fully automated; Model performance; Optimal classifiers; Performance penalties; Learning systems
"Deblasio J., Guha S., Voelker G.M., Snoeren A.C.",4,Exploring the dynamics of search advertiser fraud,2017,0,"UC San Diego, United States; Microsoft Research India, India",Microsoft;University of California San Diego,2,India;USA,2,38,28,"Most search engines generate significant revenue through search advertising, wherein advertisements are served alongside traditional search results. These advertisements are attractive to advertisers because ads can be targeted and prominently presented to users at the exact moment that the user is searching for relevant topics. Deceptive advertising is harmful to all legitimate actors in the search ad ecosystem: Users are less likely to find what they are looking for and may lose trust in ads or the search engine, advertisers lose potential revenue and face unfair competition from advertisers who are not playing by the rules, and the search engine's ecosystem suffers when both users and advertisers are unhappy. This paper explores search advertiser fraud on Microsoft's Bing search engine platform. We characterize three areas: the scale of search advertiser fraud, the targeting and bidding behavior of fraudulent advertisers, and how fraudulent advertisers impact other advertisers in the ecosystem. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",Fraud; Phishing; Search advertising; Spam; Trademark infringement,Competition; Ecology; Ecosystems; Marketing; Search engines; Bidding behavior; Fraud; MicroSoft; Phishing; Potential revenue; Spam; Trademark infringement; Crime
"Farooqi S., Leontiadis N., Zaffar F., Shafiq Z.",4,Measuring and mitigating OAuth access token abuse by collusion networks,2017,2,"University of Iowa, United States; Facebook, United States; Lahore University of Management Sciences, Pakistan",Facebook;LUMS;University of Iowa,3,Pakistan;USA,2,66,44,"We uncover a thriving ecosystem of large-scale reputation manipulation services on Facebook that leverage the principle of collusion. Collusion networks collect OAuth access tokens from colluding members and abuse them to provide fake likes or comments to their members. We carry out a comprehensive measurement study to understand how these collusion networks exploit popular thirdparty Facebook applications with weak security settings to retrieve OAuth access tokens. We infiltrate popular collusion networks using honeypots and identify more than one million colluding Facebook accounts by ""milking"" these collusion networks. We disclose our findings to Facebook and collaborate with them to implement a series of countermeasures that mitigate OAuth access token abuse without sacrificing application platform usability for third-party developers. These countermeasures remained in place until April 2017, after which Facebook implemented a set of unrelated changes in its infrastructure to counter collusion networks. We are the first to report and effectively mitigate large-scale OAuth access token abuse in the wild. © 2017 Association for Computing Machinery.",Access tokens; Collusion networks; OAuth; Online social networks,Online systems; Access tokens; Application platforms; Comprehensive measurement; Facebook applications; OAuth; On-line social networks; Security settings; Third parties; Social networking (online)
"Iqbal U., Shafiq Z., Qian Z.",3,The ad wars: Retrospective measurement and analysis of anti-adblock filter lists,2017,6,"University of Iowa, United States; University of California-Riverside, United States",University of California Riverside;University of Iowa,2,USA,1,69,26,"The increasing popularity of adblockers has prompted online publishers to retaliate against adblock users by deploying anti-adblock scripts, which detect adblock users and bar them from accessing content unless they disable their adblocker. To circumvent antiadblockers, adblockers rely on manually curated anti-adblock filter lists for removing anti-adblock scripts. Anti-adblock filter lists currently rely on informal crowdsourced feedback from users to add/remove filter list rules. In this paper, we present the first comprehensive study of anti-adblock filter lists to analyze their effectiveness against anti-adblockers. Specifically, we compare and contrast the evolution of two popular anti-adblock filter lists. We show that these filter lists are implemented very differently even though they currently have a comparable number of filter list rules. We then use the Internet Archive's Wayback Machine to conduct a retrospective coverage analysis of these filter lists on Alexa top-5K websites over the span of last five years. We find that the coverage of these filter lists has considerably improved since 2014 and they detect anti-adblockers on about 9% of Alexa top-5K websites. To improve filter list coverage and speedup addition of new filter rules, we also design and implement a machine learning based method to automatically detect anti-adblock scripts using static JavaScript code analysis. © 2017 Association for Computing Machinery.",Adblocking; Anti-adblocking; JavaScript; Machine learning; Privacy; Static code analysis; The wayback machine,Artificial intelligence; Bandpass filters; Data privacy; High level languages; Websites; Adblocking; Anti-adblocking; Coverage analysis; Design and implements; Internet archive; Javascript; Measurement and analysis; Static code analysis; Learning systems
"Kotronis V., Nomikos G., Manassakis L., Mavrommatis D., Dimitropoulos X.",5,Shortcuts through colocation facilities,2017,1,"FORTH, Greece; FORTH, Greece University of Crete, Greece",Greece University of Crete,1,Greece,1,53,44,"Network overlays, running on top of the existing Internet substrate, are of perennial value to Internet end-users in the context of, e.g., real-time applications. Such overlays can employ traffic relays to yield path latencies lower than the direct paths, a phenomenon known as Triangle Inequality Violation (TIV). Past studies identify the opportunities of reducing latency using TIVs. However, they do not investigate the gains of strategically selecting relays in Colocation Facilities (Colos). In this work, we answer the following questions: (i) how Colo-hosted relays compare with other relays as well as with the direct Internet, in terms of latency (RTT) reductions; (ii) what are the best locations for placing the relays to yield these reductions. To this end, we conduct a large-scale onemonth measurement of inter-domain paths between RIPE Atlas (RA) nodes as endpoints, located at eyeball networks. We employ as relays Planetlab nodes, other RA nodes, and machines in Colos. We examine the RTTs of the overlay paths obtained via the selected relays, as well as the direct paths. We find that Colo-based relays perform the best and can achieve latency reductions against direct paths, ranging from a few to 100s of milliseconds, in 76% of the total cases; _75% (58% of total cases) of these reductions require only 10 relays in 6 large Colos. © 2017 Copyright held by the owner/author(s).",Latency; Overlay network; Relay; Triangle Inequality Violation,Overlay networks; Inter-domain; Latency; Latency reduction; Network overlay; Planetlab nodes; Real-time application; Relay; Triangle inequality violations; Measurements
"Deblasio J., Savage S., Voelker G.M., Snoeren A.C.",4,Tripwire: Inferring internet site compromise,2017,3,"UC, San Diego, United States",University of California San Diego,1,USA,1,42,19,"Password reuse has been long understood as a problem: credentials stolen from one site may be leveraged to gain access to another site for which they share a password. Indeed, it is broadly understood that attackers exploit this fact and routinely leverage credentials extracted from a site they have breached to access high-value accounts at other sites (e.g., email accounts). However, as a consequence of such acts, this same phenomena of password reuse attacks can be harnessed to indirectly infer site compromises-even those that would otherwise be unknown. In this paper we describe such a measurement technique, in which unique honey accounts are registered with individual third-party websites, and thus access to an email account provides indirect evidence of credentials theft at the corresponding website. We describe a prototype system, called Tripwire, that implements this technique using an automated Web account registration system combined with email account access data from a major email provider. In a pilot study monitoring more than 2,300 sites over a year, we have detected 19 site compromises, including what appears to be a plaintext password compromise at an Alexa top-500 site with more than 45 million active users. © 2017 Copyright held by the owner/author(s).",Cybercrime; Password reuse; Webmail; Website compromise,Electronic mail; Websites; Cybercrime; Internet sites; Measurement techniques; Password reuse; Pilot studies; Prototype system; Registration systems; Webmail; Authentication
"Lichtblau F., Streibelt F., KrŸger T., Richter P., Feldmann A.",5,"Detection, classification, and analysis of inter-domain traffic with spoofed source IP addresses",2017,0,"TU Berlin, Germany",TU Berlin,1,Germany,1,57,34,"IP traffic with forged source addresses (i.e., spoofed traffic) enables a series of threats ranging from the impersonation of remote hosts to massive denial-of-service attacks. Consequently, IP address spoofing received considerable attention with efforts to either suppress spoofing, to mitigate its consequences, or to actively measure the ability to spoof in individual networks. However, as of today, we still lack a comprehensive understanding both of the prevalence and the characteristics of spoofed traffic lin the wild_ as well as of the networks that inject spoofed traffic into the Internet. In this paper, we propose and evaluate a method to passively detect spoofed packets in traffic exchanged between networks in the inter-domain Internet. Our detection mechanism identifies both source IP addresses that should never be visible in the inter-domain Internet (i.e., unrouted and bogon sources) as well as source addresses that should not be sourced by individual networks, as inferred from BGP routing information. We apply our method to classify the traffic exchanged between more than 700 networks at a large European IXP. We find that the majority of connected networks do not, or not consistently, filter their outgoing traffic. Filtering strategies and contributions of spoofed traffic vary heavily across networks of different types and sizes. Finally, we study qualitative characteristics of spoofed traffic, regarding both application popularity as well as structural properties of addresses. Combining our observations, we identify and study dominant attack patterns. © 2017 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.",Denial-of-service; Inter-domain traffic; IP spoofing; Network filtering,Denial-of-service attack; Network security; Denial of Service; Detection mechanism; Filtering strategies; Inter-domain traffic; IP spoofing; Network filtering; Qualitative characteristics; Routing information; Internet protocols
"RŸth J., Bormann C., Hohlfeld O.",3,Large-scale scanning of TCP's initial window,2017,3,"Communication and Distributed Systems, RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,24,16,"Improving web performance is fueling the debate of sizing TCP's initial congestion window (IW), which is a critical performance parameter especially for short-lived flows. This debate yielded several RFC updates to recommended IW sizes, e.g., an increase to IW10 in 2010. The current adoption of IW recommendations is, however, unknown. In this paper, we therefore conduct large-scale measurements covering the entire IPv4 space inferring the IW distribution size by probing HTTP and HTTPS servers. We present an HTTP and TLS scanning method implemented in ZMap, enabling quick estimations of IW sizes at Internet scale. For the first time since the standardization and implementation of IW10, we shed light on the rugged landscape of IW configurations on the Internet. © 2017 Copyright held by the owner/author(s).",Measurements; TCP initial window,Measurements; Surveying instruments; Transmission control protocol; Congestion window; Critical performance parameters; Large-scale measurement; Large-scale scanning; Scanning methods; Short-lived flow; Web performance; HTTP
"Sundaresan S., Lee D., Deng X., Feng Y., Dhamdhere A.",5,Challenges in inferring internet congestion using throughput measurements,2017,6,"Princeton University, United States; Georgia Tech, United States; University of New South Wales, Australia; CAIDA, Univ. of California, San Diego, United States",Georgia Tech;Princeton University;University of New South Wales,3,Australia;USA,2,44,41,"We revisit the use of crowdsourced throughput measurements to infer and localize congestion on end-to-end paths, with particular focus on points of interconnections between ISPs. We analyze three challenges with this approach. First, accurately identifying which link on the path is congested requires fine-grained network tomography techniques not supported by existing throughput measurement platforms. Coarse-grained network tomography can perform this link identification under certain topological conditions, but we show that these conditions do not always hold on the global Internet. Second, existing measurement platforms provide limited visibility of paths to popular web content sources, and only capture a small fraction of interconnections between ISPs. Third, crowdsourcing measurements inherently risks sample bias: using measurements from volunteers across the Internet leads to uneven distribution of samples across time of day, access link speeds, and home network conditions. Finally, it is not clear how large a drop in throughput to interpret as evidence of congestion. We investigate these challenges in detail, and offer guidelines for deployment of measurement infrastructure, strategies, and technologies that can address empirical gaps in our understanding of congestion on the Internet. © 2017 Association for Computing Machinery.",Internet congestion; Internet topology; Throughput,Internet service providers; Personal communication systems; Throughput; Topology; End-to-end path; Internet congestion; Internet topologies; Limited visibility; Network condition; Network tomography; Throughput measurements; Topological conditions; Home networks
"Bhartia A., Chen B., Wang F., Pallas D., Musaloiu-E R., Lai T.T.-T., Ma H.",7,"Measurement-based, practical techniques to improve 802.11ac performance",2017,1,"Cisco Meraki, United States",Cisco,1,USA,1,52,17,"Devices implementing newer wireless standards continue to displace older wireless technology. As 802.11ac access points (APs) are rapidly adopted in enterprise environments, new challenges arise. This paper first presents an overview of trends in enterprise wireless networks based on a large-scale measurement study, in which we collect data from an anonymous subset of millions of radio access points in hundreds of thousands of real-world deployments. Based on the observed data and our experience deploying wireless networks at scale, we then propose two techniques that we have implemented in Meraki APs to improve both overall network capacity and performance perceived by end users: (i) a dynamic channel assignment algorithm, TurboCA, that adjusts to frequent RF condition changes, and (ii) a novel approach, FastACK, that improves the end-to-end performance of TCP traversing high-throughput wireless links. Finally, we evaluate TurboCA with metrics taken from a variety of real-world networks and evaluate TCP performance of FastACK with extensive testbed experiments. © 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.",802.11ac; Channel assignment; Network measurement; TCP,Human computer interaction; Mobile telecommunication systems; Wireless networks; Wireless telecommunication systems; 802.11ac; Channel Assignment; Dynamic channel assignment; End-to-end performance; Enterprise environment; Enterprise wireless network; Large-scale measurement; Network measurement; Transmission control protocol
"Shukla A., Shi M., Feldmann A.",3,Automatic custom generation of topologies and configuration of routing protocols in SDN,2017,0,"TU Berlin, Germany",TU Berlin,1,Germany,1,6,3,"Software-Defined Networks (SDNs) has been an area of interest among researchers from academia and industry. SDNs, however, also introduce new challenges, for example researchers work under strict time constraints and need to conduct frequent experiments to verify their ideas on scalable simulation of real-life topologies. The challenge is two-fold: First, the researchers need to manually generate the topologies and second, manually configure the devices in the generated topologies to enable routing protocols. We demonstrate two novel tools, namely, Topology Generator and Enhanced Automatic Configuration RouteFlow (EACRF), which automatically generate the custom scalable topologies at the SDN data plane and configure routing protocols like BGP and OSPF, at the SDN control plane, in a seamless fashion in quick time. EACRF is an enhancement of RouteFlow which can be used in conjunction with Topology Generator or independently. © 2017 ACM.",Mininet; OpenFlow; Quagga; Reproducible Research; SDN,Topology; Area of interest; Automatic configuration; Control planes; Mininet; Openflow; Quagga; Reproducible research; Time constraints; Routing protocols
"Meyer P., Hiesgen R., Schmidt T.C., Nawrocki M., WŠhlisch M.",5,Towards distributed threat intelligence in real-time,2017,0,"HAW Hamburg, Germany; FU Berlin, Germany",Freie UniversitŠt Berlin;HAW Germany,2,Germany,1,9,6,"In this demo, we address the problem of detecting anomalies on the Internet backbone in near real-time. Many of today's incidents may only become visible from inspecting multiple data sources and by considering multiple vantage points simultaneously. We present a setup based on the distributed forensic platform VAST that was extended to import various data streams from passive measurements and incident reporting at multiple locations, and perform an effective correlation analysis shortly after the data becomes exposed to our queries. © 2017 ACM.",Internet security; Network forensic; Threat detection,Digital forensics; Correlation analysis; Internet backbone; Internet security; Multiple data sources; Multiple vantage points; Near-real time; Passive measurements; Threat detection; Data flow analysis
"Neves M., Levchenko K., Barcellos M.",3,Sandboxing data plane programs for fun and profit,2017,0,"UFRGS, Brazil; UC San Diego, United States",University of California San Diego,1,Brazil;USA,2,3,3,"This paper describes the design and implementation of a generalpurpose compile-time sandbox for P4 data plane programs. Our mechanism allows a supervisor to interpose on another program's interaction with the forwarding device. The sandboxing technique we use provides also a powerful new program structuring model, allowing a data plane developer to combine crosscutting program modules in a safe way. To demonstrate the capabilities of our construct, we describe the implementation of a data plane security kernel that enforces end host isolation policies on top of a programmable data plane. © 2017 ACM.",P4; Programmable data plane; Sandbox,Compile time; Data planes; Design and implementations; New programs; Program module; Sandbox; Sandboxing techniques; Security kernel
"Dasari M., Kelton C., Nejati J., Balasubramanian A., Das S.R.",5,Demystifying hardware bottlenecks in mobileweb quality of experience,2017,1,"Stony Brook University, United States",Stony Brook University,1,USA,1,7,6,"Mobile web page load time depends on three key factors: (1) the complexity of the Webpage, (2) the underlying network conditions, and (3) the processing capability of the device. While there are several works focusing on the Web complexity and the network, there is a little work in understanding the hardware bottlenecks in the page load process. In this poster, we analyze the effect of hardware bottlenecks of Web pages. We also analyze the effect of GPU offloading, a commonly used solution to speed up Web page loads. © 2017 ACM.",CPU-GPU; Page Load Time; Web QoE,Complex networks; Graphics processing unit; Hardware; Quality of service; Mobile web pages; Page Load Time; Processing capability; Quality of experience (QoE); Speed up; Underlying networks; Web QoE; Websites
"Dethise A., Chiesa M., Canini M.",3,Privacy-preserving detection of inter-domain SDN rules overlaps,2017,0,"KAUST, UniversitŽ Catholique de Louvain, Belgium; UniversitŽ Catholique de Louvain, Belgium; KAUST, Saudi Arabia",Universite Catholique de Louvain,1,Belgium;Saudi Arabia,2,9,7,"SDN approaches to inter-domain routing promise better traffic engineering, enhanced security, and higher automation. Yet, na•ve deployment of SDN on the Internet is dangerous as the control-plane expressiveness of BGP is significantly more limited than the data-plane expressiveness of SDN, which allows fine-grained rules to deflect traffic from BGP's default routes. This mismatch may lead to incorrect forwarding behaviors such as forwarding loops and blackholes, ultimately hindering SDN deployment at the inter-domain level. In this work, we make a first step towards verifying the correctness of inter-domain forwarding state with a focus on loop freedom while keeping private the SDN rules, as they comprise confidential routing information. To this end, we design a simple yet powerful primitive that allows two networks to verify whether their SDN rules overlap, i.e., the set of packets matched by these rules is non-empty, without leaking any information about the SDN rules. We propose an efficient implementation of this primitive by using recent advancements in Secure Multi-Party Computation and we then leverage it as the main building block for designing a system that detects Internet-wide forwarding loops among any set of SDN-enabled Internet eXchange Points. © 2017 ACM.",Inter-domain routing; Network Verification; Privacy; SMPC,Efficient implementation; Interdomain Routing; Internet exchange points; Privacy preserving; Routing information; Secure multi-party computation; SMPC; Traffic Engineering; Data privacy
"Song H., Ji Z., Zhang Y., Xia Y.",4,3D fabric: Differential deceleration and detour for congestion free data center networks,2017,0,"Futurewei Technologies, China; Huawei IP Network Research Department, Beijing, China",Huawei Technologies,1,China,1,7,6,"3D Fabric jointly uses two strategies for congestion avoidance: .ow rate adjustment and path switch. 3D Fabric predicts .ow's size and only decelerates large .ows in case of light congestion. When the network is heavily congested, it starts to decelerate small .ows as well, and meanwhile, considers to switch large .ow's path with the help of a new artiffcial .owlet generation method. ns-3 simulation shows 3D Fabric's FCT outperforms DCTCP by more than 50% for small .ows and 3% for large .ows with low implementation cost. © 2017 ACM.",Congestion Control; Data Center Network; Load Balancing,Resource allocation; 3-D fabrics; Congestion avoidance; Data center networks; Generation method; Implementation cost; Ns-3 simulations; Rate adjustment; Congestion control (communication)
"Fu Z., Zhou S., Li J.",3,BitFA: A novel data structure for fast and update-friendly regular expression matching,2017,0,"Department of Automation, Research Institute of Information Technology, Tsinghua University, Tsinghua, China; Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, United States; Research Institute of Information Technology, Tsinghua National Lab for Information Science and Technology, Tsinghua University, Tsinghua, China",Tsinghua University;University of Southern California,2,China;USA,2,7,3,"This paper proposes bitFA, a novel data structure optimized for fast and update-friendly regular expression matching. bitFA leverages fast bit manipulation, instruction-level parallelism and bitmap compression techniques to achieve 5x to 25x acceleration compared to existing NFA or DFA based regular expression matching methods. © 2017 ACM.",Bit Manipulation; Finite Automaton; Regular Expression,Data structures; Finite automata; Pipeline processing systems; Bit manipulation; Compression techniques; Instruction level parallelism; Regular expressions; Regular-expression matching; Pattern matching
"Dong J., Wang Y., Tian C., Jin B., Yin H., Zhang G.",6,WVCC: Weighted virtual congestion control for datacenter networks,2017,0,"Department of Computer Science, Tsinghua University, China; Future Network Theory Lab, Huawei, China; State Key Laboratory for Novel, Software Technology, Nanjing University, China",Nanjing University;Tsinghua University,2,China,1,5,5,"Enforcing virtualized congestion control is a new trend for datacenter networks. Virtual Congestion Control (VCC) can also enforce differentiated Quality-of-Service (QoS) for flows. However, current flow differentiation algorithms only provide qualitative rather than quantitative bandwidth allocation. Weighted bandwidth allocation is critical to enforce administrator policy. In this work, we propose Weighted Virtual Congestion Control (WVCC) enforcement for datacenter networks. It is a novel per-flow differentiation mechanism capable of proportionally allocating bandwidth among flows. © 2017 ACM.",Congestion Control; Network Proportionality; Virtualization,Bandwidth; Congestion control (communication); Quality of service; Virtualization; Current flows; Data center networks; Differentiated quality of services; Differentiation algorithms; Quality control
"Kwon M., Vajpayee S., Vijayaragavan P., Dhuliya A., Marshall J.",5,Use of cuckoo filters with FD.io VPP for Software IPv6 routing lookup,2017,0,"Rochester Institute of Technology, United States; Cisco Systems, Inc., United States",Cisco;Rochester Institute of Technology,2,USA,1,9,7,"The filter technologies, e.g., Bloom filters, have been used for IP lookup for their compactness and efficiency.We investigate the performance of cuckoo filters with Cisco's VPP (Vector Packet Processing) for IP lookup.We also introduce a variant called a length-aware cuckoo filter that treats incoming IP addresses discriminatively, and study its performance with VPP. As proof-of-concept, we implement cuckoo filters with VPP, and test them on both functions and performance with focus on the ip6-input node in VPP. © 2017 ACM.",Cuckoo filters; IP lookup; Packet forwarding; Software routers,Bandpass filters; Bloom filters; Filter technology; IP lookup; Packet forwarding; Packet processing; Proof of concept; Routing lookup; Software routers; Routers
"Van Rijswijk-Deij R., Chung T., Choffnes D., Mislove A., Toorop W.",5,The root canary: Monitoring and measuring the DNSSEC root key rollover,2017,0,"University of Twente, SURFnet, Netherlands; Northeastern University, United States; NLnet Labs, United States",Northeastern University;University of Twente,2,Netherlands;USA,2,5,5,"The Domain Name System (DNS) is part of the core of the Internet. Over the past decade, much-needed security features were added to this protocol, with the introduction of the DNS Security Extensions. DNSSEC adds authenticity and integrity to the protocol using digital signatures, and turns the DNS into a public key infrastructure (PKI). At the top of this PKI is a single key, the so-called Key Signing Key (KSK) for the DNS root. The current Root KSK was introduced in 2010, and has not changed since. This year, the Root KSK will be replaced for the first time ever. This event potentially has a major impact on the Internet. Thousands of DNS resolvers worldwide rely on this key to validate DNSSEC signatures, and must start using the new key, either through an automated process, or manual intervention. Failure to pick up the new key will result in resolvers becoming completely unavailable to end users. This work presents the ""Root Canary"", a system to monitor and measure this event from the perspective of validating DNS resolvers for its entire nine-month duration. The system combines three active measurement platforms to have the broadest possible coverage of validating resolvers. Results will be presented in near real-time, to allow the global DNS community to act if problems arise. Furthermore, after the Root KSK rollover concludes in March 2018, we will use the recorded datasets for an in-depth analysis, from which the Internet community can draw lessons for future key rollovers. © 2017 ACM.",Active measurements; DNS; DNSSEC; Internet stability,Authentication; Automation; Distributed computer systems; Intrusion detection; Network security; Public key cryptography; Active measurement; Automated process; DNSSEC; Domain name system; Internet communities; Internet stability; Manual intervention; Public-key infrastructure; Internet protocols
"Nathan V., Narayana S., Sivaraman A., Goyal P., Arun V., Alizadeh M., Jeyakumar V., Kim C.",8,Demonstration of the marple system for network performance monitoring,2017,0,"MIT CSAIL, United States; IIT Guwahati, India; Cisco Tetration Analytics, United States; Barefoot Networks, United States",MIT,1,India;USA,2,20,15,"We demonstrate Marple [15], a system that allows network operators to measure a wide variety of performance metrics in real time. It consists of a performance query language, Marple, modeled on familiar functional operators like map, filter, and groupby. Marple is supported by a programmable key-value store on switches, which can compute flexible aggregated statistics (e.g., per-flow counts, moving averages over queueing latencies) over packets at line rate. Our switch design implements performance queries which could previously run only on end hosts, while utilizing only a modest fraction of switch hardware resources. To demonstrate the utility of Marple, we compile Marple queries to a P4-programmable software switch running within Mininet. We demonstrate two example use cases of Marple: Diagnosing the root cause of latency spikes and measuring the flowlet size distribution. © 2017 ACM.",Network hardware; Network measurement; Network programming,Hardware; Query languages; Hardware resources; Key-value stores; Network measurement; Network operator; Network performance monitoring; Network programming; Performance metrics; Programmable software; Computer programming
"Mao P., Birkner R., Holterbach T., Vanbever L.",4,Boosting the BGP convergence in SDXes with SWIFT,2017,1,"ETH ZŸrich, Switzerland",ETH Zurich,1,Switzerland,1,5,4,"BGP, the only inter-domain routing protocol used today, often converges slowly upon outages. While fast-reroute solutions exist, they can only protect from local outages, not remote ones (e.g., a failure in a transit network). To address this problem, we proposed SWIFT, a fast-reroute framework enabling BGP routers to locally restore connectivity upon remote outages by combining fast inference mechanisms in the control-plane with fast data plane updates. While SWIFT is deployable on a per-router basis, we show in this demonstration that we can deploy SWIFT in Software-Defined Internet Exchange Points (SDXes) with a simple software update. We show that ""SWIFTing"" an SDX is highly beneficial as it enables to converge the entire fabric within few seconds instead of the tens of seconds required by the original software. © 2017 ACM.",BGP; Convergence; Fast Reroute; Internet exchange point (IXP),Routing protocols; Control planes; Convergence; Fast inference; Fast reroute; Interdomain Routing; Internet exchange points; Software updates; Transit networks; Routers
"Fan C., Bi J., Zhou Y., Zhang C., Yu H.",5,NS4: A P4-driven network simulator,2017,1,"Tsinghua University, China",Tsinghua University,1,China,1,6,4,"best of our knowledge, the first research effort in applying P4 to network simulation. Key features of NS4 include (1) elimination of laborious and redundant work for developing internal models of the simulator; (2) direct migration from simulation code to realworld P4 devices; (3) simulation of P4-enabled devices and network systems; (4) seamless compatibility with ns-3; (5) better scalability over other P4 behavioral model validation tools. We proposed and prototyped NS4 by integrating a P4 behavioral model in ns-3, and evaluated its effectiveness by a user case study. Source codes and examples of NS4 are publicly available at https://ns-4.github.io/. © 2017 ACM.",P4; Simulation,Behavioral model; Internal models; Network simulation; Network simulators; Network systems; Research efforts; Simulation; Simulation code; Behavioral research
"Gilani Z., Crowcroft J., Farahbakhsh R., Tyson G.",4,The implications of twitterbot generated data traffic on networked systems,2017,2,"University of Cambridge, United Kingdom; Institut Mines Telecom - Sud-Paris, France; Queen Mary University of London, United Kingdom",Queen Mary University of London;University of Cambridge,2,France;UK,2,5,5,"The explosion of bots on theWeb brings an unprecedented increase in traffic from non-human sources. This work studies bot traffic on Twitter, finding that almost 50% of traffic is generated and propagated by a rapidly growing bot population - a major concern for networked systems in the future. © 2017 ACM.",Bot generated content; Bot network traffic; Information propagation,Bot generated content; Data traffic; Information propagation; Network traffic; Networked systems; Work study; Information dissemination
"Zhang Y., Han B., Zhang Z.-L., Gopalakrishnan V.",4,Network-assisted raft consensus algorithm,2017,0,"University of Minnesota, Twin Cities, United States; AT and T Labs - Research, United States",AT and T Labs;University of Minnesota,2,USA,1,10,8,"Consensus is a fundamental problem in distributed computing. In this poster, we ask the following question: Can we partially offload the execution of a consensus algorithm to the network to improve its performance? We argue for an affirmative answer by proposing a network-assisted implementation of the Raft consensus algorithm. Our approach reduces consensus latency, is failure-aware, and does not sacrifice correctness or scalability. In order to enable Raft-aware forwarding and quick response, we use P4-based programmable switches and offload partial Raft functionality to the switch. We demonstrate the efficacy of our approach and performance improvements it offers via a prototype implementation. © 2017 ACM.",Consensus; P4; Programmable networks; Raft algorithm; SDN,Consensus; Consensus algorithms; IS failure; Programmable network; Programmable switches; Prototype implementations; Quick response; Distributed computer systems
"Cozzolino V., Ding A.Y., Ott J., Kutscher D.",4,Enabling fine-grained edge offloading for IoT,2017,0,"Technical University of Munich, Germany; Huawei Technologies, China",TU Munich,1,China;Germany,2,4,4,"In this paper we make the case for IoT edge o.oading, which strives to exploit the resources on edge computing devices by o.oading ffne-grained computation tasks from the cloud closer to the users and data generators (i.e., IoT devices).e key motive is to enhance performance, security and privacy for IoT services. Our proposal bridges the gap between cloud computing and IoT by applying a divide and conquer approach over the multi-level (cloud, edge and IoT) information pipeline. To validate the design of IoT edge o.oading, we developed a unikernel-based prototype and evaluated the system under various hardware and network conditions. Our experimentation has shown promising results and revealed the limitation of existing IoT hardware and virtualization platforms, shedding light on future research of edge computing and IoT. © 2017 ACM.",Edge Computing; IoT; Virtualization,Hardware; Virtual reality; Virtualization; Computation tasks; Divide-and-conquer approach; Edge computing; Information pipeline; Iot services; Network condition; Security and privacy; Shedding light; Internet of things
"Szalay M., Toka L., RŽtv‡ri G., Pongr‡cz G., Csikor L., Pezaros D.P.",6,HARMLESS: Cost-effective transitioning to SDN,2017,0,"Budapest University of Technology and Economics, Hungary; MTA-BME Information Systems Research Group, Hungary; Ericsson Research, Traffic Lab Hungary, Hungary; School of Computing Science, University of Glasgow, United Kingdom",Budapest University of Technology and Economics;Ericsson Research;MTA-BME;University of Glasgow,4,Hungary;UK,2,16,15,"Recently, Software-Defined Networking has grown out of being an ""intriguing approach"" and turned into a ""must-have"" for communication networks to overcome many long-standing problems of traditional networking. However, there are still some obstacles on the way to the widespread adoption. Current commodity-off-the-shelf (COTS) SDN offerings are still in their infancy and are notorious for lacking standards compliance, scalability, and unpredictable performance indicators compared to their legacy counterparts. On the other hand, recent software-based solutions might mitigate these shortcomings, but in terms of cost-eficiency and port density they are in a lower league. Here, we present HARMLESS, a novel SDN switch design that combines the rapid innovation and upgrade cycles of software switches with the port density of hardware-based appliances into a fully data plane-transparent, vendor-neutral and cost-effective solution for smaller enterprises to gain a foothold in this era. The demo showcases the SDN migration of a dumb legacy Ethernet switch to a powerful, fully reconfigurable, OpenFlow-enabled network device without incurring any major performance and latency penalty, nor any substantial price tag enabling to realize many use cases that would have otherwise needed standalone hardware appliances. © 2017 ACM.",Migration; Software-Defined Networking; Switch design,Computer hardware; Costs; Hardware; Network function virtualization; Regulatory compliance; Software defined networking; Commodity off the shelves; Cost-effective solutions; Migration; Performance indicators; Software switches; Software-based solutions; Standing problems; Switch designs; Cost effectiveness
"Ameme D., Misra S., Mtibaa A.",3,A case for information centric networking for smart grid communications,2017,0,"Computer Science Department, New Mexico State University, United States",New Mexico State University,1,Mexico;USA,2,12,12,"The smart grid, with its large array of networked devices and bidirectional data flowbetween the end-users and the grid, presents new requirements in service reliability, communication latency, and data delivery. The traditional TCP/IP communication paradigm was not designed to handle these requirements at the envisioned scale. This calls for a novel networking paradigm. This paper makes the case for the use of the Information Centric Networking (ICN) paradigm to create the smart grid network architecture. We quantitatively assess the gains resulting from ICN's inherent functionalities, such as concurrent use of multiple interfaces, request aggregation, and stateful forwarding, which enable timely critical message delivery and fast packet re-transmissions. We perform simulations to compare IP and ICN-based smart grid deployments. Our results show that the ICN-based solution outperforms the IP-based solution, especially in a network with packet losses. © 2017 ACM.",Information-centric networks; Named-data networking.; Smart Grid,Electric power transmission networks; Internet protocols; Network architecture; Smart power grids; Communication latency; Information Centric Networks; Information-centric networkings; Information-centric networkings (ICN); Named data networkings; Smart grid; Smart Grid Communications; TCP/IP communication; Packet networks
"Ma Y., Selby N., Singh M., Adib F.",4,Fine-grained RFID localization via ultra-wideband emulation,2017,2,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,22,15,"This demo presents RFind, a system that enables fine-grained RFID localization via ultra-wideband emulation. RFind operates by measuring the time-of-flight - i.e., the time it takes the signal to travel from an antenna to an RFID tag. To do so, it emulates an ultrawide bandwidth on today's narrowband RFIDs without requiring any hardware modification to the tags. It then uses the large emulated bandwidth to estimate the time-of-flight and localize RFIDs. In contrast to past RFID localization proposals, RFind can operate in multipath-rich environments without reference tags and without requiring tag or antenna motion. The demo will allow users to move RFID-tagged objects to any location in line-of-sight, non-line-ofsight, and multi-path rich settings and check that the system can accurately localize the objects. © 2017 ACM.",Battery-free; Localization; RFID; Smart Environments; UWB,Antennas; Bandwidth; Radio frequency identification (RFID); Antenna motion; Battery-free; Hardware modifications; Localization; Rfid localizations; Smart environment; Time of flight; Ultrawide bandwidth; Ultra-wideband (UWB)
"Asgarian F., Najafi K.",2,Time synchronization in a network of bluetooth low energy beacons,2017,3,"University of Michigan, Ann Arbor, United States",University of Michigan at Ann Arbor,1,USA,1,3,2,"Time synchronization is a vital feature in many wireless sensor networks with applications ranging from structural health monitoring systems to body area sensors used for rehabilitation and sport medicine. While different wireless protocols have been utilized in sensor networks, Bluetooth Low Energy (BLE) has drawn a lot of attention in the past years due to its low-power architecture and availability in many consumer electronics. Moreover, the added non-connectable beacon mode has increased its functionality for Internet of Things (IoT) and sensor fusion. However, in this mode as devices are not paired with each other no synchronization service is available. In this paper, we present a synchronization protocol based on BLE beacons that can be used in conjunction with BLE software stacks provided with a commercial Bluetooth System-on-Chip (SoC). Offset and frequency-drift estimation techniques are discussed, and the effects of number of synchronization packets and their intervals on the overall synchronization accuracy are investigated. Experimental results show that without any resynchronization in ten minutes, average synchronization errors of less than 350 ns per minute (single hop) can be achieved. © 2017 ACM.",Beacon; Bluetooth; Sensor Networks; Time Synchronization,Bluetooth; Frequency estimation; Information services; Internet of things; Network architecture; Programmable logic controllers; Sensor networks; Structural health monitoring; Synchronization; System-on-chip; Wireless sensor networks; Beacon; Bluetooth low energies (BLE); Bluetooth low energies (BTLE); Internet of Things (IOT); Low power architecture; Structural health monitoring systems; Synchronization protocols; Time synchronization; Low power electronics
"Cao Y., Balasubramanian A., Gandhi A.",3,Rethinking TCP throughput and latency modeling,2017,0,"Stony Brook University, United States",Stony Brook University,1,USA,1,3,1,"TCP throughput and latency models are useful tools to characterize the TCP performance. The canonical throughput model [2], while useful, has some limitations since it does not consider how packet loss rate changes over time. This approach leads to poor predictions for short flows. We present a new modeling approach that characterizes the throughput and latency models by: (i) discovering the relationship between the packet loss rate and the congestion window size, and (ii) incorporating the starting congestion window and the number of parallel connections. Experimental results show that our models significantly improve modeling accuracy. © 2017 ACM.",Network measurements; Transport layer protocols,Electric connectors; Packet loss; Packet networks; Throughput; Congestion window; Congestion window size; Network measurement; Packet loss rates; Parallel connections; TCP performance; Throughput modeling; Transport layer protocols; Transmission control protocol
"Jalali F., Smith O.J., Lynar T., Suits F.",4,Cognitive IoT gateways: Automatic task sharing and switching between cloud and Edge/Fog computing,2017,5,"IBM Research, Australia",IBM,1,Australia,1,6,6,"Fog computing, also known as Edge computing, is an emerging computational paradigm, increasingly utilized in Internet of Things (IoT) applications, particularly those that cannot be served efficiently using Cloud computing due to limitations such as bandwidth, latency, Internet connectivity. At present, the norm is the static allocation of tasks by developers of an application, where some IoT applications are allocated to be performed on the Cloud, some on the Fog, and some on a hybrid Cloud-Fog. The applications are pre-programmed and predefined to be run on a platform, and this is unchangeable at run-time. IoT gateways, which are devices that bridge the IoT local network and the Internet, are in a position to make dynamic adjustments and allocation decision between platforms based upon real-time conditions such as an IoT applications' performance. However, currently there is no (or very little) intelligence embedded into IoT gateways. This paper proposes cognitive IoT gateways powered by cognitive analytics and machine learning to improve the performance of IoT applications. These IoT devices are able to automatically learn and decide when and where to run an application, be that on the Cloud or on the Fog. The dynamic task sharing and platform interchanging will enable the IoT applications to be optimized for multiple objectives including task performance. © 2017 ACM.",Fog/Edge computing; Intelligent IoT gateways; Job sharing,Computer circuits; Fog; Gateways (computer networks); Learning systems; Allocation decision; Computational paradigm; Dynamic adjustment; Internet connectivity; Internet of Things (IOT); Job sharing; Multiple-objectives; Task performance; Internet of things
"Demoulin H.M., Vaidya T., Sultana N., Wang B., Qian J., Zhang Y., Chen A., Haeberlen A., Loo B.T., Phan L.T.X., Sherr M., Shields C., Zhou W.",13,A demonstration of the DeDoS platform for defusing asymmetric DDoS attacks in data centers,2017,0,"University of Pennsylvania, United States; Georgetown University, Isaac Pedisich, United States; Georgetown University, United States",Georgetown University;University of Pennsylvania,2,USA,1,11,10,"We propose a demonstration of DeDoS, a platform for mitigating asymmetric DDoS attacks. These attacks are particularly challenging since attackers using limited resources can exhaust the resources of even well-provisioned servers. DeDoS resolves this by splitting monolithic software stacks into separable components called minimum splittable units (MSUs). If part of the application stack is experiencing a DDoS attack, DeDoS can massively replicate only the affected MSUs, potentially across many machines. This allows scaling of the impacted resource separately from the rest of the application stack so that resources can be precisely added where needed to combat the attack. Our demonstration will show that DeDoS incurs reasonable overheads in normal operations and that it significantly outperforms na•ve replication when defending against a range of asymmetric attacks. © 2017 ACM.",Denial-of-Service attacks; Distributed Systems; Real-time scheduling; Security,Demonstrations; Network security; Real time systems; Data centers; DDoS Attack; Distributed systems; Normal operations; Real - time scheduling; Security; Software stacks; Denial-of-service attack
Schmidt F.,1,Uniprof: A unikernel stack profiler,2017,0,"NEC Laboratories Europe, Germany",NEC,1,Germany,1,9,6,"Unikernels are increasingly gaining traction in real-world deployments, especially for NFV and microservices, where their low footprint and high performance are especially beneficial. However, they still suffer from a lack of tools to support developers. uniprof is a stack profiler that supports Xen unikernels on x86 and ARM and does not requires any code changes or instrumentation. Its high speed and lowoverhead (0.1% at 100 samples/s) makes it usable even in production environments, allowing the collection of realistic and highly credible data. © 2017 ACM.",Call stack profiling; Introspection; Unikernels; Xen,Call stack profiling; Code changes; High Speed; Introspection; Production environments; Real world deployment; Unikernels
"Mahfoudi M.N., Parmentelat T., Turletti T., Dabbous W., Knopp R.",5,Deploy a 5G network in less than 5 minutes demo abstract,2017,0,"UniversitŽ C™te d'Azur, Inria, France; Eurecom, France",EURECOM;UniversitŽ C™te DAzur,2,France,1,5,5,"We describe a demonstration run on R2lab, an anechoic chamber located at Inria Sophia Antipolis, France. The demonstration consists in deploying a standalone 5G network in less than 5 minutes. All the network components (base station, subscriber management, serving and packet gateways, network traffic analyzers) were run automatically using the nepi-ng experiment orchestration tool. Download and upload performance to the Internet from a commercial phone located in the anechoic chamber are shown. © 2017 ACM.",4G/5G; Wireless testbed,5G mobile communication systems; Anechoic chambers; 4G/5G; G-networks; Network Traffic analyzers; Wireless testbed; Queueing networks
"Rath F., Krude J., RŸth J., Schemmel D., Hohlfeld O., Bitsch J.ç., Wehrle K.",7,SymPerf: Predicting network function performance,2017,2,"Communication and Distributed Systems, RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,5,5,"The softwarization of networks provides a new degree of flexibility in network operation but its software components can result in unexpected runtime performance and erratic network behavior. This challenges the deployment of flexible software functions in performance critical (core) networks. To address this challenge, we present a methodology enabling the prediction of runtime performance and testing of functional behavior of Network Functions. Unlike traditional performance evaluation, e.g., testbed testing or simulation, our methodology can characterize the Network Function performance for any possible workload only by code analysis. © 2017 ACM.",Measurements; NFV; Performance; Reliability; Symbolic Execution,Measurements; Reliability; Transfer functions; Degree of flexibility; Functional behaviors; Network behaviors; Performance; Run-time performance; Software component; Software functions; Symbolic execution; Network function virtualization
"Szabo M., Majdan A., Pongracz G., Toka L., Sonkoly B.",5,Making the data plane ready for NFV: An effective way of handling resources,2017,0,"Budapest University of Technology and Economics, Hungary; Ericsson Research, Hungary",Budapest University of Technology and Economics;Ericsson Research,2,Hungary,1,4,4,"In order to enable carrier grade network services constructed from software-based network functions, we need a novel data plane supporting high performance packet processing, low latency and flexible, fine granular programmability and control. The network functions implemented as virtual machines or containers use the same hardware resources (cpu, memory) as the elements responsible for networking, therefore, a low-level resource orchestrator which is capable of jointly controlling these resources is an indispensable component. In this demonstration, we showcase our novel resource orchestrator (FERO) on top of a data plane making use of open-source components such as, Docker, DPDK and OVS. It is capable of i) generating an abstract model of the underlying hardware architecture during the bootstrap process, ii) mapping the incoming network service requests to available resources based on our recently proposed Service Graph embedding engine and the generated graph model. The impact of the orchestration decision is shown on-the-fly by real-time performance measurements on a graphical dashboard. © 2017 ACM.",Docker; DPDK; NFV; SDN; SFC,Embedded systems; Hardware; Open source software; Transfer functions; Docker; DPDK; Hardware architecture; Hardware resources; Network functions; Open-source components; Packet processing; Real time performance; Network function virtualization
"Samain J., AugŽ J., Carofiglio G., Muscariello L., Papalini M., Sardara M.",6,Enhancing mobile video delivery over an heterogeneous network access with information-centric networking,2017,0,"Cisco Systems, TŽlŽcom ParisTech, France; Cisco Systems, France",Cisco;Telecom ParisTech,2,France,1,13,8,"Mobile video delivery drives Internet traffic evolution and puts colossal pressure on future 5G networks to support higher quality and lower latency requirements over an increasingly heterogeneous network access. Future Internet paradigms recentering communication around content, such as Information Centric Networks (ICN), appear as promising candidates to relieve the challenges of a mobility-robust, efficient and cost-effective video delivery, by integrating video-awareness at network layer. In this demo, we focus on ICN-enabled Dynamic Adaptive Streaming (DAS) over an heterogeneous wireless access. We integrate ICN capabilities in DAS clients requesting 4K video content to standard DAS servers. We deploy a virtualized ICN-enabled network slice using LXC containers to connect clients to servers through an heterogeneous wireless access (802.11n and LTE emulated radios) and a simplified backhaul. The contribution of the demo is twofold. First it showcases what ICN can bring to DAS over a mobile heterogeneous access in virtue of its content-awareness at network layer. Second, it offers to the user a rich sandbox where several state-of-the-art DAS controllers are implemented and can be tested over ICN or standard TCP. © 2017 ACM.",Emulation; Information-Centric Network; Video Delivery,Cost effectiveness; Heterogeneous networks; Network layers; Dynamic-adaptive; Emulation; Heterogeneous access; Information Centric Networks; Information-centric networkings; Internet traffic; State of the art; Video delivery; Wireless telecommunication systems
"Ding J., Li Y., Li Y., Hui P., Jin D.",5,Characterizing the click and share dynamics of micro-videos in social media,2017,0,"Tsinghua University, Beijing, China; Hong Kong University of Science and Technology Hongkong, Hongkong, Hong Kong",Hong Kong University of Science and Technology;Tsinghua University,2,China;Hong Kong,2,4,4,"Micro-video has recently become an important form of user generated contents in the social media of microblogging. It is propagated by sharing and reaches the targeted audience through being clicked and watched. Since click data is usually not public available, it is still an open problem that what is the difference between sharing and clicking behaviours in the information propagation. In this work, thanks to a massive set of anonymized data from a major operator covering the whole China, we jointly study both temporal dynamics of click and share of over 10,000 micro-videos in SinaWeibo, the largest microblogging service and micro-video platform in China. We observe a significant difference between lifespans of the micro-videos in terms of both click and share. Comparatively, the clicking dynamics of micro-videos evolve more quickly than the sharing dynamics, and a delay of several hours exists between sharing and clicking dynamics, which indicates a causal effect. These observations benefit understanding the information propagation of micro-videos in terms of both click and share. © 2017 ACM.",Click; Micro-video; Share; Social media,Dynamics; Information dissemination; Click; Information propagation; Micro-blogging services; Micro-video; Share; Social media; Temporal dynamics; User-generated content; Social networking (online)
"Rotenberg N., Shulman H., Waidner M., Zeltser B.",4,Authentication-bypass vulnerabilities in SOHO routers,2017,1,"Fraunhofer Institute for Secure Information Technology SIT, Germany; Hebrew University of Jerusalem, Israel",Fraunhofer Institute for Secure Information Technology SIT;Hebrew University of Jerusalem,2,Germany;Israel,2,10,9,"SOHO routers act as a gateway to the Internet for Small Office/Home Office networks. Despite the important role that they fulfill, there is a long history of vulnerabilities allowing attackers to breach security and availability of the clients and services on SOHO networks. Following the multiple disclosures and recommendations for patches in the last two decades it seems an obvious question to verify whether the reality meets the expectation. We focus on an important class of vulnerabilities called 'authentication bypass', which allow an attacker to take control over a network device by subverting the authentication procedure. We perform a stealthy and non disruptive evaluation of authentication bypass vulnerabilities in SOHO routers. Our study focuses on a number of selected countries, to detect presence of vulnerable devices. The results of our study are worrisome: we find a large fraction of misconfigurations and insecurity issues in configuration of SOHO routers, which stand in sharp contrast to the awareness of the security and research communities to the vulnerabilities as well as a large body of work studying related topics. © 2017 ACM.",DNS security; Resolver fingeprinting; Resolver measurements,Authentication; Gateways (computer networks); Security of data; Authentication bypass; DNS securities; Misconfigurations; Network devices; Research communities; Resolver fingeprinting; Sharp contrast; Small office/home offices; Network security
"Diab K., Hefeeda M.",2,Cooperative active distribution of videos in telco-CDNs,2017,0,"School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",Simon Fraser University,1,Canada,1,12,12,"Telco-CDNs are ISP-managed CDNs deployed inside ISP networks. We propose a new content distribution system inside telco-CDN called CAD. In CAD, Content Provider and ISP collaborate to distribute multimedia content to users inside the ISP network. CAD manages both the overlay and underlay of the network to reduce the ISP interdomain traffic, improve the service latency, and minimize the intradomain link utilization. CAD achieves these goals by allowing caching servers to fetch content from other caching servers, and create videos on-demand inside the telco-CDN. We propose an algorithm to calculate the overlay and underlay of the CAD-managed telco-CDN in polynomial time. Compared against the closest approach in the literature, our initial results showed that CAD achieves up to 30% reduction in the interdomain traffic and up to 230% improvement in the service latency, while not increasing the intradomain link utilization. © 2017 ACM.",Content Distribution; TE; Telco-CDN,Grid computing; Polynomial approximation; Tellurium; Active distributions; Content distribution; Content distribution systems; Content providers; Inter-domain traffic; Link utilization; Multimedia contents; Telco-CDN; Internet service providers
"Bao J., Zhao B., Dong D., Gong Z.",4,HERO: A hybrid electrical and optical multicast for accelerating high-performance data center applications,2017,2,"College of Computer, National University of Defense Technology, Changsha, Hunan, China",National University of Defense Technology,1,China,1,4,4,"This paper presents HERO, a system for accelerating high performance data center applications by integrating hybrid electrical and optical multicast. We built a prototype and developed a flow-level simulator to evaluate the performance of HERO. Experiment and simulation results show that HERO reduces the average MFCT by _32% and_28% compared to OCS and EPS multicast, respectively. © 2017 ACM.",Data Center Network; Multicast; Optical Network,Fiber optic networks; Data center networks; Flow-level simulators; Optical multicast; Performance data; Multicasting
"Sperotto A., Van Der Toorn O., Van Rijswijk-Deij R.",3,TIDE - Threat identification using active DNS measurements,2017,1,"University of Twente, Netherlands; University of Twente, SURFnet Bv, Netherlands",University of Twente,1,Netherlands,1,6,5,"The Domain Name System contains a wealth of information about the security, stability and health of the Internet. Most research that leverages the DNS for detection of malicious activities does so by using passive measurements. The limitation of this approach, however, is that it is effective only once an attack is ongoing. In this paper,we explore a different approach.We advocate the use of active DNS measurements for pro-active (i.e., before the actual attack) identification of domains set up for malicious use. Our research makes uses of data from the OpenINTEL large-scale active DNS measurement platform, which, since February 2015, collects daily snapshots of currently more than 60% of the DNS namespace. We illustrate the potential of our approach by showing preliminary results in three case studies, namely snowshoe spam, denial of service attacks and a case of targeted phishing known as CEO fraud. © 2017 ACM.",Active measurements; DNS; Network security,Computer crime; Denial-of-service attack; Network security; Active measurement; Case-studies; Domain name system; Malicious activities; Namespaces; Passive measurements; Threat identification; Wealth of information; Internet protocols
"Yi B., Xia J., Chen L., Chen K.",4,Towards zero copy dataflows using RDMA,2017,1,"HKUST, Hong Kong",Hong Kong University of Science and Technology,1,Hong Kong,1,5,5,"Remote Direct Memory Access (RDMA) offers ultra-low latency and CPU bypass networking to application programmers. Existing applications are often designed around socket based software stack that manages application buffers separately from networking buffers and do memory copies between them when sending/receiving data. With large sized (up to hundreds MB) application buffers, the cost of such copies adds non trivial overhead to the end-to-end communication pipeline. In thiswork,we made an attempt to design a zero copy transport for distribute dataflow frameworks that unifies application and networking buffer management and completely eliminates unnecessary memory copies. Our prototype on top of TensorFlow shows 2.43x performance improvement over gRPC based transport and 1.21x performance improvement over an alternative RDMA transport with private buffers and memory copies. © 2017 ACM.",Kernel bypass networking; Memory management,Application programmers; Buffer management; End-to-End communication; Kernel bypass; Low latency; Memory management; Remote direct memory access; Software stacks; Application programs
"Friebe S., Florian M.",2,"DPS-discuss: Demonstrating decentralized, pseudonymous, sybil-resistant communication",2017,0,"Institute of Telematics, Karlsruhe, Germany; Bundesdruckerei GmbH, Berlin, Germany",Bundesdruckerei GmbH,1,Germany,1,6,4,"A current trend on the Internet is the increasing surveillance of its users. A few big service providers have divided most of the user-facing Internet between them, observing and recording the activities of their users to increase profits. Additionally, government agencies have been found to practice mass surveillance. With regard to this it becomes even more important to provide online services that protect the privacy of their users and avoid censorship by single, powerful entities. To reach these goals, a trusted third party should be avoided. A prototype service which fulfills these goals is DPS-Discuss, a decentralized, pseudonymous online discussion application. It uses the libraries BitNym and Peer-Tor-Peer for pseudonym management and anonymous communication. © 2017 ACM.",Bitcoin; Censorship; Pseudonymity; Sybil-Resistance; Tor,Anonymous communication; Bitcoin; Censorship; Government agencies; Online discussions; Pseudonymity; Service provider; Trusted third parties; Network security
"Gao Q., Dey P., Ahammad P.",3,Perceived performance of Top Retail webpages in the wild: Insights from large-scale crowdsourcing of above-the-fold QoE,2017,2,"Instart Logic Inc., 450 Lambert Ave, Palo Alto, CA, United States",Instart Logic Inc.,1,USA,1,21,11,"Clearly, no one likes webpages with poor quality of experience (QoE). Being perceived as slow or fast is a key element in the overall perceived QoE of web applications. While extensive effort has been put into optimizing web applications (both in industry and academia), not a lot of work exists in characterizing what aspects of webpage loading process truly influence human end-user's perception of the Speed of a page. In this paper we present SpeedPerception 1, a large-scale web performance crowdsourcing framework focused on understanding the perceived loading performance of above-the-fold (ATF) webpage content. Our end goal is to create free open-source benchmarking datasets to advance the systematic analysis of how humans perceive webpage loading process. In Phase-1 of our SpeedPerception study using Internet Retailer Top 500 (IR 500) websites [3], we found that commonly used navigation metrics such as onLoad and Time To First Byte (TTFB) fail (less than 60% match) to represent majority human perception when comparing the speed of two webpages. We present a simple 3-variable-based machine learning model that explains the majority end-user choices better (with 87 ± 2% accuracy). In addition, our results suggest that the time needed by end-users to evaluate relative perceived speed of webpage is far less than the time of its visualComplete event. © 2017 Association for Computing Machinery.",Above-the-fold; Crowdsourcing; OnLoad; Perceived speed; Perceptual SpeedIndex; Quality of experience; SpeedIndex; TTFB; Web performance,Convolutional codes; Crowdsourcing; Learning systems; Open systems; Websites; Above-the-fold; OnLoad; Perceptual SpeedIndex; Quality of experience (QoE); SpeedIndex; TTFB; Web performance; Quality of service
"Tasiopoulos A.G., Atarashi R., Psaras I., Pavlou G.",4,On the bitrate adaptation of Shared Media Experience Services,2017,0,"University College London, United Kingdom; IIJ-Innovation Institute, Japan",IIJ Research Laboratory;University College London,2,Japan;UK,2,18,14,"In Shared Media Experience Services (SMESs), a group of people is interested in streaming consumption in a synchronised way, like in the case of cloud gaming, live streaming, and interactive social applications. However, group synchronisation comes at the expense of other Quality of Experience (QoE) factors due to both the dynamic and diverse network conditions that each group member experiences. Someone might wonder if there is a way to keep a group synchronised while maintaining the highest possible QoE for each one of its members. In this work, at first we create a Quality Assessment Framework capable of evaluating different SMESs improvement approaches with respect to traditional metrics like media bitrate quality, playback disruption, and end user desynchronisation. Secondly, we focus on the bitrate adaptation for improving the QoE of SMESs, as an incrementally deployable end user triggered approach, and we formulate the problem in the context of Adaptive Real Time Dynamic Programming (ARTDP). Finally, we develop and apply a simple QoE aware bitrate adaptation mechanism that we compare against youtube live-streaming traces to find that it improves the youtube performance by more than 30%. © 2017 Association for Computing Machinery.",Bitrate adaptation; QoE assessment framework; Shared media experience services (SMESs),Convolutional codes; Dynamic programming; Media streaming; Synchronization; Video streaming; Adaptation mechanism; Bit rates; QoE assessment framework; Quality assessment; Quality of experience (QoE); Real-time dynamic programming; Shared media experience services (SMESs); Social applications; Quality of service
"Trevisan M., Drago I., Mellia M.",3,PAIN: A passive web speed indicator for ISPs,2017,2,"Politecnico di Torino, Italy",Politecnico di Torino,1,Italy,1,13,13,"Understanding the quality of web browsing enjoyed by users is key to optimize services and keep users' loyalty. This is crucial for Internet Service Providers (ISPs) to anticipate problems. Quality is subjective, and the complexity of today's pages challenges its measurement. OnLoad time and SpeedIndex are notable attempts to quantify web performance. However, these metrics are computed using browser instrumentation and, thus, are not available to ISPs. PAIN (PAssive INdicator) is an automatic system to observe the performance of web pages at ISPs. It leverages passive flow-level and DNS measurements which are still available in the network despite the deployment of HTTPS. With unsupervised learning, PAIN automatically creates a model from the timeline of requests issued by browsers to render web pages, and uses it to analyze the web performance in real-time. We compare PAIN to indicators based on in-browser instrumentation and find strong correlations between the approaches. It reflects worsening network conditions and provides visibility into web performance for ISPs. © 2017 Association for Computing Machinery.",Machine learning; Passive measurements; QoE metrics,Convolutional codes; Health; HTTP; Learning systems; Websites; Automatic systems; Flow level; In browsers; Network condition; Passive measurements; QoE metrics; Strong correlation; Web performance; Internet service providers
"Borchert K., Hirth M., Zinner T., Gšritz A.",4,Designing a survey tool for monitoring enterprise QoE,2017,2,"Department of Communication Networks, University of Wurzburg, Germany; Occupational and Consumer Psychology, Freiburg University, Germany",Freiburg University;University of Wurzburg,2,Germany,1,16,13,"Enterprise applications like SAP are part of the day-to-day work of a large number of employees. Similar to many modern applications, enterprise applications are often implemented in a distributed fashion and consequently sufer from network degradations resulting in impairments like increased loading delays. While the inluence of these impairments on the perceived quality of users is well researched for consumer applications and network services, the impact of these impairments in a business environment is yet to be investigated. To address this gap we develop a non-intrusive software tool for continuously collecting subjective ratings on the performance of an enterprise application from a large number of employees. Based on the feedback from a company and results from two initial ield studies we discuss the speciic challenges when assessing the perceived quality of employees during regular working hours and point out our further research directions. © 2017 Association for Computing Machinery.",Enterprise; Quality of experience; User study,Application programs; Convolutional codes; Industry; Business environments; Consumer applications; Enterprise applications; Modern applications; Network degradations; Quality of experience (QoE); Subjective rating; User study; Quality of service
"Wamser F., Hšfner S., Seufert M., Tran-Gia P.",4,Server and content selection for MPEG DASH video streaming with client information,2017,0,"Department of Communication Networks, University of WŸrzburg, WŸrzburg, Germany",University of Wurzburg,1,Germany,1,10,10,"In HTTP adaptive streaming (HAS), such as MPEG DASH, the video is split into chunks and is available in different quality levels. If the video chunks are stored or cached on different servers to deal with the high load in the network and the Quality of Experience (QoE) requirements of the users, the problem of content selection arises. In this paper, we evaluate client-side algorithms for dynamically selecting an appropriate content server during DASH video streaming. We present three algorithms with which the DASH client itself can determine the most appropriate server based on client-specific metrics, like actual latency or bandwidth to the content servers. We evaluate and discuss the proposed algorithms with respect to the resulting DASH streaming behavior in terms of buffer levels and quality level selection. © 2017 Association for Computing Machinery.",Client-based access for cloud services; Cloud services; Quality of experience,Convolutional codes; Distributed database systems; HTTP; Motion Picture Experts Group standards; Quality control; Video streaming; Web services; Adaptive streaming; Buffer levels; Client specific; Cloud services; Content servers; Quality levels; Quality of experience (QoE); Server-based; Quality of service
"Zimmermann T., Wolters B., Hohlfeld O.",3,A QoE perspective on HTTP/2 server push,2017,1,"Communication and Distributed Systems, RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,24,19,"HTTP/2 was recently standardized to optimize the Web by promising faster Page Load Times (PLT) as compared to the widely deployed HTTP/1.1. One promising feature is HTTP/2 server push, which turns the former pull-only into a push-enabled Web. By enabling servers to preemptively push resources to the clients without explicit request, it promises further improvements of the overall PLT. Despite this potential, it remains unknown if server push can indeed yield human perceivable improvements. In this paper, we address this open question by assessing server push in both i) a laboratory and ii) a crowdsourcing study. Our study assesses the question if server push can lead to perceivable faster PLTs as compared to HTTP/1.1 and HTTP/2 without push. We base this study on a set of 28 push-enabled real-word websites selected in an Internet-wide measurement. Our results reveal that our subjects are able to perceive utilization of server push. However, its usage does not necessarily accomplish perceived PLT improvements and can sometimes even be noticeably detrimental. © 2017 Association for Computing Machinery.",HTTP/2 server push; Quality of experience; User study,Convolutional codes; Quality of service; Quality of experience (QoE); Server pushes; User study; Wide measurement; HTTP
"Khokhar M.J., Saber N.A., Spetebroot T., Barakat C.",4,On active sampling of controlled experiments for QoE modeling,2017,3,"UniversitŽ C™te d'Azur, Inria, France",UniversitŽ C™te DAzur,1,France,1,17,12,"For internet applications, measuring, modeling and predicting the quality experienced by end users as a function of network conditions is challenging. A common approach for building application specific Quality of Experience (QoE) models is to rely on controlled experimentation. For accurate QoE modeling, this approach can result in a large number of experiments to carry out because of the multiplicity of the network features, their large span (e.g., bandwidth, delay) and the time needed to setup the experiments themselves. However, most often, the space of network features in which experimentations are carried out shows a high degree of uniformity in the training labels of QoE. This uniformity, difficult to predict beforehand, amplifies the training cost with little or no improvement in QoE modeling accuracy. So, in this paper, we aim to exploit this uniformity, and propose a methodology based on active learning, to sample the experimental space intelligently, so that the training cost of experimentation is reduced. We prove the feasibility of our methodology by validating it over a particular case of YouTube streaming, where QoE is modeled both in terms of interruptions and stalling duration. © 2017 Association for Computing Machinery.",Active learning; Controlled experimentation; Internet measurement; Quality of experience; YouTube,Artificial intelligence; Convolutional codes; Quality control; Active Learning; Controlled experimentation; Internet measurement; Quality of experience (QoE); YouTube; Quality of service
"Bajpai V., Ott J., KŸhlewind M., Trammell B., SchšnwŠlder J., Sperotto A.",6,Challenges with reproducibility,2017,6,"TU Munich, Germany; ETH ZŸrich, Switzerland; Jacobs University Bremen, Germany; University of Twente, Netherlands",ETH Zurich;Jacobs University of Bremen;TU Munich;University of Twente,4,Germany;Netherlands;Switzerland,3,26,25,"The Computer Science (CS) culture is gentle to accepting papers that are non-reproducible as long as they appear plausible. In this paper, we discuss some of the challenges with reproducibility and a set of recommendations that we as a community can undertake to initiate a cultural change. © 2017 Association for Computing Machinery.",Reproducibility,Cultural changes; Reproducibilities
"Flittner M., Bauer R., Rizk A., Gei§ler S., Zinner T., Zitterbart M.",6,Taming the complexity of artifact reproducibility,2017,2,"Technische UniversitŠt Darmstadt, Germany; University of WŸrzburg, Germany; Karlsruhe Institute of Technology, Germany",Karlsruhe Institute of Technology;TU Darmstadt;University of Wurzburg,3,Germany,1,20,12,"Reproducing research results, as it is required for peer review, can be a time-consuming and difficult task. In this work, we propose three approaches to improve the way of how research results can be substantiated and discuss their applicability. Our proposals are based on a brief study on evaluation methods (for SDN research) and insights from a comprehensive discussion on reproducibility. © 2017 Association for Computing Machinery.",Artifact review; Evaluation; Reproducibility,Evaluation; Evaluation methods; Peer review; Reproducibilities; Research results
"Ferreira D.C., V‡zquez F.I., Vormayr G., Bachl M., Zseby T.",5,A meta-Analysis approach for feature selection in network traffic research,2017,4,"Institute of Telecom., TU Wien, Gusshausstrasse 25 / E389, Vienna, 1040, Austria",TU Wien,1,Austria,1,9,8,"The selection of features for network traffic analysis and anomaly detection is a challenge for experts who aim to build systems that discover traffic patterns, characterize networks, and improve security. There are no major guidelines or best practices for feature selection in the field. The literature is full of different proposals that ultimately depend on feature availability, types of known traffic, tool limitations, specific goals, and, fundamentally, the experts' knowledge and intuition. In this work we have revisited 71 principal publications in the field of network traffic analysis from 2005 to 2017. Relevant information has been curated according to formalized data structures and stored in JSON format, creating a database for the smart retrieval of network traffic analysis researches. Metaanalysis performed upon the explored publications disclosed a set of main features that are common in a considerable volume of works and could be used as a baseline for future research. Additionally, aiming for validation and generalization in network traffic research, the creation of such meta-Analysis environments is highly valuable. It allows homogenizing and joining criteria for the design of experiments, thus avoiding getting lost or becoming irrelevant due to the high complexity and variability that network traffic analysis involves. © 2017 Association for Computing Machinery.",Feature selection; Meta-Analysis; Network traffic analysis,Design of experiments; Anomaly detection; Best practices; Build systems; High complexity; In networks; Meta analysis; Network traffic analysis; Traffic pattern; Feature extraction
"Scheitle Q., WŠhlisch M., Gasser O., Schmidt T.C., Carle G.",5,Towards an ecosystem for reproducible research in computer networking,2017,17,"Technical University of Munich, Germany; Freie UniversitŠt Berlin, Germany; HAW Hamburg, Germany",Freie UniversitŠt Berlin;TU Munich,2,Germany,1,9,4,"Reproducibility is key to rigorous scientific progress. However, many publications in the computer networks community lack support for reproducibility. In this paper, we argue that the lack is mainly rooted in the additional effort that authors need to spend, without expecting sufficient benefits. Based on our experience in both authoring reproducible research and reproducing publications, we propose an ecosystem that incentivizes authors and reproducers to invest additional effort. This ecosystem consists of various building blocks, which can be combined into venue-specific profiles. A key building block is the Reproducibility Challenge, which we suggest to co-locate with the annual SIGCOMM conference to leverage reproducibility research in practice. © 2017 Association for Computing Machinery.",Networks; Reproducibility; Reproducibility challenge,Ecology; Ecosystems; Networks (circuits); Building blockes; Computer networking; Reproducibilities; Reproducible research; Scientific progress; Specific profile; Computer networks
Nussbaum L.,1,Testbeds support for reproducible research,2017,1,"Inria, Villers-ls-Nancy, F-54600, France; UniversitŽ de Lorraine, LORIAF-54500, France; CNRS, LORIA, UMR 7503F-54500, France",UniversitŽ de Lorraine,1,France,1,15,12,"In the context of experimental research, testbeds play an important role in enabling reproducibility of experiments, by providing a set of services that help experiments with setting up the experimental environment, and collecting data about it. This paper explores the status of three different testbeds (Chameleon, CloudLab and Grid'5000) regarding features required for, or related to reproducible research, and discusses some open questions on that topic. © 2017 Association for Computing Machinery.",Experimentation; Reproducible research; Testbeds,Experimental environment; Experimental research; Experimentation; Reproducibilities; Reproducible research; Testbeds
"Canini M., Crowcroft J.",2,Learning reproducibility with a yearly networking contest,2017,4,"KAUST, Saudi Arabia; University of Cambridge, United Kingdom",University of Cambridge,1,Saudi Arabia;UK,2,33,21,"Better reproducibility of networking research results is currently a major goal that the academic community is striving towards. This position paper makes the case that improving the extent and pervasiveness of reproducible research can be greatly fostered by organizing a yearly international contest. We argue that holding a contest undertaken by a plurality of students will have benefits that are two-fold. First, it will promote hands-on learning of skills that are helpful in producing artifacts at the replicable-research level. Second, it will advance the best practices regarding environments, testbeds, and tools that will aid the tasks of reproducibility evaluation committees by and large. © 2017 Association for Computing Machinery.",Design contest; Gamification; Reproducible research,Academic community; Design contests; Gamification; Hands-on learning; Position papers; Reproducibilities; Reproducible research; Research results; Education
"Mahfoudi M.N., Turletti T., Parmentelat T., Dabbous W.",4,Lessons learned while trying to reproduce the OpenRF experiment,2017,1,"UniversitŽ C™te D'Azur, Inria, France",UniversitŽ C™te DAzur,1,France,1,3,3,"Evaluating and comparing performance of wireless systems, like for any other scientific area, requires the ability to reproduce experimental results. In this paper, we describe the specific issues that we encountered when focusing on reproducing the experiments described in a paper related to wireless systems. We selected the OpenRF paper published in SIGCOMM 2013, a very interesting research work allowing to perform beamforming on commodity WiFi devices. We illustrate how reproducibility is strongly dependent on the used hardware, and why an extensive knowledge of the used hardware and its design is necessary. On the basis of this experience, we propose some recommendations and lessons for the design of reproducible wireless experiments. © 2017 Association for Computing Machinery.",Reproducibility,Reproducibilities; Wireless systems; Hardware
"Panwar G., Tourani R., Mick T., Mtibaa A., Misra S.",5,DICE: Dynamic multi-RAT selection in the ICN-enabled wireless edge,2017,3,"New Mexico State University, United States",New Mexico State University,1,Mexico;USA,2,22,17,"Coupled with the rapid increase in mobile device users and the bandwidth and latency demands are the continuous increase of devices' processing capabilities, storage, and wireless connectivity options. The multiple radio access technology (multi-RAT) is proposed to satisfy mobile users' increasing needs. The Information-Centric Networking (ICN) paradigm isbetter tuned (than the current Internet Protocol approach) to support multi-RAT communications. ICN eschews the connection-based content retrieval model used today and has desirable features such as data naming, in-network caching, and device mobility - a paradigm ripe for exploration. We propose DICE, an ICN forwarding strategy that helps a device dynamically select a subset of its multi-RAT interfaces for communication. DICE assesses the state of edge links and network congestion to determine the minimum number of interfaces required to to perform data delivery. We perform simulations to compare DICE's performance with bestroute2 and multicast strategies (part of the named data networking simulator, ndnSIM). We show that DICE is the best of both worlds: providing a higher delivery ratio (0.2-2 times) and much lower overhead (by 2-8 times) for different packet rates. © 2017 Association for Computing Machinery.",5G; Forwarding strategy; ICN; Multi-RAT; NDN,Digital storage; Interface states; Mobile devices; Mobile telecommunication systems; Network architecture; Desirable features; Forwarding strategies; Information-centric networkings (ICN); Mobile device users; Named data networkings; Network congestions; Processing capability; Wireless connectivities; Rats
Chakareski J.,1,"VR/AR immersive communication: Caching, edge computing, and transmission trade-offs",2017,5,"University of Alabama, United States",University of Alabama,1,USA,1,30,22,"We study the delivery of 360 ¡ -navigable videos to 5G VR/AR wireless clients in future cooperative multi-cellular systems. A collection of small-cell base stations interconnected via back-haul links are sharing their caching and computing resources to maximize the aggregate reward they earn by serving 360 ¡ videos requested by VR/AR wireless clients. We design an efficient representation method to construct the 360 ¡ videos such that they only deliver the remote scene viewpoint content genuinely needed by the VR/AR user, thereby overcoming the present highly inefficient approach of sending a bulky 360 ¡ video, whose major part comprises scene information never accessed by the user.Moreover, we design an optimization framework that allows the base stations to select cooperative caching/rendering/streaming strategies that maximize the aggregate reward they earn when serving the users, for the given caching/computational resources at each base station. We formulate the problem of interest as integer programming, show its NPhardness, and derive a fully-polynomial-time approximation solution with strong performance guarantees. Our advances demonstrate orders of magnitude operational efficiency gains over stateof- the-art caching and 360 ¡ video representation mechanisms and are very promising. This is a first-of-its-kind study to explore fundamental trade-offs between caching, computing, and communication for emerging VR/AR applications of broad societal impact. © 2017 Copyright held by the owner/author(s).",360 ¡ video; Small-cell networks; Virtual/augmented reality,Aggregates; Augmented reality; Base stations; Commerce; Integer programming; Polynomial approximation; Polynomials; Virtual reality; Fully polynomial time approximation; Operational efficiencies; Optimization framework; Performance guarantees; Representation method; Small cell Networks; Video representations; Virtual/augmented reality; Economic and social effects
"Avino G., Malinverno M., Malandrino F., Casetti C., Chiasserini C.F.",5,Characterizing docker overhead in mobile edge computing scenarios,2017,1,"Politecnico di Torino, Torino, Italy",Politecnico di Torino,1,Italy,1,14,6,"Mobile Edge Computing (MEC) is an emerging network paradigm that provides cloud and IT services at the point of access of the network. Such proximity to the end user translates into ultra-low latency and high bandwidth, while, at the same time, it alleviates traffic congestion in the network core. Due to the need to run servers on edge nodes (e.g., an LTE-A macro eNodeB), a key element of MEC architectures is to ensure server portability and low overhead. A possible tool that can be used for this purpose is Docker, a framework that allows easy, fast deployment of Linux containers. This paper addresses the suitability of Docker in MEC scenarios by quantifying the CPU consumed by Docker when running two different containerized services: multiplayer gaming and video streaming. Our tests, run with varying numbers of clients and servers, yield different results for the two case studies: for the gaming service, the overhead logged by Docker increases only with the number of servers; conversely, for the video streaming case, the overhead is not affected by the number of either clients or servers. © 2017 Association for Computing Machinery.",5G networks; Containers; Docker; Mobile edge computing,Computer operating systems; Containers; Traffic congestion; Video streaming; Docker; Edge computing; Fast deployments; G-networks; High bandwidth; Low overhead; Multi-player gaming; Network core; Distributed computer systems
"Hurtig P., Alfredsson S., Brunstrom A., Evensen K., Grinnemo K.-J., Hansen A.F., Rozensztrauch T.",7,A NEAT approach to mobile communication,2017,0,"Karlstad University, Sweden; Celerway Communications, Sweden",Karlstad University,1,Sweden,1,21,21,"The demands for mobile communication is ever increasing. Mobile applications are increasing both in numbers and in heterogeneity of their requirements, and an increasingly diverse set of mobile technologies are employed. This creates an urgent need for optimizing end-to-end services based on application requirements, conditions in the network and available transport solutions; something which is very hard to achieve with today's internet architecture. In this paper, we introduce the NEAT transport architecture as a solution to this problem. NEAT is designed to offer a flexible and evolvable transport system, where applications communicate their transport-service requirements to the NEAT system in a generic, transport-protocol independent way. The best transport option is then configured at run-time based on application requirements, network conditions, and available transport options. Through a set of real life mobile use case experiments, we demonstrate how applications with different properties and requirements could employ the NEAT system in multi-access environments, showing significant performance benefits as a result. © 2017 Copyright held by the owner/author(s).",3G; 4G; Cellular; Heterogeneity; LTE; MPTCP; Multiple paths; NEAT; Policies; TCP; Transport selection; WLAN,Network architecture; Public policy; Transportation; Wireless telecommunication systems; Cellular; Heterogeneity; MPTCP; Multiple-path; NEAT; Transport selection; WLAN; Mobile telecommunication systems
"Blšcher M., Viering M., Schmid S., Eugster P.",4,The grand CRU challenge,2017,0,"Department of Computer Science, TU Darmstadt, Darmstadt, Germany; Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, TU Berlin, Berlin, Germany; Department of Computer Science, Purdue University, West Lafayette, United States",Aalborg University;Purdue University;TU Berlin;TU Darmstadt,4,Denmark;Germany;USA,3,10,10,"One of the main objectives of any cluster management system is the maximization of cluster resource utilization (CRU). In this paper, we argue that there is a dilemma underlying the challenge of maximizing CRU, as soon as network resources enter the picture. In contrast to local resources which can be handled in a more isolated fashion, global network resources are namely shared, and their allocation is intertwined with that of local resources. For effective resource management, either applications thus have to learn more about the infrastructure, or the resource manager has to understand application semantics - both options violate the separation of applications from the underlying infrastructure strived for by resource managers. This paper makes the case for a resource management system that addresses the dilemma, and presents first ideas. © 2017 Association for Computing Machinery.",Cloud computing; Cluster scheduling; Resource manager architecture,Cloud computing; Cluster computing; Containers; Managers; Natural resources management; Resource allocation; Semantics; Application Semantics; Cluster management system; Cluster scheduling; Network resource; Resource management; Resource management systems; Resource managers; Resource utilizations; Distributed computer systems
"Zhang L., Amin S.O., Westphal C.",3,VR video conferencing over named data networks,2017,4,"Huawei Research Center, Santa Clara, CA  95050, United States",Huawei Technologies,1,USA,1,15,14,"We propose a VR video conferencing system over named data networks (NDN). The system is designed to support real-time, multi-party streaming and playback of 360 degree video on a web player. A centralized architecture is used, with a signaling server to coordinate multiple participants. To ensure real-time requirement, a protocol featuring prefetching is used for producer-consumer communication. Along with the native support of multicast in NDN, this design is expected to better support large amount of data streaming between multiple users. As a proof of concept, a protoype of the system is implemented with one-way real-time 360 video streaming. Experiments showthat seamless streaming and interactive playback of 360 video can be achieved with low latency. Therefore, the proposed system has the potential to provide immersive VR experience for real-time multi-party video conferencing. © 2017 Association for Computing Machinery.",Named data networking; Virtual reality,Augmented reality; Virtual reality; Centralized architecture; Data streaming; Multi-party video conferencing; Named data networkings; Named data networks; Proof of concept; Real time requirement; Video conferencing system; Video conferencing
"Shafagh H., Hithnawi A.",2,Privacy-preserving quantified self: Secure sharing and processing of encrypted small data,2017,1,"Department of Computer Science, ETH Zurich, Switzerland",ETH Zurich,1,Switzerland,1,46,39,"The emergence of a plethora of wearables and sensing technologies has enabled non-intrusive digitization of our daily physical activities. Emerging applications utilize such data to make inferences about our physiological and health states, provide health diagnosis, and contribute to wellbeing improvements. The common approach for such applications is to collect data, either using mobile applications or special hardware, e.g., wearables, and store them on a third party storage provider. This results in many unconnected data silos of self-quantification data. Researchers and industry, advocate for a common personal storage space, to conquer the myriad of small chunks of data, deemed to be lost/forgotten in the long term. The benefits of such co-located personal data are tremendous, specifically with regards to personalized medicine, treatment, and health care. However, the centralized storage of data exacerbates the privacy and security concerns that the IoT ecosystem is facing today. In this position paper, we advocate the necessity of privacy and security guarantees for the paradigm of co-located storage of personal health data. We envision two core security functionalities: true end-to-end encryption, such that only encrypted data is stored in the cloud and secure sharing of encrypted data, without disclosing data owner's secret keys. We discuss the challenges in adopting such an end-to-end encryption paradigm while preserving the cloud's basic processing functionalities over encrypted data and how to cryptographically enforce access control. © 2017 Copyright is held by the owner/author(s).",Encrypted processing; Homomorphic encryption; IoT; Privacy; Secure sharing,Access control; Cryptography; Diagnosis; Digital storage; Internet of things; Wearable technology; Emerging applications; End-to-end encryption; Ho-momorphic encryptions; Mobile applications; Personalized medicines; Privacy and security; Processing functionality; Secure sharing; Data privacy
"Duanmu F., Kurdoglu E., Hosseini S.A., Liu Y., Wang Y.",5,Prioritized buffer control in two-tier 360 video streaming,2017,8,"New York University, Tandon School of Engineering, Brooklyn, NY  11201, United States",NYU,1,USA,1,15,15,"360 degree video compression and streaming is one of the key components of Virtual Reality (VR) applications. In 360 video streaming, a user may freely navigate through the captured 3D environment by changing her desired viewing direction. Only a small portion of the entire 360 degree video is watched at any time. Streaming the entire 360 degree raw video is therefore unnecessary and bandwidthconsuming. One the other hand, only streaming the video in the predicted user's view direction will introduce streaming discontinuity whenever the the prediction is wrong. In this work, a two-tier 360 video streaming framework with prioritized buffer control is proposed to effectively accommodate the dynamics in both network bandwidth and viewing direction. Through simulations driven by real network bandwidth and viewing direction traces, we demonstrate that the proposed framework can significantly outperform the conventional 360 video streaming solutions. © 2017 Association for Computing Machinery.",360 degree video; Buffer control; Video streaming; Virtual reality,Augmented reality; Bandwidth; Video streaming; Virtual reality; 3-D environments; 360 degree video; Buffer control; Network bandwidth; Real networks; Two tiers; View directions; Viewing directions; Image compression
"Peiro Sajjad H., Hakimzadeh K., Perera S.",3,Reproducible distributed clusters with mutable containers: To minimize cost and provisioning time,2017,0,"Royal Institute of Technology, Stockholm, Sweden",KTH Royal Institute of Technology,1,Sweden,1,29,24,"Reproducible and repeatable provisioning of large-scale distributed systems is laborious. The cost of virtual infrastructure and the provisioning complexity are two of the main concerns. The trade-offs between virtual machines (VMs) and containers, the most popular virtualization technologies, further complicate the problem. Although containers incur little overhead compared to VMs, VMs are required for their certain guarantees such as hardware isolation. In this paper, we present a mutable container provisioning solution, enabling users to switch infrastructure between VMs and containers seamlessly. Our solution allows for significant infrastructure-cost optimizations. We discuss that immutable containers come short for certain provisioning scenarios. However, mutable containers can incur a large time overhead. To reduce the time overhead, we propose multiple provisioning-time optimizations. We implement our solution in Karamel, an open-sourced reproducible provisioning system. Based on our evaluation results, we discuss the cost-optimization opportunities and the time-optimization challenges of our new model. © 2017 Association for Computing Machinery.",Cloud; Containers; Mutable; Provisioning; Reproducible clusters,Clouds; Costs; Economic and social effects; Distributed clusters; Infrastructure costs; Large-scale distributed system; Mutable; Provisioning; Reproducible clusters; Virtual infrastructures; Virtualization technologies; Containers
"Morabito R., Beijar N.",2,A framework based on SDN and containers for dynamic service chains on IoT gateways,2017,4,"Ericsson Research, NomadicLab, Finland",Ericsson Research,1,Finland,1,14,13,"In this paper, we describe a new approach for managing service function chains in scenarios where data from Internet of Things (IoT) devices is partially processed at the network edge. Our framework is enabled by two emerging technologies, Software-Defined Networking (SDN) and container based virtualization, which ensure several benefits in terms of flexibility, easy programmability, and versatility. These features are well suitable with the increasingly stringent requirements of IoT applications, and allow a dynamic and automated network service chaining. An extensive performance evaluation, which has been carried out by means of a testbed, seeks to understand how our proposed framework performs in terms of computational overhead, network bandwidth, and energy consumption. By accounting for the constraints of typical IoT gateways, our evaluation tries to shed light on the actual deployability of the framework on low-power nodes. © 2017 Association for Computing Machinery.",Container virtualization; Internet of things; Microservices; Service chaining; Software defined networking,Chains; Containers; Energy utilization; Network function virtualization; Software defined networking; Virtual reality; Virtualization; Computational overheads; Emerging technologies; Internet of Things (IOT); Microservices; Service chaining; Service functions; Software defined networking (SDN); Stringent requirement; Internet of things
"Afzal S., Chen J., Ramakrishnan K.K.",3,Characterization of 360-degree videos,2017,10,"University of California, Riverside, United States",University of California Riverside,1,USA,1,19,13,"Online streaming of Virtual Reality and 360¡ videos is rapidly growing, as more and more major content providers and news outlets adopt the format to enrich the user experience. We characterize 360¡ videos by examining several thousand YouTube videos across more than a dozen categories. 360¡ videos, at first sight, seem to pose a challenge for the network to stream because of their substantially higher bit rates and larger number of resolutions. However, a careful examination of video characteristics reveals that there are significant opportunities for reducing the actual bit rate delivered to client devices based on the user's field of view. We study the bit rate and the motion in 360¡ videos, and compare them against regular videos by investigating several important metrics. We find that 360¡ videos are less variable in terms of bit rate, and have less motion than regular videos. Our expectation is that variability in the bit rates due to the motion of the camera in regular videos (or switching between cameras) is now translated to responsiveness requirements for end to end 360¡ streaming architectures. © 2017 Association for Computing Machinery.",360¡ videos; Measurements; Video delivery,Augmented reality; Cameras; Measurements; Bit rates; Client devices; Content providers; End to end; Field of views; Streaming architecture; User experience; Video delivery; Virtual reality
"Sheoran A., Sharma P., Fahmy S., Saxena V.",4,Contain-ed: An NFV micro-service system for containing e2e latency,2017,0,"Purdue University, United States; Hewlett Packard Labs, United States; Hewlett Packard Enterprise, United States",Purdue University,1,USA,1,16,8,"Network Functions Virtualization (NFV) has enabled operators to dynamically place and allocate resources for network services to match workload requirements. However, unbounded end-toend (e2e) latency of Service Function Chains (SFCs) resulting from distributed Virtualized Network Function (VNF) deployments can severely degrade performance. In particular, SFC instantiations with inter-data center links can incur high e2e latencies and Service Level Agreement (SLA) violations. These latencies can trigger timeouts and protocol errors with latency-sensitive operations. Traditional solutions to reduce e2e latency involve physical deployment of service elements in close proximity. These solutions are, however, no longer viable in the NFV era. In this paper, we present our solution that bounds the e2e latency in SFCs and inter-VNF control message exchanges by creating micro-service aggregates based on the affinity between VNFs. Our system, Contain-ed, dynamically creates and manages affinity aggregates using light-weight virtualization technologies like containers, allowing them to be placed in close proximity and hence bounding the e2e latency. We have applied Contain-ed to the Clearwater IP Multimedia System and built a proof-of-concept. Our results demonstrate that, by utilizing application and protocol specific knowledge, affinity aggregates can effectively bound SFC delays and significantly reduce protocol errors and service disruptions. © 2017 Association for Computing Machinery.",Containers; Network functions virtualization,Aggregates; Containers; Multimedia systems; Transfer functions; Virtual reality; Virtualization; IP multimedia system; Network functions; Network services; Service disruptions; Service functions; Service Level Agreements; Specific knowledge; Virtualization technologies; Network function virtualization
"Duarte J.M., Braun T., Villas L.A.",3,Receiver mobility in vehicular named data networking,2017,4,"University of Bern, Switzerland; IC, University of Campinas, Brazil",University of Bern;University of Campinas,2,Brazil;Switzerland,2,13,10,"This work investigates the topic of Vehicular Named Data Networking (VNDN). We propose a new VNDN routing protocol and address the negative effects caused by receiver mobility. In particular, we identify the problem of Reverse Path Partitioning (RPP) that often prevents Data messages from reaching Content Requesters, degrading application performance. To mitigate RPP we propose a mechanism called Auxiliary Forwarding Set (AFS). AFS takes several mobility factors as inputs and extends the NDN core philosophy by identifying an extra set of eligible nodes to forward Data messages whenever retransmissions are required due to RPP. Simulation results show that AFS is an efficient and scalable solution to improve VNDN application performance regardless of receiver mobility. © 2017 Association for Computing Machinery.",Named-data networking; Receiver mobility; Vehicular Ad-hoc networks; Vehicular named-data networking,Ad hoc networks; Network architecture; Application performance; Data messages; Mobility factors; Named data networkings; Retransmissions; Reverse path; Scalable solution; Vehicular ad hoc networks
"Mangiante S., Klas G., Navon A., GuanHua Z., Ran J., Dias Silva M.",6,VR is on the edge: How to deliver 360- videos in mobile networks,2017,10,"Vodafone Group R and D, Newbury, United Kingdom; Huawei, Network Technology Lab., Israel; Huawei, Network Technology Lab., Nanjing, China",Vodafone,1,China;Israel;UK,3,15,10,"VR/AR is rapidly progressing towards enterprise and end customers with the promise of bringing immersive experience to numerous applications. Soon it will target smartphones from the cloud and 360¡ video delivery will need unprecedented requirements for ultralow latency and ultra-high throughput to mobile networks. Latest developments in NFV and Mobile Edge Computing reveal already the potential to enable VR streaming in cellular networks and to pave the way towards 5G and next stages in VR technology. In this paperwe present a Field Of View(FOV) rendering solution at the edge of a mobile network, designed to optimize the bandwidth and latency required by VR 360¡ video streaming. Preliminary test results show the immediate benefits in bandwidth saving this approach can provide and generate new directions for VR/AR network research. © 2017 Copyright held by the owner/author(s).",360¡ video delivery; Edge computing; Field of view; Mobile network,Augmented reality; Bandwidth; Virtual reality; Wireless networks; Bandwidth savings; Cellular network; Edge computing; End customers; Field of views; Latest development; Video delivery; VR technology; Mobile telecommunication systems
"Cozzolino V., Yi Ding A., Ott J.",3,FADES: Fine-grained edge offloading with unikernels,2017,5,"Technical University of Munich, Germany",TU Munich,1,Germany,1,17,17,"FADES is an edge offloading architecture that empowers us to run compact, single purpose tasks at the edge of the network to support a variety of IoT and cloud services. The design principle behind FADES is to efficiently exploit the resources of constrained edge devices through fine-grained computation offloading. FADES takes advantage of MirageOS unikernels to isolate and embed application logic in concise Xen-bootable images.We have implemented FADES and evaluated the system performance under various hardware and network conditions. Our results show that FADES can effectively strike a balance between running complex applications in the cloud and simple operations at the edge. As a solid step to enable finegrained edge offloading, our experiments also reveal the limitation of existing IoT hardware and virtualization platforms, which shed light on future research to bring unikernel into IoT domain. © 2017 Association for Computing Machinery.",Edge computing; IoT; Virtualization,Computation theory; Containers; Hardware; Virtual reality; Virtualization; Application logic; Cloud services; Complex applications; Design Principles; Edge computing; Fine-grained computation; Network condition; Simple operation; Internet of things
Siris V.A.,1,Popularity-aware intra-domain mobility management,2017,1,"Mobile Multimedia Laboratory, Department of Informatics, School of Information Sciences and Technology, Athens University of Economics and Business, Greece",Athens University of Economics and Business,1,Greece,1,17,12,"We present and evaluate a popularity-aware intra-domain mobile content management model based on which the Name Resolution System (NRS) is updated with the current location of mobile content only when the content has sufficiently high popularity and sufficiently low mobility. Specifically, the current location of mobile content is updated only when the overall cost of location updates is smaller than the cost of broadcasting location queries. On the other hand, the location of content with low popularity and high mobility that is not tracked by the NRS is discovered by broadcasting location queries. Our evaluation investigates how the performance gains of the proposed model, in terms of reduced total signaling cost and reduced memory requirements of the NRS, depend on the aggregate content request rate, content mobility (rate of content location changes), number of content objects, content popularity, and correlation between content popularity and mobility. © 2017 Association for Computing Machinery.",Internet of mobile things; Mobile content; Name resolution,Costs; Aggregate contents; Content popularities; Location queries; Mobile content; Mobility management; Name resolution; Performance Gain; Reduced memory requirements; Location
"Zhao Y., Xia N., Tian C., Li B., Tang Y., Wang Y., Zhang G., Li R., Liu A.X.",9,Performance of container networking technologies,2017,2,"State Key Laboratory for Novel, Software Technology, Nanjing University, Nanjing, 210023, China; Future Network Theory Lab, Huawei, Hongkong999077, China; College of Computer Science and Network Security, Dongguan University of Technology, Dongguan, 523808, China; Department of Computer Science and Engineering, Michigan State University, East Lansing, 48824, United States",Dongguan University of Technology;Michigan State University;Nanjing University,3,China;USA,2,10,8,"Container networking is now an important part of cloud virtualization architectures. It provides network access for containers by connecting both virtual and physical network interfaces. The performance of container networking has multiple dependencies, and each factor may significantly affect the performance. In this paper, we perform systematic experiments to study the performance of container networking technologies. For every measurement result, we try our best to qualify influencing factors. © 2017 Association for Computing Machinery.",Container; Measurement; Networking,Measurements; Multiple dependencies; Network access; Networking; Networking technology; Systematic experiment; Containers
Kano M.,1,BlueSkyNet: BLE multi-hop network management architecture,2017,0,"Intel Corporation, United States",Intel,1,USA,1,13,12,"Bluetooth Low Energy (BLE) is aimed for Internet of Things (IoT) devices with limited battery capacity and small bandwidth. Despite the increasing number of IoT devices and the improving performance of BLE, the usage model is still limited to point-to-point with no mobility. This limitation prevents the devices to spread across a large field or a home. While multi-hop technologies had been studied and commercialized, they do not fully take advantage of the BLE's low-power feature; and their configurations cannot easily be changed once the network is deployed. We have designed an architecture called BlueSkyNet. It allows network administrators to form and manage a BLE multi-hop network that allows nodes to be mobile. It takes advantage of the improving performance of BLE, and allows the network configurations to be modified in a software-defined way. © 2017 Association for Computing Machinery.",Bluetooth Low Energy; Multi-hop network,Bluetooth; Internet of things; Network architecture; Network management; Battery capacity; Bluetooth low energies (BLE); Bluetooth low energies (BTLE); Improving performance; Internet of Things (IOT); Multihop networks; Network administrator; Network configuration; Low power electronics
"Ran X., Chen H., Liu Z., Chen J.",4,Delivering deep learning to mobile devices via offloading,2017,5,"University of California, Riverside, United States; College of William and Mary, United States",College of William and Mary;University of California Riverside,2,USA,1,32,31,"Deep learning has the potential to make Augmented Reality (AR) devices smarter, but few AR apps use such technology today because it is compute-intensive, and front-end devices cannot deliver sufficient compute power. We propose a distributed framework that ties together front-end devices with more powerful back-end ""helpers"" that allow deep learning to be executed locally or to be offloaded. This framework should be able to intelligently use current estimates of network conditions and back-end server loads, in conjunction with the application's requirements, to determine an optimal strategy. This work reports our preliminary investigation in implementing such a framework, in which the front-end is assumed to be smartphones. Our specific contributions include: (1) development of an Android application that performs real-time object detection, either locally on the smartphone or remotely on a server; and (2) characterization of the tradeoffs between object detection accuracy, latency, and battery drain, based on the system parameters of video resolution, deep learning model size, and offloading decision. © 2017 Association for Computing Machinery.",Neural networks; Offloading; Wireless,Augmented reality; Neural networks; Object detection; Object recognition; Radio; Smartphones; Virtual reality; Android applications; Current estimates; Detection accuracy; Distributed framework; Front-end devices; Offloading; Optimal strategies; Video resolutions; Deep learning
"Ju R., He J., Sun F., Li J., Li F., Zhu J., Han L.",7,Ultra wide view based panoramic VR streaming,2017,8,"Huawei Techologies, Nanjing, 211100, China",Huawei Technologies,1,China,1,15,12,"Online VR streaming faces great challenges such as the high throughput and real time interaction requirement. In this paper, we propose a novel ultra wide view based method to stream high quality VR on Internet at low bandwidth and little computation cost. First, we only transmit the region where user is looking at instead of full 360 ¡ view to save bandwidth. To achieve this goal, we split the source VR into small grid videos in advance. The grid videos are able to reconstruct any view flexibly in user end. Second, according to the fact that users generally interact at low speed, we expand the view that user requested to meet the real time interaction requirement. Besides, a low resolution full view stream is supplied to handle exceptional cases such as high speed view change. We test our solution in an experimental network. The results show remarkable bandwidth saving of over 60% in average at little computation cost while supplying the same quality of experience as local VR. © 2017 Association for Computing Machinery.",Low latency; Video streaming; Virtual reality,Augmented reality; Bandwidth; Communication channels (information theory); Quality of service; Video streaming; Bandwidth savings; Computation costs; High throughput; Low latency; Low resolution; Low-bandwidth; Quality of experience (QoE); Real time interactions; Virtual reality
"Kang H., Tao S.",2,Container-based emulation of network control plane,2017,1,"IBM Research, Yorktown Heights, NY  10598, United States",IBM,1,USA,1,32,29,"An ongoing challenge in network system development is in evaluating the design and implementation of its control plane, without actually deploying it at production scale. Existing approaches based on simulation or emulation have various limitations. The emergence of containers oers a new way of emulating network control plane. In this paper, we design a container-based emulation framework, and introduce its implementation with two concrete use cases: a centralized SDN control plane design in Open Virtual Network (OVN) and a decentralized design in Docker's libnetwork. Through sample scalability studies on these two designs, we demonstrate the effectiveness of the proposed approach. © 2017 Association for Computing Machinery.",Container; Emulation; Scalability; SDN,Scalability; Control planes; Decentralized design; Design and implementations; Emulation; Emulation framework; Network control plane; Production scale; Virtual networks; Containers
"Shang J., Wu J.",2,A robust sign language recognition system with multiple Wi-Fi devices,2017,1,"Department of Computer and Information Sciences, Temple University, Philadelphia, PA  19122, United States",Temple University,1,USA,1,11,9,"Sign language is important since it provides a way for us to the deaf culture and more opportunities to communicate with those who are deaf or hard of hearing. Since sign language chiefly uses body languages to convey meaning, Human Activity Recognition (HAR) techniques can be used to recognize them for some sign language translation applications. In this paper, we show for the first time that Wi-Fi signals can be used to recognize sign language. The key intuition is that different hand and arm motions introduce different multi-path distortions in Wi-Fi signals and generate different unique patterns in the time-series of Channel State Information (CSI). More specifically, we propose a Wi-Fi signal-based sign language recognition system called WiSign. Different from existing Wi-Fi signal-based human activity recognition systems, WiSign uses 3 Wi-Fi devices to improve the recognition performance. We implemented the WiSign using a TP-Link TL-WR1043ND Wi-Fi router and two Lenovo X100e laptops. The evaluation results show that our system can achieve a mean prediction accuracy of 93.8% and mean false positive of 1.55%. © 2017 Association for Computing Machinery.",Human activity recognition; Machine learning; Signal processing; Wi-Fi signals,Audition; Channel state information; Learning systems; Pattern recognition; Signal processing; Evaluation results; False positive; Hard of hearings; Human activity recognition; Human activity recognition systems; Prediction accuracy; Sign Language recognition; Wi-Fi signals; Wireless local area networks (WLAN)
"Zhang W., Han B., Hui P.",3,On the networking challenges of mobile Augmented Reality,2017,7,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, Hong Kong; AT and T Labs Research, 1 AT and T Way, Bedminster, NJ  07921, United States",AT and T Labs;Hong Kong University of Science and Technology,2,Hong Kong;USA,2,21,20,"In this paper, we conduct a reality check for Augmented Reality (AR) on mobile devices. We dissect and measure the cloud-offloading feature for computation-intensive visual tasks of two popular commercial AR systems. Our key finding is that their cloud-based recognition is still not mature and not optimized for latency, data usage and energy consumption. In order to identify the opportunities for further improving the Quality of Experience (QoE) for mobile AR, we break down the end-to-end latency of the pipeline for typical cloud-based mobile AR and pinpoint the dominating components in the critical path. © 2017 Association for Computing Machinery.",Augmented Reality; Cloud offloading; End-to-end latency; Networking challenges; Reality check,Augmented reality; Energy utilization; Green computing; Mobile telecommunication systems; Quality of service; Virtual reality; Vision; Computation intensives; Critical Paths; End to end latencies; Mobile augmented reality; Networking challenges; Quality of experience (QoE); Reality check; Visual tasks; Distributed computer systems
"Zhang Y., Gu J., Lee Y., Chowdhury M., Shin K.G.",5,Performance isolation anomalies in RDMA,2017,2,"University of Michigan, United States",University of Michigan at Ann Arbor,1,USA,1,25,22,"To meet the increasing throughput and latency demands of modern applications, many operators are rapidly deploying RDMA in their datacenters. At the same time, developers are re-designing their software to take advantage of RDMA's benefits for individual applications. However, when it comes to RDMA's performance, many simple questions remain open. In this paper, we consider the performance isolation characteristics of RDMA. Specifically, we conduct three sets of experiments -three combinations of one throughput-sensitive flow and one latency-sensitive flow -in a controlled environment, observe large discrepancies in RDMA performance with and without the presence of a competing flow, and describe our progress in identifying plausible root-causes. © 2017 Copyright held by the owner/author(s).",Fairness; Performance isolation; RDMA,Computer networks; Information systems; Competing flow; Controlled environment; Fairness; Isolation characteristics; Modern applications; Performance isolation; RDMA; Sensitive flow; Application programs
"Vasilakos X., Al-Khalidi M., Siris V.A., Reed M.J., Thomos N., Polyzos G.C.",6,Mobility-based proactive multicast for seamless mobility support in cellular network environments,2017,0,"Department of Informatics, School of Information Sciences and Technology, Athens University of Economics and Business, 76 Patission Str., Athens, GR 10434, Greece; School of Computer Science and Electronic Engineering, University of Essex, Wivenhoe Park, Colchester, CO4 3SQ, United Kingdom",Athens University of Economics and Business;University of Essex,2,Greece;UK,2,22,13,"Information-Centric Networking (ICN) is receiver driven, asynchronous and location-independent, hence it natively supports client-mobility. However, post-handover delay is a problem for delay-sensitive mobile applications, as they need to (re-)submit their subscriptions and wait for them to get resolved and (probably re-) transmitted before receiving the demanded data. To avoid this problem and optimize performance, this paper proposes a Mobilitybased Proactive Multicast (MPM) scheme. Unlike reactive or blind multicast solutions proposed in the past, MPM takes autonomous decisions locally at various network access points (cells) prior to the movement of mobile clients, using a semi-Markov mobility prediction model that predicts next-cell transitions, along with anticipating the duration between the transitions for an arbitrary user in a cellular network. Since cellular backhaul links are typically a bottleneck, MPM trades-off effectively part of the capacity of the (congested) backhaul link for a decreased delay experienced by users after handovers thanks to a congestion pricing scheme used for backhaul capacity allocation. Our preliminary performance evaluation results show that MPM captures well the temporal locality of mobile requests due to the semi-Markov mobility prediction model, hence it achieves a better performance compared to both a (i) blind/na•ve multicast and a (ii) content popularity-based proactive multicast. © 2017 Association for Computing Machinery.",Markov; Mobility prediction; Proactive multicast,Forecasting; Mobile telecommunication systems; Traffic congestion; Wireless networks; Capacity allocation; Content popularities; Information-centric networkings (ICN); Location independent; Markov; Mobility predictions; Multicast solutions; Seamless mobility support; Multicasting
"Sagari S.S., Mathur S., Saha D., Amin S.O., Ravindran R., Seskar I., Raychaudhuri D., Wang G.",8,Realization of CDMA-based IoT services with shared band operation of LTE in 5G,2017,1,"Huawei Research CenterCA, United States; WINLAB, Rutgers UniversityNJ, United States; University at Albany, SUNYNY, United States",Huawei Technologies;Rutgers University;SUNY Albany,3,USA,1,15,13,"5G network is geared towards massive deployment of Internet-of- Things (IoTs) with requirements of low end-to-end latency, low control overhead and low power transmissions. Current 4G network is optimized for large bandwidth applications and inefficient to handle short sporadic IoT messages. This paper focuses on low power underlay CDMA access for IoT devices considering eventdriven and latency sensitive traffic profile, thus will significantly reduce the access time. We propose a PHY/MAC layer design for CDMA based communication for IoT devices. We evaluate coexisting operation of CDMA based IoT network in presence of the exiting LTE network. Our proposed protocol will integrate IoT traffic with legacy system by minimal modification at the edge network, essentially eNodeB. We show that the underlay CDMA IoT network meets IoT data traffic requirements with minimal degradation (_ 3%) to the LTE throughput. We also implement the proposed design using Software Defined Radios and show the viability of the proposal under different network scenarios. © 2017 Association for Computing Machinery.",5G; CDMA; Experimentation; Internet of Things (IoT); LTE; Openairinterface; System modeling; USRP,5G mobile communication systems; Bandwidth; Code division multiple access; Legacy systems; Low power electronics; Mobile telecommunication systems; Queueing networks; Radio communication; Software radio; Wireless telecommunication systems; Experimentation; Internet of Things (IOT); Openairinterface; System modeling; USRP; Internet of things
"Qian P., Wang N., Oh B.-H., Ge C., Tafazolli R.",5,Optimization of webpage downloading performance with content-aware mobile edge computing,2017,0,"5GIC, Institute for Communication Systems, University of Surrey, Guildford, GU2 7XH, United Kingdom",University of Surrey,1,UK,1,15,11,"With increased complexity of webpages nowadays, computation latency incurred by webpage processing during downloading operations has become a newly identified factor that may substantially affect user experiences in a mobile network. In order to tackle this issue, we propose a simple but effective transport-layer optimization technique which requires necessary context information dissemination from the mobile edge computing (MEC) server to user devices where such an algorithm is actually executed. The key novelty in this case is the mobile edge's knowledge about webpage content characteristics which is able to increase downloading throughput for user QoE enhancement. Our experiment results based on a real LTE-A test-bed show that, when the proportion of computation latency varies between 20% and 50% (which is typical for today's webpages), the downloading throughput can be improved up to 34.5%, with reduced downloading time by up to 25.1% c. Copyright 2017 ACM.",Computation time; Mobile computing; Webpage downloading,Information dissemination; Mobile computing; Computation time; Content-aware; Downloading time; Edge computing; Optimization techniques; Transport layers; User devices; User experience; Websites
"Cardoso K.V., Abdel-Rahman M.J., MacKenzie A.B., DaSilva L.A.",4,Virtualization and programmability in mobile wireless networks: Architecture and resource management,2017,1,"Universidade Federal de Goi‡s, Goi‰nia, GO, Brazil; Wireless at Virginia Tech, Blacksburg, VA, United States; Trinity College Dublin, Dublin, Ireland",Trinity College Dublin;Universidade Federal de Goi‡s;Virginia Tech,3,Brazil;Ireland;USA,3,17,17,"We present a high-level end-to-end architecture for virtualization and programmability in next-generation mobile wireless networks. Our architecture envisions three major players: Service Providers, who wish to orchestrate wireless networks with particular characteristics to support particular applications; Resource Providers, who contribute resources such as spectrum, access points, backhaul infrastructure, and computing; and Virtual Network Builders, who marshal resources into networks for Service Providers.We take into account resource sharing and investigate how virtualization and programmability a#ect resource management. We show that: (i) virtualization reduces cost significantly, (ii) this cost reduction does not degrade the user satisfaction, and (iii) non-virtualized networks need to keep a large amount of idle capacity to satisfy coverage. © 2017 Association for Computing Machinery.",Probabilistic resource allocation; Two-stage sequential optimization; Wireless network virtualization,Cost reduction; Distributed computer systems; Internet service providers; Natural resources management; Resource allocation; Virtual reality; Virtualization; Wireless networks; Mobile wireless network; Network virtualization; Resource management; Resource providers; Resource sharing; Sequential optimization; User satisfaction; Virtual networks; Network architecture
"Duan Y., Gallo M., Traverso S., Laufer R., Giaccone P.",5,Towards a scalable modular QUIC server,2017,0,"Politecnico di Torino, Italy; Nokia Bell Labs, United States",Nokia,1,Italy;USA,2,30,17,"QUIC has been recently proposed as an alternative transport protocol for web services requiring both low latency and end-to-end encryption. In a different direction, recent kernel-bypass techniques enabling high-speed packet I/O have fostered the development of scalable middleboxes and servers with the introduction of userspace network stacks. Attempting to join the best of both solutions, we introduce in this paper a modular L2-L7 network stack in user space based on QUIC. Our modular and scalable QUIC transport protocol called cQUIC is implemented in Click and uses IntelR DPDK for high-speed packet I/O. We prototype cQUIC and show at least an order of magnitude improvement over the Google QUIC server. We also show that cQUIC scalability is CPU (and not I/O) bounded due to the high cost of cryptographic operations. From real-world traffic traces, we observe that up to 18% of QUIC connections are established using the expensive 2-RTT handshake, limiting scalability further. © 2017 Copyright held by the owner/author(s).",Application layer; Network stack; Transport protocol,Cryptography; Network layers; Scalability; Web services; Application layers; Cryptographic operations; End-to-end encryption; Kernel bypass; Middleboxes; Network stack; Traffic traces; Transport protocols; Internet protocols
"Primorac M., Bugnion E., Argyraki K.",3,How to measure the killer microsecond,2017,3,"EPFL, Switzerland","EPFL, Switzerland",1,Switzerland,1,27,24,"Datacenter-networking research requires tools to both generate traffic and accurately measure latency and throughput. While hardwarebased tools have long existed commercially, they are primarily used to validate ASICs and lack flexibility, e.g., to study new protocols. They are also too expensive for academics. The recent development of kernel-bypass networking and advanced NIC features such as hardware timestamping have created new opportunities for accurate latency measurements. This paper compares these two approaches, and in particular whether commodity servers and NICs, when properly configured, can measure the latency distributions as precisely as specialized hardware. Our work shows that well-designed commodity solutions can capture subtle differences in the tail latency of stateless UDP traffic. We use hardware devices as the ground truth, both to measure latency and to forward traffic. We compare the ground truth with observations that combine five latency-measuring clients and five different port forwarding solutions and configurations. State-of-theart software such as MoonGen that uses NIC hardware timestamping provides sufficient visibility into tail latencies to study the effect of subtle operating system configuration changes. We also observe that the kernel-bypass-based TRex software, that only relies on the CPU to timestamp traffic, can also provide solid results when NIC timestamps are not available for a particular protocol or device. © Copyright 2017 held by Owner/Author. Publication rights licensed to ACM.",Microsecond latency,Computer hardware; Negative impedance converters; Ground truth; Hardware devices; Kernel bypass; Latency measurements; Microsecond latency; Specialized hardware; System configurations; Timestamping; Hardware
"Raman A., Sastry N., Sathiaseelan A., Chandaria J., Secker A.",5,Wi-stitch: Content delivery in converged edge networks,2017,4,"King's College London, United Kingdom; University of Cambridge, United Kingdom; BBC R and D, United Kingdom",BBC R and D;Kings College London;University of Cambridge,3,UK,1,30,24,"Wi-Fi, the most commonly used access technology at the very edge, supports download speeds that are orders of magnitude faster than the average home broadband or cellular data connection. Furthermore, it is extremely common for users to be within reach of their neighbours' Wi-Fi access points. Given the skewed nature of interest in content items, it is likely that some of these neighbours are interested in the same items as the users. We sketch the design of Wi-Stitch, an architecture that exploits these observations to construct a highly efficient content sharing infrastructure at the very edge and show through analysis of a real workload that it can deliver substantial (up to 70%) savings in network traffic. The Wi- Stitch approach can be used both by clients of fixed-line broadband, as well as mobile devices obtaining indoors access in converged networks. © 2017 Copyright held by the owner/author(s).",Content sharing; Edge cooperation; Wifi offloading,Access technology; Content delivery; Content Sharing; Converged networks; Edge cooperation; Orders of magnitude; Wi-fi access points; Wi-Fi offloading; Wireless local area networks (WLAN)
"Vasilescu L., Olteanu V., Raiciu C.",3,Sharing CPUs via endpoint congestion control,2017,1,"University Politehnica of Bucharest, Splaiul Independentei 313a, Bucharest, Romania",University Politehnica of Bucharest,1,Romania,1,14,11,"Software network processing relies on dedicated cores and hardware isolation to ensure appropriate throughput guarantees. Such isolation comes at the expense of low utilization in the average case, and severely restricts the number of network processing functions one can execute on a host. In this paper we propose that multiple processing functions should simply share a CPU core, turning the CPU into a special type of ""link"".We use multiple NIC receive queues and the FastClick suite to test the feasibility of this approach.We find that, as expected, per core throughput decreases when more processes are contending; however the decrease is not dramatic: Around 10% drop with 10 processes, and 50% in the worst case where the processing is very cheap (bridging). We also find that the processor is not shared fairly when the different functions have different per packet costs. Finally, we implement and test in simulation a solution that enables efficient CPU sharing by sending congestion signals proportional to per-packet cost for each flow. This enables endpoint congestion control (e.g. TCP) to react appropriately and share the CPU fairly. © 2017 Copyright held by the owner/author(s).",Congestion control; CPU sharing,Computer networks; Congestion control (communication); Information systems; Average case; CPU cores; Dedicated cores; Multiple processing; Network processing; Software network; Throughput guarantees; Program processors
"Shpiner A., Zahavi E., Dahley O., Barnea A., Damsker R., Yekelis G., Zus M., Kuta E., Baram D.",9,RoCE rocks without PFC: Detailed evaluation,2017,1,"Mellanox Technologies, Yokneam, Israel","Mellanox Technologies, Israel",1,Israel,1,14,14,"In recent years, the usage of RDMA in data center networks has increased significantly, with RDMA over Converged Ethernet (RoCE) emerging as the canonical approach for deployingRDMAin Ethernetbased data centers. Initial implementations of RoCE required a lossless fabric for optimal performance. This is typically achieved by enabling Priority Flow Control (PFC) on Ethernet NICs and switches. The RoCEv2 specification introduced RoCE congestion control, which allows throttling the transmission rate in response to congestion. Consequently, packet loss is minimized and performance is maintained, even if the underlying Ethernet network is lossy. In this paper, we discuss the latest developments in RoCE congestion control. Hardware congestion control reduces the latency of the congestion control loop; it reacts promptly in the face of congestion by throttling the transmission rate quickly and accurately. The short control loop also prevents network buffers from overfilling under various congestion scenarios. In addition, fast hardware retransmission complements congestion control in severe congestion scenarios, by significantly reducing the performance penalty of packet drops. We survey architectural features that allow deployment of RoCE over lossy networks and present real lab test. © 2017 Copyright held by the owner/author(s).",Congestion control; Performance; RoCE,Congestion control (communication); Ethernet; Hardware; Packet loss; Architectural features; Data center networks; Latest development; Optimal performance; Performance; Performance penalties; RoCE; Transmission rates; Packet networks
"Mohan N., Zhou P., Govindaraj K., Kangasharju J.",4,Managing data in computational edge clouds,2017,4,"University of Helsinki, Finland; Robert Bosch GmbH, Germany",Robert Bosch GmbH;University of Helsinki,2,Finland;Germany,2,16,16,"Edge clouds handle data and computations closer to its source and users. Applications like industrial automation, bring new challenges and require solutions tailored for computationcentric edge cloud networks. In this paper we build on existing edge and fog computing models and develop a solution to predict and store data in edge resource caches for upcoming computations. Our solution is based on grouping caches according to the workloads they serve. We further develop methods for populating the caches and ensuring the coherence of the cached data. We evaluate the performance of our grouping mechanisms and show that they bring significant performance gains, both in terms of network traffic and access latency. © 2017 Association for Computing Machinery.",Cache groups; Edge caching; Edge cloud; Fog cloud,Cache groups; Computing model; Edge caching; Edge clouds; Edge resources; Industrial automation; Network traffic; Performance Gain; Distributed computer systems
"Liu G., Ramakrishnan K.K., Schlansker M., Tourrilhes J., Wood T.",5,"Design challenges for high performance, scalable NFV interconnects",2017,2,"George Washington University, United States; University of California, Riverside, United States; Hewlett Packard Labs, United States",George Washington University;University of California Riverside,2,USA,1,19,14,"Software-based network functions (NFs) have seen growing interest. Increasingly complex functionality is achieved by having multiple functions chained together to support the required networkresident services. Network Function Virtualization (NFV) platforms need to scale and achieve high performance, potentially utilizing multiple hosts in a cluster. Efficient data movement is crucial, a cornerstone of kernel bypass. Moving packet data involves delivering the packet from the network interface to an NF, moving it across functions on the same host, and finally across yet another network to NFs running on other hosts in a cluster/data center. In this paper we measure the performance characteristics of different approaches for moving data at each of these levels. We also introduce a new high performance inter-host interconnect using InfiniBand. We evaluate the performance of Open vSwitch and the OpenNetVM NFV platform, considering a simple forwarding function and Snort, a popular intrusion detection system. © 2017 Association for Computing Machinery.",Network function virtualization; RDMA; Service chaining,Intrusion detection; Transfer functions; Virtual reality; Virtualization; Data movements; Design challenges; Intrusion Detection Systems; Multiple function; Network functions; Performance characteristics; RDMA; Service chaining; Network function virtualization
"Ristov S., Weinsberg Y., Dolev D., Anker T.",4,LogMemcached an RDMA based continuous cache replication,2017,1,"Hebrew University of Jerusalem, Israel; Microsoft, United States; Mellanox Technologies, Israel",Hebrew University of Jerusalem;Microsoft,2,Israel;USA,2,14,7,"One of the advantages of cloud computing is its ability to quickly scale out services to meet demand. A common technique to mitigate the increasing load in these services is to deploy a cache. Although it seems natural that the caching layer would also deal with availability and fault tolerance, these issues are nevertheless often ignored, as the cache has only recently begun to be considered a critical system component. A cache may evict items at any moment, and so a failing cache node can simply be treated as if the set of items stored on that node have already been evicted. However, setting up a cache instance is a time-consuming operation that could inadvertently affect the service's operation. This paper addresses this limitation by introducing cache replication at the server side by expanding Memcached (which currently provides availability via client side replication). This paper presents the design and implementation of LogMemcached, a modification of Memcached's internal data structures to include state replication via RDMA to provide an increased system availability, improved failure resilience and enhanced load balancing capabilities without compromising performance and with introducing a very low CPU load, while keeping the main principles of Memcached's Design Philosophy. © 2017 Association for Computing Machinery.",Availability; Cache replication; Memcached; RDMA,Fault tolerance; Cache replication; Design and implementations; Design philosophy; Failure resilience; Memcached; RDMA; State replications; System availability; Availability
"Tseng J., Wang R., Tsai J., Wang Y., Tai T.-Y.C.",5,Accelerating Open vSwitch with integrated GPU,2017,1,"Intel Labs, United States",Intel,1,USA,1,27,21,"With the fast development of Software Defined Networking (SDN) and network virtualization, software-based network virtual switches have emerged as a critical component to provide network services to VMs. Among virtual switches, Open vSwitch (OvS) is an open source virtual switch implementation commonly used and well-studied. Using Data Plane Development Kit (DPDK) with OvS to bypass the OS kernel and process packets in userspace provides tremendous performance benefits on general purpose platforms. Integrated GPUs, residing on the same die with the CPU on general purpose platforms, offering many advanced features such as on-chip interconnect CPU-GPU communication, and sharing physical/virtual memory, become a promising additional compute resource to further accelerate the OvS process. In this paper, we design and implement an inline GPU assisted OvS architecture, via offloading the expensive tuple space search to GPU and balancing switching processing between CPU and GPU. We evaluated the performance on an Intel¨ Xeon¨ processor of the E3-1575M v5 product family (code-name Skylake) with an integrated GT4e GPU. The results show that our proposed architecture improved the OvS throughput by 3x, compared to the optimized CPU-only OvS-DPDK implementation. © Copyright 2017 ACM.",Integrated GPU; Open vSwitch; Software defined networking; Software packet processing; Tuple space search; Virtual switch,Memory architecture; Network architecture; Network function virtualization; Open source software; Program processors; Software defined networking; Design and implements; Network virtualization; Open vswitch; Packet processing; Performance benefits; Proposed architectures; Software defined networking (SDN); Tuple space search; Graphics processing unit
"Grewe D., Wagner M., Arumaithurai M., Psaras I., Kutscher D.",5,Information-centric mobile edge computing for connected vehicle environments: Challenges and research directions,2017,13,"Robert Bosch GmbH, Corporate Sector Research and Advance Engineering, Renningen, Germany; University of Goettingen, Institute of Computer Science, Goettingen, Germany; University College London, Dept. of Electronic and Electrical Engineering, London, United Kingdom; Huawei German Research Center, Munich, Germany",Huawei Technologies;Robert Bosch GmbH;University College London;University of Goettingen,4,Germany;UK,2,34,22,"Connected vehicle systems form the basis for future features of functions and applications within the automotive domain. In order to allow resource intensive services, cloud offloading and especially Mobile Edge Computing is a promising approach. In this paper, we present a detailed futuristic vehicular scenario - Electronic Horizon - and list the challenges. We argue that the resulting challenges are representative of many of the envisioned use-cases of Mobile Edge Computing .We then present how Information-Centric Networking in combination with Mobile Edge Computing has the potential to support such a futuristic scenario. Finally, we present research directions that could enhance the solution space. © 2017 Copyright held by the owner/author(s).",Connected vehicles; Electronic horizon; Information-centric networking; Mobile edge computing; Vehicular networks,Automotive domains; Edge computing; Electronic horizon; Information-centric; Information-centric networkings; Solution space; Vehicle system; Vehicular networks; Vehicles
"Prasad A.S., Arumaithurai M., Koll D., Fu X.",4,RAERA: A robust auctioning approach for edge resource allocation,2017,2,"University of Goettingen, Germany",University of Goettingen,1,Germany,1,34,34,"In edge computing, content and service providers aim at enhancing user experience by providing services closer to the user. At the same time, infrastructure providers such as access ISPs aim at utilizing their infrastructure by selling edge resources to these content and service providers. In this context, auctions are widely used to set a price that reflects supply and demand in a fair way. In this work, we propose RAERA, the first robust auction scheme for edge resource allocation that is suitable to work with the market uncertainty typical for edge resources-here, customers typically have different valuation distribution for a wide range of heterogeneous resources. Additionally, RAERA encourages truthful bids and allows the infrastructure provider to maximize its break-even profit. Our preliminary evaluations highlight that REARA offers a time dependent fair price. Sellers can achieve higher revenue in the range of 5%-15% irrespective of varying demands and the buyers pay up to 20% lower than their top bid amount. © 2017 Association for Computing Machinery.",Auctions; Mobile edge computing; Pricing; Robust optimization,Commerce; Costs; Economics; Optimization; Resource allocation; Sales; Auctions; Edge computing; Heterogeneous resources; Infrastructure providers; Market uncertainty; Robust optimization; Service provider; Supply and demand; Resource valuation
"Yu Y., Li X., Qian C.",3,SDLB: A scalable and dynamic software load balancer for fog and Mobile Edge Computing,2017,5,"University of Kentucky, United States; University of California, Santa Cruz, United States",University of California Santa Cruz;University of Kentucky,2,USA,1,22,18,"Mobile Edge Computing (MEC) provides computing/storage offloading and resource virtualization to mobile devices at the network edge. A load balancer is a necessary network function to determine the destination MEC host of each packet from a mobile device, for such virtualization. Due to the new characteristics of MEC, such as resource limitation and high dynamics, existing solutions of cloud load balancer cannot be directly applied to MEC. This paper presents a new design of a Scalable and Dynamic Load Balancer, called SDLB, that satisfies the requirements of MEC. The core algorithm of SDLB is minimal perfect hashing, which provides two perfect features as a load balancer. Evaluation results show that SDLB is faster by 4_ to 10_ and uses much less (< 50%) memory, than a widely-used load balancer design for cloud. © 2017 Copyright held by the owner/author(s).",Mobile Edge Computing; Network functions virtualization; Software load balancer,Dynamic loads; Mobile devices; Transfer functions; Virtual reality; Virtualization; Dynamic softwares; Edge computing; Evaluation results; Load balancer; Minimal perfect hashing; Network functions; Resource limitations; Resource Virtualization; Network function virtualization
"Mao H., Netravali R., Alizadeh M.",3,Neural adaptive video streaming with pensieve,2017,43,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,29,26,"Client-side video players employ adaptive bitrate (ABR) algorithms to optimize user quality of experience (QoE). Despite the abundance of recently proposed schemes, state-of-the-art ABR algorithms suffer from a key limitation: they use fixed control rules based on simplified or inaccurate models of the deployment environment. As a result, existing schemes inevitably fail to achieve optimal performance across a broad set of network conditions and QoE objectives. We propose Pensieve, a system that generates ABR algorithms using reinforcement learning (RL). Pensieve trains a neural network model that selects bitrates for future video chunks based on observations collected by client video players. Pensieve does not rely on pre-programmed models or assumptions about the environment. Instead, it learns to make ABR decisions solely through observations of the resulting performance of past decisions. As a result, Pensieve automatically learns ABR algorithms that adapt to a wide range of environments and QoE metrics.We compare Pensieve to state-of-theart ABR algorithms using trace-driven and real world experiments spanning a wide variety of network conditions, QoE metrics, and video properties. In all considered scenarios, Pensieve outperforms the best state-of-the-art scheme, with improvements in average QoE of 12%-25%. Pensieve also generalizes well, outperforming existing schemes even on networks for which it was not explicitly trained. © 2017 ACM.",Bitrate adaptation; Reinforcement learning; Video streaming,Convolutional codes; Learning algorithms; Reinforcement learning; Video streaming; Adaptive video streaming; Bit rates; Network condition; Neural network model; Optimal performance; Quality of experience (QoE); Real world experiment; State of the art; Quality of service
"Kassing S., Valadarsky A., Shahaf G., Schapira M., Singla A.",5,"Beyond fat-trees without antennae, mirrors, and disco-balls",2017,6,"ETH ZŸrich, Switzerland; Hebrew University of Jerusalem, Switzerland",ETH Zurich;Hebrew University of Jerusalem,2,Switzerland,1,53,45,"Recent studies have observed that large data center networks often have a few hotspots while most of the network is underutilized. Consequently, numerous data center network designs have explored the approach of identifying these communication hotspots in real-time and eliminating them by leveraging flexible optical or wireless connections to dynamically alter the network topology. These proposals are based on the premise that statically wired network topologies, which lack the opportunity for such online optimization, are fundamentally inefficient, and must be built at uniform full capacity to handle unpredictably skewed traffic. We show this assumption to be false. Our results establish that state-of-the-art static networks can also achieve the performance benefits claimed by dynamic, reconfigurable designs of the same cost: for the skewed traffic workloads used to make the case for dynamic networks, the evaluated static networks can achieve performance matching full-bandwidth fat-trees at two-thirds of the cost. Surprisingly, this can be accomplished even without relying on any form of online optimization, including the optimization of routing configuration in response to the traffic demands. Our results substantially lower the barriers for improving upon today's data centers by showing that a static, cabling-friendly topology built using commodity equipment yields superior performance when combined with well-understood routing methods. © 2017 ACM.",Data center; Routing; Topology,Antennas; Convolutional codes; Forestry; Optical communication; Topology; Data center networks; Data centers; Online optimization; Performance benefits; Performance matching; Reconfigurable designs; Routing; Wireless connection; Network routing
"Zaostrovnykh A., Pirelli S., Pedrosa L., Argyraki K., Candea G.",5,A formally verified nat,2017,9,"EPFL, Switzerland","EPFL, Switzerland",1,Switzerland,1,40,36,"We present a Network Address Translator (NAT) written in C and proven to be semantically correct according to RFC 3022, as well as crash-free and memory-safe. There exists a lot of recent work on network verification, but it mostly assumes models of network functions and proves properties specific to network configuration, such as reachability and absence of loops. Our proof applies directly to the C code of a network function, and it demonstrates the absence of implementation bugs. Prior work argued that this is not feasible (i.e., that verifying a real, stateful network function written in C does not scale) but we demonstrate otherwise: NAT is one of the most popular network functions and maintains per-flow state that needs to be properly updated and expired, which is a typical source of verification challenges.We tackle the scalability challenge with a new combination of symbolic execution and proof checking using separation logic; this combination matcheswell the typical structure of a network function. We then demonstrate that formally proven correctness in this case does not come at the cost of performance. The NAT code, proof toolchain, and proofs are available at [58]. © 2017 ACM.",Lazy Proofs; Network-Function Verification; Symbolic Execution,Convolutional codes; Model checking; Network function virtualization; Source separation; Transfer functions; Lazy Proofs; Network address translators; Network configuration; Network functions; Per-flow state; Separation logic; Symbolic execution; Typical structures; C (programming language)
"Cho I., Jang K., Han D.",3,Credit-scheduled delay-bounded congestion control for datacenters,2017,13,"KAIST, South Korea; Google Inc., United States",Google;KAIST,2,South Korea;USA,2,60,40,"Small RTTs (-tens of microseconds), bursty flow arrivals, and a large number of concurrent flows (thousands) in datacenters bring fundamental challenges to congestion control as they either force a flow to send at most one packet per RTT or induce a large queue build-up. The widespread use of shallow buffered switches also makes the problem more challenging with hosts generating many flows in bursts. In addition, as link speeds increase, algorithms that gradually probe for bandwidth take a long time to reach the fairshare. An ideal datacenter congestion control must provide 1) zero data loss, 2) fast convergence, 3) low buffer occupancy, and 4) high utilization. However, these requirements present conflicting goals. This paper presents a new radical approach, called ExpressPass, an end-to-end credit-scheduled, delay-bounded congestion control for datacenters. ExpressPass uses credit packets to control congestion even before sending data packets, which enables us to achieve bounded delay and fast convergence. It gracefully handles bursty flow arrivals. We implement ExpressPass using commodity switches and provide evaluations using testbed experiments and simulations. ExpressPass converges up to 80 times faster than DCTCP in 10 Gbps links, and the gap increases as link speeds become faster. It greatly improves performance under heavy incast workloads and significantly reduces the flow completion times, especially, for small and medium size flows compared to RCP, DCTCP, HULL, and DX under realistic workloads. © 2017 ACM.",Congestion Control; Credit-based; Datacenter Network,Congestion control (communication); Convolutional codes; Bounded delays; Buffer occupancy; Commodity switches; Completion time; Credit-based; Data center networks; Fast convergence; High utilizations; Concurrency control
"Giotsas V., Dietzel C., Smaragdakis G., Feldmann A., Berger A., Aben E.",6,Detecting peering infrastructure outages in the wild,2017,12,"CAIDA/TU Berlin, Germany; TU Berlin/DE-CIX, Germany; MIT/TU Berlin, Germany; TU Berlin, Germany; MIT/Akamai, Germany; RIPE NCC, Germany",University of California San Diego;Akamai Technologies;MIT;TU Berlin,4,Germany,1,72,60,"Peering infrastructures, namely, colocation facilities and Internet exchange points, are located in every major city, have hundreds of network members, and support hundreds of thousands of interconnections around the globe. These infrastructures are well provisioned and managed, but outages have to be expected, e.g., due to power failures, human errors, attacks, and natural disasters. However, little is known about the frequency and impact of outages at these critical infrastructures with high peering concentration. In this paper, we develop a novel and lightweight methodology for detecting peering infrastructure outages. Our methodology relies on the observation that BGP communities, announced with routing updates, are an excellent and yet unexplored source of information allowing us to pinpoint outage locations with high accuracy. We build and operate a system that can locate the epicenter of infrastructure outages at the level of a building and track the reaction of networks in near real-time. Our analysis unveils four times as many outages as compared to those publicly reported over the past five years. Moreover, we show that such outages have significant impact on remote networks and peering infrastructures. Our study provides a unique view of the Internet's behavior under stress that often goes unreported. © 2017 ACM.",BGP Community; Colocation; Interconnection Facility; IXP; Outages; Peering; Resilience,Convolutional codes; Disasters; BGP Community; Colocations; Internet exchange points; Natural disasters; Near-real time; Peering; Remote networks; Resilience; Outages
"Ruamviboonsuk V., Netravali R., Uluyol M., Madhyastha H.V.",4,Vroom: Accelerating the mobile web with server-aided dependency resolution,2017,5,"University of Michigan, United States; MIT, United States",MIT;University of Michigan at Ann Arbor,2,USA,1,100,85,"The existing slowness of the web on mobile devices frustrates users and hurts the revenue of website providers. Prior studies have attributed high page load times to dependencies within the page load process: network latency in fetching a resource delays its processing, which in turn delays when dependent resources can be discovered and fetched. To securely address the impact that these dependencies have on page load times, we present VROOM, a rethink of how clients and servers interact to facilitate web page loads. Unlike existing solutions, which require clients to either trust proxy servers or discover all the resources on any page themselves, VROOM's key characteristics are that clients fetch every resource directly from the domain that hosts it but web servers aid clients in discovering resources. Input from web servers decouples a client's processing of resources from its fetching of resources, thereby enabling independent use of both the CPU and the network. As a result, VROOM reduces the median page load time by more than 5 seconds across popular News and Sports sites. To enable these benefits, our contributions lie in making web servers capable of accurately aiding clients in resource discovery and judiciously scheduling a client's receipt of resources. © 2017 ACM.",Mobile web; Page load times; Web performance,Convolutional codes; Websites; Key characteristics; Mobile web; Network latencies; Page load times; Proxy server; Resource discovery; Web performance; Web servers; Web services
"Zhang H., Zhang J., Bai W., Chen K., Chowdhury M.",5,Resilient datacenter load balancing in the wild,2017,12,"SING Lab, Hong Kong University of Science and Technology, Hong Kong; University of Michigan, United States",Hong Kong University of Science and Technology;University of Michigan at Ann Arbor,2,Hong Kong;USA,2,47,25,"Production datacenters operate under various uncertainties such as traffic dynamics, topology asymmetry, and failures. Therefore, datacenter load balancing schemes must be resilient to these uncertainties; i.e., they should accurately sense path conditions and timely react to mitigate the fallouts. Despite significant efforts, prior solutions have important drawbacks. On the one hand, solutions such as Presto and DRB are oblivious to path conditions and blindly reroute at fixed granularity. On the other hand, solutions such as CONGA and CLOVE can sense congestion, but they can only reroute when flowlets emerge; thus, they cannot always react timely to uncertainties. To make things worse, these solutions fail to detect/handle failures such as blackholes and random packet drops, which greatly degrades their performance. In this paper, we introduce Hermes, a datacenter load balancer that is resilient to the aforementioned uncertainties. At its heart, Hermes leverages comprehensive sensing to detect path conditions including failures unattended before, and it reacts using timely yet cautious rerouting. Hermes is a practical edge-based solution with no switch modification. We have implemented Hermes with commodity switches and evaluated it through both testbed experiments and large-scale simulations. Our results show that Hermes achieves comparable performance to CONGA and Presto in normal cases, and well handles uncertainties: under asymmetries, Hermes achieves up to 10% and 20% better flow completion time (FCT) than CONGA and CLOVE; under switch failures, it outperforms all other schemes by over 32%. © 2017 ACM.",Datacenter fabric; Distributed; Load balancing,Resource allocation; Commodity switches; Completion time; Datacenter; Distributed; Large scale simulations; Load-balancing schemes; Path condition; Traffic dynamics; Convolutional codes
"Huang Q., Jin X., Lee P.P.C., Li R., Tang L., Chen Y.-C., Zhang G.",7,Sketchvisor: Robust network measurement for software packet processing,2017,11,"Huawei Future Network Theory Lab, China; Johns Hopkins University, United States; Chinese University of Hong Kong, Hong Kong",Chinese University of Hong Kong;Johns Hopkins University,2,China;Hong Kong;USA,3,35,28,"Network measurement remains a missing piece in today's software packet processing platforms. Sketches provide a promising building block for filling this void by monitoring every packet with fixed-size memory and bounded errors. However, our analysis shows that existing sketch-based measurement solutions suffer from severe performance drops under high traffic load. Although sketches are efficiently designed, applying them in network measurement inevitably incurs heavy computational overhead. We present SketchVisor, a robust network measurement framework for software packet processing. It augments sketch-based measurement in the data plane with a fast path, which is activated under high traffic load to provide high-performance local measurement with slight accuracy degradations. It further recovers accurate network-wide measurement results via compressive sensing. We have built a SketchVisor prototype on top of Open vSwitch. Extensive testbed experiments show that SketchVisor achieves high throughput and high accuracy for a wide range of network measurement tasks and microbenchmarks. © 2017 ACM.",Network measurement; Sketch; Software packet processing,Convolutional codes; Compressive sensing; Computational overheads; Local measurement; Micro-benchmarks; Network measurement; Packet processing; Sketch; Wide measurement; Packet networks
"Mellette W.M., McGuinness R., Roy A., Forencich A., Papen G., Snoeren A.C., Porter G.",7,"Rotornet: A scalable, low-complexity, optical datacenter network",2017,15,"University of California, San Diego, United States",University of California San Diego,1,USA,1,62,31,"The ever-increasing bandwidth requirements of modern datacenters have led researchers to propose networks based upon optical circuit switches, but these proposals face significant deployment challenges. In particular, previous proposals dynamically configure circuit switches in response to changes in workload, requiring network-wide demand estimation, centralized circuit assignment, and tight time synchronization between various network elements- resulting in a complex and unwieldy control plane. Moreover, limitations in the technologies underlying the individual circuit switches restrict both the rate at which they can be reconfigured and the scale of the network that can be constructed. We propose RotorNet, a circuit-based network design that addresses these two challenges. While RotorNet dynamically reconfigures its constituent circuit switches, it decouples switch configuration from traffic patterns, obviating the need for demand collection and admitting a fully decentralized control plane. At the physical layer, RotorNet relaxes the requirements on the underlying circuit switches-in particular by not requiring individual switches to implement a full crossbar-enabling them to scale to 1000s of ports. We show that RotorNet outperforms comparably priced Fat Tree topologies under a variety of workload conditions, including traces taken from two commercial datacenters. We also demonstrate a small-scale RotorNet operating in practice on an eight-node testbed. © 2017 ACM.",Datacenter; Optical switching,Convolutional codes; Network layers; Optical switches; Time switches; Bandwidth requirement; Data center networks; Datacenter; Demand estimation; Optical circuits; Optical switching; Switch configuration; Time synchronization; Complex networks
"Gupta T., Fingler H., Alvisi L., Walfish M.",4,Pretzel: Email encryption and provider-supplied functions are compatible,2017,3,"UT Austin, United States; NYU, United States; Cornell, United States",NYU;University of Texas at Austin,2,USA,1,33,6,"Emails today are often encrypted, but only between mail servers- the vast majority of emails are exposed in plaintext to the mail servers that handle them. While better than no encryption, this arrangement leaves open the possibility of attacks, privacy violations, and other disclosures. Publicly, email providers have stated that default end-to-end encryption would conflict with essential functions (spam filtering, etc.), because the latter requires analyzing email text. The goal of this paper is to demonstrate that there is no conflict. We do so by designing, implementing, and evaluating Pretzel. Starting from a cryptographic protocol that enables two parties to jointly perform a classification task without revealing their inputs to each other, Pretzel refines and adapts this protocol to the email context. Our experimental evaluation of a prototype demonstrates that email can be encrypted end-to-end and providers can compute over it, at tolerable cost: clients must devote some storage and processing, and provider overhead is roughly 5_ versus the status quo. © 2017 ACM.",Encrypted email; Linear classifiers; Secure two-party computation,Convolutional codes; Digital storage; Electronic mail; Function evaluation; Classification tasks; Cryptographic protocols; E-mail encryption; Encrypted email; End-to-end encryption; Experimental evaluation; Linear classifiers; Secure two-party computations; Cryptography
"Zhuo D., Ghobadi M., Mahajan R., Fšrster K.-T., Krishnamurthy A., Anderson T.",6,Understanding and mitigating packet corruption in data center networks,2017,4,"University of Washington, United States; Microsoft Research, United States; Microsoft Research and Intentionet, United States; Aalborg University, Denmark",Aalborg University;Microsoft;University of Washington at Seattle,3,Denmark;USA,2,144,71,"We take a comprehensive look at packet corruption in data center networks, which leads to packet losses and application performance degradation. By studying 350K links across 15 production data centers, we find that the extent of corruption losses is significant and that its characteristics differ markedly from congestion losses. Corruption impacts fewer links than congestion, but imposes a heavier loss rate; and unlike congestion, corruption rate on a link is stable over time and is not correlated with its utilization. Based on these observations, we developed CorrOpt, a system to mitigate corruption. To minimize corruption losses, it intelligently selects which corrupting links can be safely disabled, while ensuring that each top-of-rack switch has a minimum number of paths to reach other switches. CorrOpt also recommends specific actions (e.g., replace cables, clean connectors) to repair disabled links, based on our analysis of common symptoms of different root causes of corruption. Our recommendation engine has been deployed in over seventy data centers of a large cloud provider. Our analysis shows that, compared to current state of the art, CorrOpt can reduce corruption losses by three to six orders of magnitude and improve repair accuracy by 60%. © 2017 ACM.",CorrOpt; Data Center Networks; Fault Mitigation; Optics; Packet Corruption,Convolutional codes; Crime; Optics; Repair; Application performance; Congestion loss; CorrOpt; Data center networks; Fault mitigations; Orders of magnitude; Packet Corruption; State of the art; Packet networks
"Saeed A., Dukkipati N., Valancius V., Lam V., Contavalli C., Vahdat A.",6,Carousel: Scalable traffic shaping at end hosts,2017,7,"Georgia Institute of Technology, United States; Google, Inc., United States",Georgia Tech;Google,2,USA,1,38,35,"Traffic shaping, including pacing and rate limiting, is fundamental to the correct and efficient operation of both datacenter and wide area networks. Sample use cases include policy-based bandwidth allocation to flow aggregates, rate-based congestion control algorithms, and packet pacing to avoid bursty transmissions that can overwhelm router buffers. Driven by the need to scale to millions of flows and to apply complex policies, traffic shaping is moving from network switches into the end hosts, typically implemented in software in the kernel networking stack. In this paper, we show that the performance overhead of end-host traffic shaping is substantial limits overall system scalability as we move to thousands of individual traffic classes per server. Measurements from production servers show that shaping at hosts consumes considerable CPU and memory, unnecessarily drops packets, suffers from head of line blocking and inaccuracy, and does not provide backpressure up the stack.We present Carousel, a framework that scales to tens of thousands of policies and flows per server, built from the synthesis of three key ideas: i) a single queue shaper using time as the basis for releasing packets, ii) fine-grained, just-in-time freeing of resources in higher layers coupled to actual packet departures, and iii) one shaper per CPU core, with lock-free coordination. Our production experience in serving video traffic at a Cloud service provider shows that Carousel shapes traffic accurately while improving overall machine CPU utilization by 8% (an improvement of 20% in the CPU utilization attributed to networking) relative to state-of-art deployments. It also conforms 10 times more accurately to target rates, and consumes two orders of magnitude less memory than existing approaches. © 2017 ACM.",Backpressure; Pacing; Rate-limiters; TimingWheel; Traffic shaping,Congestion control (communication); Convolutional codes; Coordination reactions; Wide area networks; Back pressures; Bursty transmission; Cloud service providers; Head of line blocking; Pacing; Rate-based congestion control; TimingWheel; Traffic-shaping; Just in time production
"Xia Y., Sun X.S., Dzinamarira S., Wu D., Huang X.S., Ng T.S.E.",6,A tale of two topologies: Exploring convertible data center network architectures with flat-tree,2017,4,"Rice University, United States",Rice University,1,USA,1,44,33,"This paper promotes convertible data center network architectures, which can dynamically change the network topology to combine the benefits of multiple architectures. We propose the flat-tree prototype architecture as the first step to realize this concept. Flat-tree can be implemented as a Clos network and later be converted to approximate random graphs of different sizes, thus achieving both Clos-like implementation simplicity and random-graph-like transmission performance. We present the detailed design for the network architecture and the control system. Simulations using real data center traffic traces show that flat-tree is able to optimize various workloads with different topology options. We implement an example flat-tree network on a 20-switch 24-server testbed. The traffic reaches the maximal throughput in 2.5s after a topology change, proving the feasibility of converting topology at run time. The network core bandwidth is increased by 27.6% just by converting the topology from Clos to approximate random graph. This improvement can be translated into acceleration of applications as we observe reduced communication time in Spark and Hadoop jobs. © 2017 ACM.",Clos networks; Convertible data center networks; Random graph networks,Convolutional codes; Forestry; Graph theory; Switching networks; Topology; Trees (mathematics); Clos networks; Communication time; Data center networks; Maximal throughput; Network topology; Prototype architecture; Random graphs; Transmission performance; Network architecture
"Sun C., Bi J., Zheng Z., Yu H., Hu H.",5,NFP: Enabling network function parallelism in NFV,2017,17,"Tsinghua University, China; Clemson University, United States",Clemson University;Tsinghua University,2,China;USA,2,51,43,"Software-based sequential service chains in Network Function Virtualization (NFV) could introduce significant performance overhead. Current acceleration efforts for NFV mainly target on optimizing each component of the sequential service chain. However, based on the statistics from real world enterprise networks, we observe that 53.8% network function (NF) pairs can work in parallel. In particular, 41.5% NF pairs can be parallelized without causing extra resource overhead. In this paper, we present NFP, a high performance framework, that innovatively enables network function parallelism to improve NFV performance. NFP consists of three logical components. First, NFP provides a policy specification scheme for operators to intuitively describe sequential or parallel NF chaining intents. Second, NFP orchestrator intelligently identifies NF dependency and automatically compiles the policies into high performance service graphs. Third, NFP infrastructure performs light-weight packet copying, distributed parallel packet delivery, and load-balanced merging of packet copies to support NF parallelism. We implement an NFP prototype based on DPDK in Linux containers. Our evaluation results show that NFP achieves significant latency reduction for real world service chains. © 2017 ACM.",Network function parallelism; NFV; Service chain,Chains; Computer operating systems; Convolutional codes; Transfer functions; Current acceleration; Enterprise networks; Evaluation results; Latency reduction; Network functions; Performance frameworks; Policy specification; Service chain; Network function virtualization
"Marinos I., Watson R.N.M., Handley M., Stewart R.R.",4,Disk|crypt|net: Rethinking the stack for high-performance video streaming,2017,2,"University of Cambridge, United Kingdom; University College London, United Kingdom; Netflix Inc., United States",Netflix Inc.;University College London;University of Cambridge,3,UK;USA,2,65,53,"Conventional operating systems used for video streaming employ an in-memory disk buffer cache to mask the high latency and low throughput of disks. However, data from Netflix servers show that this cache has a low hit rate, so does little to improve throughput. Latency is not the problem it once was either, due to PCIe-attached flash storage. With memory bandwidth increasingly becoming a bottleneck for video servers, especially when end-to-end encryption is considered, we revisit the interaction between storage and networking for video streaming servers in pursuit of higher performance. We show how to build high-performance userspace network services that saturate existing hardware while serving data directly from disks, with no need for a traditional disk buffer cache. Employing netmap, and developing a new diskmap service, which provides safe high-performance userspace direct I/O access to NVMe devices, we amortize system overheads by utilizing efficient batching of outstanding I/O requests, process-to-completion, and zerocopy operation.We demonstrate how a buffer-cache-free design is not only practical, but required in order to achieve efficient use of memory bandwidth on contemporary microarchitectures. Minimizing latency between DMA and CPU access by integrating storage and TCP control loops allows many operations to access only the last-level cache rather than bottle-necking on memory bandwidth. We illustrate the power of this design by building Atlas, a video streaming web server that outperforms state-of-the-art configurations, and achieves ~72Gbps of plaintext or encrypted network traffic using a fraction of the available CPU cores on commodity hardware. © 2017 ACM.",Network Performance; Network stacks; Storage stacks,Bandwidth; Bottles; Computer hardware; Convolutional codes; Cryptography; Digital storage; Hardware; Network performance; Video streaming; Commodity hardware; End-to-end encryption; High-performance video streaming; Last-level caches; Memory bandwidths; Micro architectures; Network stack; Video streaming servers; Cache memory
"Zave P., Ferreira R.A., Zou X.K., Morimoto M., Rexford J.",5,Dynamic service chaining with dysco,2017,10,"ATandT Labs-Research, United States; UFMS, United States; Google, United States; NEC Corporation of America, United States; Princeton University, United States",Google;AT and T Labs;Princeton University,3,USA,1,33,16,"Middleboxes are crucial for improving network security and performance, but only if the right traffic goes through the right middleboxes at the right time. Existing traffic-steering techniques rely on a central controller to install fine-grained forwarding rules in network elements-at the expense of a large number of rules, a central point of failure, challenges in ensuring all packets of a session traverse the same middleboxes, and difficulties with middleboxes that modify the ""five tuple."" We argue that a session-level protocol is a fundamentally better approach to traffic steering, while naturally supporting host mobility and multihoming in an integrated fashion. In addition, a session-level protocol can enable new capabilities like dynamic service chaining, where the sequence of middleboxes can change during the life of a session, e.g., to remove a load-balancer that is no longer needed, replace a middlebox undergoing maintenance, or add a packet scrubber when traffic looks suspicious. Our Dysco protocol steers the packets of a TCP session through a service chain, and can dynamically reconfigure the chain for an ongoing session. Dysco requires no changes to end-host and middlebox applications, host TCP stacks, or IP routing. Dysco's distributed reconfiguration protocol handles the removal of proxies that terminate TCP connections, middleboxes that change the size of a byte stream, and concurrent requests to reconfigure different parts of a chain. Through formal verification using Spin and experiments with our Linux-based prototype, we show that Dysco is provably correct, highly scalable, and able to reconfigure service chains across a range of middleboxes. © 2017 ACM.",NFV; Session Protocol; Spin; Verification,Chains; Computer operating systems; Convolutional codes; Formal verification; Transmission control protocol; Verification; Central point; Concurrent requests; Distributed reconfiguration; Dynamic services; Integrated fashion; Network security and performance; Spin; TCP connections; Network security
"Narayana S., Sivaraman A., Nathan V., Goyal P., Arun V., Alizadeh M., Jeyakumar V., Kim C.",8,Language-directed hardware design for network performance monitoring,2017,20,"MIT CSAIL, United States; IIT Guwahati, India; Cisco Tetration Analytics, United States; Barefoot Networks, United States",MIT,1,India;USA,2,50,45,"Network performance monitoring today is restricted by existing switch support for measurement, forcing operators to rely heavily on endpoints with poor visibility into the network core. Switch vendors have added progressively more monitoring features to switches, but the current trajectory of adding specific features is unsustainable given the ever-changing demands of network operators. Instead, we ask what switch hardware primitives are required to support an expressive language of network performance questions. We believe that the resulting switch hardware design could address a wide variety of current and future performance monitoring needs. We present a performance query language, Marple, modeled on familiar functional constructs like map, filter, groupby, and zip. Marple is backed by a new programmable key-value store primitive on switch hardware. The key-value store performs flexible aggregations at line rate (e.g., a moving average of queueing latencies per flow), and scales to millions of keys. We present a Marple compiler that targets a P4-programmable software switch and a simulator for highspeed programmable switches. Marple can express switch queries that could previously run only on end hosts, while Marple queries only occupy a modest fraction of a switch's hardware resources. © 2017 ACM.",Network hardware; Network measurement; Network programming,Computer programming; Computer software; Convolutional codes; Network performance; Program compilers; Query languages; Query processing; Flexible aggregation; Future performance; Hardware resources; Network measurement; Network performance monitoring; Network programming; Programmable software; Programmable switches; Hardware
"Chole S., Fingerhut A., Ma S., Sivaraman A., Vargaftik S., Berger A., Mendelson G., Alizadeh M., Chuang S.-T., Keslassy I., Orda A., Edsall T.",12,DRMT: Disaggregated programmable switching,2017,8,"Cisco Systems, Inc., United States; MIT, United States; Technion, United States; VMware, Inc., United States",Cisco;MIT;VMware Inc.,3,USA,1,65,35,"We present dRMT (disaggregated Reconfigurable Match-Action Table), a new architecture for programmable switches. dRMT overcomes two important restrictions of RMT, the predominant pipelinebased architecture for programmable switches: (1) table memory is local to an RMT pipeline stage, implying that memory not used by one stage cannot be reclaimed by another, and (2) RMT is hardwired to always sequentially execute matches followed by actions as packets traverse pipeline stages. We show that these restrictions make it difficult to execute programs efficiently on RMT. dRMT resolves both issues by disaggregating the memory and compute resources of a programmable switch. Specifically, dRMT moves table memories out of pipeline stages and into a centralized pool that is accessible through a crossbar. In addition, dRMT replaces RMT's pipeline stages with a cluster of processors that can execute match and action operations in any order. We show how to schedule a P4 program on dRMT at compile time to guarantee deterministic throughput and latency. We also present a hardware design for dRMT and analyze its feasibility and chip area. Our results show that dRMT can run programs at line rate with fewer processors compared to RMT, and avoids performance cliffs when there are not enough processors to run a program at line rate. dRMT's hardware design incurs a modest increase in chip area relative to RMT, mainly due to the crossbar. © 2017 ACM.",Disagreggation; Packet processing; Programmable switching; RMT,Computer hardware; Convolutional codes; Hardware; Integrated circuit design; Memory architecture; Packet switching; Pipelines; Program processors; Reconfigurable architectures; Compile time; Compute resources; Disagreggation; Hardware design; Packet processing; Pipeline stages; Programmable switches; Reconfigurable; Pipeline processing systems
"Song Z., Shangguan L., Jamieson K.",3,Wi-fi goes to town: Rapid picocell switching for wireless transit networks,2017,4,"Princeton University, United States",Princeton University,1,USA,1,25,7,"This paper presents the design and implementation of Wi-Fi Goes to Town, the first Wi-Fi based roadside hotspot network designed to operate at vehicular speeds with meter-sized picocells. Wi-Fi Goes to Town APs make delivery decisions to the vehicular clients they serve at millisecond-level granularities, exploiting path diversity in roadside networks. In order to accomplish this, we introduce new buffer management algorithms that allow participating APs to manage each others' queues, rapidly quenching each others' transmissions and flushing each others' queues. We furthermore integrate our fine-grained AP selection and queue management into 802.11's frame aggregation and block acknowledgement functions, making the system effective at modern 802.11 bit rates that need frame aggregation to maintain high spectral efficiency. We have implemented our system in an eight-AP network alongside a nearby road, and evaluate its performance with mobile clients moving at up to 35 mph. Depending on the clients' speed, Wi-Fi Goes to Town achieves a 2.4-4.7_ TCP throughput improvement over a baseline fast handover protocol that captures the state of the art in Wi-Fi roaming, including the recent IEEE 802.11k and 802.11r standards. © 2017 ACM.",Handover; Transit Networks; Wi-Fi,Convolutional codes; Queueing theory; Roadsides; Wireless local area networks (WLAN); Buffer management; Design and implementations; Frame aggregation; Handover; High spectral efficiency; Queue management; Rapidly quenching; Transit networks; Wi-Fi
"Basat R.B., Einziger G., Friedman R., Luizelli M.C., Waisbard E.",5,Constant time updates in hierarchical heavy hitters,2017,12,"Technion, United States; Nokia Bell Labs, South Korea; UFRGS, Brazil",Nokia,1,Brazil;South Korea;USA,3,49,16,"Monitoring tasks, such as anomaly and DDoS detection, require identifying frequent flow aggregates based on common IP prefixes. These are known as hierarchical heavy hitters (HHH), where the hierarchy is determined based on the type of prefixes of interest in a given application. The per packet complexity of existing HHH algorithms is proportional to the size of the hierarchy, imposing significant overheads. In this paper, we propose a randomized constant time algorithm for HHH. We prove probabilistic precision bounds backed by an empirical evaluation. Using four real Internet packet traces, we demonstrate that our algorithm indeed obtains comparable accuracy and recall as previous works, while running up to 62 times faster. Finally, we extended Open vSwitch (OVS) with our algorithm and showed it is able to handle 13.8 million packets per second. In contrast, incorporating previous works in OVS only obtained 2.5 times lower throughput. © 2017 ACM.",Heavy Hitters; Measurement; Monitoring; Streaming,Acoustic streaming; Measurements; Monitoring; Constant time algorithms; DDoS detection; Empirical evaluations; Heavy-hitter; Hierarchical heavy hitters; Internet packets; Million packets per seconds; Monitoring tasks; Convolutional codes
"Holterbach T., Vissicchio S., Dainotti A., Vanbever L.",4,Swift: Predictive fast reroute,2017,7,"ETH ZŸrich, CAIDA, UC San Diego, United States; University College London, United Kingdom; CAIDA, UC San Diego, United States; ETH ZŸrich, Switzerland",ETH Zurich;University College London;University of California San Diego,3,Switzerland;UK;USA,3,46,30,"Network operators often face the problem of remote outages in transit networks leading to significant (sometimes on the order of minutes) downtimes. The issue is that BGP, the Internet routing protocol, often converges slowly upon such outages, as large bursts of messages have to be processed and propagated router by router. In this paper, we present SWIFT, a fast-reroute framework which enables routers to restore connectivity in few seconds upon remote outages. SWIFT is based on two novel techniques. First, SWIFT deals with slow outage notification by predicting the overall extent of a remote failure out of few control-plane (BGP) messages. The key insight is that significant inference speed can be gained at the price of some accuracy. Second, SWIFT introduces a new dataplane encoding scheme, which enables quick and flexible update of the affected forwarding entries. SWIFT is deployable on existing devices, without modifying BGP. We present a complete implementation of SWIFT and demonstrate that it is both fast and accurate. In our experiments with real BGP traces, SWIFT predicts the extent of a remote outage in few seconds with an accuracy of -90% and can restore connectivity for 99% of the affected destinations. © 2017 ACM.",BGP; Convergence; Fast Reroute; Root Cause Analysis,Convolutional codes; Restoration; Convergence; Encoding schemes; Fast reroute; Internet routing; Network operator; Novel techniques; Root cause analysis; Transit networks; Routers
"Yap K.-K., Motiwala M., Rahe J., Padgett S., Holliman M., Baldus G., Hines M., Kim T., Narayanan A., Jain A., Lin V., Rice C., Rogan B., Singh A., Tanaka B., Verma M., Sood P., Tariq M., Tierney M., Trumic D., Valancius V., Ying C., Kallahalla M., Koley B., Vahdat A.",25,"Taking the edge off with espresso: Scale, reliability and programmability for global internet peering",2017,16,"Google, United States",Google,1,USA,1,70,41,"We present the design of Espresso, Google's SDN-based Internet peering edge routing infrastructure. This architecture grew out of a need to exponentially scale the Internet edge cost-effectively and to enable application-aware routing at Internet-peering scale. Espresso utilizes commodity switches and host-based routing/packet processing to implement a novel fine-grained traffic engineering capability. Overall, Espresso provides Google a scalable peering edge that is programmable, reliable, and integrated with global traffic systems. Espresso also greatly accelerated deployment of new networking features at our peering edge. Espresso has been in production for two years and serves over 22% of Google's total traffic to the Internet. © 2017 ACM.",Networking; Peering Routers; Traffic Engineering,Convolutional codes; Application aware routing; Commodity switches; Global Internet; Networking; Programmability; Routing infrastructure; Traffic Engineering; Traffic systems; Internet
"Handley M., Raiciu C., Agache A., Voinescu A., Moore A.W., Antichi G., Wojcik M.",7,Re-architecting datacenter networks and stacks for low latency and high performance,2017,16,"University College London, London, United Kingdom; University Politehnica of Bucharest, Bucharest, Romania; University of Cambridge, Cambridge, United Kingdom",University College London;University Politehnica of Bucharest;University of Cambridge,3,Romania;UK,2,32,25,"Modern datacenter networks provide very high capacity via redundant Clos topologies and low switch latency, but transport protocols rarely deliver matching performance. We present NDP, a novel datacenter transport architecture that achieves near-optimal completion times for short transfers and high flow throughput in a wide range of scenarios, including incast. NDP switch buffers are very shallow and when they fill the switches trim packets to headers and priority forward the headers. This gives receivers a full view of instantaneous demand from all senders, and is the basis for our novel, high-performance, multipath-aware transport protocol that can deal gracefully with massive incast events and prioritize traffic from different senders on RTT timescales. We implemented NDP in Linux hosts with DPDK, in a software switch, in a NetFPGA-based hardware switch, and in P4. We evaluate NDP's performance in our implementations and in large-scale simulations, simultaneously demonstrating support for very low-latency and high throughput. © 2017 ACM.",Datacenters; Network Stacks; Transport Protocols,Computer operating systems; Convolutional codes; Data center networks; Data centers; High throughput; Large scale simulations; Matching performance; Network stack; Software switches; Transport protocols; Internet protocols
"Ma Y., Selby N., Adib F.",3,Drone relays for battery-free networks,2017,9,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,41,34,"Battery-free sensors, such as RFIDs, are annually attached to billions of items including pharmaceutical drugs, clothes, and manufacturing parts. The fundamental challenge with battery-free sensors is that they are only reliable at short distances of tens of centimeters to few meters. As a result, today's systems for communicating with and localizing battery-free sensors are crippled by the limited range. To overcome this challenge, this paper presents RFly, a system that leverages drones as relays for battery-free networks. RFly delivers two key innovations. It introduces the first full-duplex relay for battery-free networks. The relay can seamlessly integrate with a deployed RFID infrastructure, and it preserves phase and timing characteristics of the forwarded packets. RFly also develops the first RF-localization algorithm that can operate through a mobile relay. We built a hardware prototype of RFly's relay into a custom PCB circuit and mounted it on a Parrot Bebop drone. Our experimental evaluation demonstrates that RFly enables communication with commercial RFIDs at over 50 m. Moreover, its through-relay localization algorithm has a median accuracy of 19 centimeters. These results demonstrate that RFly provides powerful primitives for communication and localization in battery-free networks. © 2017 ACM.",Battery-free; Drones; Full-Duplex; Localization; Relay; RFID; SAR,Convolutional codes; Drones; Drug products; Radio frequency identification (RFID); Unmanned aerial vehicles (UAV); Battery-free; Experimental evaluation; Full-duplex; Localization; Localization algorithm; Pharmaceutical drugs; Relay; Timing characteristics; Electric batteries
"Miao R., Zeng H., Kim C., Lee J., Yu M.",5,Silkroad: Making stateful layer-4 load balancing fast and cheap using switching asics,2017,22,"University of Southern California, United States; Facebook, United States; Barefoot Networks, United States; Yale University, United States",Facebook;University of Southern California;Yale University,3,USA,1,52,31,"In this paper, we show that up to hundreds of software load balancer (SLB) servers can be replaced by a single modern switching ASIC, potentially reducing the cost of load balancing by over two orders of magnitude. Today, large data centers typically employ hundreds or thousands of servers to load-balance incoming traffic over application servers. These software load balancers (SLBs) map packets destined to a service (with a virtual IP address, or VIP), to a pool of servers tasked with providing the service (with multiple direct IP addresses, or DIPs). An SLB is stateful, it must always map a connection to the same server, even if the pool of servers changes and/or if the load is spread differently across the pool. This property is called per-connection consistency or PCC. The challenge is that the load balancer must keep track of millions of connections simultaneously. Until recently, it was not possible to implement a load balancer with PCC in a merchant switching ASIC, because high-performance switching ASICs typically can not maintain per-connection states with PCC. Newer switching ASICs provide resources and primitives to enable PCC at a large scale. In this paper, we explore how to use switching ASICs to build much faster load balancers than have been built before. Our system, called SilkRoad, is defined in a 400 line P4 program and when compiled to a state-of-the-art switching ASIC, we show it can load-balance ten million connections simultaneously at line rate. © 2017 ACM.",Load balancing; Programmable switches,Application specific integrated circuits; Convolutional codes; Lakes; Resource allocation; Switching; Virtual addresses; Application Servers; Incoming traffic; Keep track of; Load balance; Load balancer; Orders of magnitude; Programmable switches; State of the art; Servers
"Ghorbani S., Yang Z., Godfrey P.B., Ganjali Y., Firoozshahian A.",5,Drill: Micro load balancing for low-latency data center networks,2017,16,"University of Wisconsin-Madison, United States; University of Illinois at Urbana-Champaign, United States; University of Toronto, Canada; Intel, United States",UIUC;University of Toronto;;University of Wisconsin-Madison,4,Canada;USA,2,42,20,"The trend towards simple datacenter network fabric strips most network functionality, including load balancing, out of the network core and pushes it to the edge. This slows reaction to microbursts, the main culprit of packet loss in datacenters.We investigate the opposite direction: could slightly smarter fabric significantly improve load balancing? This paper presents DRILL, a datacenter fabric for Clos networks which performs micro load balancing to distribute load as evenly as possible on microsecond timescales. DRILL employs perpacket decisions at each switch based on local queue occupancies and randomized algorithms to distribute load. Our design addresses the resulting key challenges of packet reordering and topological asymmetry. In simulations with a detailed switch hardware model and realistic workloads, DRILL outperforms recent edge-based load balancers, particularly under heavy load. Under 80% load, for example, it achieves 1.3-1.4_ lower mean flow completion time than recent proposals, primarily due to shorter upstream queues. To test hardware feasibility, we implement DRILL in Verilog and estimate its area overhead to be less than 1%. Finally, we analyze DRILL's stability and throughput-efficiency. © 2017 ACM.",Clos; Datacenters; Load balancing; Microbursts; Traffic engineering,Computer hardware description languages; Convolutional codes; Drills; Hardware; Resource allocation; Clos; Data center networks; Data centers; Microbursts; Network functionality; Randomized Algorithms; Throughput efficiency; Traffic Engineering; Packet networks
"Yuan Y., Lin D., Mishra A., Marwaha S., Alur R., Loo B.T.",6,Quantitative network monitoring with netqre,2017,4,"University of Pennsylvania, United States; LinkedIn Inc., United States",LinkedIn Inc.;University of Pennsylvania,2,USA,1,73,59,"In network management today, dynamic updates are required for traffic engineering and for timely response to security threats. Decisions for such updates are based on monitoring network traffic to compute numerical quantities based on a variety of network and application-level performance metrics. Today's state-of-the-art tools lack programming abstractions that capture application or session-layer semantics, and thus require network operators to specify and reason about complex state machines and interactions across layers. To address this limitation, we present the design and implementation of NetQRE, a high-level declarative toolkit that aims to simplify the specification and implementation of such quantitative network policies. NetQRE integrates regular-expression-like pattern matching at flow-level as well as application-level payloads with aggregation operations such as sum and average counts. We describe a compiler for NetQRE that automatically generates an efficient implementation with low memory footprint. Our evaluation results demonstrate that NetQRE allows natural specification of a wide range of quantitative network tasks ranging from detecting security attacks to enforcing application-layer network management policies. NetQRE results in high performance that is comparable with optimized manually-written low-level code and is significantly more efficient than alternative solutions, and can provide timely enforcement of network policies that require quantitative network monitoring. © 2017 ACM.",NetQRE; Network monitoring language; Quantitative regular expression,Computer programming; Computer programming languages; Convolutional codes; Network layers; Network management; Pattern matching; Semantics; Specifications; Application layer network; Application-level performance; Design and implementations; Efficient implementation; NetQRE; Network Monitoring; Programming abstractions; Regular expressions; Computer systems programming
"Iordanou C., Soriente C., Sirivianos M., Laoutaris N.",4,Who is fiddling with prices? building and deploying a watchdog service for e-commerce,2017,3,"Universidad Carlos III de Madrid, Telefonica Research, Spain; Telefonica Research, Spain; Cyprus University of Technology, Cyprus; Data Transparency Lab, Spain",Cyprus University of Technology;Telefonica Research;Universidad Carlos III de Madrid,3,Cyprus;Spain,2,41,24,"We present the design, implementation, validation, and deployment of the Price Sheriff, a highly distributed system for detecting various types of online price discrimination in e-commerce. The Price Sheriff uses a peer-to-peer architecture, sandboxing, and secure multiparty computation to allow users to tunnel price check requests through the browsers of other peers without tainting their local or server-side browsing history and state. Having operated the Price Sheriff for several months with approximately one thousand real users, we identify several instances of cross-border price discrimination based on the country of origin. Even within national borders, we identify several retailers that return different prices for the same product to different users. We examine whether the observed differences are due to personal-data-induced discrimination or A/B testing, and conclude that it is the latter. © 2017 ACM.",Online Price Discrimination,Commerce; Convolutional codes; Distributed computer systems; Electronic commerce; A/b testing; Browsing history; Cross-border; Distributed systems; Peer-to-peer architectures; Price discrimination; Secure multi-party computation; Server sides; Costs
"Qazi Z.A., Walls M., Panda A., Sekar V., Ratnasamy S., Shenker S.",6,A high performance packet core for next generation cellular networks,2017,10,"UC Berkeley, United States; Nefeli Networks, Inc., United States; Carnegie Mellon University, United States",Carnegie Mellon University;Nefeli Networks Inc.;University of California Berkeley,3,USA,1,23,20,"Cellular traffic continues to grow rapidly making the scalability of the cellular infrastructure a critical issue. However, there is mounting evidence that the current Evolved Packet Core (EPC) is ill-suited to meet these scaling demands: EPC solutions based on specialized appliances are expensive to scale and recent software EPCs perform poorly, particularly with increasing numbers of devices or signaling traffic. In this paper, we design and evaluate a new system architecture for a software EPC that achieves high and scalable performance. We postulate that the poor scaling of existing EPC systems stems from the manner in which the system is decomposed which leads to device state being duplicated across multiple components which in turn results in frequent interactions between the different components. We propose an alternate approach in which state for a single device is consolidated in one location and EPC functions are (re)organized for efficient access to this consolidated state. In effect, our design ""slices"" the EPC by user. We prototype and evaluate PEPC, a software EPC that implements the key components of our design. We show that PEPC achieves 3-7_ higher throughput than comparable software EPCs that have been implemented in industry and over 10_ higher throughput than a popular open-source implementation (OpenAirInterface). Compared to the industrial EPC implementations, PEPC sustains high data throughput for 10-100_ more users devices per core, and a 10_ higher ratio of signaling-to-data traffic. In addition to high performance, PEPC's by-user organization enables efficient state migration and customization of processing pipelines. We implement user migration in PEPC and show that state can be migrated with little disruption, e.g., migration adds only up to 4_s of latency to median per packet latencies. © 2017 ACM.",Cellular Networks; EPC; Network Function,Convolutional codes; Function evaluation; Mobile telecommunication systems; Next generation networks; Open source software; Packet networks; Throughput; Wireless networks; Alternate approaches; Cellular infrastructure; Cellular network; Network functions; Next generation cellular networks; Open source implementation; Scalable performance; System architectures; Open systems
"Beckett R., Gupta A., Mahajan R., Walker D.",4,A general approach to network configuration verification,2017,13,"Princeton University, United States; Microsoft Research and Intentionet, United States",Microsoft;Princeton University,2,USA,1,46,45,"We present Minesweeper, a tool to verify that a network satisfies a wide range of intended properties such as reachability or isolation among nodes, waypointing, black holes, bounded path length, load-balancing, functional equivalence of two routers, and fault-tolerance. Minesweeper translates network configuration files into a logical formula that captures the stable states to which the network forwarding will converge as a result of interactions between routing protocols such as OSPF, BGP and static routes. It then combines the formula with constraints that describe the intended property. If the combined formula is satisfiable, there exists a stable state of the network in which the property does not hold. Otherwise, no stable state (if any) violates the property. We used Minesweeper to check four properties of 152 real networks from a large cloud provider. We found 120 violations, some of which are potentially serious security vulnerabilities. We also evaluated Minesweeper on synthetic benchmarks, and found that it can verify rich properties for networks with hundreds of routers in under five minutes. This performance is due to a suite of model-slicing and hoisting optimizations that we developed, which reduce runtime by over 460x for large networks. © 2017 ACM.",Control plane analysis; Network verification,Fault tolerance; Routing protocols; Cloud providers; Control planes; Functional equivalence; Large networks; Logical formulas; Network configuration; Security vulnerabilities; Synthetic benchmark; Convolutional codes
"Kulkarni S.G., Zhang W., Hwang J., Rajagopalan S., Ramakrishnan K.K., Wood T., Arumaithurai M., Fu X.",8,Nfvnice: Dynamic backpressure and scheduling for NFV service chains,2017,9,"University of Gšttingen, Germany; George Washington University, United States; IBM T J Watson Research Center, United States; University of California, Riverside, United States",George Washington University;IBM;University of California Riverside;University of Goettingen,4,Germany;USA,2,35,28,"Managing Network Function (NF) service chains requires careful system resource management. We propose NFVnice, a user space NF scheduling and service chain management framework to provide fair, efficient and dynamic resource scheduling capabilities on Network Function Virtualization (NFV) platforms. The NFVnice framework monitors load on a service chain at high frequency (1000Hz) and employs backpressure to shed load early in the service chain, thereby preventing wasted work. Borrowing concepts such as rate proportional scheduling from hardware packet schedulers, CPU shares are computed by accounting for heterogeneous packet processing costs of NFs, I/O, and traffic arrival characteristics. By leveraging cgroups, a user space process scheduling abstraction exposed by the operating system, NFVnice is capable of controlling when network functions should be scheduled. NFVnice improves NF performance by complementing the capabilities of the OS scheduler but without requiring changes to the OS's scheduling mechanisms. Our controlled experiments show that NFVnice provides the appropriate rate-cost proportional fair share of CPU to NFs and significantly improves NF performance (throughput and loss) by reducing wasted work across an NF chain, compared to using the default OS scheduler. NFVnice achieves this even for heterogeneous NFs with vastly different computational costs and for heterogeneous workloads. © 2017 ACM.",Backpressure; Cgroups; Network Functions (NF); NF-Scheduling,Chains; Convolutional codes; Costs; Scheduling; Space platforms; Transfer functions; Back pressures; Cgroups; Controlled experiment; Dynamic resource scheduling; Heterogeneous workloads; Network functions; Scheduling mechanism; System resource management; Network function virtualization
"Schlinker B., Kim H., Cui T., Katz-Bassett E., Madhyastha H.V., Cunha I., Quinn J., Hasan S., Lapukhov P., Zeng H.",10,Engineering egress with edge fabric steering oceans of content to theworld,2017,13,"Facebook, United States; University of Southern California, United States; Columbia University, United States; University of Michigan, United States; Universidade Federal de Minas Gerais, Brazil",Columbia University;Facebook;Universidade Federal de Minas Gerais;University of Michigan at Ann Arbor;University of Southern California,5,Brazil;USA,2,54,35,"Large content providers build points of presence around the world, each connected to tens or hundreds of networks. Ideally, this connectivity lets providers better serve users, but providers cannot obtain enough capacity on some preferred peering paths to handle peak traffic demands. These capacity constraints, coupled with volatile traffic and performance and the limitations of the 20 year old BGP protocol, make it difficult to best use this connectivity. We present Edge Fabric, an SDN-based system we built and deployed to tackle these challenges for Facebook, which serves over two billion users from dozens of points of presence on six continents. We provide the first public details on the connectivity of a provider of this scale, including opportunities and challenges. We describe how Edge Fabric operates in near real-time to avoid congesting links at the edge of Facebook's network. Our evaluation on production traffic worldwide demonstrates that Edge Fabric efficiently uses interconnections without congesting them and degrading performance.We also present real-time performance measurements of available routes and investigate incorporating them into routing decisions. We relate challenges, solutions, and lessons from four years of operating and evolving Edge Fabric. © 2017 ACM.",Border Gateway Protocol; Content Distribution Network; Internet Routing; Software Defined Networking; Traffic Engineering,Convolutional codes; Social networking (online); Software defined networking; Telecommunication traffic; Border gateway protocol; Capacity constraints; Content distribution networks; Internet routing; Points of presences; Real time performance; Routing decisions; Traffic Engineering; Gateways (computer networks)
"Luckie M., Beverly R.",2,The impact of router outages on the as-level internet,2017,3,"University of Waikato, New Zealand; Naval Postgraduate School, United States",Naval Postgraduate School;University of Waikato,2,New Zealand;USA,2,33,28,"We propose and evaluate a new metric for understanding the dependence of the AS-level Internet on individual routers. Whereas prior work uses large volumes of reachability probes to infer outages, we design an efficient active probing technique that directly and unambiguously reveals router restarts. We use our technique to survey 149,560 routers across the Internet for 2.5 years. 59,175 of the surveyed routers (40%) experience at least one reboot, and we quantify the resulting impact of each router outage on global IPv4 and IPv6 BGP reachability. Our technique complements existing data and control plane outage analysis methods by providing a causal link from BGP reachability failures to the responsible router(s) and multi-homing configurations. While we found the Internet core to be largely robust, we identified specific routers that were single points of failure for the prefixes they advertised. In total, 2,385 routers - 4.0% of the routers that restarted over the course of 2.5 years of probing - were single points of failure for 3,396 IPv6 prefixes announced by 1,708 ASes. We inferred 59% of these routers were the customer-edge border router. 2,374 (70%) of the withdrawn prefixes were not covered by a less specific prefix, so 1,726 routers (2.9%) of those that restarted were single points of failure for at least one network. However, a covering route did not imply reachability during a router outage, as no previously-responsive address in a withdrawn more specific prefix responded during a one-week sample.We validate our reboot and single point of failure inference techniques with four networks, finding no false positive or false negative reboots, but find some false negatives in our single point of failure inferences. © 2017 ACM.",BGP; Internet reliability; Routing; Single points of failure,Convolutional codes; Internet; Internet protocols; Surveys; Active probing techniques; As-level internets; False negatives; Inference techniques; Internet reliabilities; Outage analysis; Routing; Single point; Routers
"Onaolapo J., Mariconti E., Stringhini G.",3,What happens after you are Pwnd: Understanding the use of leaked webmail credentials in the wild,2016,12,"University College London, United Kingdom",University College London,1,UK,1,50,29,"Cybercriminals steal access credentials to webmail accounts and then misuse them for their own profit, release them publicly, or sell them on the underground market. Despite the importance of this problem, the research community still lacks a comprehensive understanding of what these stolen accounts are used for. In this paper, we aim to shed light on the modus operandi of miscreants accessing stolen Gmail accounts. We developed an infrastructure that is able to monitor the activity performed by users on Gmail accounts, and leaked credentials to 100 accounts under our control through various means, such as having information-stealing malware capture them, leaking them on public paste sites, and posting them on underground forums. We then monitored the activity recorded on these accounts over a period of 7 months. Our observations allowed us to devise a taxonomy of malicious activity performed on stolen Gmail accounts, to identify differences in the behavior of cybercriminals that get access to stolen accounts through different means, and to identify systematic attempts to evade the protection systems in place at Gmail and blend in with the legitimate user activity. This paper gives the research community a better understanding of a so far understudied, yet critical aspect of the cybercrime economy.",Cybercrime; Malware; Underground Economy; Webmail,Computer crime; Cybercrime; Legitimate users; Malicious activities; Modus operandi; Protection systems; Research communities; Underground Economy; Webmail; Malware
"Hastings M., Fried J., Heninger N.",3,Weak keys remain widespread in network devices,2016,9,"University of Pennsylvania, United States",University of Pennsylvania,1,USA,1,38,29,"In 2012, two academic groups reported having computed the RSA private keys for 0.5% of HTTPS hosts on the internet, and traced the underlying issue to widespread random number generation failures on networked devices. The vulnerability was reported to dozens of vendors, several of whom responded with security advisories, and the Linux kernel was patched to fix a boottime entropy hole that contributed to the failures. In this paper, we measure the actions taken by vendors and end users over time in response to the original disclosure. We analyzed public internet-wide TLS scans performed between July 2010 and May 2016 and extracted 81 million distinct RSA keys. We then computed the pairwise common divisors for the entire set in order to factor over 313,000 keys vulnerable to the aw, and fingerprinted implementations to study patching behavior over time across vendors. We find that many vendors appear to have never produced a patch, and observed little to no patching behavior by end users of affected devices. The number of vulnerable hosts increased in the years after notification and public disclosure, and several newly vulnerable implementations have appeared since 2012. Vendor notification, positive vendor responses, and even vendor-produced public security advisories appear to have little correlation with end-user security.",Networked devices; Security vulnerabilities,Computer operating systems; HTTP; Linux kernel; Networked devices; Public disclosures; Public internet; Public security; RSA private key; Security advisories; Security vulnerabilities; Random number generation
"Korczynski M., Kr—l M., Van Eeten M.",3,Zone poisoning: The how and where of non-secure DNS dynamic updates,2016,5,"Delft University of Technology, Netherlands; UniversitŽ de Technologie de Compigne, France",TU Delft;UniversitŽ de Technologie de Compigne,2,France;Netherlands,2,41,36,"This paper illuminates the problem of non-secure DNS dynamic updates, which allow a miscreant to manipulate DNS entries in the zone files of authoritative name servers. We refer to this type of attack as to zone poisoning. This paper presents the first measurement study of the vulnerability. We analyze a random sample of 2.9 million domains and the Alexa top 1 million domains and find that at least 1,877 (0.065%) and 587 (0.062%) of domains are vulnerable, respectively. Among the vulnerable domains are governments, health care providers and banks, demonstrating that the threat impacts important services. Via this study and subsequent notifications to affected parties, we aim to improve the security of the DNS ecosystem.",Domain Name System; Dynamic updates; Measurement; Security; Zone poisoning,Health risks; Measurements; Domain name system; Dynamic update; Health care providers; Measurement study; Name servers; Random sample; Secure DNS; Security; Internet protocols
"Luckie M., Dhamdhere A., Huffaker B., Clark D., Claffy K.",5,Bdrmap: Inference of borders between IP Networks,2016,11,"University of Waikato, New Zealand; CAIDA, UC San Diego, United States; MIT, Germany",MIT;University of California San Diego;University of Waikato,3,Germany;New Zealand;USA,3,40,25,"We tackle the tedious and unsolved problem of automatically and correctly inferring network boundaries in traceroute. We explain why such a conceptually sim-ple task is so hard in the real world, and how lack of progress has impeded a wide range of research and de-velopment efforts for decades. We develop and validate a method that uses targeted traceroutes, knowledge of traceroute idiosyncrasies, and codification of topologi-cal constraints in a structured set of heuristics, to cor-rectly identify interdomain links at the granularity of individual border routers. In this study we focus on the network boundaries we have most con-dence we can accurately infer in the presence of sampling bias: in-terdomain links attached to the network launching the traceroute. We develop a scalable implementation of our algorithm and validate it against ground truth infor-mation provided by four networks on 3,277 links, which showed 96.3%-98.9% of our inferences were correct. With 19 vantage points (VPs) distributed across a large U.S. broadband provider, we use our method to re-veal the tremendous density of router-level interconnec-tion between some ASes. In January 2016, the broad-band provider had 45 router-level links with a Tier-1 peer. We also quantify the VP deployment required to observe this ISP's interdomain connectivity, with 17 VPs required to observe all 45 links. Our method forms the cornerstone of the system we are building to map interdomain performance, and we release our code.",Internet topology; Router ownership,Heuristic methods; Routers; Border routers; Broadband providers; Ground truth; Internet topologies; Network boundaries; Sampling bias; Scalable implementation; Unsolved problems; Internet protocols
"Lee Y., Spring N.",2,Identifying and aggregating homogeneous IPv4 /24 blocks with hobbit,2016,4,"University of Maryland, United States",University of Maryland College Park,1,USA,1,44,27,"Addresses in the Internet are typically measured as if they represent larger aggregates. These larger blocks may be based on prefixes advertised through BGP, with larger prefixes broken into ""/24s."" Such an approach is typical in network mapping and other research, and tries to balance the detail available by probing more addresses with the efficiency available by probing only as many as will discover new information. In this paper, we consider prefix homogeneity: The extent to which addresses within the same prefix are colocated in topology and have similar performance. We consider whether ""24"" is the right unit of homogeneity, whether additional efficiency is possible by using larger or even discontiguous address aggregates in some cases, and in what situations additional detail may be missed by treating addresses as representative of /24 blocks. With these results, we present a map of homogeneous address aggregates in the network.",IPv4 /24 block; Last-hop router; Topological proximity,Aggregates; Efficiency; Topology; Co-located; In networks; IPv4 /24 block; Topological proximity; Internet protocols
"Li Z., Wang X., Huang N., Kaafar M.A., Li Z., Zhou J., Xie G., Steenkiste P.",8,An empirical analysis of a large-scale mobile cloud storage service,2016,8,"ICT-CAS, China; CSIRO Data61, Australia; Tsinghua Uni., China; CNIC-CAS, China; CMU, United States",Carnegie Mellon University;CSIRO;Tsinghua University,3,Australia;China;USA,3,34,17,"Cloud storage services are serving a rapidly increasing number of mobile users. However, little is known about the differences between mobile and traditional cloud storage services at scale. In order to understand mobile user access behavior, we analyzed a dataset of 350 million HTTP request logs from a large-scale mobile cloud storage service. This paper presents our results and discusses the implications for system design and network performance. Our key observation is that the examined mobile cloud storage service is dominated by uploads, and the vast majority of users rarely retrieve their uploads during the one-week observation period. In other words, mobile users lean towards the usage of cloud storage for backup. This suggests that delta encoding and chunk-level deduplication found in traditional cloud storage services can be reasonably omitted in mobile scenarios. We also observed that the long idle time between chunk transmissions by Android clients should be shortened since they cause significant performance degradation due to the restart of TCP slow-start. Other observations related to session characteristics, load distribution, user behavior and engagement, and network performance.",Mobile cloud storage; TCP performance; User behavior,HTTP; Mobile telecommunication systems; Network performance; Transmission control protocol; Cloud storage services; Empirical analysis; Load distributions; Mobile clouds; Observation Period; Performance degradation; TCP performance; User behaviors; Behavioral research
"Ghobadi M., Mahajan R.",2,Optical layer failures in a large backbone,2016,9,"Microsoft Research, United States",Microsoft,1,USA,1,30,28,"We analyze optical layer outages in a large backbone, using data for over a year from thousands of optical channels carrying live IP layer traffic. Our analysis uncovers several findings that can help improve network management and routing. For instance, we find that optical links have a wide range of availabilities, which questions the common assumption in fault-Tolerant routing designs that all links have equal failure probabilities. We also find that by monitoring changes in optical signal quality (not visible at IP layer), we can better predict (probabilistically) future outages. Our results suggest that backbone traffic engineering strategies should consider current and past optical layer performance and route computation should be based on the outage-risk profile of the underlying optical links.",Availability; Optical layer; Outage; Q-factor; Wide-Area backbone network,Availability; Network architecture; Optical links; Outages; Q factor measurement; Wide area networks; Failure Probability; Fault tolerant routing; Monitoring change; Optical layers; Q-factors; Route computation; Traffic Engineering; Wide-area backbone networks; Internet protocols
"Alcock S., Mšller J.-P., Nelson R.",3,Sneaking past the firewall: Quantifying the unexpected traffic on major TCP and UDP Ports,2016,0,"University of Waikato, Hamilton, New Zealand",University of Waikato,1,New Zealand,1,26,16,"This study aims to identify and quantify applications that are making use of port numbers that are typically associated with other major Internet applications (i.e. port 53, 80, 123, 443, 8000 and 8080) to bypass port-based traffic controls such as firewalls. We use lightweight packet inspection to examine each flow observed using these ports on our campus network over the course of a week in September 2015 and identify applications that are producing network traffic that does not match the expected application for each port. We find that there are numerous programs that co-opt the port numbers of major Internet applications on our campus, many of which are Chinese in origin and are not recognized by existing traffic classification tools. As a result of our investigation, new rules for identifying over 20 new applications have been made available to the research community.",Application Protocols; Firewalls; Traffic Classification,Computer system firewalls; Telecommunication traffic; Transmission control protocol; Application protocols; Campus network; Internet application; Network traffic; New applications; Packet inspection; Research communities; Traffic classification; Application programs
"Mani S.K., Durairajan R., Barford P., Sommers J.",4,MNTP: Enhancing time synchronization for mobile devices,2016,2,"University of Wisconsin-Madison, United States; ComScore, Inc., United States; Colgate University, United States",Colgate University;ComScore Inc.;;University of Wisconsin-Madison,4,USA,1,18,14,"Clock synchronization between Internet hosts is important in a variety of applications including gaming, finance and measurement. While clock synchronization issues in wireline networks have been well studied, mobile hosts present challenges that have not received as much attention. In this paper, we describe a study of clock synchronization in mobile hosts, which often implement a simplified version of the Network Time Protocol (NTP), known as SNTP, due to resource constraints typical of mobile devices. We begin by reporting an analysis of logs from NTP servers that highlights the significant differences in synchronization behavior of wireline vs. wireless hosts. This analysis motivates a laboratory-based study of the details of clock synchronization on mobile hosts, which reveals the causes and extent to which synchronization can become misaligned. We then describe a new protocol that we call Mobile NTP (MNTP), which is designed to be simple, efficient and easy to deploy. We implement MNTP on a wireless laptop and demonstrate its capability over a range of operating conditions. We find that MNTP maintains clock synchronization to within 25ms of a reference clock, which is over 12 times better than standard SNTP.",Measurement; Mobile; SNTP; Time; Wireless,Clocks; Measurements; Mechanical clocks; Mobile telecommunication systems; Radio; Clock Synchronization; Mobile; Network time protocol; Operating condition; Resource Constraint; SNTP; Time; Time synchronization; Synchronization
"Ahmad S., Haamid A.L., Qazi Z.A., Zhou Z., Benson T., Qazi I.A.",6,A view from the other side: Understanding mobile phone characteristics in the developing world,2016,9,"LUMS, Pakistan; UC Berkeley, United States; Duke University, United States",Duke University;LUMS;University of California Berkeley,3,Pakistan;USA,2,54,20,"Mobile devices are becoming increasingly dominant in the developing world. However, there is little insight into the characteristics of devices being used in such regions. Using a dataset of _0.5 million subscribers from one of the largest cellular operators in Pakistan, we analyze the characteristics of cell phones based on different features (e.g., CPU, memory, and cellular interface). We identify potential device-level bottlenecks for Internet access and analyze the security implications of the phones being used. To aid the analysis of cell phones, we propose abstractions (e.g., connectivity, capacity, and device security) and cluster phones based on these abstractions. Our analysis reveals interesting insights for improving mobile web performance.",Cellular Networks; Developing Regions; Mobile Devices,Abstracting; Cellular telephones; Developing countries; Mobile devices; Mobile phones; Telecommunication equipment; Telephone sets; Cell phone; Cellular interfaces; Cellular network; Cellular operators; Developing regions; Developing world; Internet access; Security implications; Mobile security
"Membrey P., Veitch D., Chang R.K.C.",3,Time to measure the Pi,2016,0,"Department of Computing, Hong Kong Polytechnic University, Hunghom, Hong Kong; School of Computing and Communications, University of Technology, Sydney, Australia",Hong Kong Polytechnic University;University of Technology Sydney,2,Australia;Hong Kong,2,37,20,"The Raspberry Pi platform is increasingly being used for network measurement due to its low cost, ease of de-ployment, and ability to run Linux. Timestamps are a critical part of measurement data, yet the suitability of the Pi for timing has not been established. We use ref-erence hardware to characterize the Pi's STC hardware counter, and to evaluate its performance when paired with a low cost yet powerful GPS 'hat'. We find that the platform can support timing adequate for most mea-surement purposes, but with some caveats.",Clock synchronization; GPS hat; Internet of Thing; Network measurement; PPS; Raspberry Pi,Computer operating systems; Internet of things; Polypropylenes; Clock Synchronization; Hardware counters; Low costs; Measurement data; Network measurement; Time stamps; Hardware
"Jonker M., Sperotto A., Van Rijswijk-Deij R., Sadre R., Pras A.",5,Measuring the adoption of DDoS protection services,2016,11,"University of Twente, Netherlands; University of Twente and SURFnet Bv, Netherlands; UniversitŽ Catholique de Louvain, Belgium",University of Twente;University of Twente;Universite Catholique de Louvain,3,Belgium;Netherlands,2,21,13,"Distributed Denial-of-Service (DDoS) attacks have steadily gained in popularity over the last decade, their intensity ranging from mere nuisance to severe. The increased num-ber of attacks, combined with the loss of revenue for the targets, has given rise to a market for DDoS Protection Ser-vice (DPS) providers, to whom victims can outsource the cleansing of their traffic by using traffic diversion. In this paper, we investigate the adoption of cloud-based DPSs worldwide. We focus on nine leading providers. Our outlook on adoption is made on the basis of active DNS measurements. We introduce a methodology that allows us, for a given domain name, to determine if traffic diversion to a DPS is in effect. It also allows us to distinguish various methods of traffic diversion and protection. For our analysis we use a long-Term, large-scale data set that covers well over 50% of all names in the global domain namespace, in daily snapshots, over a period of 1.5 years. Our results show that DPS adoption has grown by 1.24_ during our measurement period, a prominent trend com-pared to the overall expansion of the namespace. Our study also reveals that adoption is often lead by big players such as large Web hosters, which activate or deactivate DDoS protection for millions of domain names at once.",Active DNS measurements; Cloud-based security; DDoS attack mitigation; Protection networks; Protection services,Distributed computer systems; Internet protocols; Network security; Cloud-based; Ddos attack mitigations; Distributed denial of service attack; Domain names; Global domain; Large scale data sets; Protection services; Traffic diversion; Denial-of-service attack
"Xue M., Ballard C., Liu K., Nemelka C., Wu Y., Ross K., Qian H.",7,You can yak but you can't hide: Localizing anonymous social network users,2016,10,"East China Normal University (ECNU), Shanghai, China; New York University Shanghai (NYU Shanghai), Shanghai, China; New York University (NYU), New York, United States","East China Normal University (ECNU);NYU;NYU,Shanghai",3,China;USA,2,13,13,"The recent growth of anonymous social network services - such as 4chan, Whisper, and Yik Yak - has brought online anonymity into the spotlight. For these services to function properly, the integrity of user anonymity must be preserved. If an attacker can determine the physical location from where an anonymous message was sent, then the attacker can potentially use side information (for example, knowledge of who lives at the location) to de-Anonymize the sender of the message. In this paper, we investigate whether the popular anonymous social media application Yik Yak is susceptible to localization attacks, thereby putting user anonymity at risk. The problem is challenging because Yik Yak application does not provide information about distances between user and message origins or any other message location information. We provide a comprehensive data collection and supervised machine learning methodology that does not require any reverse engineering of the Yik Yak protocol, is fully automated, and can be remotely run from anywhere. We show that we can accurately predict the locations of messages up to a small average error of 106 meters. We also devise an experiment where each message emanates from one of nine dorm colleges on the University of California Santa Cruz campus. We are able to determine the correct dorm college that generated each message 100% of the time.",Anonymous Social Networks; Localization Attack; Machine Learning Inference; Yik Yak,Artificial intelligence; Learning systems; Location; Reverse engineering; Supervised learning; Localization Attack; Location information; Physical locations; Side information; Social network services; Supervised machine learning; University of California; Yik Yak; Social networking (online)
"Guo Y., Qian F., Chen Q.A., Morley Mao Z., Sen S.",5,Understanding on-device bufferbloat for cellular upload,2016,9,"University of Michigan, United States; Indiana University, United States; ATandT Labs-Research, United States",AT and T Labs;Indiana University;University of Michigan at Ann Arbor,3,India;USA,2,25,19,"Despite the extensive characterization of the growth of cellular network traffic, we observe two important trends not yet thoroughly investigated. First, fueled by the LTE technology and applications involving wearable devices and device-Todevice (D2D) communication, device upload traffic is increasingly popular. Second, the multi-Tasking and multiwindow features of modern mobile devices allow many concurrent TCP connections, resulting in potentially complex interactions. Motivated by these new observations, we conduct to our knowledge the first comprehensive characterization of cellular upload traffic and investigate its interaction with other concurrent traffic. In particular, we reveal rather poor performance associated with applications running concurrently with cellular upload traffic, due to excessive ondevice buffering (i.e., on-device bufferbloat). This leads to significant performance degradation on real mobile applications, e.g., 66% of download throughput degradation and more than doubling of page load times. We further systematically study a wide range of solutions for mitigating ondevice bufferbloat, and provide concrete recommendations by proposing a system called QCUT to control the firmware buffer occupancy from the OS kernel.",Bufferbloat; Cellular Networks; Radio Firmware; Upload,Complex networks; Firmware; Mobile devices; Mobile telecommunication systems; Wearable technology; Wireless networks; Bufferbloat; Cellular network; Cellular network traffics; Mobile applications; Performance degradation; Poor performance; Throughput degradation; Upload; Wireless telecommunication systems
"Comarela G., Terzi E., Crovella M.",3,Detecting unusually-routed ASes: Methods and applications,2016,2,"Boston University, United States",Boston University,1,USA,1,47,30,"The routes used in the Internet's interdomain routing system are a rich information source that could be exploited to answer a wide range of questions. However, analyzing routes is dificult, because the fundamental object of study is a set of paths. In this paper we present new analysis tools-metrics and methods-for analyzing AS paths, and apply them to study interdomain routing in the Internet over a recent 13-year period. Our goal is to develop a quantitative understanding of changes in Internet routing at the micro level (of individual ASes) as well as at the macro level (of the set of all ASes). To that end we equip an existing metric (Routing State Distance) with a new set of tools for identifying and characterizing unusually-routed ASes. At the micro level, we use our tools to identify clusters of ASes that have the most unusual routing at each time (interestingly, such clusters often correspond to sets of jointly-owned ASes). We also show that analysis of individual ASes can expose business and engineering strategies of the organizations owning the ASes. These strategies are often related to content delivery or service replication. At the macro level, we show that ASes with the most unusual routing define discernible and interpretable phases of the Internet's evolution. Furthermore, we show that our tools can be used to provide a quantitative measure of the ‡ttening' of the Internet.",Interdomain routing; Path-based network,Content delivery; Information sources; Inter-domain routing systems; Interdomain Routing; Internet routing; nocv1; Path-based; Quantitative measures; Service replications; Measurements
"Siekkinen M., Masala E., KŠmŠrŠinen T.",3,A first look at quality of mobile live streaming experience: The case of periscope,2016,14,"School of Science, Aalto University, Finland; Control and Comp. Eng. Dep., Politecnico di Torino, Italy",Aalto University,1,Finland;Italy,2,37,26,"Live multimedia streaming from mobile devices is rapidly gaining popularity but little is known about the QoE they provide. In this paper, we examine the Periscope service. We first crawl the service in order to understand its usage patterns. Then, we study the protocols used, the typical quality of experience indicators, such as playback smoothness and latency, video quality, and the energy consumption of the Android application.",HLS; Mobile live streaming; Periscope; QoE; RTMP,Energy utilization; Optical instruments; Quality of service; Android applications; Live streaming; Multimedia streaming; Periscope; Quality of experience (QoE); RTMP; Usage patterns; Video quality; Video streaming
"Goncalves G.D., Drago I., Borges A.V., Couto A.P., De Almeida J.M.",5,Analysing costs and benefits of content sharing in cloud storage,2016,2,"UFMG, Brazil; Politecnico di Torino, Italy; UFJF, Brazil","Politecnico di Torino;UFJF, Brazil;UFMG, Brazil",3,Brazil;Italy,2,22,15,"Content sharing is among the most important features of personal cloud storage. It allows users to easily send files to each other, as well as to perform collaborative work in almost real-time. Content sharing seems to attract users to cloud storage, but it comes with a cost: files need to be spread to many user devices, posing extra workload to servers in the cloud. Which pricing model should providers adopt to offer content sharing while remaining profitable? Answering this question is challenging as many factors affect users' and providers' interests. In this paper we take a first step towards answering it. We propose a payoff function that captures costs and benefits of content sharing for both users and providers. We then apply the function to analyse the feasibility of a new pricing model for content sharing. In this new model, users receive credits if they offer upstream bandwidth for providers. Our preliminary results show that this pricing model is advantageous, leading to an increase on payoff of more than 2% of users and providers. © 2016 ACM.",Cloud storage; Dropbox; Pricing,Convolutional codes; Cost benefit analysis; Digital storage; Cloud storages; Collaborative Work; Content Sharing; Costs and benefits; Dropbox; Important features; Payoff function; Personal clouds; Costs
"De Oliveira I.N., Endo P.T., Melo W.D., Sadok D., Kelner J.",5,Should I wait or should I push? A performance analysis of push feature in HTTP/2 connections,2016,5,"Federal University of Pernambuco, Recife, Pernambuco, Brazil; University of Pernambuco, Caruaru, Pernambuco, Brazil",Federal University of Pernambuco;University of Pernambuco,2,Brazil,1,4,4,"Since its standardization, the HTTP has been widely used for transmission of hypertext and hypermedia files, such as audio and video. Recently, the protocol was updated and received modifications, such as server push, focused on improvements in the network usage. This fact introduces new challenges to web developers that raise questions, such as ""which resources should a server push?"" and ""when should a server push resources?"". Due that, it is crucial to analyze which scenarios these new features can be really useful. Therefore, this work presents a performance analysis of server push feature on HTTP/2 connections. According to results, we can observe that, despite the server push be presented as an improvement, regarding to the web page load time, its improper use may cause degradation of the QoE. © 2016 ACM.",HTTP/2; Page load time; QoE; Server push,Convolutional codes; Hypertext systems; Websites; Audio and video; Hypermedia; Network usage; Page load time; Performance analysis; Server pushes; Web developers; HTTP
"Trevisan M., Drago I., Mellia M.",3,Impact of access line capacity on adaptive video streaming quality - A passive perspective,2016,2,"Politecnico di Torino, Italy",Politecnico di Torino,1,Italy,1,7,7,"Adaptive streaming over HTTP is largely used to de-liver live and on-demand video. It works by adjusting video quality according to network conditions. While QoE for different streaming services has been studied, it is still unclear how access line capacity impacts QoE of broadband users in video sessions. We make a first step to answer this question by characterizing parameters in-fluencing QoE, such as frequency of video adaptations. We take a passive point of view, and analyze a dataset summarizing video sessions of a large population for one year. We first split customers based on their estimated access line capacity. Then, we quantify how the latter affects QoE metrics by parsing HTTP requests of Mi-crosoft Smooth Streaming (MSS) services. For selected services, we observe that at least 3 Mbps of downstream capacity is needed to let the player select the best bi-trate, while at least 6 Mbps are required to minimize delays to retrieve initial fragments. Surprisingly, cus-tomers with faster access lines obtain limited benefits, hinting to restrictions on the design of services. © 2016 ACM.",Access line capacity; Live video; QoE-metrics,Convolutional codes; HTTP; Internet; Telecommunication lines; Video streaming; Access lines; Adaptive streaming over http; Adaptive video streaming; Live video; Network condition; QoE-metrics; Selected services; Streaming service; Telecommunication networks
"Casas P., D'Alconzo A., Zseby T., Mellia M.",4,Big-DAMA: Big data analytics for network traffic monitoring and analysis,2016,9,"AIT Vienna, Austria; TU Wien, Austria; Politecnico di Torino, Italy",TU Wien,1,Austria;Italy,2,10,10,"The complexity of the Internet has dramatically increased in the last few years, making it more important and challenging to design scalable Network Traffic Monitoring and Analysis (NTMA) applications and tools. Critical NTMA applications such as the detection of anomalies, network attacks and intrusions, require fast mechanisms for online analysis of thousands of events per second, as well as efficient techniques for offline analysis of massive historical data. We are witnessing a major development in Big Data Analysis Frameworks (BDAFs), but the application of BDAFs and scalable analysis techniques to the NTMA domain remains poorly understood and only in-house and difficult to benchmark solutions are conceived. In this position paper we describe the basis of the Big-DAMA research project, which aims at tackling this growing need by benchmarking and developing novel scalable techniques and frameworks capable to analyze both online network traffic data streams and offline massive traffic datasets. © 2016 ACM.",Big data; Data mining; Data stream processing; Machine learning; Network traffic monitoring and analysis,Benchmarking; Convolutional codes; Data communication systems; Data handling; Data mining; Learning systems; Analysis frameworks; Benchmark solutions; Data stream processing; Network traffic monitoring; Off-line analysis; On-line analysis; Scalable analysis; Scalable networks; Big data
"Siracusano G., Bifulco R., Kuenzer S., Salsano S., Melazzi N.B., Huici F.",6,On-the-fly TCP acceleration with miniproxy,2016,6,"Univ. of Rome Tor Vergata, NEC Laboratories Europe, Germany; NEC Laboratories Europe, Germany; Univ. of Rome Tor Vergata, CNIT, Italy",NEC,1,Germany;Italy,2,21,16,"TCP proxies are basic building blocks for many advanced middleboxes. In this paper we present Miniproxy, a TCP proxy built on top of a specialized minimalistic cloud operating system. Miniproxy's connection handling performance is comparable to that of full-fledged GNU/Linux TCP proxy implementations, but its minimalistic footprint enables new use cases. Specifically, Miniproxy requires as little as 6 MB to run and boots in tens of milliseconds, enabling massive consolidation, on-the-fly instantiation and edge cloud computing scenarios. We demonstrate the benefits of Miniproxy by implementing and evaluating a TCP acceleration use case. © 2016 ACM.",Early SYN Forwarding; HTTP proxy; Middleboxes; TCP Acceleration; TCP proxy; Unikernels,Open source software; Transfer functions; Transmission control protocol; Virtual reality; Basic building block; Early SYN Forwarding; Edge clouds; Handling performance; Middleboxes; On the flies; TCP proxy; Unikernels; Network function virtualization
"Chen J., Ammar M., Fayed M., Fonseca R.",4,Client-driven network-level QoE fairness for encrypted 'DASH-S',2016,4,"Brown University, United States; Georgia Institute of Technology, United States; University of Stirling, United Kingdom",Brown University;Georgia Tech;University of Stirling,3,UK;USA,2,27,22,"Adaptive video streams, when competing behind a bottleneck link, generate flows that lead to instability, under-utilization, and unfairness. Recent studies suggest this negatively impacts users' perceived quality of experience (QoE). Two general classes of solution exist. Client-side bitrate adaptation improves stability and may achieve flow-rate equality. However, operating in isolation, bitrate adaptation has no ability to establish equal end-user experience, or QoE fairness, among competing clients. Conversely, network services can manage bottleneck resources to achieve QoE fairness, yet the widespread use of HTTPS renders them ineffective. In this paper we step back to evaluate the issue with a broad and fully inclusive view of fairness, or equality, by any definition. Our focal contribution is a constructive argument that makes clear, given ubiquitous use of encrypted HTTP, all notions of QoE fairness or equality can only be achieved when clients and network collaborate. Furthermore, operating boundaries are identified with their features and limits.We then architect and implement client-Driven Video Delivery (cDVD), a proof-ofconcept that provides a client-level API into the network, to explore these boundaries. cDVD measurements reinforce our argument and raise new opportunities for exploration. © 2016 ACM.",DASH; Fairness; Performance; Quality of experience,Application programming interfaces (API); Convolutional codes; Cryptography; HTTP; Internet; Video streaming; Bottleneck resources; DASH; End-user experience; Fairness; Network services; Perceived quality; Performance; Quality of experience (QoE); Quality of service
"Sultana N., Kohlweiss M., Moore A.W.",3,Light at the middle of the tunnel: Middleboxes for selective disclosure of network monitoring to distrusted parties,2016,3,"Cambridge University, United Kingdom; Microsoft Research, United States",University of Cambridge;Microsoft,2,UK;USA,2,25,19,"Network monitoring is vital to the administration and operation of networks, but it requires privileged ac-cess that only highly trusted parties are granted. This severely limits opportunities for external parties, such as service or equipment providers, auditors, or even clients, to measure the health or operation of a net-work in which they are stakeholders, but do not have access to its internal structure. In this position paper we propose the use of mid-dleboxes to open up network monitoring to external parties using techniques from privacy-preservation re-search. This would allow distrusted parties to make more inferences about the network state than currently possible, without learning any precise information about the network or data that crosses it. Thus the state of the network would be more trans-parent to external stakeholders, who would be empow-ered to verify claims made by network operators. Net-work operators would be able to provide more informa-tion about their network without compromising security or privacy. © 2016 ACM.",Measurement; Network monitoring; Performance; Privacy; Security,Data privacy; Measurement; Transfer functions; Virtual reality; External stakeholders; Internal structure; Network Monitoring; Network operator; Performance; Position papers; Privacy preservation; Security; Network function virtualization
"Khalid J., Coatsworth M., Gember-Jacobson A., Akella A.",4,A standardized southbound API for VNF management,2016,3,"Department of Computer Sciences, University of Wisconsin, Madison, United States",University of Wisconsin-Madison,1,USA,1,26,24,"Network Function Virtualization (NFV) offers network operators great flexibility toward managing network functions, i.e. in-network appliances such as firewalls, load balancers and NATs. Several frameworks exist to this end; however VNF management is fragmented, and no standard management API exists. As a result, each framework uses a proprietary API which a network function must support to fully realize its benefits. This lack of standardization is a major barrier in the wider adoption of NFV. We propose a standard, framework-agnostic southbound API to facilitate faster adoption of NFV and enable innovation in the design of both management frameworks and network functions. © 2016 ACM.",Network functions virtualization; Service chaining; State management,Computer system firewalls; Transfer functions; Virtual reality; In networks; Load balancer; Management frameworks; Management IS; Network functions; Network operator; Service chaining; State management; Network function virtualization
Vencioneck R.D.,1,"A Datacenter network architecture for low latency, automation and virtualization",2016,0,"PoP-ES, RNP, Brazil","PoP-ES, RNP, Brazil",1,Brazil,1,28,21,"Future Datacenter networking must enable long-term innovation in an automated way, without decreasing the forwarding speed. Current Software Defined Networking (SDN) solutions are creating complex architectures that rely on layers of software overlays above often unknown hardware. This paper proposes Lodenet, a novel software-defined architecture for Datacenter networks that eliminates physical routers and switches, making simplification, visibility, isolation, access policies, service chaining and Network Functions Virtualization (NFV) possible without overlays, and plus lowering forwarding latency. For this purpose, layer two is replaced, letting to servers the core function of forwarding packets, while the border, namely applications and services, receives precalculated routes from controller. A virtual switch prototype shows that, in the proposed network, forwarding latency is about 6 times lower than in traditional Linux virtualization environment. © 2016 Copyright held by the owner/author(s).",Link layer design; Low latency network; Software-defined datacenter,Computer operating systems; Convolutional codes; Network function virtualization; Virtual reality; Virtualization; Complex architectures; Data center networks; Datacenter; Forwarding latency; Link layers; Low-latency networks; Network functions; Software defined networking (SDN); Network architecture
"Rattaro C., Belzarena P.",2,Cognitive Radio Networks: Analysis of a paid-sharing approach based on a fluid model,2016,0,"Facultad de Ingenier’a, Universidad de la Repœblica, Montevideo, Uruguay",Universidad de la Repœblica,1,Uruguay,1,7,7,"Cognitive Radio Networks have emerged in the last years as a solution for two problems: spectrum underutilization and spectrum scarcity. In this context we consider a paid-sharing approach where secondary users (SUs) pay for spectrum utilization. We assume a preemptive system where primary users (PUs) have strict priority over SUs; when a PU arrives to the system and all the channels are busy, a SU will be deallocated. This affected SU will then be reimbursed, implying some cost for the PUs service provider. This paper bears on the analysis of the behavior of the system where the number of users is arbitrary large and an admission control policy over SUs is applied. We develop a computationally efficient way to find an accurate estimation of the optimal admission control boundary based on the fluid limit technique. Our results are validated through numerical examples. © 2016 ACM.",Admission control; Cognitive Radio; Fluid model,Access control; Convolutional codes; Spectrum analysis; Accurate estimation; Admission control policies; Cognitive radio network; Computationally efficient; Fluid modeling; Preemptive systems; Service provider; Spectrum utilization; Cognitive radio
"Turchetti R.C., Duarte E.P., Jr.",3,Computing a precise timeout interval despite a communication channel with varying behavior,2016,0,"CTISM, Federal University of Santa Maria, UFSM, Santa Maria, Brazil; Department Informatics, Federal University of Parana, UFPR, Curitiba, Brazil",Federal University of Parana;Federal University of Santa Maria,2,Brazil,1,5,3,"Computing a precise timeout is critical for the performance of reliable protocols. In this work we propose tuning_ strategy that modifies the strategy proposed by Jacobson, in a way that better reflects a varying behavior of the communication channel. The tuning_ strategy dynamically adjusts the weights employed to compute the timeout. Experimental results obtained from running tuning_ using real traces show that the strategy reduces significantly the number of false detections: it does not reach 1% of the number of false detections of the original algorithm. In addition, our strategy shows a reduction of the fault detection time. © 2016 ACM.",Failure detection; Network reliability; Timeout control,Convolutional codes; Fault detection; Failure detection; False detections; Network reliability; Original algorithms; Real trace; Timeout interval; Communication channels (information theory)
"Dwaraki A., Wolf T.",2,Adaptive service-chain routing for virtual network functions in software-defined networks,2016,20,"Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA, United States",University of Massachusetts Amherst,1,USA,1,5,2,"Software-defined networking is shifting data communication networks toward more centralized control. The availability of virtual machines and lightweight containers enables dynamic placement of virtual network functions on demand. A key challenge is to efficiently route service-chain requests and place processing functions in a network under operational constraints. We present a novel method of solving the node-constrained service chain routing problem in a software-defined network. The main idea is to transform the network representation to a layered graph that considers processing steps and allows the use of conventional shortestpath algorithms, such as Dijkstra's algorithm, to solve the problem. We demonstrate the feasibility of this approach through an emulated prototype implementation that uses dynamic utilization measurements on links and hosts to determine network conditions at runtime. © 2016 ACM.",Layered graph; Network function virtualization; Service chaining; Software defined networking,Chains; Network layers; Routing algorithms; Software defined networking; Transfer functions; Virtual reality; Centralized control; Dijkstra's algorithms; Layered graphs; Network representation; Operational constraints; Prototype implementations; Service chaining; Shortest path algorithms; Network function virtualization
"Berenguer S.S., Carisimo E., Alvarez-Hamelin J.I., Pintor F.V.",4,Hidden Internet topologies info: Truth or myth?,2016,3,"UC3M, Madrid, Spain; INTECIN (UBA-CONICET), Buenos Aires, Argentina","INTECIN, Argentina;UC3M,Spain",2,Argentina;Spain,2,13,7,"Internet mapping projects usually get information from several routing data collectors or vantage points. The accuracy of maps relies on the amount and location of these collectors, which are usually near the backbone or at large developed regions, such as ARIN's or RIPE NCC's. The lack of vantage points in Latin America makes these maps not really show the current actual status of the network in this region. For this reason, in this work we have added data from some local sources and measured how much information was missing without them. © 2016 ACM.",Latin America; Network topology; Traceroute,Convolutional codes; Developed regions; Internet mapping; Internet topologies; Latin America; Local source; Network topology; Routing data; Traceroute; Topology
"Souza C., Mota E., Soares D., Manzoni P., Cano J.C., Calafate C.",6,Improving delivery delay in social-based message forwarding in Delay Tolerant Networks,2016,1,"Federal University of Amazonas, Institute of Computing, Brazil; Universitat of Politecnica de Valencia, Computer Engineering Department, Spain",Federal University of Amazonas;Universitat of Politecnica de Valencia,2,Brazil;Spain,2,10,6,"Friendship and Selfishness Forwarding (FSF) is an algorithm for DTN environments that takes into account two social characteristics of the candidate nodes to relaying messages: the friendship and the individual selfishness. In this paper we adopt DLK, a buffer management policy based on the social relationship strength [5], instead of the Drop Oldest (DO) buffer management strategy previously used. Since the original version of FSF did not deliver 40% of the messages on the average, we try reduce this rate considering the cases in which the relay drops the message because the message TTL expires. We evaluate this situation by using a very large TTL value assigned to each message. Preliminary trace-driven simulations results show that, after these improvements, the FSF algorithm delivers more messages, because DLK keeps in the buffer messages that the relay can deliver in future contacts. The difference between the results, though, are still not statistically negligible, so there is space for further deeper investigation. © 2016 ACM.",Delay tolerant networks; Friendship; Routing; Selfishness; Social characteristics,Convolutional codes; Drops; Wireless networks; Buffer management; Friendship; Message forwarding; Routing; Selfishness; Social characteristics; Social relationships; Trace driven simulation; Delay tolerant networks
"Vanerio J.M., Casas P.",2,WhatsApp calling: A revised analysis on WhatsApp's architecture and calling service,2016,0,"Universidad de la Repœblica, Uruguay; AIT Austrian Institute of Technology, Austria",AIT Austrian Institute of Technology;Universidad de la Repœblica,2,Austria;Uruguay,2,6,6,"The use of instant messaging applications in mobile networks has largely increased in recent years, replacing traditional messaging applications (SMS, MMS). WhatsApp is the application of this kind with the greatest market share worldwide; as a consequence, mobile operators are becoming growingly interested in understanding its underlying functioning and growth. In this paper we revise some of the results presented in our previous work on WhatsApp characterization, and extend this analysis to the new WhatsApp calling service. We study how the underlying WhatsApp architecture has changed after its acquisition by Facebook in early 2014, and shed some initial light on the new calling functionality, active since mid 2015. While the main backbone of the WhatsApp service is still hosted by the same cloud provider - SoftLayer, we uncover the usage of Facebook servers to support and implement the calling service. © 2016 ACM.",Calling service; Network characterization; WhatsApp,Competition; Convolutional codes; Message passing; Social networking (online); Calling service; Cloud providers; Facebook; Instant messaging; Market share; Mobile operators; Network characterization; WhatsApp; Network architecture
"Asghar H.J., Melis L., Soldani C., De Cristofaro E., Kaafar M.A., Mathy L.",6,SplitBox: Toward efficient private network function virtualization,2016,9,"Data61, CSIRO, United Kingdom; University College London, United Kingdom; University of LiŽge, Belgium",University College London;University of Liege,2,Belgium;UK,2,5,2,"This paper presents SplitBox, a scalable system for privately processing network functions that are outsourced as software processes to the cloud. Specifically, providers processing the network functions do not learn the network policies instructing how the functions are to be processed. We first propose an abstract model of a generic network function based on match-action pairs, assuming that this is processed in a distributed manner by multiple honest-but-curious providers. Then, we introduce our SplitBox system for private network function virtualization and present a proof-of-concept implementation on FastClick-an extension of the Click modular router-using a firewall as a use case. Our experimental results show that SplitBox achieves a throughput of over 2 Gbps with 1 kB-sized packets on average, traversing up to 60 firewall rules. © 2016 ACM.",Firewalls; Middlebox Privacy; Network Function Virtualization; Secret Sharing,Computer system firewalls; Transfer functions; Virtual reality; Abstract modeling; Click modular router; Generic networks; Middleboxes; Network functions; Processing Network; Proof of concept; Secret sharing; Network function virtualization
"De Camargo E.T., Duarte E.P., Jr.",3,Network monitoring with imperfect tests,2016,0,"Federal Technology University of Paran‡ (UTFPR), Toledo, Brazil; Federal University of Paran‡ (UFPR), Department of Informatics, Curitiba, Brazil",Federal Technology University of Paran‡ (UTFPR);Federal University of Parana,2,Brazil,1,13,10,"System-level Diagnosis is a long standing theory that employs tests to determine which units of a given system are faulty and fault-free. Diagnosis has been applied to network fault management, including LAN, WAN, and wireless network monitoring. A common assumption of several diagnosis models is that a fault-free tester is capable of correctly determining whether the tested unit is faulty or fault-free. As most real systems are not synchronous, this assumption is actually hard to implement in practice, and thus results in a probabilistic solution. In this work we report our initial efforts to design a model to allow network monitoring with imperfect tests, i.e. a fault-free tester may not be able to correctly determine the state of the tested unit. We investigate our hypothesis through an implementation of a LAN monitoring system. © 2016 ACM.",Network monitoring; System-level Diagnosis,Convolutional codes; Monitoring; Diagnosis model; Imperfect tests; Monitoring system; Network fault management; Network Monitoring; Probabilistic solution; System-level diagnosis; Wireless network monitoring; Fault detection
"Maribondo P.D.S., Fernandes N.C.",2,Avoiding voice traffic degradation in IP enterprise networks using CAoS,2016,1,"Midiacom - PPGEET - UFF, Brazil","Midiacom - PPGEET - UFF, Brazil",1,Brazil,1,12,3,"In this paper we propose a new method for Codec Adaptation Over Software-defined networks: CAoS. This is based on a software-defined network architecture and implements an efficient and innovating approach for voice degradation avoidance in enterprise networks. Enterprise scarce WAN links queue voice traffic and limit it to a certain number of calls by performing QoS and CAC on border elements. This study proposes the use of an existing centralized SDN controller to monitor real-time voice traffic and to avoid voice congestion. We implement a codec adaptation to VoIP peers that are competing for scarce throughput. Emulation tests were performed using Mininet, POX controller, and programmable VoIP clients. CAoS module was added to the software-based controller and it was divided in two sub-modules: monitoring and decision modules. Programmable VoIP clients received a third module, called SIP module, which is responsible for effectively updating the codec in use. The results show that qu0ality of voice increases significantly when congestion occurs in a link and CAoS is running. © 2016 ACM.",Codec; Software defined networking; VoIP,Controllers; Convolutional codes; Internet telephony; Network architecture; Software defined networking; Traffic congestion; Voice/data communication systems; Border element; Codec; Decision modules; Enterprise networks; Real-time voice; Submodules; Voice traffic; VoIP; Internet protocols
"Vidal S., Amaro J.R., Viotti E., Giachino M., Gramp’n E.",5,RAUflow: Building virtual private networks with MPLS and OpenFlow,2016,3,"Instituto de Computaci—n (INCO), Universidad de la Repœblica (UdelaR), Montevideo, Uruguay",Universidad de la Repœblica,1,Uruguay,1,7,6,"Control and Data Plane separation is a well established networking paradigm, fuelled by the raising of Software Defined Networking (SDN), which foresee the implementation of complex, valuable network behaviour over commodity hardware. The Academic Network of Uruguay (in spanish Red Academica Uruguaya - RAU) comprises several universities, research centres and government institutions; RAU is planning a major upgrade, and SDN is a candidate technology to tackle present and future requirements. To test the feasibility of this approach, we built a RAU2 network prototype composed of NetFPGA based routers over 10G optical links. Over this infrastructure we developed RA Uflow, a network control application on top of the Ryu SDN controller, which combines OpenFlow and MPLS to implement network services conforming to RAU evolution requirements. In this paper we analyze the deployment and scalability of VPN services over RAU2 prototype. © 2016 ACM.",Network experimentation; Software Defined Networking; Virtual private networks,Computer networks; Convolutional codes; multi-protocol label switching; Network function virtualization; Optical links; Software defined networking; Commodity hardware; Government institutions; Network control; Network experimentations; Network services; Research centres; Software defined networking (SDN); VPN services; Virtual private networks
"Casas P., Gardlo B., Schatz R., Mellia M.",4,An educated guess on QoE in operational networks through large-scale measurements,2016,5,"AIT Austrian Institute of Technology, Austria; Politecnico di Torino, Austria",AIT Austrian Institute of Technology,1,Austria,1,7,7,"Network monitoring and reporting systems as well as network quality benchmarking campaigns use the Av-erage Downlink Throughput (ADT) as the main Key Performance Indicators (KPIs) reflecting the health of the network. In this paper we address the problem of network performance monitoring and assessment in op-erational networks from a user-centric, Quality of Ex-perience (QoE) perspective. While accurate QoE es-timation requires measurements and KPIs collected at multiple levels of the communications stack - including network, transport, application and end-user layers, we take a practical approach and provide an educated guess on QoE using only a standard ADT-based KPI as input. Armed with QoE models mapping downlink bandwidth to user experience, we estimate the QoE undergone by customers of both cellular and fixed-line networks, using large-scale passive traffic measurements. In particular, we study the performance of three highly popular end-customer services: YouTube, Facebook and WhatsApp. Results suggest that up to 33% of the observed traffic flows might result in sub-optimal - or even poor, end-customer experience in both types of network. © 2016 ACM.",Cellular networks; Network measurements; Performance; QoE; Subjective lab tests,Convolutional codes; Internet; Sales; Cellular network; Fixed line networks; Key performance indicators; Large-scale measurement; Network measurement; Network performance monitoring; Performance; Traffic measurements; Benchmarking
"Bocchi E., De Cicco L., Rossi D.",3,Measuring the quality of experience of web users,2016,8,"TŽlŽcom ParisTech, France; Politecnico di Bari, Italy; ENST, France",Politecnico di Bari;Telecom ParisTech,2,France;Italy,2,19,19,"Measuring quality ofWeb users experience (WebQoE) faces the following trade-off. On the one hand, current practice is to resort to metrics, such as the document completion time (onLoad), that are simple to measure though knowingly inaccurate. On the other hand, there are metrics, like Google's SpeedIndex, that are better correlated with the actual user experience, but are quite complex to evaluate and, as such, relegated to lab experiments. In this paper, we first provide a comprehensive state of the art on the metrics and tools available forWebQoE assessment. We then apply these metrics to a representative dataset (the Alexa top-100 webpages) to better illustrate their similarities, differences, advantages and limitations. We next introduce novel metrics, inspired by Google's SpeedIndex, that (i) offer significant advantage in terms of computational complexity, (ii) while maintaining a high correlation with the SpeedIndex at the same time. These properties makes our proposed metrics highly relevant and of practical use. © 2016 ACM.",Abovethe-fold; ByteIndex; DOM; MOS; ObjectIndex; OnLoad; Quality of experience; SpeedIndex; TTFB; TTFP,Complex networks; Convolutional codes; Economic and social effects; Internet; Molybdenum; Telecommunication networks; Websites; Abovethe-fold; ByteIndex; ObjectIndex; OnLoad; Quality of experience (QoE); SpeedIndex; TTFB; TTFP; Quality of service
"Azevedo E., Aschoff R., Machado M., Sadok D., Melo R., Do Carmo U.",6,Adopting security routines in legacy organizations,2016,0,"GPRT-UFPE, 1235 Moras Rego Av., Recife, Brazil; IFPE-Palmares, Km 186 (PE) BR-101 Rd., Palmares, Brazil; CHESF, 333 Delmiro Gouveia St., Recife, Brazil","GPRT-UFPE, Brazil",1,Brazil,1,20,10,"Security is a critical issue and exploitation of vulnerabilities is increasing in sophistication and damage. Furthermore, legacy systems tend to offer difficulty when upgrades are needed, especially regarding security. This paper presents a strategy based on three topics to adopt secure routines while avoiding production drop in legacy systems. We present a framework prototype and discuss its success in securing the network of a power plant. © 2016 ACM.",Aaa; Information security; Legacy systems; Pbm,Convolutional codes; Security of data; Critical issues; Legacy systems
"Formoso A., Casas P.",2,Looking for network latency clusters in the LAC region,2016,3,"LACNIC Labs, United States; AIT Austrian Institute of Technology, Austria",AIT Austrian Institute of Technology,1,Austria;USA,2,7,3,"Measuring Internet connectivity is complex and represents a major challenge. Successful connectivity measurement requires access to a large number of probes, distributed across the monitored networks, as well as a large number of measurements to capture as much intraand inter-network information as possible. In this paper we present an approach to measure ICMP connectivity based on RTT measurements, performed on a distributed active measurement platform. Based on these measurements, we study the intra-country and intercountry network connectivity within the Latin America and Caribbean (LAC) region. By relying on clustering algorithms, we unveil LAC sub-regions showing better connectivity patterns, and identify regions with poor connectivity. The presented techniques and results are not only highly useful to improve network management and content location in the LAC region, but also to advance the Internet connectivity among LAC countries. © 2016 ACM.",Clustering; Distributed active measurements; Graph analysis; Internet connectivity; Latency,Convolutional codes; Active measurement; Clustering; Graph analysis; Internet connectivity; Latency; Clustering algorithms
"Liu B., Bi J., Zhou Y.",3,Source address validation in software defined networks,2016,7,"Institute for Network Sciences and Cyberspace (INSC), Tsinghua University, China; Tsinghua National Laboratory for Information Science and Technology (TNList), China; Huawei Technologies Co. Ltd., China",Tsinghua University,1,China,1,6,4,"In this paper, we present the preliminary design and implementation of SDN-SAVI, an SDN application that enables SAVI functionalities in SDN networks. In this proposal, all the functionalities are implemented on the controller without modifying SDN switches. To enforce SAVI on packets in the data plane, the controller installs binding tables in switches using existing SDN techniques, such as OpenFlow. With SDN-SAVI, a network administrator can now enforce SAVI in her network by merely integrating a module on the controller, rather than purchasing SAVI-capable switches and replacing legacy ones. © 2016 ACM.",SAVI; SDN,Convolutional codes; Software defined networking; Binding table; Data planes; Network administrator; Openflow; Preliminary design; SAVI; Source address; Controllers
"Li Y., Iannone L.",2,Performance evaluation of locator/identifier separation protocol through RIPE Atlas,2016,2,"Telecom ParisTech, Paris, France",Telecom ParisTech,1,France,1,1,1,"The Locator/Identifier Separation Protocol (LISP) introduces several benefits to the Internet architecture, yet, since it is just in the initial deployment stage, comprehensive understanding of its integration performance with legacy Internet becomes essential. We leverage on RIPE Atlas, the largest Internet measurement infrastructure, to conduct large scale measurements analysis to provide the feedback to improve LISP technology. The preliminary evaluations show that LISP generally has a reliable performance, compared with the existing Internet. From our vantage point, we observe that LISP introduces a non-negligible latency for the European and North American destinations, occasionally some extremely large delay, however, it shows a faster connection for the Asian intercontinental transmission. © 2016 ACM.",Experimentation; LISP; Measurement; RIPE Atlas,Convolutional codes; Internet; Measurements; Network architecture; Experimentation; Internet architecture; Internet measurement; Large-scale measurement; LISP; Locator/identifier separations; Reliable performance; RIPE Atlas; Internet protocols
"Fernandes E.L., Antichi G., Castro I., Uhlig S.",4,Horse: Towards an SDN traffic dynamics simulator for large scale networks,2016,0,"Queen Mary, University of London, United Kingdom; University of Cambridge, United Kingdom",University of Cambridge;University of London,2,UK,1,5,3,"The Software Defined Networking (SDN) paradigm can be successfully applied to the inter-domain ecosystem to empower network fabrics with finer grained policies and traffic engineering capabilities. However, introducing SDN at the inter-domain level might also lead to misconfigurations with potential to negatively impact on the Internet. Simulators are a popular approach to verify network behaviour and test applications before going into production. In the case of SDN, the available options do not scale for large scale networks nor high traffic loads. In this paper we propose a new simulator to foster SDN research and improve our understanding on the impact of the new use cases over the traffic flow. A simulation tool capable of efficiently reproducing large scale networks, high traffic loads, and policies, by abstracting the interactions between switches and controllers of the SDN network. © 2016 Copyright held by the owner/author(s).",Simulation; Software defined networking,Convolutional codes; Simulators; Software defined networking; Large-scale network; Misconfigurations; Network fabric; Simulation; Software defined networking (SDN); Test applications; Traffic dynamics; Traffic Engineering; Computer software
"Singh R., Gill P.",2,PathCache: A path prediction toolkit,2016,1,"Stony Brook University, United States",Stony Brook University,1,USA,1,6,6,"Path prediction on the Internet has been a topic of research in the networking community for close to a decade. Applications of path prediction solutions have ranged from optimizing selection of peers in peer- to-peer networks to improving and debugging CDN predictions. Recently, revelations of traffic correlation and surveillance on the Internet have raised the topic of path prediction in the context of network security. Specifically, predicting network paths can allow us to identify and avoid given organizations on network paths (e.g., to avoid traffic correlation attacks in Tor) or to infer the impact of hijacks and interceptions when direct measurements are not available. In this poster we propose the design and implementation of PathCache which aims to reuse measurement data to estimate AS level paths on the Internet. Unlike similar systems, PathCache does not assume that routing on the Internet is destination based. Instead, we develop an algorithm to compute confidence in paths between ASes. These multiple paths ranked by their confidence values are returned to the user. © 2016 ACM.",Internet measurement,Convolutional codes; Distributed computer systems; Forecasting; Internet; Peer to peer networks; Confidence values; Correlation attack; Design and implementations; Direct measurement; Internet measurement; Measurement data; Networking community; Optimizing selection; Network security
"Zhang P., Bharadia D., Joshi K., Katti S.",4,Enabling backscatter communication among commodity WiFi radios,2016,2,"Stanford University, United States; MIT, United States",MIT;Stanford University,2,USA,1,7,3,"We present the first low power backscatter system that can be deployed completely using commodity WiFi infrastructure. With this system, a low power tag reflects existing 802.11b transmissions from a commodity WiFi transmitter, and the backscattered signals can be decoded as a standard WiFi packet by a commodity 802.11b receiver. The key invention is a novel technique called codeword translation, which allows a backscatter tag to embed its information on standard 802.11b packets by just translating the original transmitted 802.11b codeword to another valid 802.11b codeword. This allows any 802.11b receiver to decode the backscattered packet, thus opening the doors for widespread deployment of low-power backscatter communication using widely available WiFi infrastructure. We show experimentally that we can achieve an uplink throughput of up to 1Mbps at ranges of up to 8m and ranges of up to 50m where it achieves a throughput of around 100Kbps, which is twice as better than the recently published passive WiFi system. © 2016 ACM.",Backscatter; Sensor; Wireless,Backscattering; Convolutional codes; Decoding; Radio; Sensors; Back-scattered; Backscattered signal; Codeword; Low Power; Novel techniques; Wi-Fi transmitters; WiFi systems; Wireless local area networks (WLAN)
"Patra P.G., Rothenberg C., Pongr‡cz G.",3,MACSAD: Multi-architecture compiler system for abstract dataplanes (aka partnering P4 with ODP),2016,4,"University of Campinas (UNICAMP), Campinas, Sao Paulo, Brazil; TrafficLab, Ericsson Research, Budapest, Hungary",Ericsson Research;University of Campinas,2,Brazil;Hungary,2,1,1,"Software Defined Networking (SDN) strives for deep programmable hardware and software dataplanes without giving up on performance. Domain Specific Languages (DSL) such as P4 seek to provide top-down high-level capabilities to define the datapath pipeline agnostic to the network platform and independent from any network protocols. At the crossroads, bottom-up industry efforts at the OpenDataPlane (ODP) initiative are pursuing open-source multi-architecture APIs for dataplane programmability across various networking platforms. Towards P4 code reuse for various targets (portability), we propose MACSAD as a compiler system that brings together the higher-level P4 language and the abstract, target-independent ODP APIs. The demo showcases two P4 applications compiled into heterogeneous datapath platforms supporting ODP. © 2016 ACM.",OpenDataPlane; P4; Software defined networking,Computer programming languages; Convolutional codes; High level languages; Network architecture; Network protocols; Open source software; Problem oriented languages; Software defined networking; Compiler systems; Domain specific languages; Network platforms; Open sources; OpenDataPlane; Programmability; Programmable hardware; Software defined networking (SDN); Program compilers
"Jeong S.H., Kang A.R., Kim J., Kim H.K., Mohaisen A.",5,A longitudinal analysis of .i2p leakage in the public DNS infrastructure,2016,4,"University at Buffalo, SUNY, United States; Korea University, South Korea; Chung-Ang University, South Korea",Chung-Ang University;Korea University;SUNY Buffalo,3,South Korea;USA,2,2,1,"The Invisible Internet Project (I2P) is an overlay network that provides secure and anonymous communication channels. EepSites are the anonymous websites hosted in the I2P network. To access the eepSites, DNS requests of a domain name suffixed with the .i2p pseudo top-level domain (TLD) are routed within the I2P network. However, not only that .i2p queries are leaking in the public DNS infrastructure, but also such leakage has various plausible root causes and implications that are different from other related leakage. In this paper, we analyze the leaked .i2p requests captured in the A and J root name servers of the public DNS, showing that a large number of queries are observed and outlining various potential directions of addressing such leakage. © 2016 ACM.",DNS; I2P; Network analysis; Privacy; Security,Convolutional codes; Data privacy; Electric network analysis; Internet protocols; Overlay networks; Anonymous communication; Domain names; Internet projects; Longitudinal analysis; Root cause; Root name servers; Security; Top level domains; Servers
"De Silva U., Lertsinsrubtavee A., Sathiaseelan A., Kanchanasut K.",4,Named data networking based smart home lighting,2016,6,"Asian Institute of Technology, Thailand; University of Cambridge, United Kingdom",Asian Institute of Technology;University of Cambridge,2,Thailand;UK,2,5,4,"In this paper, we provide an initial evaluation of a home smart lighting system - demonstrating the advantages of ICN paradigm through the primitive features of NDN architecture. A prototype of NDN based smart home lighting was developed and benchmarked against the IP cloud based approach. © 2016 ACM.",Networks _ home networks; Networks _ network design; Networks _ network protocol,Automation; Convolutional codes; Home networks; Intelligent buildings; Network protocols; Personal communication systems; Cloud-based; Named data networkings; Network design; Smart homes; Smart lightings; Lighting
"Yang H., Wang X., Nguyen C.-T., Lu S.",4,Conan: Content-aware access network flow scheduling to improve QoE of home users,2016,1,"National Key Laboratory for Novel Software Technology, Nanjing University, China",Nanjing University,1,China,1,3,3,"There has always been a gap of perception between Internet Service Providers (ISPs) and their customers when considering the performance of network service. On one hand, ISPs invest to increase downstream speed of access network infrastructure. On the other hand, users cannot achieve perceived quality of experience (QoE). This paper addresses this problem by introducing a system, Conan, which enables content-aware flow scheduling to improve the QoE of users. Conan exploits to satisfy users' requirements in the access network (LAN), which is the performance bottleneck actually. By leveraging the technique of software defined networking (SDN), Conan are able to specify the expected network capacity for different applications. Automatic application identification is deployed at home gateway to improve the scalability, and flexible bandwidth allocation is realized at LAN for specified applications. Using video streaming service optimization as an example, we demonstrate that our system can automatically allocate bandwidth for video flows. © 2016 Copyright held by the owner/author(s).",Dynamic resource allocation; QoE; SDN,Application programs; Bandwidth; Convolutional codes; Data flow analysis; Gateways (computer networks); Internet; Internet service providers; Scheduling; Video streaming; Automatic application; Dynamic resource allocations; Network Capacity; Network services; Perceived quality; Performance bottlenecks; Software defined networking (SDN); Video streaming services; Quality of service
"Wang W., Liu C., Su J., He W.",4,Achieving consistent SDN control with declarative applications,2016,0,"McGill University, Canada; Logistic Information Center, PLA, Canada; National University of Defense Technology, China",McGill University;National University of Defense Technology,2,Canada;China,2,3,3,"Software-defined networking enables applications act as blackboxes independently to control the network flexibly. However, these independent applications may generate conflicting control decisions. To reconcile applications automatically and dynamically, we implement control applications with Prolog, which enables applications to execute jointly to make consistent control decisions. When conflicts occur, we design a compromise algorithm by sacrificing a subset of applications to maximize the desired control objectives. © 2016 ACM.",Network control consistency; Software-defined networking,Convolutional codes; Software defined networking; Compromise algorithm; Control applications; Control decisions; Control objectives; Network control; Application programs
"Tilmans O., Vissicchio S., Vanbever L., Rexford J.",4,Fibbing in action: On-demand load-balancing for better video delivery,2016,5,"UniversitŽ Catholique de Louvain, Belgium; ETH ZŸrich, Switzerland; Princeton University, United States",ETH Zurich;Princeton University;Universite Catholique de Louvain,3,Belgium;Switzerland;USA,3,5,5,"Video streaming, in conjunction with social networks, have given birth to a new traffic pattern over the Internet: transient, localized traffic surges, known as flash crowds. Traditional traffic-engineering methods can hardly cope with these surges, as they are unpredictable by nature. Consequently, networks either have to be overprovisioned, which is expensive and wastes resources, or risk to periodically incur congestion, which infuriates customers. This demonstration shows how Fibbing [1] can improve network performance and preserve users' quality of experience when accessing video streams, by implementing a fine-grained load-balancing service. This service leverages two unique features of Fibbing: programming per destination load-balancing and implementing uneven splitting ratios. © 2016 ACM.",Fibbing; Link-state routing; Traffic engineering,Convolutional codes; Quality of service; Video streaming; Fibbing; Link-state routing; Quality of experience (QoE); Splitting ratio; Traffic Engineering; Traffic pattern; Unique features; Video delivery; Network management
"Liu Z., Manousis A., Vorsanger G., Sekar V., Braverman V.",5,One sketch to rule them all: Rethinking network flow monitoring with UnivMon,2016,52,"Johns Hopkins University, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Johns Hopkins University,2,USA,1,5,3,"Network management requires accurate estimates of metrics for many applications including traffic engineering (e.g., heavy hitters), anomaly detection (e.g., entropy of source addresses), and security (e.g., DDoS detection). Obtaining accurate estimates given router CPU and memory constraints is a challenging problem. Existing approaches fall in one of two undesirable extremes: (1) low fidelity general-purpose approaches such as sampling, or (2) high fidelity but complex algorithms customized to specific application-level metrics. Ideally, a solution should be both general (i.e., supports many applications) and provide accuracy comparable to custom algorithms. This paper presents UnivMon, a framework for flow monitoring which leverages recent theoretical advances and demonstrates that it is possible to achieve both generality and high accuracy. UnivMon uses an application-agnostic data plane monitoring primitive; different (and possibly unforeseen) estimation algorithms run in the control plane, and use the statistics from the data plane to compute application-level metrics. We present a proofof-concept implementation of UnivMon using P4 and develop simple coordination techniques to provide a ""one-bigswitch"" abstraction for network-wide monitoring. We evaluate the effectiveness of UnivMon using a range of trace-driven evaluations and show that it offers comparable (and sometimes better) accuracy relative to custom sketching solutions across a range of monitoring tasks. © 2016 ACM.",Flow monitoring; Sketching; Streaming algorithms,Algorithms; Complex networks; Convolutional codes; Network management; Complex algorithms; Coordination technique; Estimation algorithm; Flow monitoring; Memory constraints; Sketching; Streaming algorithm; Traffic Engineering; Monitoring
"Wang Z., Cheng B., Zhai Z., Feng Y., Jin Y., Chen J.",6,EasyApp: A cross-platform mobile applications development environment based on OSGi,2016,2,"State Key Laboratory of Networking and Switching Technology Beijing, University of Posts and Telecommunications, Beijing, China",Beijing University of Posts and Telecommunications,1,China,1,51,29,"The rapid development of mobile internet attracts many end-users to creating mobile applications. Traditional development process cannot meet their needs. We present a cross-platform mobile development environment based on OSGi framework, EasyApp. It provides a highly-integrated, UI-friendly and easily-operating environment. Applications are developed with web techniques. Users could create mobile applications with draggable widgets. Native APIs of mobile phone can be invoked with abundant plugins. After designing, users could package and download applications of multiple platforms. © 2016 ACM.",End-user development; Mobile application; OSGi; Widgets communication,Convolutional codes; Human computer interaction; Mobile telecommunication systems; Development environment; Development process; End user development; Mobile applications; Mobile applications development; Multiple platforms; Operating environment; OSGi; Mobile computing
"Zhang P., Rostami M., Hu P., Ganesan D.",4,Enabling practical backscatter communication for on-body sensors,2016,32,"College of Information and Computer Sciences, University of Massachusetts, Amherst, MA  01003, United States",University of Massachusetts Amherst,1,USA,1,2,2,"In this paper, we look at making backscatter practical for ultra-low power on-body sensors by leveraging radios on existing smartphones and wearables (e.g. WiFi and Bluetooth). The difficulty lies in the fact that in order to extract the weak backscattered signal, the system needs to deal with self interference from the wireless carrier (WiFi or Bluetooth) without relying on built-in capability to cancel or reject the carrier interference. Frequency-shifted backscatter (or FS-Backscatter) is based on a novel idea - the backscatter tag shifts the carrier signal to an adjacent non-overlapping frequency band (i.e. adjacent WiFi or Bluetooth band) and isolates the spectrum of the backscattered signal from the spectrum of the primary signal to enable more robust decoding. We show that this enables communication of up to 4.8 meters using commercial WiFi and Bluetooth radios as the carrier generator and receiver. We also show that we can support a range of bitrates using packet-level and bit-level decoding methods. We build on this idea and show that we can also leverage multiple radios typically present on mobile and wearable devices to construct multi-carrier or multi-receiver scenarios to improve robustness. Finally, we also address the problem of designing an ultra-low power tag that can frequency shift by 20MHz while consuming tens of micro-watts. Our results show that FS-Backscatter is practical in typical mobile and static on-body sensing scenarios while only using commodity radios and antennas. © 2016 ACM.",Backscatter; Sensor; Wireless,Backscattering; Bluetooth; Convolutional codes; Decoding; Electromagnetic wave backscattering; Frequency bands; Radio; Radio systems; Sensors; Wearable antennas; Wearable technology; Wi-Fi; Wireless local area networks (WLAN); Backscattered signal; Bluetooth radio; Carrier interference; Decoding methods; Frequency shift; Self-interferences; Wearable devices; Wireless carriers; Wearable sensors
"Chen A., Wu Y., Haeberlen A., Zhou W., Loo B.T.",5,"The good, the bad, and the differences: Better network diagnostics with differential provenance",2016,16,"University of Pennsylvania, United States; Georgetown University, United States",Georgetown University;University of Pennsylvania,2,USA,1,55,42,"In this paper, we propose a new approach to diagnosing problems in distributed systems. Our approach is based on the insight that many of the trickiest problems are anomalies. For instance, in a network, problems often affect only a small fraction of the traffic (perhaps a certain subnet), or they only manifest infrequently. Thus, it is quite common for the operator to have ""examples"" of both working and non-working traffic readily available - perhaps a packet that was misrouted, and a similar packet that was routed correctly. In this case, the cause of the problem is likely to be wherever the two packets were treated differently by the network. We present the design of a debugger that can leverage this information using a novel concept that we call differential provenance. Differential provenance tracks the causal connections between network states and state changes, just like classical provenance, but it can additionally perform rootcause analysis by reasoning about the differences between two provenance trees. We have built a diagnostic tool that is based on differential provenance, and we have used our tool to debug a number of complex, realistic problems in two scenarios: software-defined networks and MapReduce jobs. Our results show that differential provenance can deliver very concise diagnostic information; in many cases, it can even identify the precise root cause of the problem. © 2016 Copyright held by the owner/author(s).",Debugging; Network diagnostics; Provenance,Computer debugging; Convolutional codes; Program debugging; Program diagnostics; Diagnostic tools; Distributed systems; Network diagnostics; Network state; New approaches; Novel concept; Provenance; Root cause analysis; Complex networks
"Flach T., Papageorge P., Terzis A., Pedrosa L.D., Cheng Y., Karim T., Katz-Bassett E., Govindan R.",8,An Internet-wide analysis of traffic policing,2016,17,"University of Southern California, United States; Google, United States",Google;University of Southern California,2,USA,1,37,29,"Large flows like video streams consume significant bandwidth. Some ISPs actively manage these high volume flows with techniques like policing, which enforces a flow rate by dropping excess traffic. While the existence of policing is well known, our contribution is an Internet-wide study quantifying its prevalence and impact on transport-level and video-quality metrics. We developed a heuristic to identify policing from server-side traces and built a pipeline to process traces at scale collected from hundreds of Google servers worldwide. Using a dataset of 270 billion packets served to 28,400 client ASes, we find that, depending on region, up to 7% of connections are identified to be policed. Loss rates are on average 6x higher when a trace is policed, and it impacts video playback quality. We show that alternatives to policing, like pacing and shaping, can achieve traffic management goals while avoiding the deleterious effects of policing. © 2016 Copyright held by the owner/author(s).",Network measurement; TCP; Traffic policing; Traffic shaping,Convolutional codes; Internet; Video streaming; Deleterious effects; Network measurement; Server sides; Traffic management; Traffic policing; Traffic-shaping; Video Playback; Video quality; Internet service providers
"Gember-Jacobson A., Viswanathan R., Akella A., Mahajan R.",4,Fast control plane analysis using an abstract representation,2016,13,"University of Wisconsin-Madison, United States; Microsoft Research, China",Microsoft;;University of Wisconsin-Madison,3,China;USA,2,68,36,"Networks employ complex, and hence error-prone, routing control plane configurations. In many cases, the impact of errors manifests only under failures and leads to devastating effects. Thus, it is important to proactively verify control plane behavior under arbitrary link failures. State-of-the-art verifiers are either too slow or impractical to use for such verification tasks. In this paper we propose a new high level abstraction for control planes, ARC, that supports fast control plane analyses under arbitrary failures. ARC can check key invariants without generating the data plane - which is the main reason for current tools' ineffectiveness. This is possible because of the nature of verification tasks and the constrained nature of control plane designs in networks today. We develop algorithms to derive a network's ARC from its configuration files. Our evaluation over 314 networks shows that ARC computation is quick, and that ARC can verify key invariants in under 1s in most cases, which is orders-of-magnitude faster than the state-of-the-art. © 2016 ACM.",Abstract representation; Control plane; Network verification,Convolutional codes; Abstract representation; Arbitrary failures; Configuration files; Control planes; Devastating effects; Orders of magnitude; State of the art; Verification task; Complex networks
"Voellmy A., Chen S., Wang X., Yang Y.R.",4,Magellan: Generating multi-table datapath from datapath oblivious algorithmic SDN policies,2016,2,"Yale University, United States; Tongji University, China",Tongji University;Yale University,2,China;USA,2,25,15,"Despite the emergence of multi-table pipelining as a key feature of next-generation SDN data-path models, there is no existing work that addresses the substantial programming challenge of utilizing multi-tables automatically. In this paper, we present Magellan, the first system that addresses the aforementioned challenge. Introducing two novel, substantial algorithms, map-explore and table-design, Magellan achieves automatic derivation and population of multi-table pipelines from a datapath-oblivious, high-level SDN program written in a general-purpose language. Comparing the flow tables generated by Magellan with those produced from standard SDN controllers including OpenDaylight and Floodlight, we show that Magellan uses between 46-68x fewer rules. © 2016 ACM.",Multi-table pipeline; Programming model; SDN,Convolutional codes; Electric lighting; High level languages; Pipelines; Automatic derivation; Data paths; First systems; Flow tables; General purpose languages; Key feature; Programming models; Table design; Algorithms
"McCauley J., Zhao M., Jackson E.J., Raghavan B., Ratnasamy S., Shenker S.",6,The deforestation of L2,2016,2,"UC Berkeley, ICSI, United States; UESTC, ICSI, United States; UC Berkeley, United States; ICSI, United States",University of California Berkeley,1,USA,1,1,1,"A major staple of layer 2 has long been the combination of flood-and-learn Ethernet switches with some variant of the Spanning Tree Protocol. However, STP has significant shortcomings - chiefly, that it throws away network capacity by removing links, and that it can be relatively slow to reconverge after topology changes. In recent years, attempts to rectify these shortcomings have been made by either making L2 look more like L3 (notably TRILL and SPB, which both incorporate L3-like routing) or by replacing L2 switches with ""L3 switching"" hardware and extending IP all the way to the host. In this paper, we examine an alternate point in the L2 design space, which is simple (in that it is a single data plane mechanism with no separate control plane), converges quickly, delivers packets during convergence, utilizes all available links, and can be extended to support both equal-cost multipath and efficient multicast. © 2016 ACM.",L2 routing; Spanning tree,Convolutional codes; Control planes; Design spaces; Ethernet switches; L2 routing; Network Capacity; Spanning tree; Spanning tree protocols; Topology changes; Deforestation
"Sivaraman A., Subramanian S., Alizadeh M., Chole S., Chuang S.-T., Agrawal A., Balakrishnan H., Edsall T., Katti S., McKeown N.",10,Programmable packet scheduling at line rate,2016,20,"MIT CSAIL, United States; Barefoot Networks, United States; Cisco Systems, United States; Stanford University, United States",MIT;Stanford University,2,USA,1,32,19,"Switches today provide a small menu of scheduling algorithms. While we can tweak scheduling parameters, we cannot modify algorithmic logic, or add a completely new algorithm, after the switch has been designed. This paper presents a design for a programmable packet scheduler, which allows scheduling algorithms - potentially algorithms that are unknown today - to be programmed into a switch without requiring hardware redesign. Our design uses the property that scheduling algorithms make two decisions: in what order to schedule packets and when to schedule them. Further, we observe that in many scheduling algorithms, definitive decisions on these two questions can be made when packets are enqueued. We use these observations to build a programmable scheduler using a single abstraction: the push-in first-out queue (PIFO), a priority queue that maintains the scheduling order or time. We show that a PIFO-based scheduler lets us program a wide variety of scheduling algorithms. We present a hardware design for this scheduler for a 64-port 10 Gbit/s shared-memory (output-queued) switch. Our design costs an additional 4% in chip area. In return, it lets us program many sophisticated algorithms, such as a 5-level hierarchical scheduler with programmable decisions at each level. © 2016 Copyright held by the owner/author(s).",Programmable scheduling; Switch hardware,Algorithms; Convolutional codes; Design; Hardware; Reconfigurable hardware; Scheduling; 10-Gbit/s; Design costs; Hardware design; Packet scheduler; Packet scheduling; Priority queues; Scheduling parameters; Shared memory; Scheduling algorithms
"Li B., Tan K., Luo L., Peng Y., Luo R., Xu N., Xiong Y., Cheng P., Chen E.",9,ClickNP: Highly flexible and high performance network processing with reconfigurable hardware,2016,38,"Microsoft Research, China; USTC, China; Microsoft, China; SJTU, China",Microsoft,1,China,1,42,13,"Highly flexible software network functions (NFs) are crucial components to enable multi-tenancy in the clouds. However, software packet processing on a commodity server has limited capacity and induces high latency. While software NFs could scale out using more servers, doing so adds significant cost. This paper focuses on accelerating NFs with programmable hardware, i.e., FPGA, which is now a mature technology and inexpensive for datacenters. However, FPGA is predominately programmed using low-level hardware description languages (HDLs), which are hard to code and difficult to debug. More importantly, HDLs are almost inaccessible for most software programmers. This paper presents ClickNP, a FPGA-accelerated platform for highly flexible and high-performance NFs with commodity servers. ClickNP is highly flexible as it is completely programmable using high-level C-like languages, and exposes a modular programming abstraction that resembles Click Modular Router. ClickNP is also high performance. Our prototype NFs show that they can process traffic at up to 200 million packets per second with ultra-low latency (< 2_s). Compared to existing software counterparts, with FPGA, ClickNP improves throughput by 10x, while reducing latency by 10x. To the best of our knowledge, ClickNP is the first FPGA-accelerated platform for NFs, written completely in high-level language and achieving 40 Gbps line rate at any packet size. © 2016 ACM.",Compiler; FPGA; Network function virtualization; Reconfigurable hardware,C (programming language); Computer hardware; Computer hardware description languages; Computer programming; Computer programming languages; Computer software; Convolutional codes; Field programmable gate arrays (FPGA); Hardware; High level languages; Packet networks; Transfer functions; Click modular router; Compiler; High performance networks; Million packets per seconds; Modular programming; Packet processing; Programmable hardware; Virtualizations; Reconfigurable hardware
"Chen L., Chen K., Bai W., Alizadeh M.",4,Scheduling mix-flows in commodity datacenters with Karuna,2016,28,"SING Group, CSE Department, Hong Kong University of Science and Technology, Hong Kong",Hong Kong University of Science and Technology,1,Hong Kong,1,46,33,"Cloud applications generate a mix of flows with and without deadlines. Scheduling such mix-flows is a key challenge; our experiments show that trivially combining existing schemes for deadline/non-deadline flows is problematic. For example, prioritizing deadline flows hurts flow completion time (FCT) for non-deadline flows, with minor improvement for deadline miss rate. We present Karuna, a first systematic solution for scheduling mix-flows. Our key insight is that deadline flows should meet their deadlines while minimally impacting the FCT of non-deadline flows. To achieve this goal, we design a novel Minimal-impact Congestion control Protocol (MCP) that handles deadline flows with as little bandwidth as possible. For non-deadline flows, we extend an existing FCT minimization scheme to schedule flows with known and unknown sizes. Karuna requires no switch modifications and is backward compatible with legacy TCP/IP stacks. Our testbed experiments and simulations show that Karuna effectively schedules mix-flows, for example, reducing the 95th percentile FCT of non-deadline flows by up to 47.78% at high load compared to pFabric, while maintaining low (<5.8%) deadline miss rate. © 2016 Copyright held by the owner/author(s).",Datacenter network; Deadline; Flow scheduling,Convolutional codes; Transmission control protocol; Backward compatible; Cloud applications; Completion time; Congestion control protocols; Data center networks; Data centers; Deadline; Flow scheduling; Scheduling
"Govindan R., Minei I., Kallahalla M., Koley B., Vahdat A.",5,Evolve or die: High-availability design principles drawn from Google's network infrastructure,2016,45,"Google, United States; University of Southern California, United States",Google;University of Southern California,2,USA,1,40,11,"Maintaining the highest levels of availability for content providers is challenging in the face of scale, network evolution, and complexity. Little, however, is known about the network failures large content providers are susceptible to, and what mechanisms they employ to ensure high availability. From a detailed analysis of over 100 high-impact failure events within Google's network, encompassing many data centers and two WANs, we quantify several dimensions of availability failures. We find that failures are evenly distributed across different network types and across data, control, and management planes, but that a large number of failures happen when a network management operation is in progress within the network. We discuss some of these failures in detail, and also describe our design principles for high availability motivated by these failures. These include using defense in depth, maintaining consistency across planes, failing open on large failures, carefully preventing and avoiding failures, and assessing root cause quickly. Our findings suggest that, as networks become more complicated, failures lurk everywhere, and, counter-intuitively, continuous incremental evolution of the network can, when applied together with our design principles, result in a more robust network. © 2016 Copyright held by the owner/author(s).",Availability; Control plane; Management plane,Availability; Complex networks; Convolutional codes; Network management; Telecommunication networks; Control planes; Design Principles; High availability; Incremental evolutions; Management operation; Management planes; Network evolution; Network infrastructure; Information management
"Arzani B., Ciraci S., Loo B.T., Schuster A., Outhred G.",5,Taking the blame game out of data centers operations with NetPoirot,2016,13,"University of Pennsylvania, United States; Microsoft, China; Technion, United States",Microsoft;University of Pennsylvania,2,China;USA,2,39,26,"Today, root cause analysis of failures in data centers is mostly done through manual inspection. More often than not, customers blame the network as the culprit. However, other components of the system might have caused these failures. To troubleshoot, huge volumes of data are collected over the entire data center. Correlating such large volumes of diverse data collected from different vantage points is a daunting task even for the most skilled technicians. In this paper, we revisit the question: how much can you infer about a failure in the data center using TCP statistics collected at one of the endpoints? Using an agent that captures TCP statistics we devised a classification algorithm that identifies the root cause of failure using this information at a single endpoint. Using insights derived from this classification algorithm we identify dominant TCP metrics that indicate where/why problems occur in the network. We validate and test these methods using data that we collect over a period of six months in the Azure production cloud. © 2016 ACM.",Data centers; Network diagnostics; TCP,Convolutional codes; Classification algorithm; Data centers; Large volumes; Manual inspection; Network diagnostics; Root cause analysis; Root cause of failures; Troubleshoots; Classification (of information)
"Cohen A., Gilad Y., Herzberg A., Schapira M.",4,Jumpstarting BGP security with path-end validation,2016,8,"Hebrew University of Jerusalem, Israel; Boston University, MIT, United States; Bar-Ilan University, Israel",Bar-Ilan University;Boston University;Hebrew University of Jerusalem;MIT,4,Israel;USA,2,31,20,"Extensive standardization and R&D efforts are dedicated to establishing secure interdomain routing. These efforts focus on two mechanisms: origin authentication with RPKI, and path validation with BGPsec. However, while RPKI is finally gaining traction, the adoption of BGPsec seems not even on the horizon due to inherent, possibly insurmountable, obstacles, including the need to replace today's routing infrastructure and meagre benefits in partial deployment. Consequently, secure interdomain routing remains a distant dream. We propose an easily deployable, modest extension to RPKI, called ""path-end validation"", which does not entail replacing/upgrading today's BGP routers. We show, through rigorous security analyses and extensive simulations on empirically derived datasets, that path-end validation yields significant benefits even in very limited partial adoption. We present an open-source, readily deployable prototype implementation of path-end validation. © 2016 ACM.",BGP security; Routing security; RPKI,Bgp securities; Extensive simulations; Origin authentications; Prototype implementations; Routing infrastructure; Routing security; RPKI; Secure inter-domain routing; Convolutional codes
"Wang Y., Lin D., Li C., Zhang J., Liu P., Hu C., Zhang G.",7,Application driven network: Providing on-demand services for applications,2016,10,"Huawei Future Network Theory Lab, Hong Kong; Huawei Wireless Technology Lab, China; Xi'an Jiaotong University, China",Xian JiaoTong University,1,China;Hong Kong,2,46,34,Application Driven Network (ADN) is a new paradigm that provides on-demand differentiated services for applications. A physical network in ADN is sliced into various logically isolated sub-networks. Each network slice can have its own network architecture and protocol to serve one application exclusively. ADN enhances the user experience while keeping the resource efficiency by further imposing multiplexing among these logically isolated sub-networks. © 2016 Copyright held by the owner/author(s).,Application driven network; DiffServ; NFV; SDN,Convolutional codes; Quality of service; Differentiated Services; DiffServ; On demands; On-demand services; Physical network; Resource efficiencies; Sub-network; User experience; Network architecture
"Li Z., Zhang Y., Zhao Y., Peng Y., Li D.",5,Best effort task scheduling for data parallel jobs,2016,0,"National Lab. for Parallel and Distributed Processing, National University of Defense Technology, China",National University of Defense Technology,1,China,1,4,4,"The tasks of data-parallel computation jobs come up with diverse and time-varying resource requirements. The dynamic nature of task requirements brings challenges on making good scheduling decisions. In this paper, we present BETS to cope with the requirement dynamics that aims at maximizing cluster resource utilization. BETS employs a task model that represents runtime task requirements, a coarse-grained task pipeline to make fully use of resources in a time-division multiplexing fashion, and fine-grained resource management to guarantee performance. © 2016 ACM.",Data-parallel jobs; Task model; Task scheduling,Convolutional codes; Scheduling algorithms; Time division multiplexing; Data parallel; Resource management; Resource requirements; Resource utilizations; Scheduling decisions; Task modeling; Task pipelines; Task-scheduling; Multitasking
"Yiakoumis Y., Katti S., McKeown N.",3,Neutral net neutrality,2016,5,"Stanford University, United States",Stanford University,1,USA,1,4,4,"Should applications receive special treatment from the network? And if so, who decides which applications are preferred? This discussion, known as net neutrality, goes beyond technology and is a hot political topic. In this paper we approach net neutrality from a user's perspective. Through user studies, we demonstrate that users do indeed want some services to receive preferential treatment; and their preferences have a heavy-tail: a one-size-fits-all approach is unlikely to work. This suggests that users should be able to decide how their traffic is treated. A crucial part to enable user preferences, is the mechanism to express them. To this end, we present network cookies, a general mechanism to express user preferences to the network. Using cookies, we prototype Boost, a user-defined fast-lane and deploy it in 161 homes. © 2016 Copyright held by the owner/author(s).",Differentiated services; Fast-lanes; Net neutrality; Network cookies; Zero-rating,Convolutional codes; Quality of service; Differentiated Services; Fast-lanes; Heavy-tails; Net neutralities; Special treatments; User study; Internet
"Sun C., Bi J., Zheng Z., Hu H.",4,SLA-NFV: An SLA-aware high performance framework for network function virtualization,2016,1,"Institute for Network Sciences and Cyberspace, Tsinghua University, China; Department of Computer Science, Tsinghua University, China; Tsinghua National Laboratory for Information Science and Technology (TNList), China; Clemson University, United States",Clemson University;Tsinghua University,2,China;USA,2,32,17,"We propose SLA-NFV, a Service Level Agreement (SLA) aware framework, for building high-performance NFV, focusing on fulfilling SLAs of service subscribers (or tenants). SLA-NFV leverages a hybrid infrastructure with both software and programmable hardware to enhance NFV's capability with respect to various SLAs. Evaluations show that a hybrid service chain could reduce latency by up to 60% compared with a pure software service chain. © 2016 Copyright held by the owner/author(s).",High Performance; Hybrid Infrastructure; NFV; SLA,Convolutional codes; High Performance; Hybrid Infrastructure; Hybrid services; Network functions; Performance frameworks; Programmable hardware; Service Level Agreements; Software services; Chains
"Nagaraj K., Bharadia D., Mao H., Chinchali S., Alizadeh M., Katti S.",6,NUMFabric: Fast and flexible bandwidth allocation in datacenters,2016,13,"Stanford University, United States; MIT CSAIL, United States",MIT;Stanford University,2,USA,1,3,3,"We present NUMFabric, a novel transport design that provides flexible and fast bandwidth allocation control. NUMFabric is flexible: it enables operators to specify how bandwidth is allocated amongst contending flows to optimize for different service-level objectives such as weighted fairness, minimizing flow completion times, multipath resource pooling, prioritized bandwidth functions, etc. NUMFabric is also very fast: it converges to the specified allocation 2.3x faster than prior schemes. Underlying NUMFabric is a novel distributed algorithm for solving network utility maximization problems that exploits weighted fair queueing packet scheduling in the network to converge quickly. We evaluate NUMFabric using realistic datacenter topologies and highly dynamic workloads and show that it is able to provide flexibility and fast convergence in such stressful environments. © 2016 Copyright held by the owner/author(s).",Convergence; Network utility maximization; Packet scheduling; Resource allocation; Weighted max-min,Convolutional codes; Packet networks; Resource allocation; Scheduling algorithms; Telecommunication services; Convergence; Different services; Fast convergence; Max-min; Network utility maximization; Packet scheduling; Weighted fair queueing; Weighted fairness; Bandwidth
"Moln‡r L., Pongr‡cz G., Enyedi G., Kis Z.L., Csikor L., Juh‡sz F., Koršsi A., RŽtv‡ri G.",8,Dataplane specialization for high-performance OpenFlow software switching,2016,11,"TrafficLab., Ericsson Research, Hungary; Department of Telecommunications and Media Informatics, BME, Hungary; MTA-BME Information Systems Research Group, Hungary",Ericsson Research;MTA-BME,2,Hungary,1,69,33,"OpenFlow is an amazingly expressive dataplane programming language, but this expressiveness comes at a severe performance price as switches must do excessive packet classification in the fast path. The prevalent OpenFlow software switch architecture is therefore built on flow caching, but this imposes intricate limitations on the workloads that can be supported efficiently and may even open the door to malicious cache overflow attacks. In this paper we argue that instead of enforcing the same universal flow cache semantics to all OpenFlow applications and optimize for the common case, a switch should rather automatically specialize its dataplane piecemeal with respect to the configured workload. We introduce ESWITCH, a novel switch architecture that uses on-the-fly template-based code generation to compile any OpenFlow pipeline into efficient machine code, which can then be readily used as fast path. We present a proof-of-concept prototype and we demonstrate on illustrative use cases that ESWITCH yields a simpler architecture, superior packet processing speed, improved latency and CPU scalability, and predictable performance. Our prototype can easily scale beyond 100 Gbps on a single Intel blade even with complex OpenFlow pipelines. © 2016 ACM.",OpenFlow software switching; Packet classification; Template-based code generation,Codes (symbols); Convolutional codes; Packet networks; Pipelines; Semantics; Code Generation; Openflow; Overflow attacks; Packet classification; Packet-processing speed; Proof of concept; Software switches; Switch architectures; Pipeline codes
"Edmundson A., Ensafi R., Feamster N., Rexford J.",4,A first look into transnational routing detours,2016,1,"Princeton University, United States",Princeton University,1,USA,1,66,45,"An increasing number of countries are passing laws that facilitate the mass surveillance of their citizens. In response, governments and citizens are increasingly paying attention to the countries that their Internet traffic traverses. In some cases, countries are taking extreme steps, such as building new IXPs and encouraging local interconnection to keep local traffic local. We find that although many of these efforts are extensive, they are often futile, due to the inherent lack of hosting and route diversity for many popular sites. We investigate how the use of overlay network relays and the DNS open resolver infrastructure can prevent traffic from traversing certain jurisdictions. Copyright 2016 ACM.",Routing; Surveillance,Convolutional codes; Overlay networks; Space surveillance; First look; Internet traffic; Route diversity; Routing; Network security
"Rostami A., …hlŽn P., Santos M.A.S., Vidal A.",4,Multi-domain orchestration across RAN and transport for 5G,2016,3,"Ericsson Research, Finland",Ericsson Research,1,Finland,1,4,2,"End-to-End programmability across radio, transport and compute resources is a key enabler for the fifth generation of mobile communication networks (5G). In our work we look into how SDN can realize the required cross-domain programmability, as well as slicing of resources towards multiple clients. We present design and implementation of a hierarchical, modular and programmable orchestration architecture across radio access networks and transport networks. We demonstrate how the developed multi-domain orchestration improves the service creation as well as resource utilization across the domains using real-time monitoring. © 2016 ACM.",5G; Multi-domain orchestration; Network slicing; SDN,Design and implementations; Mobile communication networks; Multi domains; Network slicing; Radio access networks; Real time monitoring; Resource utilizations; Transport networks; Convolutional codes
"Zhang Y., Xu K., Yao G., Zhang M., Nie X.",5,PieBridge: A cross-DR scale large data transmission scheduling system,2016,3,"Tsinghua University, China; Baidu, China; Tsinghua National Laboratory for Information Science and Technology, China",Tsinghua University,1,China,1,2,1,"Cross-DR WAN (Datacenter Region Wide Area Network) with various services are deployed to provide timely data information and analytics for users in a wide range of geographical locations. For its reliability and performance, data duplication synchronization is essential among different IDCs (Internet datacenters). However, this problem poses a challenge. First, data duplication requires huge amount of bandwidth whereas the bandwidth of cross-DR links and the upload/download rates of server interfaces are limited. Second, data transmissions are time sensitive, but the current network cannot complete such tasks in a timely manner. In this work, we present PieBridge, a cross-RD data duplicate transmission platform that accommodates hundreds of TBs of data generated from user applications online data analytics. We deployed PieBridge on the IDCs of Baidu and obtained promising performance results in comparison with the prevalent approaches. © 2016 ACM.",Cross-DR WAN; Large-scale data transmission,Bandwidth; Convolutional codes; Data communication systems; Data transfer; Data centers; Data duplication; Data informations; Geographical locations; Large data; Large scale data; Online data; Server interfaces; Wide area networks
"Ghobadi M., Mahajan R., Phanishayee A., Devanur N., Kulkarni J., Ranade G., Blanche P.-A., Rastegarfar H., Glick M., Kilper D.",10,ProjecToR: Agile reconfigurable data center interconnect,2016,56,"Microsoft Research, China; University of Arizona, United States",Microsoft;University of Arizona,2,China;USA,2,5,3,"We explore a novel, free-space optics based approach for building data center interconnects. It uses a digital micromirror device (DMD) and mirror assembly combination as a transmitter and a photodetector on top of the rack as a receiver (Figure 1). Our approach enables all pairs of racks to establish direct links, and we can reconfigure such links (i.e., connect different rack pairs) within 12 _s. To carry traffic from a source to a destination rack, transmitters and receivers in our interconnect can be dynamically linked in millions of ways. We develop topology construction and routing methods to exploit this flexibility, including a flow scheduling algorithm that is a constant factor approximation to the offline optimal solution. Experiments with a small prototype point to the feasibility of our approach. Simulations using realistic data center workloads show that, compared to the conventional folded-Clos interconnect, our approach can improve mean flow completion time by 30-95% and reduce cost by 25-40%. © 2016 ACM.",Data centers; Free-space optics; Reconfigurablility,Approximation algorithms; Convolutional codes; Space optics; Transmitters; Completion time; Constant factor approximation; Data centers; Digital micro-mirror device; Free space optics; Optimal solutions; Reconfigurablility; Topology construction; Scheduling algorithms
"Cronkite-Ratcliff B., Bergman A., Vargaftik S., Ravi M., McKeown N., Abraham I., Keslassy I.",7,Virtualized congestion control,2016,22,"VMware, India; Stanford, United States; Technion, United States",Stanford University,1,India;USA,2,40,10,"New congestion control algorithms are rapidly improving datacenters by reducing latency, overcoming incast, increasing throughput and improving fairness. Ideally, the operating system in every server and virtual machine is updated to support new congestion control algorithms. However, legacy applications often cannot be upgraded to a new operating system version, which means the advances are off-limits to them. Worse, as we show, legacy applications can be squeezed out, which in the worst case prevents the entire network from adopting new algorithms. Our goal is to make it easy to deploy new and improved congestion control algorithms into multitenant datacenters, without having to worry about TCP-friendliness with non-participating virtual machines. This paper presents a solution we call virtualized congestion control. The datacenter owner may introduce a new congestion control algorithm in the hypervisors. Internally, the hypervisors translate between the new congestion control algorithm and the old legacy congestion control, allowing legacy applications to enjoy the benefits of the new algorithm. We have implemented proof-of-concept systems for virtualized congestion control in the Linux kernel and in VMware's ESXi hypervisor, achieving improved fairness, performance, and control over guest bandwidth allocations. © 2016 ACM.",Algorithmic virtualization; Datacenters; DCTCP; ECN; Hypervisors; TCP; Virtualized congestion control,Computer operating systems; Convolutional codes; Java programming language; Transmission control protocol; Data centers; DCTCP; Hypervisors; Legacy applications; Proof of concept; TCP friendliness; Virtual machines; Virtualizations; Algorithms
"Lee K.S., Wang H., Shrivastav V., Weatherspoon H.",4,Globally synchronized time via datacenter networks,2016,10,"Computer Science Department, Cornell University, United States",Cornell University,1,USA,1,54,36,"Synchronized time is critical to distributed systems and network applications in a datacenter network. Unfortunately, many clock synchronization protocols in datacenter networks such as NTP and PTP are fundamentally limited by the characteristics of packet switching networks. In particular, network jitter, packet buffering and scheduling in switches, and network stack overheads add non-deterministic variances to the round trip time, which must be accurately measured to synchronize clocks precisely. In this paper, we present the Datacenter Time Protocol (DTP), a clock synchronization protocol that does not use packets at all, but is able to achieve nanosecond precision. In essence, DTP uses the physical layer of network devices to implement a decentralized clock synchronization protocol. By doing so, DTP eliminates most non-deterministic elements in clock synchronization protocols. Further, DTP uses control messages in the physical layer for communicating hundreds of thousands of protocol messages without interfering with higher layer packets. Thus, DTP has virtually zero overhead since it does not add load at layers 2 or higher at all. It does require replacing network devices, which can be done incrementally. We demonstrate that the precision provided by DTP in hardware is bounded by 25.6 nanoseconds for directly connected nodes, 153.6 nanoseconds for a datacenter with six hops, and in general, is bounded by 4T D where D is the longest distance between any two servers in a network in terms of number of hops and T is the period of the fastest clock (Å 6.4ns). Moreover, in software, a DTP daemon can access the DTP clock with usually better than 4T (Å 25.6ns) precision. As a result, the end-to-end precision can be better than 4T D + 8T nanoseconds. By contrast, the precision of the state of the art protocol (PTP) is not bounded: The precision is hundreds of nanoseconds when a network is idle and can decrease to hundreds of microseconds when a network is heavily congested. © 2016 Copyright held by the owner/author(s).",Datacenter Networks,Clocks; Convolutional codes; Mechanical clocks; Packet switching; Switching networks; Synchronization; Time switches; Clock Synchronization; Control messages; Data center networks; Distributed systems and networks; Packet buffering; Physical layers; Protocol message; State-of-the art protocols; Network layers
"Jin X., Li Y., Wei D., Li S., Gao J., Xu L., Li G., Xu W., Rexford J.",9,Optimizing bulk transfers with software-defined optical WAN,2016,25,"Princeton, United States; Tsinghua, China; Stony Brook, United States; Sodero Networks, United States; ATandT Labs., United States",AT and T Labs;Tsinghua University;Princeton University,3,China;USA,2,53,28,"Bulk transfer on the wide-area network (WAN) is a fundamental service to many globally-distributed applications. It is challenging to efficiently utilize expensive WAN bandwidth to achieve short transfer completion time and meet mission-critical deadlines. Advancements in software-defined networking (SDN) and optical hardware make it feasible and beneficial to quickly reconfigure optical devices in the optical layer, which brings a new opportunity for traffic management on the WAN. We present Owan, a novel traffic management system that optimizes wide-area bulk transfers with centralized joint control of the optical and network layers. Owan can dynamically change the network-layer topology by reconfiguring the optical devices. We develop efficient algorithms to jointly optimize optical circuit setup, routing and rate allocation, and dynamically adapt them to traffic demand changes. We have built a prototype of Owan with commodity optical and electrical hardware. Testbed experiments and large-scale simulations on two ISP topologies and one inter-DC topology show that Owan completes transfers up to 4.45x faster on average, and up to 1.36x more transfers meet their deadlines, as compared to prior methods that only control the network layer. © 2016 ACM.",Bulk transfers; Cross-layer network management; Optical networks; Software-defined networking; Wide area networks,Algorithms; Convolutional codes; Fiber optic networks; Hardware; Internet service providers; Network layers; Network management; Optical devices; Reconfigurable hardware; Software defined networking; Topology; Bulk transfer; Cross-layer networks; Distributed applications; Large scale simulations; Mission critical; Software defined networking (SDN); Traffic management; Traffic management systems; Wide area networks
"Shukla A., SchŸtze A., Ludwig A., Dudycz S., Schmid S., Feldmann A.",6,Towards transiently secure updates in asynchronous SDNs,2016,2,"TU Berlin, Germany; Uni Wroclaw, Poland; Aalborg University, Denmark",Aalborg University;TU Berlin,2,Denmark;Germany;Poland,3,68,52,"Software-Defined Networks (SDNs) promise to overcome the often complex and error-prone operation of traditional computer networks, by enabling programmability, automation and verifiability. Yet, SDNs also introduce new challenges, for example due to the asynchronous communication channel between the logically centralized control platform and the switches in the data plane. In particular, the asynchronous communication of network update commands (e.g., OpenFlow FlowMod messages) may lead to transient inconsistencies, such as loops or bypassed waypoints (e.g., firewalls). One approach to ensure transient consistency even in asynchronous environments is to employ smart scheduling algorithms: algorithms which update subsets of switches in each communication round only, where each subset in itself guarantees consistency. In this demo, we show how to change routing policies in a transiently consistent manner. We demonstrate two algorithms, namely, Wayup [5] and Peacock [4], which partition the network updates sent from SDN controller towards OpenFlow software switches into multiple rounds as per respective algorithms. Later, the barrier messages are utilized to ensure reliable network updates. © 2016 ACM.",Mininet; SDN,Algorithms; Complex networks; Convolutional codes; Scheduling algorithms; Asynchronous communication; Centralized control; Communication rounds; Mininet; Reliable Networks; Routing policies; Software switches; Traditional computers; Computer system firewalls
"Dos Reis Fontes R., Rothenberg C.E.",2,Mininet-WiFi: A platform for hybrid physical-virtual software-defined wireless networking research,2016,5,"University of Campinas (UNICAMP), Campinas, Sao Paulo, Brazil",University of Campinas,1,Brazil,1,5,5,"Software-Defined Wireless Networking (SDWN) is being considered an appealing paradigm to design and operate wireless networks through higher-level abstractions and programmatic interfaces such as the Open-Flow protocol. Identified benefits include cost savings, service velocity and customization, resource optimization through novel approaches to user mobility, traffic offloading, multi-layer and multi-path routing, and so on. This demonstration features Mininet-WiFi as a SDWN emulator with the ability to run realistic experiments in hybrid physical-virtual environments, where users attending the conference are able to experience first hand by connecting their devices and interacting with virtual WiFi stations in a wireless mesh network or reach the Internet through the emulated SDWN infrastructure. OpenFlow 1.3 metering and IP header re-writing actions will showcase HTTP flow redirection and rate limitation of real users' wireless traffic. © 2016 ACM.",Mesh networks; OpenFlow; SDN; SDWN; Wireless,Convolutional codes; HTTP; Mesh generation; MESH networking; Radio; Virtual reality; Wireless local area networks (WLAN); Wireless networks; Higher-level abstraction; Multi path routing; Openflow; Resource optimization; SDWN; User mobility; Wireless networking; Wireless traffic; Wi-Fi
"Yang J., Hu C., Zheng P., Wang R., Zhang P., Guan X.",6,Rethinking the design of OpenFlow switch counters,2016,0,"Xi'an Jiaotong University, China; Xi'an Jiaotong University, Tsinghua University, China",Tsinghua University;Xian JiaoTong University,2,China,1,5,5,"OpenFlow, as the Software Defined Networking (SDN) primitive, provides a simple forwarding plane abstraction, which heavily relies on the fast memory inside the OpenFlow Switch (OFS). OFS components, e.g. flow table, meter table, counters, have to compete for the limited fast memory resource. As a result, only a few counting functions are defined as mandatory in the OFS specification, although a lot of SDN proposals depend on a detailed states collected by the optional counters in the specification. This fact motivates us to rethink the way to maintain counters in the OFS. We propose a new architecture called CACTI, which only consumes several registers in the fast path and moves the completed counters into the on chip RAM like cache in the slow path processor. Theoretical analysis and experiments on the prototype system demonstrated the efficiency of our architecture: CACTI is capable to achieve the throughput of 29.4-39.7M pps packets per second (pps). No RAM resource is needed any more in the fast path, instead, CACTI consumes only 0.24-0.54% Look-Up Table and 0.35-0.43% flip-flops compared with the entire FPGA-based OFS design in the fast path, and the unused CPU cache in the slow path. © 2016 ACM.",OpenFlow; SDN counter,Computer architecture; Convolutional codes; Flip flop circuits; Integrated circuit design; Memory architecture; Specifications; Table lookup; Counting functions; Forwarding planes; Openflow; Openflow switches; Packets per seconds; Prototype system; SDN counter; Software defined networking (SDN); Random access storage
"Shahbaz M., Choi S., Pfaff B., Kim C., Feamster N., McKeown N., Rexford J.",7,"PISCES: A programmable, protocol-independent software switch",2016,37,"Princeton University, United States; Stanford University, United States; VMware, Inc., United States; Barefoot Networks, Inc., United States",Barefoot Networks Inc.;Princeton University;Stanford University;VMware Inc.,4,USA,1,5,5,"Hypervisors use software switches to steer packets to and from virtual machines (VMs). These switches frequently need upgrading and customization - to support new protocol headers or encapsulations for tunneling and overlays, to improve measurement and debugging features, and even to add middlebox-like functions. Software switches are typically based on a large body of code, including kernel code, and changing the switch is a formidable undertaking requiring domain mastery of network protocol design and developing, testing, and maintaining a large, complex codebase. Changing how a software switch forwards packets should not require intimate knowledge of its implementation. Instead, it should be possible to specify how packets are processed and forwarded in a high-level domain-specific language (DSL) such as P4, and compiled to run on a software switch. We present PISCES, a software switch derived from Open vSwitch (OVS), a hard-wired hypervisor switch, whose behavior is customized using P4. PISCES is not hard-wired to specific protocols; this independence makes it easy to add new features. We also show how the compiler can analyze the high-level specification to optimize forwarding performance. Our evaluation shows that PISCES performs comparably to OVS and that PISCES programs are about 40 times shorter than equivalent changes to OVS source code. Copyright 2016 ACM.",Compiler optimizations; Domain-specific languages (DSL); OVS; P4; PISCES; Programmable data planes; Software switch; Software-defined networks (SDN),Codes (symbols); Complex networks; Computer programming languages; Convolutional codes; Graphical user interfaces; High level languages; Network protocols; Problem oriented languages; Software testing; Switching circuits; Compiler optimizations; Data planes; Domain specific languages; PISCES; Software switches; Program compilers
"Choi B., Kim J., Han D.",3,Application-specific acceleration framework for mobile applications,2016,2,"KAIST, South Korea",KAIST,1,South Korea,1,75,55,"Minimizing response times for mobile applications is critical for quality user experience that often impacts the revenue of mobile services. Generalized approaches to accelerated mobile applications (e.g., TCP acceleration, SPDY, compression) are less effective because they do not take account for application specific behaviors. In contrast, application specific approaches build application-specific proxies by leveraging the app-specific protocol behaviors to enable dynamic caching and/or prefetching. However, this is non-trivial because it requires manual analysis of application level protocols and their interactions. Therefore, only a small number of apps enjoyed the benefit. This paper addresses the problem of scaling the number of applications by automating the process. To this end, we present a framework for mobile application acceleration that leverages automatic protocol analysis to automatically discover opportunities for app acceleration. The framework automatically finds out when and where to prefetch or perform dynamic caching. We present the framework design and a preliminary result that demonstrates its viability. © 2016 ACM.",Android; Automatic proxying; Protocol behavior; Static analysis,Convolutional codes; Mobile computing; Static analysis; Transmission control protocol; Android; Application specific; Application-level protocol; Automatic proxying; Mobile applications; Protocol analysis; Protocol behavior; Specific protocol; Mobile telecommunication systems
"Baldi M., Bonafiglia R., Risso F., Sapio A.",4,Modeling native software components as virtual network functions,2016,1,"Department of Control and Computer Engineering, Politecnico di Torino, Italy",Politecnico di Torino,1,Italy,1,5,2,"Virtual Network Functions (VNFs) are often realized using virtual machines (VMs) because they provide an isolated environment compatible with classical cloud computing technologies. However, VMs are demanding in terms of required resources (CPU and memory) and therefore not suitable for low-cost devices like residential gateways. Such equipment often runs a Linux-based operating system that includes by default a (large) number of common network functions, which can provide some of the services otherwise offered by simple VNFs, but with reduced overhead. In this paper those native software components are made available through a Network Function Virtualization (NFV) platform, thus making their use transparent from the VNF developer point of view. © 2016 ACM.",Network functions virtualization; Service orchestration; Virtual network functions,Computer operating systems; Convolutional codes; Transfer functions; Virtual reality; Cloud computing technologies; Network functions; Residential gateways; Service orchestration; Software component; Virtual machines; Virtual networks; Virtualizations; Distributed computer systems
"Li H., Hu C., Zhang P., Xie L.",4,Modular SDN compiler design with intermediate representation,2016,3,"Xi'an Jiaotong University, China",Xian JiaoTong University,1,China,1,1,1,"Software Defined Networking (SDN) is evolving to such a phase that multiple programming languages and rule specifications coexist. However, current SDN compilers are closely bound to both languages and rules, thus disable the interoperability and compatibility of SDN programs. To solve this problem, we propose to modularize the SDN compiler by leveraging intermediate representation (IR), a common technique for computer compiler design. Specifically, we introduce Semantic Rule (SR) as the first IR for SDN compilers, which is a simple, language-independent, and semantic-preserving representation. We develop two optimizations on the semantic rule to coordinate cross-language programs in a single network and compress the number of compiled rules. We implement a modular compiler prototype with the proposed SR, and demonstrate that RYU programs can run at both OpenFlow and POF network. With synthetic network configurations, we demonstrate that the optimizations on SRs are effective, efficient and scalable. © 2016 ACM.",Intermediate representation; Software-defined networks,Convolutional codes; Semantics; Software defined networking; Compiler design; Cross languages; Intermediate representations; Language independents; Semantic rules; Single networks; Software defined networking (SDN); Synthetic networks; Program compilers
"Vasisht D., Kumar S., Rahul H., Katabi D.",4,Eliminating channel feedback in next-generation cellular networks,2016,20,"MIT CSAIL, United States; CMU, China",MIT,1,China;USA,2,5,5,"This paper focuses on a simple, yet fundamental question: ""Can a node infer the wireless channels on one frequency band by observing the channels on a different frequency band?"" This question arises in cellular networks, where the uplink and the downlink operate on different frequencies. Addressing this question is critical for the deployment of key 5G solutions such as massive MIMO, multi-user MIMO, and distributed MIMO, which require channel state information. We introduce R2-F2, a system that enables LTE base stations to infer the downlink channels to a client by observing the uplink channels from that client. By doing so, R2-F2 extends the concept of reciprocity to LTE cellular networks, where downlink and uplink transmissions occur on different frequency bands. It also removes a major hurdle for the deployment of 5G MIMO solutions. We have implemented R2-F2 in software radios and integrated it within the LTE OFDM physical layer. Our results show that the channels computed by R2-F2 deliver accurate MIMO beamforming (to within 0.7 dB of beamforming gains with ground truth channels) while eliminating channel feedback overhead. © 2016 Copyright held by the owner/author(s).",FDD systems; LTE,Beamforming; Channel state information; Convolutional codes; Frequency bands; MIMO systems; Mobile telecommunication systems; Network layers; Next generation networks; Orthogonal frequency division multiplexing; Wireless networks; Channel feedbacks; Different frequency; Distributed MIMO; Downlink channels; FDD systems; Next generation cellular networks; Up-link transmissions; Wireless channel; Wireless telecommunication systems
"Su J., Chen S., Han B., Xu C., Wang X.",5,A 60Gbps DPI prototype based on memory-centric FPGA,2016,2,"College of Computer, National University of Defense Technology, Changsha, 410073, China; National Key Laboratory of Parallel and Distributed Processing, Changsha, 410073, China",National University of Defense Technology,1,China,1,56,47,"Deep packet inspection (DPI) is widely used in content-aware network applications to detect string features. It is of vital importance to improve the DPI performance due to the ever-increasing link speed. In this demo, we propose a novel DPI architecture with a hierarchy memory structure and parallel matching engines based on memory-centric FPGA. The implemented DPI prototype is able to provide up to 60Gbps full-text string matching throughput and fast rules update speed. © 2016 ACM.",DPI; Hierarchical memory; String matching,Convolutional codes; Field programmable gate arrays (FPGA); Reconfigurable hardware; Content-aware networks; Deep packet inspection (DPI); Hierarchical memory; Link speed; Matching engines; Memory structure; String matching; Text string; Packet networks
"Sung Y.-W.E., Tie X., Wong S.H.Y., Zeng H.",4,Robotron: Top-down network management at facebook scale,2016,12,"Facebook, Inc., United States",Facebook,1,USA,1,6,2,"Network management facilitates a healthy and sustainable network. However, its practice is not well understood outside the network engineering community. In this paper, we present Robotron, a system for managing a massive production network in a top-down fashion. The system's goal is to reduce effort and errors on management tasks by minimizing direct human interaction with network devices. Engineers use Robotron to express high-level design intent, which is translated into low-level device configurations and deployed safely. Robotron also monitors devices' operational state to ensure it does not deviate from the desired state. Since 2008, Robotron has been used to manage tens of thousands of network devices connecting hundreds of thousands of servers globally at Facebook. © 2016 Copyright held by the owner/author(s).",Facebook; Network management; Robotron,Convolutional codes; Social networking (online); Device configurations; Facebook; High-level design; Human interactions; Massive production; Network engineering; Operational state; Robotron; Network management
"Jiang J., Das R., Ananthanarayanan G., Chou P.A., Padmanabhan V.N., Sekar V., Dominique E., Goliszewski M., Kukoleca D., Vafin R., Zhang H.",11,VIA: Improving internet telephony call quality using predictive relay selection,2016,15,"Microsoft, China; CMU, China; Conviva, China",Microsoft,1,China,1,38,22,"The use of the Internet for voice calls is here to stay. In spite of the volume and importance of Internet telephony, we have little understanding of (1) how network performance impacts user-perceived call quality, and (2) why and where such quality problems occur in the wild. To bridge this gap, we analyze a data set of 430 million calls from Skype, with clients across 1900 ASes and 126 countries. We observe that call quality problems are quite pervasive. More importantly, these problems are significantly spread out geographically and over time, thereby making simple fixes targeted at specific ""pockets"" of poor performance largely ineffective. To alleviate call quality problems, we present an architecture called VIA that revisits the use of classical overlay techniques to relay calls. We argue that this approach is both timely and pragmatic given the emergence of private backbones in recent years to connect globally distributed datacenters, which can serve as a readily available infrastructure for a managed overlay network. Trace-driven analysis shows that an oracle-based overlay can potentially improve up to 53% of calls whose quality is impacted by poor network performance. A key challenge is realizing these benefits in practice, in the face of significant spatial and temporal variability in performance and a large number of relaying choices. We develop a practical relay selection approach that intelligently combines prediction-based filtering with an online exploration-exploitation strategy. Trace-driven analysis and a small-scale deployment shows that VIA cuts the incidence of poor network conditions for calls by 45% (and for some countries and ASes by over 80%) while staying within a budget for relaying traffic through the managed network. © 2016 ACM.",Internet telephony; Managed overlay networks; Predictive relay selection; Quality of experience,Budget control; Convolutional codes; Developing countries; Internet; Internet telephony; Network performance; Overlay networks; Quality of service; Trace analysis; Managed networks; Network condition; Online explorations; Overlay techniques; Poor performance; Quality of experience (QoE); Relay selection; Spatial and temporal variability; Quality control
"Zhang H., Chen L., Yi B., Chen K., Chowdhury M., Geng Y.",6,CODA: Toward automatically identifying and scheduling COflows in the DArk,2016,31,"SING Group, Hong Kong University of Science and Technology, Hong Kong; University of Michigan, United States; Huawei, China",Hong Kong University of Science and Technology;University of Michigan at Ann Arbor,2,China;Hong Kong;USA,3,38,17,"Leveraging application-level requirements using coflows has recently been shown to improve application-level communication performance in data-parallel clusters. However, existing coflow-based solutions rely on modifying applications to extract coflows, making them inapplicable to many practical scenarios. In this paper, we present CODA, a first attempt at automatically identifying and scheduling coflows without any application modifications. We employ an incremental clustering algorithm to perform fast, application-transparent coflow identification and complement it by proposing an error-tolerant coflow scheduler to mitigate occasional identification errors. Testbed experiments and large-scale simulations with production workloads show that CODA can identify coflows with over 90% accuracy, and its scheduler is robust to inaccuracies, enabling communication stages to complete 2.4x (5.1x) faster on average (95-th percentile) compared to per-flow mechanisms. Overall, CODA's performance is comparable to that of solutions requiring application modifications. © 2016 ACM.",Coflow; Data-intensive applications; Datacenter networks,Clustering algorithms; Convolutional codes; Co-flow; Communication performance; Data center networks; Data-intensive application; Identification errors; Incremental clustering algorithm; Large scale simulations; Production workloads; Scheduling
"Sivaraman A., Cheung A., Budiu M., Kim C., Alizadeh M., Balakrishnan H., Varghese G., McKeown N., Licking S.",9,Packet transactions: High-level programming for line-rate switches,2016,48,"MIT CSAIL, United States; University of Washington, United States; VMWare Research, United States; Barefoot Networks, United States; Microsoft Research, China; Stanford University, United States",Stanford University;MIT;University of Washington at Seattle;VMWare Research,4,China;USA,2,68,38,"Many algorithms for congestion control, scheduling, network measurement, active queue management, and traffic engineering require custom processing of packets in the data plane of a network switch. To run at line rate, these dataplane algorithms must be implemented in hardware. With today's switch hardware, algorithms cannot be changed, nor new algorithms installed, after a switch has been built. This paper shows how to program data-plane algorithms in a high-level language and compile those programs into low-level microcode that can run on emerging programmable line-rate switching chips. The key challenge is that many data-plane algorithms create and modify algorithmic state. To achieve line-rate programmability for stateful algorithms, we introduce the notion of a packet transaction: a sequential packet-processing code block that is atomic and isolated from other such code blocks. We have developed this idea in Domino, a C-like imperative language to express data-plane algorithms. We show with many examples that Domino provides a convenient way to express sophisticated data-plane algorithms, and show that these algorithms can be run at line rate with modest estimated chip-area overhead. © 2016 Copyright held by the owner/author(s).",Programmable switches; Stateful data-plane algorithms,C (programming language); Computer programming languages; Convolutional codes; Hardware; High level languages; Information management; Packet networks; Reconfigurable hardware; Scheduling; Switching circuits; Active Queue Management; Data planes; High-level programming; Imperative languages; Network measurement; Packet processing; Programmable switches; Traffic Engineering; Algorithms
"Hu P., Zhang P., Rostami M., Ganesan D.",4,Braidio: An integrated active-passive radio for mobile devices with asymmetric energy budgets,2016,14,"College of Information and Computer Sciences, University of Massachusetts, Amherst, MA  01003, United States",University of Massachusetts Amherst,1,USA,1,63,29,"While many radio technologies are available for mobile devices, none of them are designed to deal with asymmetric available energy. Battery capacities of mobile devices vary by up to three orders of magnitude between laptops and wearables, and our inability to deal with such asymmetry has limited the lifetime of constrained portable devices. This paper presents a radically new design for low-power radios - one that is capable of dynamically splitting the power burden of communication between the transmitter and receiver in proportion to the available energy on the two devices. We achieve this with a novel carrier offload method that dynamically moves carrier generation across end points. While such a design might raise the specter of a high-power, large form-factor radio, we show that this integration can be achieved with no more than a BLE-style active radio augmented with a few additional components. Our design, Braidio is a low-power, tightly integrated, low-cost radio capable of operating as an active and passive transceiver. When these modes operate in an interleaved (braided) manner, the end result is a power-proportional low-power radio that is able to achieve 1:2546 to 3546:1 power consumption ratios between a transmitter and a receiver, all while operating at low power. © 2016 ACM.",Architecture; Asymmetric; Backscatter; Energy; Wireless,Architecture; Backscattering; Budget control; Convolutional codes; Mobile devices; Radio; Radio broadcasting; Radio transmission; Transmitters; Asymmetric; Asymmetric energy; Carrier generation; Energy; Low power radios; Radio technologies; Three orders of magnitude; Transmitter and receiver; Radio transceivers
"Laki S., Horp‡csi D., Všršs P., Kitlei R., Lesk— D., Tejfel M.",6,High speed packet forwarding compiled from protocol independent data plane specifications,2016,10,"Faculty of Informatics, Eštvšs Lor‡nd University, Budapest, Hungary",Eotvos Lorand University,1,Hungary,1,54,22,"P4 is a high level language for programming network switches that allows for great flexibility in the description of packet structure and processing, independent of the specifics of the underlying hardware. In this demo, we present our prototype P4 compiler in which the hardware independent and hardware specific functionalities are separated. We have identified the requisites of the latter, which form the interface of our target specific Hardware Abstraction Library (HAL); the compiler turns P4 code into a target independent core program that is linked to this library and invokes its operations. The two stage separation improves portability: to support a new architecture, only the hardware dependent library has to be implemented. In the demo, we demonstrate the flexibility of our compiler with a HAL for Intel DPDK, and show the packet processing and forwarding performance of compiled switches in different scenarios. © 2016 ACM.",P4; Packet forwarding; Programmable data plane; SDN,Computer hardware description languages; Computer programming languages; Convolutional codes; Hardware; High level languages; Packet networks; Reconfigurable hardware; Data planes; Hardware independent; Network switches; Packet forwarding; Packet processing; Packet structure; Specific hardware; Two-stage separation; Program compilers
"Bremler-Barr A., Harchol Y., Hay D.",3,"OpenBox: A software-defined framework for developing, deploying, and managing network functions",2016,50,"School of Computer Science, Interdisciplinary Center, Herzliya, Israel; School of Computer Science and Engineering, Hebrew University, Jerusalem, Israel",Hebrew University of Jerusalem;Interdisciplinary Center,2,Israel,1,6,3,"We present OpenBox - a software-defined framework for network-wide development, deployment, and management of network functions (NFs). OpenBox effectively decouples the control plane of NFs from their data plane, similarly to SDN solutions that only address the network's forwarding plane. OpenBox consists of three logic components. First, user-defined OpenBox applications provide NF specifications through the OpenBox north-bound API. Second, a logically-centralized OpenBox controller is able to merge logic of multiple NFs, possibly from multiple tenants, and to use a network-wide view to efficiently deploy and scale NFs across the network data plane. Finally, OpenBox instances constitute OpenBox's data plane and are implemented either purely in software or contain specific hardware accelerators (e.g., a TCAM). In practice, different NFs carry out similar processing steps on the same packet, and our experiments indeed show a significant improvement of the network performance when using OpenBox. Moreover, OpenBox readily supports smart NF placement, NF scaling, and multi-tenancy through its controller. © 2016 ACM.",Middleboxes; Network functions; Software-defined networks,Convolutional codes; Logic gates; Reconfigurable hardware; Software defined networking; Transfer functions; Control planes; Forwarding planes; Logic components; Middleboxes; Multi tenancies; Network functions; Processing steps; Specific hardware; Computer circuits
"Iyer V., Talla V., Kellogg B., Gollakota S., Smith J.R.",5,Inter-technology backscatter: Towards internet connectivity for implanted devices,2016,48,"University of Washington, United States",University of Washington at Seattle,1,USA,1,42,32,"We introduce inter-technology backscatter, a novel approach that transforms wireless transmissions from one technology to another, on the air. Specifically, we show for the first time that Bluetooth transmissions can be used to create Wi-Fi and ZigBee-compatible signals using backscatter communication. Since Bluetooth, Wi-Fi and ZigBee radios are widely available, this approach enables a backscatter design that works using only commodity devices. We build prototype backscatter hardware using an FPGA and experiment with various Wi-Fi, Bluetooth and ZigBee devices. Our experiments show we can create 2-11 Mbps Wi-Fi standards-compliant signals by backscattering Bluetooth transmissions. To show the generality of our approach, we also demonstrate generation of standards-complaint ZigBee signals by backscattering Bluetooth transmissions. Finally, we build proof-of-concepts for previously infeasible applications including the first contact lens form-factor antenna prototype and an implantable neural recording interface that communicate directly with commodity devices such as smartphones and watches, thus enabling the vision of Internet connected implanted devices. © 2016 ACM.",Backscatter; Implantable devices; Internet of things,Antennas; Bluetooth; Convolutional codes; Implants (surgical); Internet of things; Lens antennas; Signal theory; Wireless local area networks (WLAN); Zigbee; Implantable devices; Implanted device; Internet connectivity; Neural recordings; Proof of concept; WiFi standard; Wireless transmissions; ZigBee device; Backscattering
"Jiang Y., Ravindranath L., Nath S., Govindan R.",4,"WebPerf: Evaluating ""what-if"" scenarios for cloud-hosted web applications",2016,5,"University of Southern California, United States; Microsoft Research, China",Microsoft;University of Southern California,2,China;USA,2,50,32,"Developers deploying web applications in the cloud often need to determine how changes to service tiers or runtime load may affect user-perceived page load time. We devise and evaluate a systematic methodology for exploring such ""what-if"" questions when a web application is deployed. Given a website, a web request, and ""what-if"" scenario, with a hypothetical configuration and runtime conditions, our methodology, embedded in a system called WebPerf, can estimate a distribution of cloud latency of the request under the ""what-if"" scenario. In achieving this goal, WebPerf makes three contributions: (1) automated instrumentation of websites written in an increasingly popular task asynchronous paradigm, to capture causal dependencies of various computation and asynchronous I/O calls; (2) an algorithm to use the call dependencies, together with online- and offline-profiled models of various I/O calls to estimate a distribution of end-to-end latency of the request; and (3) an algorithm to find the optimal measurements to take within a limited time to minimize modeling errors. We have implemented WebPerf for Microsoft Azure. In experiments with six real websites and six scenarios, the WebPerf's median estimation error is within 7% in all experiments. © 2016 ACM.",Async-await; Dependency; Instrumentation; What-if,Algorithms; Convolutional codes; Websites; Windows operating system; Async-await; Automated instrumentation; Dependency; End to end latencies; Instrumentation; Optimal measurements; Systematic methodology; What-if; World Wide Web
"He K., Rozner E., Agarwal K., Gu Y., Felter W., Carter J., Akella A.",7,AC/DC TCP: Virtual congestion control enforcement for datacenter networks,2016,36,"University of Wisconsin-Madison, United States; IBM Research, United States; IBM, United States",IBM;;University of Wisconsin-Madison,3,USA,1,47,17,"Multi-tenant datacenters are successful because tenants can seamlessly port their applications and services to the cloud. Virtual Machine (VM) technology plays an integral role in this success by enabling a diverse set of software to be run on a unified underlying framework. This flexibility, however, comes at the cost of dealing with out-dated, inefficient, or misconfigured TCP stacks implemented in the VMs. This paper investigates if administrators can take control of a VM's TCP congestion control algorithm without making changes to the VM or network hardware. We propose AC_DC TCP, a scheme that exerts fine-grained control over arbitrary tenant TCP stacks by enforcing per-flow congestion control in the virtual switch (vSwitch). Our scheme is light-weight, flexible, scalable and can police non-conforming flows. In our evaluation the computational overhead of AC_DC TCP is less than one percentage point and we show implementing an administrator-defined congestion control algorithm in the vSwitch (i.e., DCTCP) closely tracks its native performance, regardless of the VM's TCP stack. © 2016 Copyright held by the owner/author(s).",Congestion control; Datacenter networks; Virtualization,Algorithms; Congestion control (communication); Convolutional codes; Law enforcement; Computational overheads; Data center networks; Fine-grained control; Multi tenants; Percentage points; TCP congestion control algorithm; Virtual machine technology; Virtualizations; Transmission control protocol
"Cziva R., Jouet S., Pezaros D.P.",3,Roaming edge vNFs using Glasgow Network Functions,2016,5,"Networked Systems Research Laboratory, University of Glasgow, United Kingdom",University of Glasgow,1,UK,1,74,50,"While the network edge is becoming more important for the provision of customized services in next generation mobile networks, current NFV architectures are unsuitable to meet the increasing future demand. They rely on commodity servers with resource-hungry Virtual Machines that are unable to provide the high network function density and mobility requirements necessary for upcoming wide-area and 5G networks. In this demo, we showcase Glasgow Network Functions (GNF), a virtualization framework suitable for next generation mobile networks that exploits lightweight network functions (NFs) deployed at the edge and transparently following users' devices as they roam between cells. © 2016 Copyright held by the owner/author(s).",Container network functions; Fifth-generation mobile networks; Glasgow network functions; Network function virtualization; Software-defined networks,Convolutional codes; Mobile telecommunication systems; Software defined networking; Transfer functions; Virtual reality; Wide area networks; Wireless networks; Customized services; G-networks; Network edges; Network functions; Virtual machines; Virtualizations; Next generation networks
"Amar Y., Haddadi H., Mortier R.",3,Privacy-aware infrastructure for managing personal data,2016,3,"Queen Mary University of London, United Kingdom; University of Cambridge, United Kingdom",Queen Mary University of London;University of Cambridge,2,UK,1,4,4,"In recent times, we have seen a proliferation of personal data. This can be attributed not just to a larger proportion of our lives moving online, but also through the rise of ubiquitous sensing through mobile and IoT devices. Alongside this surge, concerns over privacy, trust, and security are expressed more and more as different parties attempt to take advantage of this rich assortment of data. The Databox seeks to enable all the advantages of personal data analytics while at the same time enforcing accountability and control in order to protect a user's privacy. In this work, we propose and delineate a personal networked device that allows users to collate, curate, and mediate their personal data. © 2016 ACM.",Networks; Personal data; Privacy,Convolutional codes; Networks (circuits); Data analytics; Networked devices; Privacy aware; Data privacy
"Fazzion E., Cunha I., Guedes D., Meira W., Jr., Teixeira R., Veitch D., Diot C.",8,Efficient remapping of internet routing events,2016,0,"UFMG, Australia; Inria, Australia; University of Technology Sydney, Australia; Safran, France",University of Technology Sydney,1,Australia;France,2,4,4,"Routing events impact multiple paths in the Internet, but current active topology mapping techniques monitor paths independently. Detecting a routing event on one Internet path does not trigger any measurements on other possibly-impacted paths. This approach leads to outdated and inconsistent routing information. We characterize routing events in the Internet and investigate probing strategies to efficiently identify paths impacted by a routing event. Our results indicate that targeted probing can help us quickly remap routing events and maintain more up-to-date and consistent topology maps. © 2016 Copyright held by the owner/author(s).",Routing events; Topology mapping; Traceroute,Convolutional codes; Mapping; Topology; Internet paths; Internet routing; Multiple-path; Probing strategies; Routing events; Routing information; Topology mapping; Traceroute; Internet
"Guo C., Wu H., Deng Z., Soni G., Ye J., Padhye J., Lipshteyn M.",7,RDMA over commodity ethernet at scale,2016,32,"Microsoft, China",Microsoft,1,China,1,2,2,"Over the past one and half years, we have been using RDMA over commodity Ethernet (RoCEv2) to support some of Microsoft's highly-reliable, latency-sensitive services. This paper describes the challenges we encountered during the process and the solutions we devised to address them. In order to scale RoCEv2 beyond VLAN, we have designed a DSCP-based priority flow-control (PFC) mechanism to ensure large-scale deployment. We have addressed the safety challenges brought by PFC-induced deadlock (yes, it happened!), RDMA transport livelock, and the NIC PFC pause frame storm problem. We have also built the monitoring and management systems to make sure RDMA works as expected. Our experiences show that the safety and scalability issues of running RoCEv2 at scale can all be addressed, and RDMA can replace TCP for intra data center communications and achieve low latency, low CPU overhead, and high throughput. © 2016 Copyright held by the owner/author(s).",Deadlock; PFC; PFC propagation; RDMA; RoCEv2,Convolutional codes; Transmission control protocol; Commodity ethernet; Deadlock; High throughput; Large-scale deployment; Monitoring and management systems; RDMA; RoCEv2; Scalability issue; Ethernet
"HŠtšnen S., Savolainen P., Rao A., Flinck H., Tarkoma S.",5,Off-the-shelf software-defined Wi-Fi networks,2016,1,"University of Helsinki, Finland; Helsinki Institute for Information Technology HIIT, Finland; Nokia Bell Labs, Finland",Helsinki Institute for Information Technology;Nokia;University of Helsinki,3,Finland,1,42,30,"Wi-Fi networks were one of the first use-cases for Software-defined networking (SDN). However, to deploy a software-defined Wi-Fi network today, one has to rely on research prototypes with availability, documentation, hardware requirements, and scalability issues. To alleviate this situation, we demonstrate two simple techniques to bring SDN functionality to existing Wi-Fi networks and discuss their benefits and short-comings. Researchers can use our techniques to convert their existing Wi-Fi testbeds into software defined Wi-Fi testbeds. Our two techniques thus significantly lower the barrier-to-entry for deploying software-defined Wi-Fi networks. © 2016 Copyright held by the owner/author(s).",SDN; Testbeds; Wi-fi,Convolutional codes; Testbeds; Wireless local area networks (WLAN); Research prototype; Scalability issue; Short-comings; Software defined networking (SDN); Wi Fi networks; Wi-Fi
"Moshref M., Yu M., Govindan R., Vahdat A.",4,Trumpet: Timely and precise triggers in data centers,2016,27,"USC, United States; Google, Inc., United States",Google,1,USA,1,8,6,"As data centers grow larger and strive to provide tight performance and availability SLAs, their monitoring infrastructure must move from passive systems that provide aggregated inputs to human operators, to active systems that enable programmed control. In this paper, we propose Trumpet, an event monitoring system that leverages CPU resources and end-host programmability, to monitor every packet and report events at millisecond timescales. Trumpet users can express many network-wide events, and the system efficiently detects these events using triggers at end-hosts. Using careful design, Trumpet can evaluate triggers by inspecting every packet at full line rate even on future generations of NICs, scale to thousands of triggers per end-host while bounding packet processing delay to a few microseconds, and report events to a controller within 10 milliseconds, even in the presence of attacks. We demonstrate these properties using an implementation of Trumpet, and also show that it allows operators to describe new network events such as detecting correlated bursts and loss, identifying the root cause of transient congestion, and detecting short-term anomalies at the scale of a data center tenant. © 2016 ACM.",End-host monitoring; Network event monitoring,Convolutional codes; Active systems; Event monitoring; Future generations; Human operator; Packet processing; Passive systems; Programmability; Programmed controls; Packet networks
"Fršmmgen A., Stohr D., Fornoff J., Effelsberg W., Buchmann A.",5,Capture and replay: Reproducible network experiments in Mininet,2016,3,"Distributed Multimedia Systems, Germany; Databases and Distributed Systems, TU Darmstadt, Germany",TU Darmstadt,1,Germany,1,58,47,"Network emulations are widely used in the networking community. The network emulator Mininet recently gained popularity, as it allows running real Linux applications on top of an emulated network. The specification of the network includes the topology as well as static bandwidth, latency, and packet drops probability parameters. Even though evaluations with static parameters provide useful insights, real world measurements show dynamically changing bandwidths, posing special challenges that need to be addressed in network research. In this demo, we capture bandwidth traces in the wild and reproducibly replay these traces in Mininet. Our capture and replay infrastructure consists of a Mininet extension for replaying bandwidth traces, a measurement Android app, as well as a graphical repository for bandwidth traces. We exemplary demonstrate this toolchain for reproducible DASH and Multipath TCP experiments. © 2016 ACM.",Bandwidth replay; Mininet; Reproducible research,Computer operating systems; Convolutional codes; Mininet; Multipath TCP; Network emulation; Network emulators; Networking community; Packet drops; Reproducible research; Static parameters; Bandwidth
"Gao K., Gu C., Xiang Q., Yang Y.R., Bi J.",5,FAST: A simple programming abstraction for complex state-dependent SDN programming,2016,1,"Tsinghua Univeristy, China; Tongji University, China; Yale University, United States",Tongji University;Tsinghua University;Yale University,3,China;USA,2,5,5,"Handling state dependencies is a major challenge in modern SDN programming, but existing frameworks do not provide sufficient abstractions nor tools to address this challenge. In this paper, we propose a novel, high-level programming abstraction and implement the Function Automation SysTem (FAST). With the two key features, i.e., automated state dependency tracking and efficient re-execution scheduling, we demonstrate that Fast substantially simplifies state-dependent SDN programming and boosts the performance. © 2016 ACM.",Programming abstraction; SDN; State dependency,Automation; Computer programming; Convolutional codes; Automation systems; Dependency tracking; High-level programming; Key feature; Programming abstractions; Re-execution; State dependency; State-dependent; Abstracting
"Arashloo M.T., Koral Y., Greenberg M., Rexford J., Walker D.",5,SNAP: Stateful network-wide abstractions for packet processing,2016,35,"Princeton University, United States; Pomona College, United States",Pomona College;Princeton University,2,USA,1,2,0,"Early programming languages for software-defined networking (SDN) were built on top of the simple match-action paradigm offered by OpenFlow 1.0. However, emerging hardware and software switches offer much more sophisticated support for persistent state in the data plane, without involving a central controller. Nevertheless, managing stateful, distributed systems efficiently and correctly is known to be one of the most challenging programming problems. To simplify this new SDN problem, we introduce SNAP. SNAP offers a simpler ""centralized"" stateful programming model, by allowing programmers to develop programs on top of one big switch rather than many. These programs may contain reads and writes to global, persistent arrays, and as a result, programmers can implement a broad range of applications, from stateful firewalls to fine-grained traffic monitoring. The SNAP compiler relieves programmers of having to worry about how to distribute, place, and optimize access to these stateful arrays by doing it all for them. More specifically, the compiler discovers read/write dependencies between arrays and translates one-big-switch programs into an efficient internal representation based on a novel variant of binary decision diagrams. This internal representation is used to construct a mixed-integer linear program, which jointly optimizes the placement of state and the routing of traffic across the underlying physical topology. We have implemented a prototype compiler and applied it to about 20 SNAP programs over various topologies to demonstrate our techniques' scalability. © 2016 ACM.",Network programming language; One big switch; Optimization; SNAP; Software defined networks; Stateful packet processing,Application programs; Binary decision diagrams; Computer programming; Convolutional codes; Distributed computer systems; Integer programming; Optimization; Packet networks; Problem oriented languages; Software defined networking; Topology; Hardware and software; Internal representation; Mixed integer linear program; Network programming language; Packet processing; Programming problem; SNAP; Software defined networking (SDN); Program compilers
"Zhao S., Sydney A., Medhi D.",3,Building application-aware network environments using SDN for optimizing Hadoop applications,2016,5,"University of Missouri-Kansas City, United States; Raytheon BBN Technologies, United States",University of Missouri-Kansas City,1,USA,1,45,39,"Hadoop has become the de facto standard for Big Data analytics, especially for workloads that use the MapReduce (M/R) framework. However, the lack of network awareness of the default MapReduce resource manager in Hadoop can cause unbalanced job scheduling, network bottleneck, and eventually increase the Hadoop run time if Hadoop nodes are clustered in several geographically distributed locations. In this paper, we present an application-aware network approach using software-defined networking (SDN) for distributed Hadoop clusters. We develop the SDN applications for this environment that consider network topology discovery, traffic monitoring, and flow rerouting in addition to loop avoidance mechanisms. © 2016 ACM.",Application-aware networking; Hadoop; Software-defined networking,Big data; Convolutional codes; Software defined networking; Application-aware network; Building applications; Hadoop; Network awareness; Network bottlenecks; Network topology discoveries; Software defined networking (SDN); Traffic monitoring; Application programs
"Chaviaras G., Gigis P., Sermpezis P., Dimitropoulos X.",4,ARTEMIS: Real-time detection and automatic mitigation for BGP prefix hijacking,2016,1,"FORTH, University of Crete, Greece",University of Crete,1,Greece,1,7,7,"Prefix hijacking is a common phenomenon in the Internet that often causes routing problems and economic losses. In this demo, we propose ARTEMIS, a tool that enables network administrators to detect and mitigate prefix hijacking incidents, against their own prefixes. ARTEMIS is based on the real-time monitoring of BGP data in the Internet, and software-defined networking (SDN) principles, and can completely mitigate a prefix hijacking within a few minutes (e.g., 5-6mins in our experiments) after it has been launched. © 2016 ACM.",Network management; Network monitoring; Network security,Convolutional codes; Internet; Losses; Network management; Bgp prefix hijackings; Network administrator; Network Monitoring; Prefix hijacking; Real time monitoring; Real-time detection; Routing problems; Software defined networking (SDN); Network security
"Chang L., Xiong J., Chen X., Wang J., Hu J., Fang D., Wang W.",7,TafLoc: Time-adaptive and fine-grained device-free localization with little cost,2016,0,"Northwest University, China; Singapore Management University, Singapore",Northwest University;Singapore Management University,2,China;Singapore,2,12,3,"Many emerging applications drive the needs of device-free localization (DfL), in which the target can be localized without any device attached. Because of the ubiquitousness of WiFi infrastructures nowadays, the widely available Received Signal Strength (RSS) information at the WiFi Access points are commonly employed for localization purposes. However, current RSS based DfL systems have one main drawback hindering their real-life applications. That is, the RSS measurements (fingerprints) vary slowly in time even without any change in the environment and frequent updates of RSS at each location lead to a high human labor cost. In this paper, we propose an RSS based low cost DfL system named TafLoc which is able to accurately localize the target over a long time scale. To reduce the amount of human labor cost in updating the RSS fingerprints, TafLoc represents the RSS fingerprints as a matrix which has several unique properties. Based on these properties, we propose a novel fingerprint matrix reconstruction scheme to update the whole fingerprint database with just a few RSS measurements, thus the labor cost is greatly reduced. Extensive experiments illustrate the effectiveness of TafLoc, outperforming the state-of-the-art RSS based DfL systems. © 2016 ACM.","Device free localization; Received signal strength; Time adaptive, fine-grained",Compensation (personnel); Convolutional codes; Cost accounting; Cost reduction; Costs; Digital storage; Employment; Matrix algebra; Mobile computing; Wages; Wireless local area networks (WLAN); Device-free localizations; Emerging applications; Fine grained; Fingerprint database; Real-life applications; Received signal strength; State of the art; Wi-fi access points; RSS
"Stoenescu R., Popovici M., Negreanu L., Raiciu C.",4,SymNet: Scalable symbolic execution for modern networks,2016,25,"University Politehnica of Bucharest, Splaiul Independentei 313, Bucharest, Romania",University Politehnica of Bucharest,1,Romania,1,3,3,"We present SymNet, a network static analysis tool based on symbolic execution. SymNet injects symbolic packets and tracks their evolution through the network. Our key novelty is SEFL, a language we designed for expressing data plane processing in a symbolic-execution friendly manner. SymNet statically analyzes an abstract data plane model that consists of the SEFL code for every node and the links between nodes. SymNet can check networks containing routers with hundreds of thousands of prefixes and NATs in seconds, while verifying packet header memory-safety and covering network functionality such as dynamic tunneling, stateful processing and encryption. We used SymNet to debug middlebox interactions from the literature, to check properties of our department's network and the Stanford backbone. Modeling network functionality is not easy. To aid users we have developed parsers that automatically generate SEFL models from router and switch tables, firewall configurations and arbitrary Click modular router configurations. The parsers rely on prebuilt models that are exact and fast to analyze. Finally, we have built an automated testing tool that combines symbolic execution and testing to check whether the model is an accurate representation of the real code. © 2016 ACM.",Data plane verification; Symbolic execution; SymNet,Computational linguistics; Convolutional codes; Data handling; Model checking; Static analysis; Automated testing tools; Click modular router; Data planes; Data-plane processing; Dynamic tunneling; Network functionality; Symbolic execution; SymNet; Routers
"Sun Y., Yin X., Jiang J., Sekar V., Lin F., Wang N., Liu T., Sinopoli B.",8,CS2P: Improving video bitrate selection and adaptation with data-driven throughput prediction,2016,49,"ICT/CAS, China; CMU, China; IQIYI, China",Carnegie Mellon University,1,China,1,24,4,"Bitrate adaptation is critical to ensure good quality-of-experience (QoE) for Internet video. Several efforts have argued that accurate throughput prediction can dramatically improve the efficiency of (1) initial bitrate selection to lower startup delay and offer high initial resolution and (2) midstream bitrate adaptation for high QoE. However, prior efforts did not systematically quantify real-world throughput predictability or develop good prediction algorithms. To bridge this gap, this paper makes three contributions. First, we analyze the throughput characteristics in a dataset with 20M+ sessions. We find: (a) Sessions sharing similar key features (e.g., ISP, region) present similar initial throughput values and dynamic patterns; (b) There is a natural ""stateful"" behavior in throughput variability within a given session. Second, building on these insights, we develop CS2P, a throughput prediction system which uses a data-driven approach to learn (a) clusters of similar sessions, (b) an initial throughput predictor, and (c) a Hidden-Markov-Model based midstream predictor modeling the stateful evolution of throughput. Third, we develop a prototype system and show using trace-driven simulation and real-world experiments that: (1) CS2P outperforms existing prediction approaches by 40% and 50% in terms of the median prediction error for initial and midstream throughput and (2) CS2P achieves 3.2% improvement on overall QoE and 10.9% higher average bitrate over state-of-art Model Predictive Control (MPC) approach, which uses Harmonic Mean for throughput prediction. © 2016 ACM.",Bitrate adaptation; Dynamic Adaptive Streaming over HTTP (DASH); Internet video; TCP; Throughput prediction,Algorithms; Convolutional codes; Forecasting; Hidden Markov models; HTTP; Internet; Internet service providers; Markov processes; Model predictive control; Predictive control systems; Quality of service; Transmission control protocol; Video streaming; Bit rates; Dynamic Adaptive Streaming over HTTP; Internet video; Prediction algorithms; Quality of experience (QoE); Real world experiment; Throughput variabilities; Trace driven simulation; Throughput
"Mace J., Bodik P., Musuvathi M., Fonseca R., Varadarajan K.",5,2DFQ: Two-dimensional fair queueing for multi-tenant cloud services,2016,4,"Brown University, United States; Microsoft, China",Brown University;Microsoft,2,China;USA,2,50,24,"In many important cloud services, different tenants execute their requests in the thread pool of the same process, requiring fair sharing of resources. However, using fair queue schedulers to provide fairness in this context is difficult because of high execution concurrency, and because request costs are unknown and have high variance. Using fair schedulers like WFQ and WF2Q in such settings leads to bursty schedules, where large requests block small ones for long periods of time. In this paper, we propose Two-Dimensional Fair Queueing (2DFQ), which spreads requests of different costs across different threads and minimizes the impact of tenants with unpredictable requests. In evaluation on production workloads from Azure Storage, a large-scale cloud system at Microsoft, we show that 2DFQ reduces the burstiness of service by 1-2 orders of magnitude. On workloads where many large requests compete with small ones, 2DFQ improves 99th percentile latencies by up to 2 orders of magnitude. © 2016 Copyright held by the owner/author(s).",Fair request scheduling; Multi-tenant systems,Convolutional codes; Digital storage; Distributed database systems; Scheduling; Web services; Windows operating system; Cloud services; Cloud systems; Fair queueing; Multi tenants; Orders of magnitude; Production workloads; Request scheduling; Thread pools; Queueing theory
"Beckett R., Mahajan R., Millstein T., Padhye J., Walker D.",5,Don't mind the gap: Bridging network-wide objectives and device-level configurations,2016,16,"Princeton, United States; Microsoft, China; UCLA, United States",Microsoft,1,China;USA,2,81,29,"We develop Propane, a language and compiler to help network operators with a challenging, error-prone task - bridging the gap between network-wide routing objectives and low-level configurations of devices that run complex, distributed protocols. The language allows operators to specify their objectives naturally, using high-level constraints on both the shape and relative preference of traffic paths. The compiler automatically translates these specifications to router-level BGP configurations, using an effective intermediate representation that compactly encodes the flow of routing information along policy-compliant paths. It guarantees that the compiled configurations correctly implement the specified policy under all possible combinations of failures. We show that Propane can effectively express the policies of datacenter and backbone networks of a large cloud provider; and despite its strong guarantees, our compiler scales to networks with hundreds or thousands of routers. © 2016 ACM.",BGP; Compilation; Distributed systems; Domain-specific language; Fault tolerance; Propane; Synthesis,Computer programming languages; Convolutional codes; Fault tolerance; Fault tolerant computer systems; High level languages; Problem oriented languages; Program compilers; Propane; Routers; Synthesis (chemical); Back-bone network; Compilation; Distributed protocols; Distributed systems; Domain specific languages; Error prone tasks; Intermediate representations; Routing information; Complex networks
"Bernal M.V., Cerrato I., Risso F., Verbeiren D.",4,A transparent highway for inter-virtual network function communication with Open vSwitch,2016,1,"Dept. of Computer and Control Engineering, Politecnico di Torino, Turin, Italy; Tessares SA, Louvain-la-Neuve, Belgium",Politecnico di Torino,1,Belgium;Italy,2,32,22,"This paper presents a software architecture that can dynamically and transparently establish direct communication paths between DPDK-based virtual network functions executed in virtual machines, by recognizing new point-to-point connections in traffic steering rules. We demonstrate the huge advantages of this architecture in terms of performance and the possibility to implement it with localized modifications in Open vSwitch and DPDK, without touching the VNFs. © 2016 ACM.",DPDK; NFV; Open vSwitch; Performance,Convolutional codes; Transfer functions; Direct communications; DPDK; Open vswitch; Performance; Point-to-point connections; Virtual machines; Virtual networks; Network architecture
"Jalaparti V., Bliznets I., Kandula S., Lucier B., Menache I.",5,Dynamic pricing and traffic engineering for timely inter-datacenter transfers,2016,18,"Microsoft, China",Microsoft,1,China,1,1,1,"As more business moves to the cloud, inter-datacenter bandwidth becomes an ever more valuable and congested resource. This bandwidth is typically sold using a fixed price per GB, and transfers are scheduled using traffic engineering mechanisms. However, this separation between the economic and engineering aspects of the problem makes it difficult to steer customer demand to lightly loaded paths and times, which is important for managing costs (typically proportional to peak usage) and providing service guarantees. To address these issues, we design and evaluate Pretium - a framework that combines dynamic pricing with traffic engineering for inter-datacenter bandwidth. In Pretium, users specify their required rates or transfer sizes with deadlines, and a price module generates a price quote for different guarantees (promises) on these requests. The price quote is generated using internal prices (which can vary over time and links) which are maintained and periodically updated by Pretium based on history. A supplementary schedule adjustment module gears the agreed-upon network transfers towards an efficient operating point by optimizing time-varying operation costs. Using traces from a large production WAN, we show that Pretium achieves up to 80% of the social welfare of an offline oracular scheme, significantly outperforming usage-based pricing alternatives. © 2016 Copyright held by the owner/author(s).",Deadline scheduling; Dynamic pricing; Inter-datacenter networks; Percentile pricing,Bandwidth; Convolutional codes; Cost engineering; Time varying networks; Data center networks; Deadline scheduling; Dynamic pricing; Engineering aspects; Network transfers; Schedule adjustments; Service guarantees; Traffic Engineering; Costs
"Hamed E., Rahul H., Abdelghany M.A., Katabi D.",4,Real-time distributed MIMO systems,2016,17,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,35,20,"Recent years have seen a lot of work in moving distributed MIMO from theory to practice. While this prior work demonstrates the feasibility of synchronizing multiple transmitters in time, frequency, and phase, none of them deliver a full-fledged PHY capable of supporting distributed MIMO in real-time. Further, none of them can address dynamic environments or mobile clients. Addressing these challenges, requires new solutions for low-overhead and fast tracking of wireless channels, which are the key parameters of any distributed MIMO system. It also requires a software-hardware architecture that can deliver a distributed MIMO within a full-fledged 802.11 PHY, while still meeting the tight timing constraints of the 802.11 protocol. This architecture also needs to perform coordinated power control across distributed MIMO nodes, as opposed to simply letting each node perform power control as if it were operating alone. This paper describes the design and implementation of MegaMIMO 2.0, a system that achieves these goals and delivers the first real-time fully distributed 802.11 MIMO system. © 2016 Copyright held by the owner/author(s).",Distributed MIMO; Multi-user MIMO; Wireless networks,Convolutional codes; Network architecture; Power control; Real time systems; Wireless networks; Coordinated power; Design and implementations; Distributed MIMO; Dynamic environments; Hardware architecture; Multi-user MIMO; Multiple transmitters; Timing constraints; MIMO systems
"Qiao S., Hu C., Guan X., Zou J.",4,Taming the flow table overflow in OpenFlow switch,2016,6,"Xi'an Jiaotong University, Xi'an, China",Xian JiaoTong University,1,China,1,17,11,"SDN has become the wide area network technology, which the academic and industry most concerned about.The limited table sizes of today's SDN switches has turned to the most prominent short planks in the network design implementation. TCAM based flow table can provide an excellent matching performance while it really costs much. Even the flow table overflow cannot be prevented by a fixed-capacity flow table. In this paper, we design FTS(Flow Table Sharing) mechanism that can improve the performance disaster caused by overflow. We demonstrate that FTS reduces both control messages quantity and RTT time by two orders of magnitude compared to current state-of-the-art OpenFlow table-miss handler. © 2016 ACM.",Flow table; Group table; Overflow; SDN; Table-miss,Convolutional codes; Flow tables; Group table; Matching performance; Openflow switches; Orders of magnitude; Overflow; State of the art; Table-miss; Wide area networks
"Durairajan R., Barford P.",2,A techno-economic framework for broadband deployment in underserved areas,2016,1,"University of Wisconsin-Madison, United States; University of Wisconsin-Madison, comScore, Inc., United States",University of Wisconsin-Madison;ComScore Inc.,2,USA,1,2,2,"A large body of economic research has shown the strong correlation between broadband connectivity and economic productivity (e.g., [1Ð3]). These findings motivate government agencies such as the FCC in the US to provide incentives to services providers to deploy broadband infrastructure in unserved or underserved areas. In this paper, we describe a framework for identifying target areas for network infrastructure deployment. Our approach considers (i) infrastructure availability, (ii) user demographics, and (iii) deployment costs. We use multi-objective optimization to identify geographic areas that have the highest concentrations of un/underserved users and that can be upgraded at the lowest cost. To demonstrate the efficacy of our framework, we consider physical infrastructure and demographic data from the US and two different deployment cost models. Our results identify a list of counties that would be attractive targets for broadband deployment from both cost and impact perspectives. We conclude with discussion on the implications and broader applications of our framework. © 2016 ACM.",Broadband deployment targets; Multi-criteria optimization; Underserved areas,Broadband networks; Multiobjective optimization; Population statistics; Broadband connectivity; Broadband deployment; Broadband infrastructure; Economic productivity; Government agencies; Multicriteria optimization; Network infrastructure; Under-served areas; Costs
"Waites W., Sweet J., Baig R., Buneman P., Fayed M., Hughes G.",6,RemIX: A distributed internet exchange for remote and rural networks,2016,2,"University of Edinburgh, United Kingdom; HUBS C.I.C, United Kingdom; Guifi.net, Spain; University of Stirling, United Kingdom",University of Edinburgh;University of Stirling,2,Spain;UK,2,42,19,"The Internet Exchange Point (IXP), an Ethernet fabric central to the structure of the global Internet, is largely absent from community-driven collaborative network infrastructure. IXPs exist in central, typically urban, environments where strong network infrastructure ensures high levels of connectivity. Between rural and remote networks, separated by distance and terrain, no such infrastructure exists. In this paper we present RemIX a distributed IXP architecture designed for the community network environment. We examine this praxis using an implementation in Scotland, with suggestions for future development and research. © 2016 ACM.",Community broadband; Internet exchanges (IXP),Collaborative network; Community broadband; Community networks; Global Internet; Internet Exchange; Internet exchange points; Network infrastructure; Remote networks; Distributed computer systems
"Baig R., Dalmau L., Roca R., Navarro L., Freitag F., Sathiaseelan A.",6,Making community networks economically sustainable: The Guifi.net experience,2016,8,"Fundaci— Guifi.net, Gurb, Catalonia, Spain; UPC, Barcelona, Spain; Cambridge University, Cambridge, United Kingdom",University of Cambridge,1,Spain;UK,2,19,15,"Community networks have flourished around the world as complementary models for enabling access to the Internet and its services. Nevertheless, there is still an ongoing debate on how to make them sustainable and scalable beyond voluntary efforts and non-refundable contributions. The approach taken by Guifi.net has been to enable professional activity and to develop a set of tools to ensure the reinvestment of a fraction of the benefits of this professional activity. This has contributed to building the largest community network, with an annual turnover of millions of euros and the creation of dozens of direct jobs. The implementation of these tools is producing extensive data sets that allow characterisation of key parameters in the deployment and operation of these infrastructures to examine behaviours and trends and to identify good and bad practices, fraud, etc. A more detailed knowledge of the economic aspects has a positive effect on reducing the uncertainty of investments, expansion plans, and operations. © 2016 Copyright held by the owner/author(s).",Capital expenditure; Community networks; Cost-sharing; Economic sustainability; Operational expenditure,Cost effectiveness; Investments; Capital expenditures; Community networks; Cost sharing; Economic sustainability; Operational expenditures; Costs
"Montes I., Cruz M., Remillano A., II, Ocampo R., Villanoy M., Beltran L., II, Festin C.",9,"Tangible sharing, invisible mechanisms: The design and implementation of the BayanihaNets access sharing network",2016,1,"Electrical and Electronics Engineering Institute, University of the Philippines, Diliman, Philippines; Department of Computer Science, University of the Philippines, Diliman, Philippines",University of the Philippines,1,Philippines,1,8,6,"Cooperation through resource pooling may help deliver affordable connectivity to those without subscriptions and improve access for those with existing connections. Using the concept of bayanihan, a Filipino expression for a deeply traditional and cultural type of cooperation, we designed and implemented a cooperative access sharing network that makes sharing tangible to users. We highlight the altruism users exercise in sharing connectivity and the negative impact of selfish actions, if any, through the use of the familiar interfaces, mechanisms and idiom from online social networking applications. Our strategy of promoting and enabling network infrastructure sharing as a social activity may thus be described asÕsocial networking through social networking.Õ We discuss our bayanihan-based design principles, present initial experimental results on bandwidth sharing in a controlled environment, and describe our upcoming pilot deployment. © Copyright 2016 ACM.",Cooperative networking; Resource pooling,Bandwidth sharing; Controlled environment; Cooperative networkings; Design and implementations; Design Principles; Network infrastructure; Online social networkings; Resource pooling; Social networking (online)
"Gember-Jacobson A., Wu W., Li X., Akella A., Mahajan R.",5,Management plane analytics,2015,9,"University of Wisconsin-Madison, United States; Microsoft Research, United States",Microsoft;;University of Wisconsin-Madison,3,USA,1,22,13,"While it is generally held that network management is tedious and error-prone, it is not well understood which specific management practices increase the risk of failures. Indeed, our survey of 51 network operators reveals a significant diversity of opinions, and our characterization of the management practices in the 850+ networks of a large online service provider shows significant diversity in prevalent practices. Motivated by these observations, we develop a management plane analytics (MPA) framework that an organization can use to: (i) infer which management practices impact network health, and (ii) develop a predictive model of health, based on observed practices, to improve network management. We overcome the challenges of sparse and skewed data by aggregating data from many networks, reducing data dimensionality, and oversam-pling minority cases. Our learned models predict network health with an accuracy of 76-89%, and our causal analysis uncovers some high impact practices that operators thought had a low impact on network health. Our tool is publicly available, so organizations can analyze their own management practices. © 2015 ACM.",Decision trees; Network health; Network management practices; Quasi-experimental design,Decision trees; Health; Internet; Causal analysis; Data dimensionality; Management planes; Management practices; Network operator; On-line service; Predictive modeling; Risk of failure; Network management
"Li Z., Wilson C., Xu T., Liu Y., Lu Z., Wang Y.",6,Offline downloading in China: A comparative study,2015,8,"Tsinghua University Tencent Co., Ltd., China; Northeastern University, Boston, MA, United States; University of California, San Diego, CA, United States; State University of New York, United States; Binghamton University, United States; Tsinghua University, Beijing, China",Northeastern University;SUNY Binghamton;Tsinghua University;University of California San Diego,4,China;USA,2,39,22,"Although Internet access has become more ubiquitous in recent years, most users in China still suffer from low-quality connections, especially when downloading large files. To address this issue, hundreds of millions of China's users have resorted to technologies that allow for ""offline downloading"", where a proxy is employed to pre-download the user's requested file and then deliver the file at her convenience. In this paper, we examine two typical implementations of offline downloading: the cloud-based approach and the smart AP (access point) based approach. Using a large-scale dataset collected from a major cloud-based system and comprehensive benchmarks of popular smart APs, we find that the two approaches are complementary while also being subject to distinct performance bottlenecks. Driven by these results, we design and implement a proof-of-concept middleware called ODR (Offline Downloading Redirector) to help users get rid of performance bottlenecks. We feel that offline downloading has broad applicability to other areas of the world that lack broadband penetration. By deploying offline downloading technologies, coupled with our proposed ODR middleware, the Internet experiences for users in many parts of the world can be improved. © 2015 ACM.",Cloud storage; DTN; Internet; Offline downloading; Smart AP,Benchmarking; Internet; Middleware; Broadband penetration; Cloud storages; Comparative studies; Design and implements; DTN; Offline; Performance bottlenecks; Smart AP; Electronic document exchange
"Andriesse D., Rossow C., Bos H.",3,Reliable recon in adversarial peer-to-Peer botnets,2015,9,"VU University, Amsterdam, Netherlands; Saarland University, Germany",Saarland University;Vrije University,2,Germany;Netherlands,2,72,32,"The decentralized nature of Peer-to-Peer (P2P) botnets precludes traditional takedown strategies, which target dedicated command infrastructure. P2P botnets replace this infrastructure with command channels distributed across the full infected population. Thus, mitigation strongly relies on accurate reconnaissance techniques which map the botnet population. While prior work has studied passive disturbances to reconnaissance accuracy - such as IP churn and NAT gateways -, the same is not true of active antireconnaissance attacks. This work shows that active attacks against crawlers and sensors occur frequently in major P2P botnets. Moreover, we show that current crawlers and sensors in the Sality and Zeus botnets produce easily detectable anomalies, making them prone to such attacks. Based on our findings, we categorize and evaluate vectors for stealthier and more reliable P2P botnet reconnaissance.",Crawling; Peer-to-Peer botnet; Reconnaissance,Internet; Network security; Active attack; Botnets; Crawling; Peer to peer; Reconnaissance; Malware
"Fukuda K., Asai H., Nagami K.",3,Tracking the evolution and diversity in network usage of smartphones,2015,9,"National Institute of Informatics, Sokendai, Japan; University of Tokyo, Japan; Intec, Japan",National Institute of Informatics;University of Tokyo,2,Japan,1,37,34,"We analyze the evolution of smartphone usage from a dataset obtained from three, 15-day-long, user-side, measurements with over 1500 recruited smartphone users in the Greater Tokyo area from 2013 to 2015. This dataset shows users across a diverse range of networks; cellular access (3G to LTE), WiFi access (2.4 to 5GHz), deployment of more public WiFi access points (APs), as they use diverse applications such as video, file synchronization, and major software updates. Our analysis shows that smartphone users select appropriate network interfaces taking into account the deployment of emerging technologies, their bandwidth demand, and their economic constraints. Thus, users show diversity in both how much traffic they send, as well as on what networks they send it. We show that users are gradually but steadily adopting WiFi at home, in offices, and public spaces over these three years. The majority of light users have been shifting their traffic to WiFi. Heavy hitters acquire more bandwidth via WiFi, especially at home. The percentage of users explicitly turning off their WiFi interface during the day decreases from 50% to 40%. Our results highlight that the offloading environment has been improved during the three years, with more than 40% of WiFi users connecting to multiple WiFi APs in one day. WiFi offload at offices is still limited in our dataset due to a few accessible APs, but WiFi APs in public spaces have been an alternative to cellular access for users who request not only simple connectivity but also bandwidth-consuming applications such as video streaming and software updates.",LTE; Smartphone traffic; WiFi; WiFi offload,Application programs; Bandwidth; Internet; Signal encoding; Smartphones; Video streaming; Wireless telecommunication systems; Bandwidth demand; Diverse applications; Economic constraints; Emerging technologies; File synchronization; LTE; Software updates; Wi-fi access points; Wi-Fi
"Vlachou C., Henri S., Thiran P.",3,Electri-Fi your data: Measuring and combining power-line communications with WiFi,2015,3,"EPFL, Switzerland","EPFL, Switzerland",1,Switzerland,1,52,47,"Power-line communication (PLC) is widely used as it offers high data-rates and forms a network over electrical wiring, an existing and ubiquitous infrastructure. PLC is increasingly being deployed in hybrid networks that combine multiple technologies, the most popular among which is WiFi. However, so far, it is not clear to which extent PLC can boost network performance or how hybrid implementations can exploit to the fullest this technology. We compare the spatial and temporal variations of WiFi and PLC. Despite the potential of PLC and its vast deployment in commercial products, little is known about its performance. To route or load balance traffic in hybrid networks, a solid understanding of PLC and its link metrics is required. We conduct experiments in a testbed of more than 140 links. We introduce link metrics that are crucial for studying PLC and that are required for quality-aware algorithms by recent standardizations of hybrid networks. We explore the spatial and temporal variation of PLC channels, showing that they are highly asymmetric and that link quality and link-metric temporal variability are strongly correlated. Based on our variation study, we propose and validate a capacity estimation technique via a metric that only uses the frame header. We also focus on retransmissions due to channel errors or to contention, a metric related to delay, and examine the sensitivity of metrics to background traffic. Our performance evaluation provides insight into the implementation of hybrid networks; we ease the intricacies of understanding the performance characteristics of the PHY and MAC layers. © 2015 ACM.",Capacity estimation; HomePlug AV; Hybrid networks; IEEE 1901; IEEE 1905; Link metrics; Power-line communications,Electric power measurement; Internet; Capacity estimation; HomePlug AV; Hybrid network; IEEE 1901; IEEE 1905; Link metrics; Power line communications; Wi-Fi
"Hu X., Song L., Van Bruggen D., Striegel A.",4,Is there WiFi yet? How aggressive probe requests deteriorate energy and throughput,2015,11,"University of Notre Dame, Notre Dame, IN  46556, United States",University of Notre Dame,1,USA,1,22,16,"WiFi offloading has emerged as a key component of cellular operator strategy to meet the rich data needs of modern mobile devices. Hence, mobile devices tend to aggressively seek out WiFi in order to provide improved user Quality of Experience (QoE) and cellular capacity relief. For home and work environments, aggressive WiFi scans can significantly improve the speed at which mobile nodes join the WiFi network. Unfortunately, the same aggressive behavior that excels in the home environment incurs considerable side effects in crowded wireless environments. In this paper, we analyze empirical data collected from large (stadium) and medium (classroom) venues, and show through controlled experiments (laboratory) how aggressive WiFi scans can have significant implications for energy and throughput for mobile nodes. We close with several thoughts on the disjoint incentives for properly balancing WiFi discovery speed and crowded network interactions. © 2015 ACM.",Energy; Performance; Probe request; WiFi,Internet; Mobile devices; Probes; Quality of service; Cellular operators; Controlled experiment; Energy; Network interaction; Performance; Quality of experience (QoE); Wireless environment; Work environments; Wi-Fi
"Fukuda K., Heidemann J.",2,Detecting malicious activity with DNS backscatter,2015,7,"National Institute of Informatics, Sokendai, Japan; University of Southern California, Information Sciences Institute, United States",National Institute of Informatics;University of Southern California,2,Japan;USA,2,14,12,"Network-wide activity is when one computer (the originator) touches many others (the targets). Motives for activity may be benign (mailing lists, CDNs, and research scanning), malicious (spammers and scanners for security vulnerabilities), or perhaps indeterminate (ad trackers). Knowledge of malicious activity may help anticipate attacks, and understanding benign activity may set a baseline or characterize growth. This paper identifies DNS backscatter as a new source of information about network-wide activity. Backscatter is the reverse DNS queries caused when targets or middleboxes automatically look up the domain name of the originator. Queries are visible to the authoritative DNS servers that handle reverse DNS. While the fraction of backscatter they see depends on the server's location in the DNS hierarchy, we show that activity that touches many targets appear even in sampled observations. We use information about the queriers to classify originator activity using machine-learning. Our algorithm has reasonable precision (70-80%) as shown by data from three different organizations operating DNS servers at the root or country-level. Using this technique we examine nine months of activity from one authority to identify trends in scanning, identifying bursts corresponding to Heartbleed and broad and continuous scanning of ssh.",DNS; Domain name system; Internet; Network activity; Scanning,Artificial intelligence; Backscattering; Classification (of information); Internet; Learning systems; Scanning; Continuous scanning; DNS; Domain name system; Mailing lists; Malicious activities; Network activities; Sampled observations; Security vulnerabilities; Internet protocols
"Durumeric Z., Adrian D., Mirian A., Kasten J., Bursztein E., Lidzborski N., Thomas K., Eranti V., Bailey M., Halderman J.A.",10,Neither snow nor rain nor MITM_ An empirical analysis of email delivery security,2015,18,"University of Michigan, United States; Google, Inc., United States; University of Illinois, Urbana Champaign, United States",Google;UIUC;University of Michigan at Ann Arbor,3,USA,1,57,45,"The SMTP protocol is responsible for carrying some of users' most intimate communication, but like other Internet protocols, authentication and confidentiality were added only as an afterthought. In this work, we present the first report on global adoption rates of SMTP security extensions, including: STARTTLS, SPF, DKIM, and DMARC. We present data from two perspectives: SMTP server configurations for the Alexa Top Million domains, and over a year of SMTP connections to and from Gmail. We find that the top mail providers (e.g., Gmail, Yahoo, and Outlook) all proactively encrypt and authenticate messages. However, these best practices have yet to reach widespread adoption in a long tail of over 700,000 SMTP servers, of which only 35% successfully configure encryption, and 1.1% specify a DMARC authentication policy. This security patchwork - paired with SMTP policies that favor failing open to allow gradual deployment - exposes users to attackers who downgrade TLS connections in favor of cleartext and who falsify MX records to reroute messages. We present evidence of such attacks in the wild, highlighting seven countries where more than 20% of inbound Gmail messages arrive in cleartext due to network attackers.",DKIM; DMARC; Email; Mail; SMTP; SPF; STARTTLS; TLS,Authentication; Cryptography; Electronic mail; Internet; Thallium; DKIM; DMARC; Mail; SMTP; SPF; STARTTLS; Internet protocols
"Javed M., Herley C., Peinado M., Paxson V.",4,Measurement and analysis of traffic exchange services,2015,4,"U.C. Berkeley, International Computer Science Institute, United States; Microsoft Research, United States",Microsoft;University of California Berkeley,2,USA,1,47,41,"Traffic exchange services enable members to bring traffic to their websites from a diverse pool of IP addresses, in return for visiting sites of other members. We examine the world of traffic exchanges to characterize their makeup, usage, and monetization. We find that the ecosystem includes a range of services, from manual exchanges where participants must solve CAPTCHAs between successive page views, to exchanges that provide tools that automatically surf without requiring any user action. By ""milking"" a sample of these exchanges, we analyze month-long datasets to examine the nature of URLs that members submit to them. We find a wide prevalence of URLs for services that pay users in return for views to their content, and at least 30% of the requested impressions are for pages that clearly participate in a class of impression fraud called referrer spoofing. We also analyze the size and composition of a sample of these exchange networks by making purchases, finding that the exchanges delivered visits from roughly 200K unique IP addresses, and that in some exchange networks, the majority of visits came from cloud hosting services.",Click fraud; Impression fraud; Traffic exchanges,Internet; CAPTCHAs; Click fraud; Cloud hosting; Exchange networks; Impression fraud; IP addresss; Measurement and analysis; User action; Crime
"Vattikonda B.C., Dave V., Guha S., Snoeren A.C.",4,Empirical analysis of search advertising strategies,2015,2,"University of California, San Diego, United States; Microsoft, Mountain View, CA, United States; Microsoft Research, Bangalore, India",Microsoft;University of California San Diego,2,India;USA,2,37,32,"Top search ad placement is the coin of today's Internet services realm. An entire industry of search engine marketing companies have emerged to help advertisers optimize their ad campaigns to deliver high returns on investment, peddling a plethora of advertising strategies. Yet, very little is publicly known about the effectiveness of online search advertising, especially when trying to compare the various campaign strategies used by advertisers. This paper presents the first large-scale measurement of the effectiveness - measured in terms of incremental conversion gains - of online search ads. We develop a simple metric called net acquisition benefit (NAB) that admits comparisons between the efficacy of different ad campaign strategies without access to advertisers' private financial information. We study three common campaign strategies used by advertisers on a large search ad network: cannibalization, poaching, and ad extensions. Considering data from a month in the last two years, we employ NAB to identify cases where these campaign strategies are justified. Advertisers and ad agencies can replicate our methodology to apply it to other strategies of interest. © 2015 ACM.",Advertising effectiveness; Sponsored search,Internet; Online searching; Search engines; Advertising effectiveness; Advertising strategy; Empirical analysis; Financial information; Large-scale measurement; Returns on investment; Search engine marketings; Sponsored searches; Marketing
"Liu D., Zhao Y., Xu H., Sun Y., Pei D., Luo J., Jing X., Feng M.",8,Opprentice: Towards practical and automatic anomaly detection through machine learning,2015,18,"Tsinghua University, China; Baidu, China; Petro China, China",Tsinghua University,1,China,1,44,38,"Closely monitoring service performance and detecting anomalies are critical for Internet-based services. However, even though dozens of anomaly detectors have been proposed over the years, deploying them to a given service remains a great challenge, requiring manually and iteratively tuning detector parameters and thresholds. This paper tackles this challenge through a novel approach based on supervised machine learning. With our proposed system, Opprentice (Operators' apprentice), operators' only manual work is to periodically label the anomalies in the performance data with a convenient tool. Multiple existing detectors are applied to the performance data in parallel to extract anomaly features. Then the features and the labels are used to train a random forest classifier to automatically select the appropriate detector-parameter combinations and the thresholds. For three different service KPIs in a top global search engine, Opprentice can automatically satisfy or approximate a reasonable accuracy preference (recall ³ 0.66 and precision ³ 0.66). More importantly, Opprentice allows operators to label data in only tens of minutes, while operators traditionally have to spend more than ten days selecting and tuning detectors, which may still turn out not to work in the end. © 2015 ACM.",Anomaly detection; Machine learning; Tuning detectors,Artificial intelligence; Decision trees; Internet; Learning systems; Search engines; Signal detection; Supervised learning; Anomaly detection; Detector parameters; Global search engine; Internet-based services; Monitoring services; Random forest classifier; Reasonable accuracy; Supervised machine learning; Feature extraction
"Bischof Z.S., Rula J.P., Bustamante F.E.",3,In and out of Cuba: Characterizing Cuba's connectivity,2015,8,"Northwestern University, United States",Northwestern University,1,USA,1,51,32,"The goal of our work is to characterize the current state of Cuba's access to the wider Internet. This work is motivated by recent improvements in connectivity to the island and the growing commercial interest following the ease of restrictions on travel and trade with the US. In this paper, we profile Cuba's networks, their connections to the rest of the world, and the routes of international traffic going to and from the island. Despite the addition of the ALBA-1 submarine cable, we find that round trip times to websites hosted off the island remain very high; pings to popular websites frequently took over 300 ms. We also find a high degree of path asymmetry in traffic to/from Cuba. Specifically, in our analysis we find that traffic going out of Cuba typically travels through the ALBA-1 cable, but, surprisingly, traffic on the reverse path often traverses high-latency satellite links, adding over 200 ms to round trip times. Last, we analyze queries to public DNS servers and SSL certificate requests to characterize the availability of network services in Cuba.",Developing countries; Measurement; Performance; Satellite,Cables; Developing countries; Internet; Measurements; Satellites; Websites; DNS server; International traffic; Network services; Performance; Reverse path; Round trip time; SSL certificates; Satellite links
"Wu W., He K., Akella A.",3,PerfSight: Performance diagnosis for software dataplanes,2015,9,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,21,17,"The advent of network functions virtualization (NFV) means that data planes are no longer simply composed of routers and switches. Instead they are very complex and involve a variety of sophisticated packet processing elements that reside on the OSes and software running on compute servers where network functions (NFs) are hosted. In this paper, we argue that these new ""software data planes"" are susceptible to at least three new classes of performance problems. To diagnose such problems, we design, implement and evaluate, PerfSight, a ground-up system that works by extracting comprehensive low-level information regarding packet processing and I/O performance of the various elements in the software data plane. PerfSight then analyzes the information gathered in various dimensions (e.g., across all VMs on a machine, or all VMs deployed by a tenant). By looking across aggregates, we show that it becomes possible to detect and diagnose key performance problems. Experimental results show that our framework can result in accurate detection of the root causes of key performance problems in software data planes, and it imposes very little overhead.",Data center networks; Diagnosis; Performance; Software data plane,Complex networks; Diagnosis; Internet; Transfer functions; Data center networks; Network functions; Packet processing; Performance; Performance diagnosis; Performance problems; Software data; Virtualizations; Packet networks
"Anwar R., Niaz H., Choffnes D., Cunha ê., Gill P., Katz-Bassett E.",6,Investigating interdomain routing policies in the wild,2015,12,"Stony Brook University, United States; Northeastern University, United States; Universidade Federal de Minas Gerais, Brazil; University of Southern California, United States",Northeastern University;Stony Brook University;Universidade Federal de Minas Gerais;University of Southern California,4,Brazil;USA,2,37,20,"Models of Internet routing are critical for studies of Internet security, reliability and evolution, which often rely on simulations of the Internet's routing system. Accurate models are difficult to build and suffer from a dearth of ground truth data, as ISPs often treat their connectivity and routing policies as trade secrets. In this environment, researchers rely on a number of simplifying assumptions and models proposed over a decade ago, which are widely criticized for their inability to capture routing policies employed in practice. In this study we put Internet topologies and models under the microscope to understand where they fail to capture real routing behavior. We measure data plane paths from thousands of vantage points, located in eyeball networks around the globe, and find that between 14-35% of routing decisions are not explained by existing models. We then investigate these cases, and identify root causes such as selective prefix announcement, misclassification of undersea cables, and geographic constraints. Our work highlights the need for models that address such cases, and motivates the need for further investigation of evolving Internet connectivity.",BGP; Network measurement; Routing,Internet; Internet service providers; BGP; Interdomain Routing; Internet connectivity; Internet topologies; Misclassifications; Network measurement; Routing; Simplifying assumptions; Network routing
"Gracia-Tinedo R., Tian Y., SampŽ J., Harkous H., Lenton J., Garc’a-L—pez P., S‡nchez-Artigas M., Vukolic M.",8,Dissecting UbuntuOne: Autopsy of a global-scale personal cloud back-end,2015,21,"Universitat Rovira i Virgili, Italy; Eurecom, Italy; EPFL, Italy; Canonical Ltd., Italy; IBM Research, Zurich, Switzerland",EURECOM;IBM;Universitat Rovira i Virgili,3,Italy;Switzerland,2,41,30,"Personal Cloud services, such as Dropbox or Box, have been widely adopted by users. Unfortunately, very little is known about the internal operation and general characteristics of Personal Clouds since they are proprietary services. In this paper, we focus on understanding the nature of Personal Clouds by presenting the internal structure and a measurement study of UbuntuOne (U1). We first detail the U1 architecture, core components involved in the U1 metadata service hosted in the datacenter of Canonical, as well as the interactions of U1 with Amazon S3 to outsource data storage. To our knowledge, this is the first research work to describe the internals of a large-scale Personal Cloud. Second, by means of tracing the U1 servers, we provide an extensive analysis of its back-end activity for one month. Our analysis includes the study of the storage workload, the user behavior and the performance of the U1 metadata store. Moreover, based on our analysis, we suggest improvements to U1 that can also benefit similar Personal Cloud systems. Finally, we contribute our dataset to the community, which is the first to contain the back-end activity of a large-scale Personal Cloud. We believe that our dataset provides unique opportunities for extending research in the field.",Measurement; Performance analysis; Personal cloud,Digital storage; Internet; Measurements; Metadata; Core components; Internal operations; Internal structure; Measurement study; Metadata services; Performance analysis; Personal clouds; User behaviors; Behavioral research
"Cangialosi F., Levin D., Spring N.",3,Ting: Measuring and exploiting latencies between all tor nodes,2015,6,"University of Maryland, United States",University of Maryland College Park,1,USA,1,31,24,"Tor is a peer-to-peer overlay routing network that achieves unlinkable communication between source and destination. Unlike traditional mix-nets, Tor seeks to balance anonymity and performance, particularly with respect to providing low-latency communication. As a result, understanding the latencies between peers in the Tor network could be an extremely powerful tool in understanding and improving Tor's performance and anonymity properties. Unfortunately, there are no practical techniques for inferring accurate latencies between two arbitrary hosts on the Internet, and Tor clients are not instrumented to collect and report on these measurements. In this paper, we present Ting, a technique for measuring latencies between arbitrary Tor nodes from a single vantage point. Through a ground-truth validation, we show that Ting is accurate, even with few samples, and does not require modifications to existing clients. We also apply Ting to the live Tor network, and show that its measurements are stable over time. We demonstrate that the all-pairs latency datasets that Ting permits can be applied in disparate ways, including faster methods of deanonymizing Tor circuits and efficiently finding long circuits with low end-to-end latency.",Deanonymization; Latency measurement; Tor,Internet; Anonymity property; Deanonymization; End to end latencies; Latency measurements; Low-latency communication; Measuring latency; Peer-to-peer overlays; Tor; Peer to peer networks
"Ensafi R., Fifield D., Winter P., Feamster N., Weaver N., Paxson V.",6,Examining how the great firewall discovers hidden circumvention servers,2015,15,"Princeton University, United States; UC Berkeley, United States; Karlstad, Sweden; ICSI, United States",Princeton University;University of California Berkeley,2,Sweden;USA,2,33,18,"Recently, the operators of the national censorship infrastructure of China began to employ ""active probing"" to detect and block the use of privacy tools. This probing works by passively monitoring the network for suspicious traffic, then actively probing the corresponding servers, and blocking any that are determined to run circumvention servers such as Tor. We draw upon multiple forms of measurements, some spanning years, to illuminate the nature of this probing. We identify the different types of probing, develop fingerprinting techniques to infer the physical structure of the system, localize the sensors that trigger probing - showing that they differ from the ""Great Firewall"" infrastructure - and assess probing's efficacy in blocking different versions of Tor. We conclude with a discussion of the implications for designing circumvention servers that resist such probing mechanisms.",Active probing; Censorship circumvention; Deep packet inspection; Great firewall of China; Tor,Internet; Active probing; Censorship circumvention; Deep packet inspection; Great firewall of China; Tor; Security of data
"Liu Y., Tome W., Zhang L., Choffnes D., Levin D., Maggs B., Mislove A., Schulman A., Wilson C.",9,An end-to-end measurement of certificate revocation in the Web's PKI,2015,31,"Northeastern University, United States; University of Maryland, United States; Duke University and Akamai Technologies, United States; Stanford University, United States",Duke University;Northeastern University;Stanford University;University of Maryland College Park,4,USA,1,35,29,"Critical to the security of any public key infrastructure (PKI) is the ability to revoke previously issued certificates. While the overall SSL ecosystem is well-studied, the frequency with which certificates are revoked and the circumstances under which clients (e.g., browsers) check whether certificates are revoked are still not well-understood. In this paper, we take a close look at certificate revocations in the Web's PKI. Using 74 full IPv4 HTTPS scans, we find that a surprisingly large fraction (8%) of the certificates served have been revoked, and that obtaining certificate revocation information can often be expensive in terms of latency and bandwidth for clients. We then study the revocation checking behavior of 30 different combinations of web browsers and operating systems; we find that browsers often do not bother to check whether certificates are revoked (including mobile browsers, which uniformly never check). We also examine the CRLSet infrastructure built into Google Chrome for disseminating revocations; we find that CRLSet only covers 0.35% of all revocations. Overall, our results paint a bleak picture of the ability to effectively revoke certificates today.",Certificates; CRLSet; Extended validation; HTTPS; PKI; Revocation; SSL; TLS; Web browsers; X.509,HTTP; Internet; Public key cryptography; Thallium; World Wide Web; Certificates; CRLSet; Extended validation; HTTPS; PKI; Revocation; SSL; X.509; Web browsers
"Halvorson T., Der M.F., Foster I., Savage S., Saul L.K., Voelker G.M.",6,From.academy to.zone: An analysis of the new TLD land rush,2015,6,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,52,38,"The com, net, and org TLDs contain roughly 150 million registered domains, and domain registrants often have a difficult time finding a desirable and available name. In 2013, ICANN began delegation of a new wave of TLDs into the Domain Name System with the goal of improving meaningful name choice for registrants. The new rollout resulted in over 500 new TLDs in the first 18 months, nearly tripling the number of TLDs. Previous rollouts of small numbers of new TLDs have resulted in a burst of defensive registrations as companies aggressively defend their trademarks to avoid consumer confusion. This paper analyzes the types of domain registrations in the new TLDs to determine registrant behavior in the brave new world of naming abundance. We also examine the cost structures and monetization models for the new TLDs to identify which registries are profitable. We gather DNS, Web, and WHOIS data for each new domain, and combine this with cost structure data from ICANN, the registries, and domain registrars to estimate the total cost of the new TLD program. We find that only 15% of domains in the new TLDs show characteristics consistent with primary registrations, while the rest are promotional, speculative, or defensive in nature; indeed, 16% of domains with NS records do not even resolve yet, and 32% are parked. Our financial analysis suggests only half of the registries have earned enough to cover their application fees, and 10% of current registries likely never will solely from registration revenue. © 2015 ACM.",Domain Name System; Internet economics; Registration intent; Top-level domains,Costs; Economics; Internet; Internet protocols; Servers; Cost structure; Domain name system; Domain registrations; Financial analysis; Internet economics; Monetization models; Registration intent; Top level domains; Cost benefit analysis
"Wang H., Xu F., Li Y., Zhang P., Jin D.",5,Understanding mobile traffic patterns of large scale cellular towers in urban environment,2015,42,"Tsinghua National Laboratory for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; University of Massachusetts, Amherst, United States",Tsinghua University;University of Massachusetts Amherst,2,China;USA,2,30,13,"Understanding mobile traffic patterns of large scale cellular towers in urban environment is extremely valuable for Internet service providers, mobile users, and government managers of modern metropolis. This paper aims at extracting and modeling the traffic patterns of large scale towers deployed in a metropolitan city. To achieve this goal, we need to address several challenges, including lack of appropriate tools for processing large scale traffic measurement data, unknown traffic patterns, as well as handling complicated factors of urban ecology and human behaviors that affect traffic patterns. Our core contribution is a powerful model which combines three dimensional information (time, locations of towers, and traffic frequency spectrum) to extract and model the traffic patterns of thousands of cellular towers. Our empirical analysis reveals the following important observations. First, only five basic time-domain traffic patterns exist among the 9,600 cellular towers. Second, each of the extracted traffic pattern maps to one type of geographical locations related to urban ecology, including residential area, business district, transport, entertainment, and comprehensive area. Third, our frequency-domain traffic spectrum analysis suggests that the traffic of any tower among the 9,600 can be constructed using a linear combination of four primary components corresponding to human activity behaviors. We believe that the proposed traffic patterns extraction and modeling methodology, combined with the empirical analysis on the mobile traffic, pave the way toward a deep understanding of the traffic patterns of large scale cellular towers in modern metropolis.",Geographical location; Measurement study; Mobile data traffic; Traffic patterns,Behavioral research; Ecology; Frequency domain analysis; Internet; Internet service providers; Location; Spectrum analysis; Time domain analysis; Towers; Urban planning; Geographical locations; Measurement study; Metropolitan cities; Mobile data traffic; Modeling methodology; Three-dimensional information; Traffic measurements; Traffic pattern; Urban transportation
"Pujol E., Hohlfeld O., Feldmann A.",3,Annoyed users: Ads and ad-block usage in the wild,2015,21,"TU Berlin, Germany; RWTH Aachen, Germany",TU Berlin,1,Germany,1,28,27,"Content and services which are offered for free on the Internet are primarily monetized through online advertisement. This business model relies on the implicit agreement between content providers and users where viewing ads is the price for the ""free"" content. This status quo is not acceptable to all users, however, as manifested by the rise of ad-blocking plugins which are available for all popular Web browsers. Indeed, ad-blockers have the potential to substantially disrupt the widely established business model of ""free"" content - currently one of the core elements on which the Web is built. In this work, we shed light on how users interact with ads. We show how to leverage the functionality of AdBlock Plus, one of the most popular ad-blockers to identify ad traffic from passive network measurements. We complement previous work, which focuses on active measurements, by characterizing ad-traffic in the wild, i.e., as seen in a residential broadband network of a major European ISP. Finally, we assess the prevalence of ad-blockers in this particular network and discuss possible implications for content providers and ISPs.",AdBlock plus; Advertising; Residential broadband traffic; Web,Housing; Internet; Internet service providers; Marketing; Active measurement; AdBlock plus; Broadband traffic; Business modeling; Content providers; Online advertisements; Passive network measurement; Web; Web browsers
"Kliman-Silver C., Hannak A., Lazer D., Wilson C., Mislove A.",5,"Location, location, location: The impact of geolocation on web search personalization",2015,14,"Brown University, United States; Northeastern University, United States",Brown University;Northeastern University,2,USA,1,59,41,"To cope with the immense amount of content on the web, search engines often use complex algorithms to personalize search results for individual users. However, personalization of search results has led to worries about the Filter Bubble Effect, where the personalization algorithm decides that some useful information is irrelevant to the user, and thus prevents them from locating it. In this paper, we propose a novel methodology to explore the impact of location-based personalization on Google Search results. Assessing the relationship between location and personalization is crucial, since users' geolocation can be used as a proxy for other demographic traits, like race, income, educational attainment, and political affiliation. In other words, does location-based personalization trap users in geolocal Filter Bubbles? Using our methodology, we collected 30 days of search results from Google Search in response to 240 different queries. By comparing search results gathered from 59 GPS coordinates around the US at three different granularities (county, state, and national), we are able to observe that differences in search results due to personalization grow as physical distance increases. However these differences are highly dependent on what a user searches for: queries for local establishments receive 4-5 different results per page, while more general terms exhibit essentially no personalization.",Geolocation; Internet Filter Bubble; Personalization; Search,Algorithms; Internet; Location; Search engines; Tracking (position); Complex algorithms; Different granularities; Educational attainments; Geolocations; Location-based personalization; Novel methodology; Personalizations; Search; World Wide Web
"Kakhki A.M., Razaghpanah A., Li A., Koo H., Golani R., Choffnes D., Gill P., Mislove A.",8,Identifying traffic differentiation in mobile networks,2015,19,"Northeastern University, United States; Stony Brook University, United States",Northeastern University;Stony Brook University,2,USA,1,26,20,"Traffic differentiation - giving better (or worse) performance to certain classes of Internet traffic - is a well-known but poorly understood traffic management policy. There is active discussion on whether and how ISPs should be allowed to differentiate Internet traffic [8, 21], but little data about current practices to inform this discussion. Previous work attempted to address this problem for fixed line networks; however, there is currently no solution that works in the more challenging mobile environment. In this paper, we present the design, implementation, and evaluation of the first system and mobile app for identifying traffic differentiation for arbitrary applications in the mobile environment (i.e., wireless networks such as cellular and WiFi, used by smartphones and tablets). The key idea is to use a VPN proxy to record and replay the network traffic generated by arbitrary applications, and compare it with the network behavior when replaying this traffic outside of an encrypted tunnel. We perform the first known testbed experiments with actual commercial shaping devices to validate our system design and demonstrate how it outperforms previous work for detecting differentiation. We released our app and collected differentiation results from 12 ISPs in 5 countries. We find that differentiation tends to affect TCP traffic (reducing rates by up to 60%) and that interference from middleboxes (including video-transcoding devices) is pervasive. By exposing such behavior, we hope to improve transparency for users and help inform future policies. © 2015 ACM.",Mobile networks; Network neutrality; Traffic differentiation,Internet; Internet service providers; Mobile telecommunication systems; Transmission control protocol; Wireless networks; Current practices; Encrypted tunnels; Fixed line networks; Mobile environments; Network neutralities; Record-and-replay; Traffic management; Video-transcoding; Wi-Fi
"Luckie M., Beverly R., Wu T., Allman M., Claffy K.",5,Resilience of deployed TCP to blind attacks,2015,4,"University of Waikato, New Zealand; Naval Postgraduate School, New Zealand; CAIDA, UC San Diego, United States; ICSI, United States",Naval Postgraduate School;University of California San Diego;University of Waikato,3,New Zealand;USA,2,37,30,"As part of TCP's steady evolution, recent standards have recommended mechanisms to protect against weaknesses in TCP. But adoption, configuration, and deployment of TCP improvements can be slow. In this work, we consider the resilience of deployed TCP implementations to blind in-window attacks, where an off-path adversary disrupts an established connection by sending a packet that the victim believes came from its peer, causing data corruption or connection reset. We tested operating systems (and middleboxes deployed in front) of webservers in the wild in September 2015 and found 22% of connections vulnerable to in-window SYN and reset packets, 30% vulnerable to in-window data packets, and 38.4% vulnerable to at least one of three in-window attacks we tested. We also tested out-of-window packets and found that while few deployed systems were vulnerable to reset and SYN packets, 5.4% of connections accepted in-window data with an invalid acknowledgment number. In addition to evaluating commodity TCP stacks, we found vulnerabilities in 12 of 14 of the routers and switches we characterized - critical network infrastructure where the potential impact of any TCP vulnerabilities is particularly acute. This surprisingly high level of extant vulnerabilities in the most mature Internet transport protocol in use today is a perfect illustration of the Internet's fragility. Embedded in historical context, it also provides a strong case for more systematic, scientific, and longitudinal measurement and quantitative analysis of fundamental properties of critical Internet infrastructure, as well as for the importance of better mechanisms to get best security practices deployed. © 2015 ACM.",Blind attacks; Middleboxes; Security; TCP,Critical infrastructures; Internet; Internet protocols; Blind attacks; Fundamental properties; Internet infrastructure; Internet transport protocols; Middleboxes; Security; TCP; TCP vulnerabilities; Transmission control protocol
"Sapiezynski P., Gatej R., Mislove A., Lehmann S.",4,Opportunities and challenges in crowdsourced wardriving,2015,7,"Technical University of Denmark, Denmark; University of Copenhagen, Denmark; Northeastern University, United States",Northeastern University;TU Denmark;University of Copenhagen,3,Denmark;USA,2,40,21,"Knowing the physical location of a mobile device is crucial for a number of context-aware applications. This information is usually obtained using the Global Positioning System (GPS), or by calculating the position based on proximity of WiFi access points with known location (where the position of the access points is stored in a database at a central server). To date, most of the research regarding the creation of such a database has investigated datasets collected both artificially and over short periods of time (e.g., during a one-day drive around a city). In contrast, most in-use databases are collected by mobile devices automatically, and are maintained by large mobile OS providers. As a result, the research community has a poor understanding of the challenges in creating and using large-scale WiFi localization databases. We address this situation using the deployment of over 800 mobile devices to real users over a 1.5 year period. Each device periodically records WiFi scans and its GPS coordinates, reporting the collected data to us. We identify a number of challenges in using such data to build a WiFi localization database (e.g., mobility of access points), and introduce techniques to mitigate them. We also explore the level of coverage needed to accurately estimate a user's location, showing that only a small subset of the database is needed to achieve high accuracy.",Location; Mobility; Wardriving; Wifi,Carrier mobility; Database systems; Digital storage; Global positioning system; Internet; Location; Wi-Fi; Central servers; Context aware applications; GPS Coordinates; Physical locations; Research communities; Wardriving; Wi-fi access points; Wi-Fi localizations; Mobile devices
"Calder M., Flavel A., Katz-Bassett E., Mahajan R., Padhye J.",5,Analyzing the performance of an anycast CDN,2015,34,"Microsoft, United States; University of Southern California, United States",Microsoft;University of Southern California,2,USA,1,28,15,"Content delivery networks must balance a number of trade-offs when deciding how to direct a client to a CDN server. Whereas DNS-based redirection requires a complex global traffic manager, anycast depends on BGP to direct a client to a CDN front-end. Anycast is simple to operate, scalable, and naturally resilient to DDoS attacks. This simplicity, however, comes at the cost of precise control of client redirection. We examine the performance implications of using anycast in a global, latency-sensitive, CDN. We analyze millions of client-side measurements from the Bing search service to capture anycast versus unicast performance to nearby front-ends. We find that anycast usually performs well despite the lack of precise control but that it directs roughly 20% of clients to a suboptimal front-end. We also show that the performance of these clients can be improved through a simple history-based prediction scheme.",Anycast; CDN; Measurement,Complex networks; Denial-of-service attack; Internet; Internet protocols; Measurements; Anycast; CDN; Content delivery network; Number of trades; Precise control; Prediction schemes; Search services; Traffic managers; Economic and social effects
"Rosen S., Nikravesh A., Guo Y., Mao Z.M., Qian F., Sen S.",6,Revisiting network energy efficiency of mobile apps: Performance in the wild,2015,13,"University of Michigan, United States; Indiana University, United States; AT and T Labs - Research, United States",AT and T Labs;Indiana University;University of Michigan at Ann Arbor,3,India;USA,2,39,2,"Energy consumption due to network traffic on mobile devices continues to be a significant concern. We examine a range of excessive energy consumption problems caused by background network traffic through a two-year user study, and also validate these findings through in-lab testing of the most recent versions of major mobile apps. We discover a new energy consumption problem where foreground network traffic persists after switching from the foreground to the background, leading to unnecessary energy and data drain. Furthermore, while we find some apps have taken steps to improve the energy impact of periodic background traffic, energy consumption differences of up to an order of magnitude exist between apps with near-identical functionality. Finally, by examining how apps are used in the wild, we find that some apps continue to generate unneeded traffic for days when the app is not being used, and in some cases this wasted traffic is responsible for a majority of the app's network energy overhead. We propose that these persistent, widespread and varied sources of excessive energy consumption in popular apps should be addressed through new app management tools that tailor network activity to user interaction patterns. © 2015 ACM.",4G LTE; Cellular network performance; Mobile energy consumption; Smartphones,Energy efficiency; Energy utilization; Internet; Mobile devices; Mobile telecommunication systems; Smartphones; 4G LTE; Background traffic; Energy overheads; Excessive energy; Identical functionalities; Management tool; Network activities; User interaction; Wireless telecommunication systems
"Emmerich P., GallenmŸller S., Raumer D., Wohlfart F., Carle G.",5,MoonGen: A scriptable high-speed packet generator,2015,61,"Technische UniversitŠt MŸnchen, Department of Computer Science, Network Architectures and Services, Germany",TU Munich,1,Germany,1,27,21,"We present MoonGen, a flexible high-speed packet generator. It can saturate 10GbE links with minimum-sized packets while using only a single CPU core by running on top of the packet processing framework DPDK. Linear multicore scaling allows for even higher rates: We have tested MoonGen with up to 178.5 Mpps at 120Gbit/s. Moving the whole packet generation logic into user-controlled Lua scripts allows us to achieve the highest possible flexibility. In addition, we utilize hardware features of commodity NICs that have not been used for packet generators previously. A key feature is the measurement of latency with sub-microsecond precision and accuracy by using hardware timestamping capabilities of modern commodity NICs. We address timing issues with software-based packet generators and apply methods to mitigate them with both hardware support and with a novel method to control the inter-packet gap in software. Features that were previously only possible with hardware-based solutions are now provided by MoonGen on commodity hardware. MoonGen is available as free software under the MIT license in our git repository at https://github.com/emmericp/MoonGen. © 2015 ACM.",DPDK; Lua; Packet generation; User space networking,Hardware; HTTP; Internet; Packet networks; Commodity hardware; DPDK; Hardware features; Hardware supports; Lua; Packet generations; Packet processing; User spaces; Reconfigurable hardware
"KŸhrer M., Hupperich T., Bushart J., Rossow C., Holz T.",5,Going wild: Large-scale classification of open DNS resolvers,2015,18,"Ruhr-University Bochum, Germany; Saarland University, Germany",Ruhr-University Bochum;Saarland University,2,Germany,1,28,22,"Since several years, millions of recursive DNS resolvers are - deliberately or not - open to the public. This, however, is counter-intuitive, since the operation of such openly accessible DNS resolvers is necessary in rare cases only. Furthermore, open resolvers enable both amplification DDoS and cache snooping attacks, and can be abused by attackers in multiple other ways. We thus find open recursive DNS resolvers to remain one critical phenomenon on the Internet. In this paper, we illuminate this phenomenon by analyzing it from two different angles. On the one hand, we study the landscape of DNS resolvers based on empirical data we collected for over a year. We analyze the changes over time and classify the resolvers according to device type and software version. On the other hand, we take the viewpoint of a client and measure the response authenticity of these resolvers. Besides legitimate redirections (e.g., to captive portals or router login pages), we find millions of resolvers to deliberately manipulate DNS resolutions (i.e., return bogus IP address information). To understand this threat in more detail, we systematically analyze non-legitimate DNS responses and reveal open DNS resolvers that manipulate DNS resolutions to censor communication channels, inject advertisements, serve malicious files, perform phishing, or redirect to other kinds of suspicious or malicious activities.",Agglomerative hierarchical clustering; Content delivery network; DNS resolution paths; Domain name system,Internet; Agglomerative hierarchical clustering; Content delivery network; Critical phenomenon; DNS resolution paths; Domain name system; Large scale classifications; Malicious activities; Software versions; Internet protocols
"Li H., Lu X., Liu X., Xie T., Bian K., Lin F.X., Mei Q., Feng F.",8,Characterizing smartphone usage patterns from millions of android users,2015,26,"Peking University, China; University of Illinois, Urbana-Champaign, United States; Purdue University, United States; University of Michigan, United States; Wandoujia Lab., China",Peking University;Purdue University;UIUC;University of Michigan at Ann Arbor,4,China;USA,2,43,34,"The prevalence of smart devices has promoted the popularity of mobile applications (a.k.a. apps) in recent years. A number of interesting and important questions remain unanswered, such as why a user likes/dislikes an app, how an app becomes popular or eventually perishes, how a user selects apps to install and interacts with them, how frequently an app is used and how much traffic it generates, etc. This paper presents an empirical analysis of app usage behaviors collected from millions of users of Wandoujia, a leading Android app marketplace in China. The dataset covers two types of user behaviors of using over 0.2 million Android apps, including (1) app management activities (i.e., installation, updating, and uninstallation) of over 0.8 million unique users and (2) app network traffic from over 2 million unique users. We explore multiple aspects of such behavior data and present interesting patterns of app usage. The results provide many useful implications to the developers, users, and disseminators of mobile apps. © 2015 ACM.",Android apps; App management; App performance; App popularity; App stores,Behavioral research; Internet; Android apps; App stores; Empirical analysis; Management activities; Mobile applications; Network traffic; Usage patterns; User behaviors; Android (operating system)
"Chachra N., Savage S., Voelker G.M.",3,Affiliate crookies: Characterizing affiliate marketing abuse,2015,4,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,25,24,"Modern affiliate marketing networks provide an infrastructure for connecting merchants seeking customers with independent marketers (affiliates) seeking compensation. This approach depends on Web cookies to identify, at checkout time, which affiliate should receive a commission. Thus, scammers ""stuff"" their own cookies into a user's browser to divert this revenue. This paper provides a measurement-based characterization of cookie-stuffing fraud in online affiliate marketing. We use a custom-built Chrome extension, AffTracker, to identify affiliate cookies and use it to gather data from hundreds of thousands of crawled domains which we expect to be targeted by fraudulent affiliates. Overall, despite some notable historical precedents, we found cookie-stuffing fraud to be relatively scarce in our data set. Based on what fraud we detected, though, we identify which categories of merchants are most targeted and which third-party affiliate networks are most implicated in stuffing scams. We find that large affiliate networks are targeted significantly more than merchant-run affiliate programs. However, scammers use a wider range of evasive techniques to target merchant-run affiliate programs to mitigate the risk of detection suggesting that in-house affiliate programs enjoy stricter policing. © 2015 ACM.",Affiliate marketing; Measurement; Online advertising; Security,Commerce; Crime; Internet; Measurements; Chrome extensions; Data set; Measurement-based; Online advertising; Security; Third parties; Web cookies; Marketing
"Chen L., Mislove A., Wilson C.",3,Peeking beneath the hood of uber,2015,40,"Northeastern University, Boston, MA, United States",Northeastern University,1,USA,1,18,9,"Recently, Uber has emerged as a leader in the ""sharing economy"". Uber is a ""ride sharing"" service that matches willing drivers with customers looking for rides. However, unlike other open marketplaces (e.g., AirBnB), Uber is a black-box: they do not provide data about supply or demand, and prices are set dynamically by an opaque ""surge pricing"" algorithm. The lack of transparency has led to concerns about whether Uber artificially manipulate prices, and whether dynamic prices are fair to customers and drivers. In order to understand the impact of surge pricing on passengers and drivers, we present the first in-depth investigation of Uber. We gathered four weeks of data from Uber by emulating 43 copies of the Uber smartphone app and distributing them throughout downtown San Francisco (SF) and midtown Manhattan. Using our dataset, we are able to characterize the dynamics of Uber in SF and Manhattan, as well as identify key implementation details of Uber's surge price algorithm. Our observations about Uber's surge price algorithm raise important questions about the fairness and transparency of this system.",Algorithm auditing; Sharing economy; Surge pricing; Uber,Algorithms; Economics; Internet; Transparency; Black boxes; Dynamic price; Manhattans; Ride-sharing; San Francisco; Sharing economy; Uber; Costs
"McQuistin S., Perkins C.",2,Is explicit congestion notification usable with UDP?,2015,5,"School of Computing Science, University of Glasgow, United Kingdom",University of Glasgow,1,UK,1,32,32,"We present initial measurements to determine if ECN is usable with UDP traffic in the public Internet. This is interesting because ECN is part of current IETF proposals for congestion control of UDP-based interactive multimedia, and due to the increasing use of UDP as a substrate on which new transport protocols can be deployed. Using measurements from the author's homes, their workplace, and cloud servers in each of the nine EC2 regions worldwide, we test reachability of 2500 servers from the public NTP server pool, using ECT(0) and not-ECT marked UDP packets. We show that an average of 98.97% of the NTP servers that are reachable using not-ECT marked packets are also reachable using ECT(0) marked UDP packets, and that _98% of network hops pass ECT(0) marked packets without clearing the ECT bits. We compare reachability of the same hosts using ECN with TCP, finding that 82.0% of those reachable with TCP can successfully negotiate and use ECN. Our findings suggest that ECN is broadly usable with UDP traffic, and that support for use of ECN with TCP has increased.",Explicit congestion notification; Network measurement; UDP,Interactive computer systems; Internet; Multimedia systems; Cloud servers; Explicit congestion notification; Interactive multimedia; Network hops; Network measurement; Public internet; Transport protocols; UDP; Transmission control protocol
"Vanaubel Y., MŽrindol P., Pansiot J.-J., Donnet B.",4,MPLS under the microscope: Revealing actual transit path diversity,2015,6,"UniversitŽ de Lige, Belgium; UniversitŽ de Strasbourg, France",UniversitŽ de Lige;UniversitŽ de Strasbourg,2,Belgium;France,2,17,13,"Traffic Engineering (TE) is one of the keys for improving packet forwarding in the Internet. It allows IP network operators to finely tune their forwarding paths according to various customer needs. One of the most popular tool available today for optimizing the use of networking resources is MPLS. On the one hand, operators may use MPLS and label distribution mechanisms such as RSVP-TE in conjunction with BGP to define multiple transit paths (for a given edge pair) verifying different constraints on their network. On the other hand, when operators simply enable LDP for distributing MPLS labels in order to improve the scalability of their network, another kind of path diversity may appear thanks to the ECMP feature of IGP routing. In this paper, using an MPLS labels analysis, we demonstrate that it is possible to better understand the transit path diversity deployed within a given ISP. More specifically, we introduce the Label Pattern Recognition (LPR) algorithm, a method for analyzing traceroute data including MPLS information. LPR reveals the actual usage of MPLS according to the inferred label distribution protocol and is able to make the distinction between ECMP and TE multi-path forwarding. Based on an extensive and longitudinal traceroute dataset obtained from CAIDA, we apply LPR and find that each ISP behavior is really specific in regard to its MPLS usage. In particular, we are able to observe independently for each ISP the MPLS path diversity and usage, and its evolution over time. Globally speaking, the main outcomes of our study are that (i) the usage of MPLS has been increasing over the the last five years with basic encapsulation being predominant, (ii) path diversity is mainly provided thanks to ECMP and LDP, and, (iii), TE using MPLS is as common as MPLS without path diversity. © 2015 ACM.",ECMP; LDP; MPLS; Multipath; Network discovery; RSVP-TE; Traceroute; Traffic engineering,Internet; Pattern recognition; Telecommunication networks; ECMP; LDP; MPLS; Multipath; Network discovery; RSVP-TE; Traceroute; Traffic Engineering; Internet service providers
"Benson K., Dainotti A., Claffy K., Snoeren A.C., Kallitsis M.",5,Leveraging internet background radiation for opportunistic network analysis,2015,3,"Computer Science and Engineering, UC San Diego, United States; CAIDA, UC San Diego, United States; Merit Network, Inc., United States",Merit Network Inc.;University of California San Diego,2,USA,1,32,20,"For more than a decade, unsolicited traffic sent to unused regions of the address space has provided valuable insight into malicious Internet activities. In this paper, we explore the utility of this traffic, known as Internet Background Radiation (IBR), for a different purpose: as a data source of Internet-wide measurements. We collect and analyze IBR from two large darknets, carefully deconstructing its various components and characterizing them along dimensions applicable to Internet-wide measurements. Intuitively, IBR can provide insight into network properties when traffic from that network contains relevant information and is of sufficient volume. We turn this intuition into a scientific investigation, examining which networks send IBR, identifying components of IBR that enable opportunistic network inferences, and characterizing the frequency and granularity of traffic sources. We also consider the influences of time of collection and position in the address space on our results. We leverage IBR properties in three case studies to show that IBR can supplement existing techniques by improving coverage and/or diversity of analyzable networks while reducing measurement overhead. Our main contribution is a new framework for understanding the circumstances and properties for which unsolicited traffic is an appropriate data source for inference of macroscopic Internet properties, which can help other researchers assess its utility for a given study.",Internet background radiation; Network telescope; Opportunistic network analysis,Radiation; Internet activity; Internet background radiation; Internet properties; Network properties; Network telescopes; Opportunistic networks; Scientific investigation; Wide measurement; Internet
"Padmanabhan R., Owen P., Schulman A., Spring N.",4,Timeouts: Beware surprisingly high delay,2015,3,"University of Maryland, United States; Stanford University, United States",Stanford University;University of Maryland College Park,2,USA,1,51,34,"Active probing techniques, such as ping, have been used to detect outages. When a previously responsive end host fails to respond to a probe, studies sometimes attempt to confirm the outage by retrying the ping or attempt to identify the location of the outage by using other tools such as traceroute. The latent problem, however, is, how long should one wait for a response to the ping? Too short a timeout risks confusing congestion or other delay with an outage. Too long a timeout may slow the process and prevent observing and diagnosing short-duration events, depending on the experiment's design. We believe that conventional timeouts for active probes are underestimates, and analyze data collected by Heidemann et al. in 2006-2015. We find that 5% of pings from 5% of addresses take more than 5 seconds. Put another way, for 5% of the responsive IP addresses probed by Heidemann, a false 5% loss rate would be inferred if using a timeout of 5 seconds. To arrive at this observation, we filtered artifacts of the data that could occur with too-long a timeout, including responses to probes sent to broadcast addresses. We also analyze ICMP data collected by Zmap in 2015 to find that around 5% of all responsive addresses observe a greater than one second round-trip time consistently. Further, the prevalence of high round trip time has been increasing and it is often associated with the first ping, perhaps due to negotiating a wireless connection. In addition, we find that the Autonomous Systems with the most high-latency addresses are typically cellular. This paper describes our analysis process and results that should encourage researchers to set longer timeouts when needed and report on timeout settings in the description of future measurements.",ICMP Echo; Maximum segment lifetime; Outage detection; Outages; Ping; Reachability; Timeouts,Flow control; Internet; Outages; Probes; ICMP Echo; Maximum segment lifetime; Ping; Reachability; Timeouts; Internet protocols
"Liu S., Foster I., Savage S., Voelker G.M., Saul L.K.",5,Who is .com? Learning to parse WHOIS records,2015,13,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,23,10,"WHOIS is a long-established protocol for querying information about the 280M+ registered domain names on the Internet. Unfortunately, while such records are accessible in a ""human-readable"" format, they do not follow any consistent schema and thus are challenging to analyze at scale. Existing approaches, which rely on manual crafting of parsing rules and per-registrar templates, are inherently limited in coverage and fragile to ongoing changes in data representations. In this paper, we develop a statistical model for parsing WHOIS records that learns from labeled examples. Our model is a conditional random field (CRF) with a small number of hidden states, a large number of domain-specific features, and parameters that are estimated by efficient dynamic-programming procedures for probabilistic inference. We show that this approach can achieve extremely high accuracy (well over 99%) using modest amounts of labeled training data, that it is robust to minor changes in schema, and that it can adapt to new schema variants by incorporating just a handful of additional examples. Finally, using our parser, we conduct an exhaustive survey of the registration patterns found in 102M com domains. © 2015 ACM.",Information extraction; Machine learning; Named entity recognition; WHOIS,Artificial intelligence; Information retrieval; Internet; Internet protocols; Learning algorithms; Learning systems; Natural language processing systems; Random processes; Conditional random field; Data representations; Labeled training data; Named entity recognition; Probabilistic inference; Registration pattern; Statistical modeling; WHOIS; Dynamic programming
"Walls R.J., Kilmer E.D., Lageman N., McDaniel P.D.",4,Measuring the impact and perception of acceptable advertisements,2015,6,"Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA, United States",Pennsylvania State University,1,USA,1,26,21,"In 2011, Adblock Plus - the most widely-used ad blocking software - began to permit some advertisements as part of their Acceptable Ads program. Under this program, some ad networks and content providers pay to have their advertisements shown to users. Such practices have been controversial among both users and publishers. In a step towards informing the discussion about these practices, we present the first comprehensive study of the Acceptable Ads program. Specifically, we characterize which advertisements are allowed and how the whitelisting has changed since its introduction in 2011. We show that the list of filters used to whitelist acceptable advertisements has been updated on average every 1.5 days and grew from 9 filters in 2011 to over 5,900 in the Spring of 2015. More broadly, the current whitelist triggers filters on 59% of the top 5,000 websites. Our measurements also show that the program allows advertisements on 2.6 million parked domains. Lastly, we take the lessons learned from our analysis and suggest ways to improve the transparency of the whitelisting process.",Acceptable ads; Ad avoidance; Adblock plus,Acceptable ads; Ad avoidance; Adblock plus; Content providers; Internet
"Miao R., Potharaju R., Yu M., Jain N.",4,The dark menace: Characterizing network-based attacks in the cloud,2015,10,"University of Southern California, United States; Microsoft, United States; Microsoft Research, United States",Microsoft;University of Southern California,2,USA,1,34,29,"As the cloud computing market continues to grow, the cloud platform is becoming an attractive target for attackers to disrupt services and steal data, and to compromise resources to launch attacks. In this paper, using three months of NetFlow data in 2013 from a large cloud provider, we present the first large-scale characterization of inbound attacks towards the cloud and outbound attacks from the cloud. We investigate nine types of attacks ranging from network-level attacks such as DDoS to application-level attacks such as SQL injection and spam. Our analysis covers the complexity, intensity, duration, and distribution of these attacks, highlighting the key challenges in defending against attacks in the cloud. By characterizing the diversity of cloud attacks, we aim to motivate the research community towards developing future security solutions for cloud systems. © 2015 ACM.",Attack characterization; DDoS; Network-based attacks,Complex networks; Internet; Application-level attacks; Cloud platforms; Cloud providers; DDoS; Network-based attacks; Research communities; Scale characterization; Security solutions; Computer crime
"Chiu Y.-C., Schlinker B., Radhakrishnan A.B., Katz-Bassett E., Govindan R.",5,Are we one hop away from a better internet?,2015,24,"Department of Computer Science, University of Southern California, United States",University of Southern California,1,USA,1,51,31,"The Internet suffers from well-known performance, reliability, and security problems. However, proposed improvements have seen little adoption due to the difficulties of Internet-wide deployment. We observe that, instead of trying to solve these problems in the general case, it may be possible to make substantial progress by focusing on solutions tailored to the paths between popular content providers and their clients, which carry a large share of Internet traffic. In this paper, we identify one property of these paths that may provide a foothold for deployable solutions: they are often veryshort. Our measurements show that Google connects directly to networks hosting more than 60% of end-user prefixes, and that other large content providers have similar connectivity. These direct paths open the possibility of solutions that sidestep the headache of Internet-wide deployability, and we sketch approaches one might take to improve performance and security in this setting. © 2015 ACM.",Internet topology; Measurements,Measurements; Content providers; Deployability; Direct paths; End users; Improve performance; Internet topologies; Internet traffic; Security problems; Internet
"Bae S., Kim J., Ban D., Lee K.-H., Han D., Lim S., Park W., Kim C.-K.",8,StreetSense: Effect of bus Wi-Fi APs on pedestrian smartphone,2015,5,"Seoul National University, South Korea; Samsung Electronics, South Korea",Seoul National University,1,South Korea,1,44,9,"Recently, we have received a growing number of reports that complain about poor and unstable internet connections at bus stops in metro Seoul. Careful analyses led us to conclude that Wi-Fi APs equipped on buses instigate the trouble. According to the ambitious free Wi-Fi expansion plan by the city of Seoul, public buses started to equip Wi-Fi APs. As buses with APs stop and go, they actualize intermittent connection opportunities to riders waiting at the bus stops. However, the connection durations are too short such that bus APs are a nuisance rather than a convenience. We collected the basic statistics such as AP inter-arrival and sojourn times and measured link level performance metrics. We observed the effect of frequent frame losses on the TCP congestion control and eventually on the TCP throughput. We also measured the performance of applications such as PLT (Page Load Time). The measurement results showed that passing APs are useful only for some applications in very limited situations while they are virtually useless and just irritations in many cases. We also discovered that poor Wi-Fi connections pervert MPTCP; MPTCP performs worse than the generic single path TCP over the LTE network. We expect that our results will be used as the reference data in redesigning Wi-Fi offloading mechanisms as well as in planning and deploying urban Wi-Fi networks. © 2015 ACM.",AP; Bus; LTE; MPTCP; Smartphone; WiFi,Bus terminals; Buses; Internet; Signal encoding; Smartphones; Transmission control protocol; Wireless telecommunication systems; AP; Intermittent connections; Internet connection; Link-level performance; LTE; MPTCP; TCP congestion control; Wi-Fi connections; Wi-Fi
"Elkhatib Y., Tyson G., Sathiaseelan A.",3,Does the internet deserve everybody?,2015,2,"Lancaster University, United Kingdom; Queen Mary University of London, United Kingdom; University of Cambridge, United Kingdom",Lancaster University;Queen Mary University of London;University of Cambridge,3,UK,1,26,17,"There has been a long standing tradition amongst developed nations of inuencing, both directly and indirectly, the activities of developing economies. Behind this is one of a range of aims: building/improving living standards, bettering the social status of recipient communities, etc. In some cases, this has resulted in prosperous relations, yet often this has been seen as the exploitation of a power position or a veneer for other activities (e.g. to tap into new emerging markets). In this paper, we explore whether initiatives to improve Internet connectivity in developing regions are always ethical. We draw a list of issues that would aid in formulating Internet initiatives that are ethical, effective, and sustainable. © 2015 ACM.",Developing regions; GAIA; ICT4D; Internet penetration,Internet; Developing economies; Developing regions; Emerging markets; GAIA; ICT4D; Internet connectivity; Living standards; Social status; Philosophical aspects
"Galati A., Mangold S., Prinsloo M., Behr D., Almeida L.",5,Ethical challenges in the MOSAIC 2B project,2015,0,"Disney Research, Zurich, 8006, Switzerland; Infusion Knowledged, 14A King Street, Irene, Pretoria, South Africa; EPI-USE Africa, Pretoria, 0081, South Africa; Associa‹o CCG/zgdv, Guimar‹es, 4800-058, Portugal",Disney Research,1,Portugal;South Africa;Switzerland,3,19,14,"The MOSAIC 2B project aims to unleash business opportunities for micro-entrepreneurs in rural areas of South Africa by providing them with entertainment and educational media content (mobile empowerment). For this purpose, our cinema-in-a-backpack kit was developed to receive media and screen the content at micro events. Delay Tolerant Networking (DTN) is used to distribute the content, cost effectively, from urban areas to recipients in the rural areas. The mobile cinema is the use case for DTN and the facilitator in creating micro-enterprise opportunities for local entrepreneurs. This paper presents ethical challenges and implications that have to be ad-dressed when running experiements to connect rural communities in South Africa and provide them with micro-cinema experience. © 2015 ACM.",Delay Tolerant Networks; Mobile Cinema,Philosophical aspects; Rural areas; Business opportunities; Delay Tolerant Networking; Media content; Micro-enterprises; Micro-events; Mobile Cinema; Rural community; South Africa; Delay tolerant networks
"Khan M.T., Kanich C.",2,"High fidelity, high risk, high reward: Using high-fidelity networking data in ethically sound research",2015,1,"Department of Computer Science, University of Illinois at Chicago, United States","University of Illinois, Chicago",1,USA,1,18,8,"Network tap data can provide researchers with access to every packet owing into or out of an organization. However, building a sound ethical framework around using this data is a necessary task before the community can embrace this data source. Here we describe the ethical issues, present example use cases, and suggest strategies for creating a strong ethical footing for this research while maintaining some level of utility to the researchers. © 2015 ACM.",Data Collection; Internet Measurement; Personally Identifiable Information; User Privacy,Data collection; Data-source; Ethical issues; High-fidelity; Internet measurement; Personally identifiable information; User privacy; Philosophical aspects
"Hutton L., Henderson T.",2,Some challenges for ethics in social network research,2015,1,"School of Computer Science, University of St.Andrews, St.Andrews, Fife, United Kingdom",University of St. Andrews,1,UK,1,8,2,"Social network sites (SNSes) comprise one of the most popular networked applications of late, with hundreds of millions of users. Collecting and analysing data from such systems creates myriad ethical issues and challenges for researchers both in networked systems and other fields, as highlighted by recent media sensitivity about research studies that have used data from Facebook. In our workshop contribution we discuss recent work that we have been carrying out in the area of responsible SNS research, revolving around themes of reproducibility, consent, incentives, and creating ethical workows. © 2015 ACM.",Ethics; Methodology; Reproducible research; Research ethics; Social networks sites,Social networking (online); Ethics; Methodology; Networked applications; Networked systems; Reproducibilities; Reproducible research; Research ethics; Social Network Sites; Philosophical aspects
"Kablan M., Caldwell B., Han R., Jamjoom H., Keller E.",5,Stateless network functions,2015,24,"University of Colorado, Boulder, CO, United States; IBM Watson Research Center, Yorktown Heights, NY, United States",IBM;University of Colorado Boulder,2,USA,1,20,19,"Newly virtualized network functions (like firewalls, routers, and intrusion detection systems) should be easy to consume. Despite recent efforts to improve their elasticity and high availability, network functions continue to maintain important flow state, requiring traditional development and deployment life cycles. At the same time, many cloud-scale applications are being rearchitected to be stateless by cleanly pushing application state into dedicated caches or backend stores. This state separation is enabling these applications to be more agile and support the so-called continuous deployment model. In this paper, we propose that network functions should be similarly redesigned to be stateless. Drawing insights from different classes of network functions, we describe how stateless network functions can leverage recent advances in low-latency network systems to achieve acceptable performance. Our Click-based prototype integrates with RAMCloud; using NAT as an example network function, we demonstrate that we are able to create stateless network functions that maintain the desired performance. © 2015 ACM.",InfiniBand; NAT; NFV; RDMA; Stateless architecture,Intrusion detection; Life cycle; Transfer functions; Virtual reality; Acceptable performance; Deployment models; High availability; Infiniband; Intrusion Detection Systems; Low-latency networks; Network functions; RDMA; Computer system firewalls
"Gember-Jacobson A., Akella A.",2,"Improving the safety, scalability, and efficiency of network function state transfers",2015,23,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,24,14,"Several frameworks have been proposed to orchestrate the transfer of internal state between network function (NF) instances. Unfortunately, these frameworks suffer from safety, efficiency, and scalability problems due to their excessive use of packet buffering. We propose two novel enhancements, packet reprocessing and peer-to-peer transfers, to address these issues. We show these enhancements reduce the average per-packet latency overhead by up to 92% and state transfer times by up to 70%. © 2015 ACM.",Network functions virtualization; Peer-to-peer; Software defined networking,Efficiency; Scalability; Software defined networking; Transfer functions; Virtual reality; Internal state; Network functions; Packet buffering; Packet latencies; Peer to peer; Peer-to-peer transfer; Scalability problems; Virtualizations; Peer to peer networks
"Zhou Z., Benson T.",2,Towards a safe playground for HTTPS and middleboxes with QoS2,2015,5,"Duke University, United States",Duke University,1,USA,1,16,12,"The increase in concern over network privacy has prompted adoption of HTTPS to sky-rocket with over 50% of traffic delivered using HTTPS. Unfortunately encryption HTTPS eliminates the benefits provided by middleboxes such as proxies and caches. We claim that these limitations, highlight the need for alternative mechanisms for quickly and safely viewing websites. QoS2 argues for fine-grained identification of common content and user-specific content, which are then delivered over either HTTP or HTTPS respectively. The main challenge in enabling QoS2, lies in ensuring that security is not compromised, namely preventing to Man in the Middle attacks. QoS2 overcomes these attacks by judiciously employing object level checksums which are sent exclusively over an HTTPS connection. To quantify the benefits of QoS2, we have manually tagged content for a number of sites and emulated an QoS2 server: initial results are promising with QoS2 providing a 20%-70% speed up over traditional HTTPS. © 2015 ACM.",Network management; Network performance; Network security; Transport layer security,HTTP; Network management; Network performance; Proxy caches; Rockets; Transfer functions; Virtual reality; Checksums; Fine grained; Man in the middle attacks; Middleboxes; Network privacy; Speed up; Transport layer security; Network security
"Gushchin A., Walid A., Tang A.",3,Scalable routing in SDN-enabled networks with consolidated middleboxes,2015,20,"Cornell University, United States; Bell Labs, Alcatel-Lucent, United States",Bell Labs;Cornell University,2,USA,1,25,21,"Middleboxes are special network devices that perform various functions such as enabling security and efficiency. SDN-based routing approaches in networks with middleboxes need to address resource constraints, such as memory in the switches and processing power of middleboxes, and traversal constraint where a flow must visit the required middleboxes in a specific order. In this work we propose a solution based on MultiPoint-To-Point Trees (MPTPT) for routing traffic in SDN-enabled networks with consolidated middleboxes. We show both theoretically and via simulations that our solution significantly reduces the number of routing rules in the switches, while guaranteeing optimum throughput and meeting processing requirements. Additionally, the underlying algorithm has low complexity making it suitable in dynamic network environment. © 2015 ACM.",Middlebox; MultiPoint-To-Point Tree; Software-defined networking; Traffic engineering,Complex networks; Computational complexity; Forestry; Software defined networking; Transfer functions; Virtual reality; Dynamic network environment; Middleboxes; MultiPoint-To-Point Tree; Processing power; Resource Constraint; Specific ordering; Traffic Engineering; Various functions; Network routing
"Song S., Kim D., Park H., Choi B.-Y., Choi T.",5,CO-REDUCE: Collaborative redundancy reduction service in software-defined networks,2015,2,"University of Missouri, Kansas City, MO, United States; Electronics and Telecommunications Research Institute, Daejeon, South Korea","Electronics and Telecommunications Research Institute,South Korea;University of Missouri",2,South Korea;USA,2,12,7,"A large portion of digital data is transferred repeatedly across networks and duplicated in storage systems, which costs excessive bandwidth, storage, energy, and operations. Thus, great effort has been made in both areas of networks and storage systems to lower the redundancies. However, due to the lack of the coordination capabilities, expensive procedures of C-H-I (Chunking, Hashing, and Indexing) are incurring recursively on the path of data processing. In this paper, we propose a collaborative redundancy reduction service (CO-REDUCE) in Software-Defined Networks (SDN). Taking advantage of SDN control, CO-REDUCE renders the promising vision of Redundancy Elimination as a network service (REaaS) as a real practical service. CO-REDUCE is a new virtualized network function service that dynamically offloads computational operations and memory management tasks of deduplication to the group of the software designed network middleboxes. Chaining various redundant REs of both storage and network into a service, COREDUCE consolidates and simplifies the expensive C-H-I processes. We develop service coordination protocols and virtualization and control mechanisms in SDN, and indexing algorithms for CO-REDUCE software-designed middleboxes (SDMB). Our evaluation results from the system and Mininet-based prototypes show that CO-REDUCE achieves 2-4 times more bandwidth reduction than existing RE technologies and has compatible storage space savings to existing storage de-duplication techniques while reducing expensive overhead of processing time and memory size. © 2015 ACM.",Data de-duplication; Network redundancy elimination; Software-defined networking,Bandwidth; Data handling; Digital storage; Indexing (materials working); Indexing (of information); Redundancy; Software defined networking; Transfer functions; Virtual reality; Bandwidth reductions; Computational operations; Data de duplications; Indexing algorithms; Network redundancy; Redundancy elimination; Redundancy reductions; Service coordination; Data storage equipment
"Fan J., Gao X., Ye Z., Ren K., Guan C., Qiao C.",6,GREP: Guaranteeing reliability with enhanced protection in NFV,2015,22,"SUNY Buffalo, Buffalo, NY, United States",SUNY Buffalo,1,USA,1,21,10,"Network Function Virtualization (NFV) is a promising technique to greatly improve the effectiveness and flexibility of network management through a process called Service Function Chain (SFC) mapping, which can efficiently provision network services over a virtualized and shared middlebox platform. However, such an evolution towards software-defined middlebox introduces new challenges to network services which require high reliability. Sufficient redundancy can protect the network services when physical failures occur, but in doing so, the efficiency of physical resources may be greatly decreased. This paper presents GREP, a novel online algorithm that can minimize the physical resources consumption while guaranteeing the required high reliability with a polynomial time complexity. Simulation results show that our proposed algorithm can significantly improve the request acceptance ratio and reduce resource consumption. © 2015 ACM.",Algorithms; Reliability; Service Function Chain (SFC),Algorithms; Chains; Network management; Polynomial approximation; Reliability; Software reliability; Transfer functions; Virtual reality; High reliability; Network functions; Network services; On-line algorithms; Physical resources; Polynomial time complexity; Resource consumption; Service functions; Complex networks
"Kothandaraman B., Du M., Skšldstršm P.",3,Centrally controlled distributed VNF state management,2015,16,"Royal Institute of Technology, Stockholm, Sweden; Acreo Swedish ICT AB, Stockholm, Sweden",KTH Royal Institute of Technology,1,Sweden,1,11,9,"The realization of increased service flexibility and scalability through the combination of Virtual Network Functions (VNF) and Software Defined Networks (SDN) requires careful management of both VNF and forwarding state. Without coordination, service scalability comes at a high cost due to unacceptable levels of packet loss, reordering and increased latencies. Previously developed techniques has shown that these issues can be managed, at least in scenarios with low traffic rates and optimistic control plane latencies. In this paper we extend previous work on coordinated state management in order to remove performance bottlenecks, this is done through distributed state management and minimizing control plane interactions. Evaluation of our changes show substantial performance gains using a distributed approach while maintaining centralized control. © 2015 ACM.",Middleboxes; Scalable network functions; Software-defined networking,Scalability; Software defined networking; Virtual reality; Careful management; Centralized control; Distributed approaches; Middleboxes; Performance bottlenecks; Scalable networks; Service flexibility; Service scalability; Transfer functions
"Vallina-Rodriguez N., Sundaresan S., Kreibich C., Paxson V.",4,Header enrichment or ISP enrichment? Emerging privacy threats in mobile networks,2015,5,"ICSI, United States; Lastline, United States; UC Berkeley, United States",University of California Berkeley,1,USA,1,12,12,"HTTP header enrichment allows mobile operators to annotate HTTP connections via the use of a wide range of request headers. Operators employ proxies to introduce such headers for operational purposes, and-as recently widely publicized-also to assist advertising programs in identifying the subscriber responsible for the originating traffic, with significant consequences for the user's privacy. In this paper, we use data collected by the Netalyzr network troubleshooting service over 16 months to identify and characterize HTTP header enrichment in modern mobile networks. We present a timeline of HTTP header usage for 299 mobile service providers from 112 countries, observing three main categories: (1) unique user and device identifiers (e.g., IMEI and IMSI), (2) headers related to advertising programs, and (3) headers associated with network operations. © 2015 ACM.",Cookies; HTTP; Mobile networks; Privacy; Proxies; Web,Data privacy; Internet service providers; Marketing; Mobile telecommunication systems; Transfer functions; Virtual reality; Wireless networks; Advertising programs; Cookies; Mobile operators; Mobile service providers; Network operations; Network troubleshooting; Privacy threats; Proxies; HTTP
"Rula J.P., Bischof Z.S., Bustamante F.E.",3,Second chance: Understanding diversity in broadband access network performance,2015,1,"Dept. of EECS, Northwestern University, Evanston, IL, United States",Northwestern University,1,USA,1,20,17,"In recognition of the increasing importance of broadband, several governments have embarked on large-scale efforts to measure broadband services from devices within end-user's homes. Participants for these studies were selected based on features that, a priori, were thought to be relevant to service performance such as geographic region, access technology and subscription level. Every new-year deployment since has followed the same model, ensuring that the number of measurement points remains stable despite the natural churn. In this paper, we start to explore the issue of vantage point selection in residential broadband networks by leveraging the publicly available datasets collected as part of the FCC Broadband America study. We present the first analysis of the variation of performance in edge networks and diversity of individual vantage points. We explore the underlying causes of this diversity through a factor analysis of contextual factors within an ISP such as the geographic location of subscribers. The goal of this analysis is to inform additional deployments in ongoing studies, and guide the design and deployment of future investigations into broadband networks. © 2015 ACM.",Broadband networks; Measurement techniques,Crowdsourcing; Internet; Internet service providers; Access technology; Broad-band access networks; Broadband service; Contextual factors; Geographic location; Measurement points; Measurement techniques; Service performance; Broadband networks
"S‡nchez M.A., Bustamante F.E., Krishnamurthy B., Willinger W.",4,Experiment coordination for large-scale measurement platforms,2015,1,"HP Labs, United States; Northwestern University, United States; AT and T Labs Research, United States; Niksun Inc., United States",AT and T Labs;HP Labs;Niksun Inc.;Northwestern University,4,USA,1,10,7,"The risk of placing an undesired load on networks and networked services through probes originating from measurement platforms has always been present. While several scheduling schemes have been proposed to avoid undue loads or DDoS-like effects from uncontrolled experiments, the motivation scenarios for such schemes have generally been considered sufficiently unlikely"" and safely ignored by most existing measurement platforms. We argue that the growth of large, crowdsourced measurement systems means we cannot ignore this risk any longer. In this paper we expand on our original lease-based coordination scheme designed for measurement platforms that embrace crowdsourcing as their method-of-choice. We compare it with two alternative strategies currently implemented by some of the existing crowdsourced measurement platforms: centralized rate-limiting and individual rate limiting. Our preliminary results show that our solution outperforms these two naive strategies for coordination according to at least two different intuitive metrics: Resource utilization and bound compliance. We find that our scheme efficiently allows the scalable and effective coordination of measurements among potentially thousands of hosts while providing individual clients with enough exibility to act on their own. © 2015 ACM.",Measurement coordination; Measurement task scheduling; Network-wide active measurements,Crowdsourcing; Internet; Active measurement; Coordination scheme; Large-scale measurement; Measurement system; Networked services; Resource utilizations; Scheduling schemes; Task-scheduling; Risk assessment
"Faggiani A., Gregori E., Lenzini L., Luconi V.",4,Measuring the internet topology with smartphones,2015,1,"IIT-CNR, Pisa, Italy; Dip. Ing. dell'Informazione, University of Pisa, Pisa, Italy",University of Pisa,1,Italy,1,13,7,"Despite the very well known smartphone issues such as on-off behaviour and battery/bandwidth limitations, in this paper we show that smartphones can be successfully employed in a crowdsourcing system to perform Internet AS-level topology discovery. We propose and illustrate a measurement methodology that takes these issues into account. We implemented such methodology in Portolan, our smartphone-based crowdsourcing system, and ran six months of measurements. We show that smartphones mobility allows to obtain measure- ments from 706 different ASes with just 200 active de- vices. Moreover, we show that our methodology manages to bring novelty with relatively few measurements. On average 27.75% of the AS links found by Portolan are not found by BGP measurements. © 2015 ACM.",Crowdsourcing; Internet measurements; Smartphones,Crowdsourcing; Internet; Signal encoding; Topology; AS-links; Internet as levels; Internet measurement; Internet topologies; Measurement methodology; On-off behaviour; Topology discovery; Smartphones
"Molinari M., Fida M.-R., Marina M.K., Pescape A.",4,Spatial interpolation based cellular coverage prediction with crowdsourced measurements,2015,12,"University of Napoli Federico II, Italy; University of Edinburgh, Edinburgh, United Kingdom",University of Edinburgh;University of Napoli Federico II,2,Italy;UK,2,20,13,"Coverage extension and prediction has always been of great importance for mobile network operators. For coverage extension, the empirical and analytical path loss models assist in better positioning of the infrastructure. However postdeployment coverage prediction can be more cost effectively enabled by crowdsourced measurements. Unlike drive testing, crowdsourced measurements along with spatial interpolation techniques can help generate coverage maps with less expense and labor. Using controlled measurements taken with commodity smartphones, we empirically study the accuracy of a wide range of spatial interpolation techniques, including various forms of Kriging, in different scenarios that capture the unique characteristics of crowdsourced measurements (inaccurate locations, sparse and non-uniform measurements, etc.). Our results indicate that Ordinary Kriging is a fairly robust technique overall, across all scenarios. © 2015 ACM.",Cellular coverage prediction; Crowdsourced mobile network measurement; Spatial interpolation,Crowdsourcing; Digital storage; Forecasting; Internet; Interpolation; Mobile telecommunication systems; Wireless networks; Cellular coverage; Coverage extension; Coverage prediction; Mobile network operators; Network measurement; Ordinary kriging; Path loss models; Spatial interpolation; Spatial variables measurement
"Mandalari A.M., Bagnulo M., Lutu A.",3,Informing protocol design through crowdsourcing: The case of pervasive encryption,2015,3,"University Carlos III of Madrid, Madrid, Spain; Simula Research Laboratory, Norway",Simula Research;University Carlos III of Madrid,2,Norway;Spain,2,18,15,"Middleboxes, such as proxies, firewalls and NATs play an important role in the modern Internet ecosystem. On one hand, they perform advanced functions, e.g. traffic shaping, security or enhancing application performance. On the other hand, they turn the Internet into a hostile ecosystem for innovation, as they limit the deviation from deployed protocols. It is therefore essential, when designing a new protocol, to first understand its interaction with the elements of the path. The emerging area of crowdsourcing solutions can help to shed light on this issue. Such approach allows us to reach large and different sets of users and also different types of devices and networks to perform Internet measurements. In this paper, we show how to make informed protocol design choices by using a crowdsourcing platform. We consider a specific use case, namely the case of pervasive encryption in the modern Inter- net. Given the latest public disclosures of the NSA global surveillance operations, the issue of privacy in the Internet became of paramount importance. Internet community efforts are thus underway to increase the adoption of encryption. Using a crowdsourcing ap- proach, we perform large-scale TLS measurements to advance our understanding on whether wide adoption of encryption is possible in today's Internet. © 2015 ACM.",Internet measurements; Middle-boxes; TLS,Computer system firewalls; Crowdsourcing; Cryptography; Ecology; Ecosystems; Internet; Network security; Thallium; Advanced functions; Application performance; Crowdsourcing platforms; Global surveillance; Internet communities; Internet measurement; Middle-boxes; Pervasive encryption; Internet protocols
"Huz G., Bauer S., Claffy K., Beverly R.",4,Experience in using mturk for network measurement,2015,2,"Naval Postgraduate School, United States; MIT CSAIL, United States; CAIDA, United States",MIT;Naval Postgraduate School,2,USA,1,9,9,"Conducting sound measurement studies of the global Internet is inherently difficult. The collected data sig- nificantly depends on vantage point(s), sampling strategies, security policies, or measurement populations - And conclusions drawn from the data can be sensitive to these biases. Crowdsourcing is a promising approach to address these challenges, although the epistemological implications have not yet received substantial attention by the research community. We share our findings from leveraging Amazon's Mechanical Turk (MTurk) system for three distinct network measurement tasks. We describe our failure to outsource to MTurk an execution of a security measurement tool, our subsequent successful integration of a simple yet meaningful measurement within a HIT, and finally the successful use of MTurk to quickly provide focused small sample sets that could not be obtained easily via alternate means. Finally, we discuss the implications of our experiences for other crowdsourced measurement research. © 2015 ACM.",Crowdsourcing; Mechanical turk; Network measurement,Architectural acoustics; Crowdsourcing; Internet; Population statistics; Amazon's mechanical turks; Measurement research; Measurement study; Mechanical turks; Network measurement; Research communities; Sampling strategies; Security measurement; Web services
"Le A., Varmarken J., Langhoff S., Shuba A., Gjoka M., Markopoulou A.",6,AntMonitor: A system for monitoring from mobile devices,2015,23,"CalIT2, UC Irvine, United States; IT Univ. of Copenhagen, Denmark; CalIT2, EECS, CPCC, UC Irvine, United States",University of California Irvine,1,Denmark;USA,2,25,19,"We propose AntMonitor - A system for passive monitoring, collection and analysis of fine-grained, large-scale packet measurements from Android devices. AntMonitor is the first system of its kind that combines the following properties: (i) it provides participating users with fine-grained control of which data to contribute; (ii) it does not require administrative privileges; (iii) it supports client-side analysis of traffic; and (iv) it supports collection of large-scale, fine-grained, and semantic-rich traffic. The first three properties benefit mobile users, by giving them control over their privacy while also enabling a number of services to incentivize their participation. The last property makes AntMonitor a powerful tool for network researchers who want to collect and analyze large-scale, yet fine-grained mobile measurements. As a proof-of-concept, we have developed and deployed a prototype of AntMonitor, and we have used it to monitor 9 users for several months. AntMonitor has high network throughput while incurring lower CPU and battery costs than existing mobile monitoring systems. Our preliminary experience with the prototype demonstrates its capabilities and its potential for enabling several research activities, including network measurement from the edge, classification of mobile traffic, and detection of privacy leakage and other malicious behaviors. © 2015 ACM.",Mobile networks; Network monitoring,Crowdsourcing; Internet; Mobile devices; Mobile telecommunication systems; Semantics; Wireless networks; Fine-grained control; High network throughput; Mobile measurements; Mobile monitoring system; Network measurement; Network Monitoring; Packet measurements; Research activities; Monitoring
"Levin D., Lee Y., Valenta L., Li Z., Lai V., Lumezanu C., Spring N., Bhattacharjee B.",8,Alibi routing,2015,11,"University of Maryland, United States; University of Pennsylvania, United States; NEC Labs, United States",University of Maryland College Park;University of Pennsylvania,2,USA,1,23,4,"There are several mechanisms by which users can gain insight into where their packets have gone, but no mechanisms allow users undeniable proof that their packets did not traverse certain parts of the world while on their way to or from another host. This paper introduces the problem of finding ""proofs of avoidance"": Evidence that the paths taken by a packet and its response avoided a user-specified set of ""forbidden"" geographic regions. Proving that something did not happen is often intractable, but we demonstrate a lowoverhead proof structure built around the idea of what we call ""alibis"": Relays with particular timing constraints that, when upheld, would make it impossible to traverse both the relay and the forbidden regions. We present Alibi Routing, a peer-to-peer overlay routing system for finding alibis securely and efficiently. One of the primary distinguishing characteristics of Alibi Routing is that it does not require knowledge of-or modifications to-the Internet's routing hardware or policies. Rather, Alibi Routing is able to derive its proofs of avoidance from user-provided GPS coordinates and speed of light propagation delays. Using a PlanetLab deployment and larger-scale simulations, we evaluate Alibi Routing to demonstrate that many source-destination pairs can avoid countries of their choosing with little latency inflation. We also identify when Alibi Routing does not work: it has difficulty avoiding regions that users are very close to (or, of course, inside of). © 2015 ACM.",Alibi routing; Censorship avoidance; Overlay routing; Peer-to-peer; Provable route avoidance,Convolutional codes; Alibi routing; Censorship avoidance; Overlay routing; Peer to peer; Provable route avoidance; Peer to peer networks
"Yin X., Jindal A., Sekar V., Sinopoli B.",4,A Control-theoretic approach for dynamic adaptive video streaming over HTTP,2015,165,"Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,50,31,"User-perceived quality-of-experience (QoE) is critical in Internet video applications as it impacts revenues for content providers and delivery systems. Given that there is little support in the network for optimizing such measures, bottlenecks could occur anywhere in the delivery system. Consequently, a robust bitrate adaptation algorithm in client-side players is critical to ensure good user experience. Previous studies have shown key limitations of state-of-art commercial solutions and proposed a range of heuristic fixes. Despite the emergence of several proposals, there is still a distinct lack of consensus on: (1) How best to design this client-side bitrate adaptation logic (e.g., use rate estimates vs. buffer occupancy); (2) How well specific classes of approaches will perform under diverse operating regimes (e.g., high throughput variability); or (3) How do they actually balance different QoE objectives (e.g., startup delay vs. rebuffering). To this end, this paper makes three key technical contributions. First, to bring some rigor to this space, we develop a principled control-theoretic model to reason about a broad spectrum of strategies. Second, we propose a novel model predictive control algorithm that can optimally combine throughput and buffer occupancy information to outperform traditional approaches. Third, we present a practical implementation in a reference video player to validate our approach using realistic trace-driven emulations. © 2015 ACM.",Bitrate adaptation; DASH; Internet video; Model predictive control,Algorithms; Convolutional codes; HTTP; Internet; Optimization; Predictive control systems; Quality of service; Video streaming; Adaptation algorithms; Bit rates; Content providers; Control-theoretic approach; DASH; Internet video; Technical contribution; Traditional approaches; Model predictive control
"Prakash C., Lee J., Turner Y., Kang J.-M., Akella A., Banerjee S., Clark C., Ma Y., Sharma P., Zhang Y.",10,PGA: Using graphs to express and automatically reconcile network policies,2015,65,"University of Wisconsin-Madison, United States; HP Labs, United States; Banyan, United States; HP Networking, United States",HP Labs;;University of Wisconsin-Madison,3,USA,1,52,32,"Software Defined Networking (SDN) and cloud automation enable a large number of diverse parties (network operators, application admins, tenants/end-users) and control programs (SDN Apps, network services) to generate network policies independently and dynamically. Yet existing policy abstractions and frameworks do not support natural expression and automatic composition of high-level policies from diverse sources. We tackle the open problem of automatic, correct and fast composition of multiple independently specified network policies. We first develop a high-level Policy Graph Abstraction (PGA) that allows network policies to be expressed simply and independently, and leverage the graph structure to detect and resolve policy conflicts efficiently. Besides supporting ACL policies, PGA also models and composes service chaining policies, i.e., the sequence of middleboxes to be traversed, by merging multiple service chain requirements into conflict-free composed chains. Our system validation using a large enterprise network policy dataset demonstrates practical composition times even for very large inputs, with only sub-millisecond runtime latencies. © 2015 ACM.",Policy graphs; Software-defined networks,Abstracting; Application programs; Chains; Convolutional codes; Software defined networking; Automatic composition; Graph structures; High level policies; Large enterprise; Multiple services; Network services; Software defined networking (SDN); System validation; Programmed control systems
"Roy A., Zengy H., Baggay J., Porter G., Snoeren A.C.",5,Inside the social network's (Datacenter) network,2015,156,"Department of Computer Science and Engineering, University of California, San Diego, United States; Facebook, Inc., United States",Facebook;University of California San Diego,2,USA,1,42,29,"Large cloud service providers have invested in increasingly larger datacenters to house the computing infrastructure required to support their services. Accordingly, researchers and industry practitioners alike have focused a great deal of effort designing network fabrics to efficiently interconnect and manage the traffic within these datacenters in performant yet efficient fashions. Unfortunately, datacenter operators are generally reticent to share the actual requirements of their applications, making it challenging to evaluate the practicality of any particular design. Moreover, the limited large-scale workload information available in the literature has, for better or worse, heretofore largely been provided by a single datacenter operator whose use cases may not be widespread. In this work, we report upon the network traffic observed in some of Facebook's datacenters. While Facebook operates a number of traditional datacenter services like Hadoop, its core Web service and supporting cache infrastructure exhibit a number of behaviors that contrast with those reported in the literature. We report on the contrasting locality, stability, and predictability of network traffic in Facebook's datacenters, and comment on their implications for network architecture, traffic engineering, and switch design. © 2015 ACM.",Datacenter traffic patterns,Convolutional codes; Network architecture; Web services; Cloud service providers; Computing infrastructures; Core web services; Network fabric; Network traffic; Switch designs; Traffic Engineering; Traffic pattern; Social networking (online)
"Chang L., Chen X., Fang D., Wang J., Xing T., Liu C., Tang Z.",7,FALE: Fine-grained device free localization that can adaptively work in different areas with little effort,2015,5,"Northwest University, Xi'an, China",Northwest University,1,China,1,40,37,"Many emerging applications and the ubiquitous wireless signals have accelerated the development of Device Free localization (DFL) techniques, which can localize objects without the need to carry any wireless devices. Most traditional DFL methods have a main drawback that as the pre-obtained Received Signal Strength (RSS) measurements (i.e., fingerprint) in one area cannot be directly applied to the new area for localization, and the calibration process of each area will result in the human effort exhausting problem. In this paper, we propose FALE, a fine-grained transferring DFL method that can adaptively work in different areas with little human effort and low energy consumption. FALE employs a rigorously designed transferring function to transfer the fingerprint into a projected space, and reuse it across different areas, thus greatly reduce the human effort. On the other hand, FALE can reduce the data volume and energy consumption by taking advantage of the compressive sensing (CS) theory. Extensive real-word experimental results also illustrate the effectiveness of FALE. © 2015 ACM.",Area diversity; Device free localization; Received signal strength; Transferring,Compressed sensing; Convolutional codes; Energy utilization; RSS; Area diversity; Calibration process; Compressive sensing; Device-free localizations; Emerging applications; Low energy consumption; Received signal strength; Transferring; Mobile computing
"Riggio R., Schulz-Zander J., Bradai A.",3,Virtual network function orchestration with Scylla,2015,2,"CREATE-NET Trento, Italy; TU-Berlin, Berlin, Germany",TU Berlin,1,Germany;Italy,2,4,4,"Network Function Virtualization promises to reduce the cost to deploy and to operate large networks by migrating various network functions from dedicated hardware appliances to software instances running on general purpose networking and computing platforms. In this paper we demonstrate Scylla a Programmable Network Fabric architecture for Enterprise WLANs. The framework supports basic Virtual Network Function lifecycle management functionalities such as instantiation, monitoring, and migration. We release the entire platform under a permissive license for academic use. © 2015 ACM.",Enterprise WLANs; Network function virtualization,Convolutional codes; Virtual reality; Computing platform; Dedicated hardware; Enterprise wlans; Life-cycle management; Network functions; Programmable network; Virtual networks; Virtualizations; Transfer functions
"Kotaru M., Joshi K., Bharadia D., Katti S.",4,SpotFi: Decimeter level localization using WiFi,2015,206,"Stanford University, Stanford, CA, United States",Stanford University,1,USA,1,5,2,"This paper presents the design and implementation of SpotFi, an accurate indoor localization system that can be deployed on commodity WiFi infrastructure. SpotFi only uses information that is already exposed by WiFi chips and does not require any hardware or firmware changes, yet achieves the same accuracy as state-of-the-art localization systems. SpotFi makes two key technical contributions. First, SpotFi incorporates super-resolution algorithms that can accurately compute the angle of arrival (AoA) of multipath components even when the access point (AP) has only three antennas. Second, it incorporates novel filtering and estimation techniques to identify AoA of direct path between the localization target and AP by assigning values for each path depending on how likely the particular path is the direct path. Our experiments in a multipath rich indoor environment show that SpotFi achieves a median accuracy of 40 cm and is robust to indoor hindrances such as obstacles and multipath. © 2015 ACM.",CSI; Indoor localization; OFDM; WiFi; Wireless,Convolutional codes; Direction of arrival; Firmware; Orthogonal frequency division multiplexing; Radio; Wi-Fi; Design and implementations; Estimation techniques; Indoor localization; Indoor localization systems; Localization system; Multi-path components; Super resolution algorithms; Technical contribution; Indoor positioning systems
"Ernits M., TammekŠnd J., Maennel O.",3,Tee: A fully automated cyber defense competition for students,2015,4,"Tallinn University of Technology, Akadeemia Tee 15a, Tallinn, Estonia; Estonian IT College, Raja 4C, Tallinn, Estonia",Estonian IT College;Tallinn University of Technology,2,Estonia,1,72,8,"We present an Intelligent Training Exercise Environment (i- Tee1), a fully automated Cyber Defense Competition plat- form. The main features of i-tee are: Automated attacks, automated scoring with immediate feedback using a score- board, and background trafic generation. The main advantage of the platform is easy integration into existing curricula and suitability for continuous education as well as on-site training at companies. The platform implements a modular approach called learning spaces for implementing different competitions and hands-on labs. The platform is highly automated to enable execution with up to 30 teams by one person using a single server. The platform is publicly available under MIT license2. © 2015 ACM.",Auto-configuration; Cyber security exercises; Virtual networks,Convolutional codes; Curricula; Network security; Auto-configuration; Automated attacks; Continuous educations; Cyber security exercise; Immediate feedbacks; Modular approach; Training exercise; Virtual networks; Automation
"Sherry J., Gao P.X., Basu S., Panda A., Krishnamurthy A., Macioccoy C., Maneshy M., Martins J., Ratnasamy S., Rizzo L., Shenke S.",11,Rollback-recovery for middleboxes,2015,46,"UC Berkeley, United States; University of Washington, United States; Intel Research, United States; NEC Labs, United States; University of Pisa, Italy; ICSI, United States",Intel;University of California Berkeley;University of Pisa;University of Washington at Seattle,4,Italy;USA,2,3,3,"Network middleboxes must offer high availability, with automatic failover when a device fails. Achieving high availability is challenging because failover must correctly restore lost state (e.g., activity logs, port mappings) but must do so quickly (e.g., in less than typical transport timeout values to minimize disruption to applications) and with little overhead to failure-free operation (e.g., additional per-packet latencies of 10-100s of _s). No existing middlebox design provides failover that is correct, fast to recover, and imposes little increased latency on failure-free operations. We present a new design for fault-tolerance in middleboxes that achieves these three goals. Our system, FTMB (for Fault-Tolerant MiddleBox), adopts the classical approach of ""rollback recovery"" in which a system uses information logged during normal operation to correctly reconstruct state after a failure. However, traditional rollback recovery cannot maintain high throughput given the frequent output rate of middleboxes. Hence, we design a novel solution to record middlebox state which relies on two mechanisms: (1) 'ordered logging', which provides lightweight logging of the information needed after recovery, and (2) a 'parallel release' algorithm which, when coupled with ordered logging, ensures that recovery is always correct. We implement ordered logging and parallel release in Click and show that for our test applications our design adds only 30_s of latency to median per packet latencies. Our system introduces moderate throughput overheads (5-30%) and can reconstruct lost state in 40-275ms for practical systems. © 2015 ACM.",Middlebox reliability; Parallel fault-tolerance,Availability; Convolutional codes; Design; Recovery; Telecommunication networks; Classical approach; Failure-free operations; High availability; Middleboxes; Minimize disruption; Normal operations; Roll-back recoveries; Test applications; Fault tolerance
"Reuter A., WŠhlisch M., Schmidt T.C.",3,RPKI MIRO: Monitoring and inspection of RPKI objects,2015,2,"Freie UniversitŠt Berlin, HAW Hamburg, Germany",Freie UniversitŠt Berlin,1,Germany,1,62,36,"The Resource Public Key Infrastructure (RPKI) stores attestation objects for Internet resources. In this demo, we present RPKI MIRO, an open source software framework to monitor and inspect these RPKI objects. RPKI MIRO provides resource owners, RPKI operators, researchers, and lecturers with intuitive access to the content of the deployed RPKI repositories. It helps to optimize the repository structure and to identify failures. © 2015 ACM.",PKI Monitoring; RPKI measurement; Secure inter-domain routing,Computer programming; Convolutional codes; Distributed computer systems; Open systems; Public key cryptography; Software engineering; Internet resources; Public key infrastructure; Resource owners; Secure inter-domain routing; Open source software
"Alistarh D., Ballani H., Costa P., Funnell A., Benjamin J., Watts P., Thomsen B.",7,"A high-radix, low-latency optical switch for data centers",2015,8,"Microsoft Research, United Kingdom; University College London, United Kingdom",Microsoft;University College London,2,UK,1,8,7,"We demonstrate an optical switch design that can scale up to a thousand ports with high per-port bandwidth (25 Gbps+) and low switching latency (40 ns). Our design uses a broadcast and select architecture, based on a passive star coupler and fast tunable transceivers. In addition we employ time division multiplexing to achieve very low switching latency. Our demo shows the feasibility of the switch data plane using a small testbed, comprising two transmitters and a receiver, connected through a star coupler. © 2015 ACM.",Optical switching; TDMA; WDM,Convolutional codes; Optical switches; Stars; Time division multiplexing; Wavelength division multiplexing; Data centers; Fast tunable; High radix; Low latency; Optical switching; Passive star couplers; Star couplers; Switch data; Time division multiple access
"Zhu Y., Eran H., Firestone D., Guo C., Lipshteyn M., Liron Y., Padhye J., Raindel S., Yahia M.H., Zhang M.",10,Congestion control for large-scale RDMA deployments,2015,62,"Microsoft, China; Mellanox, Israel; U.C. Santa Barbara, United States",Microsoft,1,China;Israel;USA,3,8,7,"Modern datacenter applications demand high throughput (40Gbps) and ultra-low latency (< 10 _s per hop) from the network, with low CPU overhead. Standard TCP/IP stacks cannot meet these requirements, but Remote Direct Memory Access (RDMA) can. On IP-routed datacenter networks, RDMA is deployed using RoCEv2 protocol, which relies on Priority-based Flow Control (PFC) to enable a drop-free network. However, PFC can lead to poor application performance due to problems like head-of-line blocking and unfairness. To alleviates these problems, we introduce DCQCN, an end-to-end congestion control scheme for RoCEv2. To optimize DCQCN performance, we build a fluid model, and provide guidelines for tuning switch buffer thresholds, and other protocol parameters. Using a 3-tier Clos network testbed, we show that DCQCN dramatically improves throughput and fairness of RoCEv2 RDMA traffic. DCQCN is implemented in Mellanox NICs, and is being deployed in Microsoft's datacenters. © 2015 ACM.",Congestion control; Datacenter transport; Ecn; Pfc; Rdma,Congestion control (communication); Convolutional codes; Internet protocols; Switching networks; Application performance; Data center networks; Datacenter; End-to-end congestion control; Head of line blocking; Protocol parameters; Rdma; Remote direct memory access; Transmission control protocol
"Rifai M., Lopez-Pacheco D., Urvoy-Keller G.",3,Coarse-grained scheduling with software-defined networking switches,2015,4,"University Nice Sophia Antipolis, France",University Nice Sophia Antipolis,1,France,1,49,36,"Software-Defined Networking (SDN) enables consolidation of the control plane of a set of network equipments with a fine-grained control of traffic flows inside the network. In this work, we demonstrate that some coarse-grained scheduling mechanisms can be easily offered by SDN switches without requiring any unsupported operation in OpenFlow. We leverage the feedback loop - flow statistics - exposed by SDN switches to the controller, combined with priority queuing mechanisms, usually available in typical switches on their output ports. We illustrate our approach through experimentations with an OpenvSwitch SDN switch controlled by a Beacon controller. © 2015 ACM.",Size-based scheduling; Software-defined networking,Controllers; Convolutional codes; Scheduling; Coarse-grained; Control planes; Fine-grained control; Network equipment; Priority queuing; Scheduling mechanism; Size-based scheduling; Software defined networking (SDN); Software defined networking
"Costa P., Ballani H., Razavi K., Kash I.",4,R2C2: A network stack for rack-scale computers,2015,10,"Microsoft Research, VU University Amsterdam, Netherlands",Microsoft;Vrije University,2,Netherlands,1,7,5,"Rack-scale computers, comprising a large number of microservers connected by a direct-connect topology, are expected to replace servers as the building block in data centers. We focus on the problem of routing and congestion control across the rack's network, and find that high path diversity in rack topologies, in combination with workload diversity across it, means that traditional solutions are inadequate. We introduce R2C2, a network stack for rack-scale computers that provides flexible and efficient routing and congestion control. R2C2 leverages the fact that the scale of rack topologies allows for low-overhead broadcasting to ensure that all nodes in the rack are aware of all network flows. We thus achieve rate-based congestion control without any probing; each node independently determines the sending rate for its flows while respecting the provider's allocation policies. For routing, nodes dynamically choose the routing protocol for each flow in order to maximize overall utility. Through a prototype deployed across a rack emulation platform and a packet-level simulator, we show that R2C2 achieves very low queuing and high throughput for diverse and bursty workloads, and that routing flexibility can provide significant throughput gains. © 2015 ACM.",Congestion control; Rack-scale computers; Rack-scale network stack; Route selection,Computer networks; Congestion control (communication); Convolutional codes; Topology; Allocation policies; Efficient routing; Emulation platform; Network stack; Rate-based congestion control; Route Selection; Routing flexibility; Workload diversities; Network routing
"Jalaparti V., Bodik P., Menache I., Rao S., Makarychev K., Caesar M.",6,Network-aware scheduling for data-parallel jobs: Plan when you can,2015,75,"University of Illinois, Urbana-Champaign, United States; Microsoft, China",Microsoft;UIUC,2,China;USA,2,62,41,"To reduce the impact of network congestion on big data jobs, cluster management frameworks use various heuristics to schedule compute tasks and/or network flows. Most of these schedulers consider the job input data fixed and greedily schedule the tasks and flows that are ready to run. However, a large fraction of production jobs are recurring with predictable characteristics, which allows us to plan ahead for them. Coordinating the placement of data and tasks of these jobs allows for significantly improving their network locality and freeing up bandwidth, which can be used by other jobs running on the cluster. With this intuition, we develop Corral, a scheduling framework that uses characteristics of future workloads to determine an offline schedule which (i) jointly places data and compute to achieve better data locality, and (ii) isolates jobs both spatially (by scheduling them in different parts of the cluster) and temporally, improving their performance. We implement Corral on Apache Yarn, and evaluate it on a 210 machine cluster using production workloads. Compared to Yarn's capacity scheduler, Corral reduces the makespan of these workloads up to 33% and the median completion time up to 56%, with 20-90% reduction in data transferred across racks. © 2015 ACM.",Cluster schedulers; Cross-layer optimization; Data-intensive applications; Joint data and compute placement,Big data; Convolutional codes; Fences; Information management; Job shop scheduling; Scheduling; Wool; Yarn; Cluster management; Cluster schedulers; Cross layer optimization; Data-intensive application; Network congestions; Network-Aware Scheduling; Production workloads; Scheduling frameworks; Data reduction
"Bharadiay D., Joshiy K., Kotaru M., Katti S.",4,BackFi: High throughput WiFi backscatter,2015,72,"Stanford University, United States; Co-Primary, United States",Stanford University,1,USA,1,50,30,"We present BackFi, a novel communication system that enables high throughput, long range communication between very low power backscatter IoT sensors andWiFi APs using ambient WiFi transmissions as the excitation signal. Specifically, we show that it is possible to design IoT sensors and WiFi APs such that the WiFi AP in the process of transmitting data to normal WiFi clients can decode backscatter signals which the IoT sensors generate by modulating information on to the ambient WiFi transmission. We show via prototypes and experiments that it is possible to achieve communication rates of up to 5 Mbps at a range of 1 m and 1 Mbps at a range of 5 meters. Such performance is an order to three orders of magnitude better than the best known priorWiFi backscatter system [27, 25]. BackFi design is energy efficient, as it relies on backscattering alone and needs insignificant power, hence the energy consumed per bit is small. © 2015 ACM.",Ambient backscatter; Backscatter communication; Backscatter decoder; Full duplex backscatter; Internet of things (ioT); WiFi backscatter,Convolutional codes; Decoding; Energy efficiency; Internet of things; Throughput; Backscatter signals; Communication rate; Excitation signals; Full-duplex; Internet of Things (IOT); Long-range communications; Three orders of magnitude; Transmitting data; Backscattering
"Mukerjee M.K., Naylor D., Jiang J., Han D., Seshan S., Zhang H.",6,"Practical, real-time centralized control for CDN-based live video delivery",2015,47,"Carnegie Mellon University, United States; KAIST, United States; Conviva Inc., United States",Carnegie Mellon University;Conviva Inc.;KAIST,3,USA,1,55,24,"Live video delivery is expected to reach a peak of 50 Tbps this year [7]. This surging popularity is fundamentally changing the Internet video delivery landscape. CDNs must meet users' demands for fast join times, high bitrates, and low buffering ratios, while minimizing their own cost of delivery and responding to issues in real-time. Wide-area latency, loss, and failures, as well as varied workloads (""mega-events"" to long-tail), make meeting these demands challenging. An analysis of video sessions [32] concluded that a centralized controller could improve user experience, but CDN systems have shied away from such designs due to the difficulty of quickly handling failures [29], a requirement of both operators and users. We introduce VDN, a practical approach to a video delivery network that uses a centralized algorithm for live video optimization. VDN provides CDN operators with real-time, fine-grained control. It does this in spite of challenges resulting from the wide-area (e.g., state inconsistency, partitions, failures) by using a hybrid centralized+distributed control plane, increasing average bitrate by 1.7_ and decreasing cost by 2_ in different scenarios. © 2015 ACM.",CDNs; Central optimization; Hybrid control; Live video,Convolutional codes; Distributed parameter control systems; CDNs; Centralized algorithms; Centralized control; Centralized controllers; Distributed control planes; Fine-grained control; Hybrid controls; Live video; Integrated control
"Markmann T., Schmidt T.C., WŠhlisch M.",3,Federated end-to-end authentication for the constrained internet of things using IBC and ECC,2015,13,"HAW Hamburg, Germany; Freie UniversitŠt Berlin, Germany",Freie UniversitŠt Berlin,1,Germany,1,45,26,"Authentication of smart objects is a major challenge for the Internet of Things (IoT), and has been left open in DTLS. Leveraging locally managed IPv6 addresses with identity- based cryptography (IBC), we propose an eficient end-to-end authentication that (a) assigns a robust and deployment- friendly federation scheme to gateways of IoT subnetworks, and (b) has been evaluated with a modern twisted Edwards elliptic curve cryptography (ECC). Our early results demonstrate feasibility and promise efficiency after ongoing optimisations. © 2015 ACM.",Authentication; End-to-end security; Federation; Id-based cryptography; Smart objects,Authentication; Convolutional codes; Cryptography; Internet; Public key cryptography; Elliptic Curve Cryptography(ECC); End-to-end security; Federation; Federation schemes; ID-based cryptography; Identity based cryptography; Internet of thing (IOT); Smart objects; Internet of things
"Hu P., Zhang P., Ganesan D.",3,Laissez-faire : Fully asymmetric backscatter communication,2015,42,"College of Information and Computer Sciences, University of Massachusetts, Amherst, MA  01003, United States",University of Massachusetts Amherst,1,USA,1,5,4,"Backscatter provides dual-benefits of energy harvesting and low-power communication, making it attractive to a broad class of wireless sensors. But the design of a protocol that enables extremely power-efficient radios for harvesting-based sensors as well as high-rate data transfer for data-rich sensors presents a conundrum. In this paper, we present a new fully asymmetric backscatter communication protocol where nodes blindly transmit data as and when they sense. This model enables fully flexible node designs, from extraordinarily power efficient backscatter radios that consume barely a few micro-watts to high-throughput radios that can stream at hundreds of Kbps while consuming a paltry tens of micro-watts. The challenge, however, lies in decoding concurrent streams at the reader, which we achieve using a novel combination of time-domain separation of interleaved signal edges, and phase-domain separation of colliding transmissions. We provide an implementation of our protocol, LF-Backscatter, and show that it can achieve an order of magnitude or more improvement in throughput, latency and power over state-of-art alternatives. © 2015 ACM.",Architecture; Backscatter; Wireless,Architecture; Convolutional codes; Data transfer; Energy harvesting; Radio; High throughput; Interleaved signals; Low-power communication; Node designs; Phase domain; Power efficient; Transmit data; Wireless sensor; Backscattering
"Kumar A., Kasinadhuni N., Carlin B., Jain S., Zermeno E.C., Amarandei-Stavila M., Stuart S., Naik U., Gunn C.S., Robin M., Vahdat A., Raghuraman A., Ai J., Siganporia A.",14,"BwE: Flexible, hierarchical bandwidth allocation for WAN distributed computing",2015,44,"Google Inc., United States",Google,1,USA,1,27,19,"WAN bandwidth remains a constrained resource that is economically infeasible to substantially overprovision. Hence, it is important to allocate capacity according to service priority and based on the incremental value of additional allocation. For example, it may be the highest priority for one service to receive 10Gb/s of bandwidth but upon reaching such an allocation, incremental priority may drop sharply favoring allocation to other services. Motivated by the observation that individual flows with fixed priority may not be the ideal basis for bandwidth allocation, we present the design and implementation of Bandwidth Enforcer (BwE), a global, hierarchical bandwidth allocation infrastructure. BwE supports: i) service-level bandwidth allocation following prioritized bandwidth functions where a service can represent an arbitrary collection of fiows, ii) independent allocation and delegation policies according to user-defined hierarchy, all accounting for a global view of bandwidth and failure conditions, iii)multi-path forwarding common in traffic-engineered networks, and iv) a central administrative point to override (perhaps faulty) policy during exceptional conditions. BwE has delivered more service-efficient bandwidth utilization and simpler management in production for multiple years. © 2015 ACM.",Bandwidth allocation; Max-min fair; Software- defined network; Wide-area networks,Bandwidth; Convolutional codes; Distributed computer systems; Frequency allocation; Software defined networking; Constrained resources; Design and implementations; Efficient bandwidth; Failure conditions; Fixed priorities; Max-min; Multi-path forwarding; Service priority; Wide area networks
"Tune P., Roughan M.",2,Spatiotemporal traffic matrix synthesis,2015,10,"ARC Centre of Excellence for Mathematical and Statistical Frontiers, School of Mathematical Sciences, University of Adelaide, Australia",University of Adelaide,1,Australia,1,30,17,"Traffic matrices describe the volume of traffic between a set of sources and destinations within a network. These matrices are used in a variety of tasks in network planning and traffic engineering, such as the design of network topologies. Traffic matrices naturally possess complex spatiotemporal characteristics, but their proprietary nature means that little data about them is available publicly, and this situation is unlikely to change. Our goal is to develop techniques to synthesize traffic matrices for researchers who wish to test new network applications or protocols. The paucity of available data, and the desire to build a general framework for synthesis that could work in various settings requires a new look at this problem. We show how the principle of maximum entropy can be used to generate a wide variety of traffic matrices constrained by the needs of a particular task, and the available information, but otherwise avoiding hidden assumptions about the data. We demonstrate how the framework encompasses existing models and measurements, and we apply it in a simple case study to illustrate the value. © 2015 ACM.",Maximum entropy; Network design; Spatiotemporal modeling; Traffic engineering; Traffic matrix synthesis,Complex networks; Convolutional codes; Entropy; Maximum entropy methods; Telecommunication traffic; Network applications; Network design; Principle of Maximum Entropy; Sources and destinations; Spatio-temporal models; Spatiotemporal characteristics; Traffic Engineering; Traffic matrices; Matrix algebra
"Antichi G., Rotsos C., Moore A.W.",3,Enabling performance evaluation beyond 10 Gbps,2015,0,"University of Cambridge, United Kingdom; Lancaster University, United Kingdom",Lancaster University;University of Cambridge,2,UK,1,49,25,"Despite network monitoring and testing being critical for computer networks, current solutions are both extremely ex- pensive and inexible. This demo presents OSNT (www.osnt.org), a community- driven, high-performance, open-source traffic generator and capture system built on top of the NetFPGA-10G board which enables flexible network testing. The platform sup- ports full line-rate traffic generation regardless of packet size across the four card ports, packet capture filtering and packet thinning in hardware and sub-_sec time precision in traffic generation and capture, corrected using an external GPS device. Furthermore, it provides a software APIs to test the dataplane performance of multi-10G switches, providing a starting point for a number of different test cases. OSNT flexibility is further demonstrated through the OFLOPS-turbo platform: An integration of OSNT with the OFLOPS OpenFlow switch performance evaluation plat- form, enabling control and data plane evaluation of 10G switches. This demo showcases the applicability of the OSNT platform to evaluate the performance of legacy and OpenFlow- enabled networking devices, and demonstrates it using commercial switches. © 2015 ACM.",High-performance; NetFPGA; Network testing; OpenFlow; OSNT; SDN,Convolutional codes; Field programmable gate arrays (FPGA); Open source software; Open systems; High-performance; NetFPGA; Network Monitoring; Networking devices; Openflow; Openflow switches; OSNT; Traffic generation; Software testing
"Sherry J., Lan C., Popa R.A., Ratnasamy S.",4,BlindBox: Deep packet inspection over encrypted traffic,2015,78,"UC Berkeley, United States; ETH Zurich UC Berkeley, Switzerland",ETH Zurich;University of California Berkeley,2,Switzerland;USA,2,3,3,"Many network middleboxes perform deep packet inspection (DPI), a set of useful tasks which examine packet payloads. These tasks include intrusion detection (IDS), exfiltration detection, and parental filtering. However, a long-standing issue is that once packets are sent over HTTPS, middleboxes can no longer accomplish their tasks because the payloads are encrypted. Hence, one is faced with the choice of only one of two desirable properties: The functionality of middleboxes and the privacy of encryption. We propose BlindBox, the first system that simultaneously provides both of these properties. The approach of Blind- Box is to perform the deep-packet inspection directly on the encrypted traffic. BlindBox realizes this approach through a new protocol and new encryption schemes. We demonstrate that BlindBox enables applications such as IDS, exfiltration detection and parental filtering, and supports real rulesets from both open-source and industrial DPI systems. We implemented BlindBox and showed that it is practical for settings with long-lived HTTPS connections. Moreover, its core encryption scheme is 3-6 orders of magnitude faster than existing relevant cryptographic schemes. © 2015 ACM.",Middlebox privacy; Network privacy; Searchable encryption,Convolutional codes; HTTP; Inspection; Intrusion detection; Open systems; Packet networks; Cryptographic schemes; Deep packet inspection; Deep packet inspection (DPI); Encryption schemes; Middleboxes; Network privacy; Orders of magnitude; Searchable encryptions; Cryptography
"Sonkoly B., Czentye J., Szabo R., Jocha D., Elek J., Sahhaf S., Tavernier W., Risso F.",8,Multi-domain service orchestration over networks and clouds: A unified approach,2015,22,"Budapest University of Technology and Economics, Hungary; Ericsson Research, Hungary; Ghent University - IMinds, Belgium; Politecnico di Torino, Italy",Budapest University of Technology and Economics;Ericsson Research;Ghent University,3,Belgium;Hungary;Italy,3,52,27,"End-to-end service delivery often includes transparently inserted Network Functions (NFs) in the path. Flexible service chaining will require dynamic instantiation of both NFs and traffic forwarding overlays. Virtualization techniques in compute and networking, like cloud and Software Defined Networking (SDN), promise such flexibility for service providers. However, patching together existing cloud and network control mechanisms necessarily puts one over the above, e.g., OpenDaylight under an OpenStack controller. We designed and implemented a joint cloud and network resource virtualization and programming API. In this demonstration, we show that our abstraction is capable for flexible service chaining control over any technology domains. © 2015 ACM.",Multi-domain orchestration; NFV; SDN; SFC control plane,Application programming interfaces (API); Convolutional codes; Flight control systems; Virtual reality; Control planes; End-to-end service; Multi domains; Network functions; Service orchestration; Software defined networking (SDN); Technology domain; Virtualization Techniques; Distributed computer systems
"Kheirkhah M., Wakeman I., Parisis G.",3,Short vs. long flows: A battle that both can win,2015,3,"School of Engineering and Informatics, University of Sussex, United Kingdom",University of Sussex,1,UK,1,2,2,"In this paper, we introduce MMPTCP, a novel transport protocol which aims at unifying the way data is transported in data centres. MMPTCP runs in two phases; initially, it randomly scatters packets in the network under a single congestion window exploiting all available paths. This is beneficial to latency-sensitive flows. During the second phase, MMPTCP runs in Multi-Path TCP (MPTCP) mode, which has been shown to be very efficient for long flows. Initial evaluation shows that our approach significantly improves short ow completion times while providing high through- put for long flows and high overall network utilisation. © 2015 ACM.",Data center; Multi-path TCP; Ns-3; Packet scatter,Convolutional codes; All available paths; Completion time; Congestion window; Data centers; Multipaths; Overall networks; Sensitive flow; Transport protocols; Transmission control protocol
"Yuan Z., Xue Y., Van Der Schaar M.",3,BitMiner: Bits mining in internet traffic classification,2015,3,"Department of Automation, Tsinghua University, Beijing, China; Department of Electrical Engineering, UCLA, Los Angeles, CA, United States; Tsinghua National Lab for Information Science and Technology, Beijing, China; Research Institute of Information Technology, Tsinghua University, Beijing, China",Tsinghua University,1,China;USA,2,9,7,"Traditionally, signatures used for traffic classification are constructed at the byte-level. However, as more and more data-transfer formats of network protocols and applications are encoded at the bit-level, byte-level signatures are losing their effectiveness in traffic classification. In this poster, we creatively construct bit-level signatures by associating the bit-values with their bit-positions in each traffic flow. Furthermore, we present BitMiner, an automated traffic mining tool that can mine application signatures at the most fine-grained bit-level granularity. Our preliminary test on popular peer-to-peer (P2P) applications, e.g. Skype, Google Hangouts, PPTV, eMule, Xunlei and QQDownload, reveals that although they all have no byte-level signatures, there are significant bit-level signatures hidden in their traffic. © 2015 ACM.",Bit-level signatures; Bits mining; Traffic classification,Convolutional codes; Data transfer; Network protocols; Peer to peer networks; Application signatures; Bit level; Data transfer format; Fine grained; Internet traffic classifications; Peer-to-peer application; Traffic classification; Traffic flow; Telecommunication traffic
"Ren X., Ananthanarayanan G., Wierman A., Yu M.",4,Hopper: Decentralized speculation-aware cluster scheduling at scale,2015,44,"California Institute of Technology, United States; Microsoft Research, United Kingdom; University of Southern California, United States",California Institute of Technology;Microsoft;University of Southern California,3,UK;USA,2,5,4,"As clusters continue to grow in size and complexity, providing scalable and predictable performance is an increasingly important challenge. A crucial roadblock to achieving predictable performance is stragglers, i.e., tasks that take significantly longer than expected to run. At this point, speculative execution has been widely adopted to mitigate the impact of stragglers. However, speculation mechanisms are designed and operated in- dependently of job scheduling when, in fact, scheduling a speculative copy of a task has a direct impact on the resources available for other jobs. In this work, we present Hopper, a job scheduler that is speculation- Aware, i.e., that integrates the tradeoffs associated with speculation into job scheduling decisions. We implement both centralized and decentralized prototypes of the Hopper scheduler and show that 50% (66%) improvements over state-of-the-art centralized (decentralized) schedulers and speculation strategies can be achieved through the coordination of scheduling and speculation. © 2015 ACM.",Decentralized scheduling; Fairness; Speculation; Straggler,Convolutional codes; Hoppers; Cluster scheduling; Decentralized scheduling; Fairness; Job scheduling; Speculation; Speculative execution; State of the art; Straggler; Scheduling
"Van Rijswijk-Deij R., Jonker M., Sperotto A., Pras A.",4,"The internet of names: A DNS big dataset: Actively measuring 50% of the entire DNS name space, every day",2015,4,"University of Twente, Netherlands; SURFnet bv, Netherlands",University of Twente,1,Netherlands,1,50,36,"The Domain Name System (DNS) is part of the core infrastructure of the Internet. Tracking changes in the DNS over time provides valuable information about the evolution of the Internet's infrastructure. Until now, only one large-scale approach to perform these kinds of measurements existed, passive DNS (pDNS). While pDNS is useful for applications like tracing security incidents, it does not provide suficient information to reliably track DNS changes over time. We use a complementary approach based on active measurements, which provides a unique, comprehensive dataset on the evolution of DNS over time. Our high-performance infrastructure performs Internet-scale active measurements, currently querying over 50% of the DNS name space on a daily basis. Our infrastructure is designed from the ground up to enable big data analysis approaches on, e.g., a Hadoop cluster. With this novel approach we aim for a quantum leap in DNS-based measurement and analysis of the Internet. © 2015 ACM.",Active measurements; Big data; DNS; Internet evolution,Big data; Convolutional codes; Internet; Active measurement; Analysis approach; Core infrastructure; Domain name system; Internet evolutions; Measurement and analysis; Quantum leaps; Security incident; Internet protocols
"Schlinker B., Mysore R.N., Smith S., Mogul J.C., Vahdat A., Yu M., Katz-Bassett E., Rubin M.",8,Condor: Better topologies through declarative design,2015,6,"Google, Inc., India; University of Southern California, United States",Google;University of Southern California,2,India;USA,2,1,0,"The design space for large, multipath datacenter networks is large and complex, and no one design fits all purposes. Network architects must trade off many criteria to design costeffective, reliable, and maintainable networks, and typically cannot explore much of the design space. We present Condor, our approach to enabling a rapid, efficient design cycle. Condor allows architects to express their requirements as constraints via a Topology Description Language (TDL), rather than having to directly specify network structures. Condor then uses constraint-based synthesis to rapidly generate candidate topologies, which can be analyzed against multiple criteria. We show that TDL supports concise descriptions of topologies such as fat-trees, BCube, and DCell; that we can generate known and novel variants of fat-trees with simple changes to a TDL file; and that we can synthesize large topologies in tens of seconds. We also show that Condor supports the daunting task of designing multi-phase network expansions that can be carried out on live networks. © 2015 ACM.",Expandable topologies; SLO compliance; Topology design,Complex networks; Convolutional codes; Design; Digital to analog conversion; Economic and social effects; Forestry; Candidate topologies; Data center networks; Description languages; Efficient designs; Network architects; Network structures; SLO compliance; Topology design; Topology
"Ballani H., Costa P., Gkantsidis C., Grosvenor M.P., Karagiannis .T., Koromilas L., O'shea G.",7,Enabling end-host network functions,2015,29,"Microsoft Research, Cambridge University, United Kingdom; University of Crete, Greece",University of Cambridge;Microsoft;University of Crete,3,Greece;UK,2,44,32,"Many network functions executed in modern datacenters, e.g., load balancing, application-level QoS, and congestion control, exhibit three common properties at the data plane: They need to access and modify state, to perform computations, and to access application semantics | this is critical since many network functions are best expressed in terms of application-level messages. In this paper, we argue that the end hosts are a natural enforcement point for these functions and we present Eden, an architecture for implementing network functions at end hosts with minimal network support. Eden comprises three components, a centralized controller, an enclave at each end host, and Eden-compliant applications called stages. To implement network functions, the controller configures stages to classify their data into messages and the enclaves to apply action functions based on a packet's class. Our Eden prototype includes enclaves implemented both in the OS kernel and on programmable NICs. Through case studies, we show how application-level classification and the ability to run actual programs on the data-path allows Eden to efficiently support a broad range of network functions at the network's edge. © 2015 ACM.",Data-plane programming; Network functions; Network management; SDN; Software defined networking,Application programs; Convolutional codes; Network management; Semantics; Software defined networking; Transfer functions; Access applications; Application level; Centralized controllers; Common property; Data planes; Minimal networks; Network functions; Three component; Information management
"Burnett S., Feamster N.",2,Encore: Lightweight measurement of web censorship with cross-origin requests,2015,18,"School of Computer Science, Georgia Tech, United States; Department of Computer Science, Princeton, United States",Georgia Tech,1,USA,1,65,54,"Despite the pervasiveness of Internet censorship, we have scant data on its extent, mechanisms, and evolution. Measuring censorship is challenging: it requires continual measurement of reachability to many target sites from diverse vantage points. Amassing suitable vantage points for longitudinal measurement is difficult; existing systems have achieved only small, short-lived deployments. We observe, however, that most Internet users access content via Web browsers, and the very nature of Web site design allows browsers to make requests to domains with different origins than the main Web page. We present Encore, a system that harnesses crossorigin requests to measure Web filtering from a diverse set of vantage points without requiring users to install custom software, enabling longitudinal measurements from many vantage points. We explain how Encore induces Web clients to perform cross-origin requests that measure Web filtering, design a distributed platform for scheduling and collecting these measurements, show the feasibility of a global-scale deployment with a pilot study and an analysis of potentially censoredWeb content, identify several cases of filtering in six months of measurements, and discuss ethical concerns that would arise with widespread deployment.",Network measurement; Web censorship; Web security,Convolutional codes; Internet; Websites; World Wide Web; Different origins; Distributed platforms; Ethical concerns; Existing systems; Internet censorship; Network measurement; Web censorship; WEB security; Web browsers
"Jang K., Sherry J., Ballani H., Moncaster T.",4,Silo: Predictable message latency in the cloud,2015,39,"Intel Labs, Santa Clara, CA, United States; UC Berkeley, Berkeley, CA, United States; Microsoft Research, Cambridge, United Kingdom; University of Cambridge, Cambridge, United Kingdom",Microsoft;University of California Berkeley;University of Cambridge,3,UK;USA,2,47,27,"Many cloud applications can benefit from guaranteed latency for their network messages, however providing such predictability is hard, especially in multi-tenant datacenters.We identify three key requirements for such predictability: guaranteed network bandwidth, guaranteed packet delay and guaranteed burst allowance. We present Silo, a system that offers these guarantees in multi-tenant datacenters. Silo leverages the tight coupling between bandwidth and delay: controlling tenant bandwidth leads to deterministic bounds on network queuing delay. Silo builds upon network calculus to place tenant VMs with competing requirements such that they can coexist. A novel hypervisor-based policing mechanism achieves packet pacing at sub-microsecond granularity, ensuring tenants do not exceed their allowances. We have implemented a Silo prototype comprising a VM placement manager and a Windows filter driver. Silo does not require any changes to applications, guest OSes or network switches. We show that Silo can ensure predictable message latency for cloud applications while imposing low overhead. © 2015 ACM.",Guaranteed latency; Latency SLA; Network calculus; Network QOS; Traffic pacing,Bandwidth; Calculations; Convolutional codes; Cloud applications; Competing requirements; Guaranteed latency; Latency SLA; Network bandwidth; Network calculus; Network QoS; Network queuing delays; Quality of service
"Hartert R., Vissicchio S., Schaus P., Bonaventure O., Filsfils C., Telkamp T., Francois P.",7,A declarative and expressive approach to control forwarding paths in carrier-grade networks,2015,47,"UniversitŽ Catholique de Louvain, Belgium; Cisco Systems, Inc., Belgium; IMDEA Networks Institute, Belgium",Cisco;IMDEA Networks;Universite Catholique de Louvain,3,Belgium,1,21,17,"SDN simplifies network management by relying on declarativity (high-level interface) and expressiveness (network flexibility). We propose a solution to sup- port those features while preserving high robustness and scalability as needed in carrier-grade networks. Our solution is based on (i) a two-layer architecture separating connectivity and optimization tasks; and (ii) a centralized optimizer called DEFO, which translates high-level goals expressed almost in natural language into com- pliant network configurations. Our evaluation on real and synthetic topologies shows that DEFO improves the state of the art by (i) achieving better trade offs for classic goals covered by previous works, (ii) supporting a larger set of goals (refined traffic engineering and service chaining), and (iii) optimizing large ISP networks in few seconds. We also quantify the gains of our implementation, running Segment Routing on top of IS-IS, over possible alternatives (RSVP-TE and OpenFlow). ©2015 ACM.",ISP; MPLS; Optimization; SDN; Segment routing; Service chaining; Traffic engineering,Convolutional codes; Economic and social effects; High level languages; Network management; Optimization; High level interface; MPLS; Network configuration; Network flexibility; Segment routing; Service chaining; Synthetic topology; Traffic Engineering; Internet service providers
"Zaki Y., Pštsch T., Chen J., Subramanian L., Gšrg C.",5,Adaptive congestion control for unpredictable cellular networks,2015,30,"NYU Abu Dhabi, Abu Dhabi, United Arab Emirates; University of Bremen, Bremen, Germany; NYU and CTED, New York, United States",NYU Abu Dhabi;NYU;University of Bremen,3,Germany;United Arab Emirates;USA,3,64,41,"Legacy congestion controls including TCP and its variants are known to perform poorly over cellular networks due to highly variable capacities over short time scales, self inicted packet delays, and packet losses unrelated to congestion. To cope with these challenges, we present Verus, an end-to-end congestion control protocol that uses delay measurements to react quickly to the capacity changes in cellular networks without explicitly attempting to predict the cellular channel dynamics. The key idea of Verus is to continuously learn a delay profile that captures the relationship between end-to-end packet delay and outstanding window size over short epochs and uses this relationship to increment or decrement the window size based on the observed short-term packet delay variations. While the delay-based control is primarily for congestion avoidance, Verus uses standard TCP features including multiplicative decrease upon packet loss and slow start. Through a combination of simulations, empirical evaluations using cellular network traces, and real-world evaluations against standard TCP avors and state of the art protocols like Sprout, we show that Verus outperforms these protocols in cellular channels. In comparison to TCP Cubic, Verus achieves an order of magnitude (> 10x) reduction in delay over 3G and LTE networks while achieving comparable throughput (some- Times marginally higher). In comparison to Sprout, Verus achieves up to 30% higher throughput in rapidly changing cellular networks. © 2015 ACM.",Cellular network; Congestion control; Delay-based; Transport protocol,Congestion control (communication); Convolutional codes; Mobile telecommunication systems; Packet loss; Packet networks; Transmission control protocol; Wireless networks; Wireless telecommunication systems; Adaptive congestion control; Cellular network; Delay-based; End-to-end congestion control; Multiplicative decrease; Packet delay variation; State-of-the art protocols; Transport protocols; Adaptive control systems
"LŽvai T., Pelle I., NŽmeth F., Guly‡s A.",4,EPOXIDE: A modular prototype for SDN troubleshooting,2015,5,"HSN Lab, Budapest University of Technology and Economics, Hungary",Budapest University of Technology and Economics,1,Hungary,1,62,44,"SDN opens a new chapter in network troubleshooting as be- sides misconfigurations and firmware/hardware errors, soft- ware bugs can occur all over the SDN stack. As an answer to this challenge the networking community developed a wealth of piecemeal SDN troubleshooting tools aiming to track down misconfigurations or bugs of a specific nature (e.g. in a given SDN layer). In this demonstration we present EPOXIDE, an Emacs based modular framework, which can effectively combine existing network and software troubleshooting tools in a single platform and defines a possible way of integrated SDN troubleshooting. © 2015 ACM.",Debugging; Emacs; Network troubleshooting; SDN,Computer debugging; Firmware; Emacs; Misconfigurations; Modular framework; Network troubleshooting; Networking community; Single platform; Specific nature; Troubleshooting tools; Convolutional codes
"Blond S.L., Choffnes D., Caldwell W., Druschel P., Merritt N.",5,"Herd: A scalable, traffic analysis resistant anonymity network for VoIP systems",2015,13,"MPI-SWS, United States; Northeastern University, United States",Northeastern University,1,USA,1,35,19,"Effectively anonymizing Voice-over-IP (VoIP) calls requires a scalable anonymity network that is resilient to traffic analysis and has sufficiently low delay for high-quality voice calls. The popular Tor anonymity network, for instance, is not designed for the former and cannot typically achieve the latter. In this paper, we present the design, implementation, and experimental evaluation of Herd, an anonymity network where a set of dedicated, fully interconnected cloud-based proxies yield suitably low-delay circuits, while untrusted superpeers add scalability. Herd provides caller/callee anonymity among the clients within a trust zone (e.g., jurisdiction) and under a strong adversarial model. Simulations based on a trace of 370 million mobile phone calls among 10:8 million users indicate that Herd achieves anonymity among millions of clients with low bandwidth requirements, and that superpeers decrease the bandwidth and CPU requirements of the trusted infrastructure by an order of magnitude. Finally, experiments using a prototype deployment on Amazon EC2 show that Herd has a delay low enough for high-quality calls in most cases. © 2015 ACM.",Anonymity networks; Intersection attacks; Strong anonymity; Voice-over-IP,Bandwidth; Convolutional codes; Delay circuits; Internet telephony; Networks (circuits); Voice/data communication systems; Anonymity networks; Experimental evaluation; Intersection attacks; Mobile phone calls; Prototype deployment; Strong anonymity; Traffic analysis; Voice over IP; Quality control
"Singh A., Ong J., Agarwal A., Anderson G., Armistead A., Bannon R., Boving S., Desai G., Felderman B., Germano P., Kanagala A., Provost J., Simmons J., Tanda E., Wanderer J., Hšlzle U., Stuart S., Vahdat A.",18,Jupiter rising: A decade of clos topologies and centralized control in acenter network,2015,198,"Google, Inc., India",Google,1,India,1,2,1,"We present our approach for overcoming the cost, operational complexity, and limited scale endemic to datacenter networks a decade ago. Three themes unify the five generations of datacenter networks detailed in this paper. First, multi-stage Clos topologies built from commodity switch silicon can support cost-effective de- ployment of building-scale networks. Second, much of the general, but complex, decentralized network routing and management protocols supporting arbitrary deployment scenarios were overkill for single-operator, pre-planned datacenter networks. We built a centralized control mechanism based on a global configuration pushed to all datacenter switches. Third, modular hardware design coupled with simple, robust soft- ware allowed our design to also support inter-cluster and wide-area networks. Our datacenter networks run at dozens of sites across the planet, scaling in capacity by 100x over ten years to more than 1Pbps of bisection bandwidth. © 2015 ACM.",Centralized control and management; Clos topology; Datacenter networks; Merchant silicon,Complex networks; Convolutional codes; Cost effectiveness; Integrated control; Topology; Bisection bandwidth; Centralized control; Data center networks; Decentralized networks; Deployment scenarios; Global configuration; Management protocols; Operational complexity; Wide area networks
"Asai H., Ohara Y.",2,Poptrie: A compressed trie with population count for fast and scalable software IP routing table lookup,2015,20,"University of Tokyo, Japan; NTT Communications Corporation, Japan",University of Tokyo,1,Japan,1,47,22,"Internet of Things leads to routing table explosion. An inexpensive approach for IP routing table lookup is required against ever growing size of the Internet. We con- Tribute by a fast and scalable software routing lookup algorithm based on a multiway trie, called Poptrie. Named after our approach to traversing the tree, it leverages the population count instruction on bit-vector indices for the descendant nodes to compress the data structure within the CPU cache. Poptrie outperforms the state-of-the-art technologies, Tree BitMap, DXR and SAIL, in all of the evaluations using random and real destination queries on 35 routing tables, including the real global tier-1 ISP's full-route routing table. Poptrie peaks between 174 and over 240 Million lookups per second (Mlps) with a single core and tables with 500{ 800k routes, consistently 4{578% faster than all competing algorithms in all the tests we ran. We provide the comprehensive performance evaluation, remarkably with the CPU cycle analysis. This paper shows the suitability of Poptrie in the future Internet including IPv6, where a larger route table is expected with longer prefixes. © 2015 ACM.",IP routing table lookup; Longest prefix match; Trie,Convolutional codes; Data compression; Forestry; Internet; Internet protocols; Internet service providers; Population statistics; Telecommunication networks; Trees (mathematics); Competing algorithms; Comprehensive performance evaluation; Future internet; IP routing; Longest prefix matches; Software routing; State-of-the-art technology; Trie; Table lookup
"Lantz B., O'connor B.",2,A mininet-based virtual testbed for distributed SDN development,2015,12,"Open Networking Laboratory, Menlo Park, CA, United States",Open Networking Laboratory,1,USA,1,24,18,"The need for fault tolerance and scalability is leading to the development of distributed SDN operating systems and applications. But how can you develop such systems and applications reliably without access to an expensive testbed? We continue to observe SDN development practices using full system virtualization or heavyweight containers, increasing complexity and overhead while decreasing usability. We demonstrate a simpler and more efficient approach: using Mininet's cluster mode to easily deploy a virtual testbed of lightweight containers on a single machine, an ad hoc cluster, or a dedicated hardware testbed. By adding an open source, distributed network operating system such as ONOS, we can create a flexible and scalable open source development platform for distributed SDN system and application software development. © 2015 ACM.",Container based emulation; Distributed systems; Mininet; Network OS; SDN; Software defined networking,Application programs; Complex networks; Containers; Convolutional codes; Fault tolerance; Fault tolerant computer systems; Open source software; Software defined networking; Software design; Testbeds; Dedicated hardware; Development practices; Distributed networks; Distributed systems; Mininet; Open source development; System virtualization; Virtual test beds; Open systems
"Pirzada H.A., Mahboob M.R., Qazi I.A.",3,eSDN: Rethinking datacenter transports using end-host SDN controllers,2015,2,"Computer Science Department, SBA School of Science and Engineering, LUMS, Pakistan",LUMS,1,Pakistan,1,39,18,We propose eSDN; a practical approach for deploying new datacenter transports without requiring any changes to the switches. eSDN uses light-weight SDN controllers at the end-hosts for querying network state. It obviates the need for statistics collection by a centralized controller especially on short timescales. We show that eSDN can scale well and allow a range of datacenter transports to be realized. © 2015 ACM.,Datacenters; SDN; Transport protocols,Convolutional codes; Centralized controllers; Data centers; Datacenter; Light weight; Network state; Time-scales; Transport protocols; Controllers
"WŠhlisch M., Schmidt T.C.",2,See How ISPs Care: An RPKI validation extension for web browsers,2015,1,"Freie UniversitŠt Berlin, Germany; HAW Hamburg, Germany",Freie UniversitŠt Berlin,1,Germany,1,7,5,"The Resource Public Key Infrastructure (RPKI) allows BGP routers to verify the origin AS of an IP prefix. In this demo, we present a software extension which performs prefix origin validation in the web browser of end users. The browser extension shows the RPKI validation outcome of the web server infrastructure for the requested web domain. It fol- lows the common plug-in concepts and does not require special modifications of the browser software. It operates on live data and helps end users as well as operators to gain better insight into the Internet security landscape. © 2015 ACM.",BGP; Deployment; RPKI; Secure inter-domain routing; Web,Convolutional codes; Internet service providers; Public key cryptography; Routers; World Wide Web; Deployment; End users; Internet security; Public key infrastructure; RPKI; Secure inter-domain routing; Web domains; Web servers; Web browsers
"Pu Q., Ananthanarayanan G., Kandula P.B., Kandula S., Akella A., Bahl P., Stoica I.",7,Low latency geo-distributed data analytics,2015,72,"Microsoft Research, United Kingdom; University of California at Berkeley, United States; University of Wisconsin at Madison, United States",Microsoft;University of California Berkeley;;University of Wisconsin-Madison,4,UK;USA,2,7,0,"Low latency analytics on geographically distributed datasets (across datacenters, edge clusters) is an upcoming and increasingly important challenge. The dominant approach of aggregating all the data to a single data- center significantly inates the timeliness of analytics. At the same time, running queries over geo-distributed inputs using the current intra-DC analytics frameworks also leads to high query response times because these frameworks cannot cope with the relatively low and variable capacity of WAN links. We present Iridium, a system for low latency geo-distributed analytics. Iridium achieves low query response times by optimizing placement of both data and tasks of the queries. The joint data and task placement optimization, however, is intractable. Therefore, Iridium uses an online heuristic to redistribute datasets among the sites prior to queries' arrivals, and places the tasks to reduce network bottlenecks during the query's execution. Finally, it also contains a knob to budget WAN usage. Evaluation across eight worldwide EC2 re- gions using production queries show that Iridium speeds up queries by 3_ ø19_ and lowers WAN usage by 15% ø 64% compared to existing baselines. © 2015 ACM.",Data analytics; Geo-distributed; Low latency; Network aware; Wan analytics,Budget control; Convolutional codes; Iridium; Optimization; Data analytics; Distributed data analytics; Geo-distributed; Low latency; Network bottlenecks; Network-aware; Placement optimization; Variable capacity; Wide area networks
"He K., Rozner E., Agarwal K., Felter W., Carter J., Akella A.",6,Presto: Edge-based load balancing for fast datacenter networks,2015,73,"University of Wisconsin-Madison, United States; IBM Research, United States",IBM;;University of Wisconsin-Madison,3,USA,1,7,6,"Datacenter networks deal with a variety of workloads, ranging from latency-sensitive small flows to bandwidth-hungry large flows. Load balancing schemes based on flow hashing, e.g., ECMP, cause congestion when hash collisions occur and can perform poorly in asymmetric topologies. Recent proposals to load balance the network require centralized traffic engineering, multipath-aware transport, or expensive specialized hardware. We propose a mechanism that avoids these limitations by (i) pushing load-balancing functionality into the soft network edge (e.g., virtual switches) such that no changes are required in the transport layer, customer VMs, or networking hardware, and (ii) load balancing on fine-grained, near-uniform units of data (flowcells) that fit within end-host segment offload optimizations used to support fast networking speeds. We design and implement such a soft-edge load balancing scheme, called Presto, and evaluate it on a 10 Gbps physical testbed. We demonstrate the computational impact of packet reordering on receivers and propose a mechanism to handle reordering in the TCP receive offload functionality. Presto's performance closely tracks that of a single, non-blocking switch over many workloads and is adaptive to failures and topology asymmetry. © 2015 ACM.",Load balancing; Software-defined networking,Convolutional codes; Hardware; Reconfigurable hardware; Resource allocation; Software defined networking; Topology; Centralized traffic; Data center networks; Design and implements; Load-balancing schemes; Packet reordering; Physical testbeds; Specialized hardware; Transport layers; Network management
"Jeong S.H., Kang A.R., Kim H.K.",3,Analysis of game Bot's behavioral characteristics in social interaction networks of MMORPG,2015,2,"Korea University, Seoul, South Korea",Korea University,1,South Korea,1,62,44,"MMORPG (MassivelyMultiplayer Online Role-Playing Game) is one of the best platforms to observe human's behaviors. In collaboration with a leading online game company, NCSoft, we can observe all behaviors in a large-scale of commercialized MMORPG. Especially, we analyzed the behavioral differences between game bots and human users. We categorized the five groups, Bot-Bot, Bot-All, Human-Human, Human-All and All-All, and we observe the characteristics of six social interaction networks for each group. As a re- sult, we found that there are significant differences in social behaviors between game bots and human. © 2015 ACM.",Game bot; Massively multiplayer online game; Social network analysis,Convolutional codes; Distributed computer systems; Interactive computer graphics; Internet; Social networking (online); Social sciences; Behavioral characteristics; Game bots; Massively multi-player online games; Massively-multiplayer; On-line games; Role-playing game; Social behavior; Social interactions; Behavioral research
"Durairajan R., Barford P., Sommers J., Willinger W.",4,InterTubes: A study of the us long-haul fiber-optic infrastructure,2015,17,"University of Wisconsin Madison, United States; ComScore, Inc., United States; Colgate University, United States; NIKSUN, Inc, United States",Colgate University;ComScore Inc.;;University of Wisconsin-Madison,4,USA,1,65,47,"The complexity and enormous costs of installing new longhaul fiber-optic infrastructure has led to a significant amount of infrastructure sharing in previously installed conduits. In this paper, we study the characteristics and implications of infrastructure sharing by analyzing the long-haul fiber-optic network in the US. We start by using fiber maps provided by tier-1 ISPs and major cable providers to construct a map of the long-haul US fiber-optic infrastructure. We also rely on previously underutilized data sources in the form of public records from federal, state, and municipal agencies to improve the fidelity of our map. We quantify the resulting map's1 connectivity characteristics and confirm a clear correspondence between long-haul fiber-optic, roadway, and railway infrastructures. Next, we examine the prevalence of high-risk links by mapping end-to-end paths resulting from large-scale traceroute campaigns onto our fiber-optic infrastructure map. We show how both risk and latency (i.e., propagation delay) can be reduced by deploying new links along previously unused transportation corridors and rights-of-way. In particular, focusing on a subset of high-risk links is sufficient to improve the overall robustness of the network to failures. Finally, we discuss the implications of our findings on issues related to performance, net neutrality, and policy decision-making. © 2015 ACM.",Long-haul fiber map; Risk mitigation; Shared risk,Complex networks; Convolutional codes; Decision making; Fiber optic networks; Fibers; Internet service providers; Railroad transportation; Infrastructure sharing; Long haul; Municipal agencies; Policy decisions; Propagation delays; Railway infrastructure; Risk mitigation; Transportation corridors; Fiber optics
"Zhu Y., Kang N., Cao J., Greenberg A., Lu G., Mahajan R., Maltz D., Yuan L., Zhang M., Zhao B.Y., Zheng H.",11,Packet-level telemetry in large datacenter networks,2015,52,"Microsoft, China; U.C. Santa Barbara, United States; Princeton University, United States",Princeton University;Microsoft,2,China;USA,2,3,3,"Debugging faults in complex networks often requires capturing and analyzing traffic at the packet level. In this task, datacenter networks (DCNs) present unique challenges with their scale, traffic volume, and diversity of faults. To troubleshoot faults in a timely manner, DCN administratorsmust a) identify affected packets inside large volume of traffic; b) track them across multiple network components; c) analyze traffic traces for fault patterns; and d) test or confirm potential causes. To our knowledge, no tool today can achieve both the specificity and scale required for this task. We present Everflow, a packet-level network telemetry system for large DCNs. Everflow traces specific packets by implementing a powerful packet filter on top of ""match and mirror"" functionality of commodity switches. It shuffles captured packets to multiple analysis servers using load balancers built on switch ASICs, and it sends ""guided probes"" to test or confirm potential faults. We present experiments that demonstrate Everflow's scalability, and share experiences of troubleshooting network faults gathered from running it for over 6 months in Microsoft's DCNs. © 2015 ACM.",Datacenter network; Failure detection; Probe,Convolutional codes; Probes; Telemetering equipment; Analysis server; Commodity switches; Data center networks; Failure detection; Potential faults; Telemetry systems; Traffic volumes; Troubleshooting networks; Complex networks
"Guo C., Yuan L., Xiang D., Dang Y., Huang R., Maltz D., Liu Z., Wang V., Pang B., Chen H., Lin Z.-W., Kurien V.",12,Pingmesh: A Large-scale system for data center network latency measurement and analysis,2015,74,"Microsoft, China; Midfin Systems, United States",Microsoft,1,China;USA,2,108,34,"Can we get network latency between any two servers at any time in large-scale data center networks? The collected latency data can then be used to address a series of challenges: Telling if an application perceived latency issue is caused by the network or not, defining and tracking network service level agreement (SLA), and automatic network troubleshooting. We have developed the Pingmesh system for largescale data center network latency measurement and analysis to answer the above question affirmatively. Pingmesh has been running in Microsoft data centers for more than four years, and it collects tens of terabytes of latency data per day. Pingmesh is widely used by not only network software developers and engineers, but also application and service developers and operators. © 2015 ACM.",Data center networking; Network troubleshooting; Silent packet drops,Application programs; Convolutional codes; Automatic networks; Data center networkings; Data center networks; Network troubleshooting; Packet drops; Service developers; Software developer; Tracking networks; Large scale systems
"Vissicchio S., Tilmans O., Vanbever L., Rexford J.",4,Central control over distributed routing,2015,61,"UniversitŽ Catholique de Louvain, Belgium; ETH Zurich, Switzerland; Princeton University, United States",ETH Zurich;Princeton University;Universite Catholique de Louvain,3,Belgium;Switzerland;USA,3,36,29,"Centralizing routing decisions offers tremendous flexibility, but sacrifices the robustness of distributed protocols. In this paper, we present Fibbing, an architecture that achieves both flexibility and robustness through central control over distributed routing. Fibbing introduces fake nodes and links into an underlying link- state routing protocol, so that routers compute their own forwarding tables based on the augmented topology. Fibbing is expressive, and readily supports flexible load balancing, trafic engineering, and backup routes. Based on high-level forwarding requirements, the Fibbing controller computes a compact augmented topology and injects the fake components through standard routing-protocol messages. Fibbing works with any unmodified routers speaking OSPF. Our experiments also show that it can scale to large networks with many forwarding requirements, introduces minimal overhead, and quickly reacts to network and controller failures. © 2015 ACM.",Fibbing; Link-state routing; SDN,Convolutional codes; Network management; Robustness (control systems); Routers; Routing protocols; Topology; Controller failure; Distributed protocols; Distributed routing; Fibbing; Forwarding tables; Link State Routing protocol; Link-state routing; Routing decisions; Controllers
"Mittal R., Lam V.T., Dukkipati N., Blem E., Wassel H., Ghobadi M., Vahdat A., Wang Y., Wetherall D., Zats D.",10,TIMELY: RTT-based congestion control for the datacenter,2015,85,"UC Berkeley, United States; Microsoft, China; Google Inc., United States",Google;Microsoft;University of California Berkeley,3,China;USA,2,25,19,"Datacenter transports aim to deliver low latency messaging together with high throughput. We show that simple packet delay, measured as round-trip times at hosts, is an effective congestion signal without the need for switch feedback. First, we show that advances in NIC hardware have made RTT measurement possible with microsecond accuracy, and that these RTTs are sufficient to estimate switch queueing. Then we describe how TIMELY can adjust transmission rates using RTT gradients to keep packet latency low while delivering high bandwidth. We implement our design in host software running over NICs with OS-bypass capabilities. We show using experiments with up to hundreds of machines on a Clos network topology that it provides excellent performance: Turning on TIMELY for OS-bypass messaging over a fabric with PFC lowers 99 percentile tail latency by 9X while maintaining near line-rate throughput. Our system also outperforms DCTCP running in an optimized kernel, reducing tail latency by 13X. To the best of our knowledge, TIMELY is the first delay-based congestion control protocol for use in the datacenter, and it achieves its results despite having an order of magnitude fewer RTT signals (due to NIC offload) than earlier delay-based schemes such as Vegas. © 2015 ACM.",Datacenter transport; Delay-based congestion control; Osbypass; Rdma,Convolutional codes; Negative impedance converters; Telecommunication networks; Datacenter; Delay-based congestion control; Microsecond accuracy; Osbypass; Packet latencies; Rdma; RTT measurements; Transmission rates; Switching networks
"Yau S., Ge L., Hsieh P.-C., Hou I.-H., Cui S., Kumar P.R., Ekbal A., Kundargi N.",8,WiMAC: Rapid implementation platform for user definable MAC protocols through separation,2015,3,"Texas a and M University, United States; National Instruments, United States",Texas A and M University,1,USA,1,42,24,"This demo presentsWiMAC, a general-purpose wireless testbed for researchers to quickly prototype a wide variety of real-time MAC protocols for wireless networks. As the interface between the link layer and the physical layer, MAC protocols are often tightly coupled with the underlying physical layer, and need to have extremely small latencies. Implementing a new MAC requires a long time. In fact, very few MACs have ever been implemented, even though dozens of new MAC protocols have been proposed. To enable quick prototyping, we employ the mechanism vs. policy separation to decompose the functionality in the MAC layer and the PHY layer. Built on the separation framework, WiMAC achieves the independence of the software from the hardware, offering a high degree of function reuse and design flexibility. Hence, our platform not only supports easy cross-layer design but also allows protocol changes on the fly. Following the 802.11-like reference design, we demonstrate that deploying a new MAC protocol is quick and simple on the proposed platform through the implementation of the CSMA/CA and CHAIN protocols. © 2015 ACM.",Mac; Software-defined radio; Wireless testbed,Carrier sense multiple access; Computer software reusability; Convolutional codes; Embedded systems; Network layers; Separation; Software radio; Testbeds; Wireless networks; Cross-layer design; Design flexibility; Implementation platforms; Physical layers; Reference designs; Software-defined radios; Tightly-coupled; Wireless testbed; Medium access control
"Bao J., Dong D., Zhao B., Luo Z., Wu C., Gong Z.",6,FlyCast: Free-space optics accelerating multicast communications in physical layer,2015,9,"College of Computer, National University of Defense Technology Changsha, Hunan, China",National University of Defense Technology,1,China,1,48,12,"In this paper, we propose FlyCast, an architecture using the physical layer of free-space optics (FSO) to accelerate multicast communication. FlyCast leverages off-the-shelf devices (e.g. switchable mirror, beam splitter) to physically split the FSO beam to multi receivers on demand, which enables to build dynamical multicast trees in physical layer and accelerates multicast communications. We demonstrate the feasibility of FlyCast through our theoretical analysis and the proof-of-concept prototype. © 2015 ACM.",Data center network; Free space optics; Multicast,Convolutional codes; Network layers; Space optics; Data center networks; Free space optics; Multicast communication; Multicast tree; Off-the-shelf devices; Physical layers; Proof of concept; Switchable mirrors; Multicasting
"Zheng L., Joe-Wong C., Tan C.W., Chiang M., Wang X.",5,How to bid the cloud,2015,61,"Princeton University, United States; National University of Singapore, Singapore; University of Hong Kong, Hong Kong",National University of Singapore;Princeton University;University of Hong Kong,3,Hong Kong;Singapore;USA,3,6,6,"Amazon's Elastic Compute Cloud (EC2) uses auction-based spot pricing to sell spare capacity, allowing users to bid for cloud resources at a highly reduced rate. Amazon sets the spot price dynamically and accepts user bids above this price. Jobs with lower bids (including those already running) are interrupted and must wait for a lower spot price before resuming. Spot pricing thus raises two basic questions: how might the provider set the price, and what prices should users bid? Computing users' bidding strategies is particularly challenging: higher bid prices reduce the probability of, and thus extra time to recover from, interruptions, but may increase users' cost. We address these questions in three steps: (1) modeling the cloud provider's setting of the spot price and matching the model to historically offered prices, (2) deriving optimal bidding strategies for different job requirements and interruption overheads, and (3) adapting these strategies to MapReduce jobs with master and slave nodes having different interruption overheads. We run our strategies on EC2 for a variety of job sizes and instance types, showing that spot pricing reduces user cost by 90% with a modest increase in completion time compared to on-demand pricing. © 2015 ACM.",Cloud pricing; Optimization; Spot instance,Convolutional codes; Cost reduction; Optimization; Bidding strategy; Cloud providers; Completion time; Elastic compute clouds; Optimal bidding strategy; Spare capacity; Spot instances; Spot pricing; Costs
"Naylor D., Schomp K., Varvello M., Leontiadis I., Blackburn J., Lopez D., Papagiannaki K., Rodriguez P.R., Steenkiste P.",9,Multi-context TLS (mcTLS): Enabling secure in-network functionality in TLS,2015,41,"Carnegie Mellon University, United States; Case Western Reserve University, United States; Telef—nica Research, Spain",Carnegie Mellon University;Case Western Reserve University;Telefonica Research,3,Spain;USA,2,4,4,"A significant fraction of Internet trafic is now encrypted and HTTPS will likely be the default in HTTP/2. How- ever, Transport Layer Security (TLS), the standard protocol for encryption in the Internet, assumes that all functionality resides at the endpoints, making it impossible to use in-network services that optimize network resource usage, improve user experience, and protect clients and servers from security threats. Re-introducing in-network functionality into TLS sessions today is done through hacks, often weakening overall security. In this paper we introduce multi-context TLS (mcTLS), which extends TLS to support middleboxes. mcTLS breaks the current ""all-or-nothing""security model by al- lowing endpoints and content providers to explicitly in- Troduce middleboxes in secure end-to-end sessions while controlling which parts of the data they can read or write. We evaluate a prototype mcTLS implementation in both controlled and ""live"" experiments, showing that its benefits come at the cost of minimal overhead. More importantly, we show that mcTLS can be incrementally deployed and requires only small changes to client, server, and middlebox software. © 2015 ACM.",HTTPS; SSL; TLS,Convolutional codes; Cryptography; HTTP; Internet; Internet protocols; Network protocols; Seebeck effect; Thallium; Content providers; HTTPS; In-network services; Network resource; Security threats; Standard protocols; Transport layer security; User experience; Network security
"Abari O., Vasisht D., Katabi D., Chandrakasan A.",4,Caraoke: An E-Toll transponder network for smart cities,2015,19,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,40,33,"Electronic toll collection transponders, e.g., E-ZPass, are a widely-used wireless technology. About 70% to 89% of the cars in US have these devices, and some states plan to make them mandatory. As wireless devices however, they lack a basic function: A MAC protocol that prevents collisions. Hence, today, they can be queried only with directional antennas in isolated spots. However, if one could interact with e-toll transponders anywhere in the city despite collisions, it would enable many smart applications. For example, the city can query the transponders to estimate the vehicle flow at every intersection. It can also localize the cars using their wireless signals, and detect those that run a redlight. The same infrastructure can also deliver smart streetparking, where a user parks anywhere on the street, the city localizes his car, and automatically charges his account. This paper presents Caraoke, a networked system for delivering smart services using e-toll transponders. Our design operates with existing unmodified transponders, allowing for applications that communicate with, localize, and count transponders, despite wireless collisions. To do so, Caraoke exploits the structure of the transponders' signal and its properties in the frequency domain. We built Caraoke reader into a small PCB that harvests solar energy and can be easily deployed on street lamps. We also evaluated Caraoke on four streets on our campus and demonstrated its capabilities. © 2015 ACM.",Active RFID; Electronic toll collection (ETC); Rf localization; Smart city; Wireless,Convolutional codes; Directive antennas; Frequency domain analysis; Medium access control; Polychlorinated biphenyls; Radio; Solar energy; Toll collection; Toll highways; Wireless telecommunication systems; Active RFID; Directional Antenna; Electronic toll collection; Networked systems; Rf localization; Smart applications; Smart cities; Wireless technologies; Transponders
"Zhou D., Fan B., Lim H., Andersen D.G., Kaminsky M., Mitzenmacher M., Wang R., Singh A.",8,Scaling up clustered network appliances with scalebricks,2015,13,"Carnegie Mellon University, United States; Intel Labs, United States; Harvard University, United States; Connectem, Inc., United States",Harvard University;Carnegie Mellon University;Connectem Inc.,3,USA,1,38,29,"This paper presents ScaleBricks, a new design for building scalable, clustered network appliances that must ""pin"" flow state to a specific handling node without being able to choose which node that should be. ScaleBricks applies a new, compact lookup structure to route packets directly to the appropriate handling node, without incurring the cost of multiple hops across the internal interconnect. Its lookup structure is many times smaller than the alternative approach of fully replicating a forwarding table onto all nodes. As a result, ScaleBricks is able to improve throughput and latency while simultaneously increasing the total number of flows that can be handled by such a cluster. This architecture is effective in practice: Used to optimize packet forwarding in an existing commercial LTE-to-Internet gateway, it increases the throughput of a four-node cluster by 23%, reduces latency by up to 10%, saves memory, and stores up to 5.7x more entries in the forwarding table. © 2015 ACM.",Hashing algorithms; Network function virtualization; Scalability,Cluster computing; Convolutional codes; Scalability; Clustered networks; Forwarding tables; Hashing algorithms; Internet gateway; Lookup structures; Multiple hops; Packet forwarding; Virtualizations; Gateways (computer networks)
"Schulz-Zander J., Mayer C., Ciobotaru B., Schmid S., Feldmann A., Riggio R.",6,Programming the home and enterprise WiFi with openSDWN,2015,2,"TU Berlin, Berlin, Germany; Deutsche Telekom Innovation, Laboratories / TU Berlin, Berlin, Germany; CREATE-NET, Trento, Italy",TU Berlin,1,Germany;Italy,2,64,36,"The quickly growing demand for wireless networks and the numerous application-specific requirements stand in stark contrast to today's inflexible management and operation of WiFi networks. In this paper, we present and evaluate OPENSDWN, a novel WiFi architecture based on an SDN/NFV approach. OPENSDWN exploits datapath programmability to enable service differentiation and fine-grained transmission control, facilitating the prioritization of critical applications. OPENSDWN implements per-client virtual access points and per-client virtual middleboxes, to render network functions more flexible and support mobility and seamless migration. OPENSDWN can also be used to out-source the control over the home network to a participatory interface or to an Internet Service Provider. © 2015 ACM.",Enterprise WLANs; Network function virtualization; Programmable RAN; Software-defined networking; Wi-Fi,Convolutional codes; Home networks; Internet; Internet service providers; Personal communication systems; Software defined networking; Transfer functions; Application specific requirements; Critical applications; Enterprise wlans; Programmable RAN; Service differentiation; Transmission control; Virtualizations; Wi-Fi architecture; Wi-Fi
"Konte M., Perdisci R., Feamster N.",3,ASwatch: An as reputation system to expose bulletproof hosting aSes,2015,13,"Georgia Tech, United States; University of Georgia, United States; Princeton University, United States",Georgia Tech;Princeton University;University of Georgia,3,USA,1,34,19,"Bulletproof hosting Autonomous Systems (ASes)-malicious ASes fully dedicated to supporting cybercrime-provide freedom and resources for a cyber-criminal to operate. Their services include hosting a wide range of illegal content, botnet C&C servers, and other malicious resources. Thousands of new ASes are registered every year, many of which are often used exclusively to facilitate cybercrime. A natural approach to squelching bulletproof hosting ASes is to develop a reputation system that can identify them for takedown by law enforcement and as input to other attack detection systems (e.g., spam filters, botnet detection systems). Unfortunately, current AS reputation systems rely primarily on data-plane monitoring of malicious activity from IP addresses (and thus can only detect malicious ASes after attacks are underway), and are not able to distinguish between malicious and legitimate but abused ASes. As a complement to these systems, in this paper, we explore a fundamentally different approach to establishing AS reputation. We present ASwatch, a system that identifies malicious ASes using exclusively the control-plane (i.e., routing) behavior of ASes. ASwatch's design is based on the intuition that, in an attempt to evade possible detection and remediation efforts, malicious ASes exhibit ""agile"" control plane behavior (e.g., short-lived routes, aggressive re-wiring). We evaluate our system on known malicious ASes; our results show that ASwatch detects up to 93% of malicious ASes with a 5% false positive rate, which is reasonable to effectively complement existing defense systems. © 2015 ACM.",As reputation; Bulletproof hosting; Malicious networks,Computer crime; Convolutional codes; Crime; Textiles; Attack detection; Autonomous systems; Botnet detections; Bulletproof hosting; False positive rates; Malicious activities; Natural approaches; Reputation systems; Malware
"Wu H., Li J., Zhi J.",3,Could end system caching and cooperation replace in-network caching in CCN?,2015,2,"Computer Network Information Center, Chinese Academy of Sciences, Beijing, 100190, China",Chinese Academy of Sciences,1,China,1,3,1,"CCN has been witnessed as a promising future Internet architecture. In-network caching has been paid much attention, but there is still no consensus on its usage, due to its non-negligible costs. Meanwhile, massive storage and bandwidth resources of end systems still remain underutilized. To this end, we present an End System Caching and Cooperation scheme in CCN, called ESCC to realize content distribution of CCN, without using costly innetwork caching. ESCC enables fast content distribution through clients caching and sharing contents with each other. Experiments show that ESCC can achieve better performance than the universal caching. It is also quite simple, efficient, robust and has low overhead. ESCC could be a candidate substitute for the costly and unnecessary universal caching. © 2015 ACM.",Caching; CCN; Cooperation; End system,Convolutional codes; Bandwidth resource; Caching; Content distribution; Cooperation; End systems; Future internet architecture; Low overhead; Massive storages; Digital storage
"Nan G., Qiao X., Tu Y., Tan W., Guo L., Chen J.",6,Design and implementation: The native web browser and server for content-centric networking,2015,1,"State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China; China IBM T.J. Watson Research Center, Yorktown Heights, NY  10598, United States",IBM;Beijing University of Posts and Telecommunications,2,China;USA,2,40,29,"Content-Centric Networking (CCN) has recently emerged as a clean-slate Future Internet architecture which has a completely different communication pattern compared with exiting IP network. Since the World Wide Web has become one of the most popular and important applications on the Internet, how to efiectively support the dominant browser and server based web applications is a key to the success of CCN. However, the existing web browsers and servers are mainly designed for the HTTP protocol over TCP/IP networks and cannot directly support CCN-based web applications. Existing research mainly focuses on plug-in or proxy/gateway approaches at client and server sides, and these schemes seriously impact the service performance due to multiple protocol conversions. To address above problems, we designed and implemented a CCN web browser and a CCN web server to natively support CCN protocol. To facilitate the smooth evolution from IP networks to CC- N, CCNBrowser and CCNxTomcat also support the HTTP protocol besides the CCN. Experimental results show that CCNBrowser and CCNxTomcat outperform existing implementations. Finally, a real CCN-based web application is deployed on a CCN experimental testbed, which validates the applicability of CCNBrowser and CCNxTomcat. © 2015 ACM.",Content-centric networking; Web browser; Web server,Convolutional codes; HTTP; Hypertext systems; Internet; Network architecture; Transmission control protocol; Web browsers; Web services; World Wide Web; Communication pattern; Content-centric networkings; Design and implementations; Experimental testbed; Future internet architecture; Protocol conversion; Service performance; Web servers; Internet protocols
"Bogdanov K., Pe—n-Quir—s M., Maguire G.Q., Kosti_ D.",4,Toward automated testing of geo-distributed replica selection algorithms,2015,0,"KTH Royal Institute of Technology, Sweden; University Complutense of Madrid (UCM), Spain",KTH Royal Institute of Technology;University Complutense of Madrid (UCM),2,Spain;Sweden,2,7,6,"Many geo-distributed systems rely on a replica selection algorithms to communicate with the closest set of replicas. Unfortunately, the bursty nature of the Internet trafic and ever changing network conditions present a problem in identifying the best choices of replicas. Suboptimal replica choices result in increased response latency and reduced system performance. In this work we present GeoPerf, a tool that tries to automate testing of geo-distributed replica selection algorithms. We used GeoPerf to test Cassandra and MongoDB, two popular data stores, and found bugs in each of these systems. © 2015 ACM.",Replica selection algorithms; Symbolic execution,Convolutional codes; Program debugging; Automated testing; Best choice; Cassandras; Distributed systems; Network condition; Reduced systems; Replica selections; Symbolic execution; Algorithms
"Szab— D., NŽmeth F., Sonkoly B., Guly‡s A., Fitzek F.H.P.",5,Owards the 5G revolution: A Software defined network architecture exploiting network coding as a service,2015,14,"HSN Lab, Budapest Univ. of Technology and Economics, Hungary; 5G Lab Germany, Technische UniversitŠt Dresden, Germany",TU Dresden,1,Germany;Hungary,2,5,5,"Many networking visioners agree that 5G will be much more than the incremental improvement, in terms of data rate, of 4G. Besides the mobile networks, 5G will fundamentally influence the core infrastructure as well. In our vision the realization of the challenging promises of 5G (e.g. extremely fast, low-overhead, low-delay access of mostly cloudified services and content) will require the massive use of multi-pathing equipped with low overhead transport solutions tailored to fast, reliable and secure data retrieval from cloud architectures. In this demo we present a prototype architecture supporting such services by making use of automatically configured multipath service chains implementing network coding based transport solutions over off-the-shelf software defined networking (SDN) components. © 2015 ACM.",A SDN; Mininet; Network coding; NFV,Codes (symbols); Convolutional codes; Network coding; Software defined networking; Cloud architectures; Core infrastructure; Incremental improvements; Mininet; Prototype architecture; Service chain; Software defined networking (SDN); Transport solution; Network architecture
"Chowdhury M., Stoica I.",2,Efficient coflow scheduling without prior knowledge,2015,86,"UC Berkeley, United States",University of California Berkeley,1,USA,1,8,3,"Inter-coflow scheduling improves application-level communication performance in data-parallel clusters. However, existing efficient schedulers require a priori coflow information and ignore cluster dynamics like pipelining, task failures, and speculative executions, which limit their applicability. Schedulers without prior knowledge compromise on performance to avoid head-of-line blocking. In this paper, we present Aalo that strikes a balance and efficiently schedules coflows without prior knowledge. Aalo employs Discretized Coflow-Aware Least-Attained Service (D-CLAS) to separate coflows into a small number of priority queues based on how much they have already sent across the cluster. By performing prioritization across queues and by scheduling coflows in the FIFO order within each queue, Aalo's non-clairvoyant scheduler reduces coflow completion times while guaranteeing starvation freedom. EC2 deployments and trace-driven simulations show that communication stages complete 1:93 faster on average and 3:59 faster at the 95th percentile using Aalo in comparison to per-flow mechanisms. Aalo's performance is comparable to that of solutions using prior knowledge, and Aalo outperforms them in presence of cluster dynamics. © 2015 ACM.",Coflow; Data-intensive applications; Datacenter networks,Convolutional codes; Queueing theory; Co-flow; Communication performance; Data center networks; Data-intensive application; Head of line blocking; Least attained service; Speculative execution; Trace driven simulation; Scheduling
"Howard H., Crowcroft J.",2,Coracle: Evaluating consensus at the internet edge,2015,1,"University of Cambridge, United Kingdom",University of Cambridge,1,UK,1,4,3,"Distributed consensus is fundamental in distributed systems for achieving fault-tolerance. The Paxos algorithm has long dominated this domain, although it has been recently challenged by algorithms such as Raft and Viewstamped Replication Revisited. These algorithms rely on Paxos's original assumptions, unfortunately these assumptions are now at odds with the reality of the modern internet. Our insight is that cur- rent consensus algorithms have significant availability issues when deployed outside the well defined context of the data- center. To illustrate this problem, we developed Coracle, a tool for evaluating distributed consensus algorithms in settings that more accurately represent realistic deployments. We have used Coracle to test two examples of network configurations that contradict the liveness claims of the Raft algorithm. Through the process of exercising these algorithms under more realistic assumptions, we demonstrate wider availability issues faced by consensus algorithms when deployed on real world networks. © 2015 ACM.",Dependable systems; Distributed consensus; Fault-tolerance,Convolutional codes; Fault tolerance; Fault tolerant computer systems; Internet; Consensus algorithms; Data centers; Dependable systems; Distributed consensus; Distributed systems; Network configuration; Paxos algorithms; Real-world networks; Algorithms
"Peuster M., Karl H.",2,An architecture for energy-aware on-demand mobile network management,2015,1,"University of Paderborn, Germany",University of Paderborn,1,Germany,1,52,38,"The increasing amount of mobile traffic leads to a significantly higher energy consumption of mobile networks that is mainly caused by the high number of required base stations. One recent solution for this is based on a two-layered network that uses long-range macro cells to provide a full coverage signaling overlay and short-range small cells for fast data transmissions. These small cells can be switched off when they are not needed and allow network-wide energy optimizations. This paper presents an architecture that extends existing mobile networks to integrate a small cell layer that supports on-demand cell activation. We discuss how additional small cells can be interconnected with existing core components and how they can be controlled by a resource management component. Finally, a Wi-Fi based proof of concept testbed implementation is presented that demonstrates the feasibility of the approach. © 2015 ACM.",Cell-switching; HetNet; MPTCP; Small cells; Testbed,Cells; Cytology; Energy utilization; Mobile telecommunication systems; Network architecture; Network layers; Network management; Power management; Power management (telecommunication); Testbeds; Wireless networks; Cell switching; Energy optimization; Fast data transmission; HetNet; MPTCP; Proof of concept; Resource management; Small cells; Cell signaling
"Marina M.K., Radu V., Balampekos K.",3,Impact of indoor-outdoor context on crowdsourcing based mobile coverage analysis,2015,4,"University of Edinburgh, United Kingdom; Nokia Networks, South Korea",University of Edinburgh,1,South Korea;UK,2,5,2,"We consider the crowdsourcing based mobile cellular network measurement paradigm that is becoming increasingly popular. In particular, we aim to study the impact of user indoor/outdoor environment context at time of measurement. Focusing on signal strength as the measurement metric and using a real large crowdsourced measurement dataset for central London area along with estimated environment state (indoor or outdoor), we show that indoor-outdoor context has a significant impact, suggesting that conflating indoor and outdoor measurements can lead to unreliable results. We validate these observations using a set of diverse and controlled measurements with indoor/outdoor ground truth information. We also discuss some opportunities for future work (e.g., accurate and efficient context detection) relevant to crowdsourced mobile network measurement systems. © 2015 ACM.",Cellular coverage; Crowdsourced mobile network measurement; Indoor-outdoor environment context,Crowdsourcing; Wireless networks; Cellular coverage; Context detection; Environment state; Mobile cellular networks; Network measurement; Network measurement systems; Outdoor environment; Outdoor measurements; Mobile telecommunication systems
"Naveen K.P., Massoulie L., Baccelli E., Viana A.C., Towsley D.",5,On the interaction between content caching and request assignment in cellular cache networks,2015,13,"INRIA Saclay, Campus de l'Ecole Polytechnique, Palaiseau, 91120, France; MSR, INRIA, Campus de l'Ecole Polytechnique, Palaiseau, 91120, France; Dept. of Computer Science, University of Massachusetts, Amherst, MA  01003, United States",INRIA;University of Massachusetts Amherst,2,France;USA,2,14,13,"The potential availability of storage space at cellular and femtocell base-stations (BSs) raises the following question: How should one optimize performance through both load balancing and content replication when requests can be sent to several such BSs? We formally introduce an optimization model to address this question and propose an online algorithm for dynamic caching and request assignment. Crucially our request assignment scheme is based on a server price signal that jointly reflects content and bandwidth availability. We prove that our algorithm is optimal and stable in a limiting regime that is obtained by scaling the arrival rates and content chunking. From an implementation standpoint, guided by the online algorithm we design a lightweight scheme for request assignments that is based on load and cache-miss cost signals; for cache replacements, we propose to use the popular LRU (Least Recently Used) strategy. Through simulations, we exhibit the efficacy of our joint-price based request assignment strategy in comparison to the common practices of assigning requests purely based on either bandwidth availability or content availability. © 2015 ACM.",Cellular cache networks; Fluid approximations; LRU caches; Lyapunov stability; Online algorithm,Algorithms; Approximation algorithms; Bandwidth; Costs; Network management; Telecommunication networks; Cache networks; Fluid approximation; LRU caches; Lyapunov stability; On-line algorithms; Optimization
"Casas P., Schatz R., Wamser F., Seufert M., Irmer R.",5,Exploring QoE in cellular networks: How much bandwidth do you need for popular smartphone apps?,2015,12,"FTW, Vienna, Austria; University of WŸrzburg, Germany; Vodafone Research and Development, United Kingdom",University of Wurzburg;Vodafone,2,Austria;Germany;UK,3,23,19,"A quarter of the world population will be using smartphones to access the Internet in the near future. In this context, understanding the Quality of Experience (QoE) of popular services in such devices becomes paramount for cellular network operators, who need to offer high quality levels to reduce the risks of customers churning for quality dissatisfaction. In this paper we study the problem of QoE provisioning in smartphones, presenting the results obtained from subjective lab tests performed for five popular apps: YouTube, Facebook, Web browsing through Chrome, Google Maps, and WhatsApp. The analysis addresses the impact of the access downlink bandwidth on the QoE of these apps when accessed through smartphones. The results presented in this paper provide a sound basis for better understanding the QoE requirements of popular services and mobile apps, as well as for dimensioning the underlying provisioning network. To the best of our knowledge, this is the first paper providing such a comprehensive analysis of QoE in mobile devices. © 2015 ACM.",Mobile apps; QoE; Smartphones; Subjective lab tests,Bandwidth; Mobile devices; Mobile telecommunication systems; Smartphones; Websites; Wireless networks; Cellular network; Comprehensive analysis; Google maps; High quality; Mobile apps; Quality of experience (QoE); Smartphone apps; World population; Quality of service
"Wang K., Banerjee A., Shen M., Van Der Merwe J., Cho J., Webb K.",6,MobiScud: A fast moving personal cloud in the mobile network,2015,20,"School of Computing, University of Utah, United States",University of Utah,1,USA,1,19,9,"We present MOBISCUD, an evolutionary mobile network architecture that integrates cloud and SDN technologies into a standard mobile network in backwards compatible fashion. MOBISCUD enables personalized virtual machines to seamlessly ""follow"" mobile network users as they move around. © 2015 ACM..",Cloud computing; Mobile network; Service offloading; Software define networking (SDN),Cloud computing; Mobile telecommunication systems; Network architecture; Wireless networks; Personal clouds; Service offloading; Virtual machines; Distributed computer systems
"Bates A., Pletcher J., Nichols T., Hollembaek B., Butler K.R.B.",5,Forced perspectives: Evaluating an SSL trust enhancement at scale,2014,10,"University of Florida, United States; University of Oregon, United States; ISEC Partners, United States",University of Florida;University of Oregon,2,USA,1,23,21,"The certificate authority (CA) PKI system has been used for decades as a means of providing domain identity verification services throughout the Internet, but a growing body of ev- idence suggests that our trust in this system is misplaced. A recently proposed CA alternative, Convergence, extends the Network Perspectives system of multi-path probing to perform certificate verification. Unfortunately, adoption of Convergence and other SSL/TLS trust enhancements has been slow, in part because it is unknown how these systems perform against large workloads and realistic conditions. In this work we ask the question \What if all certificates were validated with Convergence?""We perform a case study of deploying Convergence under realistic workloads with a university-wide trace of real-world HTTPS activity. By syn- Thesizing Convergence requests, we effectively force perspect- ives-based verification on an entire university in simulation. We demonstrate that through local and server caching, a single Convergence deployment can meet the requirements of millions of SSL flows while imposing under 0.1% network overhead and requiring as little as 108 ms to validate a cer- Tificate, making Convergence a worthwhile candidate for fur- Ther deployment and adoption. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",HTTPS; Public-key certificates; SSL; TLS,Internet; Certificate authority; HTTPS; Identity verification; Network overhead; Public key certificates; Realistic conditions; SSL; TLS; HTTP
"Wu W., Demar P.",2,WireCAP: A novel packet capture engine for commodity NICs in high-speed networks,2014,3,"Fermilab BataviaIL, United States",Fermilab BataviaIL,1,USA,1,14,9,"Packet capture is an essential function for many network applications. However, packet drop is a major problem with packet capture in high-speed networks. This paper presents WireCAP, a novel packet capture engine for commodity network interface cards (NICs) in high-speed networks. WireCAP provides lossless zero-copy packet capture and delivery services by exploiting multi-queue NICs and multicore architectures. WireCAP introduces two new mechanisms-the ring-buffer-pool mechanism and the buddygroup- based offloading mechanism-to address the packet drop problem of packet capture in high-speed network. WireCAP is efficient. It also facilitates the design and operation of a userspace packet-processing application. Experiments have demonstrated that WireCAP achieves better packet capture performance when compared to existing packet capture engines. In addition, WireCAP implements a packet transmit function that allows captured packets to be forwarded, potentially after the packets are modified or inspected in flight. Therefore, WireCAP can be used to support middlebox-type applications. Thus, at a high level, WireCAP provides a new packet I/O framework for commodity NICs in high-speed networks. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Linux kernel; Multi-core system; Network packet capture,Computer operating systems; Drops; Engines; HIgh speed networks; Interfaces (computer); Packet loss; Software architecture; Design and operations; Linux kernel; Multi-core systems; Multicore architectures; Network applications; Network interface cards; Network packet capture; Processing applications; Speed
"Zhang L., Choffnes D., Levin D., Dumitra_ T., Mislove A., Schulman A., Wilson C.",7,Analysis of SSL certificate reissues and revocations in the wake of Heartbleed,2014,21,"Northeastern University, United States; University of Maryland, United States; Stanford University, United States",Northeastern University;Stanford University;University of Maryland College Park,3,USA,1,35,25,"Central to the secure operation of a public key infrastruc- Ture (PKI) is the ability to revoke certificates. While much of users' security rests on this process taking place quickly, in practice, revocation typically requires a human to decide to reissue a new certificate and revoke the old one. Thus, having a proper understanding of how often systems admin- istrators reissue and revoke certificates is crucial to under- standing the integrity of a PKI. Unfortunately, this is typi- cally difficult to measure: While it is relatively easy to deter- mine when a certificate is revoked, it is difficult to determine whether and when an administrator should have revoked. In this paper, we use a recent widespread security vul- nerability as a natural experiment. Publicly announced in April 2014, the Heartbleed OpenSSL bug, potentially (and undetectably) revealed servers' private keys. Administrators of servers that were susceptible to Heartbleed should have revoked their certificates and reissued new ones, ideally as soon as the vulnerability was publicly announced. Using a set of all certificates advertised by the Alexa Top 1 Million domains over a period of six months, we explore the patterns of reissuing and revoking certificates in the wake of Heartbleed. We find that over 73% of vulnerable certificates had yet to be reissued and over 87% had yet to be revoked three weeks after Heartbleed was disclosed. Moreover, our results show a drastic decline in revocations on the weekends, even immediately following the Heartbleed announcement. These results are an important step in understanding the manual processes on which users rely for secure, authenti- cated communication. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Certificates; Extended validation; Heartbleed; HTTPS; Reissue; Revocation; SSL; TLS; X.509,HTTP; Certificates; Extended validation; Heartbleed; HTTPS; Reissue; Revocation; SSL; TLS; X.509; Wakes
"Deng S., Netravali R., Sivaraman A., Balakrishnan H.",4,"WiFi, LTE, or both? Measuring multi-homed wireless internet performance",2014,93,"MIT Computer Science and Artificial Intelligence Lab, Cambridge, MA, United States",MIT,1,USA,1,32,12,"Over the past two or three years, wireless cellular networks have become faster than before, most notably due to the deployment of LTE, HSPA+, and other similar networks. LTE throughputs can reach many megabits per second and can even rival WiFi throughputs in some locations. This paper addresses a fundamental question confronting transport and application-layer protocol designers: Which network should an application use? WiFi, LTE, or Multi-Path TCP (MPTCP) running over both? We compare LTE and WiFi for transfers of different sizes along both directions (i.e. the uplink and the downlink) using a crowdsourced mobile application run by 750 users over 180 days in 16 different countries. We find that LTE outperforms WiFi 40% of the time, which is a higher fraction than one might expect at first sight. We measure flow-level MPTCP performance and compare it with the performance of TCP running over exclusively WiFi or LTE in 20 different locations across 7 cities in the United States. For short flows, we find that MPTCP performs worse than regular TCP running over the faster link; further, selecting the correct network for the primary subflow in MPTCP is critical in achieving good performance. For long flows, however, selecting the proper MPTCP congestion control algorithm is equally important. To complement our flow-level analysis, we analyze the traffic patterns of several mobile apps, finding that apps can be categorized as ""short-flow dominated"" or ""long-flow dominated"". We then record and replay these patterns over emulatedWiFi and LTE links. We find that application performance has a similar dependence on the choice of networks as flow-level performance: An application dominated by short flows sees little gain from MPTCP, while an application with longer flows can benefit much more from MPTCP - if the application can pick the right network for the primary subflow and the right choice of MPTCP congestion control. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",LTE; Mobile device; Multi-network; Multi-path TCP,Algorithms; Internet; Mobile devices; Transmission control protocol; Application performance; Application-layer protocol; Flow-level performance; LTE; Mobile applications; Multi-path TCP; Record-and-replay; Wireless cellular networks; Wireless telecommunication systems
"Yu Z., Ge Z., Lall A., Wang J., Xu J., Yan H.",6,Crossroads: A practical data sketching solution for mining intersection of streams,2014,0,"Georgia Tech AtlantaGA, United States; AT and T Labs - Research, Florham Park, NJ, United States; Denison University, Granville, OH, United States",AT and T Labs;Denison University;Georgia Tech,3,USA,1,37,24,"The explosive increase in cellular network traffic, users, and applications, as well as the corresponding shifts in user ex- pectations, has created heavy needs and demands on cellular data providers. In this paper we address one such need: Min- ing the logs of cellular voice and data traffic to rapidly detect network performance anomalies and other events of interest. The core challenge in solving this problem is the issue that it is impossible to predict beforehand where in the traffic the event may appear, requiring us to be able to query arbitrary subsets of the network traffic (e.g., longer than usual round- Trip times for users in a specific urban area to connect to FunContent.com using a particular model of phone). Since it is infeasible to store all combinations of such data, espe- cially when it is collected in real-time, we need to be able to summarize the traffic data using succinct sketch data struc- Tures to answer these queries. The major contribution of this paper is the introduction of a scheme, called Crossroads, that can be used to compute the intersection of the measurements between two overlap- ping streams. For instance, in the above example, it is pos- sible to compute the intersection of all the data going be- Tween the downtown area and FunContent.com with all the data generated by the model of phone to detect anomalous RTT behavior. In effect, this gives us a way to essentially \square root"" the number of sketches that we need to main- Tain, transforming a prohibitively expensive problem to one that is tractable in practice. We provide rigorous analysis of our sketch and the trade-offs between memory footprint and accuracy. We also demonstrate the efficacy of our solution via simulation on data collected at a major cellular service carrier in the US. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Algorithms; Data streaming; Traffic analysis,Algorithms; Telephone sets; Arbitrary subsets; Cellular network traffics; Cellular services; Data streaming; Memory footprint; Performance anomaly; Rigorous analysis; Traffic analysis; Query processing
"Tune P., Veitch D.",2,OFSS: Skampling for the flow size distribution,2014,1,"School of Mathematical Sciences, University of Adelaide, Australia; Melbourne School of Engineering, University of Melbourne, Australia",University of Adelaide;University of Melbourne,2,Australia,1,22,15,"We introduce a new method for ow size estimation, the Op- Timised Flow Sampled Sketch, which combines the optimal properties of Flow Sampling with the computational advan- Tages of a counter array sketch. Using Fisher Information as a definitive basis of comparison, we show that it is superior to alternatives in both model and traffic based comparisons. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Fisher information; Network measure- ment; OFSS; Ow size distribution; Skampling,Fisher information matrix; Counter arrays; Fisher information; Flow sampling; Network measures; OFSS; Optimal properties; Size estimation; Skampling; Size distribution
"Van Rijswijk-Deij R., Sperotto A., Pras A.",3,DNSSEC and its potential for DDoS attacks: A comprehensive measurement study,2014,34,"SURFnet Bv, University of Twente, United States; University of Twente, United States",University of Twente,1,USA,1,26,20,"Over the past five years we have witnessed the introduction of DNSSEC, a security extension to the DNS that relies on digital signatures. DNSSEC strengthens DNS by preventing attacks such as cache poisoning. However, a common argument against the deployment of DNSSEC is its potential for abuse in Distributed Denial of Service (DDoS) attacks, in particular reflection and amplification attacks. DNS responses for a DNSSEC-signed domain are typically larger than those for an unsigned domain, thus, it may seem that DNSSEC could actually worsen the problem of DNS-based DDoS attacks. The potential for abuse in DNSSEC-signed domains has, however, never been assessed on a large scale. In this paper we establish ground truth around this open question. We perform a detailed measurement on a large dataset of DNSSEC-signed domains, covering 70% (2:5 million) of all signed domains in operation today, and compare the potential for amplification attacks to a representative sample of domains without DNSSEC. At first glance, the outcome of these measurements confirms that DNSSEC indeed worsens the DDoS phenomenon. Closer examination, however, gives a more nuanced picture. DNSSEC really only makes the situation worse for one particular query type (ANY), for which responses may be over 50 times larger than the original query (and in rare cases up to 179 ). We also discuss a number of mitigation strategies that can have immediate impact for operators and suggest future research directions with regards to these mitigation strategies. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Amplification attack; Attack; DDoS; Denial-of-service; DNS; DNSSEC; Measurements; Reflection attack,Electronic document identification systems; Internet protocols; Intrusion detection; Measurements; Network security; Attack; DDoS; Denial of Service; DNS; DNSSEC; Reflection attacks; Denial-of-service attack
"Bischof Z.S., Bustamante F.E., Stanojevic R.",3,"Need, want, can afford - broadband markets and the behavior of users",2014,7,"Northwestern University, United States; Telefonica Research, United States",Northwestern University;Telefonica Research,2,USA,1,14,8,"We present the first study of broadband services in their broader context, evaluating the impact of service character- istics (such as capacity, latency and loss), their broadband pricing and user demand. We explore these relationships, beyond correlation, with the application of natural experi- ments. Most efforts on broadband service characterization have so far focused on performance and availability, yet we lack a clear understanding of how such services are being utilized and how their use is impacted by the particulars of the market. By analyzing over 23-months of data collected from 53,000 end hosts and residential gateways in 160 countries, along with a global survey of retail broadband plans, we empirically study the relationship between broad- band service characteristics, pricing and demand. We show a strong correlation between capacity and demand, even though subscribers rarely fully utilize their links, but note a law of diminishing returns with relatively smaller increases in demand at higher capacities. Despite the fourfold increase in global IP traffic, we find that user demand on the network over a three year period remained constant for a given bandwidth capacity. We exploit natural experiments to examine the causality between these factors. The reported findings represent an important step towards understanding how user behavior, and the market features that shape it, affeect broadband networks and the Internet at large. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Broadband access networks; Causal infer- ence; Natural experiments; User behavior,Broadband networks; Commerce; Economics; Experiments; Internet; Surveys; Bandwidth capacity; Broad-band access networks; Causal infer- ence; Law of diminishing returns; Natural experiment; Residential gateways; Service characteristics; User behaviors; Behavioral research
"Hohlfeld O., Pujol E., Ciucu F., Feldmann A., Barford P.",5,A QoE perspective on sizing network buffers,2014,11,"RWTH Aachen University, Germany; TU Berlin, Germany; University of Warwick, United States; UW Madison, United States",RWTH Aachen University;TU Berlin;;University of Wisconsin-Madison;University of Warwick,5,Germany;USA,2,23,21,"Despite decades of operational experience and focused research efforts, standards for sizing and configuring buffers in network systems remain controversial. An extreme example of this is the recent claim that excessive buffering (i.e., bufferbloat) can severely impact Internet services. In this paper, we systematically examine the implications of buffer sizing choices from the perspective of factors impacting end user experience. To assess user perception of application quality under various buffer sizing schemes we employ Quality of Experience (QoE) metrics. We evaluate these metrics over a wide range of end-user applications (e.g., web browsing, VoIP, and RTP video streaming) and workloads in two realistic testbeds emulating access and backbone networks. The main finding of our extensive evaluations is that network workload, rather than buffer size, is the primary determinant of end user QoE. Our results also highlight the relatively narrow conditions under which bufferbloat seriously degrades QoE, i.e., when buffers are oversized and sustainably filled. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Buffer size; Bufferbloat; QoE,Internet; Internet telephony; Video streaming; Web browsers; Application quality; Buffer sizes; Bufferbloat; End-user applications; End-user experience; Operational experience; QoE; Quality of experience (QoE); Quality of service
"Wu H., Hsiao H.-C., Hu Y.-C.",3,Efficient large flow detection over arbitrary windows: An algorithm exact outside an ambiguity region,2014,4,"University of Illinois, Urbana-Champaign, United States; Carnegie Mellon University, National Taiwan University, Taiwan",Carnegie Mellon University;National Taiwan University;UIUC,3,Taiwan;USA,2,36,30,"Many networking and security applications can benefit from exact detection of large flows over arbitrary windows (i.e. any possible time window). Existing large flow detectors that only check the average throughput over certain time period cannot detect bursty flows and are therefore easily fooled by attackers. However, no scalable approaches pro- vide exact classification in one pass. To address this chal- lenge, we consider a new model of exactness outside an ambi- guity region, which is defined to be a range of bandwidths be- low a high-bandwidth threshold and above a low-bandwidth threshold. Given this new model, we propose a deterministic algorithm, EARDet, that detects all large flows (including bursty flows) and avoids false accusation against any small flows, regardless of the input traffic distribution. EARDet monitors flows over arbitrary time windows and is built on a frequent items finding algorithm based on average frequency. Despite its strong properties, EARDet has low storage over- head regardless of input traffic and is surprisingly scalable because it focuses on accurate classification of large flows and small flows only. Our evaluations confirm that existing approaches suffer from high error rates (e.g., misclassifying 1% of small flows as large flows) in the presence of large flows and bursty flows, whereas EARDet can accurately detect both at gigabit line rate using a small amount of memory that fits into on-chip SRAM. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Ambiguity region; Arbitrary windows; Flow classification; Large flow detection,Algorithms; Static random access storage; Vehicle routing; Ambiguity region; Average throughput; Deterministic algorithms; Finding algorithm; Flow classification; Flow detection; Gigabit line rates; Security application; Bandwidth
"Wang X.S., Krishnamurthy A., Wetherall D.",3,How much can we micro-cache web pages?,2014,11,"University of Washington, United States",University of Washington at Seattle,1,USA,1,49,37,"Browser caches are widely used to improve the performance of Web page loads. Unfortunately, current object-based caching is too coarse-grained to minimize the costs associ- Ated with small, localized updates to a Web object. In this paper, we evaluate the benefits if caching were performed at a finer granularity and at different levels (i.e., computed layout and compiled JavaScript). By analyzing Web pages gathered over two years, we find that both layout and code are highly cacheable, suggesting that our proposal can rad- ically reduce time to first paint. We also find that mobile pages are similar to their desktop counterparts in terms of the amount and composition of updates. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Caching; Micro-caching; Web applications; Web pages,Websites; Caching; Coarse-grained; Javascript; Micro-caching; Object based; Reduce time; WEB application; Web objects; Social networking (online)
"Luckie M., Dhamdhere A., Clark D., Huffaker B., Claffy K.",5,Challenges in inferring internet interdomain congestion,2014,19,"CAIDA, UC San Diego, United States; MIT, United States",MIT;University of California San Diego,2,USA,1,38,17,"We introduce and demonstrate the utility of a method to localize and quantify inter-domain congestion in the Internet. Our Time Sequence Latency Probes (TSLP) method depends on two facts: Internet traffic patterns are typically diurnal, and queues increase packet delay through a router during periods of adjacent link congestion. Repeated round trip delay measurements from a single test point to the two edges of a congested link will show sustained increased latency to the far (but not to the near) side of the link, a delay pattern that differs from the typical diurnal pattern of an uncongested link. We describe our technique and its surprising potential, carefully analyze the biggest challenge with the methodology (interdomain router-level topology inference), describe other less severe challenges, and present initial results that are sufficiently promising to motivate further attention to overcoming the challenges. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Interdomain congestion; Internet topology,Topology; Congested links; Diurnal pattern; Inter-domain; Internet topologies; Internet traffic patterns; Round trip delay; Time sequences; Topology inference; Internet
"Zander S., Andrew L.L.H., Armitage G.",3,Capturing ghosts: Predicting the used ipv4 space by inferring unobserved addresses,2014,9,"CAIA, Swinburne University of Technology Melbourne, Australia; Faculty of IT, Monash University Melbourne, Australia",Monash University;Swinburne University of Technology,2,Australia,1,21,12,"The pool of unused routable IPv4 prefixes is dwindling, with less than 4% remaining for allocation at the end of June 2014. Yet the adoption of IPv6 remains slow. We demonstrate a new capturerecapture technique for improved estimation of the size of ""IPv4 reserves"" (allocated yet unused IPv4 addresses or routable prefixes) from multiple incomplete data sources. A key contribution of our approach is the plausible estimation of both observed and unobserved-yet-active (ghost) IPv4 address space. This significantly improves our community's understanding of IPv4 address space exhaustion and likely pressure for IPv6 adoption. Using ""ping scans"", network traces and server logs we estimate that 6.3 million /24 subnets and 1.2 billion IPv4 addresses are currently in use (roughly 60% and 45% of the publicly routed space respectively). We also show how utilisation has changed over the last 2-3 years and provide an up-to-date estimate of potentially-usable remaining IPv4 space. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Capture-recapture; Used IPv4 space,Address space; Capture-recapture; Incomplete data; Server logs; Subnets; Used IPv4 space; Internet protocols
"Zarinni F., Chakraborty A., Sekar V., Das S.R., Gill P.",5,A first look at performance in mobile virtual network operators,2014,14,"Stony Brook University, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Stony Brook University,2,USA,1,39,33,"Recent industry trends suggest a new phenomenon in the mobile market: Mobile virtual network operators or MVNOs that operate on top of existing cellular infrastructures. While MVNOs have shown significant growth in the US and elsewhere in the past two years and have been successful in attracting customers, there is anecdotal evidence that users are concerned about cellular performance when choosing MVNOs over traditional cellular operators. In this paper, we present the first systematic measurement study to shed light on this emerging phenomenon. We study the performance of 3 key applications: Web access, video streaming and voice, in 2 popular MVNO families (a total of 8 carriers) in the US, where each MVNO family consists of a major base carrier and 3 MVNOs running on top of it. We observe that some MVNOs do indeed exhibit significant performance degradation and that there are key differences between the two MVNO families. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Applications; Cellular measurements; Cellular performance; Mobile measurements; Mobile performance; MVNO; QoE,Applications; Cellular performance; Mobile measurements; Mobile performance; MVNO; QoE; Video streaming
"Chen Q.A., Luo H., Rosen S., Mao Z.M., Iyer K., Hui J., Sontineni K., Lau K.",8,QoE doctor: Diagnosing mobile app QoE with automated UI control and cross-layer analysis,2014,39,"University of Michigan, United States; T-Mobile USA Inc., United States",T-Mobile USA Inc.;University of Michigan at Ann Arbor,2,USA,1,33,22,"Smartphones have become increasingly prevalent and important in our daily lives. To meet users' expectations about the Quality of Experience (QoE) of mobile applications (apps), it is essential to obtain a comprehensive understanding of app QoE and identify the critical factors that affect it. However, effectively and systematically studying the QoE of popular mobile apps such as Facebook and YouTube still remains a challenging task, largely due to a lack of a controlled and reproducible measurement methodology, and limited insight into the complex multi-layer dynamics of the system and network stacks. In this paper, we propose QoE Doctor, a tool that supports accurate, systematic, and repeatable measurements and analysis of mobile app QoE. QoE Doctor uses UI automation techniques to replay QoE-related user behavior, and measures the user-perceived latency directly from UI changes. To better understand and analyze QoE problems involving complex multi-layer interactions, QoE Doctor supports analysis across the application, transport, network, and cellular radio link layers to help identify the root causes. We implement QoE Doctor on Android, and systematically quantify various factors that impact app QoE, including the cellular radio link layer technology, carrier rate-limiting mechanisms, app design choices and user-side configuration options. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Cellular network; Cross-layer analysis; Mobile applications; Quality of experience (QoE); UI automation,Automation; Behavioral research; Complex networks; Mobile computing; Mobile telecommunication systems; Quality control; Radio links; Automation techniques; Cellular network; Configuration options; Critical factors; Cross-layer analysis; Measurement methodology; Mobile applications; Quality of experience (QoE); Quality of service
"Wang G., Wang B., Wang T., Nika A., Zheng H., Zhao B.Y.",6,Whispers in the dark: Analysis of an anonymous social network,2014,34,"Department of Computer Science, UC Santa Barbara, United States",University of California Santa Barbara,1,USA,1,39,30,"Social interactions and interpersonal communication has undergone significant changes in recent years. Increasing awareness of privacy issues and events such as the Snowden disclosures have led to the rapid growth of a new generation of anonymous social networks and messaging applications. By removing traditional concepts of strong identities and social links, these services encourage communication between strangers, and allow users to express themselves without fear of bullying or retaliation. Despite millions of users and billions of monthly page views, there is little empirical analysis of how services like Whisper have changed the shape and content of social interactions. In this paper, we present results of the first large-scale empirical study of an anonymous social network, using a complete 3-month trace of the Whisper network covering 24 million whispers written by more than 1 million unique users. We seek to understand how anonymity and the lack of social links affect user behavior. We analyze Whisper from a number of perspectives, including the structure of user interactions in the absence of persistent social links, user engagement and network stickiness over time, and content moderation in a network with minimal user accountability. Finally, we identify and test an attack that exposes Whisper users to detailed location tracking. We have notified Whisper and they have taken steps to address the problem. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Anonymous social networks; Graphs; Privacy; User engagement,Behavioral research; Data privacy; Social sciences; Empirical analysis; Empirical studies; Graphs; Inter-personal communications; Social interactions; User behaviors; User engagement; User interaction; Social networking (online)
"Quan L., Heidemann J., Pradkin Y.",3,When the internet sleeps: Correlating diurnal networks with external factors,2014,8,"Information Sciences Institute, USC, United States; Bank of China, China",University of Southern California,1,China;USA,2,48,38,"As the Internet matures, policy questions loom larger in its operation. When should an ISP, city, or government invest in infrastructure? How do their policies affect use? In this work, we develop a new approach to evaluate how policies, economic conditions and technology correlates with Internet use around the world. First, we develop an adaptive and ac- curate approach to estimate block availability, the fraction of active IP addresses in each /24 block over short timescales (every 11 minutes). Our estimator provides a new lens to in- Terpret data taken from existing long-term outage measure- ments, thus requiring no additional traffic. (If new collection was required, it would be lightweight, since on average, out- Age detection requires less than 20 probes per hour per /24 block; less than 1% of background radiation.) Second, we show that spectral analysis of this measure can identify diur- nal usage: blocks where addresses are regularly used during part of the day and idle in other times. Finally, we analyze data for the entire responsive Internet (3.7M /24 blocks) over 35 days. These global observations show when and where the Internet sleeps|networks are mostly always-on in the US and Western Europe, and diurnal in much of Asia, South America, and Eastern Europe. ANOVA (Analysis of Variance) testing shows that diurnal networks correlate negatively with country GDP and electrical consumption, quantifying that national policies and economics relate to networks. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Diurnal network usage; Internet; Internet reliability,Economics; Internet; Spectrum analysis; ANOVA (analysis of variance); Background radiation; Economic condition; Electrical consumption; Global observation; Internet reliabilities; National policies; Network usage; Internet service providers
"Chen Y.-C., Liao Y., Baldi M., Lee S.-J., Qiu L.",5,OS fingerprinting and tethering detection in mobile networks,2014,12,"University of Texas, Austin, United States; Narus Inc., United States",Narus Inc.;University of Texas at Austin,2,USA,1,44,38,"Fingerprinting the Operating System(OS) running on a device based on its traffic has several applications, such as NAT detection, policy enforcement in enterprise networks, and billing for shared access in mobile networks. In this paper, we propose to utilize several features in TCP/IP headers for OS identification, and use real traffic traces to evaluate the accuracy of fingerprinting. Our tracedriven study shows that several techniques that successfully fingerprint desktop OSes are not effective for fingerprinting mobile devices. Therefore, we propose new features for fingerprinting OSes on mobile devices. We also consider NAT/tethering detection, an important application of OS fingerprinting. We use the presence of multiple OSes from the same IP address along with TCP timestamp, clock frequency, and boot time to detect tethering. Evaluation shows that our approach effectively detects tethering and outperforms existing schemes. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",OS fingerprint; TCP/IP; Tethering detection,Internet protocols; Mobile devices; Wireless networks; Clock frequency; Enterprise networks; IP addresss; Policy enforcement; Real traffic; TCP/IP; TCP/IP headers; Tethering detections; Mobile telecommunication systems
"Richter P., Smaragdakis G., Feldmann A., Chatzis N., Boettger J., Willinger W.",6,Peering at peerings: On the role of IXP route servers,2014,15,"TU Berlin, Germany; MIT, TU Berlin, Germany; Niksun, Germany",MIT;TU Berlin,2,Germany,1,40,31,"During the last few years, more and more of the medium-to-large Internet eXchange Points (IXP) around the world have started to operate a route server and offer its use as a free value-added service to their members. This service has greatly simplified inter-domain routing for those members and has made it easy for them to peer with possibly hundreds of networks at those IXPs from the get-go. In this paper, we report on an empirical analysis that is based on a unique collection of IXP-provided datasets from two different European IXPs that operate a route server and gave us access to a wealth of route server-specific BGP data. Both IXPs also made the traffic datasets that they routinely collect from their public switching infrastructures available to us. Using this information, we perform a first-of-its-kind study that correlates a detailed control plane view with a rich data plane view to reason about the different peering options available at these IXPs and how some of the major Internet players make use of them. In the process, we highlight the important role that the IXPs' route servers play for inter-domain routing in today's Internet and demonstrate the benefits of studying IXP peerings in a manner that is not agnostic but fully aware of traffic. We conclude with a discussion of some of the ramifications of our findings for both network researchers and operators. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",BGP; Internet exchange point (IXP); Peering; Routing,Dense wavelength division multiplexing; BGP; Empirical analysis; Interdomain Routing; Internet exchange points; Internet players; Peering; Routing; Value added service; Internet
"Khattak S., Javed M., Khayam S.A., Uzmi Z.A., Paxson V.",5,A look at the consequences of internet censorship through an ISP lens,2014,10,"University of Cambridge, United Kingdom; UC Berkeley, United States; PLUMgrid, United States; LUMS SBASSE, United States; ICSI, United States",LUMS;University of California Berkeley;University of Cambridge,3,UK;USA,2,43,29,"Internet censorship artificially changes the dynamics of resource production and consumption, affecting a range of stakeholders that include end users, service providers, and content providers. We analyze two large-scale censorship events in Pakistan: blocking of pornographic content in 2011 and of YouTube in 2012. Using traffic datasets collected at home and SOHO networks before and after the censorship events, we: A) quantify the demand for blocked content, b) illuminate challenges encountered by service providers in implementing the censorship policies, c) investigate changes in user behavior (e.g., with respect to circumvention) after censorship, and d) assess benefits extracted by competing content providers of blocked content. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Censorship; Content blocking; ISP traffic; Porn; Video streaming,Behavioral research; Internet; Video streaming; Censorship; Content blocking; Content providers; Internet censorship; Porn; Production and consumption; Service provider; User behaviors; Internet service providers
"De Cristofaro E., Friedman A., Jourjon G., Kaafar M.A., Shafiq M.Z.",5,Paying for likes? Understanding facebook like fraud using honeypots,2014,30,"University Colege London, London, United Kingdom; NICTA, Sydney, Australia; NICTA, INRIA, Sydney, Australia; University of Iowa, Iowa City, IA, United States",INRIA;NICTA;University College London;University of Iowa,4,Australia;UK;USA,3,42,18,"Facebook pages offer an easy way to reach out to a very large audience as they can easily be promoted using Facebook's advertising platform. Recently, the number of likes of a Facebook page has become a measure of its popularity and profitability, and an underground market of services boosting page likes, aka like farms, has emerged. Some reports have suggested that like farms use a network of profiles that also like other pages to elude fraud protection algorithms, however, to the best of our knowledge, there has been no systematic analysis of Facebook pages' promotion methods. This paper presents a comparative measurement study of page likes garnered via Facebook ads and by a few like farms. We deploy a set of honeypot pages, promote them using both methods, and analyze garnered likes based on likers' demographic, temporal, and social characteristics. We highlight a few interesting findings, including that some farms seem to be operated by bots and do not really try to hide the nature of their operations, while others follow a stealthier approach, mimicking regular users' behavior. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Honeypots; Malicious activities; Online social networks,Crime; Online systems; Comparative measurements; Facebook pages; Honeypots; Malicious activities; On-line social networks; Protection algorithms; Systematic analysis; To a very large; Social networking (online)
"Durairajan R., Sommers J., Barford P.",3,Layer 1-informed internet topology measurement,2014,5,"University of Wisconsin-Madison, United States; Colgate University, United States",Colgate University;;University of Wisconsin-Madison,3,USA,1,45,44,"Understanding the Internet's topological structure continues to be fraught with challenges. In this paper, we investigate the hypothesis that physical maps of service provider infras- Tructure can be used to effectively guide topology discov- ery based on network layer TTL-limited measurement. The goal of our work is to focus layer 3-based probing on broadly identifying Internet infrastructure that has a fixed geographic location such as POPs, IXPs and other kinds of hosting fa- cilities. We begin by comparing more than 1.5 years of TTL- limited probe data from the Ark [25] project with maps of service provider infrastructure from the Internet Atlas [15] project. We find that there are substantially more nodes and links identified in the service provider map data ver- sus the probe data. Next, we describe a new method for probe-based measurement of physical infrastructure called POPsicle that is based on careful selection of probe source- destination pairs. We demonstrate the capability of our method through an extensive measurement study using ex- isting \looking glass"" vantage points distributed throughout the Internet and show that it reveals 2.4 times more phys- ical node locations versus standard probing methods. To demonstrate the deployability of POPsicle we also conduct tests at an IXP. Our results again show that POPsicle can identify more physical node locations compared with stan- dard layer 3 probes, and through this deployment approach it can be used to measure thousands of networks world wide. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Physical internet; Popsicle probing heuristic,Internet; Maps; Probes; Topology; Geographic location; Internet infrastructure; Internet topology measurement; Measurement study; Nodes and links; Popsicle probing heuristic; Service provider; Topological structure; Network layers
"Rula J.P., Bustamante F.E.",2,Behind the curtain - Cellular DNS and content replica selection,2014,12,"Northwestern University, United States",Northwestern University,1,USA,1,30,28,"DNS plays a critical role in the performance of smartdevices within cellular networks. Besides name resolution, DNS is commonly relied upon for directing users to nearby content caches for better performance. In light of this, it is surprising how little is known about the structure of cellular DNS and its effectiveness as a client localization method. In this paper we take a close look at cellular network DNS and uncover several features of cellular DNS, such as cellular network opaqueness and client to resolver inconsistency, that make it unsuitable for client localization in modern cellular networks. We study these issues in two leading mobile network markets - US and South Korea - using a collection of over 340 volunteer devices to probe the DNS infrastructure of each client's cellular provider. We show the extent of the problem with regards to replica selection and compare its localization performance against public DNS alternatives. As a testament to cellular DNS's poor localization, we find surprisingly that public DNS can render equal or better replica performance over 75% of the time. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Cellular DNS; Content delivery networks; Domain name system,Mobile telecommunication systems; Wireless networks; Better performance; Cellular DNS; Cellular network; Content delivery network; Domain name system; Localization method; Localization performance; Replica selections; Internet protocols
"Czyz J., Kallitsis M., Gharaibeh M., Papadopoulos C., Bailey M., Karir M.",6,Taming the 800 pound gorilla: The rise and decline of NTP DDoS attacks,2014,51,"University of Michigan, United States; Merit Network, Inc., United States; Colorado State University, United States; University of Illinois, United States",Colorado State University;Merit Network Inc.;UIUC;University of Michigan at Ann Arbor,4,USA,1,49,41,"Distributed Denial of Service (DDoS) attacks based on Network Time Protocol (NTP) amplification, which became prominent in December 2013, have received significant global attention. We chronicle how this attack rapidly rose from obscurity to become the dominant large DDoS vector. Via the lens of five distinct datasets, we characterize the advent and evolution of these attacks. Through a dataset that measures a large fraction of global Internet traffic, we show a three order of magnitude rise in NTP. Using a large darknet, we observe a similar rise in global scanning activity, both malicious and research. We then dissect an active probing dataset, which reveals that the pool of amplifiers totaled 2.2M unique IPs and includes a small number of ""mega amplifiers,"" servers that replied to a single tiny probe packet with gigabytes of data. This dataset also allows us, for the first time, to analyze global DDoS attack victims (including ports attacked) and incidents, where we show 437K unique IPs targeted with at least 3 trillion packets, totaling more than a petabyte. Finally, ISP datasets shed light on the local impact of these attacks. In aggregate, we show the magnitude of this major Internet threat, the community's response, and the effect of that response. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Darknet; DDoS; NTP,Internet; Internet service providers; Network security; Active probing; Darknet; DDoS; Distributed denial of service attack; Global Internet; Network time protocol; NTP; Probe packets; Denial-of-service attack
"Hannak A., Soeller G., Lazer D., Mislove A., Wilson C.",5,Measuring price discrimination and steering on E-commerce web sites,2014,52,"Northeastern University, Boston, MA, United States",Northeastern University,1,USA,1,26,20,"Today, many e-commerce websites personalize their content, including Netix (movie recommendations), Amazon (product suggestions), and Yelp (business reviews). In many cases, personalization provides advantages for users: for example, when a user searches for an ambiguous query such as \router,"" Amazon may be able to suggest the woodworking tool instead of the networking device. However, personalization on e-commerce sites may also be used to the user's disadvantage by manipulating the products shown (price steering) or by customizing the prices of products (price discrimination). Unfortunately, today, we lack the tools and techniques necessary to be able to detect such behavior. In this paper, we make three contributions towards addressing this problem. First, we develop a methodology for accurately measuring when price steering and discrimination occur and implement it for a variety of e-commerce web sites. While it may seem conceptually simple to detect differences between users' results, accurately attributing these differences to price discrimination and steering requires correctly addressing a number of sources of noise. Second, we use the accounts and cookies of over 300 real-world users to detect price steering and discrimination on 16 popular e-commerce sites. We find evidence for some form of personalization on nine of these e-commerce sites. Third, we investigate the effect of user behaviors on personalization. We create fake accounts to simulate different user features including web browser/OS choice, owning an account, and history of purchased or viewed products. Overall, we find numerous instances of price steering and discrimination on a variety of top e-commerce sites. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",E-commerce; Personalization; Price discrimination; Search,Behavioral research; Commerce; Electronic commerce; Social networking (online); Websites; E-commerce websites; Movie recommendations; Networking devices; Number of sources; Personalizations; Price discrimination; Search; Tools and techniques; Costs
"Baltrunas D., Elmokashfi A., Kvalbein A.",3,Neasuring the reliability of mobile broadband networks,2014,13,"Simula Research Laboratory, Norway",Simula Research,1,Norway,1,36,29,"Mobile broadband networks play an increasingly important role in society, and there is a strong need for independent assessments of their robustness and performance. A promis- ing source of such information is active end-to-end measure- ments. It is, however, a challenging task to go from individ- ual measurements to an assessment of network reliability, which is a complex notion encompassing many stability and performance related metrics. This paper presents a frame- work for measuring the user-experienced reliability in mo- bile broadband networks. We argue that reliability must be assessed at several levels, from the availability of the net- work connection to the stability of application performance. Based on the proposed framework, we conduct a large-scale measurement study of reliability in 5 mobile broadband net- works. The study builds on active measurements from hun- dreds of measurement nodes over a period of 10 months. The results show that the reliability of mobile broadband networks is lower than one could hope: More than 20% of connections from stationary nodes are unavailable more than 10 minutes per day. There is, however, a significant poten- Tial for improving robustness if a device can connect simul- Taneously to several networks. We find that in most cases, our devices can achieve 99.999% (""five nines"") connection availability by combining two operators. We further show how both radio conditions and network configuration play important roles in determining reliability, and how external measurements can reveal weaknesses and incidents that are not always captured by the operators' existing monitoring tools. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Mobile broadband; Reliability; Robustness,Broadband networks; Complex networks; Robustness (control systems); Active measurement; Application performance; Connection availability; Independent assessment; Large-scale measurement; Mobile broadband; Network configuration; Network reliability; Reliability
"Chaabane A., Chen T., Cunche M., De Cristofaro E., Friedman A., Kaafar M.A.",6,Censorship in the wild: Analyzing internet filtering in Syria,2014,14,"INRIA Rh™ne-Alpes, Montbonnot, France; NICTA, Sydney, Australia; INRIA Lyon, University of Lyon, France; University College London, London, United Kingdom; NICTA and INRIA Rh™ne-Alpes, Sydney, Australia",INRIA;NICTA;University College London;University of Lyon,4,Australia;France;UK,3,54,40,"Internet censorship is enforced by numerous governments worldwide, however, due to the lack of publicly available information, as well as the inherent risks of performing active measurements, it is often hard for the research community to investigate censorship practices in the wild. Thus, the leak of 600GB worth of logs from 7 Blue Coat SG-9000 proxies, deployed in Syria to filter Internet traffic at a country scale, represents a unique opportunity to provide a detailed snapshot of a real-world censorship ecosystem. This paper presents the methodology and the results of a measurement analysis of the leaked Blue Coat logs, revealing a relatively stealthy, yet quite targeted, censorship. We find that traffic is filtered in several ways: using IP addresses and domain names to block subnets or websites, and keywords or categories to target specific content. We show that keyword-based censorship produces some collateral damage as many requests are blocked even if they do not relate to sensitive content. We also discover that Instant Messaging is heavily censored, while filtering of social media is limited to specific pages. Finally, we show that Syrian users try to evade censorship by using web/socks proxies, Tor, VPNs, and BitTorrent. To the best of our knowledge, our work provides the first analytical look into Internet filtering in Syria. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Censorship; Internet filtering; Measurements,Measurements; Active measurement; Censorship; Collateral damage; Instant messaging; Internet censorship; Internet filtering; Internet traffic; Research communities; Internet
"Pujol E., Richter P., Chandrasekaran B., Smaragdakis G., Feldmann A., Maggs B., Ng K.-C.",7,Back-office web traffic on the internet,2014,7,"TU Berlin, Germany; Duke University, United States; MIT, TU Berlin, Akamai, Germany; Duke, Akamai, Germany; Akamai, Germany",Duke University;MIT;TU Berlin,3,Germany;USA,2,24,21,"Although traffic between Web servers and Web browsers is readily apparent to many knowledgeable end users, fewer are aware of the extent of server-to-server Web traffic carried over the public Internet. We refer to the former class of traffic as front-office Internet Web traffic and the latter as back-office Internet Web traffic (or just front-office and back-office traffic, for short). Back-office traffic, which may or may not be triggered by end-user activity, is essential for today's Web as it supports a number of popular but complex Web services including large-scale content delivery, social networking, indexing, searching, advertising, and proxy services. This paper takes a first look at back-office traffic, measuring it from various vantage points, including from within ISPs, IXPs, and CDNs. We describe techniques for identifying back-office traffic based on the roles that this traffic plays in the Web ecosystem. Our measurements show that back-office traffic accounts for a significant fraction not only of core Internet traffic, but also of Web transactions in the terms of requests and responses. Finally, we discuss the implications and opportunities that the presence of backoffice traffic presents for the evolution of the Internet ecosystem. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Content delivery; Crawlers; Network measurement; Online advertisements; Real-time bidding; The web,Complex networks; Ecology; Ecosystems; Internet; Internet service providers; Social networking (online); Web browsers; World Wide Web; Content delivery; Crawlers; Network measurement; Online advertisements; Real- time; The web; Web services
"Zarras A., Kapravelos A., Stringhini G., Holz T., Kruegel C., Vigna G.",6,The dark alleys of madison avenue: Understanding malicious advertisements,2014,37,"Ruhr-University Bochum, United States; UC Santa Barbara, United States; University College London, United Kingdom",Ruhr-University Bochum;University College London;University of California Santa Barbara,3,UK;USA,2,31,26,"Online advertising drives the economy of the World Wide Web. Modern websites of any size and popularity include advertisements to monetize visits from their users. To this end, they assign an area of their web page to an advertising company (so called ad exchange) that will use it to display promotional content. By doing this, the website owner im- plicitly trusts that the advertising company will offer legiti- mate content and it will not put the site's visitors at risk of falling victims of malware campaigns and other scams. In this paper, we perform the first large-scale study of the safety of the advertisements that are encountered by the users on the Web. In particular, we analyze to what extent users are exposed to malicious content through ad- vertisements, and investigate what are the sources of this malicious content. Additionally, we show that some ad ex- changes are more prone to serving malicious advertisements than others, probably due to their deficient filtering mech- Anisms. The observations that we make in this paper shed light on a little studied, yet important, aspect of advertise- ment networks, and can help both advertisement networks and website owners in securing their web pages and in keep- ing their visitors safe. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Malvertising; Malware; Online advertising,Computer crime; Marketing; Social networking (online); Websites; World Wide Web; Ad exchanges; Exposed to; Large-scale studies; Malvertising; Online advertising; Malware
"Wang L., Nappa A., Caballero J., Ristenpart T., Akella A.",5,Whowas: A platform for measuring web deployments on IaaS clouds,2014,4,"University of Wisconsin - Madison, United States; IMDEA Software Institute, United States; Universidad PolitŽcnica de Madrid, Spain",IMDEA Networks;Universidad PolitŽcnica de Madrid;;University of Wisconsin-Madison,4,Spain;USA,2,59,51,"Public infrastructure-as-a-service (IaaS) clouds such as Amazon EC2 and Microsoft Azure host an increasing number of web services. The dynamic, pay-as-you-go nature of modern IaaS systems enable web services to scale up or down with demand, and only pay for the resources they need. We are unaware, however, of any studies reporting on measurements of the patterns of usage over time in IaaS clouds as seen in practice. We fill this gap, offering a measurement platform that we call WhoWas. Using active, but lightweight, probing, it enables associating web content to public IP addresses on a day-by-day basis. We exercise WhoWas to provide the first measurement study of churn rates in EC2 and Azure, the efficacy of IP blacklists for malicious activity in clouds, the rate of adoption of new web software by public cloud customers, and more. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Active measurement; Azure; Cloud computing; EC2; Web service,Cloud computing; Social networking (online); Web services; Websites; Windows operating system; World Wide Web; Active measurement; Azure; EC2; Malicious activities; Measurement study; Measurements of; Pay-as-you-go; Public infrastructures; Infrastructure as a service (IaaS)
"Sommer R., Vallentin M., De Carli L., Paxson V.",4,"HILTI: An abstract execution environment for deep, stateful network traffic analysis",2014,12,"ICSI, LBNL, United States; UC Berkeley, United States; University of Wisconsin-Madison, United States; ICSI, UC Berkeley, United States",University of California Berkeley;;University of Wisconsin-Madison,3,USA,1,32,27,"When developing networking systems such as firewalls, routers, and intrusion detection systems, one faces a striking gap between the ease with which one can often describe a desired analysis in high-level terms, and the tremendous amount of low-level implementation details that one must still grapple with to come to a robust solution. We present HILTI, a platform that bridges this divide by providing to application developers much of the low-level functionality, without tying it to a specific analysis structure. HILTI consists of two parts: (i) an abstract machine model that we tailor specifically to the networking domain, directly supporting the field's common abstractions and idioms in its instruction set; and (ii) a compilation strategy for turning programs written for the abstract machine into optimized, natively executable code. We have developed a prototype of the HILTI compiler toolchain that fully implements the design's functionality, and ported exemplars of networking applications to the HILTI model to demonstrate the aptness of its abstractions. Our evaluation of HILTI's functionality and performance confirms its potential to become a powerful platform for future application development. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Deep packet inspection; Intrusion detection; Real-time monitoring,Abstracting; Computer system firewalls; Software prototyping; Abstract executions; Application developers; Deep packet inspection; Future applications; Intrusion Detection Systems; Network traffic analysis; Networking applications; Real time monitoring; Intrusion detection
"Comarela G., Crovella M.",2,Identifying and analyzing high impact routing events with PathMiner,2014,7,"Boston University, Boston, United States",Boston University,1,USA,1,43,33,"Understanding the dynamics of the interdomain routing system is challenging. One reason is that a single routing or policy change can have far reaching and complex effects. Connecting observed behavior with its underlying causes is made even more difficult by the amount of noise in the BGP system. In this paper we address these challenges by presenting PathMiner, a system to extract large scale routing events from background noise and identify the AS or link responsible for the event. PathMiner is distinguished from previous work in its ability to identify and analyze large-scale events that may re-occur many times over long timescales. The central idea behind PathMiner is that although a routing change at one AS may induce large-scale, complex responses in other ASes, the correlation among those responses (in space and time) helps to isolate the relevant set of responses from background noise, and makes the cause much easier to identify. Hence, PathMiner has two components: An algorithm for mining large scale coordinated changes from routing tables, and an algorithm for identifying the network element (AS or link) responsible for the set of coordinated changes. We describe the implementation and validation of PathMiner. We show that it is scalable, being able to extract significant events from multiple years of routing data at a daily granularity. Finally, using PathMiner we study interdomain routing over past 9 years and use it to characterize the presence of large scale routing events and to identify the responsible network elements. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",BGP; Boolean tensor factorization; Interdomain routing,Complex networks; Background noise; BGP; Complex response; Inter-domain routing systems; Interdomain Routing; Large-scale event; Tensor factorization; Underlying cause; Network routing
"Zaki Y., Chen J., Pštsch T., Ahmad T., Subramanian L.",5,Dissecting web latency in Ghana,2014,20,"New York University Abu Dhabi, United Arab Emirates; University of Bremen Bremen, Germany; NYU, CTED, NYUAD, United States",NYU;NYU Abu Dhabi;University of Bremen,3,Germany;United Arab Emirates;USA,3,46,25,"Web access is prohibitively slow in many developing regions despite substantial effort to increase bandwidth and network penetration. In this paper, we explore the fundamental bot- Tlenecks that cause poor web performance from a client's perspective by carefully dissecting webpage load latency con- Tributors in Ghana. Based on our measurements from 2012 to 2014, we find several interesting issues that arise due to the increasing complexity of web pages and number of server redirections required to completely render the assets of a page. We observe that, rather than bandwidth, the primary bottleneck of web performance in Ghana is the lack of good DNS servers and caching infrastructure. The main bottle- necks are: (a) Recursive DNS query resolutions; (b) HTTP redirections; (c) TLS/SSL handshakes. We experiment with a range of well-known end-to-end latency optimizations and find that simple DNS caching, redirection caching, and the use of SPDY can all yield substantial improvements to user- perceived latency. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Developing countries; DNS; HAR; Web,Bandwidth; Bottles; Complex networks; Developing countries; HTTP; Social networking (online); Websites; Developing regions; DNS; End-to-end latency; HAR; Network penetrations; Query resolution; Web; Web performance; Internet protocols
"Sanchez M.A., Bustamante F.E., Krishnamurthy B., Willinger W., Smaragdakis G., Erman J.",6,Inter-domain traffic estimation for the outsider,2014,5,"Northwestern University, United States; AT and T Labs Research, United States; Niksun, Inc., United States; MIT, TU Berlin, Germany",AT and T Labs;MIT;Niksun Inc.;Northwestern University;TU Berlin,5,Germany;USA,2,20,12,"Characterizing the ow of Internet trafic is important in a wide range of contexts, from network engineering and application design to understanding the network impact of consumer demand and business relationships. Despite the growing interest, the nearly impossible task of col- lecting large-scale, Internet-wide trafic data has severely constrained the focus of trafic-related studies. In this paper, we introduce a novel approach to character- ize inter-domain trafic by reusing large, publicly available traceroute datasets. Our approach builds on a simple insight the popularity of a route on the Internet can serve as an informative proxy for the volume of trafic it carries. It ap- plies structural analysis to a dual-representation of the AS- level connectivity graph derived from available traceroute datasets. Drawing analogies with city grids and trafic, it adapts data transformations and metrics of route popularity from urban planning to serve as proxies for trafic volume. We call this approach Network Syntax, highlighting the connection to urban planning Space Syntax. We apply Network Syntax in the context of a global ISP and a large Internet eXchange Point and use ground-truth data to demonstrate the strong correlation (r2 values of up to 0.9) between inter-domain trafic volume and the different proxy metrics. Working with these two network entities, we show the potential of Network Syntax for identifying critical links and inferring missing trafic matrix measurements. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",As-level path; Inter-domain trafic; Traceroute,Internet; Syntactics; Urban planning; As-level paths; Business relationships; Data transformation; Inter-domain; Inter-domain traffic; Internet exchange points; Network engineering; Traceroute; Internet service providers
"Ma L., He T., Swami A., Towsley D., Leung K.K., Lowe J.",6,Node failure localization via network tomography,2014,13,"IBM T. J. Watson Research, Yorktown Heights, NY, United States; Army Research Laboratory AdelphiMD, United States; University of Massachusetts AmherstMA, United States; Imperial College, London, United Kingdom; DSTL Salisbury, United Kingdom","Army Research Lab, Adlephi;IBM;Imperial College London;University of Massachusetts Amherst",4,UK;USA,2,32,31,"We investigate the problem of localizing node failures in a communication network from end-to-end path measurements, under the assumption that a path behaves normally if and only if it does not contain any failed nodes. To uniquely localize node failures, the measurement paths must show different symptoms under different failure events, i.e., for any two distinct sets of failed nodes, there must be a measurement path traversing one and only one of them. This condition is, however, impractical to test for large networks. Our first contribution is a characterization of this condition in terms of easily verifiable conditions on the network topology with given monitor placements under three families of probing mechanisms, which differ in whether measurement paths are (i) arbitrarily controllable, (ii) controllable but cycle-free, or (iii) uncontrollable (i.e., determined by the default routing protocol). Our second contribution is a characterization of the maximum identifiability of node failures, measured by the maximum number of simultaneous failures that can always be uniquely localized. Specifically, we bound the maximal identifiability from both the upper and the lower bounds which differ by at most one, and show that these bounds can be evaluated in polynomial time. Finally, we quantify the impact of the probing mechanism on the capability of node failure localization under different probing mechanisms on both random and real network topologies. We observe that despite a higher implementation cost, probing along controllable paths can significantly improve a network's capability to localize simultaneous node failures. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Identifiability condition; Maximum identifiability; Network tomography; Node failure localization,Polynomial approximation; Topology; End-to-end path; Identifiability; Identifiability conditions; Implementation cost; Network tomography; Network topology; Node failure; Polynomial-time; Electric network topology
"Jones B., Lee T.-W., Feamster N., Gill P.",4,Automated detection and fingerprinting of censorship block pages,2014,7,"Georgia Tech, United States; Stony Brook University, United States",Georgia Tech;Stony Brook University,2,USA,1,52,25,"One means of enforcing Web censorship is to return a block page, which informs the user that an attempt to access a webpage is unsuccessful. Detecting block pages can provide a more complete picture of Web censorship, but automatically identifying block pages is difficult because Web content is dynamic, personalized, and may even be in different languages. Previous work has manually detected and identified block pages, which is difficult to reproduce; it is also time-consuming, which makes it difficult to perform continuous, longitudinal studies of censorship. This paper presents an automated method both to detect block pages and to fingerprint the filtering products that generate them. Our automated method enables continuous measurements of block pages; we found that our methods successfully detect 95% of block pages and identify five filtering tools, including a tool that had not been previously identified ""in the wild"". Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Censorship; Internet measurement,Internet; Social networking (online); Automated detection; Automated methods; Censorship; Continuous measurements; Filtering tools; Internet measurement; Longitudinal study; Web content; Automation
"Li Z., Jin C., Xu T., Wilson C., Liu Y., Cheng L., Liu Y., Dai Y., Zhang Z.-L.",9,Towards network-level efficiency for cloud storage services,2014,36,"Tsinghua University, China; University of Minnesota Twin Cities, United States; University of California, San Diego, United States; Northeastern University BostonMA, United States; State University of New York Binghamton University, United States; Tsinghua University, Beijing, China; Peking University Beijing, China",Northeastern University;Peking University;SUNY Binghamton;Tsinghua University;University of California San Diego;University of Minnesota Twin Cities,6,China;USA,2,29,13,"Cloud storage services such as Dropbox, Google Drive, and Microsoft OneDrive provide users with a convenient and reliable way to store and share data from anywhere, on any device, and at any time. The cornerstone of these services is the data synchronization (sync) operation which automatically maps the changes in users' local filesystems to the cloud via a series of network communications in a timely manner. If not designed properly, however, the tremendous amount of data sync traffic can potentially cause (financial) pains to both service providers and users. This paper addresses a simple yet critical question: Is the current data sync traffic of cloud storage services efficiently used? We first define a novel metric named TUE to quantify the Traffic Usage Efficiency of data synchronization. Based on both real-world traces and comprehensive experiments, we study and characterize the TUE of six widely used cloud storage services. Our results demonstrate that a considerable portion of the data sync traffic is in a sense wasteful, and can be effectively avoided or significantly reduced via carefully designed data sync mechanisms. All in all, our study of TUE of cloud storage services not only provides guidance for service providers to develop more efficient, trafficeconomic services, but also helps users pick appropriate services that best fit their needs and budgets. Copyright © 2014 by the Association for Computing Machinery, Inc. (ACM).",Cloud storage service; Data synchronization; Network-level efficiency; Traffic usage efficiency,Budget control; Efficiency; Synchronization; Cloud storage services; Critical questions; Current data; Data synchronization; Level efficiencies; Network communications; Real-world; Service provider; Digital storage
"Gabielkov M., Rao A., Legout A.",3,Sampling online social networks: An experimental study of Twitter,2014,3,"Inria, Sophia Antipolis, France",INRIA,1,France,1,13,10,"Online social networks (OSNs) are an important source of information for scientists in different fields such as computer science, sociology, economics, etc. However, it is hard to study OSNs as they are very large. For instance, Facebook has 1.28 billion active users in March 2014 and Twitter claims 255 million active users in April 2014. Also, companies take measures to prevent crawls of their OSNs and refrain from sharing their data with the research community. For these reasons, we argue that sampling techniques will be the best technique to study OSNs in the future. In this work, we take an experimental approach to study the characteristics of well-known sampling techniques on a full social graph of Twitter crawled in 2012 [2]. Our contribution is to evaluate the behavior of these techniques on a real directed graph by considering two sampling scenarios: (a) obtaining most popular users (b) obtaining an unbiased sample of users, and to find the most suitable sampling techniques for each scenario. © Authors 2014.",sampling; social graph; social networks; twitter,Convolutional codes; Sampling; Experimental approaches; Facebook; On-line social networks; Online social networks (OSNs); Research communities; Sampling technique; Social graphs; twitter; Social networking (online)
"Wang P., Ansari J., Petrova M., MŠhšnen P.",4,Demo: CogMAC+ - A decentralized multichannel MAC protocol for cognitive wireless networks,2014,3,"Institute for Networked Systems, RWTH Aachen University, Kackertstrasse 9, D-52072, Aachen, Germany",RWTH Aachen University,1,Germany,1,48,36,"Cognitive MAC schemes are emerging as a prospective solution to efficiently utilize the wireless medium. In order to enable opportunistic access to unused licensed band, a node has to monitor the frequency spectrum and carry out its transmission without causing harmful interference to the primary user. In this work, we demonstrate a decentralized multichannel MAC protocol CogMAC+ which uses a multichannel preamble reservation scheme to achieve parallel transmissions for multiple secondary users. Moreover, CogMAC+ uses an adaptive energy detection scheme to dynamically set the frame detection threshold based on the false positive detection ratio. Our table-top demonstration shows that CogMAC+ enables spectral coexistence and allows nodes to utilize spectrum opportunities efficiently in a dynamic fashion. © 2014 Authors.",cognitive radios; mac; sdr platform; spectrum agile,Cognitive radio; Software radio; Cognitive wireless networks; False positive detection; Harmful interferences; mac; Multi-channel MAC protocols; Parallel transmission; Sdr platforms; spectrum agile; Medium access control
"Kogan K., Nikolenko S., Rottenstreich O., Culhane W., Eugster P.",5,SAX-PAC (Scalable And eXpressive PAcket Classification),2014,34,"Purdue University, NetSysAlgo, United States; Steklov Mathematical Institute at St. Petersburg, National Research University Higher School of Economics, Russian Federation; Mellanox, Israel; Purdue University, United States; Technical University of Darmstadt, Germany",National Research University Higher School of Economics;Purdue University;Steklov Mathematical Institute;TU Darmstadt,4,Germany;Israel;Russia;USA,4,4,3,"Efficient packet classification is a core concern for network services. Traditional multi-field classification approaches, in both software and ternary content-addressable memory (TCAMs), entail tradeoffs between (memory) space and (lookup) time. TCAMs cannot efficiently represent range rules, a common class of classification rules confining values of packet fields to given ranges. The exponential space growth of TCAM entries relative to the number of fields is exacerbated when multiple fields contain ranges. In this work, we present a novel approach which identifies properties of many classifiers which can be implemented in linear space and with worst-case guaranteed logarithmic time and allows the addition of more fields including range constraints without impacting space and time complexities. On real-life classifiers from Cisco Systems and additional classifiers from ClassBench (with real parameters), 90-95% of rules are thus handled, and the other 5-10% of rules can be stored in TCAM to be processed in parallel. © 2014 ACM.",packet classification; TCAM,Convolutional codes; Packet networks; Classification approach; Classification rules; Logarithmic time; Packet classification; Range constraints; Space and time complexity; TCAM; Ternary content addressable memory; Ternary content adressable memory
"Nam H., Kim K.-H., Calin D., Schulzrinne H.",4,YouSlow: A performance analysis tool for adaptive bitrate video streaming,2014,12,"Columbia University, New York, NY, United States; Bell Laboratories, Alcatel-Lucent, Murray Hill, NJ, United States",Bell Labs;Columbia University,2,USA,1,13,12,"Adaptive bitrate (ABR) technologies are being widely used in today's popular HTTP-based video streaming such as YouTube and Netflix. Such a rate-switching algorithm embedded in a video player is designed to improve video quality-of-experience (QoE) by selecting an appropriate resolution based on the analysis of network conditions while the video is playing. However, a bad viewing experience is often caused by the video player having difficulty estimating transit or client-side network conditions accurately. In order to analyze the ABR streaming performance, we developed YouSlow, a web browser plug-in that can detect and report live buffer stalling events to our analysis tool. Currently, YouSlow has collected more than 20,000 of YouTube video stalling events over 40 countries. © 2014 Authors.",adaptive bitrate streaming (ABR); HTTP video streaming; video quality of experience,Convolutional codes; HTTP; Quality of service; Video streaming; Bit rates; Http video streaming; HTTP-based video streaming; Network condition; Performance analysis; Quality of experiences; Video quality; Web browser plug-in; Quality control
"Dong M., Li Q., Zarchy D., Godfrey B., Schapira M.",5,Rethinking congestion control architecture: Performance-oriented congestion control,2014,2,"University of Illinois, Urbana Champaign, IL, United States; Hebrew University of Jerusalem, Israel",Hebrew University of Jerusalem;UIUC,2,Israel;USA,2,43,32,"After more than two decades of evolution, TCP and its end host based modifications can still suffer from severely degraded performance under real-world challenging network conditions. The reason, as we observe, is due to TCP family's fundamental architectural deficiency, which hardwires packet-level events to control responses and ignores emprical performance. Jumping out of TCP lineage's architectural deficiency, we propose Performance-oriented Congestion Control (PCC), a new congestion control architecture in which each sender controls its sending strategy based on empirically observed performance metrics. We show through preliminary experimental results that PCC achieves consistently high performance under various challenging network conditions. © 2014 Authors.",congestion control,Congestion control (communication); Control architecture; Control response; Degraded performance; Host-based; Network condition; Performance metrics; Performance-oriented; Show through; Convolutional codes
"Michel O., Coughlin M., Keller E.",3,Extending the software-defined network boundary,2014,1,"University of Colorado Boulder, United States",University of Colorado Boulder,1,USA,1,7,3,"Given that Software-Defined Networking is highly successful in solving many of today's manageability, flexibility, and scalability issues in large-scale networks, in this paper we argue that the concept of SDN can be extended even further. Many applications (esp. stream processing and big-data applications) rely on graph-based inter-process communication patterns that are very similar to those in computer networks. To our mind, this network abstraction spanning over different types of entities is highly suitable for and would benefit from central (SDN-inspired) control for the same reasons classical networks do. In this work, we investigate the commonalities between such intra-host networks and classical computer networking. Based on this, we study the feasibility of a central network controller that manages both network traffic and intra-host communication over a custom bus system. © 2014 Authors.",multithreading; SDN; stream processing,Interprocess communication; Large-scale network; Multi-threading; Network abstractions; SDN; Software-defined networkings; Software-defined networks; Stream processing; Convolutional codes
"Timner Y., Pettersson J., Hannu H., Wang M., Johansson I.",5,"Network assisted rate adaptation for conversational video over LTE, concept and performance evaluation",2014,2,"Ericsson Research, LuleŒ, Sweden",Ericsson Research,1,Sweden,1,10,7,"This work investigates rate adaptation of conversational video in a mobile system using Long Term Evolution, LTE, and where the adaptation is assisted by the radio network. The conventional way to do rate adaptation is through adaptation in the end-points where the transmission rate is selected based on measurements of received packets. This study investigates two network-based algorithms for rate adaptation, a rate fair algorithm that assigns the same rate to all conversational video users in a cell, and a resource fair algorithm that aims to give all users in the cell a fair amount of resources. Both algorithms are combined with delay based scheduling. Both network-based algorithms perform excellently. The delay stays low even when the resource utilization is close to 100%, and the video rate is adapted to the system load. As could be expected, the average user rates are higher with the resource fair algorithm. An end-point based adaptation algorithm is investigated as well, but it cannot keep a low delay at high load. © 2014 ACM.",4g mobile communication; conversational video; delay scheduling; fairness; lte; quality of service; radio resource management; rate adaptation,Algorithms; Mobile telecommunication systems; Point contacts; Quality of service; Scheduling; 4G mobile communication; conversational video; Delay scheduling; fairness; lte; Radio resource management; Rate adaptation; Wireless telecommunication systems
"Xin Y., Baldin I., Heermann C., Mandal A., Ruth P.",5,Capacity of inter-cloud layer-2 virtual networking,2014,2,"Renci, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States",University of North Carolina at Chapel Hill,1,USA,1,4,4,"Due to the economy of scale of Ethernet networks and available dynamic circuit capability from the major national research and educational networks, VLAN (Virtual LAN) based virtual networking solution has been successfully adopted in some advanced distributed cloud systems. However, there are two major constraints in this adaptation: (1) dynamic circuit service is far from pervasive; (2) there is only limited VLAN tags offered by regional network service providers. In this paper, after examining layer-2 networking in large-scale distributed cloud environments, we present a graph theoretical model to study the network capacity in terms of the number of inter-cloud connections that can co-exist. We further design the algorithms to achieve this capacity for both point-to-point and multi-point inter-cloud connections in both static and dynamic scenarios. We also study a general topology embedding problem based on this model. As tagging is a common mechanism for isolating communication channels in other network layers, the proposed models and algorithms can be extended to optical and IP networks. © 2014 ACM.",capacity; inter-cloud networking; multipartite graph; vlan,Cloud computing; Graph theory; capacity; Educational networks; Embedding problems; Inter clouds; Models and algorithms; Multipartite graph; Theoretical modeling; vlan; Network layers
"Bharadia D., Katti S.",2,FastForward: Fast and constructive full duplex relays,2014,24,"Stanford University, United States",Stanford University,1,USA,1,12,7,"This paper presents, FastForward (FF), a novel full duplex relay that constructively forwards signals such that wireless network throughput and coverage is significantly enhanced. FF is a Layer 1 in-band full duplex device, it receives and transmits signals directly and simultaneously on the same frequency. It cleanly integrates into existing networks (both WiFi and LTE) as a separate device and does not require changes to the clients. FF's key invention is a constructive filtering algorithm that transforms the signal at the relay such that when it reaches the destination, it constructively combines with the direct signals from the source and provides a significant throughput gain. We prototype FF using off-the-shelf software radios running a stock WiFi PHY and show experimentally that it provides a 3x median throughput increase and nearly a 4x gain at the edge of the coverage area. © 2014 ACM.",full duplex; full duplex relay; interference cancellation; low latency cancellation,Convolutional codes; Throughput; Wi-Fi; Direct signal; Filtering algorithm; Full-duplex; Full-duplex relays; Interference cancellation; Low latency; Network throughput; Separate devices; Wireless telecommunication systems
"Zhang Z., Mara O., Argyraki K.",3,Network neutrality inference,2014,15,"UESTC, China; EPFL, Switzerland","EPFL, Switzerland",1,China;Switzerland,2,16,10,"When can we reason about the neutrality of a network based on external observations? We prove conditions under which it is possible to (a) detect neutrality violations and (b) localize them to specific links, based on external observations. Our insight is that, when we make external observations from different vantage points, these will most likely be inconsistent with each other if the network is not neutral. Where existing tomographic techniques try to form solvable systems of equations to infer network properties, we try to form unsolvable systems that reveal neutrality violations. We present an algorithm that relies on this idea to identify sets of non-neutral links based on external observations, and we show, through network emulation, that it achieves good accuracy for a variety of network conditions. © 2014 ACM.",network neutrality; network tomography,Convolutional codes; Infer networks; Network condition; Network emulation; Network neutralities; Network tomography; Network-based; Systems of equations; Tomographic techniques; Internet
"Shirali-Shahreza S., Ganjali Y.",2,Traffic statistics collection with FleXam,2014,3,"Department of Computer Science, University of Toronto, Canada",University of Toronto,1,Canada,1,30,17,"One of the limitations of wildcard rules in Software Defined Networks, such as OpenFlow, is losing visibility. FleXam is a flexible sampling extension for OpenFlow that allows the controller to define which packets should be sampled, what parts of each packet should be selected, and where they should be sent. Here, we present an interactive demo showing how FleXam enables the controller to dynamically adjust sampling rates and change the sampling scheme to optimally keep up with a sampling budget in the context of a traffic statistics collection application. © 2014 Authors.",openflow; sampling; SDN; traffic statistics,Budget control; Convolutional codes; Sampling; Openflow; Sampling rates; Sampling schemes; SDN; Software-defined networks; Traffic statistics; Traffic surveys
Cerroni W.,1,Performance of network and computing resource sharing in federated cloud systems,2014,2,"DEI - University of Bologna, via Venezia, 52, 47521 Cesena (FC), Italy",University of Bologna,1,Italy,1,32,17,"The increasing demand of computing, storage and communication resources by cloud-based applications is fostering new forms of infrastructure sharing such as cloud federations, which can take advantage of virtualization technologies and, in particular, of virtual machine live migration techniques. Such a scenario requires a quantitative characterization of the performance of the inter-data center communication considering possible limitations in both network and computing resource availability. This paper provides an analytical model for joint dimensioning of shared network and data center capacity in a federate cloud. © 2014 ACM.",cloud computing; distributed cloud networking; inter-data center communication; virtual machine migration,Cloud computing; Computer simulation; Cloud-based applications; Communication resources; Computing resource; Distributed clouds; Infrastructure sharing; Quantitative characterization; Virtual machine migrations; Virtualization technologies; Digital storage
"Moshref M., Yu M., Govindan R., Vahdat A.",4,DREAM: Dynamic resource allocation for software-defined measurement,2014,46,"University of Southern California, United States; Google, UC San Diego, United States",Google;University of California San Diego;University of Southern California,3,USA,1,7,7,"Software-defined networks can enable a variety of concurrent, dynamically instantiated, measurement tasks, that provide fine-grain visibility into network traffic. Recently, there have been many proposals to configure TCAM counters in hardware switches to monitor traffic. However, the TCAM memory at switches is fundamentally limited and the accuracy of the measurement tasks is a function of the resources devoted to them on each switch. This paper describes an adaptive measurement framework, called DREAM, that dynamically adjusts the resources devoted to each measurement task, while ensuring a user-specified level of accuracy. Since the trade-off between resource usage and accuracy can depend upon the type of tasks, their parameters, and traffic characteristics, DREAM does not assume an a priori characterization of this trade-off, but instead dynamically searches for a resource allocation that is sufficient to achieve a desired level of accuracy. A prototype implementation and simulations with three network-wide measurement tasks (heavy hitter, hierarchical heavy hitter and change detection) and diverse traffic show that DREAM can support more concurrent tasks with higher accuracy than several other alternatives. © 2014 ACM.",resource allocation; software-defined measurement,Computer simulation; Convolutional codes; Ternary content adressable memory; Adaptive measurements; Change detection; Concurrent tasks; Dynamic resource allocations; Hierarchical heavy hitters; Prototype implementations; Software-defined networks; Traffic characteristics; Resource allocation
"Li J., Berg S., Zhang M., Reiher P., Wei T.",5,DrawBridge - Software-defined DDoS-resistant traffic engineering,2014,11,"University of Oregon, Eugene, OR, United States; University of California, Los Angeles, CA, United States; University of Califonia, Berkeley, CA, United States",University of Califonia;University of California Los Angeles;University of Oregon,3,USA,1,10,9,"End hosts in today's Internet have the best knowledge of the type of traffic they should receive, but they play no active role in traffic engineering. Traffic engineering is conducted by ISPs, which unfortunately are blind to specific user needs. End hosts are therefore subject to unwanted traffic, particularly from Distributed Denial of Service (DDoS) attacks. This research proposes a new system called DrawBridge to address this traffic engineering dilemma. By realizing the potential of software-defined networking (SDN), in this research we investigate a solution that enables end hosts to use their knowledge of desired traffic to improve traffic engineering during DDoS attacks. © 2014 Authors.",DDoS; software-defined networking; traffic engineering,Convolutional codes; Internet service providers; Network security; DDoS; DDoS Attack; Distributed denial of service attack; Software-defined networkings; Traffic Engineering; Unwanted traffic; User need; Denial-of-service attack
"Gupta A., Vanbever L., Shahbaz M., Donovan S.P., Schlinker B., Feamster N., Rexford J., Shenker S., Clark R., Katz-Bassett E.",10,SDX: A software defined Internet exchange,2014,42,"Georgia Tech., United States; Princeton University, United States; UC Berkeley, United States; Univ. of Southern California, United States",Georgia Tech;Princeton University;University of California Berkeley,3,USA,1,42,31,"BGP severely constrains how networks can deliver traffic over the Internet. Today's networks can only forward traffic based on the destination IP prefix, by selecting among routes offered by their immediate neighbors. We believe Software Defined Networking (SDN) could revolutionize wide-area traffic delivery, by offering direct control over packet-processing rules that match on multiple header fields and perform a variety of actions. Internet exchange points (IXPs) are a compelling place to start, given their central role in interconnecting many networks and their growing importance in bringing popular content closer to end users. To realize a Software Defined IXP (an ""SDX""), we need new programming abstractions that allow participating networks to create and run these applications and a runtime that both behaves correctly when interacting with BGP and ensures that applications do not interfere with each other. We must also ensure that the system scales, both in rule-table size and computational overhead. In this demo, we show how we tackle these challenges demonstrating the flexibility and scalability of our SDX platform. The paper also appears in the main program [1]. © 2014 Authors.",BGP; internet exchange point (IXP); software defined networking (SDN),Computer programming; Convolutional codes; BGP; Computational overheads; Direct control; Internet Exchange; Internet exchange points; Programming abstractions; Software defined networking (SDN); Wide-area traffic; Internet
"Dogar F.R., Karagiannis T., Ballani H., Rowstron A.",4,Decentralized task-aware scheduling for data center networks,2014,82,"Microsoft Research, United States",Microsoft,1,USA,1,4,3,"Many data center applications perform rich and complex tasks (e.g., executing a search query or generating a user's news-feed). From a network perspective, these tasks typically comprise multiple flows, which traverse different parts of the network at potentially different times. Most network resource allocation schemes, however, treat all these flows in isolation - rather than as part of a task - and therefore only optimize flow-level metrics. In this paper, we show that task-aware network scheduling, which groups flows of a task and schedules them together, can reduce both the average as well as tail completion time for typical data center applications. To achieve these benefits in practice, we design and implement Baraat, a decentralized task-aware scheduling system. Baraat schedules tasks in a FIFO order but avoids head-of-line blocking by dynamically changing the level of multiplexing in the network. Through experiments with Memcached on a small testbed and large-scale simulations, we show that Baraat outperforms state-of-the-art decentralized schemes (e.g., pFabric) as well as centralized schedulers (e.g., Orchestra) for a wide range of workloads (e.g., search, analytics, etc). © 2014 ACM.",datacenter; response time; scheduling; transport,Complex networks; Convolutional codes; Response time (computer systems); Centralized schedulers; Data center networks; Datacenter; Design and implements; Head of line blocking; Large scale simulations; Network resource allocations; transport; Scheduling
"Sun P., Mahajan R., Rexford J., Yuan L., Zhang M., Arefin A.",6,A network-state management service,2014,31,"Princeton, United States; Microsoft, United States",Microsoft;Princeton University,2,USA,1,3,2,"We present Statesman, a network-state management service that allows multiple network management applications to operate independently, while maintaining network-wide safety and performance invariants. Network state captures various aspects of the network such as which links are alive and how switches are forwarding traffic. Statesman uses three views of the network state. In observed state, it maintains an up-to-date view of the actual network state. Applications read this state and propose state changes based on their individual goals. Using a model of dependencies among state variables, Statesman merges these proposed states into a target state that is guaranteed to maintain the safety and performance invariants. It then updates the network to the target state. Statesman has been deployed in ten Microsoft Azure datacenters for several months, and three distinct applications have been built on it. We use the experience from this deployment to demonstrate how Statesman enables each application to meet its goals, while maintaining network-wide invariants. © 2014 ACM.",datacenter network; network state; software-defined networking,Convolutional codes; Data center networks; Data centers; Management applications; Management service; Multiple networks; Network state; Software-defined networkings; State variables; Windows operating system
"Bao J., Zhao B., Yu W., Feng Z., Wu C., Gong Z.",6,OpenSAN: A software-defined satellite network architecture,2014,12,"College of Computer, National University of Defense Technology, Changsha, Hunan, China",National University of Defense Technology,1,China,1,29,24,"In recent years, with the rapid development of satellite technology including On Board Processing (OBP) and Inter Satellite Link (ISL), satellite network devices such as space IP routers have been experimentally carried in space. However, there are many difficulties to build a future satellite network with current terrestrial Internet technologies due to the distinguished space features, such as the severely limited resources, remote hardware/software upgrade in space. In this paper, we propose OpenSAN, a novel architecture of software-defined satellite network. By decoupling the data plane and control plane, OpenSAN provides satellite network with high efficiency, fine-grained control, as well as flexibility to support future advanced network technology. Moreover, we also discuss some practical challenges in the deployment of OpenSAN. © 2014 Authors.",satellite network; software-defined network,Network architecture; Satellite links; Advanced network technologies; Fine-grained control; Inter-satellite link; Internet technology; On-board processing; Satellite network; Satellite technology; Software-defined networks; Convolutional codes
"Kandula S., Menache I., Schwartz R., Babbula S.R.",4,Calendaring for wide area networks,2014,33,"Microsoft, United States",Microsoft,1,USA,1,30,30,"Datacenter WAN traffic consists of high priority transfers that have to be carried as soon as they arrive alongside large transfers with pre-assigned deadlines on their completion (ranging from minutes to hours). The ability to offer guarantees to large transfers is crucial for business needs and impacts overall cost-of-business. State-of-the-art traffic engineering solutions only consider the current time epoch and hence cannot provide pre-facto promises for long-lived transfers. We present Tempus, an online traffic engineering scheme that exploits information on transfer size and deadlines to appropriately pack long-running transfers across network paths and time, thereby leaving enough capacity slack for future high-priority requests. Tempus builds on a tailored approximate solution to a mixed packing-covering linear program, which is parallelizable and scales well in both running time and memory usage. Consequently, Tempus is able to quickly and effectively update its solution when new transfers arrive or unexpected changes happen. These updates involve only small edits to existing transfers. Therefore, as experiments on traces from a large production WAN show, Tempus can offer and keep promises to long-lived transfers well in advance of their actual deadline; the promise on minimal transfer size is comparable with an offline optimal solution and outperforms state-of-the-art solutions by 2-3X. © 2014 ACM.",deadlines; inter-datacenter; mixed packing covering; online temporal planning; software-defined networking; wide area network,Convolutional codes; Linear programming; deadlines; inter-datacenter; Mixed packing; Software-defined networkings; Temporal planning; Wide area networks
"Willis D.F., Dasgupta A., Banerjee S.",3,ParaDrop: A multi-tenant platform for dynamically installed third party services on home gateways,2014,25,"Department of Computer Science, University of Wisconsin - Madison, Madison, WI, United States; Department of Electrical Engineering, University of Wisconsin - Madison, Madison, WI, United States",University of Wisconsin-Madison,1,USA,1,4,3,"The landscape of computing capabilities within the home has seen a recent shift from persistent desktops to mobile platforms, which has led to the use of the cloud as the primary computing platform implemented by developers today. Cloud computing platforms, such as Amazon EC2 and Google App Engine, are popular for many reasons including their reliable, always on, and robust nature. The capabilities that centralized computing platforms provide are inherent to their implementation, and unmatched by previous platforms (e.g., Desktop applications). Thus, third-party developers have come to rely on cloud computing platforms to provide high quality services to their end-users. © 2014 Authors.",edge computing,Computer programming; Computer science; Cloud computing platforms; Computing capability; Computing platform; Desktop applications; Edge computing; Google app engines; High quality service; Third party services; Platform as a Service (PaaS)
"Jin X., Liu H.H., Gandhi R., Kandula S., Mahajan R., Zhang M., Rexford J., Wattenhofer R.",8,Dynamic scheduling of network updates,2014,139,"Microsoft Research, United States; Princeton University, United States; Yale University, United States; Purdue University, United States; ETH Zurich, Switzerland",ETH Zurich;Microsoft;Princeton University;Purdue University;Yale University,5,Switzerland;USA,2,24,18,"We present Dionysus, a system for fast, consistent network updates in software-defined networks. Dionysus encodes as a graph the consistency-related dependencies among updates at individual switches, and it then dynamically schedules these updates based on runtime differences in the update speeds of different switches. This dynamic scheduling is the key to its speed; prior update methods are slow because they pre-determine a schedule, which does not adapt to runtime conditions. Testbed experiments and data-driven simulations show that Dionysus improves the median update speed by 53 - 88% in both wide area and data center networks compared to prior methods. © 2014 ACM.",network update; software-defined networking,Computer simulation; Convolutional codes; Wide area networks; Consistent network; Data center networks; Data-driven simulation; Dynamic scheduling; Runtimes; Software-defined networkings; Software-defined networks; Scheduling
"Zhu L., Hu Z., Heidemann J., Wessels D., Mankin A., Somaiya N.",6,T-DNS: Connection-oriented DNS to improve privacy and security (poster abstract),2014,2,"University of Southern California, United States; Verisign Labs., United States",University of Southern California,1,USA,1,2,2,"DNS is the canonical protocol for connectionless UDP. Yet DNS today is challenged by eavesdropping that compromises privacy, source-address spoofing that results in denial-of-service (DoS) attacks on the server and third parties, injection attacks that exploit fragmentation, and size limitations that constrain policy and operational choices. We propose T-DNS to address these problems. It uses TCP to smoothly support large payloads and to mitigate spoofing and amplification for DoS. T-DNS uses transport-layer security (TLS) to provide privacy from users to their DNS resolvers and optionally to authoritative servers. Our model shows end-to-end latency from TLS to the recursive resolver is only about 9% slower when UDP is used to the authoritative server, and 22% slower with TCP to the authoritative. With diverse traces we show that frequent connection reuse is possible (60-95% for stub and recursive resolvers, although half that for authoritative servers). Our experiment shows that after connection establishment, TCP and TLS latency is equivalent to UDP. With conservative timeouts (20 s at authoritative servers and 60 s elsewhere) and conservative estimates of connection state memory requirements, we show that server memory requirements well within current, commodity server hardware. We identify the key design and implementation decisions needed to minimize overhead: query pipelining, out-of-order responses, TLS connection resumption, and plausible timeouts. This poster abstract summarizes work we describe in detail in ISI-TR-2014-693. © 2014 Authors.",domain name system (DNS); network protocols; performance; privacy; security; transport layer security (TLS),Convolutional codes; Data privacy; Denial-of-service attack; Network security; Seebeck effect; Transmission control protocol; Design and implementations; Domain name system; End-to-end latency; Memory requirements; performance; Privacy and security; security; Transport layer security; Network protocols
"Loch A., Schulz M., Hollick M.",3,WARP drive - Accelerating wireless multi-hop cross-layer experimentation on SDRs,2014,2,"Technische UniversitŠt Darmstadt, Secure Mobile Networking Lab., Mornewegstr. 32, 64293 Darmstadt, Germany",TU Darmstadt,1,Germany,1,35,31,"Rapid prototyping of cross-layer multi-hop schemes in wireless networks often poses a hard challenge. While SDRs allow to implement virtually any cross-layer technique, the underlying programming models for rapid prototyping are inherently designed for one-hop communication. Moreover, existing solutions are typically non-real-time and fall back to offline processing. While this is well-suited for evaluating techniques at the physical layer, the media access control and network layers demand interactivity. Further, network size becomes a critical parameter in multi-hop settings but the size of SDR testbeds is often limited, requiring costly reimplementations in a network simulator to investigate larger settings. We develop a framework to overcome these limitations and enable rapid prototyping of cross-layer multi-hop mechanisms on SDRs. We build on (1) a modular software design to allow for mechanism exchange, (2) a virtual timeline to abstract from the non-real-time nature of transmissions, and (3) a seamless switch from practical experiments to simulations using the same code. We provide a reference implementation of our framework to the community as a starting point for rapid prototyping of cross-layer multi-hop mechanisms. © 2014 Authors.",cross-layer; rapid prototyping; wireless multi-hop networks,Experiments; Medium access control; Network layers; Software radio; Wireless networks; Cross-layer; Cross-layer techniques; Media access control; Modular software designs; Multi-hop mechanism; Off-line processing; Reference implementation; Wireless multi-hop network; Rapid prototyping
"Koll D., Li J., Fu X.",3,"SOUP: An online social network by the people, for the people",2014,2,"University of Gšttingen, Gšttingen, Germany; University of Oregon, Eugene, OR, United States",University of Goettingen;University of Oregon,2,Germany;USA,2,17,16,"With increasing frequency, users raise concerns about data privacy and protection in centralized Online Social Networks (OSNs), in which providers have the unprecedented privilege to access and exploit every user's private data at will. To mitigate these concerns, researchers have suggested to decentralize OSNs and thereby enable users to control and manage access to their data themselves. However, previously proposed decentralization approaches suffer from several drawbacks. To tackle their deficiencies, we introduce the Self-Organized Universe of People (SOUP). In this demonstration, we present a prototype of SOUP and share our experiences from a real-world deployment. © 2014 Authors.",decentralization; DOSN; online social networks,Access control; Convolutional codes; Data privacy; Online systems; decentralization; DOSN; On-line social networks; Online social networks (OSNs); Private data; Real-world; Social networking (online)
"Yang T., Xie G., Li Y., Fu Q., Liu A.X., Li Q., Mathy L.",7,Guarantee IP lookup performance with FIB explosion,2014,31,"ICT, CAS, China; Hunan University, China; Department of Computer Science and Engineering, Michigan State University, United States; University of Liege, Belgium",Hunan University;Michigan State University;University of Liege,3,Belgium;China;USA,3,17,9,"The Forwarding Information Base (FIB) of backbone routers has been rapidly growing in size. An ideal IP lookup algorithm should achieve constant, yet small, IP lookup time and on-chip memory usage. However, no prior IP lookup algorithm achieves both requirements at the same time. In this paper, we first propose SAIL, a Splitting Approach to IP Lookup. One splitting is along the dimension of the lookup process, namely finding the prefix length and finding the next hop, and another splitting is along the dimension of prefix length, namely IP lookup on prefixes of length less than or equal to 24 and IP lookup on prefixes of length longer than 24. Second, we propose a suite of algorithms for IP lookup based on our SAIL framework. Third, we implemented our algorithms on four platforms: CPU, FPGA, GPU, and many-core. We conducted extensive experiments to evaluate our algorithms using real FIBs and real traffic from a major ISP in China. Experimental results show that our SAIL algorithms are several times or even two orders of magnitude faster than well known IP lookup algorithms. © 2014 ACM.",IP lookup; LPM; sail; virtual router multi-FIB lookup,Convolutional codes; Field programmable gate arrays (FPGA); Routers; Information base; IP lookup; IP lookup algorithm; Lookups; LPM; On chip memory; Orders of magnitude; sail; Algorithms
"Nikitopoulos K., Zhou J., Congdon B., Jamieson K.",4,Geosphere: Consistently turning MIMO capacity into throughput,2014,8,"5G Innovation Centre, University of Surrey, United Kingdom; Department of Computer Science, University College London, United Kingdom",University College London;University of Surrey,2,UK,1,3,1,"This paper presents the design and implementation of Geosphere, a physical- and link-layer design for access point-based MIMO wireless networks that consistently improves network throughput. To send multiple streams of data in a MIMO system, prior designs rely on a technique called zero-forcing, a way of ""nulling"" the interference between data streams by mathematically inverting the wireless channel matrix. In general, zero-forcing is highly effective, significantly improving throughput. But in certain physical situations, the MIMO channel matrix can become ""poorly conditioned,"" harming performance. With these situations in mind, Geosphere uses sphere decoding, a more computationally demanding technique that can achieve higher throughput in such channels. To overcome the sphere decoder's computational complexity when sending dense wireless constellations at a high rate, Geosphere introduces search and pruning techniques that incorporate novel geometric reasoning about the wireless constellation. These techniques reduce computational complexity of 256-QAM systems by almost one order of magnitude, bringing computational demands in line with current 16- and 64-QAM systems already realized in ASIC. Geosphere thus makes the sphere decoder practical for the first time in a 4 x 4 MIMO, 256-QAM system. Results from our WARP testbed show that Geosphere achieves throughput gains over multi-user MIMO of 2x in 4 x 4 systems and 47% in 2 x 2 MIMO systems. © 2014 ACM.",distributed MIMO; MIMO; sphere decoder,Computational complexity; Convolutional codes; Design; MIMO systems; Computational demands; Design and implementations; Distributed MIMO; Geometric reasoning; Multiple streams; Network throughput; Pruning techniques; Sphere decoders; Throughput
"Netravali R., Sivaraman A., Winstein K., Das S., Goyal A., Balakrishnan H.",6,Mahimahi: A lightweight toolkit for reproducible web measurement,2014,8,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,42,22,"This demo presents a measurement toolkit, Mahimahi, that records websites and replays them under emulated network conditions. Mahimahi is structured as a set of arbitrarily composable UNIX shells. It includes two shells to record and replay Web pages, RecordShell and ReplayShell, as well as two shells for network emulation, DelayShell and LinkShell. In addition, Mahimahi includes a corpus of recorded websites along with benchmark results and link traces (https://github.com/ravinet/sites). Mahimahi improves on prior record-and-replay frameworks in three ways. First, it preserves the multi-origin nature of Web pages, present in approximately 98% of the Alexa U.S. Top 500, when replaying. Second, Mahimahi isolates its own network traffic, allowing multiple instances to run concurrently with no impact on the host machine and collected measurements. Finally, Mahimahi is not inherently tied to browsers and can be used to evaluate many different applications. A demo of Mahimahi recording and replaying a Web page over an emulated link can be found at http://youtu.be/ vytwDKBA-8s. The source code and instructions to use Mahimahi are available at http://mahimahi.mit.edu/. © 2014 Authors.",page load time; record-and-replay; web measurements,Convolutional codes; Multiple instances; Network condition; Network emulation; Network traffic; page load time; Record-and-replay; Source codes; Web measurements; Websites
"Alizadeh M., Edsall T., Dharmapurikar S., Vaidyanathan R., Chu K., Fingerhut A., Lam V.T., Matus F., Pan R., Yadav N., Varghese G.",11,CONGA: Distributed congestion-aware load balancing for datacenters,2014,134,"Cisco Systems, United States; Google, United States; Microsoft, United States",Google;Microsoft,2,USA,1,70,55,"We present the design, implementation, and evaluation of CONGA, a network-based distributed congestion-aware load balancing mechanism for datacenters. CONGA exploits recent trends including the use of regular Clos topologies and overlays for network virtualization. It splits TCP flows into flowlets, estimates real-time congestion on fabric paths, and allocates flowlets to paths based on feedback from remote switches. This enables CONGA to efficiently balance load and seamlessly handle asymmetry, without requiring any TCP modifications. CONGA has been implemented in custom ASICs as part of a new datacenter fabric. In testbed experiments, CONGA has 5x better flow completion times than ECMP even with a single link failure and achieves 2-8x better throughput than MPTCP in Incast scenarios. Further, the Price of Anarchy for CONGA is provably small in Leaf-Spine topologies; hence CONGA is nearly as effective as a centralized scheduler while being able to react to congestion in microseconds. Our main thesis is that datacenter fabric load balancing is best done in the network, and requires global schemes such as CONGA to handle asymmetry. © 2014 ACM.",datacenter fabric; distributed; load balancing,Convolutional codes; Resource allocation; Topology; Centralized schedulers; Congestion-aware; Datacenter; distributed; Load-balancing mechanisms; Network virtualization; Price of anarchy; Single-link failures; Parallel architectures
"Esposito F., Matta I.",2,A decomposition-based architecture for distributed virtual network embedding,2014,9,"Exegy Inc., St.Louis, MO, United States; Computer Science Department, Boston University, Boston, MA, United States",Boston University;Exegy Inc.,2,USA,1,2,0,"Network protocols have historically been developed on an ad-hoc basis, and cloud computing is no exception. A fundamental management protocol, not yet standardized, that cloud providers need to run to support wide-area virtual network services is the virtual network (VN) embedding protocol. In this paper, we use decomposition theory to provide a unifying architecture for the VN embedding problem. We show how our architecture subsumes existing solutions, and how it can be used by cloud providers to design a distributed VN embedding protocol that adapts to different scenarios, by merely instantiating different decomposition policies. We analyze key representative tradeoffs via simulation, and with our VN embedding testbed that uses a Linux system architecture to reserve virtual node and link capacities. In contrast with existing VN embedding solutions, we found that partitioning a VN request not only increases the signaling overhead, but may decrease cloud providers' revenue. © 2014 ACM.",cross-layer design; decomposition; distributed algorithm; network architecture; network control by pricing; network utility maximization; network virtualization; optimization; resource allocation; virtual network embedding,Cloud computing; Computer operating systems; Decomposition; Economics; Network protocols; Optimization; Parallel algorithms; Resource allocation; Cross-layer design; Network control by pricing; Network utility maximization; Network virtualization; Virtual network embedding; Network architecture
"Mok R.K.P., Li W., Chang R.K.C.",3,A user behavior based cheat detection mechanism for crowdtesting,2014,1,"Department of Computing, Hong Kong Polytechnic University, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,52,41,"Crowdtesting is increasingly popular among researchers to carry out subjective assessments of different services. Experimenters can easily assess to a huge pool of human subjects through crowdsourcing platforms. The workers are usually anonymous, and they participate in the experiments independently. Therefore, a fundamental problem threatening the integrity of these platforms is to detect various types of cheating from the workers. In this poster, we propose cheat-detection mechanism based on an analysis of the workers' mouse cursor trajectories. It provides a jQuery-based library to record browser events. We compute a set of metrics from the cursor traces to identify cheaters. We deploy our mechanism to the survey pages for our video quality assessment tasks published on Amazon Mechanical Turk. Our results show that cheaters' cursor movement is usually more direct and contains less pauses. © 2014 Authors.",cheat-detection; crowdsourcing; cursor submovement,Convolutional codes; Amazon mechanical turks; Cheat detection; Crowdsourcing; Crowdsourcing platforms; Different services; Subjective assessments; Submovements; Video quality assessment; Behavioral research
"Chen S., Fang D., Chen X., Xia T., Jin M.",5,Aerial wireless localization using target-guided flight route,2014,1,"Northwest University, China",Northwest University,1,China,1,22,13,"This poster presents GuideLoc, a highly efficient aerial wireless localization system that uses directional antennas mounted on a mini Multi-rotor Unmanned Aerial Vehicle (UAV), to enable detecting and positioning of targets. Taking advantage of angle and signal strength information of frames transmitted from targets, GuideLoc can directly fly towards the targets with the minimum flight route and time. We implement a prototype of GuideLoc using ArduCopter and evaluate the performance by simulations and experiments. Experimental results show that GuideLoc achieves an average location accuracy of 2.7 meters and reduces flight distance more than 50% compared with other known wireless localization approaches using UAV. © 2014 Authors.",flight routes; multi-rotor UAV; wireless localization,Convolutional codes; Directive antennas; Directional Antenna; Flight route; Location accuracy; Signal strengths; Wireless localization; Wireless localization systems; Unmanned aerial vehicles (UAV)
"Alwabel A., Yu M., Zhang Y., Mirkovic J.",4,SENSS: Observe and control your own traffic in the internet,2014,5,"USC, ISI, United States; USC, United States; Ericsson Research, Germany",Ericsson Research,1,Germany;USA,2,5,3,"We propose a new software-defined security service - SENSS - that enables a victim network to request services from remote ISPs for traffic that carries source IPs or destination IPs from this network's address space. These services range from statistics gathering, to filtering or quality of service guarantees, to route reports or modifications. The SENSS service has very simple, yet powerful, interfaces. This enables it to handle a variety of data plane and control plane attacks, while being easily implementable in today's ISP. Through extensive evaluations on realistic traffic traces and Internet topology, we show how SENSS can be used to quickly, safely and effectively mitigate a variety of large-scale attacks that are largely unhandled today. © 2014 Authors.",design; management; privacy; SDN; security,Convolutional codes; Data privacy; Design; Management; Quality of service; Internet topologies; Large-scale attacks; Quality of service guarantees; Realistic traffics; SDN; security; Security services; Statistics gathering; Internet service providers
"Sharma A., Tie X., Uppal H., Venkataramani A., Westbrook D., Yadav A.",6,A global name service for a highly mobile internetwork,2014,28,"School of Computer Science, University of Massachusetts Amherst, United States",University of Massachusetts Amherst,1,USA,1,3,3,"Mobile devices dominate the Internet today, however the Internet rooted in its tethered origins continues to provide poor infrastructure support for mobility. Our position is that in order to address this problem, a key challenge that must be addressed is the design of a massively scalable global name service that rapidly resolves identities to network locations under high mobility. Our primary contribution is the design, implementation, and evaluation of auspice, a next-generation global name service that addresses this challenge. A key insight underlying auspice is a demand-aware replica {placement engine} that intelligently replicates name records to provide low lookup latency, low update cost, and high availability. We have implemented a prototype of auspice and compared it against several commercial managed DNS providers as well as state-of-the-art research alternatives, and shown that auspice significantly outperforms both. We demonstrate proof-of-concept that auspice can serve as a complete end-to-end mobility solution as well as enable novel context-based communication primitives that generalize name- or address-based communication in today's Internet. © 2014 ACM.",distributed systems; mobility; network architecture,Carrier mobility; Convolutional codes; Mobile devices; Network architecture; Context-Based Communication; Distributed systems; Global name services; High availability; Mobility solutions; Network location; Primary contribution; Proof of concept; Internet
"Bharadia D., Joshi K., Katti S.",3,Robust full duplex radio link,2014,4,"Stanford University, United States",Stanford University,1,USA,1,5,2,"This paper presents demonstration of a real-time full duplex point-to-point link, where transmission and reception occurs in the same spectrum band simultaneously between a pair of full-duplex radios. This demo first builds a full duplex radio by implementing self-interference cancellation technique on top of a traditional half duplex radio architecture. We then establish a point-to-point link using a pair of these radios that can transmit and receive OFDM packets. By changing the environmental conditions around the full-duplex radios we then demonstrate the robustness of the self-interference cancellation to adapt to the changing environment. © 2014 Authors.",full duplex; interference cancellation; wireless radio,Convolutional codes; Radio links; Cancellation techniques; Changing environment; Environmental conditions; Full-duplex; Interference cancellation; Point-to-point link; Radio architectures; Wireless radios; Radio transmission
"Scott C., Wundsam A., Raghavan B., Panda A., Or A., Lai J., Huang E., Liu Z., El-Hassany A., Whitlock S., Acharya H.B., Zarifis K., Shenker S.",13,Troubleshooting blackbox SDN control software with minimal causal sequences,2014,34,"UC Berkeley, United States; Big Switch Networks, United States; ICSI, United States; Tshinghua University, China; EPFL, Switzerland; USC, United States",Tsinghua University;University of California Berkeley,2,China;Switzerland;USA,3,57,32,"Software bugs are inevitable in software-defined networking control software, and troubleshooting is a tedious, time-consuming task. In this paper we discuss how to improve control software troubleshooting by presenting a technique for automatically identifying a minimal sequence of inputs responsible for triggering a given bug, without making assumptions about the language or instrumentation of the software under test. We apply our technique to five open source SDN control platforms - -Floodlight, NOX, POX, Pyretic, ONOS - and illustrate how the minimal causal sequences our system found aided the troubleshooting process. © 2014 ACM.",SDN control software; test case minimization; troubleshooting,Convolutional codes; Diagnosis; Electric lighting; Open source software; Program debugging; Software testing; Black boxes; Control platform; Control software; Open sources; Software bug; Software-defined networkings; Test-case minimizations; Time-consuming tasks; Open systems
"Liu Y.J., Gao P.X., Wong B., Keshav S.",4,Quartz: A new design element for low-latency DCNs,2014,17,"University of Waterloo, Canada; UC Berkeley, United States",University of California Berkeley;University of Waterloo,2,Canada;USA,2,8,6,"Most datacenter network (DCN) designs focus on maximizing bisection bandwidth rather than minimizing server-to-server latency. We explore architectural approaches to building low-latency DCNs and introduce Quartz, a design element consisting of a full mesh of switches. Quartz can be used to replace portions of either a hierarchical network or a random network. Our analysis shows that replacing high port-count core switches with Quartz can significantly reduce switching delays, and replacing groups of top-of-rack and aggregation switches with Quartz can significantly reduce congestion-related delays from cross-traffic. We overcome the complexity of wiring a complete mesh using low-cost optical multiplexers that enable us to efficiently implement a logical mesh as a physical ring. We evaluate our performance using both simulations and a small working prototype. Our evaluation results confirm our analysis, and demonstrate that it is possible to build low-latency DCNs using inexpensive commodity elements without significant concessions to cost, scalability, or wiring complexity. © 2014 ACM.",datacenter; latency; optical technologies; WDM,Complex networks; Convolutional codes; Cost benefit analysis; Design; Telecommunication networks; Wavelength division multiplexing; Architectural approach; Bisection bandwidth; Data center networks; Datacenter; Hierarchical network; latency; Optical multiplexers; Optical technology; Quartz
"Rashmi K.V., Shah N.B., Gu D., Kuang H., Borthakur D., Ramchandran K.",6,"A ""hitchhiker's"" guide to fast and efficient data reconstruction in erasure-coded data centers",2014,50,"UC Berkeley, United States; Facebook, United States",Facebook;University of California Berkeley,2,USA,1,61,0,"Erasure codes such as Reed-Solomon (RS) codes are being extensively deployed in data centers since they offer significantly higher reliability than data replication methods at much lower storage overheads. These codes however mandate much higher resources with respect to network bandwidth and disk IO during reconstruction of data that is missing or otherwise unavailable. Existing solutions to this problem either demand additional storage space or severely limit the choice of the system parameters. In this paper, we present ""Hitchhiker"", a new erasure-coded storage system that reduces both network traffic and disk IO by around 25% to 45% during reconstruction of missing or otherwise unavailable data, with no additional storage, the same fault tolerance, and arbitrary flexibility in the choice of parameters, as compared to RS-based systems. Hitchhiker 'rides' on top of RS codes, and is based on novel encoding and decoding techniques that will be presented in this paper. We have implemented Hitchhiker in the Hadoop Distributed File System (HDFS). When evaluating various metrics on the data-warehouse cluster in production at Facebook with real-time traffic and workloads, during reconstruction, we observe a 36% reduction in the computation time and a 32% reduction in the data read time, in addition to the 35% reduction in network traffic and disk IO. Hitchhiker can thus reduce the latency of degraded reads and perform faster recovery from failed or decommissioned machines. © 2014 ACM.",degraded reads; disk IO; distributed storage; erasure codes; fault tolerance; network traffic; recovery,Convolutional codes; Digital storage; Fault tolerance; Forward error correction; Recovery; degraded reads; disk IO; Distributed storage; Erasure codes; Network traffic; Data reduction
"Antonescu A.-F., Braun T.",2,Modeling and simulation of concurrent workload processing in cloud-distributed enterprise information systems,2014,4,"SAP (Switzerland) Inc., Products and Innovation, Research, Althardstrasse 80, 8105 Regensdorf, Switzerland; University of Bern, Communication and Distributed Systems (CDS), NeubrŸckstrasse 10, 3012 Bern, Switzerland",SAP (Switzerland) Inc.;University of Bern,2,Switzerland,1,43,39,"Cloud Computing enables provisioning and distribution of highly scalable services in a reliable, on-demand and sustainable manner. Distributed Enterprise Information Systems (dEIS) are a class of applications with important economic value and with strong requirements in terms of performance and reliability. In order to validate dEIS architectures, stability, scaling and SLA compliance, large testing deployments are necessary, adding complexity to the design and testing of such systems. To fill this gap, we present and validate a methodology for modeling and simulating such complex distributed systems using the CloudSim cloud computing simulator, based on measurement data from an actual distributed system. We present an approach for creating a performance-based model of a distributed cloud application using recorded service performance traces. We then show how to integrate the created model into CloudSim. We validate the CloudSim simulation model by comparing performance traces gathered during distributed concurrent experiments with simulation results using different VM configurations. We demonstrate the usefulness of using a cloud simulator for modeling properties of real cloud-distributed applications. © 2014 ACM.",cloud computing; distributed applications; modelling and simulation; performance profiling,Cloud computing; Computer simulation; Cloud computing simulators; Complex distributed system; Distributed applications; Enterprise information system; Modelling and simulations; Performance and reliabilities; performance profiling; Performance-based models; Information systems
"Sundaresan S., Feamster N., Teixeira R.",3,Locating throughput bottlenecks in home networks,2014,5,"Georgia Tech., United States; INRIA, United States",Georgia Tech;INRIA,2,USA,1,32,25,"We present a demonstration of WTF (Where's The Fault?), a system that localizes performance problems in home and access networks. We implement WTF as custom firmware that runs in an off-the-shelf home router. WTF uses timing and buffering information from passively monitored traffic at home routers to detect both access link and wireless network bottlenecks. © 2014 Authors.",bottleneck location; home networks; performance diagnosis; troubleshooting,Convolutional codes; Diagnosis; Firmware; Personal communication systems; Routers; Access links; Access network; Bottleneck location; Home routers; Network bottlenecks; Performance diagnosis; Performance problems; Home networks
"Nguyen D., Sahin C., Shishkin B., Kandasamy N., Dandekar K.R.",5,A real-time and protocol-aware reactive jamming framework built on software-defined radios,2014,12,"Drexel Wireless System Laboratory, Drexel University, 3141 Chestnut St., Philadelphia, PA 19104, United States",Drexel University,1,USA,1,11,8,"This paper develops a software-defined radio (SDR) framework for real-time reactive adversarial jamming in wireless networks. The system consists of detection and RF response infrastructure, implemented in the FPGA of a USRP N210 and designed to function with the open source GNU Radio SDR library. The framework can be used to implement a fast turnaround reactive jamming system capable of timely RF response within \textit{80ns} of signal detection. Our framework also allows for full control and feedback from the FPGA hardware to the GNU Radio-based cognitive radio backend, making it applicable to a wide range of preamble-based wireless communication schemes. This paper presents the capabilities, design, and experimental evaluation of this framework. Using this platform, we demonstrate real-time reactive jamming capabilities in both WiFi (802.11g) and mobile WiMAX (802.16e) networks and quantify jamming performances by measuring the network throughput using the iperf software tool. The results indicate that our system works reliably in real time as a reactive jammer and can be used for practical assessments of modern jamming and secure communication techniques. © 2014 ACM.",denial of service; reactive jamming; software radios,Denial-of-service attack; Field programmable gate arrays (FPGA); Open source software; Open systems; Radio receivers; Software radio; Wi-Fi; Wireless telecommunication systems; Denial of Service; Experimental evaluation; FPGA hardwares; Jamming systems; Network throughput; Secure communications; Software-defined radios; Wireless communications; Jamming
"Paasch C., Ferlin S., Alay O., Bonaventure O.",4,Experimental evaluation of multipath TCP schedulers,2014,78,"ICTEAM, UCLouvain, Belgium; Simula Research Laboratory, Fornebu, Norway",Simula Research,1,Belgium;Norway,2,2,1,"Today many end hosts are equipped with multiple interfaces. These interfaces can be utilized simultaneously by multipath protocols to pool resources of the links in an efficient way while also providing resilience to eventual link failures. However how to schedule the data segments over multiple links is a challenging problem, and highly influences the performance of multipath protocols. In this paper, we focus on different schedulers for Multipath TCP. We first design and implement a generic modular scheduler framework that enables testing of different schedulers for Multipath TCP. We then use this framework to do an in-depth analysis of different schedulers by running emulated and real-world experiments on a testbed. We consider bulk data transfer as well as application limited traffic and identify metrics to quantify the scheduler's performance. Our results shed light on how scheduling decisions can help to improve multipath transfer. © 2014 ACM.",experimenting; multipath tcp; scheduling,Data transfer; Transmission control protocol; Experimental evaluation; experimenting; Multipath protocols; Multipath TCP; Multipath transfers; Multiple interfaces; Real world experiment; Scheduling decisions; Scheduling
"Jiang A.H., Bischof Z.S., Bustamante F.E.",3,A cliq of content curators,2014,1,"Northwestern University, United States",Northwestern University,1,USA,1,15,13,"A social news site presents user-curated content, ranked by popularity. Popular curators like Reddit, or Facebook have become effective way of crowdsourcing news or sharing for personal opinions. Traditionally, these services require a centralized authority to aggregate data and determine what to display. However, the trust issues that arise from a centralized system are particularly damaging to the ""Web democracy"" that social news sites are meant to provide. In this poster, we present cliq, a decentralized social news curator. cliq is a P2P based social news curator that provides private and unbiased reporting. All users in cliq share responsibility for tracking and providing popular content. Any user data that cliq needs to store is also managed across the network. We first inform our design of cliq through an analysis of Reddit. We design a way to provide content curation without a persistent moderator, or usernames. © 2014 Authors.",P2P systems; social news curation,Aggregate datum; Centralized systems; Content curation; Crowdsourcing; Curation; P2P system; P2P-based; Social news; Convolutional codes
"Wang J., Vasisht D., Katabi D.",3,RF-IDraw: Virtual touch screen in the air using RF signals,2014,104,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,23,21,"Prior work in RF-based positioning has mainly focused on discovering the absolute location of an RF source, where state-of-the-art systems can achieve an accuracy on the order of tens of centimeters using a large number of antennas. However, many applications in gaming and gesture based interface see more benefits in knowing the detailed shape of a motion. Such trajectory tracing requires a resolution several fold higher than what existing RF-based positioning systems can offer. This paper shows that one can provide a dramatic increase in trajectory tracing accuracy, even with a small number of antennas. The key enabler for our design is a multi-resolution positioning technique that exploits an intrinsic tradeoff between improving the resolution and resolving ambiguity in the location of the RF source. The unique property of this design is its ability to precisely reconstruct the minute details in the trajectory shape, even when the absolute position might have an offset. We built a prototype of our design with commercial off-the-shelf RFID readers and tags and used it to enable a virtual touch screen, which allows a user to interact with a desired computing device by gesturing or writing her commands in the air, where each letter is only a few centimeters wide. © 2014 ACM.",grating lobes; RFID; trajectory tracing; virtual touch screen,Antennas; Convolutional codes; Design; Radio frequency identification (RFID); Trajectories; Commercial off the shelves; Gesture-based interface; Grating lobes; Positioning techniques; Resolving ambiguities; State-of-the-art system; Trajectory tracing; Virtual touch screens; Human computer interaction
"Huang T.-Y., Johari R., McKeown N., Trunnell M., Watson M.",5,A buffer-based approach to rate adaptation: Evidence from a large video streaming service,2014,161,"Stanford University, United States; Netflix, United States",Stanford University,1,USA,1,1,0,"Existing ABR algorithms face a significant challenge in estimating future capacity: capacity can vary widely over time, a phenomenon commonly observed in commercial services. In this work, we suggest an alternative approach: rather than presuming that capacity estimation is required, it is perhaps better to begin by using only the buffer, and then ask when capacity estimation is needed. We test the viability of this approach through a series of experiments spanning millions of real users in a commercial service. We start with a simple design which directly chooses the video rate based on the current buffer occupancy. Our own investigation reveals that capacity estimation is unnecessary in steady state; however using simple capacity estimation (based on immediate past throughput) is important during the startup phase, when the buffer itself is growing from empty. This approach allows us to reduce the rebuffer rate by 10-20% compared to Netflix's then-default ABR algorithm, while delivering a similar average video rate, and a higher video rate in steady state. © 2014 ACM.",http-based video streaming; video rate adaptation algorithm,Algorithms; Buffer amplifiers; Video streaming; Capacity estimation; Commercial services; Current buffer; HTTP-based video streaming; Rate adaptation; Start-up phase; Video rate adaptation; Video streaming services; Convolutional codes
"Manco F., Martins J., Huici F.",3,Towards the super fluid cloud,2014,1,"NEC Europe Ltd., United Kingdom",NEC,1,UK,1,41,16,"Traditionally, the number of VMs running on a server and how quickly these can be migrated has been less than optimal mostly because of the memory and CPU requirements imposed on the system by the full-fledged OSes that the VMs run. More recently, work towards VMs based on minimalistic or specialized OSes has started pushing the envelope of how reactive or fluid the cloud can be. In this demo we will demonstrate how to concurrently execute thousands of Xen-based VMs on a single inexpensive server. We will also show instantiation and migraion of such VMs in tens of milliseconds, and transparent, wide area migration of virtualized middleboxes by combining such VMs with the multi-path TCP (MPTCP) protocol. © 2014 Authors.",cloud; performance; server consolidation; virtualization; xen,Clouds; Convolutional codes; Middleboxes; performance; Server consolidation; Virtualizations; xen; Transmission control protocol
"Rasley J., Stephens B., Dixon C., Rozner E., Felter W., Agarwal K., Carter J., Fonseca R.",8,Planck: Millisecond-scale monitoring and control for commodity networks,2014,47,"Brown University, United States; Rice University, United States; IBM Research, Austin, TX, United States; Brocade, United States",Brown University;IBM;Rice University,3,USA,1,21,18,"Software-defined networking introduces the possibility of building self-tuning networks that constantly monitor network conditions and react rapidly to important events such as congestion. Unfortunately, state-of-the-art monitoring mechanisms for conventional networks require hundreds of milliseconds to seconds to extract global network state, like link utilization or the identity of ""elephant"" flows. Such latencies are adequate for responding to persistent issues, e.g., link failures or long-lasting congestion, but are inadequate for responding to transient problems, e.g., congestion induced by bursty workloads sharing a link. In this paper, we present Planck, a novel network measurement architecture that employs oversubscribed port mirroring to extract network information at 280 _s - 7 ms timescales on a 1 Gbps commodity switch and 275 _s - 4 ms timescales on a 10 Gbps commodity switch,over 11x and 18x faster than recent approaches, respectively (and up to 291x if switch firmware allowed buffering to be disabled on some ports). To demonstrate the value of Planck's speed and accuracy, we use it to drive a traffic engineering application that can reroute congested flows in milliseconds. On a 10 Gbps commodity switch, Planck-driven traffic engineering achieves aggregate throughput within 1 - 4% of optimal for most workloads we evaluated, even with flows as small as 50 MiB, an improvement of up to 53% over previous schemes. © 2014 ACM.",networking measurement; software-defined networking; traffic engineering,Firmware; Aggregate throughput; Monitoring and control; Monitoring mechanisms; Network information; Network measurement; Software-defined networkings; Traffic Engineering; Transient problems; Convolutional codes
"Kumar S., Hamed E., Katabi D., Erran Li L.",4,LTE radio analytics made easy and accessible,2014,39,"Massachusetts Institute of Technology, United States; Bell Labs., Alcatel-Lucent, United States",Bell Labs;MIT,2,USA,1,11,10,"Despite the rapid growth of next-generation cellular networks, researchers and end-users today have limited visibility into the performance and problems of these networks. As LTE deployments move towards femto and pico cells, even operators struggle to fully understand the propagation and interference patterns affecting their service, particularly indoors. This paper introduces LTEye, the first open platform to monitor and analyze LTE radio performance at a fine temporal and spatial granularity. LTEye accesses the LTE PHY layer without requiring private user information or provider support. It provides deep insights into the PHY-layer protocols deployed in these networks. LTEye's analytics enable researchers and policy makers to uncover serious deficiencies in these networks due to inefficient spectrum utilization and inter-cell interference. In addition, LTEye extends synthetic aperture radar (SAR), widely used for radar and backscatter signals, to operate over cellular signals. This enables businesses and end-users to localize mobile users and capture the distribution of LTE performance across spatial locations in their facility. As a result, they can diagnose problems and better plan deployment of repeaters or femto cells. We implement LTEye on USRP software radios, and present empirical insights and analytics from multiple AT&T and Verizon base stations in our locality. © 2014 ACM.",analytics; cellular; LTE; PHY; wireless,Convolutional codes; Mobile telecommunication systems; Next generation networks; Radio; Synthetic aperture radar; analytics; cellular; Intercell interference; Interference patterns; LTE; PHY; Spectrum utilization; Temporal and spatial; Wireless telecommunication systems
"Naylor D., Mukerjee M.K., Steenkiste P.",3,Balancing accountability and privacy in the network,2014,9,"Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,44,29,"Though most would agree that accountability and privacy are both valuable, today's Internet provides little support for either. Previous efforts have explored ways to offer stronger guarantees for one of the two, typically at the expense of the other; indeed, at first glance accountability and privacy appear mutually exclusive. At the center of the tussle is the source address: in an accountable Internet, source addresses undeniably link packets and senders so hosts can be punished for bad behavior. In a privacy-preserving Internet, source addresses are hidden as much as possible. In this paper, we argue that a balance is possible. We introduce the Accountable and Private Internet Protocol (APIP), which splits source addresses into two separate fields - an accountability address and a return address - and introduces independent mechanisms for managing each. Accountability addresses, rather than pointing to hosts, point to accountability delegates, which agree to vouch for packets on their clients' behalves, taking appropriate action when misbehavior is reported. With accountability handled by delegates, senders are now free to mask their return addresses; we discuss a few techniques for doing so. © 2014 ACM.",accountability; privacy; source address,Convolutional codes; Data privacy; Internet protocols; accountability; Privacy preserving; Source address; Internet
"Wu Y., Zhao M., Haeberlen A., Zhou W., Loo B.T.",5,Diagnosing missing events in distributed systems with negative provenance,2014,19,"University of Pennsylvania, United States; Georgetown University, United States",Georgetown University;University of Pennsylvania,2,USA,1,31,20,"When debugging a distributed system, it is sometimes necessary to explain the absence of an event - for instance, why a certain route is not available, or why a certain packet did not arrive. Existing debuggers offer some support for explaining the presence of events, usually by providing the equivalent of a backtrace in conventional debuggers, but they are not very good at answering 'Why not?' questions: there is simply no starting point for a possible backtrace. In this paper, we show that the concept of negative provenance can be used to explain the absence of events in distributed systems. Negative provenance relies on counterfactual reasoning to identify the conditions under which the missing event could have occurred. We define a formal model of negative provenance for distributed systems, and we present the design of a system called Y! that tracks both positive and negative provenance and can use them to answer diagnostic queries. We describe how we have used Y! to debug several realistic problems in two application domains: software-defined networks and BGP interdomain routing. Results from our experimental evaluation show that the overhead of Y! is moderate. © 2014 ACM.",debugging; diagnostics; provenance,Computer debugging; Convolutional codes; Plasma diagnostics; Query processing; Debuggers; Distributed systems; Experimental evaluation; Formal model; Interdomain Routing; provenance; Software-defined networks; Program diagnostics
"Kim T.H.-J., Basescu C., Jia L., Lee S.B., Hu Y.-C., Perrig A.",6,Lightweight source authentication and path validation,2014,30,"CyLab, CMU, United States; ETH ZŸrich, Switzerland; Qualcomm, United States; UIUC, United States",ETH Zurich;UIUC,2,Switzerland;USA,2,38,22,"In-network source authentication and path validation are fundamental primitives to construct higher-level security mechanisms such as DDoS mitigation, path compliance, packet attribution, or protection against flow redirection. Unfortunately, currently proposed solutions either fall short of addressing important security concerns or require a substantial amount of router overhead. In this paper, we propose lightweight, scalable, and secure protocols for shared key setup, source authentication, and path validation. Our prototype implementation demonstrates the efficiency and scalability of the protocols, especially for software-based implementations. © 2014 ACM.",path validation; retroactive key setup; source authentication,Convolutional codes; Routers; Ddos mitigations; Higher-level security; In networks; Key setups; path validation; Prototype implementations; Secure protocols; Source authentication; Authentication
"Donovan S., Feamster N.",2,NetAssay: Providing new monitoring primitives for network operators,2014,1,"Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,37,28,"Home and business network operators have limited network statistics available over which management decisions can be made. Similarly, there are few triggered behaviors, such as usage or bandwidths cap for individual users, that are available. By looking at sources of traffic, based on Domain Name System (DNS) cues for content of particular web addresses or source Autonomous System (AS) of the traffic, network operators could create new and interesting rules for their network. NetAssay is a Software-Defined Networking (SDN)-based, network-wide monitoring and reaction framework. By integrating information from Border Gateway Protocol (BGP) and the Domain Name System, NetAssay is able to integrate formerly disparate sources of control information, and use it to provide better monitoring, more useful triggered events, and security benefits for network operators. © 2014 Authors.",network management; network monitoring; software-defined networking,Convolutional codes; Gateways (computer networks); Internet protocols; Network management; Autonomous systems; Border gateway protocol; Control information; Integrating information; Management decisions; Network Monitoring; Network statistics; Software-defined networkings; Network protocols
"Martin J., Hong G., Westall J.",3,Managing fairness and application performance with active queue management in DOCSIS-based cable networks,2014,4,"Clemson University, Clemson, SC, United States",Clemson University,1,USA,1,40,27,"We evaluate modern delay-based AQM algorithms in downstream DOCSIS 3.0 cable environments. Our focus is on fairness and application performance capabilities of two recently proposed delay-based AQM algorithms, CoDel and PIE. The evaluation involves scenarios that include tiered service levels and application workloads that include FTP, HTTP-based adaptive streaming, and VoIP traffic. Our results provide a snapshot of our current effort to evaluate AQM schemes that are likely to be deployed in emerging DOCSIS cable networks. © 2014 ACM.",cable access; network performance evaluation; packet scheduling algorithms,Algorithms; Cables; Internet telephony; Active Queue Management; Adaptive streaming; Application performance; Cable networks; DOCSIS cable networks; Network performance evaluation; Packet scheduling algorithm; Service levels; Telecommunication networks
"Xiang Y., Liu H., Lan T., Huang H., Subramaniam S.",5,"Optimizing job reliability via contention-free, distributed scheduling of vm checkpointing",2014,2,"George Washington University, Washington, DC, United States",George Washington University,1,USA,1,6,4,"Checkpointing a virtual machine (VM) is a proven technique to improve the reliability in modern datacenters. Inspired by the CSMA protocol in wireless congestion control, we propose a novel framework for distributed and contention-free scheduling of VM checkpointing to offer reliability as a transparent, elastic service in datacenters. In this work, we quantify the reliability in closed form by studying system stationary behaviors, and maximize the job reliability through utility optimization. We implement a proof-of-concept prototype based on our design. Evaluation results show that the proposed checkpoint scheduling can significantly reduce the performance interference from checkpointing and improve reliability by as much as one order of magnitude over contention-oblivious scheme. © 2014 ACM.",checkpoint; csma-based; data center; optimization.; reliability; scheduling,Cloud computing; Interference suppression; Optimization; Reliability; checkpoint; csma-based; Data centers; Distributed scheduling; Evaluation results; Proof of concept; Stationary behavior; Utility optimizations; Scheduling
"Parks A.N., Liu A., Gollakota S., Smith J.R.",4,Turbocharging ambient backscatter communication,2014,51,"University of Washington, United States",University of Washington at Seattle,1,USA,1,19,12,"Communication primitives such as coding and multiple antenna processing have provided significant benefits for traditional wireless systems. Existing designs, however, consume significant power and computational resources, and hence cannot be run on low complexity, power constrained backscatter devices. This paper makes two main contributions: (1) we introduce the first multi-antenna cancellation design that operates on backscatter devices while retaining a small form factor and power footprint, (2) we introduce a novel coding mechanism that enables long range communication as well as concurrent transmissions and can be decoded on backscatter devices. We build hardware prototypes of the above designs that can be powered solely using harvested energy from TV and solar sources. The results show that our designs provide benefits for both RFID and ambient backscatter systems: they enable RFID tags to communicate directly with each other at distances of tens of meters and through multiple walls. They also increase the communication rate and range achieved by ambient backscatter systems by 100X and 40X respectively. We believe that this paper represents a substantial leap in the capabilities of backscatter communication. © 2014 ACM.",backscatter; energy harvesting; internet of things; wireless,Convolutional codes; Design; Energy harvesting; Internet of things; Radio; Television antennas; Communication primitives; Communication rate; Computational resources; Concurrent transmission; Hardware prototype; Long-range communications; Multiple-antenna processing; Small form factors; Backscattering
"Gember-Jacobson A., Viswanathan R., Prakash C., Grandl R., Khalid J., Das S., Akella A.",7,OpenNF: Enabling innovation in network function control,2014,163,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,13,8,"Network functions virtualization (NFV) together with software-defined networking (SDN) has the potential to help operators satisfy tight service level agreements, accurately monitor and manipulate network traffic, and minimize operating expenses. However, in scenarios that require packet processing to be redistributed across a collection of network function (NF) instances, simultaneously achieving all three goals requires a framework that provides efficient, coordinated control of both internal NF state and network forwarding state. To this end, we design a control plane called OpenNF. We use carefully designed APIs and a clever combination of events and forwarding updates to address race conditions, bound overhead, and accommodate a variety of NFs. Our evaluation shows that OpenNF offers efficient state control without compromising flexibility, and requires modest additions to NFs. © 2014 ACM.",middleboxes; network functions; software-defined networking,Convolutional codes; Co-ordinated control; Forwarding state; Middleboxes; Network functions; Operating expense; Packet processing; Service Level Agreements; Software-defined networkings; Network architecture
"Munir A., Baig G., Irteza S.M., Qazi I.A., Liu A.X., Dogar F.R.",6,"Friends, not foes - Synthesizing existing transport strategies for data center networks",2014,45,"Michigan State University, United States; LUMS, Pakistan; Microsoft Research, United States",LUMS;Michigan State University;Microsoft,3,Pakistan;USA,2,41,29,"Many data center transports have been proposed in recent times (e.g., DCTCP, PDQ, pFabric, etc). Contrary to the common perception that they are competitors (i.e., protocol A vs. protocol B), we claim that the underlying strategies used in these protocols are, in fact, complementary. Based on this insight, we design PASE, a transport framework that synthesizes existing transport strategies, namely, self-adjusting endpoints (used in TCP style protocols), innetwork prioritization (used in pFabric), and arbitration (used in PDQ). PASE is deployment friendly: it does not require any changes to the network fabric; yet, its performance is comparable to, or better than, the state-of-the-art protocols that require changes to network elements (e.g., pFabric). We evaluate PASE using simulations and testbed experiments. Our results show that PASE performs well for a wide range of application workloads and network settings. © 2014 ACM.",datacenter; scheduling; transport,Convolutional codes; Scheduling; Data center networks; Datacenter; Network element; Network fabric; Network settings; Prioritization; transport; Transport strategies; Transmission control protocol
"Gandhi R., Liu H.H., Hu Y.C., Lu G., Padhye J., Yuan L., Zhang M.",7,Duet: Cloud scale load balancing with hardware and software,2014,33,"Microsoft, United States; Purdue University, United States; Yale University, United States",Microsoft;Purdue University;Yale University,3,USA,1,38,21,"Load balancing is a foundational function of datacenter infrastructures and is critical to the performance of online services hosted in datacenters. As the demand for cloud services grows, expensive and hard-to-scale dedicated hardware load balancers are being replaced with software load balancers that scale using a distributed data plane that runs on commodity servers. Software load balancers offer low cost, high availability and high flexibility, but suffer high latency and low capacity per load balancer, making them less than ideal for applications that demand either high throughput, or low latency or both. In this paper, we present Duet, which offers all the benefits of software load balancer, along with low latency and high availability - at next to no cost. We do this by exploiting a hitherto overlooked resource in the data center networks - the switches themselves. We show how to embed the load balancing functionality into existing hardware switches, thereby achieving organic scalability at no extra cost. For flexibility and high availability, Duet seamlessly integrates the switch-based load balancer with a small deployment of software load balancer. We enumerate and solve several architectural and algorithmic challenges involved in building such a hybrid load balancer. We evaluate Duet using a prototype implementation, as well as extensive simulations driven by traces from our production data centers. Our evaluation shows that Duet provides 10x more capacity than a software load balancer, at a fraction of a cost, while reducing latency by a factor of 10 or more, and is able to quickly adapt to network dynamics including failures. © 2014 ACM.",datacenter; load balancing; SDN,Computer hardware; Convolutional codes; Costs; Hardware; Parallel architectures; Resource allocation; Data center networks; Datacenter; Dedicated hardware; Extensive simulations; Hardware and software; High availability; Prototype implementations; SDN; Application programs
"Kerttula J., Malm N., Ruttik K., JŠntti R., Tirkkonen O.",5,Implementing TD-LTE as software defined radio in general purpose processor,2014,10,"Department of Communications and Networking, School of Electrical Engineering, Aalto University, Espoo, Finland",Aalto University,1,Finland,1,25,3,"Cloud radio access networks use servers that are connected to Remote Radio Heads (RRH). Base station (BS) implementation with this concept is challenging. The strict real-time nature of baseband (BB) processing seems to rule out usage of General Purpose Processors (GPP) with non-real time Operating Systems (OS). In this paper, we propose a BS architecture where most of the real-time processing is confined into a Virtual Hardware Enhancement Layer (VHEL). VHEL hides the hardware non-idealities from the software and vice versa. Possible errors due to the non-real-time OS and RRH appear as channel errors, which makes software development easier. We demonstrate the benefits of our architecture by implementing a Time-Division LTE system (TD-LTE) in C++ and running it as a user process in an Intel i7 class PC. Over-the-air transmissions are realized using USRPs. We report the performance of the implemented platform. We observe that with the given VHEL the transmitter and receiver never lose synchronization. Also the PC tends to be quick enough to feed the data; and the loss rate of subframes due to the non-real-time nature of the platform is relatively low. The proposed platform provides the possibility to implement TD-LTE on GPPs and virtual machines. © 2014 ACM.",prototyping; sdr architecture; sdr programming model,Computer hardware; Computer programming; Embedded systems; Errors; Hardware; Network architecture; Software prototyping; Software radio; Enhancement Layers; General purpose processors; Programming models; Radio access networks; Realtime processing; Remote radio heads; Software-defined radios; Transmitter and receiver; C++ (programming language)
"Wang T., Liew S.C., You L.",3,Joint phase tracking and channel decoding for OFDM PNC: Algorithm and experimental evaluation,2014,3,"Dept. of Inform. Engineering, CUHK, Hong Kong, Hong Kong",Chinese University of Hong Kong,1,Hong Kong,1,23,15,"This paper investigates the problem of joint phase tracking and channel decoding in OFDM based Physical-layer Network Coding (PNC) systems. OFDM signaling can obviate the need for tight time synchronization among multiple simultaneous transmissions in the uplink of PNC systems. However, OFDM PNC systems are susceptible to phase drifts caused by residual carrier frequency offsets (CFOs). In the traditional OFDM system in which a receiver receives from only one transmitter, pilot tones are employed to aid phase tracking. In OFDM PNC systems, multiple transmitters transmit to a receiver, and these pilot tones are shared among the multiple transmitters. This reduces the number of pilots that can be used by each transmitting node. Phase tracking in OFDM PNC is more challenging as a result. To overcome the degradation due to the reduced number of per-node pilots, this work supplements the pilots with the channel information contained in the data. In particular, we propose to solve the problems of phase tracking and channel decoding jointly. Our solution consists of the use of the expectation-maximization (EM) algorithm for phase tracking and the use of the belief propagation (BP) algorithm for channel decoding. The two problems are solved jointly through iterative processing between the EM and BP algorithms. Simulations and real experiments based on software-defined radio (SDR) show that the proposed method can improve phase tracking as well as channel decoding performance. © 2014 ACM.",belief propagation; expectation-maximization; ofdm; phase tracking; physical-layer network coding; sdr experimentation,Backpropagation; Decoding; Experiments; Iterative methods; Maximum principle; Network coding; Orthogonal frequency division multiplexing; Problem solving; Software radio; Transmitters; Belief propagation; Expectation Maximization; Phase tracking; Physical-layer network coding; sdr experimentation; Algorithms
"Peter S., Javed U., Zhang Q., Woos D., Anderson T., Krishnamurthy A.",6,One tunnel is (often) enough,2014,14,"University of Washington, United States",University of Washington at Seattle,1,USA,1,23,18,"A longstanding problem with the Internet is that it is vulnerable to outages, black holes, hijacking and denial of service. Although architectural solutions have been proposed to address many of these issues, they have had difficulty being adopted due to the need for widespread adoption before most users would see any benefit. This is especially relevant as the Internet is increasingly used for applications where correct and continuous operation is essential. In this paper, we study whether a simple, easy to implement model is sufficient for addressing the aforementioned Internet vulnerabilities. Our model, called ARROW (Advertised Reliable Routing Over Waypoints), is designed to allow users to configure reliable and secure end to end paths through participating providers. With ARROW, a highly reliable ISP offers tunneled transit through its network, along with packet transformation at the ingress, as a service to remote paying customers. Those customers can stitch together reliable end to end paths through a combination of participating and non-participating ISPs in order to improve the fault-tolerance, robustness, and security of mission critical transmissions. Unlike efforts to redesign the Internet from scratch, we show that ARROW can address a set of well-known Internet vulnerabilities, for most users, with the adoption of only a single transit ISP. To demonstrate ARROW, we have added it to a small-scale wide-area ISP we control. We evaluate its performance and failure recovery properties in both simulation and live settings. © 2014 ACM.",BGP; internet; overlay networks; reliability; source routing,Convolutional codes; Denial-of-service attack; Fault tolerance; Internet; Overlay networks; Reliability; Architectural solutions; BGP; Continuous operation; Denial of Service; Failure recovery; Mission critical; Packet transformations; Source routing; Internet service providers
"Gupta A., Vanbever L., Shahbaz M., Donovan S.P., Schlinker B., Feamster N., Rexford J., Shenker S., Clark R., Katz-Bassett E.",10,SDX: A software defined Internet exchange,2014,87,"Georgia Tech., United States; Princeton University, United States; UC Berkeley, United States; Univ. of Southern California, United States",Georgia Tech;Princeton University;University of California Berkeley,3,USA,1,20,9,"BGP severely constrains how networks can deliver traffic over the Internet. Today's networks can only forward traffic based on the destination IP prefix, by selecting among routes offered by their immediate neighbors. We believe Software Defined Networking (SDN) could revolutionize wide-area traffic delivery, by offering direct control over packet-processing rules that match on multiple header fields and perform a variety of actions. Internet exchange points (IXPs) are a compelling place to start, given their central role in interconnecting many networks and their growing importance in bringing popular content closer to end users. To realize a Software Defined IXP (an ""SDX""), we must create compelling applications, such as ""application-specific peering"" - where two networks peer only for (say) streaming video traffic. We also need new programming abstractions that allow participating networks to create and run these applications and a runtime that both behaves correctly when interacting with BGP and ensures that applications do not interfere with each other. Finally, we must ensure that the system scales, both in rule-table size and computational overhead. In this paper, we tackle these challenges and demonstrate the flexibility and scalability of our solutions through controlled and in-the-wild experiments. Our experiments demonstrate that our SDX implementation can implement representative policies for hundreds of participants who advertise full routing tables while achieving sub-second convergence in response to configuration changes and routing updates. © 2014 Authors.",BGP; internet exchange point (IXP); software defined networking (SDN),Computer programming; Convolutional codes; Experiments; BGP; Computational overheads; Internet Exchange; Internet exchange points; Programming abstractions; Software defined networking (SDN); Streaming videos; Wide-area traffic; Internet
"Arora D., Benson T., Rexford J.",3,ProActive routing in scalable data centers with PARIS,2014,3,"Arista Networks, Santa Clara, CA, United States; Duke University, Durham, NC, United States; Princeton University, Princeton, NJ, United States",Duke University;Princeton University,2,USA,1,39,29,"Modern data centers must scale to a large number of servers, while offering flexible placement and migration of virtual machines. The traditional approach of connecting layer-two pods through a layer-three core constrains VM placement. More recent 'flat' designs are more flexible but have scalability limitations due to flooding/broadcasting or querying directories of VM locations. Rather than reactively learn VM locations, our PARIS architecture has a controller that pre-positions IP forwarding entries in the switches. Switches within a pod have complete information about the VMs beneath them, while each core switch maintains complete forwarding state for part of the address space. PARIS offers network designers the flexibility to choose a topology that meets their latency and bandwidth requirements. We evaluate our PARIS prototype built using OpenFlow-compliant switches and NOX controller. Using PARIS we can build a data center network that supports up to 100K servers. © 2014 ACM.",data center networking; network virtualization; software-defined networking,Computer programming; Computer science; Bandwidth requirement; Complete information; Data center networkings; Data center networks; Network virtualization; Proactive routing; Software-defined networkings; Traditional approaches; Cloud computing
"Alyafawi I., Dimitrova D.C., Braun T.",3,SDR-based passive indoor localization system for GSM,2014,5,"University of Bern, Communication and Distributed Systems (CDS), Bern, Switzerland",University of Bern,1,Switzerland,1,23,14,"This study deals with indoor positioning using GSM radio, which has the distinct advantage of wide coverage over other wireless technologies. In particular, we focus on passive localization systems that are able to achieve high localization accuracy without any prior knowledge of the indoor environment or the tracking device radio settings. In order to overcome these challenges, newly proposed localization algorithms based on the exploitation of the received signal strength (RSS) are proposed. We explore the effects of non-line-of-sight communication links, opening and closing of doors, and human mobility on RSS measurements and localization accuracy. We have implemented the proposed algorithms on top of software defined radio systems and carried out detailed empirical indoor experiments. The performance results show that the proposed solutions are accurate with average localization errors between 2.4 and 3.2 meters. © 2014 ACM.",indoor localization; proximity algorithms; sdr system,RSS; Telecommunication links; Wireless telecommunication systems; Indoor localization; Indoor localization systems; Localization algorithm; Passive localization systems; Received signal strength; sdr system; Software-defined radios; Wireless technologies; Software radio
"Perry J., Ousterhout A., Balakrishnan H., Shah D., Fugal H.",5,"Fastpass: A centralized ""zero-queue"" datacenter network",2014,108,"M.I.T. Computer Science and Artificial Intelligence Lab., United States; Facebook, United States",Facebook,1,USA,1,17,12,"An ideal datacenter network should provide several properties, including low median and tail latency, high utilization (throughput), fair allocation of network resources between users or applications, deadline-aware scheduling, and congestion (loss) avoidance. Current datacenter networks inherit the principles that went into the design of the Internet, where packet transmission and path selection decisions are distributed among the endpoints and routers. Instead, we propose that each sender should delegate control - -to a centralized arbiter - -of when each packet should be transmitted and what path it should follow. This paper describes Fastpass, a datacenter network architecture built using this principle. Fastpass incorporates two fast algorithms: the first determines the time at which each packet should be transmitted, while the second determines the path to use for that packet. In addition, Fastpass uses an efficient protocol between the endpoints and the arbiter and an arbiter replication strategy for fault-tolerant failover. We deployed and evaluated Fastpass in a portion of Facebook's datacenter network. Our results show that Fastpass achieves high throughput comparable to current networks at a 240x reduction is queue lengths (4.35 Mbytes reducing to 18 Kbytes), achieves much fairer and consistent flow throughputs than the baseline TCP (5200x reduction in the standard deviation of per-flow throughput with five concurrent connections), scalability from 1 to 8 cores in the arbiter implementation with the ability to schedule 2.21 Terabits/s of traffic in software on eight cores, and a 2.5x reduction in the number of TCP retransmissions in a latency-sensitive service at Facebook. © 2014 ACM.",arbiter; centralized; data plane; datacenter; high throughput; low latency; scheduling; zero-queue,Asynchronous sequential logic; Concurrency control; Convolutional codes; Network architecture; Social networking (online); Telecommunication networks; Throughput; Transmission control protocol; arbiter; centralized; Data planes; Datacenter; High throughput; Low latency; zero-queue; Scheduling
"Wamser F., Zinner T., Tran-Gia P., Zhu J.",4,Dynamic bandwidth allocation for multiple network connections: Improving user QoE and network usage of YouTube in mobile broadband,2014,4,"University of WŸrzburg, WŸrzburg, Germany; Intel Labs., Hillsboro, OR, United States",University of Wurzburg,1,Germany;USA,2,18,14,"Users expect a high level of application quality without annoying interruptions or delays when using applications in a communication network. This is particularly important in mobile environments where varying channel conditions, user mobility, and interference lead to a variation of the available network resources which ultimately affects application quality. A flexible selection of one or more access technologies, however, allows to overcome resource limitations of one specific access technology. An over-the-top (OTT) virtual access network (VAN) approach allows the aggregation of multiple wireless networks into a single IP pipe to provide users more bandwidth. To minimize energy consumption and radio resource utilization, an application-tailored usage of the access technologies as well as appropriate resource scheduling mechanisms in case of concurrent usage are required. In this paper, we perform a scenario-based investigation of the performance of an OTT VAN architecture. As scenario we choose a user watching a YouTube video clip, while a Wi-Fi and a cellular network are available. We evaluate the user perceived quality, cellular usage, and device power consumption based on testbed measurements. © 2014 ACM.",bandwidth allocation for multiple network connections; cross-layer; mobile broadband; quality of experience; youtube,Energy utilization; Frequency allocation; Quality of service; Scheduling; Telecommunication networks; Cross-layer; Mobile broadband; Multiple networks; Quality of experience (QoE); YouTube; Wi-Fi
"Samadi P., Gupta V., Birand B., Wang H., Zussman G., Bergman K.",6,Accelerating incast and multicast traffic delivery for data-intensive applications using physical layer optics,2014,4,"Department of Electrical Engineering, Columbia University, New York, NY 10027, United States",Columbia University,1,USA,1,38,23,We present a control plane architecture to accelerate multicast and incast traffic delivery for data-intensive applications in cluster-computing interconnection networks. The architecture is experimentally examined by enabling physical layer optical multicasting on-demand for the application layer to achieve non-blocking performance. © 2014 Authors.,hybrid data center networks; incast; multicast; optics,Cluster computing; Convolutional codes; Network architecture; Network layers; Optics; Application layers; Control planes; Data-intensive application; Hybrid datum; incast; Multicast traffic; Optical multicasting; Physical layers; Multicasting
"Kellogg B., Parks A., Gollakota S., Smith J.R., Wetherall D.",5,Wi-Fi backscatter: Internet connectivity for RF-powered devices,2014,75,"University of Washington, United States",University of Washington at Seattle,1,USA,1,18,13,"RF-powered computers are small devices that compute and communicate using only the power that they harvest from RF signals. While existing technologies have harvested power from ambient RF sources (e.g., TV broadcasts), they require a dedicated gateway (like an RFID reader) for Internet connectivity. We present Wi-Fi Backscatter, a novel communication system that bridges RF-powered devices with the Internet. Specifically, we show that it is possible to reuse existing Wi-Fi infrastructure to provide Internet connectivity to RF-powered devices. To show Wi-Fi Backscatter's feasibility, we build a hardware prototype and demonstrate the first communication link between an RF-powered device and commodity Wi-Fi devices. We use off-the-shelf Wi-Fi devices including Intel Wi-Fi cards, Linksys Routers, and our organization's Wi-Fi infrastructure, and achieve communication rates of up to 1 kbps and ranges of up to 2.1 meters. We believe that this new capability can pave the way for the rapid deployment and adoption of RF-powered devices and achieve ubiquitous connectivity via nearby mobile devices that are Wi-Fi enabled. © 2014 ACM.",backscatter; energy harvesting; internet of things; wireless,Backscattering; Convolutional codes; Energy harvesting; Internet; Internet of things; Mobile devices; Radio; Television broadcasting; Communication rate; Hardware prototype; Internet connectivity; Rapid deployments; RF sources; RFID readers; Small devices; TV broadcast; Gateways (computer networks)
"Ayadurai V., Prytz M.",2,Proof-of-concept implementation for network orchestrated relay selection mechanism,2014,0,"Ericsson Research, FŠršgatan 6, 164 80 Stockholm, Sweden",Ericsson Research,1,Sweden,1,4,4,"This paper describes a small-scale software radio proof-of-concept implementation developed to investigate a network orchestrated relay selection concept. The idea aims to reduce ""energy-in-the-air"" by replacing single long transmissions with multiple short ones via a relaying node when possible. The implementation includes mechanisms for real-time over-the-air packet transmissions for both control and user-data traffic, and on-the-fly network topology reconfiguration, which we utilized to enable the concept. We show that significant benefits were reaped from this real-world implementation despite the relatively simplistic scenario emulated by our indoor laboratory setup. Apart from the obvious advantages of testing the concept over a real wireless medium with its associated physical characteristics, other unforeseen factors were also uncovered. Asymmetries in radio channels, variations in supposedly identical node hardware, and timing issues affecting the proposed algorithm, were just some of the experiences encountered and fed back into the design process which resulted in significant refinements and improvements to the concept. The experience shows our research-via-experimentation approach with small-scale software radio yields benefits in meeting new challenges in wireless communications. © 2014 ACM.",device-to-device; fpga; mobile networks; software radio; warp; wireless relay,Electric network topology; Field programmable gate arrays (FPGA); Wireless networks; Wireless telecommunication systems; device-to-device; Network topology reconfigurations; Packet transmissions; Physical characteristics; Real-world implementation; warp; Wireless communications; Wireless relays; Software radio
"Ashok A., Subbiah I., Varga G., Schrey M., Heinen S., Achtzehn A., Petrova M.",7,whiteLAN: Facilitate cost-efficient SDR research with COTS IEEE 802.11b/g devices,2014,2,"Integrated Analog Circuits and RF Systems, RWTH Aachen University, D-52062 Aachen, Germany; Institute for Networked Systems, RWTH Aachen University, D-52062 Aachen, Germany",RWTH Aachen University,1,Germany,1,29,23,"To build large and scalable setups, researchers usually employ mixed testbeds of regular SDR devices and cheaper, generally less flexible COTS devices. Such hybrid setups often face uncontrollable interference from other users in the ISM bands, which leads to incomparable results and requires frequent repetitions of experiments. Maintaining the ability to use COTS devices and ISM band-only SDR devices while moving experiments to less crowded frequency bands is thus of high interest to practical wireless communications research. In this paper we present whiteLAN, a frequency converter that enables IEEE 802.11b/g devices to operate over UHF frequencies. We discuss the advantages of a ISM-UHF converter setup, present the hardware architecture of our solution, and provide key performance metrics of the physical implementation. Through a comparative study of ISM vs. UHF operations we show that whiteLAN is viable for use as a plug-and-play extension for wireless research deployments. © 2014 ACM.",ieee 802.11; ism bands; sdr; testbed; uhf; wi-fi,Frequency bands; Software radio; Standards; Testbeds; Wi-Fi; Wireless telecommunication systems; Comparative studies; Hardware architecture; IEEE 802.11s; ISM bands; Performance metrics; sdr; uhf; Wireless communications; Experiments
"Di Francesco P., Malandrino F., DaSilva L.A.",3,Mobile network sharing between operators: A demand trace-driven study,2014,5,"Trinity College, Dublin, Ireland",Trinity College Dublin,1,Ireland,1,6,6,"Network sharing is often hailed as a promising and cost-effective way to tackle the ever-increasing load of cellular networks. However, its actual effectiveness strongly depends on the correlation between the networks being joined - intuitively, there is no benefit in joining two networks with exactly the same load and exactly the same deployment. In this paper, we analyse the deployment and traffic traces of two Irish operators to (i) study their correlation in space and time, and (ii) assess the potential benefit brought by network sharing. Through our analysis, we are able to show that network sharing is remarkably effective in making the load more regular over space, improving the operations and performance of cellular networks. © 2014 ACM.",cellular traffic data; hotspot analysis; resource sharing,Cellular network; Hot spot; Network sharing; Potential benefits; Resource sharing; Space and time; Traffic data; Traffic traces
"Baillargeon S., Johansson I.",2,Conex lite for mobile networks,2014,3,"Ericsson Canada, 349 Terry Fox Drive, Kanata, ON K2K 2V6, Canada; Ericsson AB, LaboratoriegrŠnd 11, 977 53, LuleŒ, Sweden",Ericsson Research,1,Canada;Sweden,2,15,9,The paper proposes ConEx Lite to ease the deployment of congestion bitrate policing in existing 4G and WiFi mobile networks with initial objectives to improve end user experience and backhaul network performance and dimensioning. ConEx Lite is a congestion management solution working at the bearer or tunnel layer independent from UE terminals and Internet endpoints or other transport protocol (e.g. TCP) implementations. It consists of simple functions that can be implemented on existing radio access and core nodes without negatively impacting the performance of the mobile network. ConEx Lite provides faster response to congestion and allows mobile operators to control the congestion volume policies according to their radio access technology and/or service mix. © 2014 ACM.,byte sequence number; congestion exposure; congestion volume; tunnel congestion policing,Byte-sequences; Congestion exposures; Congestion management; congestion volume; End-user experience; Mobile operators; Radio access technologies; Transport protocols; Transmission control protocol
Johansson I.,1,Self-clocked rate adaptation for conversational video in LTE,2014,9,"Ericsson AB, LaboratoriegrŠnd 11, 977 53, LuleŒ, Sweden",Ericsson Research,1,Sweden,1,17,17,"This paper describes a rate adaptation framework for conversational video services. The solution conforms to the packet conservation principle and uses a hybrid loss and delay based congestion control algorithm. The framework is evaluated over both simulated bottleneck scenarios as well as in a LTE system simulator and is shown to achieve both low latency and high video throughput in these scenarios, something that improves the end user experience. © 2014 ACM.",conversational; lte; real time; self-clocking; video; webrtc,Algorithms; conversational; lte; Real time; self-clocking; video; webrtc; Clocks
"Mushtaq A., Ismail A.K., Wasay A., Mahmood B., Qazi I.A., Uzmi Z.A.",6,Rethinking buffer management in data center networks,2014,0,"SBASSE, LUMS, Lahore, Pakistan; UC, Santa Barbara, CA, United States",LUMS,1,Pakistan;USA,2,10,0,"Data center operators face extreme challenges in simultaneously providing low latency for short flows, high throughput for long flows, and high burst tolerance. We propose a buffer management strategy that addresses these challenges by isolating short and long flows into separate buffers, sizing these buffers based on flow requirements, and scheduling packets to meet different flow-level objectives. Our design provides new opportunities for performance improvements that complement transport layer optimisations. © 2014 Authors.",buffer management; data center; TCP,Convolutional codes; Buffer management; Data center networks; Data centers; High throughput; Low latency; Optimisations; TCP; Transport layers; Scheduling
"Mukerjee M.K., Hong J., Jiang J., Naylor D., Han D., Seshan S., Zhang H.",7,Enabling near real-time central control for live video delivery in CDNs,2014,2,"Carnegie Mellon University, United States; KAIST, United States",Carnegie Mellon University;KAIST,2,USA,1,8,5,"User-created live video streaming is marking a fundamental shift in the workload of live video delivery. However, live-video-specific challenges and the viral nature of user-created content makes it difficult for current CDNs to deliver 1) high-quality, 2) highly-scalable, and 3) highly-responsive service. We present the design and implementation of VDN, a new control plane for CDNs designed to optimize the delivery of live streams within the CDN. VDN satisfies these requirements by using two approaches: 1) optimizing directly for video quality (not just throughput) and 2) combining centralized control with local control, allowing VDN to adapt to traffic dynamics and network failures at fine timescales. © 2014 Authors.",CDNs; central optimization; hybrid control; live video,Convolutional codes; CDNs; Central control; Centralized control; Design and implementations; Hybrid controls; Live video; Live video streaming; Traffic dynamics; Quality control
"Jeyakumar V., Alizadeh M., Geng Y., Kim C., Mazires D.",5,Millions of little minions: Using packets for low latency network programming and visibility,2014,29,"Stanford University, United States; Cisco Systems, United States; Barefoot Networks, United States",Stanford University,1,USA,1,5,0,"This paper presents a practical approach to rapidly introducing new dataplane functionality into networks: End-hosts embed tiny programs into packets to actively query and manipulate a network's internal state. We show how this ""tiny packet program"" (TPP) interface gives end-hosts unprecedented visibility into network behavior, enabling them to work with the network to achieve a desired functionality. Our design leverages what each component does best: (a) switches forward and execute tiny packet programs (at most 5~ instructions) in-band at line rate, and (b) end-hosts perform arbitrary (and easily updated) computation on network state. By implementing three different research proposals, we show that TPPs are useful. Using a hardware prototype on a NetFPGA, we show our design is feasible at a reasonable cost. © 2014 ACM.",active networks; design; measurement; performance,Active networks; Convolutional codes; Measurements; Visibility; Data-plane; Hardware prototype; Internal state; Low-latency networks; Network behaviors; Network state; performance; Research proposals; Design
"Stewart G., Gowda M., Mainland G., Radunovic B., Vytiniotis D.",5,"Demo: 802.11 a/g PHY implementation in Ziria, domain-specific language for wireless programming",2014,0,"Princeton University, Princeton, NJ, United States; UIUC, Champaign, IL, United States; Drexel University, Philadelphia, PA, United States; Microsoft Research, Cambridge, United Kingdom",Drexel University;Microsoft;Princeton University;UIUC,4,UK;USA,2,11,6,"Software-defined radio (SDR) brings the flexibility of software to the domain of wireless protocol design, promising an ideal platform both for research and innovation and the rapid deployment of new protocols on existing hardware. However, existing SDR programming platforms require either careful hand-tuning of low-level code, negating many of the advantages of software, or are too slow to be useful in the real world. In this demo we present Ziria, the first software-defined radio programming platform that is both easily programmable and performant. Ziria introduces a novel programming model tailored to wireless physical layer tasks and captures the inherent and important distinction between data and control paths in this domain. We show the capabilities of Ziria by demonstrating a real-time implementation of WiFi PHY running at 20 MHz. © 2014 Authors.",compilers; domain-specific languages; signal processing; wireless,Graphical user interfaces; Network layers; Problem oriented languages; Program compilers; Radio; Radio receivers; Real time control; Signal processing; Domain specific languages; Physical layers; Programming models; Rapid deployments; Real-time implementations; Software-defined radios; Wireless programming; Wireless protocol designs; Software radio
"Liu H.H., Kandula S., Mahajan R., Zhang M., Gelernter D.",5,Traffic engineering with forward fault correction,2014,33,"Yale University, United States; Microsoft Research, United States",Microsoft;Yale University,2,USA,1,38,32,"Network faults such as link failures and high switch configuration delays can cause heavy congestion and packet loss. Because it takes time for the traffic engineering systems to detect and react to such faults, these conditions can last long - even tens of seconds. We propose forward fault correction (FFC), a proactive approach for handling faults. FFC spreads network traffic such that freedom from congestion is guaranteed under arbitrary combinations of up to k faults. We show how FFC can be practically realized by compactly encoding the constraints that arise from this large number of possible faults and solving them efficiently using sorting networks. Experiments with data from real networks show that, with negligible loss in overall network throughput, FFC can reduce data loss by a factor of 7-130 in well-provisioned networks, and reduce the loss of high-priority traffic to almost zero in well-utilized networks. © 2014 ACM.",congestion-free; fault tolerance; traffic engineering,Fault tolerance; congestion-free; Fault corrections; Network traffic; Overall networks; Pro-active approach; Sorting network; Switch configuration; Traffic Engineering; Convolutional codes
"Molavi Kakhki A., Razaghpanah A., Golani R., Choffnes D., Gill P., Mislove A.",6,Identifying traffic differentiation on cellular data networks,2014,1,"Northeastern University, United States; Stony Brook University, United States",Northeastern University;Stony Brook University,2,USA,1,11,7,"The goal of this research is to detect traffic differentiation in cellular data networks. We define service differentiation as any attempt to change the performance of network traffic traversing an ISP's boundaries. ISPs may implement differentiation policies for a number of reasons, including load balancing, bandwidth management, or business reasons. Specifically, we focus on detecting whether certain types of network traffic receive better (or worse) performance. As an example, a wireless provider might limit the performance of third-party VoIP or video calling services (or any other competing services) by introducing delays or reducing transfer rates to encourage users to use services provided by the wireless provider. Previous work explored this problem in limited environments. Glasnost focused on BitTorrent in the desktop/laptop environment, and lacked the ability to conduct controlled experiments to provide strong evidence of differentiation. NetDiff covered a wide range of passively gathered traffic from a large ISP but likewise did not support targeted, controlled experiments. We address these limitations with Mobile Replay. © 2014 Authors.",net neutrality; traffic differentiation,Convolutional codes; Experiments; Internet telephony; Bandwidth management; Bit torrents; Cellular data networks; Controlled experiment; Net neutralities; Network traffic; Service differentiation; Transfer rates; Internet service providers
"Martelli F., Kocian A., Santi P., Gardellin V.",4,MIMO-OFDM spatial multiplexing technique implementation for GNU radio,2014,1,"Institute of Informatics and Telematics, Italian National Research Council, Via G. Moruzzi 1, Pisa, Italy",Italian National Research Council,1,Italy,1,30,2,"Multiple-Input Multiple-Output (MIMO) is a wireless technology allowing a significant increasing of the throughput without the extension of the bandwidth but by means of the use of multiple antennas both in transmission and reception. Currently, Orthogonal Frequency Division Multiplexing (OFDM) is used in conjuction with MIMO to achieve better performance. With OFDM, instead of a single carrier, the main signal is split in a sub-set of independently modulated signals on orthogonal sub-carriers. In this paper, we provide a description of our MIMONet SDR platform for network-level exploitation of MIMO technology. We present the implementation of our OFDM transceiver, developed following the structure of IEEE 802.11n standard and implementing one of the most powerful MIMO technique: spatial multiplexing. In this technique, two (or more) different data streams are simultaneously transmitted over two (or more) antennas. Starting from the original GNU Radio code, we modified and added blocks to achieve a complete implementation of MIMO-OFDM spatial multiplexing. We added some features, such as the concatenation of Forward Error Correction (FEC) in the packet construction, and the use of pilot sub-carriers for channel estimation. We also developed a new synchronization algorithm derived by extending the Van de Beek algorithm to the MIMO setting. We build the framework of the standard IEEE 802.11n. In particular, we put all the preambles needed for synchronization and channel estimation. We have also designed and implemented a fine grained signal-to-noise ratio (SNR) estimation, bit error rate (BER) and packet error rate (PER) computations, that allow us to evaluate the channel conditions and validate performance of the software implementation. © 2014 ACM.",gnu radio; mimo testbed; ofdm.; software defined radios; spatial multiplexing,Antennas; Gain control; MIMO systems; Multiplexing; Orthogonal frequency division multiplexing; Signal to noise ratio; Software radio; Standards; Wireless telecommunication systems; GNU radio; Ieee 802.11n standards; MIMO testbeds; Signal to noise ratio estimation; Software implementation; Software-defined radios; Spatial multiplexing; Synchronization algorithm; Open source software
"Heilman E., Cooper D., Reyzin L., Goldberg S.",4,From the consent of the routed: Improving the transparency of the RPKI,2014,15,"Dept. of Computer Science, Boston University, Boston, MA, United States",Boston University,1,USA,1,5,3,"The Resource Public Key Infrastructure (RPKI) is a new infrastructure that prevents some of the most devastating attacks on interdomain routing. However, the security benefits provided by the RPKI are accomplished via an architecture that empowers centralized authorities to unilaterally revoke any IP prefixes under their control. We propose mechanisms to improve the transparency of the RPKI, in order to mitigate the risk that it will be used for IP address takedowns. First, we present tools that detect and visualize changes to the RPKI that can potentially take down an IP prefix. We use our tools to identify errors and revocations in the production RPKI. Next, we propose modifications to the RPKI's architecture to (1) require any revocation of IP address space to receive consent from all impacted parties, and (2) detect when misbehaving authorities fail to obtain consent. We present a security analysis of our architecture, and estimate its overhead using data-driven analysis. © 2014 ACM.",public key infrastructures; RPKI; security; transparency,Convolutional codes; Public key cryptography; Telecommunication networks; Data-driven analysis; Interdomain Routing; IP addresss; Public key infrastructure; RPKI; security; Security analysis; Transparency
"Ge X., Liu Y., Du D.H.C., Zhang L., Guan H., Chen J., Zhao Y., Hu X.",8,OpenANFV: Accelerating network function virtualization with a consolidated framework in OpenStack,2014,24,"Department of Computer Science and Engineering, University of Minnesota, United States; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Huawei Corporation, China",Shenzhen University;University of Minnesota,2,China;USA,2,21,13,"The resources of dedicated accelerators (e.g. FPGA) are still required to bridge the gap between software-based Middleboxs(MBs) and the commodity hardware. To consolidate various hardware resources in an elastic, programmable and reconfigurable manner, we design and build a flexible and consolidated framework, OpenANFV, to support virtualized accelerators for MBs in the cloud environment. OpenANFV is seamlessly and efficiently put into Openstack to provide high performance on top of commodity hardware to cope with various virtual function requirements. OpenANFV works as an independent component to manage and virtualize the acceleration resources (e.g. cinder manages block storage resources and nova manages computing resources). Specially, OpenANFV mainly has the following three features. (1)Automated Management. Provisioning for multiple Virtualized Network Functions (VNFs) is automated to meet the dynamic requirements of NFV environment. Such automation alleviates the time pressure of the complicated provisioning and configuration as well as reduces the probability of manually induced configuration errors. (2) Elasticity. VNFs are created, migrated, and destroyed on demand in real time. The reconfigurable hardware resources in pool can rapidly and flexibly offload the corresponding services to the accelerator platform in the dynamic NFV environment. (3) Coordinating with Openstack. The design and implementation of the OpenANFV APIs coordinate with the mechanisms in Openstack to support required virtualized MBs for multiple tenants. © 2014 Authors.",FPGA; middlebox; network function virtualization; openstack,Automation; Convolutional codes; Field programmable gate arrays (FPGA); Reconfigurable hardware; Virtual reality; Automated management; Configuration errors; Design and implementations; Independent components; Middleboxes; openstack; Programmable and re-configurable; Virtualizations; Hardware
"Kalia A., Kaminsky M., Andersen D.G.",3,Using RDMA efficiently for key-value services,2014,74,"Carnegie Mellon University, United States; Intel Labs., United States",Carnegie Mellon University,1,USA,1,66,43,"This paper describes the design and implementation of HERD, a key-value system designed to make the best use of an RDMA network. Unlike prior RDMA-based key-value systems, HERD focuses its design on reducing network round trips while using efficient RDMA primitives; the result is substantially lower latency, and throughput that saturates modern, commodity RDMA hardware. HERD has two unconventional decisions: First, it does not use RDMA reads, despite the allure of operations that bypass the remote CPU entirely. Second, it uses a mix of RDMA and messaging verbs, despite the conventional wisdom that the messaging primitives are slow. A HERD client writes its request into the server's memory; the server computes the reply. This design uses a single round trip for all requests and supports up to 26 million key-value operations per second with 5 _s average latency. Notably, for small key-value items, our full system throughput is similar to native RDMA read throughput and is over 2X higher than recent RDMA-based key-value systems. We believe that HERD further serves as an effective template for the construction of RDMA-based datacenter services. © 2014 ACM.",infiniband; key-value stores; RDMA; ROCE,Convolutional codes; Throughput; Datacenter; Design and implementations; Infiniband; Key-value stores; RDMA; ROCE; Round trip; System throughput; Design
"Marinos I., Watson R.N.M., Handley M.",3,Network stack specialization for performance,2014,23,"University of Cambridge, United Kingdom; University College London, United Kingdom",University College London;University of Cambridge,2,UK,1,5,4,"Contemporary network stacks are masterpieces of generality, supporting many edge-node and middle-node functions. Generality comes at a high performance cost: current APIs, memory models, and implementations drastically limit the effectiveness of increasingly powerful hardware. Generality has historically been required so that individual systems could perform many functions. However, as providers have scaled services to support millions of users, they have transitioned toward thousands (or millions) of dedicated servers, each performing a few functions. We argue that the overhead of generality is now a key obstacle to effective scaling, making specialization not only viable, but necessary. We present Sandstorm and Namestorm, web and DNS servers that utilize a clean-slate userspace network stack that exploits knowledge of application-specific workloads. Based on the netmap framework, our novel approach merges application and network-stack memory models, aggressively amortizes protocol-layer costs based on application-layer knowledge, couples tightly with the NIC event model, and exploits microarchitectural features. Simultaneously, the servers retain use of conventional programming frameworks. We compare our approach with the FreeBSD and Linux stacks using the nginx web server and NSD name server, demonstrating 2 - 10x and 9x improvements in web-server and DNS throughput, lower CPU usage, linear multicore scaling, and saturated NIC hardware. © 2014 ACM.",clean-slate design; network performance; network stacks; network- stack specialization,Computer operating systems; Convolutional codes; Hardware; Internet protocols; Network performance; Slate; Storms; Clean slates; Dedicated servers; Individual systems; Memory models; Name servers; Network stack; Performance costs; Programming framework; Computer hardware
Sobie R.,1,Distributed cloud computing in high energy physics,2014,1,"Institute for Particle Physics, Department of Physics and Astronomy, University of Victoria, Victoria, BC, Canada",University of Victoria,1,Canada,1,31,21,"Cloud computing is increasingly being used for running high energy physics (HEP) applications. We review the motivation for using clouds in HEP and describe how they are gradually being integrated into our systems. In particular, we highlight our use of a distributed cloud computing system that integrates both private and public IaaS clouds into a unified infrastructure. We describe our experience using the distributed cloud and our plans to make the system context-aware in order to scale to larger workloads and run data-intensive HEP applications. © 2014 ACM.",cloud computing; high energy physics,High energy physics; Computing system; Context-Aware; Data intensive; Distributed clouds; Iaas clouds; Cloud computing
"Shanmugam P.K., Subramanyam N.D., Breen J., Roach C., Van Der Merwe J.",5,DEIDtect: Towards distributed elastic intrusion detection,2014,9,"University of Utah, Salt Lake City, UT, United States",University of Utah,1,USA,1,33,9,We present a distributed elastic intrusion detection architecture called DEIDtect. DEIDtect exploits the increasing deployment of cloud computing and software defined networking technology in enterprise and campus environments to deal with current inflexibilities associated with compute and network resources required by security tools. We present the detailed design and implementation of DEIDtect's networking functionality and illustrate its functionality in an emulated environment. © 2014 ACM.,cloud computing; distributed intrusion detection; software defined networking,Intrusion detection; Detailed design; Distributed intrusion detection; Network resource; Security tools; Software-defined networkings; Cloud computing
"Stewart G., Gowda M., Mainland G., Radunovi_ B., Vytiniotis D., Patterson D.",6,Ziria: Language for rapid prototyping of wireless PHY,2014,3,"Princeton, United States; UIUC, United States; Drexel, United States; Microsoft Research, United States; Microsoft, United States",Microsoft;UIUC,2,USA,1,29,14,"Software-defined radios (SDR) have the potential to bring major innovation in wireless networking design. However, their impact so far has been limited due to complex programming tools. Most of the existing tools are either too slow to achieve the full line speeds of contemporary wireless PHYs or are too complex to master. In this demo we present our novel SDR programming environment called Ziria. Ziria consists of a novel programming language and an optimizing compiler. The compiler is able to synthesize very efficient SDR code from high-level PHY descriptions written in Ziria language. To illustrate its potential, we present the design of an LTE-like PHY layer in Ziria. We run it on the Sora SDR platform and demonstrate on a test-bed that it is able to operate in real-time. © 2014 Authors.",domain specific language; DSL; programming; SDR; software-defined radio; wireless,Convolutional codes; DSL; Mathematical programming; Program compilers; Radio; Radio receivers; Software radio; Domain specific languages; Optimizing compilers; Programming environment; Programming tools; SDR; Sdr platforms; Software-defined radios; Wireless networking; High level languages
"Craven R., Beverly R., Allman M.",3,A middlebox-cooperative TCP for a non end-to-end internet,2014,15,"Naval Postgraduate School, United States; ICSI, United States",Naval Postgraduate School,1,USA,1,17,7,"Understanding, measuring, and debugging IP networks, particularly across administrative domains, is challenging. One particularly daunting aspect of the challenge is the presence of transparent middleboxes - -which are now common in today's Internet. In-path middleboxes that modify packet headers are typically transparent to a TCP, yet can impact end-to-end performance or cause blackholes. We develop TCP HICCUPS to reveal packet header manipulation to both endpoints of a TCP connection. HICCUPS permits endpoints to cooperate with currently opaque middleboxes without prior knowledge of their behavior. For example, with visibility into end-to-end behavior, a TCP can selectively enable or disable performance enhancing options. This cooperation enables protocol innovation by allowing new IP or TCP functionality (e.g., ECN, SACK, Multipath TCP, Tcpcrypt) to be deployed without fear of such functionality being misconstrued, modified, or blocked along a path. HICCUPS is incrementally deployable and introduces no new options. We implement and deploy TCP HICCUPS across thousands of disparate Internet paths, highlighting the breadth and scope of subtle and hard to detect middlebox behaviors encountered. We then show how path diagnostic capabilities provided by HICCUPS can benefit applications and the network. © 2014 ACM.",header integrity; header modifications; middlebox; TCP,Convolutional codes; Internet; Diagnostic capabilities; End-to-end performance; header integrity; header modifications; Middleboxes; Performance enhancing; Prior knowledge; TCP; Transmission control protocol
"Grandl R., Ananthanarayanan G., Kandula S., Rao S., Akella A.",5,Multi-resource packing for cluster schedulers,2014,81,"Microsoft, United States; Univ. of Wisconsin, Madison, WI, United States; Univ. of California, Berkeley, CA, United States",Microsoft,1,USA,1,8,5,"Tasks in modern data parallel clusters have highly diverse resource requirements, along CPU, memory, disk and network. Any of these resources may become bottlenecks and hence, the likelihood of wasting resources due to fragmentation is now larger. Today's schedulers do not explicitly reduce fragmentation. Worse, since they only allocate cores and memory, the resources that they ignore (disk and network) can be over-allocated leading to interference, failures and hogging of cores or memory that could have been used by other tasks. We present Tetris, a cluster scheduler that packs, i.e., matches multi-resource task requirements with resource availabilities of machines so as to increase cluster efficiency (makespan). Further, Tetris uses an analog of shortest-running-time-first to trade-off cluster efficiency for speeding up individual jobs. Tetris' packing heuristics seamlessly work alongside a large class of fairness policies. Trace-driven simulations and deployment of our prototype on a 250 node cluster shows median gains of 30% in job completion time while achieving nearly perfect fairness. © 2014 ACM.",cluster schedulers; completion time; fairness; makespan; multi-dimensional; packing,Convolutional codes; Packing; Scheduling algorithms; cluster schedulers; Completion time; fairness; Makespan; multi-dimensional; Scheduling
"Gao Z., Venkataramani A., Kurose J.F., Heimlicher S.",4,Towards a quantitative comparison of location-independent network architectures,2014,11,"School of Computer Science, University of Massachusetts Amherst, United States",University of Massachusetts Amherst,1,USA,1,46,35,"This paper presents a quantitative methodology and results comparing different approaches for location-independent communication. Our approach is empirical and is based on real Internet topologies, routing tables from real routers, and a measured workload of the mobility of devices and content across network addresses today. We measure the extent of network mobility exhibited by mobile devices with a home-brewn Android app deployed on hundreds of smartphones, and measure the network mobility of Internet content from distributed vantage points. We combine this measured data with our quantitative methodology to analyze the different cost-benefit tradeoffs struck by location-independent network architectures with respect to routing update cost, path stretch, and forwarding table size. We find that more than 20% of users change over 10 IP addresses a day, suggesting that mobility is the norm rather than the exception, so intrinsic and efficient network support for mobility is critical. We also find that with purely name-based routing approaches, each event involving the mobility of a device or popular content may result in an update at up to 14% of Internet routers; but, the fraction of impacted routers is much smaller for the long tail of unpopular content. These results suggest that recent proposals for pure name-based networking are suitable for highly aggregateable content that does not move frequently but may need to be augmented with addressing-assisted approaches to handle device mobility. © 2014 ACM.",location-independence; mobility; network architecture,Carrier mobility; Convolutional codes; Internet; Mobile devices; Routers; Telecommunication networks; Cost-benefit tradeoffs; Device mobilities; Forwarding tables; Internet routers; Internet topologies; location-independence; Quantitative comparison; Quantitative methodology; Network architecture
TŠht D.,1,The value of repeatable experiments and negative results - A journey through the history and future of AQM and fair queuing algorithms,2014,1,"Bufferbloat Project, United States",Bufferbloat Project,1,USA,1,30,20,"The Bufferbloat project was founded three and half years ago to explore solutions to why modern data networks became so slow when loaded. We set out to explore the literature, and code, from the earliest days of the Internet to today, to try and find out what had gone wrong, and to find ways to fix it. A result of that effort (so far!) has been a renaissance in interest in congestion control, and huge - orders of magnitude - improvements in network latency along the edge of the Internet, with deployable new algorithms and code. Surprisingly, we also made large improvements in simultaneous bidirectional goodput on asymmetric networks. This talk goes into the history and future of Active Queue Management (AQM) and fair queuing algorithms, touches upon current work across the field and tries to identify useful techniques for exploring and designing future work that can scale. © 2014 Author.",active queue management; ARM; bufferbloat; codel; fq-codel; linux; MIPS; OpenWrt; stochastic fair queuing; WiFi,Algorithms; Computer operating systems; Internet; Linux; Stochastic systems; Wi-Fi; Active Queue Management; ARM; Bufferbloat; codel; Fair queuing; fq-codel; MIPS; Openwrt; Queueing networks
"Garikipati K.C., Shin K.G.",2,Improving transport design for WARP SDR deployments,2014,2,"Dept. of EECS, University of Michigan, Ann Arbor, MI, United States",University of Michigan at Ann Arbor,1,USA,1,58,34,"Software-Defined radios (SDRs) are a popular platform for developing and implementing wireless protocols. Their basic architecture consists of radio front-ends hosted on an FGPA board, and a back-end processing host for running bulk of the signal processing in software. The two components are bridged, usually by an Ethernet or PCIe interface that transports the radio samples. In addition to the processing delay in software, SDRs may experience a non-negligible transport latency, for example, due to the limited Ethernet bandwidth. Wireless-Access Research Platform (WARP) is one such SDR platform that has recently gained a lot of attention. Research prototypes deploying tens of WARP radios over the Ethernet have become a familiar sight. WARP's transport design, however, is inefficient due to its linear increase in transport latency with the number of radios. We propose modifications to improve the current design. First, we utilize functional parallelism to run the read/write operations of multiple WARP radios concurrently. Second, we propose a high-bandwidth link at the host in order to support the combined transfer rates resulting from the parallel transport to/from the radios. As a result, we achieve a significant reduction in the transport latency by scaling back the linear increase to a constant overhead. © 2014 ACM.",software-defined radios; warp,Ethernet; Radio receivers; Signal processing; Supersonic aerodynamics; Back-end processing; High-bandwidth links; Parallel transport; Read/write operations; Research platforms; Research prototype; Software-defined radios; warp; Software radio
"Keller M., Karl H.",2,Response time-optimized distributed cloud resource allocation,2014,7,"University of Paderborn, Warburger Stra§e 100, 33098 Paderborn, Germany",University of Paderborn,1,Germany,1,6,3,"In the near future many more compute resources will be available at different geographical locations. To minimize the response time of requests, application servers closer to the user can hence be used to shorten network round trip times. However, this advantage is neutralized if the used data centre is highly loaded as the processing time of requests is important as well. We model the request response time as the network round trip time plus the processing time at a data centre.We present a capacitated facility location problem formalization where the processing time is modelled as the sojourn time of a queueing model. We discuss the Pareto trade-off between the number of used data centres and the resulting response time. For example, using fewer data centres could cut expenses but results in high utilization, high response time, and smaller revenues.Previous work presented a non-linear cost function. We prove its convexity and exploit this property in two ways: First, we transform the convex model into a linear model while controlling the maximum approximation error. Second, we used a convex solver instead of a slower non-linear solver.Numerical results on network topologies exemplify our work. © 2014 ACM.",convex optimization problem; distributed cloud computing; facility location problem; queueing theory; server placement problem,Convex optimization; Electric network topology; Location; Optimization; Queueing theory; Approximation errors; Capacitated facility location problems; Convex optimization problems; Distributed clouds; Facility location problem; Geographical locations; Nonlinear cost functions; Server placements; Cloud computing
"Tu G.-H., Li Y., Peng C., Li C.-Y., Wang H., Lu S.",6,Control-plane protocol interactions in cellular networks,2014,11,"University of California, Los Angeles, CA, United States; Ohio State University, Columbus, OH, United States",Ohio State University;University of California Los Angeles,2,USA,1,17,9,"Control-plane protocols are complex in cellular networks. They communicate with one another along three dimensions of cross layers, cross (circuit-switched and packet-switched) domains, and cross (3G and 4G) systems. In this work, we propose signaling diagnosis tools and uncover six instances of problematic interactions. Such control-plane issues span both design defects in the 3GPP standards and operational slips by carriers. They are more damaging than data-plane failures. In the worst-case scenario, users may be out of service in 4G, or get stuck in 3G. We deduce root causes, propose solutions, and summarize learned lessons. © 2014 ACM.",cellular networks; control-plane; protocol verification,Convolutional codes; Mobile telecommunication systems; Cellular network; control-plane; Design defects; Diagnosis tools; Packet-switched; Protocol verification; Three dimensions; Worst case scenario; Complex networks
"Yenamandra V., Srinivasan K.",2,Vidyut: Exploiting power line infrastructure for enterprise wireless networks,2014,11,"Ohio State University, United States",Ohio State University,1,USA,1,26,18,"Global synchronization across time and frequency domains signicantly benefits wireless communications. Multi-Cell (Network) MIMO, interference alignment solutions, opportunistic routing techniques in ad-hoc networks, OFDMA etc. all necessitate synchronization in either time or frequency domain or both. This paper presents Vidyut, a system that exploits the easily accessible and ubiquitous power line infrastructure to achieve synchronization in time and frequency domains across nodes distributed beyond a single-collision domain. Vidyut uses the power lines to transmit a reference frequency tone to which each node locks its frequency. Vidyut exploits the steady periodicity of delivered power signal itself to synchronize distributed nodes in time. We validate the extent of Vidyut's synchronization and evaluate its effectiveness. We verify Vidyut's suitability for wireless applications such as OFDMA and multi-cell MIMO by validating the benefits of global synchronization in an enterprise wireless network. Our experiments show a through-put gain of 8.2x over MegaMIMO, 7x over NEMOx and 2.5x over OFDMA systems. © 2014 ACM.",frequency synchronization; network mimo; power line communications; time synchronization; wireless networks,Convolutional codes; Electric lines; MIMO systems; Orthogonal frequency division multiplexing; Synchronization; Telecommunication networks; Wireless networks; Wireless telecommunication systems; Enterprise wireless network; Frequency synchronization; Global synchronization; Network MIMO; Power line communications; Time and frequency domains; Time synchronization; Wireless communications; Frequency division multiple access
"Cao Z., Kodialam M., Lakshman T.V.",3,Traffic steering in software defined networks: Planning and online routing,2014,27,"Polytechnic School of Engineering, New York University, 5 MetroTech Center, Brooklyn, NY 11201, United States; Bell Laboratories, Alcatel-Lucent, 791 Holmdel Road, Holmdel, NJ 07733, United States",Bell Labs;NYU,2,USA,1,27,18,"Middleboxes have become ubiquitous in data center as well as wide area networks. Simple routing of flows from ingress to egress along shortest paths has been replaced by policy aware paths that have to pass through the required set of middleboxes. The complex routing is one of the major impetus for the Software Defined Networking (SDN) paradigm. In this paper, we consider both offline planning and online routing problems in SDN framework. The offline planning problem is one where aggregate demands are specified and the objective is to determine whether there is enough capacity in the network to handle the demands. We develop a fast FPTAS for the problem based on segmentation and lazy dual update. In the online routing problem, flow requests are given one at a time and the objective is to steer the flows to maximize the total amount of traffic accepted over time. We develop a log-competitive algorithm based on time-dependent duals. © 2014 ACM.",FPTAS; middlebox; software defined networks; traffic scheduling,Cloud computing; Scheduling; Aggregate demands; FPTAS; Middleboxes; Off-line planning; Online routing problems; Software defined networking (SDN); Software-defined networks; Traffic scheduling; Complex networks
"Lingam S., Schmidl T., Batra A.",3,Software defined radio for smart utility networks,2014,2,"Texas Instruments, 13532 North Central Expressway, Dallas, TX, United States",Texas Instruments,1,USA,1,24,18,"In this paper, we describe a software defined radio (SDR) platform that can be used to implement the IEEE 802.15.4g standard for low data rate wireless smart utility networks (SUN). The SUN standard supports multiple wireless band plans, defines multiple physical (PHY) layers: FSK, OFDM and O-QPSK, each supporting a large number of data rates. Because of the flexibility allowed in the standards, an SDR approach provides the greatest flexibility in implementing the standard. We propose to use the SDR platform based on Texas Instruments C28x 32-bit MCU platform and a sub-1GHz CC1260 low power integrated radio. This platform can may be used for both the smart e-meter as well as the data concentrator. We begin the paper by providing an overview of the different PHY layers and enumerating the common elements across all PHYs for both the transmitter and receiver. Next, we discuss a partitioning between software and hardware that provides the flexibility without sacrificing efficiency. Finally, we provide the details of a hardware accelerator incorporated into the C28x architecture (VCU II) that can simplify many of the complex tasks associated with these PHYs. © 2014 ACM.",dsss; fsk; ieee 802.15.4g; o-qpsk; ofdm; sdr; smart grid; smart utility networks; software defined radio; software radio; sun; wireless,Complex networks; Frequency shift keying; Hardware; Orthogonal frequency division multiplexing; Radio; Smart meters; Standards; Sun; dsss; ieee 802.15.4g; o-qpsk; sdr; Smart grid; Software-defined radios; Utility network; Software radio
"Islam S., Welzl M., Gjessing S., Khademi N.",4,Coupled congestion control for RTP media,2014,5,"Department of Informatics, University of Oslo, Oslo, Norway",University of Oslo,1,Norway,1,16,15,Congestion occurs at a bottleneck along an Internet path; multiple flows between the same sender and receiver pairs can benefit from using only a single congestion control instance when they share the same bottleneck. These benefits include the ability to control the rate allocation between flows and reduced overall delay (multiple congestion control instances cause more queuing delay than one since each has no knowledge of the congestion episodes experienced by the others). We present a mechanism for coupling congestion control for real-time media and show its benefits by coupling multiple congestion controlled flows that share the same bottleneck. © 2014 ACM.,congestion control; fse; rmcat; webrtc,Congestion control (communication); Controlled flow; fse; Internet paths; Multiple congestion; Rate allocation; rmcat; Sender and receivers; webrtc; Traffic congestion
"Czyz J., Allman M., Zhang J., Iekel-Johnson S., Osterweil E., Bailey M.",6,Measuring IPv6 adoption,2014,51,"University of Michigan, United States; International Computer Science Institute, United States; Arbor Networks, Inc., United States; Verisign Labs., United States",Arbor Networks Inc.;University of California Berkeley;University of Michigan at Ann Arbor,3,USA,1,10,9,"After several IPv4 address exhaustion milestones in the last three years, it is becoming apparent that the world is running out of IPv4 addresses, and the adoption of the next generation Internet protocol, IPv6, though nascent, is accelerating. In order to better understand this unique and disruptive transition, we explore twelve metrics using ten global-scale datasets to create the longest and broadest measurement of IPv6 adoption to date. Using this perspective, we find that adoption, relative to IPv4, varies by two orders of magnitude depending on the measure examined and that care must be taken when evaluating adoption metrics in isolation. Further, we find that regional adoption is not uniform. Finally, and perhaps most surprisingly, we find that over the last three years, the nature of IPv6 utilization-in terms of traffic, content, reliance on transition technology, and performance-has shifted dramatically from prior findings, indicating a maturing of the protocol into production mode. We believe IPv6's recent growth and this changing utilization signal a true quantum leap. © 2014 ACM.",dns; internet; IP; IPv4; IPv6; measurement,Convolutional codes; Internet; Measurements; dns; IP; IPv4; IPv6; Next generation Internet; Orders of magnitude; Production modes; Transition technologies; Internet protocols
"Zhang B., Wang J., Wang X., Cheng Y., Jia X., He J.",6,AI3: Application-independent information infrastructure,2014,0,"City University of Hong Kong, Hong Kong; Huawei Technologies Co. Ltd., China",City University of Hong Kong,1,China;Hong Kong,2,15,10,"In the current Internet architecture, application service providers (ASPs) own users' data and social groups information, which made a handful of ASP companies growing bigger and bigger and denied small and medium companies from entering this business. We propose a new architecture, called Application Independent Information Infrastructure (AI3). The design goals of AI3 are: 1) Decoupling users' data from ASPs and users' social relations from ASPs, such that ASPs become independent from users' data and social relations. 2) Open architecture, such that different ASPs can interoperate with each other. This demo is to show a prototype of AI3. The demo has four parts: 1) ASPindependent data management in AI3; 2) ASP-independent management of users' social relations in AI3; 3) inter-domain data transport and user roaming; 4) real-time communications by using AI3. The demo video can be watched at: http://www.cs.cityu.edu.hk/~jia/AI3-DemoVideo.mp4. © 2014 Authors.",internet architecture; network infrastructure; storage system,Architecture; Computer architecture; Convolutional codes; Information management; Internet; Application service provider; Information infrastructures; Internet architecture; Network infrastructure; Open architecture; Real-time communication; Social relations; Storage systems; Digital storage
"Hu H., Jin Y., Wen Y., Chua T.-S., Li X.",5,Toward a biometric-aware cloud service engine for multi-screen video applications,2014,2,"School of Computing, National Univ. of Singapore, Singapore 117417, Singapore; School of Computer Eng., Nanyang Tech. University, Singapore 639798, Singapore; Center for OPTical IMagery Analysis and Learning (OPTIMAL), XIOPM, CAS, Xi'an 710119, China",Nanyang Tech. University,1,China;Singapore,2,44,35,"The emergence of portable devices and online social networks (OSNs) has changed the traditional video consumption paradigm by simultaneously providing multi-screen video watching, social networking engagement, etc. One challenge is to design a unified solution to support ever-growing features while guarantee system performance. In this demo, we design and implement a multi-screen technology to provide multi-screen interactions over wide area network (WAN). Furthermore, we incorporate face-detection technology into our system to identify users' bio-features and employ a machine learning based traffic scheduling mechanism to improve the system performance. © 2014 Authors.",cloud; internet video; second screen,Artificial intelligence; Clouds; Convolutional codes; Scheduling; Social networking (online); Wide area networks; Design and implements; Internet video; Online social networks (OSNs); Portable device; Second screens; Traffic scheduling; Unified solutions; Video applications; Biometrics
"Vallentin M., Charousset D., Schmidt T.C., Paxson V., WŠhlisch M.",5,Native actors: How to scale network forensics,2014,5,"UC Berkeley, United States; HAW Hamburg, Germany; ICSI, UC Berkeley, United States; FU Berlin, Germany",University of California Berkeley,1,Germany;USA,2,4,3,"When an organization detects a security breach, it undertakes a forensic analysis to figure out what happened. This investigation involves inspecting a wide range of heterogeneous data sources spanning over a long period of time. The iterative nature of the analysis procedure requires an interactive experience with the data. However, the distributed processing paradigms we find in practice today fail to provide this requirement: the batch-oriented nature of MapReduce cannot deliver sub-second round-trip times, and distributed in-memory processing cannot store the terabytes of activity logs needed to inspect during an incident. We present the design and implementation of Visibility Across Space and Time (VAST), a distributed database to support interactive network forensics, and libcppa, its exceptionally scalable messaging core. The extended actor framework libcppa enables VAST to distribute lightweight tasks at negligible overhead. In our live demo, we showcase how VAST enables security analysts to grapple with the huge amounts of data often associated with incident investigations. © 2014 Authors.",message-oriented middleware; network forensics; security,Design and implementations; Distributed database; Distributed processing; Heterogeneous data sources; Incident investigation; Message oriented middleware; Network forensics; security; Convolutional codes
"Yuan Z., Lu Y., Wang Z., Xue Y.",4,Droid-Sec: Deep learning in Android malware detection,2014,41,"Baidu Inc., Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Research Institute of Information Technology, Tsinghua University, Beijing, China; Tsinghua National Lab. for Information Science and Technology, Beijing, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China",Baidu Inc.;Harbin Institute of Technology;Tsinghua University,3,China,1,3,3,"As smartphones and mobile devices are rapidly becoming indispensable for many network users, mobile malware has become a serious threat in the network security and privacy. Especially on the popular Android platform, many malicious apps are hiding in a large number of normal apps, which makes the malware detection more challenging. In this paper, we propose a ML-based method that utilizes more than 200 features extracted from both static analysis and dynamic analysis of Android app for malware detection. The comparison of modeling results demonstrates that the deep learning technique is especially suitable for Android malware detection and can achieve a high level of 96% accuracy with real-world Android application sets. © 2014 Authors.",android malware; deep learning; detection,Computer crime; Convolutional codes; Error detection; Malware; Mobile devices; Static analysis; Android applications; Android malware; Android platforms; Comparison of models; Deep learning; Malware detection; Mobile malware; Network security and privacy; Android (operating system)
"Chowdhury M., Zhong Y., Stoica I.",3,Efficient coflow scheduling with Varys,2014,124,"UC Berkeley, United States; Columbia University, United States",Columbia University;University of California Berkeley,2,USA,1,5,2,"Communication in data-parallel applications often involves a collection of parallel flows. Traditional techniques to optimize flow-level metrics do not perform well in optimizing such collections, because the network is largely agnostic to application-level requirements. The recently proposed coflow abstraction bridges this gap and creates new opportunities for network scheduling. In this paper, we address inter-coflow scheduling for two different objectives: decreasing communication time of data-intensive jobs and guaranteeing predictable communication time. We introduce the concurrent open shop scheduling with coupled resources problem, analyze its complexity, and propose effective heuristics to optimize either objective. We present Varys, a system that enables data-intensive frameworks to use coflows and the proposed algorithms while maintaining high network utilization and guaranteeing starvation freedom. EC2 deployments and trace-driven simulations show that communication stages complete up to 3.16x faster on average and up to 2x more coflows meet their deadlines using Varys in comparison to per-flow mechanisms. Moreover, Varys outperforms non-preemptive coflow schedulers by more than 5x. © 2014 ACM.",coflow; data-intensive applications; datacenter networks,Complex networks; Convolutional codes; Co-flow; Data center networks; Data-intensive application; Data-parallel applications; Net work utilization; Open shop scheduling; Trace driven simulation; Traditional techniques; Scheduling
"Csoma A., Sonkoly B., Csikor L., NŽmeth F., Gulyas A., Tavernier W., Sahhaf S.",7,"ESCAPE: Extensible Service ChAin Prototyping Environment using mininet, click, NETCONF and POX",2014,19,"MTA-BME Future Internet Research Group, Budapest Univ. of Technology and Economics, Hungary; MTA-BME Information Systems Research Group, Budapest Univ. of Technology and Economics, Hungary; Ghent University, iMinds, Ghent, Belgium",Ghent University;MTA-BME,2,Belgium;Hungary,2,3,3,"Mininet is a great prototyping tool which combines existing SDN-related software components (e.g., Open vSwitch, OpenFlow controllers, network namespaces, cgroups) into a framework, which can automatically set up and configure customized OpenFlow testbeds scaling up to hundreds of nodes. Standing on the shoulders of Mininet, we implement a similar prototyping system called ESCAPE, which can be used to develop and test various components of the service chaining architecture. Our framework incorporates Click for implementing Virtual Network Functions (VNF), NETCONF for managing Click-based VNFs and POX for taking care of traffic steering. We also add our extensible Orchestrator module, which can accommodate mapping algorithms from abstract service descriptions to deployed and running service chains. © 2014 Authors.",click; mininet; NETCONF; prototyping; SDN; service chain,Conformal mapping; Convolutional codes; Software prototyping; click; mininet; NETCONF; SDN; Service chain; Chains
"Showail A., Jamshaid K., Shihada B.",3,WQM: An aggregation-aware queue management scheme for IEEE 802.11n based networks,2014,6,"King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Center for Complex Eng. Systems, KACST, MIT, Riyadh, Saudi Arabia",King Abdullah University of Science and Technology;MIT,2,Saudi Arabia,1,41,29,"Choosing the right buffer size in Wi-Fi networks is challenging due to the dynamic nature of the wireless environment. Over buffering or 'bufferbloat' may produce unacceptable end-to-end delays, while static small buffers may limit the performance gains that can be achieved with various 802.11n enhancements, such as frame aggregation. We propose WQM, a queue management scheme customized for wireless networks. WQM adapts the buffer size based on measured link characteristics and network load. Furthermore, it accounts for aggregate length when deciding about the optimal buffer size. We implement WQM on Linux and evaluate it on a wireless testbed. WQM reduces the end-to-end delay by up to 8x compared to Linux default buffer size, and 2x compared to CoDel, the state-of-the-art bufferbloat solution, while achieving comparable network goodput. Further, WQM improves fairness as it limits the ability of a single flow to saturate the buffer. © 2014 ACM.",a-mpdu; buffer size; bufferbloat; ieee 802.11n; qos; tcp,Computer operating systems; Java programming language; Linux; Quality of service; Standards; Wireless networks; a-mpdu; Buffer sizes; Bufferbloat; IEEE 802.11n; tcp; Wi-Fi
"Schmidt M., Heimgaertner F., Menth M.",3,Demo: A virtualized lab testbed with physical network outlets for hands-on computer networking education,2014,2,"University of Tuebingen, Dept. of Computer Science, Tuebingen, Germany",University of Tuebingen,1,Germany,1,4,2,"This demo presents a testbed for computer networking education. It leverages hardware virtualization to accommodate 6 PCs and 2 routers on a single testbed host to reduce costs, energy consumption, space requirements, and heat emission. The testbed excels by providing dedicated physical Ethernet and USB interfaces for virtual machines so that students can interconnect them with cables and switches like in a non-virtualized testbed © 2014 Authors.",computer networking education; virtual machines; VLAN,Computer networks; Computer simulation; Convolutional codes; Education; Energy utilization; Computer networking educations; Hardware virtualization; Heat emission; Physical network; Space requirements; USB interface; Virtual machines; VLAN; Testbeds
"Obstfeld J., Knight S., Kern E., Wang Q.S., Bryan T., Bourque D.",6,VIRL: The Virtual Internet Routing Lab,2014,5,"Cisco Systems, United States; University of Adelaide, Cisco Systems, Australia",University of Adelaide,1,Australia;USA,2,12,7,"The increasing demand to provide new network services in a timely and efficient manner is driving the need to design, test and deploy networks quickly and consistently. Testing and verifying at scale is a challenge: network equipment is expensive, requires space, power and cooling, and there is never enough test equipment for everyone who wants to use it! Network virtualization technologies enable a flexible environment for educators, researchers, and operators to create functional models of current, planned, or theoretical networks. This demonstration will show VIRL - the Virtual Internet Routing Lab - a platform that can be used for network change validation, training, education, research, or network-aware applications development. The platform combines network virtualization technologies with virtual machines (VMs) running open-source and commercial operating systems; VM orchestration capabilities; a context-aware configuration engine; and an extensible data-collection framework. The system simplifies the process to create both simple and complex environments, run simulations, and collect measurement data. © 2014 Authors.",emulation; network design; network modelling; simulation,Convolutional codes; Distance education; Equipment testing; Internet; Virtual reality; Applications development; Commercial operating systems; Context-aware configuration; emulation; Network design; Network modelling; Network virtualization; simulation; Complex networks
"Kuhn N., Lochin E., Mehani O.",3,Revisiting old friends: Is CoDel really achieving what RED cannot?,2014,13,"IMT Telecom Bretagne, 2 Rue de la Ch‰taigneraie, 35510 Cesson-SŽvignŽ, France; UniversitŽ of Toulouse, ISAE, TŽSA, 10 Avenue ƒdouard Belin, 31400 Toulouse, France; National ICT Australia, 13 Garden St, Eveleigh, NSW 2015, Australia",UniversitŽ of Toulouse,1,Australia;France,2,5,3,"We use ns-2 simulations to compare RED's gentle- mode to CoDel in terms of their ability to reduce the latency for various TCP variants. We use a common dumbbell topol- ogy with Pareto background traffic, and measure the packet delays and transmission time of a 10 MB FTP transfer. In our scenarios, we find that CoDel reduces the latency by 87%, but RED still manages to reduce it by 75%. However, the use of CoDel results in a transmission time 42% longer than when using RED. In light of its maturity, we therefore argue that RED could be considered as a good candidate to tackle Bufferbloat. © 2014 ACM.",aqm; bufferbloat; codel; ns-2; red,aqm; Bufferbloat; codel; ns-2; red; Transmission control protocol
"Hamedazimi N., Qazi Z., Gupta H., Sekar V., Das S.R., Longtin J.P., Shah H., Tanwer A.",8,FireFly: A reconfigurable wireless data center fabric using free-space optics,2014,73,"Stony Brook University, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Stony Brook University,2,USA,1,7,4,"Conventional static datacenter (DC) network designs offer extreme cost vs. performance tradeoffs - simple leaf-spine networks are cost-effective but oversubscribed, while ""fat tree""-like solutions offer good worst-case performance but are expensive. Recent results make a promising case for augmenting an oversubscribed network with reconfigurable inter-rack wireless or optical links. Inspired by the promise of reconfigurability, this paper presents FireFly, an inter-rack network solution that pushes DC network design to the extreme on three key fronts: (1) all links are reconfigurable; (2) all links are wireless; and (3) non top-of-rack switches are eliminated altogether. This vision, if realized, can offer significant benefits in terms of increased flexibility, reduced equipment cost, and minimal cabling complexity. In order to achieve this vision, we need to look beyond traditional RF wireless solutions due to their interference footprint which limits range and data rates. Thus, we make the case for using free-space optics (FSO). We demonstrate the viability of this architecture by (a) building a proof-of-concept prototype of a steerable small form factor FSO device using commodity components and (b) developing practical heuristics to address algorithmic and system-level challenges in network design and management. © 2014 ACM.",data centers; free-space optics; reconfigurablility,Bioluminescence; Convolutional codes; Design; Commodity components; Data centers; Free space optics; Increased flexibility; Performance trade-off; reconfigurablility; Small form factors; Worst-case performance; Complex networks
"Fan Y., Ding H., Hu D.",3,"Green latency-aware data deployment in data centers: Balancing latency, energy in networks and servers",2014,1,"School of Computer and Information, Hefei University of Technology, Hefei, China",Hefei University of Technology,1,China,1,25,17,"Two concerns exist in service provisioning by data centers. One is that users require to experience low latency while accessing data from the data centers. The other is to reduce the power consumed by network transport and servers in the data centers. In this paper, we tackle the problem of green data deployment in the data centers, taking into account the three factors of latency, energy consumption of the data centers and the network transport. © 2014 Authors.",data deployment; energy-efficient; latency-aware,Energy utilization; Accessing data; Data centers; data deployment; Energy efficient; In networks; Latency-aware; Power consumed; Service provisioning; Cloud computing
"Liu Y., Li Y., Wang Y., Vasilakos A.V., Yuan J.",5,Achieving efficient and fast update for multiple flows in software-defined networks,2014,7,"Tsinghua National Laboratory for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing 100084, China; Department of Computer and Telecom. Engineering, University of Western Macedonia, Greece",Tsinghua University;University of Western Macedonia,2,China;Greece;Macedonia,3,52,33,"Aiming to adapt traffic dynamics, deal with network errors, perform planned maintenance, etc., flow update is carried out frequently in Software-Defined Networks (SDN) to change the data plane configuration, and how to update the flows efficiently and successfully is an important and challenging problem. In this work, we address the multi-flow update problem and present a polynomial-time heuristic algorithm, which aims at completing the update in the shortest time considering link bandwidth and flow table size constraints. By extensive simulations under real network settings, we demonstrate the effectiveness and efficiency of our algorithm, which has near-optimal performance and is hundreds of times faster than the optimal solution. © 2014 ACM.",flow update; heuristic algorithm; software-defined networks,Cloud computing; Heuristic algorithms; Optimization; Effectiveness and efficiencies; Extensive simulations; flow update; Near-optimal performance; Optimal solutions; Planned maintenance; Software-defined networks; Traffic dynamics; Computer simulation
"Bischof Z.S., Bustamante F.E.",2,A time for reliability - The growing importance of being always on,2014,1,"Northwestern University, United States",Northwestern University,1,USA,1,2,2,"When a new technology reaches the market, we typically focus on the want or need that it can fulfill. As the technology becomes a commodity and its market matures, reliability often become a key differentiating factor between competing products. We posit that as broadband capacities continue to improve and users migrate to over-the-Internet services, such as on-demand video and voice-over-IP services, we will see this common pattern emerge for broadband services. In this poster, we present the first study of reliability in broadband networks. Using data collected from residential gateways (via FCC/SamKnows), we study the availability and reliability of fixed-line broadband services across the US. Using natural experiments, we look at the impact of increased network downtime on user network demand. We use traditional metrics (e.g. failure rate, MTBF, MTTR) to quantify broadband services, as well as each ISP's configured DNS. Since the impact of a network outage will depend on when it occurred (e.g. time of day), we compare ISP services by the annual average number of bytes lost, based on typical user demand during periods of network downtime. © 2014 Authors.",access link reliability; broadband access networks,Broadband networks; Commerce; Convolutional codes; Internet telephony; Maintenance; Servers; Access links; Broad-band access networks; Broadband service; Natural experiment; Network downtime; Network outages; Residential gateways; Voice over IP services; Reliability
"Roy A.R., Bari Md.F., Zhani M.F., Ahmed R., Boutaba R.",5,DOT: Distributed OpenFlow testbed,2014,2,"David R. Cheriton School of Computer Science, University of Waterloo, Canada",University of Waterloo,1,Canada,1,9,8,"With the growing adoption of Software Defined Networking (SDN) technology, there is a compelling need for an SDN emulator that can facilitate experimenting with new SDN solutions. Unfortunately, Mininet, the de facto standard emulator for software defined networks, fails to scale with network size and traffic volume. To address these limitations, we developed Distributed OpenFlow Testbed (DOT), a highly scalable emulator for SDN. It can emulate large SDN deployments by distributing the workload over a cluster of compute nodes. Moreover, DOT can emulate a wider range of network services compared to other publicly available SDN emulators and simulators. Our demonstration will illustrate several features of DOT including: (i) how easy it is to setup the emulator, (ii) how to deploy a topology using a single configuration file, (iii) how to run a connectivity test to ensure that the emulated network is properly deployed, and (iv) how to control and monitor the emulated components from a centralized location. We will also showcase DOT by emulating two applications: (i) policy based traffic steering through middleboxes and (ii) traffic monitoring. © 2014 Authors.",emulator; software defined networking; testbed,Convolutional codes; Control and monitor; De facto standard; emulator; Single configuration; Software defined networking (SDN); Software-defined networkings; Software-defined networks; Traffic monitoring; Testbeds
"Ansari J., Zhang X., Gaikwad S., MŠhšnen P.",4,Paper: Exploring MAC parallelization on software defined radio platforms,2014,1,"Institute for Networked Systems, RWTH Aachen University, Kackertstr. 9, D-52070 Aachen, Germany",RWTH Aachen University,1,Germany,1,4,3,"MAC layers of today's wireless systems have evolved into complex state-machines, and are characterized by strict timeliness requirements and high computational demands. MAC protocols are generally viewed as sequential extended state-machines and therefore MAC parallelization has not yet been widely considered. In this paper, we show that MAC execution efficiency can be substantially increased by exploiting parallelism and by providing the necessary hardware-software support. In particular, we enable dual-processor interrupt-driven hardware architecture and support a customized real-time operating system kernel on the widely used WARP SDR platform. Moreover, we integrate it with our framework for composing MAC protocols based on their elementary functionalities. We describe the architectural details of the system and discuss strategies for efficient scheduling of different MAC processes. We evaluate our system in realistic application test-cases. Our empirical results show that by exploiting parallelism, our system achieves significant improvements in MAC execution speed compared to the contemporary sequential implementation approach. © 2014 ACM.",mac; multicore; parellelization; prototyping; sdr,Computer architecture; Computer operating systems; Hardware; Medium access control; Scheduling; Software prototyping; mac; Multi core; parellelization; Real time operating system; Realistic applications; sdr; Sequential implementation; Software-defined radios; Software radio
"Hesmans B., Bonaventure O.",2,Tracing multipath TCP connections,2014,8,"ICTEAM, UniversitŽ Catholique de Louvain, Louvain-la-Neuve, Belgium",Universite Catholique de Louvain,1,Belgium,1,5,5,"Multipath TCP is a new extension to TCP that enables a host to transmit the packets from a given connection by using several interfaces. We propose mptcptrace, a software that enables a detailed analysis of Multipath TCP packet traces. © 2014 Authors.",Multipath TCP,Multipath TCP; Convolutional codes
"Fiadino P., Schiavone M., Casas P.",3,Vivisecting WhatsApp through large-scale measurements in mobile networks,2014,11,"FTW Vienna, Austria","FTW,Austria",1,Austria,1,26,22,"WhatsApp, the new giant in instant multimedia messaging in mobile networks is rapidly increasing its popularity, taking over the traditional SMS/MMS messaging. In this paper we present the first large-scale characterization of WhatsApp, useful among others to ISPs willing to understand the impacts of this and similar applications on their networks. Through the combined analysis of passive measurements at the core of a national mobile network, worldwide geo-distributed active measurements, and traffic analysis at end devices, we show that: (i) the WhatsApp hosting architecture is highly centralized and exclusively located in the US; (ii) video sharing covers almost 40% of the total WhatsApp traffic volume; (iii) flow characteristics depend on the OS of the end device; (iv) despite the big latencies to US servers, download throughputs are as high as 1.5 Mbps; (v) users react immediately and negatively to service outages through social networks feedbacks. © 2014 Authors.",instant multimedia messaging; large-scale measurements; mobile networks; service outages; whatsapp,Convolutional codes; Message passing; Wireless networks; Active measurement; Combined analysis; Flow charac-teristics; Large-scale measurement; Multimedia messaging; Passive measurements; Service outage; whatsapp; Internet service providers
"Parniewicz D., Doriguzzi Corin R., Ogrodowczyk L., Rashidi Fard M., Matias J., Gerola M., Fuentes V., Toseef U., Zaalouk A., Belter B., Jacob E., Pentikousis K.",12,Design and implementation of an OpenFlow hardware abstraction layer,2014,14,"Poznan Supercomputing and Networking Center, Poznan, Poland; CREATE-NET, Trento, Italy; University of Bristol, Bristol, United Kingdom; University of Basque Country, Spain; EICT GmbH, Berlin, Germany",EICT GmbH;Poznan Supercomputing and Networking Center;University of Basque Country;University of Bristol,4,Germany;Italy;Poland;Spain;UK,5,5,4,"OpenFlow is a leading standard for Software-Defined Networking (SDN) and has already played a significant role in reshaping network infrastructures. However, a wide range of existing provider domains is still not equipped with a framework that supports wider deployment of an OpenFlow-based control plane beyond Ethernet-dominated networks. We address this gap by introducing a Hardware Abstraction Layer (HAL) which can transform legacy network elements into OpenFlow capable devices. This paper details the functional architecture of HAL, discusses the key design aspects and explains how HAL can support a number of network device classes. In addition, this paper presents the implementation details of HAL for hardware platforms such as DOCSIS (Data over Cable Service Interface Specification) and DWDM (Dense Wavelength Division Multiplexing) which have so far received little attention by the OpenFlow research community despite their wide real-world deployment. © 2014 ACM.",control plane; docsis; dwdm; hardware abstraction; network virtualization; openflow; sdn,Abstracting; Cloud computing; Dense wavelength division multiplexing; Hardware; Medium access control; Control planes; docsis; Hardware abstractions; Network virtualization; Openflow; sdn; Telecommunication networks
"Lee J., Turner Y., Lee M., Popa L., Banerjee S., Kang J.-M., Sharma P.",7,Application-driven bandwidth guarantees in datacenters,2014,59,"HP Labs., United States; University of Edinburgh, United Kingdom; Databricks, United States",HP Labs;University of Edinburgh,2,UK;USA,2,3,3,"Providing bandwidth guarantees to specific applications is becoming increasingly important as applications compete for shared cloud network resources. We present CloudMirror, a solution that provides bandwidth guarantees to cloud applications based on a new network abstraction and workload placement algorithm. An effective network abstraction should enable applications to easily and accurately specify their requirements, while simultaneously enabling the infrastructure to provision resources efficiently for deployed applications. Prior research has approached the bandwidth guarantee specification by using abstractions that resemble physical network topologies. We present a contrasting approach of deriving a network abstraction based on application communication structure, called Tenant Application Graph or TAG. CloudMirror also incorporates a new workload placement algorithm that efficiently meets bandwidth requirements specified by TAGs while factoring in high availability considerations. Extensive simulations using real application traces and datacenter topologies show that CloudMirror can handle 40% more bandwidth demand than the state of the art (e.g., the Oktopus system), while improving high availability from 20% to 70%. © 2014 ACM.",application; availability; bandwidth; cloud; datacenter; virtual network,Abstracting; Applications; Availability; Clouds; Convolutional codes; Electric network topology; Telecommunication networks; Bandwidth requirement; Communication structures; Datacenter; Deployed applications; Extensive simulations; Network abstractions; Physical network topologies; Virtual networks; Bandwidth
"He K., Fisher A., Wang L., Gember A., Akella A., Ristenpart T.",6,"Next stop, the cloud: Understanding modern web service deployment in EC2 and Azure",2013,38,"University of Wisconsin, Madison, United States",University of Wisconsin-Madison,1,USA,1,20,20,"An increasingly large fraction of Internet services are hosted on a cloud computing system such as Amazon EC2 or Windows Azure. But to date, no in-depth studies about cloud usage by Internet services has been performed. We provide a detailed measurement study to shed light on how modern web service deployments use the cloud and to identify ways in which cloud-using services might improve these deployments. Our results show that: 4% of the Alexa top million use EC2/Azure; there exist several common deployment patterns for cloud-using web service front ends; and services can significantly improve their wide-area performance and failure tolerance by making better use of existing regional diversity in EC2. Driving these analyses are several new datasets, including one with over 34 million DNS records for Alexa websites and a packet capture from a large university network. Copyright 2013 ACM.",Azure; Cloud computing; DNS; EC2; Trace analysis; Web service,Azure; Computing system; DNS; EC2; Failure tolerance; Internet services; Measurement study; Web service deployments; Cloud computing; Computer aided network analysis; Computer systems; Internet; Trace analysis; Web services; Windows operating system; Websites
"Hao S., Thomas M., Paxson V., Feamster N., Kreibich C., Grier C., Hollenbeck S.",7,Understanding the domain registration behavior of spammers,2013,33,"Georgia Tech., United States; Verisign, Inc., United States; ICSI, UC Berkeley, United States; ICSI, Lastline, Inc., United States",Georgia Tech;Lastline Inc.;University of California Berkeley;Verisign Inc.,4,USA,1,48,29,"Spammers register a tremendous number of domains to evade blacklisting and takedown efforts. Current techniques to detect such domains rely on crawling spam URLs or monitoring lookup traffic. Such detection techniques are only effective after the spammers have already launched their campaigns, and thus these coun-termeasures may only come into play after the spammer has already reaped significant benefits from the dissemination of large volumes of spam. In this paper we examine the registration process of such domains, with a particular eye towards features that might indicate that a given domain likely has a malicious purpose at registration time, before it is ever used for an attack. Our assessment includes exploring the characteristics of registrars, domain life cycles, registration bursts, and naming patterns. By investigating zone changes from the.com TLD over a 5-month period, we discover that spammers employ bulk registration, that they often re-use domains previously registered by others, and that they tend to register and host their domains over a small set of registrars. Our findings suggest steps that registries or registrars could use to frustrate the efforts of miscreants to acquire domains in bulk, ultimately reducing their agility for mounting large-scale attacks. Copyright 2013 ACM.",Blacklist; DNS; Domain registration; Spam,Blacklist; DNS; Domain registrations; Large volumes; Large-scale attacks; Registration process; Spam; Spammers; Life cycle; Internet
"Vallina-Rodriguez N., Aucinas A., Almeida M., Grunenberger Y., Papagiannaki K., Crowcroft J.",6,RILAnalyzer: A comprehensive 3G monitor on your phone,2013,23,"ICSI, Spain; Computer Laboratory, University of Cambridge, United Kingdom; Telefonica Research, Spain",Telefonica Research;University of Cambridge,2,Spain;UK,2,36,17,"The popularity of smartphones, cloud computing, and the app store model have led to cellular networks being used in a completely different way than what they were designed for. As a consequence, mobile applications impose new challenges in the design and efficient configuration of constrained networks to maximize application's performance. Such difficulties are largely caused by the lack of cross-layer understanding of interactions between different entities - applications, devices, the network and its management plane. In this paper, we describe RILAnalyzer, an open-source tool that provides mechanisms to perform network analysis from within a mobile device. RILAnalyzer is capable of recording low-level radio information and accurate cellular network control-plane data, as well as user-plane data. We demonstrate how such data can be used to identify previously overlooked issues. Through a small user study across four cellular network providers in two European countries we infer how different network configurations are in reality and explore how such configurations interact with application logic, causing network and energy overheads. Copyright 2013 ACM.",Cellular; Energy; Mobile; Networks; Radio; RNC,Cellular; Energy; European Countries; Mobile; Mobile applications; Network configuration; Open source tools; RNC; Measurements; Networks (circuits); Radio; Mobile devices
"Ma L., He T., Leung K.K., Swami A., Towsley D.",5,Identifiability of link metrics based on end-to-end path measurements,2013,19,"Imperial College London, United Kingdom; IBM T. J. Watson Research, Yorktown, NY, United States; Army Research Laboratory, Adelphi, MD, United States; University of Massachusetts, Amherst, MA, United States","Army Research Lab, Adlephi;IBM;Imperial College London;University of Massachusetts Amherst",4,UK;USA,2,32,28,"We investigate the problem of identifying individual link metrics in a communication network from end-to-end path measurements, under the assumption that link metrics are additive and constant. To uniquely identify the link metrics, the number of linearly independent measurement paths must equal the number of links. Our contribution is to characterize this condition in terms of the network topology and the number/placement of monitors, under the constraint that measurement paths must be cycle-free. Our main results are: (i) it is generally impossible to identify all the link metrics by using two monitors; (ii) nevertheless, metrics of all the interior links not incident to any monitor are identifiable by two monitors if the topology satisfies a set of necessary and sufficient connectivity conditions; (iii) these conditions naturally extend to a necessary and sufficient condition for identifying all the link metrics using three or more monitors. We show that these conditions not only allow efficient identifiability tests, but also enable an efficient algorithm to place the minimum number of monitors in order to identify all link metrics. Our evaluations on both random and real topologies show that the proposed algorithm achieves iden-tifiability using a much smaller number of monitors than a baseline solution. Copyright 2013 ACM.",Identifiability condition; Linear algebraic model; Monitor placement; Network tomography,End-to-end path; Identifiability; Identifiability conditions; Linear-algebraic; Linearly independents; Network tomography; Network topology; Algorithms; Electric network topology; Topology; Telecommunication networks
"Zhao M., Aditya P., Chen A., Lin Y., Haeberlen A., Druschel P., Maggs B., Wishon B., Ponec M.",9,Peer-assisted content distribution in Akamai netsession,2013,31,"University of Pennsylvania, United States; MPI-SWS, United States; Duke University, United States; Akamai Technologies, United States",Duke University;University of Pennsylvania,2,USA,1,28,19,"Content distribution systems have traditionally adopted one of two architectures: infrastructure-based content delivery networks (CDNs), in which clients download content from dedicated, centrally managed servers, and peer-to-peer CDNs, in which clients download content from each other. The advantages and disadvantages of each architecture have been studied in great detail. Recently, hybrid, or ""peer-assisted"", CDNs have emerged, which combine elements from both architectures. The properties of such systems, however, are not as well understood. In this paper, we discuss the potential risks and benefits of peer-assisted CDNs, and we study one specific instance, Akamai's NetSession system, to examine the impact of these risks and benefits in practice. NetSession is a mature system that has been operating commercially since 2010 and currently has more than 25 million users in 239 countries and territories. Our results show that NetSession can deliver several of the key benefits of both infrastructure-based and peer-to-peer CDNs - for instance, it can offload 70-80% of the traffic to the peers without a corresponding loss of performance or reliability - and that the risks can be managed well. This suggests that hybrid designs may be an attractive option for future CDNs.",Content distribution networks; Peer-to-peer systems,Content delivery network; Content distribution; Content distribution networks; Content distribution systems; Hybrid design; Loss of performance; Peer-to-Peer system; Potential risks; Measurements; Distributed computer systems
"Luckie M., Huffaker B., Dhamdhere A., Giotsas V., Claffy K.",5,"AS relationships, customer cones, and validation",2013,81,"CAIDA, UC San Diego, United States; University College London, United Kingdom",University College London;University of California San Diego,2,UK;USA,2,35,16,"Business relationships between ASes in the Internet are typically confidential, yet knowledge of them is essential to understand many aspects of Internet structure, performance, dynamics, and evolution. We present a new algorithm to infer these relationships using BGP paths. Unlike previous approaches, our algorithm does not assume the presence (or seek to maximize the number) of valley-free paths, instead relying on three assumptions about the Internet's inter-domain structure: (1) an AS enters into a provider relationship to become globally reachable; and (2) there exists a peering clique of ASes at the top of the hierarchy, and (3) there is no cycle of p2c links. We assemble the largest source of validation data for AS-relationship inferences to date, validating 34.6% of our 126,082 c2p and p2p inferences to be 99.6% and 98.7% accurate, respectively. Using these inferred relationships, we evaluate three algorithms for inferring each AS's customer cone, defined as the set of ASes an AS can reach using customer links. We demonstrate the utility of our algorithms for studying the rise and fall of large transit providers over the last fifteen years, including recent claims about the flattening of the AS-level topology and the decreasing influence of ""tier-1"" ASes on the global Internet. Copyright 2013 ACM.",ASL relationships; Customer cones; Routing policies,AS relationships; ASL relationships; Business relationships; Global Internet; Inter-domain; Internet structure; Routing policies; Validation data; Algorithms; Internet; Sales
"Chatzis N., Smaragdakis G., Bšttger J., Krenc T., Feldmann A.",5,On the benefits of using a large IXP as an Internet vantage point,2013,17,"T-Labs, TU Berlin, Germany",TU Berlin,1,Germany,1,36,25,"In the context of measuring the Internet, a long-standing question has been whether there exist well-localized physical entities in today's network where traffic from a representative cross-section of the constituents of the Internet can be observed at a fine-enough granularity to paint an accurate and informative picture of how these constituents shape and impact much of the structure and evolution of today's Internet and the actual traffic it carries. In this paper, we first answer this question in the affirmative by mining 17 weeks of continuous sFlow data from one of the largest European IXPs. Examining these weekly snapshots, we discover a vantage point with excellent visibility into the Internet, seeing week-in and week-out traffic from all 42K+ routed ASes, almost all 450K+ routed prefixes, from close to 1.5M servers, and around a quarter billion IPs from all around the globe. Second, to show the potential of such vantage points, we analyze the server-related portion of the traffic at this IXP, identify the server IPs and cluster them according to the organizations responsible for delivering the content. In the process, we observe a clear trend among many of the critical Internet players towards network heterogenization; that is, either hosting servers of third-party networks in their own infrastructures or pursuing massive deployments of their own servers in strategically chosen third-party networks. While the latter is a well-known business strategy of companies such as Akamai, Google, and Netflix, we show in this paper the extent of network heteroge-nization in today's Internet and illustrate how it enriches the traditional, largely traffic-agnostic AS-level view of the Internet. Copyright is held by the owner/author(s).",Content delivery; Internet exchange points; Internet topology; Traffic characterization,Business strategy; Content delivery; Heterogenization; Internet exchange points; Internet players; Internet topologies; Massive deployment; Traffic characterization; Measurements; Internet
"Barbera M.V., Epasto A., Mei A., Perta V.C., Stefa J.",5,Signals from the crowd: Uncovering social relationships through smartphone probes,2013,50,"Department of Computer Science, Sapienza University of Rome, Italy",Sapienza University of Rome,1,Italy,1,37,25,"The ever increasing ubiquitousness of WiFi access points, coupled with the diffusion of smartphones, suggest that Internet every time and everywhere will soon (if not already has) become a reality. Even in presence of 3G connectivity, our devices are built to switch automatically to WiFi networks so to improve user experience. Most of the times, this is achieved by recurrently broadcasting automatic connectivity requests (known as Probe Requests) to known access points (APs), like, e.g., ""Home WiFi"", ""Campus WiFi"", and so on. In a large gathering of people, the number of these probes can be very high. This scenario rises a natural question: ""Can significant information on the social structure of a large crowd and on its socioeconomic status be inferred by looking at smartphone probes?"". In this work we give a positive answer to this question. We organized a 3-months long campaign, through which we collected around 11M probes sent by more than 160K different devices. During the campaign we targeted national and international events that attracted large crowds as well as other gatherings of people. Then, we present a simple and automatic methodology to build the underlying social graph of the smartphone users, starting from their probes. We do so for each of our target events, and find that they all feature social-network properties. In addition, we show that, by looking at the probes in an event, we can learn important sociological aspects of its participants - language, vendor adoption, and so on. Copyright 2013 ACM.",Smartphones; Social networks; Wi-Fi probe requests,Access point (APs); Automatic connectivity; Social relationships; Social structure; Socio-economic status; User experience; Wi Fi networks; Wi-fi access points; Online systems; Signal encoding; Smartphones; Social networking (online); Switching circuits; Wi-Fi; Probes
"Meiklejohn S., Pomarole M., Jordan G., Levchenko K., McCoy D., Voelker G.M., Savage S.",7,A fistful of bitcoins: Characterizing payments among men with no names,2013,189,"University of California, San Diego, United States; George Mason University, United States",George Mason University;University of California San Diego,2,USA,1,54,35,"Bitcoin is a purely online virtual currency, unbacked by either physical commodities or sovereign obligation; instead, it relies on a combination of cryptographic protection and a peer-to-peer protocol for witnessing settlements. Consequently, Bitcoin has the unintuitive property that while the ownership of money is implicitly anonymous, its flow is globally visible. In this paper we explore this unique characteristic further, using heuristic clustering to group Bitcoin wallets based on evidence of shared authority, and then using re-identification attacks (i.e., empirical purchasing of goods and services) to classify the operators of those clusters. From this analysis, we characterize longitudinal changes in the Bitcoin market, the stresses these changes are placing on the system, and the challenges for those seeking to use Bitcoin for criminal or fraudulent purposes at scale. Copyright 2013 ACM.",Anonymity; Bitcoin; Measurement,Anonymity; Bitcoin; Peer-to-peer protocols; Re identifications; Virtual currency; Measurements
"Gill P., Erramilli V., Chaintreau A., Krishnamurthy B., Papagiannaki D., Rodriguez P.",6,Follow the money understanding economics of online aggregation and advertising,2013,31,"Stony Brook University, United States; Telefonica Research, United States; Columbia University, United States; AT and T Labs - Research, United States",AT and T Labs;Columbia University;Stony Brook University;Telefonica Research,4,USA,1,41,28,"The large-scale collection and exploitation of personal information to drive targeted online advertisements has raised privacy concerns. As a step towards understanding these concerns, we study the relationship between how much information is collected and how valuable it is for advertising. We use HTTP traces consisting of millions of users to aid our study and also present the first comparative study between aggregators. We develop a simple model that captures the various parameters of today's advertising revenues, whose values are estimated via the traces. Our results show that per aggregator revenue is skewed (5% accounting for 90% of revenues), while the contribution of users to advertising revenue is much less skewed (20% accounting for 80% of revenue). Google is dominant in terms of revenue and reach (presence on 80% of publishers). We also show that if all 5% of the top users in terms of revenue were to install privacy protection, with no corresponding reaction from the publishers, then the revenue can drop by 30%. Copyright 2013 ACM.",Advertising; Aggregators; CPM; Do-not-track; Privacy; Publishers,Advertising revenues; Aggregators; CPM; Do-not-track; Online advertisements; Online aggregations; Personal information; Publishers; Data privacy; Marketing; Publishing; Economics
"Luckie M., Beverly R., Brinkmeyer W., Claffy K.",4,Speedtrap: Internet-scale IPv6 alias resolution,2013,9,"CAIDA, UC San Diego, United States; Naval Postgraduate School, United States",Naval Postgraduate School;University of California San Diego,2,USA,1,21,20,"Impediments to resolving IPv6 router aliases have precluded understanding the emerging router-level IPv6 Internet topology. In this work, we design, implement, and validate the first Internet-scale alias resolution technique for IPv6. Our technique, speedtrap, leverages the ability to induce fragmented IPv6 responses from router interfaces in a particular temporal pattern that produces distinguishing per-router fingerprints. Our algorithm surmounts three fundamental challenges to Internet-scale IPv6 alias resolution using fragment identifier values: (1) unlike for IPv4, the identifier counters on IPv6 routers have no natural velocity, (2) the values of these counters are similar across routers, and (3) the packet size required to collect inferences is 46 times larger than required in IPv4. We demonstrate the efficacy of the technique by producing router-level Internet IPv6 topologies using measurements from CAIDA's distributed infrastructure. Our preliminary work represents a step toward understanding the Internet's IPv6 router-level topology, an important objective with respect to IPv6 network resilience, security, policy, and longitudinal evolution. Copyright 2013 ACM.",Alias resolution; Internet topology; IPv6,Distributed infrastructure; Internet topologies; IPv6; IPv6 networks; Packet size; Resolution techniques; Temporal pattern; Internet; Internet protocols; Topology; Routers
"Dalek J., Haselton B., Noman H., Senft A., Crete-Nishihata M., Gill P., Deibert R.J.",7,A method for identifying and confirming the use of URL filtering products for censorship,2013,12,"Citizen Lab., University of Toronto, Canada; Dept. of Computer Science, Stony Brook University, United States",Stony Brook University;University of Toronto,2,Canada;USA,2,30,25,"Products used for managing network traffic and restricting access to Web content represent a dual-use technology. While they were designed to improve performance and protect users from inappropriate content, these products are also used to censor the Web by authoritarian regimes around the globe. This dual use has not gone unnoticed, with Western governments placing restrictions on their export. Our contribution is to present methods for identifying installations of URL filtering products and confirming their use for censorship. We first present a methodology for identifying externally visible installations of URL filtering products in ISPs around the globe. Further, we leverage the fact that many of these products accept user-submitted sites for blocking to confirm that a specific URL filtering product is being used for censorship. Using this method, we are able to confirm the use of McAfee SmartFilter in Saudi Arabia and the United Arab Emirates (UAE) and Netsweeper in Qatar, the UAE, and Yemen. Our results show that these products are being used to block a range of content, including op-positional political speech, religious discussion and gay and lesbian material, speech generally protected by international human rights norms. Copyright 2013 ACM.",Censorship; Network measurement; URL filtering,Censorship; Dual use technology; Human rights; Improve performance; Network measurement; Network traffic; United Arab Emirates; Url filtering; Measurements
"Petsas T., Papadogiannakis A., Polychronakis M., Markatos E.P., Karagiannis T.",5,Rise of the planet of the apps: A systematic study of the mobile app ecosystem,2013,42,"FORTH-ICS, Greece; Columbia University, United States; Microsoft Research, United Kingdom",Columbia University;Microsoft,2,Greece;UK;USA,3,30,24,"Mobile applications (apps) have been gaining rising popularity due to the advances in mobile technologies and the large increase in the number of mobile users. Consequently, several app distribution platforms, which provide a new way for developing, downloading, and updating software applications in modern mobile devices, have recently emerged. To better understand the download patterns, popularity trends, and development strategies in this rapidly evolving mobile app ecosystem, we systematically monitored and analyzed four popular third-party Android app marketplaces. Our study focuses on measuring, analyzing, and modeling the app popularity distribution, and explores how pricing and revenue strategies affect app popularity and developers' income. Our results indicate that unlike web and peer-to-peer file sharing workloads, the app popularity distribution deviates from commonly observed Zipf-like models. We verify that these deviations can be mainly attributed to a new download pattern, to which we refer as the clustering effect. We validate the existence of this effect by revealing a strong temporal affinity of user downloads to app categories. Based on these observations, we propose a new formal clustering model for the distribution of app downloads, and demonstrate that it closely fits measured data. Moreover, we observe that paid apps follow a different popularity distribution than free apps, and show how free apps with an ad-based revenue strategy may result in higher financial benefits than paid apps. We believe that this study can be useful to appstore designers for improving content delivery and recommendation systems, as well as to app developers for selecting proper pricing policies to increase their income. Copyright 2013 ACM.",App popularity; App pricing; Appstores; Clustering effect; Mobile apps; Revenue; Workload characterization,App popularity; Appstores; Clustering effect; Mobile apps; Workload characterization; Costs; Distributed computer systems; Earnings; Economics; Ecosystems; Mobile devices; Mobile telecommunication systems; Application programs
"Czyz J., Lady K., Miller S.G., Bailey M., Kallitsis M., Karir M.",6,Understanding IPv6 Internet background radiation,2013,10,"University of Michigan, Ann Arbor, MI, United States; Merit Network, Inc., Ann Arbor, MI, United States; Department of Homeland Security Sci. and Tech., Directorate Cyber Security Division, Washington, DC, United States",Merit Network Inc.;University of Michigan at Ann Arbor,2,USA,1,35,30,"We report the results of a study to collect and analyze IPv6 Internet background radiation. This study, the largest of its kind, collects unclaimed traffic on the IPv6 Internet by announcing five large/12 covering prefixes; these cover the majority of allocated IPv6 space on today's Internet. Our analysis characterizes the nature of this traffic across regions, over time, and by the allocation and routing status of the intended destinations, which we show help to identify the causes of this traffic. We compare results to unclaimed traffic in IPv4, and highlight case studies that explain a large fraction of the data or highlight notable properties. We describe how announced covering prefixes differ from traditional network telescopes, and show how this technique can help both network operators and the research community identify additional potential issues and mis-configurations in this critical Internet transition period. Copyright 2013 ACM.",Darknet; Internet background radiation; IPv6; Measurement; Network pollution; Routing,Darknet; Internet background radiation; IPv6; Network operator; Network telescopes; Research communities; Routing; Transition period; Internet; Measurements; Radiation; Internet protocols
"Li W., Mok R.K.P., Chang R.K.C., Fok W.W.T.",4,Appraising the delay accuracy in browser-based network measurement,2013,14,"Department of Computing, Hong Kong Polytechnic University, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,45,25,"Conducting network measurement in a web browser (e.g., speedtest and Netalyzr) enables end users to understand their network and application performance. However, very little is known about the (in) accuracy of the various methods used in these tools. In this paper, we evaluate the accuracy of ten HTTP-based and TCP socket-based methods for measuring the round-trip time (RTT) with the five most popular browsers on Linux and Windows. Our measurement results show that the delay overheads incurred in most of the HTTP-based methods are too large to ignore. Moreover, the overheads incurred by some methods (such as Flash GET and POST) vary significantly across different browsers and systems, making it very difficult to calibrate. The socket-based methods, on the other hand, incur much smaller overhead. Another interesting and important finding is that Date.getTime(), a typical timing API in Java, does not provide the millisecond resolution assumed by many measurement tools on some OSes (e.g., Windows 7). This results in a serious under-estimation of RTT. On the other hand, some tools over-estimate the RTT by including the TCP handshaking phase. Copyright 2013 ACM.",Accuracy; Delay; Measurement; Web,Accuracy; Application performance; Conducting networks; Delay; Delay overheads; Measurement tools; Network measurement; Web; Computer operating systems; HTTP; Tools; Web browsers; Measurements
"Vanaubel Y., Pansiot J.-J., MŽrindol P., Donnet B.",4,Network fingerprinting: TTL-based router signatures,2013,10,"UniversitŽ de Lige, Belgium; UniversitŽ de Strasbourg, France",UniversitŽ de Lige;UniversitŽ de Strasbourg,2,Belgium;France,2,40,35,"Fingerprinting networking equipment has many potential applications and benefits in network management and security. More generally, it is useful for the understanding of network structures and their behaviors. In this paper, we describe a simple fingerprinting mechanism based on the initial TTL values used by routers to reply to various probing messages. We show that main classes obtained using this simple mechanism are meaningful to distinguish routers platforms. Besides, it comes at a very low additional cost compared to standard active topology discovery measurements. As a proof of concept, we apply our method to gain more insight on the behavior of MPLS routers and to, thus, more accurately quantify their visible/invisible deployment. Copyright 2013 ACM.",Fingerprinting; Initial TTL; MPLS; Network discovery; Router signatures,Fingerprinting; In-network management; MPLS; Network discovery; Network structures; Networking equipment; Proof of concept; Topology discovery; Network management; Network security; Routers
"Schomp K., Callahan T., Rabinovich M., Allman M.",4,On measuring the client-side DNS infrastructure,2013,34,"Case Western Reserve University, Cleveland, OH, United States; International Computer Science Institute, Berkeley, CA, United States",Case Western Reserve University;University of California Berkeley,2,USA,1,36,14,"The Domain Name System (DNS) is a critical component of the Internet infrastructure. It allows users to interact with Web sites using human-readable names and provides a foundation for transparent client request distribution among servers in Web platforms, such as content delivery networks. In this paper, we present methodologies for efficiently discovering the complex client-side DNS infrastructure. We further develop measurement techniques for isolating the behavior of the distinct actors in the infrastructure. Using these strategies, we study various aspects of the client-side DNS infrastructure and its behavior with respect to caching, both in aggregate and separately for different actors. Copyright 2013 ACM.",Domain Name System (DNS); Internet measurement,Client request; Content delivery network; Critical component; Domain name system; Human-readable; Internet infrastructure; Internet measurement; Measurement techniques; Measurements; Internet protocols
"Berger A., Weaver N., Beverly R., Campbell L.",4,Internet nameserver IPv4 and IPv6 address relationships,2013,8,"MIT CSAIL, Akamai, United States; ICSI, UCSD, United States; Naval Postgraduate School, United States; Akamai, United States",MIT;Naval Postgraduate School,2,USA,1,29,20,"The modern Domain Name System (DNS) provides not only resolution, but also enables intelligent client routing, e.g. for Content Distribution Networks (CDNs). The adoption of IPv6 presents CDNs the opportunity to utilize different paths when optimizing traffic, and the challenge of appropriately mapping IPv6 DNS queries. This work seeks to discover the associations between Internet DNS client resolver IPv6 address(es) and IPv4 address(es). We design and implement two new techniques, one passive and one active, to gather resolver pairings. The passive technique, deployed in Akamai's production DNS infrastructure, opportunistically discovered 674k (IPv4, IPv6) associated address pairs within a six-month period. We find that 34% of addresses are one-to-one, i.e. appear in no other pair, a fraction that increases to Å 50% when aggregating IPv6 addresses into/64 prefixes. The one-to-one associations are suggestive, but not a sufficient condition, of dual-stack DNS recursive resolvers. We further substantiate our inferences via PTR records and software versions, and manual verification of sample pairings by three major Network Operators. Complex associations, where e.g. distributed DNS resolution leads to inferred address groupings that span continents and many autonomous systems exist, a subset of which we explore in more depth using the active probing technique. Among potential uses, Akamai is currently utilizing screened output from the passive technique, in conjunction with prior knowledge of IPv4, to inform IPv6 geolocation within its CDN. Copyright 2013 ACM.",DNS; IPv6; Nameservers; Resolvers,Active probing techniques; Content distribution networks; Design and implements; DNS; Intelligent clients; IPv6; Nameservers; Resolvers; Complex networks; Internet; Verification; Internet protocols
"Comarela G., GŸrsun G., Crovella M.",3,Studying interdomain routing over long timescales,2013,6,"Boston University, Boston, United States",Boston University,1,USA,1,23,14,"The dynamics of interdomain routing have traditionally been studied through the analysis of BGP update traffic. However, such studies tend to focus on the volume of BGP updates rather than their effects, and tend to be local rather than global in scope. Studying the global state of the Internet routing system over time requires the development of new methods, which we do in this paper. We define a new metric, MRSD, that allows us to measure the similarity between two prefixes with respect to the state of the global routing system. Applying this metric over time yields a measure of how the set of total paths to each prefix varies at a given timescale. We implement this analysis method in a MapReduce framework and apply it to a dataset of more than 1TB, collected daily over 3 distinct years and monthly over 8 years. We show that this analysis method can uncover interesting aspects of how Internet routing has changed over time. We show that on any given day, approximately 1% of the next-hop decisions made in the Internet change, and this property has been remarkably constant over time; the corresponding amount of change in one month is 10% and in two years is 50%. Digging deeper, we can decompose next-hop decision changes into two classes: churn, and structural (persistent) change. We show that structural change shows a strong 7-day periodicity and that it represents approximately 2/3 of the total amount of changes. Copyright 2013 ACM.",BGP; Interdomain routing,Analysis method; BGP; Global routing; Global state; Interdomain Routing; Internet routing; Mapreduce frameworks; Time-scales; Measurements; Internet
"Stringhini G., Wang G., Egele M., Kruegel C., Vigna G., Zheng H., Zhao B.Y.",7,Follow the green: Growth and dynamics in Twitter follower markets,2013,74,"Department of Computer Science, UC Santa Barbara, United States; Carnegie Mellon University, United States",Carnegie Mellon University;University of California Santa Barbara,2,USA,1,32,25,"The users of microblogging services, such as Twitter, use the count of followers of an account as a measure of its reputation or influence. For those unwilling or unable to attract followers naturally, a growing industry of ""Twitter follower markets"" provides followers for sale. Some markets use fake accounts to boost the follower count of their customers, while others rely on a pyramid scheme to turn non-paying customers into followers for each other, and into followers for paying customers. In this paper, we present a detailed study of Twitter follower markets, report in detail on both the static and dynamic properties of customers of these markets, and develop and evaluate multiple techniques for detecting these activities. We show that our detection system is robust and reliable, and can detect a significant number of customers in the wild. Copyright 2013 ACM.",Follower markets; Online social networks; Sybils; Twitter,Detection system; Dynamic property; Micro-blogging services; On-line social networks; Sybils; Twitter; Online systems; Sales; Social networking (online); Commerce
"Fusco F., Vlachos M., Dimitropoulos X., Deri L.",4,Indexing million of packets per second using GPUs,2013,18,"ETH Zurich, Gloriastrasse 35, Zurich, Switzerland; IBM Research - Zurich, SŠumerstrasse 4, RŸshlikon, Switzerland; Ntop.org, Pisa, Italy",ETH Zurich;IBM,2,Italy;Switzerland,2,13,9,"Network traffic recorders are devices that record massive volumes of network traffic for security applications, like retrospective forensic investigations. When deployed over very high-speed networks, traffic recorders must process and store millions of packets per second. To enable interactive explorations of such large traffic archives, packet indexing mechanisms are required. Indexing packets at wire rates (10 Gbps and above) on commodity hardware imposes unparalleled requirements for high throughput index creation. Such indexing throughputs are presently untenable with modern indexing technologies and current processor architectures. In this work, we propose to intelligently offload indexing to commodity General Processing Units (GPUs). We introduce algorithms for building compressed bitmap indexes in real time on GPUs and show that we can achieve indexing throughputs of up to 185 millions records per second, which is an improvement by one order of magnitude compared to the state-of-the-art. This shows that indexing network traffic at multi-10-Gbps rates is well within reach. Copyright 2013 ACM.",GPU; Indexing; Packet traces,Commodity hardware; Current processors; Forensic investigation; GPU; Interactive exploration; Packet traces; Packets per seconds; Security application; Computer architecture; HIgh speed networks; Program processors; Indexing (of information)
"Erman J., Ramakrishnan K.K.",2,Understanding the Super-sized traffic of the Super Bowl,2013,34,"AT and T Labs Research, NJ, United States",AT and T Labs,1,USA,1,37,32,"Large events like the Super Bowl, where almost 75K attendees con-gegrate for several hours, poses a significant challenge in the planning, design and deployment of wireless networks. This was one of the first events where the LTE cellular network was available widely, in addition to almost 700 WiFi free hotspots. The Super Bowl in 2013 was also unprecedented because of a stadium-wide power outage for over half an hour. This study is the first to look in-depth at the user behaviours and traffic demand of a large ISP's celluar network at such an unique event. The findings of this study can be used to guide the design of the communication networks of large venues in the future. There are several key insights from our study of the data collected. First, LTE speeds enable subscribers at venues to stream high-quality video and this can be a signficant source of traffic. Second, the configuration of the uplink for such events is key, and a thoughtful approach to the design of applications that use the cloud for storing user data can substantially mitigate the congestion on the resource constrained uplink. Further, while it is tempting to take advantage of multicast on the cellular network (e.g., deploying technologies such as eMBMS in a venue), our results indicate that there is a need to combine multicast with caching to remove the strict requirement of overlap of requests from users to derive that benefit. Copyright 2013 ACM.",Cellular networks; Characterization; Large venues,Cellular network; High-quality videos; Large venues; Power outage; Super bowl; Traffic demands; User behaviour; User data; Behavioral research; Characterization; Design; Multicasting; Outages; Wi-Fi; Wireless telecommunication systems
"Pelsser C., Cittadini L., Vissicchio S., Bush R.",4,From Paris to Tokyo: On the suitability of ping to measure latency,2013,26,"Internet Initiative Japan, Tokyo, Japan; Roma Tre University, Rome, Italy; Universite catholique de Louvain, Louvain-la-Neuve, Belgium",Roma Tre University;Universite Catholique de Louvain,2,Belgium;Italy;Japan,3,15,14,"Monitoring Internet performance and measuring user quality of experience are drawing increased attention from both research and industry. To match this interest, large-scale measurement infrastructures have been constructed. We believe that this effort must be combined with a critical review and calibrarion of the tools being used to measure performance. In this paper, we analyze the suitability of ping for delay measurement. By performing several experiments on different source and destination pairs, we found cases in which ping gave very poor estimates of delay and jitter as they might be experienced by an application. In those cases, delay was heavily dependent on the flow identifier, even if only one IP path was used. For accurate delay measurement we propose to replace the ping tool with an adaptation of paris-traceroute which supports delay and jitter estimation, without being biased by per-flow network load balancing. Copyright 2013 ACM.",Delay; Jitter; Load-balancing; Ping,Delay; Delay measurements; Internet performance; Large-scale measurement; Load-Balancing; Network load balancing; Ping; Quality of experience (QoE); Industrial research; Network management; Tools; Jitter
"Ferguson A.D., Place J., Fonseca R.",3,Growth analysis of a large ISP,2013,3,"Brown University, United States",Brown University,1,USA,1,16,11,"We present a time-series analysis of Cogent's inter-continental network. The analysis is based on descriptions of Cogent's routers and their interfaces, collected each week for more than one year. These descriptions are collected from public reverse DNS records, which we cross-validate using iffinder, a full Internet scan, and limited ground truth data provided by Cogent. For example, our dataset, which we make available to the research community, shows that while the number of Cogent routers grew by approximately 11.3 each week, the average number of interfaces per router, and the effective diameter of the inferred network remained stable over the same period. Our collected dataset includes information about interface types, port identifications, router locations, peer and customer attachments, and more. Copyright is held by the owner/author(s).",Alias resolution; Reverse DNS,Average numbers; Effective diameter; Ground truth data; Growth analysis; Inferred networks; Research communities; Reverse DNS; Data processing; Internet protocols; Internet service providers; Routers
"Khan A., Kwon T., Kim H.-C., Choi Y.",4,AS-level topology collection through looking glass servers,2013,10,"Seoul National University, South Korea; Sangmyung University, South Korea",Sangmyung University;Seoul National University,2,South Korea,1,21,12,"While accurate and complete modeling of the Internet topology at the Autonomous System (AS) level is critical for future protocol design, performance evaluation, simulation and analysis, still it remains a challenge to construct its accurate representation. In this paper, we collect BGP route announcements of ASes from Looking glass (LG) servers. By querying LG servers, we build an AS topology estimate of around 116 K AS links, from which we discover 11 K new AS links and 686 new ASes. We conclude that collecting BGP traces from LG servers can help enhance the current view of the AS topology from the BGP collector projects (e.g., RouteViews). Copyright 2013 ACM.",Border gateway protocol (BGP); Inter-domain routing; Looking glass servers,AS topologies; AS-links; Autonomous systems; Border gateway protocol; Interdomain Routing; Internet topologies; Protocol design; Simulation and analysis; Gateways (computer networks); Glass; Internet protocols; Topology
"Grover S., Park M.S., Sundaresan S., Burnett S., Kim H., Feamster N.",6,Peeking behind the NAT: An empirical study of home networks,2013,23,"School of Computer Science, Georgia Tech., United States",Georgia Tech,1,USA,1,27,13,"We present the first empirical study of home network availability, infrastructure, and usage, using data collected from home networks around the world. In each home, we deploy a router with custom firmware to collect information about the availability of home broadband network connectivity, the home network infrastructure (including the wireless connectivity in each home network and the number of devices connected to the network), and how people in each home network use the network. Downtime is more frequent and longer in developing countries - sometimes due to the network, and in other cases because users simply turn off their home router. We also find that some portions of the wireless spectrum are extremely crowded, that diurnal patterns are more pronounced during the week, and that most traffic in home networks is exchanged over a few connections to a small number of domains. Our study is both a preliminary view into many home networks and an illustration of how measurements from a home router can yield significant information about home networks. Copyright 2013 ACM.",BIsmark; Home networks,BIsmark; Diurnal pattern; Empirical studies; Home routers; Network availability; Network connectivity; Network infrastructure; Wireless connectivities; Developing countries; Firmware; Home networks; Personal communication systems; Carrier communication
"Dey R., Ding Y., Ross K.W.",3,Profiling high-school students with facebook: How online privacy laws can actually increase minors' risk,2013,6,"Polytechnic Institute of New York, University Brooklyn, New York, United States",NYU,1,USA,1,38,20,"Lawmakers, children's advocacy groups and modern society at large recognize the importance of protecting the Internet privacy of minors (under 18 years of age). Online Social Networks, in particular, take precautions to prevent third parties from using their services to discover and profile minors. These precautions include displaying only minimal information in registered minors' public profiles, not listing minors when searching for users by high school or city, and banning young children from joining altogether. In this paper we show how an attacker can circumvent these precautions. We develop efficient crawling and data mining methodologies to discover and profile most of the high school students in a targeted high school. In particular, using Facebook and for a given target high school, the methodology finds most of the students in the school, and for each discovered student infers a profile that includes significantly more information than is available in a registered minor's public profile. Such profiles can be used for many nefarious purposes, including selling the profiles to data brokers, large-scale automated spear-phishing attacks on minors, as well as physical safety attacks such as stalking, kidnapping and arranging meetings for sexual abuse. Ironically, the Children's Online Privacy Protection Act (COPPA), a law designed to protect the privacy of children, indirectly facilitates the approach. In order to bypass restrictions put in place due to the COPPA law, some children lie about their ages when registering, which not only increases the exposure for themselves but also for their non-lying friends. Our analysis strongly suggests there would be significantly less privacy leakage if Facebook did not have age restrictions. Copyright is held by the owner/author(s).",COPPA; Facebook; High school; Minor; Policy; Privacy,COPPA; Facebook; High school; High school students; Minimal information; Minor; On-line social networks; Privacy leakages; Data privacy; Public policy; Social networking (online); Students; Online systems
"Chen Y.-C., Lim Y.-S., Gibbens R.J., Nahum E.M., Khalili R., Towsley D.",6,A measurement-based study of multipath TCP performance over wireless networks,2013,129,"School of Computer Science, University of Massachusetts, Amherst, MA, United States; Computer Laboratory, University of Cambridge, Cambridge, United Kingdom; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, United States; T-Labs, Deutsche Telekom, Berlin, Germany",IBM;University of Cambridge;University of Massachusetts Amherst,3,Germany;UK;USA,3,33,23,"With the popularity of mobile devices and the pervasive use of cellular technology, there is widespread interest in hybrid networks and on how to achieve robustness and good performance from them. As most smart phones and mobile devices are equipped with dual interfaces (WiFi and 3G/4G), a promising approach is through the use of multi-path TCP, which leverages path diversity to improve performance and provide robust data transfers. In this paper we explore the performance of multi-path TCP in the wild, focusing on simple 2-path multi-path TCP scenarios. We seek to answer the following questions: How much can a user benefit from using multi-path TCP over cellular and WiFi relative to using the either interface alone? What is the impact of flow size on average latency? What is the effect of the rate/route control algorithm on performance? We are especially interested in understanding how application level performance is affected when path characteristics (e.g., round trip times and loss rates) are diverse. We address these questions by conducting measurements using one commercial Internet service provider and three major cellular carriers in the US. Copyright 2013 ACM.",3G; 4G; CDMA; Cellular networks; Congestion control; LTE; Measurements; MPTCP; Multi-path TCP; Wireless,3G; 4G; Cellular network; LTE; MPTCP; Multi-path TCP; Algorithms; Code division multiple access; Congestion control (communication); Data transfer; Internet service providers; Measurements; Mobile devices; Mobile telecommunication systems; Radio; Wireless telecommunication systems; Transmission control protocol
"Tyson G., Elkhatib Y., Sastry N., Uhlig S.",4,Demystifying porn 2.0: A look into a major adult video streaming website,2013,14,"Queen Mary University of London, United Kingdom; Lancaster University, United Kingdom; King's College London, United Kingdom",Kings College London;Lancaster University;Queen Mary University of London,3,UK,1,28,28,"The Internet has evolved into a huge video delivery infrastructure, with websites such as YouTube and Netflix appearing at the top of most traffic measurement studies. However, most traffic studies have largely kept silent about an area of the Internet that (even today) is poorly understood: adult media distribution. Whereas ten years ago, such services were provided primarily via peer-to-peer file sharing and bespoke websites, recently these have converged towards what is known as ""Porn 2.0"". These popular web portals allow users to upload, view, rate and comment videos for free. Despite this, we still lack even a basic understanding of how users interact with these services. This paper seeks to address this gap by performing the first large-scale measurement study of one of the most popular Porn 2.0 websites: YouPorn. We have repeatedly crawled the website to collect statistics about 183k videos, witnessing over 60 billion views. Through this, we offer the first characterisation of this type of corpus, highlighting the nature of YouPorn's repository. We also inspect the popularity of objects and how they relate to other features such as the categories to which they belong. We find evidence for a high level of flexibility in the interests of its user base, manifested in the extremely rapid decay of content popularity over time, as well as high susceptibility to browsing order. Using a small-scale user study, we validate some of our findings and explore the infrastructure design and management implications of our observations. Copyright 2013 ACM.",Adult websites; Measurements; Porn 2.0; Video streaming,Content popularities; Infrastructure design; Large-scale measurement; Management implications; Media distribution; Peer-to-peer file sharing; Porn 2.0; Traffic measurements; Distributed computer systems; Internet; Measurements; Video streaming; Websites
"LaCurts K., Deng S., Goyal A., Balakrishnan H.",4,Choreo: Network-aware task placement for cloud applications,2013,46,"MIT Computer Science and Artificial Intelligence Lab., Cambridge, MA, United States",MIT,1,USA,1,32,26,"Cloud computing infrastructures are increasingly being used by network-intensive applications that transfer significant amounts of data between the nodes on which they run. This paper shows that tenants can do a better job placing applications by understanding the underlying cloud network as well as the demands of the applications. To do so, tenants must be able to quickly and accurately measure the cloud network and profile their applications, and then use a network-aware placement method to place applications. This paper describes Choreo, a system that solves these problems. Our experiments measure Amazon's EC2 and Rackspace networks and use three weeks of network data from applications running on the HP Cloud network [15]. We find that Choreo reduces application completion time by an average of 8%-14% (max improvement: 61%) when applications are placed all at once, and 22%-43% (max improvement: 79%) when they arrive in real-time, compared to alternative placement schemes. Copyright 2013 ACM.",Application placement; Bottlenecks; Cloud computing; Cross Traffic; Datacenters; Measurement; Throughput,Application placements; Bottlenecks; Cloud applications; Cloud computing infrastructures; Cross-traffic; Data centers; Network-intensive applications; Placement methods; Measurements; Throughput; Cloud computing
"Turner D., Levchenko K., Savage S., Snoeren A.C.",4,A comparison of syslog and IS-IS for network failure analysis,2013,7,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,41,35,"Accurate reporting and analysis of network failures has historically required instrumentation (e.g., dedicated tracing of routing protocol state) that is rarely available in practice. In previous work, our group has proposed that a combination of common data sources could be substituted instead. In particular, by opportunistically stitching together data from router configuration logs and syslog messages, we demonstrated that a granular picture of network failures could be resolved and verified with human trouble tickets. In this paper, we more fully evaluate the fidelity of this approach, by comparing with high-quality ""ground truth"" data derived from an analysis of contemporaneous IS-IS routing protocol messages. We identify areas of agreement and disparity between these data sources, as well as potential ways to correct disparities when possible. Copyright 2013 ACM.",IS-IS; Measurement; Reliability; Syslog,Ground truth; IS-IS; Network failure; Protocol message; Router configuration; Syslog; Syslog messages; Trouble ticket; Measurements; Reliability; Routing protocols
"Sundaresan S., Feamster N., Teixeira R., Magharei N.",4,Measuring and mitigating web performance bottlenecks in broadband access networks,2013,31,"Georgia Tech., United States; CNRS, UPMC, France; Cisco Systems, United States",Georgia Tech,1,France;USA,2,36,25,"We measure Web performance bottlenecks in home broadband access networks and evaluate ways to mitigate these bottlenecks with caching within home networks. We first measure Web performance bottlenecks to nine popular Web sites from more than 5,000 broadband access networks and demonstrate that when the downstream throughput of the access link exceeds about 16 Mbits/s, latency is the main bottleneck for Web page load time. Next, we use a router-based Web measurement tool, Mirage, to deconstruct Web page load time into its constituent components (DNS lookup, TCP connection setup, object download) and show that simple latency optimizations can yield significant improvements in overall page load times. We then present a case for placing a cache in the home network and deploy three common optimizations: DNS caching, TCP connection caching, and content caching. We show that caching only DNS and TCP connections yields significant improvements in page load time, even when the user's browser is already performing similar independent optimizations. Finally, we use traces from real homes to demonstrate how prefetching DNS and TCP connections for popular sites in a home-router cache can achieve faster page load times. Copyright 2013 ACM.",Bottlenecks; Broadband networks; Connection caching; DNS prefetching; Popularity-based prefetching; Web performance,Bottlenecks; Broad-band access networks; Connection caching; Content caching; Latency optimizations; Prefetching; Web measurements; Web performance; Broadband networks; Carrier communication; Home networks; Optimization; Personal communication systems; Websites
"Krishnan S.S., Sitaraman R.K.",2,Understanding the effectiveness of video ads: A measurement study,2013,19,"Akamai Technologies, United States; University of Massachusetts, Amherst, Akamai Technologies, United States",University of Massachusetts Amherst,1,USA,1,22,16,"Online video is the killer application of the Internet. Videos are expected to constitute more than 85% of the tra# c on the consumer Internet within the next few years. However, a vexing problem for video providers is how to monetize their online videos. A popular monetization model pursued by many major video providers is inserting ads that play in-stream with the video that is being watched. Our work represents the first rigorous scientific study of the key factors that determine the e# ectiveness of video ads as measured by their completion and abandonment rates. We collect and analyze a large set of anonymized traces from Akamai's video delivery network consisting of about 65 million unique viewers watching 362 million videos and 257 million ads from 33 video providers around the world. Using novel quasi-experimental techniques, we show that an ad is 18.1% more likely to complete when placed as a mid-roll than as a pre-roll, and 14.3% more likely to complete when placed as pre-roll than as a post-roll. Next, we show that completion rate of an ad decreases with increasing ad length. A 15-second ad is 2.9% more likely to complete than a 20-second ad, which in turn is 3.9% more likely to complete than a 30-second ad. Further, we show the ad completion rate is influenced by the video in which the ad is placed. An ad placed in long-form videos such as movies and TV episodes is 4.2% more likely to complete than the same ad placed in short-form video such as news clips. Finally, we show that about one-third of the viewers who abandon leave in the first quarter of the ad, while about two-thirds leave at the halfway point in the ad. Our work represents a first step towards scientifically understanding video ads and viewer behavior. Such understanding is crucial for the long-term viability of online videos and the future evolution of the Internet. Copyright is held by the owner/author(s).",Advertisements; Internet content delivery; Monetization; Multimedia; Online videos; User behavior,Advertisements; Internet content; Monetization; Multimedia; Online video; User behaviors; Internet; Behavioral research
"Drago I., Bocchi E., Mellia M., Slatman H., Pras A.",5,Benchmarking personal cloud storage,2013,70,"University of Twente, Netherlands; Politecnico di Torino, Italy",University of Twente,1,Italy;Netherlands,2,61,33,"Personal cloud storage services are data-intensive applications already producing a significant share of Internet traffic. Several solutions offered by different companies attract more and more people. However, little is known about each service capabilities, architecture and - most of all - performance implications of design choices. This paper presents a methodology to study cloud storage services. We apply our methodology to compare 5 popular offers, revealing different system architectures and capabilities. The implications on performance of different designs are assessed executing a series of benchmarks. Our results show no clear winner, with all services suffering from some limitations or having potential for improvement. In some scenarios, the upload of the same file set can take seven times more, wasting twice as much capacity. Our methodology and results are useful thus as both benchmark and guideline for system design. Copyright is held by the owner/author(s).",Comparison; Dropbox; Measurements; Performance,Cloud storage services; Comparison; Data-intensive application; Dropbox; Internet traffic; Performance; Service capability; System architectures; Measurements; Benchmarking
"Detal G., Hesmans B., Bonaventure O., Vanaubel Y., Donnet B.",5,Revealing middlebox interference with tracebox,2013,47,"UniversitŽ catholique de Louvain, Louvain-la-Neuve, Belgium; UniversitŽ de Lige, Lige, Belgium",Universite Catholique de Louvain;UniversitŽ de Lige,2,Belgium,1,21,6,"Middleboxes such as firewalls, NAT, proxies, or Deep Packet Inspection play an increasingly important role in various types of IP networks, including enterprise and cellular networks. Recent studies have shed the light on their impact on real traffic and the complexity of managing them. Network operators and researchers have few tools to understand the impact of those boxes on any path. In this paper, we propose tracebox, an extension to the widely used traceroute tool, that is capable of detecting various types of middle-box interference over almost any path. tracebox sends IP packets containing TCP segments with different TTL values and analyses the packet encapsulated in the returned ICMP messages. Further, as recent routers quote, in the ICMP message, the entire IP packet that they received, tracebox is able to detect any modification performed by upstream middleboxes. In addition, tracebox can often pinpoint the network hop where the middlebox interference occurs. We evaluate tracebox with measurements performed on PlanetLab nodes. Our analysis reveals various types of mid-dleboxes that were not expected on such an experimental testbed supposed to be connected to the Internet without any restriction. Copyright 2013 ACM.",Middleboxes; Network discovery; Tracebox,Cellular network; Deep packet inspection; Experimental testbed; Middleboxes; Network discovery; Network operator; Tracebox; Traceroute tools; Internet protocols; Routers; Tools; Complex networks
"Potharaju R., Jain N.",2,Demystifying the dark side of the middle: A field study of middlebox failures in datacenters,2013,39,"Purdue University, United States; Microsoft Research, United States",Microsoft;Purdue University,2,USA,1,16,10,"Network appliances or middleboxes such as firewalls, intrusion detection and prevention systems (IDPS), load balancers, and VPNs form an integral part of datacenters and enterprise networks. Realizing their importance and shortcomings, the research community has proposed software implementations, policy-aware switching, consolidation appliances, moving middlebox processing to VMs, end hosts, and even offloading it to the cloud. While such efforts can use middlebox failure characteristics to improve their reliability, management, and cost-effectiveness, little has been reported on these failures in the field. In this paper, we make one of the first attempts to perform a large-scale empirical study of middlebox failures over two years in a service provider network comprising thousands of middleboxes across tens of datacenters. We find that mid-dlebox failures are prevalent and they can significantly impact hosted services. Several of our findings differ in key aspects from commonly held views: (1) Most failures are grey dominated by connectivity errors and link flaps that exhibit intermittent connectivity, (2) Hardware faults and overload problems are present but they are not in majority, (3) Mid-dleboxes experience a variety of misconfigurations such as incorrect rules, VLAN misallocation and mismatched keys, and (4) Middlebox failover is ineffective in about 33% of the cases for load balancers and firewalls due to configuration bugs, faulty failovers and software version mismatch. Finally, we analyze current middlebox proposals based on our study and discuss directions for future research. Copyright 2013 ACM.",Datacenters; Middleboxes; Network reliability,Data centers; Failure characteristics; Intermittent connectivity; Intrusion detection and prevention systems; Middleboxes; Network reliability; Service provider networks; Software implementation; Intrusion detection; Program debugging; Computer system firewalls
"Streibelt F., Bšttger J., Chatzis N., Smaragdakis G., Feldmann A.",5,Exploring EDNS-client-subnet adopters in your free time,2013,17,"T-Labs, TU Berlin, Germany",TU Berlin,1,Germany,1,32,16,"The recently proposed DNS extension, EDNS-Client-Subnet (ECS), has been quickly adopted by major Internet companies such as Google to better assign user requests to their servers and improve end-user experience. In this paper, we show that the adoption of ECS also offers unique, but likely unintended, opportunities to uncover details about these companies' operational practices at almost no cost. A key observation is that ECS allows to resolve domain names of ECS adopters on behalf of any arbitrary IP/prefix in the Internet. In fact, by utilizing only a single residential vantage point and relying solely on publicly available information, we are able to (i) uncover the global footprint of ECS adopters with very little effort, (ii) infer the DNS response cacheability and end-user clustering of ECS adopters for an arbitrary network in the Internet, and (iii) capture snapshots of user to server mappings as practiced by major ECS adopters. While pointing out such new measurement opportunities, our work is also intended to make current and future ECS adopters aware of which operational information gets exposed when utilizing this recent DNS extension. Copyright is held by the owner/author(s).",CDN; Content delivery; DNS,Arbitrary networks; CDN; Content delivery; DNS; Domain names; End users; End-user experience; Operational practices; Industry; Internet; Internet protocols
"Balachandran A., Sekar V., Akella A., Seshan S.",4,Analyzing the potential benefits of CDN augmentation strategies for Internet video workloads,2013,48,"Carnegie Mellon University, United States; Stony Brook University, United States; University of Wisconsin, Madison, United States",Carnegie Mellon University;Stony Brook University;University of Wisconsin-Madison,3,USA,1,56,33,"Video viewership over the Internet is rising rapidly, and market predictions suggest that video will comprise over 90% of Internet traffic in the next few years. At the same time, there have been signs that the Content Delivery Network (CDN) infrastructure is being stressed by ever-increasing amounts of video traffic. To meet these growing demands, the CDN infrastructure must be designed, provisioned and managed appropriately. Federated telco-CDNs and hybrid P2P-CDNs are two content delivery infrastructure designs that have gained significant industry attention recently. We observed several user access patterns that have important implications to these two designs in our unique dataset consisting of 30 million video sessions spanning around two months of video view-ership from two large Internet video providers. These include partial interest in content, regional interests, temporal shift in peak load and patterns in evolution of interest. We analyze the impact of our findings on these two designs by performing a large scale measurement study. Surprisingly, we find significant amount of synchronous viewing behavior for Video On Demand (VOD) content, which makes hybrid P2P-CDN approach feasible for VOD and suggest new strategies for CDNs to reduce their infrastructure costs. We also find that federation can significantly reduce telco-CDN provisioning costs by as much as 95%. Copyright 2013 ACM.",Internet video; Measurement; User behavior,Content delivery network; Infrastructure costs; Infrastructure design; Internet video; Large-scale measurement; User access patterns; User behaviors; Video on demands (VoD); Behavioral research; Cost reduction; Design; Measurements; Traffic signs; Video on demand; Internet
"Lentz M., Levin D., Castonguay J., Spring N., Bhattacharjee B.",5,D-mystifying the D-root address change,2013,6,"University of Maryland, United States",University of Maryland College Park,1,USA,1,38,24,"On January 3, 2013, the D-root DNS server hosted at the University of Maryland changed IP address. To avoid service disruption, the old address continues to answer queries. In this paper, we perform an initial investigation of the traffic at both the new and old addresses before, during, and since the flag day. The data we collected show non-obvious behavior: the overall query volume to the D-roots increases by roughly 50%, the old address continues to receive a high volume of queries months after the changeover, and far more queries to the old address succeed than those to the new one. Our analysis provides a window into how compliant resolvers change over and how non-standard and seemingly malicious re-solvers react (or not) to the IP address change. We provide evidence that a relatively small number of implementation errors account for nearly all discrepancies that are not misconfigurations or attacks. Copyright 2013 ACM.",Domain Name Service; Measurement; Root Server,DNS server; Domain name service; High volumes; Implementation error; IP addresss; Misconfigurations; Service disruptions; University of Maryland; Internet protocols; Measurements; Query processing
"Calder M., Fan X., Hu Z., Katz-Bassett E., Heidemann J., Govindan R.",6,Mapping the expansion of Google's serving infrastructure,2013,68,"University of Southern California, United States; USC/ISI, United States",University of Southern California,1,USA,1,38,28,"Modern content-distribution networks both provide bulk content and act as ""serving infrastructure"" for web services in order to reduce user-perceived latency. Serving infrastructures such as Google's are now critical to the online economy, making it imperative to understand their size, geographic distribution, and growth strategies. To this end, we develop techniques that enumerate IP addresses of servers in these infrastructures, find their geographic location, and identify the association between clients and clusters of servers. While general techniques for server enumeration and geolocation can exhibit large error, our techniques exploit the design and mechanisms of serving infrastructure to improve accuracy. We use the EDNS-client-subnet DNS extension to measure which clients a service maps to which of its serving sites. We devise a novel technique that uses this mapping to geolocate servers by combining noisy information about client locations with speed-of-light constraints. We demonstrate that this technique substantially improves geolocation accuracy relative to existing approaches. We also cluster server IP addresses into physical sites by measuring RTTs and adapting the cluster thresholds dynamically. Google's serving infrastructure has grown dramatically in the ten months, and we use our methods to chart its growth and understand its content serving strategy. We find that the number of Google serving sites has increased more than sevenfold, and most of the growth has occurred by placing servers in large and small ISPs across the world, not by expanding Google's backbone. Copyright 2013 ACM.",CDN; DNS; Geolocation; Measurement,CDN; Cluster server; DNS; Geographic location; Geolocations; Growth strategy; Novel techniques; Service maps; Internet service providers; Measurements; Tracking (position); Web services; Physical addresses
"Papadogiannakis A., Polychronakis M., Markatos E.P.",3,Scap: Stream-oriented network traffic capture and analysis for high-speed networks,2013,9,"FORTH-ICS, Greece; Columbia University, United States",Columbia University,1,Greece;USA,2,14,6,"Many network monitoring applications must analyze traffic beyond the network layer to allow for connection-oriented analysis, and achieve resilience to evasion attempts based on TCP segmentation. However, existing network traffic capture frameworks provide applications with just raw packets, and leave complex operations like flow tracking and TCP stream reassembly to application developers. This gap leads to increased application complexity, longer development time, and most importantly, reduced performance due to excessive data copies between the packet capture subsystem and the stream processing module. This paper presents the Stream capture library (Scap), a network monitoring framework built from the ground up for stream-oriented traffic processing. Based on a kernel module that directly handles flow tracking and TCP stream reassembly, Scap delivers to userlevel applications flow-level statistics and reassembled streams by minimizing data movement operations and discarding uninteresting traffic at early stages, while it inherently supports parallel processing on multi-core architectures, and uses advanced capabilities of modern network cards. Our experimental evaluation shows that Scap can capture all streams for traffic rates two times higher than other stream reassembly libraries, and can process more than five times higher traffic loads when eight cores are used for parallel stream processing in a pattern matching application. Copyright 2013 ACM.",Overload control; Packet capturing; Packet filtering; Performance; Stream reassembly; Traffic monitoring,Overload control; Packet capturing; Packet filtering; Performance; Stream reassembly; Traffic monitoring; Complex networks; Computer architecture; Microprocessor chips; Network layers; Packet networks; Pattern matching; Safety factor; Network architecture
"Durumeric Z., Kasten J., Bailey M., Halderman J.A.",4,Analysis of the HTTPS certificate ecosystem,2013,94,"Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI 48109, United States",University of Michigan at Ann Arbor,1,USA,1,40,31,"We report the results of a large-scale measurement study of the HTTPS certificate ecosystem - the public-key infrastructure that underlies nearly all secure web communications. Using data collected by performing 110 Internet-wide scans over 14 months, we gain detailed and temporally fine-grained visibility into this otherwise opaque area of security-critical infrastructure. We investigate the trust relationships among root authorities, intermediate authorities, and the leaf certificates used by web servers, ultimately identifying and classifying more than 1,800 entities that are able to issue certificates vouching for the identity of any website. We uncover practices that may put the security of the ecosystem at risk, and we identify frequent configuration problems that lead to user-facing errors and potential vulnerabilities. We conclude with lessons and recommendations to ensure the long-term health and security of the certificate ecosystem. Copyright 2013 ACM.",Certificates; HTTPS; Internet-wide scanning; Measurement; Public-key infrastructure; Security; SSL; TLS; X.509,Certificates; HTTPS; Public key infrastructure; Security; SSL; TLS; X.509; Ecosystems; Internet; Measurements; Surveying instruments; HTTP
"Wang Y., Rozhnova N., Narayanan A., Oran D., Rhee I.",5,An improved hop-by-hop interest shaper for congestion control in named data networking,2013,35,"North Carolina State University, United States; UniversitŽ Pierre et Marie Curie (UPMC), France; Cisco Systems, United States",North Carolina State University;University Pierre and Marie Curie,2,France;USA,2,53,30,"Hop-by-hop interest shaping has been proposed as a viable congestion control mechanism in Named Data Networking (NDN). Interest shaping exploits the strict receiver-driven traffic pattern and the symmetric bidirectional forwarding in NDN to control the returning data rate. In this paper, we point out that both interests and contents contribute to congestion and their interdependence must be considered in any interest shaping algorithm. We first analyze this issue mathematically by formulating it as an optimization problem to obtain the optimal shaping rate. Then a practical interest shaping algorithm is proposed to achieve high link utilization without congestive data loss. We further note that flow differentiation in NDN is complicated and design our scheme independently of traffic flows. We demonstrate our hop-by-hop interest shaper in conjunction with simple Additive-Increase-Multiplicative-Decrease (AIMD) clients using the ns3-based NDN simulator (ndnSIM). Our results show that the proposed shaping algorithm can effectively control congestion and achieve near-optimal throughput. Copyright © 2013 ACM.",Congestion control; Information-centric networking,Congestion control mechanism; Information-centric networkings; Link utilization; Named data networkings; Near-optimal; Optimization problems; Shaping algorithm; Traffic pattern; Congestion control (communication); Optimization; Algorithms
"Reichl P., MaillŽ P., Zwickl P., Sackl A.",4,A fixed-point model for QoE-based charging,2013,11,"University of Vienna, Dept. of Computer Science, WŠhringer Strasse 29, A-1090 Vienna, Austria; UniversitŽ europŽenne de Bretagne/TŽlŽcom Bretagne, 2, rue de la Ch‰taigneraie, F-35576 Cesson-SŽvignŽ, France; FTW Telecommunications Research Center Vienna, Donaucitystrasse 1, A-1220 Vienna, Austria","FTW,Austria;University of Vienna;UniversitŽ europŽenne de Bretagne/Telecom Bretagne",3,Austria;France,2,35,29,"Within the current paradigm change from Quality-of-Service (QoS) towards Quality-of-Experience (QoE), the question of how to charge for QoE is widely neglected in the research community despite of its obvious importance. In this paper, we present and analyze a fixed point model which specifically reflects the double role of prices, i.e. as regulating factor for demand size and at the same time as part of the QoE-based user context. The model is validated through comprehensive user trial results which allow interesting insights into the temporal behavior of end users who are confronted with a fine-grained scale of choices on video quality and corresponding tariffs. Copyright © 2013 ACM.",Internet Charging and Pricing; Network Economics; Quality of Experience; Quality of Service,Fixed points; Network economics; Quality of experience (QoE); Quality of experiences; Research communities; Temporal behavior; User context; Video quality; Economics; Quality of service
"Thomas Y., Tsilopoulos C., Xylomenos G., Polyzos G.C.",4,Multisource and multipath file transfers through publish-subscribe internetworking,2013,7,"Mobile Multimedia Laboratory, Dept. of Informatics, Athens University of Economics and Business, Greece; Dept. of Computer Science and Engineering, University of California, San Diego, United States",Athens University of Economics and Business;University of California San Diego,2,Greece;USA,2,11,10,"We present mmFTP, an information-centric and receiver-driven file transfer protocol for the Publish Subscribe Internetworking (PSI) architecture. mmFTP supports both multisource and multipath transfers, while requiring minimal complexity in terms of network operation. We describe the basic design and operation of mmFTP and present preliminary experimental performance results from a prototype implementation deployed in the PlanetLab testbed. Copyright © 2013 ACM.",Information-centric networking; Multipath; Multisource; Transport,Design and operations; File transfer protocols; Information-centric networkings; Multipath; Multipath transfers; Multisources; Prototype implementations; Transport; Complex networks; Network architecture
"Wu Y., Wu C., Li B., Lau F.C.M.",4,vSkyConf: Cloud-assisted multi-party mobile video conferencing,2013,12,"Dept. of Computer Science, University of Hong Kong, Hong Kong; Dept. of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",Hong Kong University of Science and Technology;University of Hong Kong,2,Hong Kong,1,17,14,"As an important application in today's busy world, mobile video conferencing facilitates people's virtual face-to-face communication with friends, families and colleagues, via their mobile devices on the move. However, how to provision high-quality, multi-party video conferencing experiences over mobile devices is still an open challenge. The fundamental reason behind is the lack of computation and communication capacities on the mobile devices, to scale to large conferencing sessions. In this paper, we present vSkyConf, a cloud-assisted mobile video conferencing system to fundamentally improve the quality and scale of multi-party mobile video conferencing. By novelly employing a surrogate virtual machine in the cloud for each mobile user, we allow fully scalable communication among the conference participants via their surrogates, rather than directly. The surrogates exchange conferencing streams among each other, transcode the streams to the most appropriate bit rates, and buffer the streams for the most efficient delivery to the mobile recipients. A fully decentralized algorithm is designed to decide the best paths of streams and the most suitable surrogates for video transcoding along the paths, such that the limited bandwidth is fully utilized to deliver streams of the highest possible quality to the mobile recipients. We also carefully tailor a buffering mechanism on each surrogate to cooperate with efficient stream distribution. We have implemented vSkyConf based on Amazon EC2 and verified the excellent performance of our design, as compared to the widely adopted unicast solutions. © 2013 ACM.",Cloud computing; Mobile computing; Video conferencing,Buffering mechanisms; Communication capacity; Decentralized algorithms; Face-to-face communications; Limited bandwidth; Mobile video conferencing; Multi-party video conferencing; Video-transcoding; Cloud computing; Communication; Image coding; Mobile cloud computing; Mobile computing; Mobile devices; Mobile telecommunication systems; Video conferencing
"Kravets R., Alkaff H., Campbell A., Karahalios K., Nahrstedt K.",5,CrowdWatch: Enabling in-network crowd-sourcing,2013,6,"University of Illinois, Dartmouth College, United States",Dartmouth College;UIUC,2,USA,1,8,6,"Proliferation of mobile smartphones has opened up possibilities of using crowd-sourcing to gather data from and so monitor large crowds. However, depending on the size of the crowd, current solutions either put unpredictable stress on the infrastructure and energy-constrained smartphones or do not capture the crowd behavior accurately. In response, we present CrowdWatch, a scalable, distributed and energy-efficient crowd-sourcing framework. CrowdWatch achieves its goal through off-loading some of the processing to the devices and establishing a hierarchy of participants by exploiting devices with multiple radios (i.e. WiFi (high-power) and BlueTooth (low-power)). CrowdWatch can outperform traditional crowd-sourcing frameworks by reducing the stress on the infrastructures to 10% of that of a traditional crowd-sourcing solution, while only requiring each phone to use their Wi-Fi radios 15% of the time in a dense environment. © 2013 ACM.",Crowdsourcing; Energy-management; Smartphones,Crowd behavior; Crowdsourcing; Energy efficient; Energy-constrained; In networks; Low Power; Multiple radios; Off-loading; Loading; Mobile cloud computing; Smartphones; Behavioral research
"Sadasivarao A., Syed S., Pan P., Liou C., Lake A., Guok C., Monga I.",7,Open transport switch - A software defined networking architecture for transport networks,2013,23,"Infinera Corporation, Sunnyvale, CA 94089, United States; Energy Sciences Network, Berkeley, CA 94720, United States",Energy Sciences Network;Infinera Corporation,2,USA,1,11,8,"There have been a lot of proposals to unify the control and management of packet and circuit networks but none have been deployed widely. In this paper, we propose a simple programmable architecture that abstracts a core transport node into a programmable virtual switch, that meshes well with the software-defined network paradigm while leveraging the OpenFlow protocol for control. A demonstration use-case of an OpenFlow-enabled optical virtual switch implementation managing a small optical transport network for big-data applications is described. With appropriate extensions to OpenFlow, we discuss how the programmability and flexibility SDN brings to packet-optical backbone networks will be substantial in solving some of the complex multi-vendor, multi-layer, multi-domain issues service providers face today. © 2013 ACM.",Optical networks; Otn; SDN; Transport networks; Virtualization,Optical transport networks; Otn; Programmable architectures; SDN; Software-defined networkings; Software-defined networks; Transport networks; Virtualizations; Complex networks; Fiber optic networks; Signal systems; Network architecture
"Dutta A., Saha D., Grunwald D., Sicker D.",4,CODIPHY - Composing on-demand intelligent physical layers,2013,6,"Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, CO 80309-0430, United States; Department of Computer Science, University of Colorado, Boulder, CO 80309-0430, United States",University of Colorado Boulder,1,USA,1,19,16,In this paper we present CODIPHY or Composing On-Demand Intelligent Physical Layers that aims to solve two fundamental problems in practical cognitive radio networks: Collaboration between two radio physical layers (PHY) with varying capabilities to agree on a common communication protocol and provide a method to compose a functioning software defined radio (SDR) from a set of pre-compiled libraries. Both solutions use an ontology based description of the internal structure of the radio subsystems and use the high-level dataflow represented by the ontology to target heterogeneous platforms. CODIPHY isolates the various domains of radio engineering but still allows them to share domain knowledge to achieve a common goal of radio adaptation. Automating this process through declarative specification and collaborative learning is the goal of this paper. We present a generic methodology to facilitate the concept of CODIPHY and present examples from the radio PHY domain. © 2013 ACM.,Architecture; Cognitive radio; Design automation; Physical layer; Software defined radio,Cognitive radio network; Collaborative learning; Design automations; Heterogeneous platforms; Internal structure; Physical layers; Radio engineering; Software-defined radios; Architecture; Cognitive radio; Computer aided design; Network layers; Radio; Radio broadcasting; Software radio
"Kozat U.C., Liang G., Kškten K.",3,Verifying forwarding plane connectivity and locating link failures using static rules in software defined networks,2013,4,"DOCOMO Innovations, Inc., Palo Alto, CA 94304, United States",DoCoMo USA Labs,1,USA,1,12,10,"We present efficient solutions that install static rules on the forwarding elements such that network controllers use these rules to verify topology connectivity and locate link failures. For a forwarding plane with |E| links, we verify topology connectivity using ² 2|E| static rules and one control message. We guarantee locating at least one link failure using ² 6|E| static rules and _(log(|E|)) control messages. We can also detect multiple link failures in a probabilistic sense. © 2013 ACM.",Failure detection; OpenFlow; SDN; Verification,Control messages; Failure detection; Forwarding planes; Link failures; Multiple link failures; Openflow; SDN; Software-defined networks; Verification; Topology
"Lu L., You L., Yang Q., Wang T., Zhang M., Zhang S., Liew S.C.",7,Real-time implementation of physical-layer network coding,2013,30,"Institute of Network Coding CUHK, Hong Kong, Hong Kong; Dept. of Inform. Engineering CUHK, Hong Kong, Hong Kong; Dept. of Comm. Engineering, Shenzhen University, China",Chinese University of Hong Kong;Shenzhen University,2,China;Hong Kong,2,22,18,"This paper presents the first real-time physical-layer network coding (PNC) prototype for the two-way relay wireless channel (TWRC). Theoretically, PNC could boost the throughput of TWRC by a factor of 2 compared with traditional scheduling (TS) in the high signal-to-noise (SNR) regime. Although there have been many theoretical studies on PNC performance, there have been few experimental and implementation efforts. We built the first prototype of PNC about a year ago. It was, however, an offline system in which an offline PNC decoder was used at the relay. For a real-time PNC system, there are many additional challenges, including the needs for tighter coordination of the transmissions by the two end nodes, fast real-time PNC decoding at the relay, and a PNC-compatible retransmission scheme (i.e., an ARQ protocol) to ensure reliability of packet delivery. In this paper, we describe a real-time PNC prototype, referred to as RPNC, that provides practical solutions to these challenges. Indoor environment experimental results show that RPNC boosts the throughput of TWRC by a factor of 2 compared with TS, as predicted theoretically. RPNC prototype provides an interface to the application layer, with which we demonstrate the exchange of two image data files between the two end nodes. © 2013 ACM.",Network coding; Physical-layer network coding; Realtime; Soft demodulation,Application layers; Indoor environment; Physical-layer network coding; Practical solutions; Real time; Real-time implementations; Retransmission scheme; Soft demodulation; Real time control; Signal to noise ratio; Software radio; Network coding
"Cabral C.M.S., Rothenberg C.E., Magalh‹es M.F.",3,Reproducing real NDN experiments using Mini-CCNx,2013,5,"Faculty of Electrical and Computer Engineering (FEEC), University of Campinas (UNICAMP), S‹o Paulo, Brazil",University of Campinas,1,Brazil,1,6,5,"This demo presents Mini-CCNx as a new experimentation tool for the NDN (Named Data Networking) model. Rooted in recent container-based emulation and resource isolation techniques developed to foster research in SDN/OpenFlow, Mini-CCNx features a number of contributions to support and facilitate NDN experiments using the project's official code base at scale. In addition to integrating all the available pieces of code, the platform offers experimenter-friendly configuration interfaces tailored to NDN and allows to run arbitrary topologies with hundreds of nodes without sacrificing high-fidelity results. We demonstrate how Mini-CCNx is capable of reproducing experiments on the NDN testbed using dynamic routing protocols (OSPFN) and multicast content delivery (NDNVideo). We import the whole NDN testbed topology including annotated links and show how the obtained results match published results. The experience suggests that Mini-CCNx can be a helpful experimental platform prior to going to a real deployment, altogether reducing time and costs, and yielding early insights on the end application behavior, routing configuration needs, caching characteristics, protocol performance, and so on. Copyright © 2013 ACM.",CCN; Emulation; ICN; NDN; Prototyping; Routing,CCN; Emulation; ICN; NDN; Routing; Software prototyping; Testbeds; Topology; Experiments
"Ayadurai V., Prytz M.",2,Software radio platform for Network-Assisted Device-to-Device (NA-D2D) concepts,2013,2,"Ericsson Research, FŠršgatan 6, 164 80 Stockholm, Sweden",Ericsson Research,1,Sweden,1,16,12,"This paper describes a small-scale software radio platform that has been developed and implemented to investigate the new mobile network concept of Network-Assisted Device-to-Device (NA-D2D) communications. The implementation includes mechanisms for mode selection, direct-link quality estimation, and resource allocation. We show that significant benefits were reaped from this real-world implementation despite the relatively simplistic scenario emulated by our indoor laboratory setup. Apart from the obvious advantages of testing the concept over a real wireless medium with its associated physical characteristics, other unforeseen factors were also uncovered. Asymmetries in radio channels, variations in supposedly identical node hardware, and timing issues, were just some of the experiences encountered and fed back into the research design process which resulted in significant refinements and improvements made to the mechanisms and algorithms of the NA-D2D communications concept studied. © 2013 ACM.",Device-to-device; FPGA; Mobile networks; Software radio; WARP,Device-to-device; Laboratory set-up; Physical characteristics; Quality estimation; Real-world implementation; Research designs; Software radio platform; WARP; Field programmable gate arrays (FPGA); Wireless networks; Software radio
"Balan H.V., Segura M., Deora S., Michaloliakos A., Rogalin R., Psounis K., Caire G.",7,"USC SDR, an easy-to-program, high data rate, real time software radio platform",2013,9,"University of Southern California, United States",University of Southern California,1,USA,1,9,1,"We present USC SDR, a wireless platform designed for easy-to-program, high data rate, real time wireless experimentation. The design of our platform aims at removing most of the bottlenecks encountered in the design of current software radio architectures, e.g. the requirement to program new schemes in an FPGA, and the difficulty to run real-time experiments for a long time. The architecture combines generic PCI FPGA development boards with radio front-ends built as self-sufficient daughterboards. The daughterboards are connected to the FPGAs, which in turn are plugged into the PCIE slots of a general-purpose server. Interestingly, the connection of the daughterboards to the FPGA cards is implemented through a standard FMC (FPGA Mezzanine Card) interface, such that the same RF front-end can be reused with future FPGA generations. In this way, USC SDR is not limited to a specific FPGA choice and does not require a complete re-design in order to accommodate for future more powerful FPGAs. The hardware is supported by a real-time software architecture where signal processing tasks, PHY and MAC layer algorithms can be programmed as user-level applications. As an example, we will showcase a massive MIMO testbed built using a single server with multiple PCIE slots. © 2013 ACM.",Software radio; Wireless,High data rate; Mezzanine card; MIMO testbeds; Real-time experiment; Real-time software; Software radio architecture; Wireless experimentation; Wireless platform; Radio; Signal processing; Software radio; Field programmable gate arrays (FPGA)
"Schmid S., Suomela J.",2,Exploiting locality in distributed SDN control,2013,97,"TU Berlin, T-Labs, Germany; Helsinki Institute for Information Technology HIIT, Department of Computer Science, University of Helsinki, Finland",Helsinki Institute for Information Technology;TU Berlin;University of Helsinki,3,Finland;Germany,2,5,5,"Large SDN networks will be partitioned in multiple controller domains; each controller is responsible for one domain, and the controllers of adjacent domains may need to communicate to enforce global policies. This paper studies the implications of the local network view of the controllers. In particular, we establish a connection to the field of local algorithms and distributed computing, and discuss lessons for the design of a distributed control plane. We show that existing local algorithms can be used to develop efficient coordination protocols in which each controller only needs to respond to events that take place in its local neighborhood. However, while existing algorithms can be used, SDN networks also suggest a new approach to the study of locality in distributed computing. We introduce the so-called supported locality model of distributed computing. The new model is more expressive than the classical models that are commonly used in the design and analysis of distributed algorithms, and it is a better match with the features of SDN networks. © 2013 ACM.",Local algorithms; Software defined networking,Classical model; Coordination protocols; Design and analysis; Distributed control planes; Local algorithm; Local neighborhoods; Multiple controllers; Software-defined networkings; Algorithms
McGeer R.,1,"A correct, zero-overhead protocol for network updates",2013,10,"HP Enterprise Services, Palo Alto, CA, United States",HP Labs,1,USA,1,23,12,"In this paper, we describe a new protocol for the safe update of OpenFlow networks. This protocol meets the packet consistency and weak flow consistency conditions, requires neither on-switch resources nor the diversion of packets to refuges during updates, and alls into the family of Trace-based update protocols. The feature of this protocol is a sequence of per-switch rule updates. We derive a logic circuit for the update sequence, such that there exists a consistency-preserving update for the switch network if and only if the circuit is satisfiable subject to unsatisfiability of invariant violations; further, each satisfying minterm of the circuit yields a consistency-preserving update sequence. © 2013 ACM.",Complexity; Network update; Network verification,Circuit yield; Complexity; Consistency conditions; Minterm; New protocol; Openflow networks; Switch network; Update protocol; Complex networks; Switching circuits
"Wu Q., Li Z., Xie G.",3,CodingCache: Multipath-aware CCN cache with network coding,2013,27,"Institute of Computing Technology, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",Chinese Academy of Sciences,1,China,1,19,15,"Content Centric Networking (CCN) performance by definition depends on the in-network caching efficiency. We propose CodingCache which utilizes network coding and random forwarding to improve caching efficiency under mul-tipath forwarding. Its advantage is that existing caching strategies can be easily incorporated with it for better performance. We evaluate CodingCache by extensive simulation experiments with the China Telecom network topology and a unique dataset consisting of video access logs from the PPTV system. The results demonstrate that compared with the CCN caching strategy, CodingCache improves the cache hit rate by about 60%. Copyright © 2013 ACM.",Caching; CCN; Multipath forwarding; Network coding,Better performance; Caching; Caching strategy; CCN; Content-centric networkings; Extensive simulations; Multi-path forwarding; Random forwarding; Data processing; Electric network topology; Network coding
"Dixit A., Hao F., Mukherjee S., Lakshman T.V., Kompella R.",5,Towards an elastic distributed SDN controller,2013,155,"Purdue University, United States; Bell Labs Alcatel-Lucent, United States",Bell Labs;Purdue University,2,USA,1,9,8,"Distributed controllers have been proposed for Software Defined Networking to address the issues of scalability and reliability that a centralized controller suffers from. One key limitation of the distributed controllers is that the mapping between a switch and a controller is statically configured, which may result in uneven load distribution among the controllers. To address this problem, we propose ElastiCon, an elastic distributed controller architecture in which the controller pool is dynamically grown or shrunk according to traffic conditions and the load is dynamically shifted across controllers. We propose a novel switch migration protocol for enabling such load shifting, which conforms with the Openflow standard. We also build a prototype to demonstrate the efficacy of our design. © 2013 ACM.",Data center networks; Software-defined networks,Centralized controllers; Data center networks; Distributed controller; Load distributions; Migration protocols; Software-defined networkings; Software-defined networks; Traffic conditions
"Detti A., Ricci B., Blefari-Melazzi N.",3,Supporting mobile applications with information centric networking: The case of P2P live adaptive video streaming,2013,10,"CNIT-Electronic Engineering Dept., University of Rome Tor Vergata, Italy",University of Rome Tor Vergata,1,Italy,1,6,5,"This paper briefly presents a P2P application for the live streaming of video contents encoded at multiple bit-rates, enabling neighboring cellular devices to increase the quality of video playback, by cooperatively using their cellular (e.g. HSDPA) and proximity (e.g. Wi-Fi Direct) wireless connections. The application is designed to exploit key functionalities of an Information Centric Network: routing-by-name, in-network caching and multicasting. We implemented a prototype of the application and assessed its performance in a test-bed based on Linux, the CCNx tool and real cellular connections. Copyright © 2013 ACM.",Cellular network; Information Centric Networking; Live adaptive video streaming; MPEG DASH,Adaptive video streaming; Cellular network; Information Centric Networks; Information-centric networkings; Mobile applications; Mpeg dashes; Quality of videos; Wireless connection; Computer operating systems; Motion Picture Experts Group standards; Multicasting; Video streaming; Wi-Fi; Peer to peer networks
"Parisis G., Trossen D.",2,Digital fountains in information-centric networking,2013,2,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,17,14,"In this paper, we revisit digital fountains as an information theoretic approach for disseminating information. We embed this approach, however, into the architectural context of information centric networking (ICN). We discuss how our information-centric network architecture enables efficient information dissemination through fountain coding and we present the basic network operations for disseminating information from publishers to subscribers. Copyright © 2013 ACM.",Digital fountains; Information-centric networking; Multi-path and multi-source information dissemination,Digital fountain; Information-centric; Information-centric networkings; Information-centric networkings (ICN); Information-theoretic approach; Network operations; Information dissemination; Network architecture; Fountains
"Carzaniga A., Khazaei K., Papalini M., Wolf A.L.",4,Is information-centric multi-tree routing feasible?,2013,5,"University of Lugano, Lugano, Switzerland; Imperial College London, London, United Kingdom",Imperial College London;University of Lugano,2,Switzerland;UK,2,8,3,"We have argued that an information-centric network should natively support publish/subscribe event notification in addition to on-demand content delivery. We have also argued that both primitives could use the same forwarding information base and, furthermore, that both primitives can easily support addresses that are more expressive than simple hierarchical names. In this paper we present a concrete routing scheme that realizes this: ""push"" as well as ""pull"" communication; anycast as well as multicast; and descriptor-based (as opposed to name-based) addressing. The scheme is founded on multiple tree covers that can be arranged and composed hierarchically following the structure of network domains. On each tree, the scheme combines addresses so as to reduce forwarding state. We demonstrate the feasibility and scalability of the scheme through simulations on Internet-scale workloads in realistic network settings. Copyright © 2013 ACM.",Content-based; Content-centric; Information-centric networking; Named-data; Publish/subscribe; Routing,Content-based; Content-centric; Information-centric networkings; Named-data; Publish/subscribe; Routing; Computer simulation; Forestry; Data; Forestry; Simulation
"Misra S., Tourani R., Majd N.E.",3,"Secure content delivery in information-centric networks: Design, implementation, and analyses",2013,51,"Computer Science, New Mexico State University, Las Cruces, NM, United States",New Mexico State University,1,Mexico;USA,2,10,8,"In this paper, we propose a novel secure content delivery framework, for an information-centric network, which will enable content providers (e.g., Netflix and Youtube) to securely disseminate their content to legitimate users via content distribution networks (CDNs) and Internet service providers (ISPs). Use of our framework will enable legitimate users to receive/consume encrypted content cached at a nearby router (CDN or ISP), even when the providers are offline. Our framework would slash system-downtime due to server outages, such as that recently experienced by Netflix, Pinterest, and Instagram users in the US (October 22, 2012). It will also help the providers utilize in-network caches for shaping content transmission and reducing delivery latency. We discuss the handling of security, access control, and system dynamics challenges and demonstrate the practicality of our framework by implementing it on a CCNx testbed. Copyright © 2013 ACM.",Access control; CCN/NDN; Content delivery; ICN; Security,CCN/NDN; Content delivery; Content distribution networks; Content transmission; ICN; Information-centric; Secure content deliveries; Security; Access control; Internet service providers
"Moshref M., Yu M., Govindan R.",3,Resource/accuracy tradeoffs in software-defined measurement,2013,49,"University of Southern California, United States",University of Southern California,1,USA,1,11,7,"Previous work on network measurements have explored several primitives of increasing complexity for measurement tasks at individual nodes, ranging from counters to hashing to arbitrary code fragments. In an SDN network, these primitives may require significant bandwidth, memory and processing resources, and the resources dedicated to these can affect the accuracy of the eventual measurement. In this paper, we first qualitatively discuss the tradeoff space of resource usage versus accuracy for these different primitives as a function of the spatial and temporal measurement granularity, then quantify these tradeoffs in the context of hierarchical heavy hitter detection. © 2013 ACM.",Data center; Hierarchical heavy hitter; Software defined measurement; Software defined networking,Code fragments; Data centers; Hierarchical heavy hitters; Network measurement; Processing resources; Resource usage; Software-defined networkings; Temporal measurements; Complex networks
"Huang D.Y., Yocum K., Snoeren A.C.",3,High-fidelity switch models for software-defined network emulation,2013,70,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,24,15,"Software defined networks (SDNs) depart from traditional network architectures by explicitly allowing third-party software access to the network's control plane. Thus, SDN protocols such as Open-Flow give network operators the ability to innovate by authoring or buying network controller software independent of the hardware. However, this split design can make planning and designing large SDNs even more challenging than traditional networks. While existing network emulators allow operators to ascertain the behavior of traditional networks when subjected to a given workload, we find that current approaches fail to account for significant vendor-specific artifacts in the SDN switch control path. We benchmark OpenFlow-enabled switches from three vendors and illustrate how differences in their implementation dramatically impact latency and throughput. We present a measurement methodology and emulator extension to reproduce these control-path performance artifacts, restoring the fidelity of emulation. © 2013 ACM.",Modeling; OpenFlow; SDN; Software-defined networking,Measurement methodology; Network emulators; Network operator; Openflow; Planning and designings; SDN; Software-defined networkings; Software-defined networks; Models; Network architecture
"Pere_’nit P., Ku_niart M., Vasict N., Canini M., Kostic D.",5,OF.CPP: Consistent packet processing for OpenFlow,2013,18,"EPFL, Switzerland; TU Berlin, T-Labs, Germany; Institute IMDEA Networks, Spain",IMDEA Networks;TU Berlin,2,Germany;Spain;Switzerland,3,23,20,"This paper demonstrates a new class of bugs that is likely to occur in enterprise OpenFlow deployments. In particular, step-by-step, reactive establishment of paths can cause network-wide inconsistencies or performance- and space-related inefficiencies. The cause for this behavior is inconsistent packet processing: as the packets travel through the network they do not encounter consistent state at the Open-Flow controller. To mitigate this problem, we propose to use transactional semantics at the controller to achieve consistent packet processing. We detail the challenges in achieving this goal (including the inability to directly apply database techniques), as well as a potentially promising approach. In particular, we envision the use of multi-commit transactions that could provide the necessary serialization and isolation properties without excessively reducing network performance. © 2013 ACM.",ACID; Consistency; Multi-commit transactions; Software-defined networking,Consistency; Consistent state; Database technique; Multi-commit transactions; Openflow; Packet processing; Software-defined networkings; Acids; Semantics; Packet networks
"Xing B., Zhang K., Zhang L., Lua E.K., Sun S.",5,Human-centric music medical therapy exploration system,2013,0,"Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Australia",Monash University;Zhejiang University,2,Australia;China,2,15,12,"Music emotion analytic is useful for many human-centric applications such as medical intervention. Existing studies have shown that music is a low risk, adjunctive and therapeutic medical intervention. However, there is little existing research about the types of music with identified emotions that have the most effect for different medical applications. We would like to discover various music emotions through machine learning analytic so as to identify models of how music conveys emotion features, and determine its effectiveness for medical intervention and treatment. We are developing a Human-centric Music Medical Therapy Exploration System which could recognize music emotion features from Chinese Folk Music Library, and recommend suitable music to playback for medical intervention and treatment. Our networked system is based on Support Vector Machine (SVM) algorithm to construct the models for music emotion recognition and information retrieval. Our main contributions are as follows: Firstly, we built up the Chinese folk music emotions and features library; secondly, we conducted evaluation and comparison with other algorithms such as Back Propagation (BP) and Linear Regression to set up the model construction for music emotion recognition and proved that SVM has the best performance; lastly, we integrated blood pressure and heartbeat data analytic into our system to visualize the emotion fluctuation in different music affection and make recommendation for suitable human-centric music medical therapy for hypertensive patients. Copyright © 2013 ACM.",Music emotion recognition; Music information retrieval; Music Therapy,Exploration systems; Hypertensive patients; Medical intervention; Model construction; Music emotions; Music information retrieval; Music therapy; Support vector machine algorithm; Algorithms; Blood pressure; Information retrieval; Medical applications; Support vector machines
"Li J., Bu K., Liu X., Xiao B.",4,ENDA: Embracing network inconsistency for dynamic application offloading in Mobile Cloud Computing,2013,27,"Department of Computing, Hong Kong Polytechnic University, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,15,10,"Mobile Cloud Computing (MCC) enables smartphones to offload compute-intensive codes and data to clouds or cloudlets for energy conservation. Thus, MCC liberates smartphones from battery shortage and embraces more versatile mobile applications. Most pioneering MCC research work requires a consistent network performance for offloading. However, such consistency is challenged by frequent mobile user movements and unstable network quality, thereby resulting in a suboptimal offloading decision. To embrace network inconsistency, we propose ENDA, a three-tier architecture that leverages user track prediction, realtime network performance and server loads to optimize offloading decisions. On cloud tier, we first design a greedy searching algorithm to predict user track using historical user traces stored in database servers. We then design a cloud-enabled Wi-Fi access point (AP) selection scheme to find the most energy efficient AP for smartphone offloading. We evaluate the performance of ENDA through simulations under a real-world scenario. The results demonstrate that ENDA can generate offloading decisions with optimized energy efficiency, desirable response time, and potential adaptability to a variety of scenarios. ENDA outperforms existing offloading techniques that do not consider user mobility and server workload balance management. © 2013 ACM.",Cloudlet; Mobile Cloud Computing; Offloading; Smartphones; User track prediction,Cloudlet; Dynamic applications; Mobile applications; Offloading; Real-world scenario; Searching algorithms; Three-tier architecture; Wi-fi access points; Energy efficiency; Forecasting; Network performance; Optimization; Smartphones; Mobile cloud computing
"Georgopoulos P., Elkhatib Y., Broadbent M., Mu M., Race N.",5,Towards network-wide QoE fairness using openflow-assisted adaptive video streaming,2013,129,"School of Computing and Communications, Infolab 21, Lancaster University, Lancaster, LA1 4WA, United Kingdom",Lancaster University,1,UK,1,15,10,"Video streaming is an increasingly popular way to consume media content. Adaptive video streaming is an emerging delivery technology which aims to increase user QoE and maximise connection utilisation. Many implementations naively estimate bandwidth from a one-sided client perspective, without taking into account other devices in the network. This behaviour results in unfairness and could potentially lower QoE for all clients. We propose an OpenFlow-assisted QoE Fairness Framework that aims to fairly maximise the QoE of multiple competing clients in a shared network environment. By leveraging a Software Defined Networking technology, such as OpenFlow, we provide a control plane that orchestrates this functionality. The evaluation of our approach in a home networking scenario introduces user-level fairness and network stability, and illustrates the optimisation of QoE across multiple devices in a network. Copyright © 2013 ACM.",Fairness; MPEG-DASH; OpenFlow; Quality of Experience (QoE); Software Defined Networking; Video Adaptation,Fairness; Mpeg dashes; Openflow; Quality of experience (QoE); Software-defined networkings; Video adaptation; Motion Picture Experts Group standards; Video streaming; Quality of service
"Katta N.P., Rexford J., Walker D.",3,Incremental consistent updates,2013,104,"Princeton University, United States",Princeton University,1,USA,1,9,8,"A consistent update installs a new packet-forwarding policy across the switches of a software-defined network in place of an old policy. While doing so, such an update guarantees that every packet entering the network either obeys the old policy or the new one, but not some combination of the two. In this paper, we introduce new algorithms that trade the time required to perform a consistent update against the rule-space overhead required to implement it. We break an update in to k rounds that each transfer part of the traffic to the new configuration. The more rounds used, the slower the update, but the smaller the rule-space overhead. To ensure consistency, our algorithm analyzes the dependencies between rules in the old and new policies to determine which rules to add and remove on each round. In addition, we show how to optimize rule space used by representing the minimization problem as a mixed integer linear program. Moreover, to ensure the largest flows are moved first, while using rule space efficiently, we extend the mixed integer linear program with additional constraints. Our initial experiments show that a 6-round, optimized incremental update decreases rule space overhead from 100% to less than 10%. Moreover, if we cap the maximum rule-space overhead at 5% and assume the traffic flow volume follows Zipf's law, we find that 80% of the traffic may be transferred to the new policy in the first round and 99% in the first 3 rounds. © 2013 ACM.",Consistent network updates; Frenetic; Network programming languages; OpenFlow; Software-defined networking,Consistent network; Frenetic; Network programming language; Openflow; Software-defined networkings; Computational linguistics; Integer programming; Optimization; Algorithms
"Vanbever L., Reich J., Benson T., Foster N., Rexford J.",5,HotSwap: Correct and efficient controller upgrades for software-defined networks,2013,30,"Princeton University, United States; Duke University, United States; Cornell University, United States",Cornell University;Duke University;Princeton University,3,USA,1,24,19,"Like any complex software, SDN programs must be updated periodically, whether to migrate to a new controller platform, repair bugs, or address performance issues. Nowadays, SDN operators typically perform such upgrades by stopping the old controller and starting the new one - an approach that wipes out all installed flow table entries and causes substantial disruption including losing packets, increasing latency, and even compromising correctness. This paper presents HOTSWAP, a system for upgrading SDN controllers in a disruption-free and correct manner. HOTSWAP is a hypervisor (sitting between the switches and the controller) that maintains a history of network events. To upgrade from an old controller to a new one, HOTSWAP bootstraps the new controller (by replaying the history) and monitors its output (to determine which parts of the network state may be reused with the new controller). To ensure good performance, HOTSWAP filters the history using queries specified by programmers. We describe our design and preliminary implementation of HOTSWAP, and present experimental results demonstrating its effectiveness for managing upgrades to third-party controller programs. © 2013 ACM.",Controller upgrade; Dynamic software updating; Software-defined network,Complex software; Controller programs; Dynamic software updating; Flow tables; Hypervisor; Network state; Performance issues; Software-defined networks; Complex networks; Repair; Program debugging
"Kotronis V., Schatzmann D., Ager B.",3,On bringing private traffic into public SDN testbeds,2013,1,"ETH Zurich, Switzerland",ETH Zurich,1,Switzerland,1,9,9,"The search for improved communication paradigms has fostered the emergence of publicly available testbeds supporting Software Defined Networking all around the world. However, a common shortcoming among these testbeds is the lack of real user-driven Internet traffic for experimentation. While having real user traffic inside a testbed is an indisputable advantage, the users' right for privacy and wish for availability of the network often make it impossible to simply make a testbed part of the communication path. In this paper, we discuss how a testbed operator can give privacy and availability guarantees to users who are willing to share part of their traffic with experimenters, thus making it less risky for users to opt-in to experiments. Moreover, we share the insights gained from implementing a Privacy and Availability Layer demonstrator. © 2013 ACM.",SDN; Testbed,Communication paradigm; Communication path; Internet traffic; SDN; Software-defined networkings; User traffics; Communication; Experiments; Testbeds
"Reitblatt M., Canini M., Guha A., Foster N.",4,FatTire: Declarative fault tolerance for software-defined networks,2013,112,"Cornell University, United States; TU Berlin, T-Labs, Germany",Cornell University;TU Berlin,2,Germany;USA,2,17,11,"This paper presents FatTire, a new language for writing fault-tolerant network programs. The central feature of this language is a new programming construct based on regular expressions that allows developers to specify the set of paths that packets may take through the network as well as the degree of fault tolerance required. This construct is implemented by a compiler that targets the in-network fastfailover mechanisms provided in recent versions of the Open-Flow standard, and facilitates simple reasoning about network programs even in the presence of failures. We describe the design of FatTire, present algorithms for compiling Fat-Tire programs to OpenFlow switch configurations, describe our prototype FatTire implementation, and demonstrate its use on simple examples. © 2013 ACM.",Fast failover; Fault tolerance; Frenetic; NetCore; OpenFlow,Failover; Fault-tolerant networks; Frenetic; NetCore; Openflow; Openflow switches; Regular expressions; Software-defined networks; Computer programming languages; Fault tolerance; Pattern matching; Program compilers
"De Cicco L., Carlucci G., Mascolo S.",3,Experimental investigation of the google congestion control for real-time flows,2013,27,"Politecnico di Bari, Italy",Politecnico di Bari,1,Italy,1,6,4,"Enabling real-time communication over the Internet is of ever increasing importance due to the use of Internet for audio/video communication. The RTCWeb IETF working group has been established with the goal of standardizing a set of protocols for inter-operable real-time communication among Web browsers. In this paper we experimentally evaluate the Google Congestion Control (GCC) which has been recently proposed in the RTCWeb IETF WG. By setting up a controlled testbed, we have evaluated to what extent GCC flows are able to track the available bandwidth, while minimizing queuing delays, and fairly share the bottleneck with other GCC or TCP flows. We have found that the algorithm works as expected when a GCC flow accesses the bottleneck in isolation, whereas it is not able to provide a fair bandwidth utilization when a GCC flow shares the bottleneck with either a GCC or a TCP flow. Copyright © 2013 ACM.",Congestion Control; Real-time flows; RMCAT; RTCWEB,Audio/video communication; Available bandwidth; Experimental investigations; Real-time communication; Realtime flows; RMCAT; RTCWEB; Working groups; Congestion control (communication); Internet; Transmission control protocol
"Chen J., Arumaithurai M., Fu X., Ramakrishnan K.K.",4,Reliable publish/subscribe in content-centric networks,2013,7,"Institute of Computer Science, University of Goettingen, Germany; NEC Laboratories Europe, Heidelberg, Germany; AT and T Labs-Research, Florham Park, NJ, United States",AT and T Labs;NEC;University of Goettingen,3,Germany;USA,2,20,20,"Managing congestion is a challenge in content-centric networks due to the lack of an end-to-end session context over which a 'flow' may be controlled. Flow and congestion control as well as reliable delivery are often considered even more of a challenge in content-centric publish/subscribe systems, where the nature of information dissemination is similar to multicast. These have been long-standing challenges also for IP multicast. With an unknown number of publishers, a content-centric pub/sub environment exacerbates these problems, demanding new solutions. In this paper, we propose a lightweight enhancement to content-centric publish/subscribe systems for flow and congestion control as well as for reliability. R-COPSS allows the publishers to efficiently use the content-centric network by having subscribers generate timely feedback while enabling subscribers to make use of NDN to perform local repair for reliable delivery. Rather than having all subscribers generate feedback (ACK) per packet, we seek to elect particular subscribers in a hierarchy to provide the feedback and the rest of them resort to a periodical summary. Our approach not only reduces the load on the publisher, but also removes the requirement on the publisher to limit its sending rate to the slowest subscriber. Our preliminary results show that R-COPSS performs better in terms of overall throughput and is fair to competing flows. Copyright © 2013 ACM.",CCN; Congestion control; COPSS; Multicast; NDN; Pub/Sub; Reliability,CCN; Content-centric networks; COPSS; NDN; Pub/sub; Publish/subscribe; Publish/Subscribe system; Reliable delivery; Congestion control (communication); Information dissemination; Reliability; Repair; Multicasting
"Niwa J., Okada K., Okuda T., Yamaguchi S.",4,MPSDataStore: A sensor data repository system for mobile participatory sensing,2013,4,"Graduate School of Information Science, Nara Institute of Science and Technology, Takayama 8916-5, Ikoma, Nara, Japan",Nara Institute of Science and Technology,1,Japan,1,15,13,"The development of wireless technologies, such as 3G and Wi-Fi, and the rapid growth of mobile devices equipped with sensors have enabled the practical use of Mobile Participatory Sensing (MPS). By gathering and utilizing sensor data using mobile devices, the deployment cost of services can be reduced. In the context of MPS, it is important to establish a method of storing and locating sensor data collected by millions of mobile devices. In this paper, the development of a sensor data repository system for a large-scale MPS platform is proposed. By storing sensor information in the mobile device's storage, the storage cost can be distributed. The proposed method of tracking the acquisition locations of sensor data can reduce management costs. In addition, a cache mechanism that can minimize duplicate transmissions of sensor data from mobile devices due to overlapping queries is introduced. Based on a two-day simulation, the proposed method can reduce the management cost of the acquisition locations by 80%. Furthermore, the cache method can reduce the transmission of duplicated sensor data on mobile devices. © 2013 ACM.",Cloud computing; Mobile device; Participatory sensing,Cache mechanism; Deployment costs; Management costs; Participatory Sensing; Practical use; Sensor informations; Storage costs; Wireless technologies; Cloud computing; Cost reduction; Digital storage; Mobile cloud computing; Mobile devices; Sensors; Wireless telecommunication systems; Data reduction
"Pan H., Guan H., Liu J., Ding W., Lin C., Xie G.",6,The FlowAdapter: Enable flexible multi-table processing on legacy hardware,2013,23,"Institute of Computing Technology, Chinese Academy of Sciences, China; Huawei Technologies Co. Ltd., China",Chinese Academy of Sciences,1,China,1,21,8,"OpenFlow is one of the most potential technique to enable innovation in network. To enable OpenFlow more flexibility and high-efficiency, multi-table pipeline has been introduced in OpenFlow. A HAL (Hardware Abstraction Layer) is proposed to address the incompatibility of flow table pipeline between legacy switch hardware and the controller. However, the burden of controller will be increased greatly. In this paper, an innovative middle layer called FlowAdapter is proposed. It converts flow entry rules from the controller flow table pipeline to switch hardware flow table pipeline, so that the same rules can be fitted into different types of hardware. With FlowAdapter, legacy OpenFlow hardware can be used to support multi-table pipeline rules. Located in switch, FlowAdapter is transparent to the controller. With a prototype implementation, we find that the FlowAdapter performs rules conversion effectively. © 2013 ACM.",Equivalent conversion; Flow table; FlowAdapter; Middleware; OpenFlow,Flow tables; FlowAdapter; Hardware Abstraction Layers; High-efficiency; Middle layer; Openflow; Potential techniques; Prototype implementations; Middleware; Pipelines; Hardware
"Virgilio M., Marchetto G., Sisto R.",3,PIT overload analysis in content centric networks,2013,26,"Department of Control and Computer Engineering, Politecnico di Torino, Italy",Politecnico di Torino,1,Italy,1,8,6,"Content Centric Networking represents a paradigm shift in the evolution and definition of modern network protocols. Many research efforts have been made with the purpose of proving the feasibility and the scalability of this proposal. Our main contribution is to provide an analysis of the Pending Interest Table memory requirements in real deployment scenarios, especially considering the impact of distributed denial of service attacks. In fact, the state that the protocol maintains for each resource request makes the routers more prone to resources exhaustion issues than in traditional stateless solutions. Our results are derived by using a full custom simulator and considering the different node architectures that have been proposed as valid reference models. The main outcomes point out differentiated weaknesses in each architecture we investigated and underline the need for improvements in terms of security and scalability. Copyright © 2013 ACM.",Content centric networking; DDoS attacks; Security; Simulation,Content-centric networkings; Content-centric networks; DDoS Attack; Deployment scenarios; Distributed denial of service attack; Memory requirements; Security; Simulation; Network protocols; Scalability; Network security
"Chiocchetti R., Perino D., Carofiglio G., Rossi D., Rossini G.",5,INFORM: A dynamic INterest FORwarding mechanism for information centric networking,2013,65,"Alcatel Lucent Bell Labs, Nozay, France; Telecom ParisTech, Paris, France",Bell Labs,1,France,1,12,7,"Information Centric Networking is a new communication paradigm where network primitives are based on named-data rather than host identifiers. In ICN, data retrieval is triggered by user requests which are forwarded towards a copy of the desired content item. Data can be retrieved either from a server that permanently provides a content item, or from a temporary item copy opportunistically cached by an in-network node. As the availability of cached items dynamically varies over time, the request forwarding scheme should be adapted accordingly. In this paper we focus on dynamic request forwarding in ICN, and develop an approach, inspired by Q-routing framework, that we show to outperform algorithms currently available in the state of the art. Copyright © 2013 ACM.",Caching; Forwarding; Information centric networking,Caching; Communication paradigm; Data retrieval; Forwarding; Forwarding mechanisms; Host identifiers; Information-centric networkings; State of the art
"Kuga Y., Matsuya T., Hazeyama H., Cho K., Nakamura O.",5,EtherPIPE: An Ethernet character device for network scripting,2013,0,"Keio University, Japan; NAIST, Japan; IIJ, Japan",Keio University,1,Japan,1,19,17,"The UNIX command tools are designed to combine simple generic commands to accomplish various complex tasks. Meanwhile, in network programming, we often end up writing many similar functions and packaging functions of all network layers to build an application. In this paper, we propose EtherPIPE, a character network I/O device, that allows the programmer to access network traffic data as a file through UNIX commands. By setting a UNIX pipe ""|"" from or to EtherPIPE's output or input with UNIX commands, packets can be easily processed, executing functions such as packet filtering, packet capturing, generating arbitrary packets, and rewriting header information. We developed a prototype of EtherPIPE as a character device driver for a commodity FPGA card. This paper argues for use cases of the EtherPIPE, and discusses enhanced formats of character devices for easier network scripting. © 2013 ACM.",Device driver; Ethernet; Network I/O; Shell script; Software-defined networking,Access network; Device Driver; Network I/O; Packaging functions; Packet capturing; Packet filtering; Shell script; Software-defined networkings; Ethernet; Information filtering; Network layers; UNIX; Complex networks
Murase T.,1,User cooperative mobility for better multimedia communication quality,2013,0,"NEC Corporation, 1753 Shimonumabe, Nakaharaku Kawasaki, Japan",NEC,1,Japan,1,11,8,"For mobile multimedia communications, Quality of Service (QoS) is significantly important. In general it will incur costs to improve QoS. Regarding utility function of cost versus gain for an individual user, it is useful to evaluate relationship between cost such as energy consumption and gain such as QoS. Network operators or service providers could invest more resource facilities to improve QoS that will result in rising users' service fees. User cooperative mobility is one of key technology that do not select between cost and gain tradeoff, but to provide the best solution. Copyright © 2013 ACM.",Mobile computing; Mobility; Multimedia; Quality of Experience; Quality of Service; User cooperation; Utility function,Key technologies; Mobile multimedia communications; Multi-media communications; Multimedia; Quality of experience (QoE); Service provider; User cooperation; Utility functions; Carrier mobility; Costs; Energy utilization; Mobile computing; Multimedia systems; Quality of service
Malsbury J.,1,"Modular, open-source software transceiver for PHY/MAC research",2013,6,"Ettus Research, 1043 N Shoreline Blvd., United States",Ettus Research,1,USA,1,20,7,"The USRPª (Universal Software Radio Peripheral) is a software-defined radio platform that has been widely adopted for wireless research in cognitive radio, cellular networks, and other application areas. USRP devices are often used with GNU Radio, a free and open-source DSP framework that allows designers to prototype with a combination of C++, Python, and graphical tools. This paper will investigate various methods that can be used to build complete communications stacks within GNU Radio. These methods will leverage advanced features of UHD"" (USRP Hardware Driver) and GNU radio to implement TDMA, CSMA and FHSS transceivers that can be modified in GNU Radio Companion - a graphical development environment. The implementation will also show how to interact with upper network and application layers, all within GNU Radio. The implementation presented in this paper will be open-source. It can serve as an educational resource, or as a basis for additional research. © 2013 ACM.",Cognitive radio; GNU radio; Graphical design; PHY/MAC; Prototyping; SDR architecture; SDR programming model; SDR reference design,GNU radio; Graphical designs; PHY/MAC; Programming models; Reference designs; Cognitive radio; Design; Network layers; Research; Software prototyping; Software radio; Time division multiple access; Transceivers; Computer programming
"Yang S., Lua E.K., Wang Y.",3,Towards human-centric personalized expertise ranking in community-based question answering,2013,1,"School of Computer Science, Beijing Jiaotong University, China; Faculty of Information Technology, Monash University, Australia",Beijing Jiaotong University;Monash University,2,Australia;China,2,4,4,"Search engine has been the major source for discovering user-generated content with authority, not only on content-centric multimedia but also on human-centric social networks. Many studies have demonstrated the power of graph-based ranking algorithms to propagate reputation and expertise along social graph composed of users' links for information search, to promote experts and demote spams. However, these existing works shed little light on personalized expertise ranking algorithm from view of the topic-relevance between users' interests. In this study, we demonstrated the existence of homophily in users' interests measured by social annotations using AskMeFi, a large scale community-driven question and answering (CQA) system. We discovered that best answers as rated by questioners (users posting questions), are inclined to arrive promptly from co-interest users with authority and topic-relevance after the questions are posted. We proposed Human-centric Personalized Expertise Ranking, a graph-based algorithm which takes the topic-relevance and authority among co-interest users and time traits into the computation of the expertise level of users. The experimental results revealed that our proposed algorithm significantly outperforms other non-personalized expertise ranking algorithms. Copyright © 2013 ACM.",Community-based Question Answering; Expertise ranking; Homophily; Social annotation; Topic-relevance,Community-based question answering; Expertise ranking; Homophily; Social annotations; Topic-relevance; Graphic methods; Search engines; Algorithms
"Klose R., Loch A., Hollick M.",3,Evaluating dynamic OFDMA subchannel allocation for wireless mesh networks on SDRs,2013,2,"TU Darmstadt, Secure Mobile Networking Lab., Mornewegstr. 32, 64293 Darmstadt, Germany",TU Darmstadt,1,Germany,1,4,3,"Orthogonal Frequency-Division Multiple Access (OFDMA) has emerged as an advanced technique to enhance resource utilization and efficiency in infrastructure-based networks. However, its performance in wireless mesh networks is mostly unexplored. In this paper, we practically study the benefits of OFDMA in a scenario with multiple co-located transmitters and receivers without centralized controller by means of the software-defined radio platform WARP. We propose five different dynamic subchannel allocation strategies and compare their performance to that of OFDM as a baseline. Four of these strategies are constrained to be fair with respect to the number of subchannels allocated per communication link, while the fifth always allocates a subchannel to its best possible communication link. By means of testbed experiments with software-defined radios, we show that the overall bit error rate can be reduced by a factor of ten, while the overall channel capacity can locally be enhanced by 10% to 30%. Further, we use the Subchannel Avoidance Gain as a metric to quantify the ability of a dynamic subchannel allocation strategy to avoid subchannel allocations resulting in poor channel conditions. © 2013 ACM.",OFDMA; Resource allocation; Wireless mesh networks,Centralized controllers; Channel conditions; Dynamic subchannel allocation; OFDMA; Orthogonal frequency division multiple access; Resource utilizations; Software-defined radios; Subchannel allocation; Communication; MESH networking; Radio receivers; Resource allocation; Software radio; Wireless mesh networks (WMN); Frequency division multiple access
"Bayhan S., HyytiŠ E., Kangasharju J., Ott J.",4,Seeker-assisted information search in mobile clouds,2013,7,"HIIT, Aalto University, Finland; COMNET, Aalto University, Finland; University of Helsinki, Finland",Aalto University;University of Helsinki,2,Finland,1,16,14,"The increase in the size of mobile cloud as well as the volume of information necessitates efficient search mechanisms for finding the searched information or the target node. In this paper, we focus on search mechanisms to retrieve information from within a mobile cloud in which nodes have intermittent connectivity and hence operate on a store-carry-forward manner. We design an opportunistic search scheme in which the searching node spreads a limited number of replicas of the query to the nodes it meets and these nodes, so called seekers, perform the search on behalf of the searching node. We assume that nodes are grouped into communities based on their interest profiles, and seekers use this community information to forward the data and the query to the right community-the community that is more likely to store the searched content. Since people store and search for similar information in the scope of their interest, the nodes in the same community as the searching node have higher probability to store the searched content. We model this seeker-assisted search scheme as a continuous time Markov process and analyze its performance under various inter-community/intra-community meeting rate, number of replicas, and network population. Our analysis shows that seeker-assisted search achieves a good balance between the search response time and search cost compared to the two extremes of epidemic search and direct delivery search. © 2013 ACM.",Interest similarity; Mobile opportunistic networks; Mobile search,Continuous time Markov process; Information search; Interest similarity; Intermittent connectivity; Mobile opportunistic networks; Mobile search; Search mechanism; Store carry forwards; Markov processes; Mobile cloud computing
"Krishnamoorthit V., Bergstršmt P., Carlsson N., Eager D., Mahanti A., Shahmehrit N.",6,Empowering the creative user: Personalized HTTP-based adaptive streaming of multi-path nonlinear video,2013,1,"Linkšping University, Sweden; University of Saskatchewan, Canada; NICTA, Australia",Linkšping University;NICTA;University of Saskatchewan,3,Australia;Canada;Sweden,3,15,14,"This paper presents the design, implementation, and validation of a novel system that supports streaming and playout of personalized, multi-path, nonlinear video. In contrast to regular video, in which the file content is played sequentially, our design allows multiple nonlinear video sequences of the underlying (linear) video to be stitched together and played in any personalized order, and clients can be provided multiple path choices. The design combines the ideas of HTTP-based adaptive streaming (HAS) and multi-path nonlinear video. Personalization of the content is achieved with the use of a customized metafile, which is downloaded separately from the underlying media and the manifest file that defines the HAS structure. An extension to the user interface allows path choices to be presented to and made by the user. Novel buffer management and prefetching policies are used to ensure seamless uninterrupted playback regardless of client path choices, even under scenarios in which clients defer their choices until the last possible moment. Our solution allows creative home users to easily create their own multi-path nonlinear video, opening the door to an endless possibility of new opportunities and media forms. Copyright © 2013 ACM.",HTTP-based Adaptive streaming; Multi-path video; Nonlinear video; Seamless playback,Adaptive streaming; Buffer management; File contents; Multi-path video; Multiple-path; Non-linear videos; Personalizations; Seamless playbacks; Design; User interfaces; HTTP
"Gudipati A., Perry D., Li L.E., Katti S.",4,Softran: Software defined radio access network,2013,287,"Stanford University, United States; Bell Labs, Alcatel-Lucent, United States",Bell Labs;Stanford University,2,USA,1,18,17,"An important piece of the cellular network infrastructure is the radio access network (RAN) that provides wide-area wireless connectivity to mobile devices. The fundamental problem the RAN solves is figuring out how best to use and manage limited spectrum to achieve this connectivity. In a dense wireless deployment with mobile nodes and limited spectrum, it becomes a difficult task to allocate radio resources, implement handovers, manage interference, balance load between cells, etc. We argue that LTE's current distributed control plane is suboptimal in achieving the above objective. We propose SoftRAN, a fundamental rethink of the radio access layer. SoftRAN is a software defined centralized control plane for radio access networks that abstracts all base stations in a local geographical area as a virtual big-base station comprised of a central controller and radio elements (individual physical base stations). In defining such an architecture, we create a framework through which a local geographical network can effectively perform load balancing and interference management, as well as maximize throughput, global utility, or any other objective. © 2013 ACM.",Radio access networks; Software defined networking,Cellular network infrastructure; Distributed control planes; Geographical networks; Interference management; Radio access networks; Software-defined networkings; Software-defined radios; Wireless connectivities; Base stations; Mobile devices; Mobile telecommunication systems; Radio; Local area networks
"Barkai S., Katz R., Farinacci D., Meyer D.",4,Software defined flow-mapping for scaling virtualized network functions,2013,5,"ConteXtream, 1927 FallenLeaf Ln., Los Altos, CA, United States; UC Berkeley, 101 Sproul Hall, Berkeley, CA, United States; Cisco Systems, 170 West Tasman Dr., San Jose, CA, United States; Brocade Communication, 130 Holger Way, San Jose, CA, United States",University of California Berkeley,1,USA,1,15,13,"In this paper, we describe the use of software defined flow-mapping for scale-assembly of virtual functions features-capacity. © 2013 ACM.",Flows; Location identity separation; Mapping; Network functions virtualization; Overlay; Software defined networks; Underlay,Flows; Identity separations; Overlay; Software-defined networks; Underlay; Virtualizations; Mapping
"Wang X.S., Shen H., Wetherall D.",3,Accelerating the mobile web with selective offloading,2013,10,"University of Washington, Seattle, WA, United States",University of Washington at Seattle,1,USA,1,8,6,"Mobile Web page loads are notoriously slow due to limited computing power and slow network access. Our preliminary experiments show that computation is a significant fraction of page load time on mobile devices. Also, energy arguments suggest that it will stay this way. To compensate the limited computing power, our position is that offloading portions of the page load process to the cloud can significantly improve mobile page load time. We propose a measurement-based framework that allows to offload portions of mobile page load process to the cloud. Unlike browsers that offload fixed parts of page loads such as Opera Mini, our framework will allow to offload any portion of the page load process. We will experiment with a large variety of real-world situations (e.g., varying computing power on mobile devices) by offloading varying portions of page loads using our framework. Informed by the experimental results, we will develop a mobile browser that considers the diverse situations as well as energy and data usage. © 2013 ACM.",Cloud; Mobile Web; Offload; Page load; Web,Energy arguments; Measurement-based; Mobile Browsers; Mobile web; Mobile web pages; Offload; Real world situations; Web; Clouds; Experiments; Mobile devices; Mobile cloud computing
"Shin S., Gu G.",2,Attacking software-defined networks: A first feasibility study,2013,132,"SUCCESS Lab., Texas A and M University, United States",Texas A and M University,1,USA,1,4,4,"In this paper, for the first time we show a new attack to fingerprint SDN networks and further launch efficient resource consumption attacks. This attack demonstrates that SDN brings new security issues that may not be ignored. We provide the first feasibility study of such attack and hope to stimulate further studies in SDN security research. © 2013 ACM.",Attack; Network security; Software defined networking,Attack; Feasibility studies; Resource consumption; Security issues; Security research; Software-defined networkings; Software-defined networks; Planning; Network security
"Mtibaa A., Fahim A., Harras K.A., Ammar M.H.",4,Towards resource sharing in mobile device clouds: Power balancing across mobile devices,2013,54,"Texas A and M, United States; Carnegie Mellon University, United States; Georgia Institute of Technology, United States",Carnegie Mellon University;Georgia Tech,2,USA,1,15,7,"Despite the increased capabilities of mobile devices, mobile application resource requirements can often transcend what can be accomplished on a single device. This has been addressed through several proposals for efficient computation offloading from mobile devices to remote cloud resources or closely located computing resources known as cloudlets. In this paper we consider an environment in which computational offloading is performed among a set of mobile devices. We call this environment a Mobile Device Cloud (MDC). We are interested in MDCs where nodes are highly collaborative. We develop computational offloading schemes that maximize the lifetime of the ensemble of mobile devices where we consider the network to be alive as long as no device has depleted its battery. As a secondary contribution in this work, we develop and use an experimentation platform that allows us to evaluate a range of computational models and profiles derived from a realistic testbed. We use this platform as a first step in an evaluation exercise that demonstrates the effectiveness of our computation offloading algorithms in extending the lifetime of an MDC. © 2013 ACM.",Energy saving; Mobile computing; Opportunistic computing; Resource sharing,Computation offloading; Computational model; Efficient computation; Experimentation platforms; Mobile applications; Opportunistic computing; Resource requirements; Resource sharing; Computer applications; Energy conservation; Mobile cloud computing; Mobile computing; Mobile devices
"Rondeau T.W., O'Shea T., Goergen N.",3,Inspecting GNU radio applications with ControlPort and performance counters,2013,6,"University of Pennsylvania, Philadelphia, PA 19104, United States; University of Maryland, College Park, MD, 20742, United States",University of Maryland College Park;University of Pennsylvania,2,USA,1,4,2,"Due to differences in the operating system and the effects of sample rate on the computational load of a software radio, we have historically had a difficult time understanding the performance boundaries of software radio applications. This problem further leads to difficulties in debugging, optimization, and profiling analysis of both software radio frameworks and applications. This paper introduces a new tool developed for GNU Radio that starts to solve these problems. Called Performance Counters, GNU Radio now has an inbuilt ability to measure its performance for offline optimization as well as realtime behavioral analysis and adaptation. The Performance Counters are designed such that a GNU Radio application can directly sample them or access them through the use of ControlPort, another new tool that enables remote interaction with GNU Radio. We show in this paper some of the tools we have developed around ControlPort and the Performance Counters that will help us better understand GNU Radio's performance and capabilities as well as lead to better on-line adaptation of radios. © 2013 ACM.",GNU radio; Profiling; Signal processing; Software radio,Behavioral analysis; Computational loads; GNU radio; Off-line optimization; Performance counters; Profiling; Remote interactions; Software radio applications; Behavioral research; Optimization; Signal processing; Tools; Software radio
"Malsbury J., Ettus M.",2,Simplifying FPGA design with a novel network-on-chip architecture,2013,8,"Ettus Research, 1043 N Shoreline Blvd, United States",Ettus Research,1,USA,1,15,12,"As wireless communications continue to evolve, complex new standards force researchers to adopt heterogeneous design approaches that include general purpose processors (GPP) and field-programmable gate arrays (FPGA). This combination leads to increased processing throughput, decreased latency, and increased development complexity. Compared to GPP implementations, custom FPGA designs are time-consuming. The Third-Generation Ettus Research USRPª (Universal Software Radio Peripheral) has been developed with a unique processing and routing architecture based on VITA-49, which can drastically reduce FPGA development time. This architecture allows users to easily integrate custom IP, such as channelizes, modulators, demodulators, processors or protocol stacks. The architecture will also permit scalable designs that can distribute processing across many nodes. This paper will examine this architecture and how it will reduce development time for researchers. A practical example will also be provided for reference. © 2013 ACM.",FPGA; GNU Radio; Heterogeneous systems; High-performance computing; SDR; Software-defined radio; VITA-49; VRLP,GNU radio; Heterogeneous systems; High-performance computing; SDR; Software-defined radios; VITA-49; VRLP; Design; Embedded systems; Field programmable gate arrays (FPGA); Internet protocols; Network architecture; Research; Software radio; Wireless telecommunication systems; Computer architecture
"Wen X., Chen Y., Hu C., Shi C., Wang Y.",5,Towards a secure controller platform for OpenFlow applications,2013,74,"Northwestern University, Evanston, IL, United States; Xi'an Jiaotong University, Xi'an, China; Tsinghua University, Beijing, China",Northwestern University;Tsinghua University; Xian JiaoTong University,3,China;USA,2,5,5,"The OpenFlow (OF) paradigm embraces third-party development efforts, and therefore suffers from potential trust issue on OF applications (apps). The abuse of such trust could lead to various types of attacks impacting the entire network. In this paper, we propose PermOF, a fine-grained permission system, as the first line of defense, in order to apply minimum privilege on apps. We summarize a set of 18 permissions to be enforced at the API entry of the controller. To accommodate the isolation requirements, we propose a customized isolation mechanism, which achieves comprehensive resource isolation and access control. © 2013 ACM.",OpenFlow; Policy enforcement; Security,Openflow; Policy enforcement; Security; Third-party development
"Bloessl B., Segata M., Sommer C., Dressler F.",4,An IEEE802.11a/g/p OFDM receiver for GNU radio,2013,59,"Institute of Computer Science, University of Innsbruck, Austria; Dept. of Information Engineering and Computer Science, University of Trento, Italy",University of Innsbruck;University of Trento,2,Austria;Italy,2,3,3,"Experimental research on wireless communication protocols frequently requires full access to all protocol layers, down to and including the physical layer. Software Defined Radio (SDR) hardware platforms, together with real-time signal processing frameworks, offer a basis to implement transceivers that can allow such experimentation and sophisticated measurements. We present a complete Orthogonal Frequency Division Multiplexing (OFDM) receiver implemented in GNU Radio and fitted for operation with an Ettus USRP N210. To the best of our knowledge, this is the first prototype of a GNU Radio based OFDM receiver for this technology. Our receiver comprises all layers up to parsing the MAC header and extracting the payload of IEEE 802.11a/g/p networks. It supports both WiFi with a bandwidth of 20MHz and IEEE802.11p DSRC with a bandwidth of 10MHz. We validated and verified our implementation by means of interoperability tests, and present representative performance measurements. By making the code available as Open Source we provide an easy-to-access system that can be readily used for experimenting with novel signal processing algorithms. © 2013 ACM.",GNU radio; IEEE802.11a/g/p; OFDM receiver; SDR,GNU radio; IEEE802.11a; OFDM receiver; Performance measurements; Real-time signal processing; SDR; Signal processing algorithms; Wireless communication protocols; Bandwidth; Interoperability; Network layers; Orthogonal frequency division multiplexing; Signal processing; Standards; Wireless telecommunication systems; Software radio
"Antonenko V., Smelyanskiy R.",2,Global network modelling based on mininet approach,2013,25,"Moscow State University, Applied Research Center for Computer Networks, Moscow, Russian Federation",Moscow State University,1,Russia,1,6,2,"The problem of the Global network operation analysis has a variety of applications. In this paper we show an approach to this problem on example of malware propagation in the Global networks (Wide Area Network). It is very important to be able to make accurate prediction of the consequences of such propagation. This paper introduces a new approach to malware propagation prediction based on the ideas presented by Mininet network rapid prototyping approach. The major barriers to use simulation techniques for malware propagation analysis are enormous network size and low level granularity in protocol data unit processing. Mininet cannot be used for this purpose too because of its low level scalability. In this paper, we propose a new system called Mininet CE (Cluster Edition) which is based on the ideas of existent Mininet. Mininet CE offers the solution of the Global network functionality analysis problems. In this paper, we focus on propagation analysis of a malware as network worm. The experiments with the worm Sasser demonstrate the ability of Mininet CE to be useful tool for worm propagation analysis in the Global network. © 2013 ACM.",Emulation; Malware propagation; Mininet; Network simulation; Network worms; Rapid prototyping; Virtualization,Emulation; Malware propagation; Mininet; Network simulation; Network worms; Virtualizations; Computer simulation; Computer worms; Data handling; Internet; Rapid prototyping; Data flow analysis
"Thapliya R., Hu C.",2,AdapComm: A bandwidth allocation methodology for multimedia applications in wireless networks,2013,3,"Incubation Center, Research and Technology Group, Fuji Xerox Co., Ltd., 6-1 Minatomirai, Nishi-ku, Yokohama-shi Kanagawa 220-8668, Japan",Fuji Xerox,1,Japan,1,15,11,"In this article, we propose AdaptMetric Communication (Adap-Comm), an end-to-end bandwidth estimation and allocation methodology putting emphasis on Quality of Experience at the user side. AdapComm dynamically samples the connection by sending dummy probing-TCP packets and derives the bandwidth online. This information is then sent to the server to adaptively change the data transmission to maintain user experience even in highly fluctuating networks, such as wireless connections. In future office-works, the usage of multimedia in mobile environments will be the norm, thus, we demonstrate the implementation of smooth, stall-free video streaming based on this scheme for enhanced user experience. Copyright © 2013 ACM.",Bandwidth Estimation; QoE; QoS; Video Streaming,Bandwidth estimation; Mobile environments; Multimedia applications; QoE; Quality of experience (QoE); User experience; Wireless connection; Bandwidth; Quality of service; Transmission control protocol; User interfaces; Video streaming; Telecommunication systems
"Zhang X., Ansari J., Arya M., MŠhšnen P.",4,Exploring parallelization for medium access schemes on many-core software defined radio architecture,2013,3,"RWTH Aachen University, Institute for Networked Systems, Kackertstrasse 9, D-52072 Aachen, Germany",RWTH Aachen University,1,Germany,1,5,4,"As multi-standard devices and high speed communication standards are emerging, timeliness requirements and flexibility for both baseband modem and medium access schemes are becoming essential. Software Defined Radios (SDRs), in this context, aim at offering the desired flexibility while satisfying the real-time constraints. An SDR architecture consisting of many-core homogeneous computing elements provides easy protocol implementation, a high level of portability and extension possibilities. It does not require architecture specific program code which is needed by the popular heterogeneous SDR architectures. Therefore, in this paper, we explore how a homogeneous SDR architecture is used for efficient realization and execution of Medium Access Control (MAC) protocols. In particular, we investigate the performance of two broad classes of MAC schemes on the Platform 2012 (P2012) many-core programmable computing fabric. We provide a toolchain which utilizes the characteristics of P2012 for MAC parallelization, runtime scheduling, and execution. Our results indicate that by using the supporting toolchain, reconfigurable MAC implementations are able to exploit the computational power offered by the platform and adhere to the timeliness constraints. Computationally intensive algorithms for MAC layer parameter optimization show an improvement of up to 85% in the convergence time as compared to using a single-core architecture. © 2013 ACM.",MAC; Many-core; Parallelization; SDR platform,Computationally intensive algorithms; High-speed communications; MAC; Many-core; Medium access control protocols; Parallelizations; Sdr platforms; Software-defined radio architectures; Computer software portability; Medium access control; Network architecture; Radio; Software radio; Computer architecture
"Gupta M., Sommers J., Barford P.",3,"Fast, accurate simulation for SDN prototyping",2013,39,"University of Wisconsin, United States; Colgate University, United States",Colgate University;University of Wisconsin-Madison,2,USA,1,15,12,"Thorough test and evaluation of new software-defined network (SDN)-based applications and configurations present many challenges. Examples of these challenges include scaling to large networks, accuracy, and efficiency in evaluation along with the ability to easily transition between prototype and test environments. Current methods for test and evaluation include new programming languages and frameworks, debugging and static analysis techniques, and VM-and container-based emulation tools. In this paper we describe a simulation-based tool called fs-sdn that complements and expands upon these existing approaches. Our work is designed to address the problem of prototyping and evaluating new SDN-based applications accurately, at large scale, and in a way that enables easy translation to real controller platforms like POX and NOX. We describe the design, implementation and use of fs-sdn, and demonstrate its capability by carrying out a series of experiments using fs-sdn and the Mininet platform in nearly identical configurations. We show that the measurements derived from fs-sdn are accurate compared with Mininet, but offer significant speed and scalability advantages. © 2013 ACM.",Network flows; OpenFlow; Simulation; Software-defined networks,Analysis techniques; Large networks; Network flows; Openflow; Simulation; Software-defined networks; Test and evaluation; Test Environment; Tools; Computer simulation
"Cabral C.M.S., Rothenberg C.E., Magalh‹es M.F.",3,Mini-CCNx: Fast prototyping for named data networking,2013,15,"Faculty of Electrical and Computer Engineering (FEEC), University of Campinas (UNICAMP), S‹o Paulo, Brazil",University of Campinas,1,Brazil,1,43,38,"Experimental research in Information-Centric Networking (ICN) is crucial to the evaluation of new architectural proposals that bring named pieces of content as the main element of networks. This paper presents a new fast prototyping tool for the NDN (Named Data Networking) model, Mini-CCNx, that aims at filling an existing gap in generally available experimental platforms. Using container-based emulation and resource isolation techniques, Mini-CCNx appears as a flexible, scalable, high-fidelity, and low-cost tool that enables rich experimentation with hundreds of emulated NDN nodes in a commodity laptop. Copyright © 2013 ACM.",CCN; Emulation; ICN; NDN; Prototyping; Routing,CCN; Emulation; ICN; NDN; Routing; Software prototyping; Tools
"Benton K., Camp L.J., Small C.",3,OpenFlow vulnerability assessment,2013,124,"School of Informatics and Computing, Indiana University, Bloomington, IN, United States",Indiana University,1,India;USA,2,32,25,"We provide a brief overview of the vulnerabilities present in the OpenFlow protocol as it is currently deployed by hardware and software vendors. We identify a widespread failure to adopt TLS for the OpenFlow control channel by both controller and switch vendors, leaving OpenFlow vulnerable to man-in-the-middle attacks. We also highlight the classes of vulnerabilities that emerge from the separation and centralization of the control plane in OpenFlow network designs. Finally, we offer suggestions for future work to address these vulnerabilities in a systematic fashion. © 2013 ACM.",OpenFlow; Security; Software-defined networking,Control channels; Hardware and software; Man in the middle attacks; Openflow; Openflow networks; Security; Software-defined networkings; Vulnerability assessments
"Nguyen A.-D., Senac P., Diaz M.",3,How disorder impacts routing in human-centric disruption tolerant networks,2013,4,"ISAE-University of Toulouse, LAAS-CNRS, Toulouse, France",University of Toulouse,1,France,1,7,4,"Human-Centric DTNs exhibit some degree of regularity on their temporal contact patterns [1]. The impact of this regularity on network performances has not been well studied and analyzed. In this paper, we study this temporal dimension of Human-Centric DTNs and its impacts on routing performances. We propose a simple parametric network model which covers the full spectrum of contact patterns from strictly periodic to fully random ones. Based on this model, we study the impact of contact patterns regularity on routing performances and we show how to exploit the temporal structure to navigate with a good resource/performance tradeoff in Human-Centric DTNs. Simulation and analytical analysis show that efficient routing with respect to their degree of regularity emerge within a subset of dynamic networks. Moreover, we show there is a specific degree of regularity where routing performance achieves its optimum. Copyright © 2013 ACM.",Disorder; Dynamic network structure; Human-Centric DTNs; Routing; Search and retrieval,Disorder; Dynamic network; Human-centric; Routing; Search and retrieval; Ad hoc networks; Computer simulation; Network routing; Delay tolerant networks
"Pongr‡cz G., Moln‡r L., Kis Z.L., Tur‡nyi Z.",4,Cheap silicon: A myth or reality? Picking the right data plane hardware for software defined networking,2013,10,"TrafficLab., Ericsson Research, Budapest, Hungary",Ericsson Research,1,Hungary,1,7,7,"Software-Defined Networking (SDN) promises the vision of more flexible and manageable networks, but requires certain level of programmability in the data plane. Current industry insight holds that programmable network processors are of lower performance than their hard-coded counterparts, such as Ethernet chips. This represents a roadblock to SDN adoption. In this paper we argue that contrast to the common view, the overhead of programmability is relatively low. We also argue that the apparent difference between programmable and hard-coded chips today is not primarily due to programmability itself, but because the internal balance of programmable network processors is tuned to more complex use cases. These arguments are backed with calculations and real-life measurements. © 2013 ACM.",Cost; Data plane; Efficiency; Network processor; OpenFlow; Performance; Power; Software defined networking,Data planes; Network processor; Openflow; Performance; Power; Software-defined networkings; Costs; Efficiency; Programmed control systems; Complex networks
"Saino L., Psaras I., Pavlou G.",3,Hash-routing schemes for information centric networking,2013,81,"Department of Electrical and Electronics Engineering, University College London, London, United Kingdom",University College London,1,UK,1,21,17,"Hash-routing has been proposed in the past as a mapping mechanism between object requests and cache clusters within enterprise networks. In this paper, we revisit hash-routing techniques and apply them to Information-Centric Networking (ICN) environments, where network routers have cache space readily available. In particular, we investigate whether hash-routing is a viable and efficient caching approach when applied outside enterprise networks, but within the boundaries of a domain. We design five different hash-routing schemes which efficiently exploit in-network caches without requiring network routers to maintain per-content state information. We evaluate the proposed hash-routing schemes using extensive simulations over real Internet domain topologies and compare them against various on-path caching mechanisms. We show that such schemes can increase cache hits by up to 31% in comparison to on-path caching, with minimal impact on the traffic dynamics of intra-domain links. Copyright © 2013 ACM.",Cache-aware routing; Hash-routing; ICN; Off-path caching,Cache-aware routing; Enterprise networks; Extensive simulations; Hash-routing; ICN; Information-centric networkings; Information-centric networkings (ICN); Off-path caching; Industry; Routers; Routing protocols
"Arianfar S., Sarolahti P., Ott J.",3,Deadline-based resource management for information-centric networks,2013,6,"Aalto University, Department of Communications and Networking, Finland",Aalto University,1,Finland,1,17,0,"Unlike in traditional IP-based end-to-end network sessions, in information-centric networks the data source may change during a communication session. Therefore the response time to subsequent data requests may vary significantly depending on whether data comes from nearby cache, or a distant source. This is a complication for designing resource management, reliability and other algorithms, that traditionally use RTT measurements for determining when data is considered lost and should be retransmitted (along with related congestion control adjustments). This paper discusses a different approach for designing resource management in information-centric networks: data packets are assigned with a lifetime, that is used as a basis for scheduling and resource management in the network, and for congestion control and retransmission logic at the end hosts. We demonstrate an initial evaluation of this approach based on ns-3 simulations on CCN framework. Copyright © 2013 ACM.",Content-oriented networking; Resource management,Communication sessions; Content-oriented networkings; Control adjustments; End-to-end network; Information-centric; Ns-3 simulations; Resource management; RTT measurements; Natural resources management; Resource allocation; Information management
"Williams D., Jamjoom H.",2,Cementing high availability in OpenFlow with RuleBricks,2013,15,"IBM T. J. Watson Research Center, Yorktown Heights, NY, United States",IBM,1,USA,1,23,15,"Controller applications in OpenFlow cannot be trivially augmented to support the various high availability (or failure recovery) models of server applications. Recent work on OpenFlow has largely assumed static replica configurations or has relied on controller developers to embed high availability support in their design. Instead, we present Rule-Bricks, a system for flexibly embedding high availability support in existing OpenFlow policies. RuleBricks introduces three key primitives: drop, insert, and reduce. We describe how these primitives can express various flow assignment and backup policies, demonstrating the one offered by the Chord protocol. We have implemented RuleBricks and the Chord assignment policy. Using simulation, we compare RuleBricks against a typical tree-based approach. We show that RuleBricks maintains linear scalability with the number of replicas on the Chord ring. © 2013 ACM.",High availability; OpenFlow; Software-defined networking,Chord protocol; Failure recovery; Flow assignment; High availability; Openflow; Server applications; Software-defined networkings; Tree-based approach
"Mahmudul Hoque A.K.M., Amin S.O., Alyyan A., Zhang B., Zhang L., Wang L.",6,NLSR: Named-data link state routing protocol,2013,140,"University of Memphis, United States; University of Arizona, United States; University of California, Los Angeles, United States",University of Arizona;University of California Los Angeles;University of Memphis,3,USA,1,18,10,"This paper presents the design of the Named-data Link State Routing protocol (NLSR), a routing protocol for Named Data Networking (NDN). Since NDN uses names to identify and retrieve data, NLSR propagates reachability to name prefixes instead of IP prefixes. Moreover, NLSR differs from IP-based link-state routing protocols in two fundamental ways. First, NLSR uses Interest/Data packets to disseminate routing updates, directly benefiting from NDN's data authenticity. Second, NLSR produces a list of ranked forwarding options for each name prefix to facilitate NDN's adaptive forwarding strategies. In this paper we discuss NLSR's main design choices on (1) a hierarchical naming scheme for routers, keys, and routing updates, (2) a hierarchical trust model for routing within a single administrative domain, (3) a hop-by-hop synchronization protocol to replace the traditional network-wide flooding for routing update dissemination, and (4) a simple way to rank multiple forwarding options. Compared with IP-based link state routing, NLSR offers more efficient update dissemination, built-in update authentication, and native support of multipath forwarding. Copyright © 2013 ACM.",NDN; Routing; Trust model,Hierarchical trust models; Link State Routing protocol; Multi-path forwarding; Named data networkings; NDN; Routing; Synchronization protocols; Trust modeling; Routers; Security of data; Routing protocols
"Panda A., Scott C., Ghodsi A., Koponen T., Shenker S.",5,CAP for networks,2013,30,"UC Berkeley, United States; UC Berkeley, KTH, United States; VMware, United States; UC Berkeley, ICSI, United States",University of California Berkeley,1,USA,1,14,12,"The CAP theorem showed that it is impossible for datastore systems to achieve all three of strong consistency, availability and partition tolerance. In this paper we investigate how these trade-offs apply to software-defined networks. Specifically, we investigate network policies such as tenant isolation and middlebox traversal, and prove that it is impossible for implementations to enforce them without sacrificing availability. We conclude by distilling practical design lessons from our observations. © 2013 ACM.",Availability; Correctness; Distributed controllers; Software defined network,Correctness; Distributed controller; Middleboxes; Network policy; Partition tolerances; Software-defined networks; Strong consistency; Availability
"Canini M., Kuznetsov P., Levin D., Schmid S.",4,Software transactional networking: Concurrent and consistent policy composition,2013,30,"TU Berlin, T-Labs, Germany; TŽlŽcom ParisTech, France",TU Berlin,1,France;Germany,2,9,7,"It seems natural to imagine that SDN policy specification and control is distributed, and this paper focuses on the resulting concurrency issues. Indeed, conflicts among concurrent policy updates may result in serious inconsistencies on the data plane, even when each update is installed with perpacket consistent update semantics. This paper introduces the problem of consistent composition of concurrent policy updates. Intuitively, consistent concurrent policy composition must appear as though there is no concurrency neither between any policy updates, nor between a policy update and in-flight packets on the data plane. We propose an elegant policy composition abstraction based on a transactional interface with all-or-nothing semantics: a policy update is either committed, in which case the policy is guaranteed to compose consistently over the entire network and the update is installed in its entirety, or aborted, in which case, no packet is affected by it. Consequently, the control application logic is relieved from the cumbersome and potentially error-prone synchronization and locking tasks, and control applications are kept lightweight. In this paper, we also sketch a simple implementation of the transactional synchronization: our approach is based on fine-grained locking on network components and avoids complex state machine replication. © 2013 ACM.",Control plane; Network policy; Software defined network,Control applications; Control planes; Network policy; Policy compositions; Policy specification; Software-defined networks; State machine replication; Update semantics; Complex networks; Locks (fasteners); Semantics; Concurrency control
"Hong K., Lillethun D., Ramachandran U., OttenwŠlder B., Koldehofe B.",5,Mobile fog: A programming model for large-scale applications on the internet of things,2013,195,"College of Computing, Georgia Institute of Technology, Atlanta, GA, United States; Institute of Parallel and Distributed Systems, University of Stuttgart, Stuttgart, Germany",Georgia Tech;University of Stuttgart,2,Germany;USA,2,22,4,"The ubiquitous deployment of mobile and sensor devices is creating a new environment, namely the Internet of Things (IoT), that enables a wide range of future Internet applications. In this work, we present Mobile Fog, a high level programming model for future Internet applications that are geospatially distributed, large-scale, and latency-sensitive. We analyze use cases for the programming model with camera network and connected vehicle applications to show the efficacy of Mobile Fog. We also evaluate application performance through simulation. © 2013 ACM.",Cloud computing; Fog computing; Future internet applications; Internet of things; Programming model; Situation awareness applications,Application performance; Future internet; High-level programming models; Internet of thing (IOT); Internet of Things (IOT); Large-scale applications; Programming models; Situation awareness; Cloud computing; Fog; Internet; Mobile cloud computing; Sensors; Computer systems programming
"Lu Y., Zhou B., Tung L.-C., Gerla M., Ramesh A., Nagaraja L.",6,Energy-efficient content retrieval in mobile cloud,2013,26,"Computer Science Department, UCLA, Los Angeles, CA 90095, United States; EADP Data, Electronic Arts, United States",University of California Los Angeles,1,USA,1,13,11,"Mobile cloud computing (MCC) has recently been drawing increased attention in academia as well as industry. Content retrieval is a critical service, for many mobile cloud applications and in turns relies on other resources and tools, e.g., internal storage, content searching and sharing, etc. Previous studies have shown that conventional ICN interest query schemes and content searching architectures, if not properly designed, can cause significant performance degradation and energy consumption, especially for large scale MANETs. In this paper, we specifically address the scalability and energy efficiency of the content retrieval scheme in mobile cloud computing. We propose a direction-selective forwarding scheme for the content query method that decreases traffic overhead and energy cost caused by duplicate copies of the query packets. We also advocate the parallel search method of multiple caches to increase the hit rate. Simulation experiments show that the proposed scheme yields significant improvements in efficiency and scalability for the content retrieval in large scale MANETs. © 2013 ACM.",Content retrieval; Interest dissemination; Mobile cloud,Content retrieval; Content searching; Interest dissemination; Internal storage; Mobile cloud applications; Mobile clouds; Parallel search methods; Performance degradation; Energy efficiency; Energy utilization; Mobile ad hoc networks; Scalability; Mobile cloud computing
"Anwer B., Benson T., Feamster N., Levin D., Rexford J.",5,A slick control plane for network middleboxes,2013,47,"Georgia Tech., United States; Duke University, United States; University of Maryland, United States; Princeton University, United States",Duke University;Georgia Tech;Princeton University;University of Maryland College Park,4,USA,1,8,8,"We are delighted to welcome you to the second workshop on Hot Topics in Software Defined Networks (HotSDN). Software Defined Networking (SDN) refactors the relationship between network devices and the software that controls them. Open interfaces to network switches enable more flexible and predictable network control, and they make it easier to extend network function. Many research and industry groups worldwide are pursuing different aspects of SDN, and experimental and production deployments exist. The workshop program covers many of the open research challenges with SDN, including: how to design switches and APIs; how to design a software platform for the control and management of SDN; how to design new applications that capitalize on the programmability of the network; how to lower the barrier to creating, testing, and evaluating new applications; and many others. This year's Call for Papers attracted 84 submissions, up from 72 submissions last year. After reviewing the submissions, the Program Committee decided that there were simply too many high-quality papers for a one-day program, so we added a poster session to the program. In the end, we accepted 24 full papers in addition to 14 poster papers. We believe the result is a exciting and content-filled program that provides a snapshot of the state of the art in this new and exciting field. © 2013 ACM.",Middlebox; Network management; Software-defined networking,Control and management; High quality papers; Middleboxes; Research challenges; Software defined networking (SDN); Software platforms; Software-defined networkings; Software-defined networks; Design; Industrial research; Network management; Software testing; Application programs
Erickson D.,1,The Beacon OpenFlow controller,2013,199,"Stanford University, Stanford, CA, United States",Stanford University,1,USA,1,16,12,"Beacon is a Java-based open source OpenFlow controller created in 2010. It has been widely used for teaching, research, and as the basis of Floodlight. This paper describes the architectural decisions and implementation that achieves three of Beacon's goals: to improve developer productivity, to provide the runtime ability to start and stop existing and new applications, and to be high performance. © 2013 ACM.",Beacon; Controller; Java; OpenFlow,Architectural decision; Beacon; Java; New applications; Open sources; Openflow; Runtimes; Controllers; Electric lighting
"Zhu Y., Ma D., Huang D., Hu C.",4,Enabling secure location-based services in mobile cloud computing,2013,22,"Computer and Communication Engineering, University of Science and Technology Beijing, 30 Xueyuan Rd., Beijing 100083, China; Computer and Information Science, University of Michigan-Dearborn, 4901 Evergreen Rd, Dearborn, MI 48128, United States; Computing Informatics and Decision Systems Eng., Arizona State University, 699 S. Mill Avenue, Tempe, AZ 85281, United States",Arizona State University;University of Michigan-Dearborn;University of Science and Technology Beijing,3,China;USA,2,6,4,"The increasing spread of location-based services (LBSs) has led to a renewed research interest in the security of services. To ensure the credibility and availability of LBSs, there is a pressing requirement for addressing access control, authentication and privacy issues of LBSs in a synergistic way. In this paper, we propose an innovative location-based fine-grained access control mechanism for LBSs, enabling effective finegrained access control, location-based authentication and privacy protection. Our proposed approach is based on the construction of a spatio-temporal predicate-based encryption by means of efficient secure integer comparison. Our experimental results not only validate the effectiveness of our scheme, but also demonstrate that the proposed integer comparison scheme performs better than previous bitwise comparison scheme. © 2013 ACM.",Access control; Attribute-based encryption; Comparison mechanism; Location-based service; Mobile cloud,Access control mechanism; Attribute-based encryptions; Location based; Mobile clouds; Privacy issue; Privacy protection; Research interests; Spatio-temporal; Access control; Authentication; Cryptography; Encoding (symbols); Knowledge based systems; Location based services; Telecommunication services; Mobile cloud computing
"Wang J.M., Zhang J., Bensaou B.",3,Intra-AS cooperative caching for content-centric networks,2013,70,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, Hong Kong",Hong Kong University of Science and Technology,1,Hong Kong,1,23,14,"The default caching scheme in CCN results in a high redundancy along the symmetric request-response path, and makes the caching system ine cient. Since it was first proposed, much work has been done to improve the general caching performance of CCN. Most new caching schemes attempt to reduce the on-path redundancy by passing information on content redundancy and popularity between nodes. In this paper, we tackle the problem from a di erent perspective. Instead of curbing the redundancy through special caching decisions in the beginning, we take an orthogonal approach by pro-actively eliminating redundancy via an independent intra-AS procedure. We propose an intra-AS cache cooperation scheme, to e ectively control the redundancy level within the AS and allow neighbour nodes in an AS to collaborate in serving each other's requests. We show via trace-driven simulation, that intra-AS cache cooperation improves the system caching performance and reduces considerably the tra c load on the AS gateway links, which is very appealing from an ISP's perspective. Copyright © 2013 ACM.",Caching; Content centric network; Redundancy elimination,Caching; Caching decisions; Caching performance; Content-centric networks; Cooperative caching; High redundancy; Redundancy elimination; Trace driven simulation; Redundancy
"Stringer J.P., Fu Q., Lorier C., Nelson R., Rothenberg C.E.",5,Cardigan: Deploying a distributed routing fabric,2013,19,"Victoria University of Wellington, New Zealand; University of Waikato Hamilton, New Zealand; University of Campinas (UNICAMP), Brazil",University of Campinas;University of Waikato;Victoria University of Wellington,3,Brazil;New Zealand,2,18,18,"Hybrid Software-Defined Networking (SDN) systems are an active area for network research, with many organisations exploring the opportunities unlocked by the de-coupling of network control from packet forwarding. Previous work has suggested that a hybrid networking model will pave the way for migration towards SDN, through interoperability with legacy devices. However, questions remain over the operation of such systems in production environments. In order to explore the challenges of hybrid SDN systems and build operational confidence, we built a simple distributed router using OpenFlow and deployed it at a public Internet exchange. This implementation provides insights into the challenges involved with using these technologies, and suggests the viability of mixed device environments despite the limitations of early OpenFlow implementations. © 2013 ACM.",Distributed router; Network virtualization; OpenFlow,Distributed routers; Distributed routing; Network virtualization; Networking model; Openflow; Packet forwarding; Production environments; Software-defined networkings
"Huang T.-Y., Johari R., McKeown N.",3,Downton abbey without the hiccups: Buffer-based rate adaptation for HTTP video streaming,2013,69,"Stanford University, United States",Stanford University,1,USA,1,18,15,"Recent work has shown how hard it is to pick a video streaming rate. Video service providers use heuristics to estimate the network capacity leading to unnecessary rebuffering events and suboptimal video quality. This paper argues that we should do away with estimating network capacity, and instead directly observe and control the playback buffer. We present a class of rate selection algorithms that allow us to optimize the delivered video quality while provably never unnecessarily rebuffering. Our algorithms work with discrete video rates, video chunking and for both CBR and VBR video codecs. Copyright © 2013 ACM.",HTTP-based Video Streaming; Video Rate Adaptation Algorithm,Http video streaming; HTTP-based video streaming; Network Capacity; Rate adaptation; Selection algorithm; Video quality; Video rate adaptation; Video service providers; Algorithms; HTTP; Video streaming
"Heller B., Wundsam A., Handigol N., Scott C., Zeng H., McCauley J., McKeownt N., Whitlock S., Zarifis K., Shenker S., Jeyakumar V., Kazemian P.",12,Leveraging SDN layering to systematically troubleshoot networks,2013,38,"Stanford University, United States; UC Berkeley, United States; Big Switch Networks, United States; ICSI, United States; USC, United States",Stanford University;University of California Berkeley,2,USA,1,4,4,"Today's networks are maintained by ""masters of complexity"": network admins who have accumulated the wisdom to trou-bleshoot complex problems, despite a limiting toolset. This position paper advocates a more structured troubleshooting approach that leverages architectural layering in Software-Defined Networks (SDNs). In all networks, high-level intent (policy) must correctly map to low-level forwarding behavior (hardware configuration). In SDNs, intent is explicitly expressed, forwarding semantics are explicitly defined, and each architectural layer fully specifies the behavior of the network. Building on these observations, we show how recently-developed troubleshooting tools fit into a coherent workflow that detects mistranslations between layers to precisely localize sources of errant control logic. Our goals are to explain the overall picture, show how the pieces fit together to enable a systematic workflow, and highlight the questions that remain. Once this workflow is realized, network admins can formally verify that their network is operating correctly, automatically troubleshoot bugs, and systematically track down their root cause - freeing admins to fix problems, rather than diagnose their symptoms. © 2013 ACM.",Network architecture; OpenFlow; SDN; Software-defined networks; Troubleshooting,Architectural layers; Complex problems; Hardware configurations; Openflow; Position papers; SDN; Software-defined networks; Troubleshooting tools; Diagnosis; Network architecture; Semantics; Complex networks
"Nelson T., Guha A., Dougherty D.J., Fisler K., Krishnamurthi S.",5,"A balance of power: Expressive, analyzable controller programming",2013,20,"Worcester Polytechnic Institute, United States; Cornell University, United States; Brown University, United States",Brown University;Cornell University;Worcester Polytechnic Institute,3,USA,1,8,7,"Configuration languages for traditional network hardware are often fairly limited and hence easy to analyze. Programmable controllers for software-defined networks are far more flexible, but this flexibility results in more opportunities for mis-configuration and greatly complicates analyses. We propose a new network-programming paradigm that strikes a balance between expressive power and analysis, providing a highly analyzable core language while allowing the re-use of pre-existing code written in more complex production languages. As the first step we have created FlowLog, a declarative language for programming SDN controllers. We show that FlowLog is expressive enough to build some real controller programs. It is also a finite-state language, and thus amenable to many types of analysis, such as model-checking. In this paper we present FlowLog, show examples of controller programs, and discuss analyzing them. © 2013 ACM.",Network-programming languages; OpenFlow; Software-defined networks; Verification,Complex production; Configuration languages; Controller programs; Declarative Languages; Expressive power; Finite-state; Openflow; Software-defined networks; Verification; Model checking
"Kuzniart M., Pere_’nit P., Vasict N., Canini M., Kostic D.",5,Automatic failure recovery for software-defined networks,2013,25,"EPFL, Switzerland; TU Pere_’ni, Germany; Instute IMDEA Networks, Spain",TU Pere_’ni,1,Germany;Spain;Switzerland,3,27,22,"Tolerating and recovering from link and switch failures are fundamental requirements of most networks, including Software-Defined Networks (SDNs). However, instead of traditional behaviors such as network-wide routing reconvergence, failure recovery in an SDN is determined by the specific software logic running at the controller. While this admits more freedom to respond to a failure event, it ultimately means that each controller application must include its own recovery logic, which makes the code more difficult to write and potentially more error-prone. In this paper, we propose a runtime system that automates failure recovery and enables network developers to write simpler, failure-agnostic code. To this end, upon detecting a failure, our approach first spawns a new controller instance that runs in an emulated environment consisting of the network topology excluding the failed elements. Then, it quickly replays inputs observed by the controller before the failure occurred, leading the emulated network into the forwarding state that accounts for the failed elements. Finally, it recovers the network by installing the difference ruleset between emulated and current forwarding states. © 2013 ACM.",Fault tolerance; Software defined network,Automatic failure; Failed elements; Failure recovery; Forwarding state; Network topology; Re convergences; Runtime systems; Software-defined networks; Fault tolerance; Electric network topology
"Zhao T., Yang P., Pan H., Deng R., Zhou S., Niu Z.",6,Software defined radio implementation of signaling splitting in hyper-cellular network,2013,8,"Tsinghua National Laboratory for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing 100084, China",Tsinghua University,1,China,1,19,16,"This paper presents the design and implementation of signaling splitting scheme in hyper-cellular network on a software defined radio platform. Hyper-cellular network is a novel architecture of future mobile communication systems in which signaling and data are decoupled at the air interface to mitigate the signaling overhead and allow energy efficient operation of base stations. On an open source software defined radio platform, OpenBTS, we investigate the feasibility of signaling splitting for GSM protocol and implement a novel system which can prove the proposed concept. Standard GSM handsets can camp on the network with the help of signaling base station, and data base station will be appointed to handle phone calls on demand. Our work initiates the systematic approach to study hyper-cellular concept in real wireless environment with both software and hardware implementations. © 2013 ACM.",Hyper-cellular network; OpenBTS; Signaling splitting,Design and implementations; Energy efficient operations; Open Source Software; OpenBTS; Software and hardwares; Software-defined radio implementations; Software-defined radios; Wireless environment; Base stations; Energy efficiency; Hardware; Radio; Radio broadcasting; Software engineering; Software radio; Signaling
"Lee J., Kim C., Kim C.",3,Experimental implementation of asynchronous rendezvous protocols using microsoft sora,2013,0,"Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Pohang, South Korea",Pohang University of Science and Technology (POSTECH),1,South Korea,1,7,7,"In opportunistic networks, mobile devices can communicate with each other via connections between them that are not always available. After a device discovers another device in its transmission range, communication is enabled. Without any knowledge about geographical positions of mobile devices, neighbor discovery is energy consumption process. For example, continuous scanning is the fastest way to find neighbors but most mobile devices are battery-powered and cannot afford persistent scanning. So, neighbor discovery with minimal energy consumption is very important. Most neighbor discovery schemes adopt periodic sleep-wake scheduling associated with rendezvous capability. This means that each device just explores neighbors while they wake-up. Many rendezvous protocols have been proposed to reduce energy consumption. In this paper, we implement three promising asynchronous rendezvous protocols using Microsoft Research Software Radio (Sora) board and present the experimental results. Our experiment provides experimental insight into the implementation of rendezvous protocols in real situations. © 2013 ACM.",Neighbor discovery; Opportunistic networks; Protocols,Asynchronous rendezvous; Energy consumption process; Geographical positions; Microsoft researches; Neighbor discovery; Opportunistic networks; Reduce energy consumption; Sleep-wake scheduling; Energy utilization; Mobile devices; Network protocols; Wakes; Software radio
"Martins J., Ahmed M., Raiciu C., Huici F.",4,"Enabling fast, dynamic network processing with ClickOS",2013,29,"NEC Europe Ltd., Romania; University Politehnica of Bucharest, Romania",University Politehnica of Bucharest,1,Romania,1,14,10,"Middleboxes are both crucial to today's networks and ubiquitous, but embed knowledge of today's protocols and applications to the detriment of those of tomorrow, making the network harder to evolve. SDNs seek to make it easier to extend the network with new functionality, but most of the research effort has focused on the network's control plane, that is, how packets are switched are routed through a SDN. Given the pervasiveness and importance of middleboxes, we believe that a fully programmable network should also be able to dynamically instantiate and quickly move middlebox functionality. In this paper we shift focus towards making the data plane more programmable by introducing ClickOS, a tiny, Xen-based virtual machine that can run a wide range of middleboxes. ClickOS is small (5MB when running), can be instantiated in very small times (roughly 30 milliseconds) and can fill up a 10Gb pipe while concurrently running 128 vms on a low-cost commodity server. © 2013 ACM.",ClickOS; Middleboxes; NFV; SDN; Virtualization; Xen,ClickOS; Middleboxes; NFV; SDN; Virtualizations; Xen
"Mizrahi T., Moses Y.",2,Time-based updates in software defined networks,2013,28,"Technion - Israel Institute of Technology, Israel",Technion - Israel Institute of Technology,1,Israel,1,12,6,"Network configuration updates are a routine necessity, and must be performed in a way that minimizes transient effects caused by intermediate states of the network. This challenge is especially critical in Software Defined Networks, where the control plane is managed by a logically centralized controller, and configuration updates occur frequently. In this paper we discuss the tradeoff between maintaining consistency during configuration updates and the update performance. We introduce an approach that uses time to coordinate network configuration and reconfiguration. We show a simple time-based configuration approach called TIMECONF and show that this approach offers significant advantages over existing update approaches at the cost of a brief inconsistency. We also show that time can be used as a tool for simplifying existing update approaches without compromising consistency. © 2013 ACM.",Clock synchronization; Configuration; Management; SDN; Time,Centralized controllers; Clock Synchronization; Configuration; Intermediate state; Network configuration; SDN; Software-defined networks; Time; Management
"Fayazbakhsh S.K., Sekar V., Yu M., Mogul J.C.",4,FlowTags: Enforcing network-wide policies in the presence of dynamic middlebox actions,2013,102,"Stony Brook University, United States; USC, United States; Google Inc., United States",Google;Stony Brook University,2,USA,1,28,26,"Past studies show that middleboxes are a critical piece of network infrastructure for providing security and performance guarantees. Unfortunately, the dynamic and traffic-dependent modifications induced by middleboxes make it difficult to reason about the correctness of network-wide policy enforcement (e.g., access control, accounting, and performance diagnostics). Using practical application scenarios, we argue that we need a flow tracking capability to ensure consistent policy enforcement in the presence of such dynamic traffic modifications. To this end, we propose FlowTags, an extended SDN architecture in which middleboxes add Tags to outgoing packets, to provide the necessary causal context (e.g., source hosts or internal cache/miss state). These Tags are used on switches and (other) middleboxes for systematic policy enforcement. We discuss the early promise of minimally extending middleboxes to provide this support. We also highlight open challenges in the design of southbound and northbound FlowTags APIs; new control-layer applications for enforcing and verifying policies; and automatically modifying legacy middleboxes to support FlowTags. © 2013 ACM.",Middlebox; Network policy enforcement,Application scenario; Dynamic traffic; Middleboxes; Network infrastructure; Network policy; Performance diagnostics; Policy enforcement; Security and performance
"Chen J., Zhang S., Wang H., Zhang X.",4,Practicing a record-and-replay system on USRP,2013,1,"Shenzhen Key Lab. of Advanced Communications and Information Processing, College of Information and Engineering, Shenzhen University, Shenzhen, China; Corad Technology Inc., Shenzhen, China",Corad Technology Inc.;Shenzhen University,2,China,1,9,6,"Signal recording and replaying is widely used in data analysis, device test, etc. Motivated by this fact, our paper focuses on developing a low-cost record-and-replay prototype based on USRP (Universal Software Radio Peripheral). In particular, we designed and developed a GPS (Global Positioning System) record-and-replay system, which can sample the real GPS signal and then output the analog GPS signal to other devices with cable. In this prototype, we first design the record flow graph and the replay flow graph for USRP, which is verified in the FM band with the FM (Frequency Modulation) broadcasting. After that, we replace the passive antenna with one active antenna suit to amplify the small power GPS signal, lower the quantization bits to reduce the data rate in order to support the wide bandwidth of the GPS signal. Finally, our GPS record-and-replay system is tested and verified by a real GPS receiver. The good performance of our GPS record-and-replay system showed that USRPs can not only used in academia as experiment devices but also used in industry as low-cost wireless auxiliary devices. © 2013 ACM.",GPS; Record and replay; USRP,Active antennas; Auxiliary device; FM(frequency modulation); Gps (global positioning system); Record-and-replay; Signal recording; USRP; Wide bandwidth; Antennas; Cost benefit analysis; Flow graphs; Graphic methods; Quantization (signal); Software radio; Global positioning system
"Ion M., Zhang J., Schooler E.M.",3,Toward content-centric privacy in ICN: Attribute-based encryption and routing,2013,25,"University of Trento, CREATE-NET, Via Alla Cascata 56D, Trento, 38123, Italy; Intel Labs, 3600 Juliette Lane, Santa Clara, CA, 95054, United States",University of Trento,1,Italy;USA,2,20,16,"We design a content-centric privacy scheme for Information-Centric Networking (ICN). We enhance ICN's ability to support data confidentiality by introducing attribute-based encryption into ICN and making it specific to the data attributes. Our approach is unusual in that it preserves ICN's goal to decouple publishers and subscribers for greater data accessibility, scalable multiparty communication and efficient data distribution. Inspired by application-layer publish-subscribe, we enable fine-grained access control with more expressive policies. Moreover, we propose an attribute-based routing scheme that offers interest confidentiality. A prototype system is implemented based on CCNx, a popular open source version of ICN, to showcase privacy preservation in Smart Neighborhood and Smart City applications. Copyright © 2013 ACM.",Attribute-based encryption; ICN; Privacy; Security,Attribute-based encryptions; Data accessibility; Data confidentiality; ICN; Information-centric networkings (ICN); Multi-party communication; Privacy preservation; Security; Data privacy; Open systems; Cryptography
Song H.,1,Protocol-oblivious forwarding: Unleash the power of SDN through a future-proof forwarding plane,2013,144,"Huawei Technologies, Santa Clara, CA, 95050, United States",Huawei Technologies,1,USA,1,16,6,"A flexible and programmable forwarding plane is essential to maximize the value of Software-Defined Networks (SDN). In this paper, we propose Protocol-Oblivious Forwarding (POF) as a key enabler for highly flexible and programmable SDN. Our goal is to remove any dependency on protocol-specific configurations on the forwarding elements and enhance the data-path with new stateful instructions to support genuine software defined networking behavior. A generic flow instruction set (FIS) is defined to fulfill this purpose. POF helps to lower network cost by using commodity forwarding elements and to create new value by enabling numerous innovative network services. We built both hardware-based and open source software-based prototypes to demonstrate the feasibility and advantages of POF. We report the preliminary evaluation results and the insights we learnt from the experiments. POF is future-proof and expressive. We believe it represents a promising direction to evolve the OpenFlow protocol and the future SDN forwarding elements. © 2013 ACM.",Forwarding plane; OpenFlow; POF; SDN,Evaluation results; Forwarding planes; Network services; Openflow; POF; SDN; Software-defined networkings; Software-defined networks; Software engineering
"Kreutz D., Ramos F.M.V., Verissimo P.",3,Towards secure and dependable software-defined networks,2013,318,"LaSIGE/FCUL, University of Lisbon, Portugal",University of Lisbon,1,Portugal,1,7,6,"Software-defined networking empowers network operators with more flexibility to program their networks. With SDN, network management moves from codifying functionality in terms of low-level device configurations to building software that facilitates network management and debugging. By separating the complexity of state distribution from network specification, SDN provides new ways to solve long-standing problems in networking - routing, for instance - while simultaneously allowing the use of security and dependability techniques, such as access control or multi-path. However, the security and dependability of the SDN itself is still an open issue. In this position paper we argue for the need to build secure and dependable SDNs by design. As a first step in this direction we describe several threat vectors that may enable the exploit of SDN vulnerabilities. We then sketch the design of a secure and dependable SDN control platform as a materialization of the concept here advocated. We hope that this paper will trigger discussions in the SDN community around these issues and serve as a catalyser to join efforts from the networking and security & dependability communities in the ultimate goal of building resilient control planes. © 2013 ACM.",Controllers; Dependability; SDN; Security; Threat vectors,Building softwares; Dependability; Device configurations; SDN; Security; Software-defined networkings; Software-defined networks; State distributions; Complex networks; Controllers; Network management
"Durairajan R., Ghosh S., Tang X., Barford P., Eriksson B.",5,Internet atlas: A geographic database of the internet,2013,18,"University of Wisconsin-Madison, United States; Technicolor Research, United States","Technicolor, France;;University of Wisconsin-Madison",3,USA,1,12,11,"This paper describes Internet Atlas, a new visualization and analysis portal for diverse Internet measurement data. The starting point for Atlas is a geographically anchored representation of the physical Internet including (i) nodes (e.g., hosting facilities and data centers), (ii) conduits/links that connect these nodes, and (iii) relevant meta data (e.g., source provenance). This physical representation is built by using search to identify primary source data such as maps and other repositories of service provider network information. This data is then carefully entered into the database using a combination of manual and automated processes including consistency checks and methods for geocoding both node and link data. Atlas currently contains over 9.5K PoP locations and nearly 13.5K links for over 270 networks around the world. Customized interfaces were built to import a variety of dynamic (e.g., BGP updates, Twitter feeds and weather updates) and static (e.g., highway, rail and census) data into Atlas, and to layer it on top of the physical representation. The openly available web portal [1] is based on the widely-used ArcGIS geographic information system [19], which enables visualization and diverse spatial analyses of the data. We describe the details of the portal implementation as well as on-going efforts to expand its capabilities. © 2013 ACM.",Geographic database; Internet maps; Internet topology; Physical network connectivity,Geographic database; Internet maps; Internet measurement; Internet topologies; Physical network; Portal implementation; Service provider networks; Visualization and analysis; Automation; Data visualization; Database systems; Geographic information systems; Visualization; Internet
"Hu P., Li J., Lau W.C.",3,PIXS: Programmable intelligence for cross-platform socialization,2013,1,"Department of Information Engineering, Chinese University of Hong Kong, Hong Kong; Institute of Network Technology, Beijing University of Posts and Telecommunications, China",Beijing University of Posts and Telecommunications;Chinese University of Hong Kong,2,China;Hong Kong,2,32,30,"With the proliferation of the emerging Online Social Networks and other conventional communication services, there is an increasing need for a tool which can facilitate individual users to effectively socialize across multiple, heterogeneous platforms. While the diverse nature of the heterogeneous services already makes the design of a cross-platform socialization tool challenging, an even more daunting task is to tackle the ""noisy"" nature of the Social Networking Services (SNS). Existing solutions all lack flexibility and extensibility, especially in supporting advanced users to better manage their cross-platform socialization via customized information processing. In this paper, we propose PIXS (Programmable Intelligence for Cross-platform Socialization) - an open-source, extensible middleware which provides efficient information acquisition and dissemination across heterogeneous SNSs. A distinguishing feature of PIXS is its support of script-based operations. As a proof-of-concept to demonstrate the flexibility and effectiveness of PIXS, we have developed for it a Python-based semi-supervised learning application which can prioritize incoming messages from different platforms via a Rank Preserving Regression (RPR) framework. This framework can readily incorporate the domain knowledge of the end user. Our SGD-based approach also enables adaptive and incremental training of the ranking system according to the gradual evolution of the user preference. Performance evaluation based on real message traces shows that the proposed system can boost the user's efficiency in identifying and forwarding important messages across heterogeneous SNS platforms. Additional use-cases of PIXS are also discussed. © 2013 ACM.",Middleware; Personalization; Social Networking Services,Customized information; Heterogeneous platforms; Heterogeneous services; Information acquisitions; On-line social networks; Personalizations; Semi-supervised learning; Social networking services; Data processing; Information dissemination; Middleware; Social sciences; Supervised learning; Tools; Social networking (online)
"Liu L., Yin J., Gao L.",3,Efficient social network data query processing on MapReduce,2013,9,"UMass Amherst, United States",University of Massachusetts Amherst,1,USA,1,29,8,"Social network data analysis becomes increasingly important for business intelligence and online social services. Lots of social network data is presented by Resource Description Framework (RDF). Accordingly, SPARQL, an RDF query language, becomes popular for social network data analysis. As the sizes of social networks expand rapidly, a SPARQL query usually involves a large quantity of data, and thus parallelizing its execution is desirable. MapReduce is a well-known and popular big data analysis tool. However, the state-of-the-art translation from SPARQL queries to MapReduce jobs is not efficient because it mainly follows a two layer rule which needs to transform the SPARQL triple pattern to the standard SQL join. In this paper, we propose two primitives to enable efficient translation from SPARQL queries to MapReduce jobs. We use multiple-join-with-filter to substitute traditional SQL multiple join when feasible, and merge different stages in the query workflow. The evaluation on social network data benchmarks shows that the translation based on these two primitives can achieve up to 2x speedup in query running time comparing to the traditional two layer scheme. © 2013 ACM.",MapReduce; Query processing; RDF; SPARQL,Different stages; Map-reduce; RDF; RDF query language; Resource description framework; Social service; SPARQL; Sparql queries; Query processing; Social networking (online)
"Sammarco M., Campista M.E.M., De Amorim M.D.",3,Trace selection for improved WLAN monitoring,2013,2,"UPMC Sorbonne UniversitŽs, Paris, France; Universidade Federal do Rio de Janeiro, Rio de Janeiro, Brazil",UPMC Sorbonne UniversitŽs;Universidade Federal do Rio de Janeiro,2,Brazil;France,2,16,3,"Existing measurement techniques for IEEE 802.11-based networks assume that the higher the density of monitors in the target area, the higher the quality of the measure. This assumption is, however, too strict if we consider the cost involved in monitor installation and the necessary time to collect and merge all traces. In this paper, we investigate the balance between number of traces and completeness of collected data. We propose a method based on similarity to rank collected traces according to their contribution to the monitoring system. With this method, we are able to select only a subset of traces and still keep the quality of the measure, while improving system scalability. In addition, based on the same rank, we identify monitors that can be relocated to enlarge the monitored area and increase the overall efficiency of the system. Finally, our experimental results show that the proposed solution leads to a better tradeoff in terms of unique captured frames over the number of merge operations. © 2013 ACM.",IEEE 802.11; Measurement; Monitoring; Scalability; Wireless networks,Captured frame; IEEE 802.11-based networks; IEEE 802.11s; Improving systems; Measurement techniques; Merge operations; Monitoring system; Overall efficiency; Measurements; Monitoring; Standards; Wireless networks; Scalability
"Zhan L., Fu T.Z.J., Chiu D.M., Lei Z.",4,A framework for monitoring and measuring a large-scale distributed system in real time,2013,1,"Department of Information Engineering, Chinese University of Hong Kong, Hong Kong, Hong Kong; Applied Science Technology Research Institute (ASTRI), Hong Kong, Hong Kong",Chinese University of Hong Kong,1,Hong Kong,1,21,15,"Increasingly, Internet services are supported by a large-scale and distributed infrastructure on top of the Internet. This includes Content Delivery Networks (CDNs), Peer-to-peer (P2P) networks for content distribution, and more recently Cloud Computing built out of distributed data centers. Applications include Social networks (e.g. Facebook), content distribution and sharing (e.g. YouTube) and various location-based services and applications (e.g. Google Maps). To ensure proper operation and good QoE, these services need centralized monitoring and control of its operation. In this paper, we report our experience in building such a monitoring system. The key components include a reporting mechanism for capturing the system's state, and a visualization library to help administrator to keep track of how well the system is operating. We applied our monitoring system to support a P2P-assisted video streaming network for broadcasting the 2012 London Olympic Games in Hong Kong. We explain how our system keep track (in real time) of key performance numbers interested by the administrators, such as number of concurrent users, the average rate of contribution from different peers, and the QoE observed at different peer nodes, and illustrate various ways such information is visualized. © 2013 ACM.",Large-scale; Measurement; Monitoring; Realtime; Visualization,Content delivery network; Distributed infrastructure; Large-scale; Large-scale distributed system; Monitoring and control; Peer to Peer (P2P) network; Real time; Reporting mechanisms; Distributed computer systems; Flow visualization; Internet; Location based services; Measurements; Monitoring; Social networking (online); Telecommunication services; Video streaming; Visualization; Peer to peer networks
"Doerr C., Blenn N.",2,Metric convergence in social network sampling,2013,9,"TU Delft, Department of Intelligent Systems, 2628CD Delft, Netherlands",TU Delft,1,Netherlands,1,14,11,"While enabling new research questions and methodologies, the massive size of social media platforms also poses a significant issue for the analysis of these networks. In order to deal with this data volume, researchers typically turn to samples of these graph structures to conduct their analysis. This however raises the question about the representativeness of such limited crawls, and the amount of data necessary to come to stable predictions about the underlying systems. This paper analyzes the convergence of six commonly used topological metrics as a function of the crawling method and sample size used. We find that graph crawling methods drastically over- and underestimate network metrics, and that a non-trivial amount of data is needed to arrive at a stable estimate of the underlying network. © 2013 ACM.",Breadth-First-Search BFS; Data Quality; Depth-First-Search DFS; Metric Convergence; Social Network Analysis,Breadth-first-search; Data quality; Depth first search; Metric Convergence; Research questions; Social media platforms; Topological metrics; Underlying networks; Measurements; Social networking (online)
"Chabarek J., Barford P.",2,What's in a name? Decoding router interface names,2013,7,"University of Wisconsin, Madison, United States",University of Wisconsin-Madison,1,USA,1,15,8,"DNS names assigned to interfaces of network devices along an end-to-end path are an important source of information for both operations and research. Our study focuses on the interface DNS names that encode detailed information about the device e.g., interface type, bandwidth, manufacturer. In this paper we describe a methodology for discovering and characterizing the structure of diverse interface DNS names. We extract, organize and assess the details of the encoding used in different networks. The results of our analysis show that many different encodings are used, and that meaningful encodings are common in the core of the Internet. To enable interface DNS name decoding to be used in practice, we incorporate our information extraction library into a new version of traceroute that we call PathAudit. © 2013 ACM.",Active probing; Network measurement,Active probing; Encodings; End-to-end path; Network devices; Network measurement; Traceroute; Decoding; Encoding (symbols); Internet protocols
"Hess A., Ott J.",2,Extrapolating sparse large-scale GPS traces for contact evaluation,2013,2,"University of Vienna, Austria; Aalto University, Comnet, Finland",Aalto University;University of Vienna,2,Austria;Finland,2,12,8,"Human mobility traces are increasingly used for more realistic evaluation of mobile (opportunistic) communication systems. Although GPS traces yield the most detailed data sets, they are often limited in scale and may be incomplete since they are captured using mobile devices carried by volunteers. In this paper, we explore mechanisms to improve completeness and connectivity patterns of sparse GPS traces and assess their impact by means of the GeoLife data set. We also outline insights into geographic propagation that can be gained through these large-scale location measurements. © 2013 ACM.",Contact evaluation; Data sparsity; Mobility trace analytics,Connectivity pattern; Data set; Data sparsity; GPS traces; Human mobility; Location measurements; Mobility traces; Realistic evaluations; Measurements; Mobile devices
"Kamleitner B., Dickert S., Falahrastegar M., Haddadi H.",4,Information bazaar: A contextual evaluation,2013,3,"Vienna University of Economics and Business, Vienna, Austria; Queen Mary University of London, London, United Kingdom",Queen Mary University of London;Vienna University of Economics and Business,2,Austria;UK,2,20,13,"The rise in the number of smart devices has created a large ecosystem centred on users' personal information and online activities. Numerous smartphone applications and social networking sites harvest and catalogue users' personal information, enabling brokers such as Google and Facebook to provide a platform for advertisers to use this information for targeted advertising. Despite the fact that the users of these services are at the heart of this ecosystem, there has been little effort in understanding individuals' perception of the value of their personal data in different contexts and situations. In this work, we present the results of our large-scale, contextual study over ten days that used smartphones to collect data on user activities, location, and companionship, as well as the amount of money that individuals attach to such information. Our results indicate that people can be remarkably sensitive to situational cues and also be prone to valuation biases. This study represents a first step towards providing insights into the usefulness of a marketplace for information, where users, or their agents, can freely decide to auction off various pieces of their information within established contexts. © 2013 ACM.",Activity; Location; Price; Privacy,Online activities; Personal information; Price; Smart devices; Smart-phone applications; Social networking sites; Targeted advertising; User activity; Data privacy; Ecosystems; Location; Social networking (online); Thermodynamic properties; Information dissemination
"Moore R.S., Firner B., Xu C., Howard R., Martin R.P., Zhang Y.",6,It's tea time: Do you know where your mug is?,2013,2,"Computer Science Dept., Rutgers University, Piscataway, NJ, United States; WINLAB, Rutgers University, North Brunswick, NJ, United States",Rutgers University,1,USA,1,18,17,"The transition to Internet of Things depends on the ability to create small, simple applications that are easily written and can be flexibly combined into larger, more powerful systems. We have designed an infrastructure to meet this need and report on a year's experience expanding and using it in an open-plan academic office space with up to a hundred sensors enabling nearly a dozen applications ranging from announcing tea time in the break room, notifying users that the conference room is in use, to printing documents from a web-based map. Applications are simple to write, modular, easily reused, and can incorporate diverse data inputs in a heterogeneous sensing environment. We discuss our efforts to incrementally improve user interfaces and system management. © 2013 ACM.",Modularity; Reusability; Smart Building,Conference rooms; Data input; Heterogeneous sensing; Internet of Things (IOT); Modularity; Office space; Powerful systems; System management; Intelligent buildings; Office buildings; Reusability; User interfaces
"Striegel A., Liu S., Meng L., Poellabauer C., Hachen D., Lizardo O.",6,Lessons learned from the NetSense smartphone study,2013,27,"Department of Computer Science and Engineering, University of Notre Dame, United States; Department of Sociology, University of Notre Dame, United States",University of Notre Dame,1,USA,1,18,14,"Over the past few years, smartphones have emerged as one of the most popular mechanisms for accessing content across the Internet driving considerable research to improve wireless performance. A key foundation for such research efforts is the proper understanding of user behavior. However, the gathering of live smartphone data at scale is often difficult and expensive. The focus of this paper is to explore the lessons learned from a two year study of two hundred smart phone users at the University of Notre Dame. In this paper, we offer commentary with regards to the entire process of the study covering aspects including funding considerations, technical architecture design, lessons learned, and recommendations for future efforts gathering live user data. © 2013 ACM.",Cellular Networks; Smartphone; User Study; WiFi; Wireless,Cellular network; Research efforts; Technical architecture; University of Notre Dame; User behaviors; User data; User study; Radio; Signal encoding; Smartphones; Wi-Fi; Behavioral research
Zhang J.,1,Greedy forwarding for mobile social networks embedded in hyperbolic spaces,2013,1,"Department of Computer Science, Columbia University, New York, NY, United States",Columbia University,1,USA,1,9,7,"In this work, we design and evaluate a novel greedy forwarding algorithm using metrics in hyperbolic spaces. Hyperbolic geometry has a natural topological reflection of scale-free networks, and greedy algorithm failed in Euclidean space becomes possible in hyperbolic one. We show that mobile social networks can be successfully embedded in such spaces, and obtains competitive performance in terms of message delivery ratio and cost. Under this result, we thus intuitively reveal the fundamental reason that why the famous BUBBLE Rap achieves the optimal performance. © 2013 Author.",greedy forwarding; hyperbolic spaces; mobile social networks,Competitive performance; Greedy algorithms; Greedy forwarding; Hyperbolic geometry; Hyperbolic spaces; Mobile social networks; Optimal performance; Scale free networks; Algorithms; Communication; Geometry; Network architecture; Social networking (online); Computer architecture
"Liu Y., Liu J., Liu T., Guan X., Sun Y.",5,Security risks evaluation toolbox for smart grid devices,2013,2,"Ministry of Education Key Lab. for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China",Xian JiaoTong University,1,China,1,7,7,"Numerous smart devices are deployed in smart grid for state measurement, decision-making and remote control. The security issues of smart devices attract more and more attention. In our work, the communication protocol, storage mechanism and authentication of smart devices are analyzed and a toolbox is developed to evaluate the security risks of smart devices. In this demo, our toolbox is applied to scan 3 smart meters/power monitor systems. A potential risk list is generated and the vulnerabilities are further verified. © 2013 Authors.",security risk evaluation; smart device; smart grid,Monitor system; Potential risks; Security issues; Security risk evaluations; Smart devices; Smart grid; State measurements; Storage mechanism; Computer architecture; Network architecture; Smart power grids
"Wang X., Chen C., Li J.",3,Replication free rule grouping for packet classification,2013,0,"Department of Automation, Tsinghua University, Beijing, China; Research Institute of Information Technology, Tsinghua University, Beijing, China; Tsinghua National Lab. for Information Science and Technology, China",Tsinghua University,1,China,1,7,7,"Most recent works demonstrate that grouping methodology could bring significant reduction of memory usage to decision-tree packet classification algorithms, with insignificant impact on throughput. However, these grouping techniques can hardly eliminate rule-replication completely. This work proposes a novel rule grouping algorithm without any replication. At each space decomposition step, all rules projecting on the split dimension form the maximum number of non-overlapped ranges, which guarantees the modest memory usage and grouping speed. Evaluation shows that the proposed algorithm achieves comparable memory size with less pre-processing time. © 2013 Authors.",algorithms; packet classification; rule replication,Grouping algorithm; Grouping technique; Memory usage; Packet classification; Packet classification algorithm; Pre-processing; rule replication; Space decomposition; Algorithms; Communication; Computer architecture; Packet networks; Network architecture
"Jalaparti V., Bodik P., Kandula S., Menache I., Rybalkin M., Yan C.",6,Speeding up distributed request-response workflows,2013,32,"University of Illinois at Urbana-Champaign, Champaign, IL, United States; Microsoft Research, Redmond, WA, United States; St. Petersburg Department of Steklov Institute of Mathematics, Russian Academy of Sciences, St. Petersburg, Russian Federation; Microsoft Bing, Bellevue, WA, United States",Bellevue;Microsoft;Steklov Institute of Mathematics;UIUC,4,Russia;USA,2,5,4,"We found that interactive services at Bing have highly variable datacenter-side processing latencies because their processing consists of many sequential stages, parallelization across 10s-1000s of servers and aggregation of responses across the network. To improve the tail latency of such services, we use a few building blocks: reissuing laggards elsewhere in the cluster, new policies to return incomplete results and speeding up laggards by giving them more resources. Combining these building blocks to reduce the overall latency is non-trivial because for the same amount of resource (e.g., number of reissues), different stages improve their latency by different amounts. We present Kwiken, a framework that takes an end-to-end view of latency improvements and costs. It decomposes the problem of minimizing latency over a general processing DAG into a manageable optimization over individual stages. Through simulations with production traces, we show sizable gains; the 99th percentile of latency improves by over 50% when just 0.1% of the responses are allowed to have partial results and by over 40% for 25% of the services when just 5% extra resources are used for reissues. © 2013 ACM.",distributed services; incomplete results; interactive services; optimization; reissues; tail latency,Distributed service; incomplete results; Interactive services; reissues; tail latency; Communication; Computer architecture; Optimization; Network architecture
"Le Blond S., Choffnes D., Zhou W., Druschel P., Ballani H., Francis P.",6,Towards efficient traffic-analysis resistant anonymity networks,2013,15,"MPI-SWS, Kaiserslautern, Germany; University of Washington, Seattle, WA, United States; UIUC, Urbana-Champaign, IL, United States; Microsoft Research, Cambridge, United Kingdom; Northeastern University, Boston, United States",Microsoft;Northeastern University;UIUC;University of Washington at Seattle,4,Germany;UK;USA,3,4,4,"Existing IP anonymity systems tend to sacrifice one of low latency, high bandwidth, or resistance to traffic-analysis. High-latency mix-nets like Mixminion batch messages to resist traffic-analysis at the expense of low latency. Onion routing schemes like Tor deliver low latency and high bandwidth, but are not designed to withstand traffic analysis. Designs based on DC-nets or broadcast channels resist traffic analysis and provide low latency, but are limited to low bandwidth communication. In this paper, we present the design, implementation, and evaluation of Aqua, a high-bandwidth anonymity system that resists traffic analysis. We focus on providing strong anonymity for BitTorrent, and evaluate the performance of Aqua using traces from hundreds of thousands of actual BitTorrent users. We show that Aqua achieves latency low enough for efficient bulk TCP flows, bandwidth sufficient to carry BitTorrent traffic with reasonable efficiency, and resistance to traffic analysis within anonymity sets of hundreds of clients. We conclude that Aqua represents an interesting new point in the space of anonymity network designs. © 2013 ACM.",anonymity networks; p2p file sharing; strong anonymity,Anonymity networks; Anonymity sets; Broadcast channels; High bandwidth; Low-bandwidth communications; P2P file sharing; strong anonymity; Traffic analysis; Bandwidth; Communication; Computer architecture; Design; Distributed computer systems; Network security; Telecommunication systems; Transmission control protocol; Network architecture
"Voellmy A., Wang J., Yang Y.R., Ford B., Hudak P.",5,Maple: Simplifying SDN programming using algorithmic policies,2013,64,"Yale University, New Haven, CT, United States; University of Science and Technology of China, China",University of Science and Technology of China;Yale University,2,China;USA,2,30,26,"Software-Defined Networking offers the appeal of a simple, centralized programming model for managing complex networks. However, challenges in managing low-level details, such as setting up and maintaining correct and efficient forwarding tables on distributed switches, often compromise this conceptual simplicity. In this pa- per, we present Maple, a system that simplifies SDN programming by (1) allowing a programmer to use a standard programming language to design an arbitrary, centralized algorithm, which we call an algorithmic policy, to decide the behaviors of an entire network, and (2) providing an abstraction that the programmer-defined, centralized policy runs, conceptually, ""afresh"" on every packet entering a network, and hence is oblivious to the challenge of translating a high-level policy into sets of rules on distributed individual switches. To implement algorithmic policies efficiently, Maple includes not only a highly-efficient multicore scheduler that can scale efficiently to controllers with 40+ cores, but more importantly a novel tracing runtime optimizer that can automatically record reusable policy decisions, offload work to switches when possible, and keep switch flow tables up-to-date by dynamically tracing the dependency of policy decisions on packet contents as well as the environment (system state). Evaluations using real HP switches show that Maple optimizer reduces HTTP connection time by a factor of 100 at high load. During simulated benchmarking, Maple scheduler, when not running the optimizer, achieves a throughput of over 20 million new flow requests per second on a single machine, with 95-percentile latency under 10 ms. © 2013 ACM.",algorithmic policies; openflow; software-defined networking,Centralized algorithms; Centralized programming model; Conceptual simplicity; Forwarding tables; High level policies; Openflow; Software-defined networkings; Standard programming language; Algorithms; Communication; Computer architecture; Decision making; Network architecture; Program translators; Scheduling; Time switches; Distributed computer systems
"Nandakumar R., Chintalapudi K.K., Padmanabhan V., Venkatesan R.",4,Dhwani: Secure peer-to-peer acoustic NFC,2013,32,"Microsoft Research India, Bangalore, India",Microsoft,1,India,1,33,20,"Near Field Communication (NFC) enables physically proximate devices to communicate over very short ranges in a peer-to-peer manner without incurring complex network configuration overheads. However, adoption of NFC-enabled applications has been stymied by the low levels of penetration of NFC hardware. In this paper, we address the challenge of enabling NFC-like capability on the existing base of mobile phones. To this end, we develop Dhwani, a novel, acoustics-based NFC system that uses the microphone and speakers on mobile phones, thus eliminating the need for any specialized NFC hardware. A key feature of Dhwani is the JamSecure technique, which uses self-jamming coupled with self-interference cancellation at the receiver, to provide an information-theoretically secure communication channel between the devices. Our current implementation of Dhwani achieves data rates of up to 2.4 Kbps, which is sufficient for most existing NFC applications. © 2013 ACM.",nfc; security; wireless,Key feature; Near field communications; Network configuration; nfc; Peer to peer; Secure communication channels; security; Self-interferences; Cellular telephones; Communication systems; Computer architecture; Hardware; Mobile devices; Mobile phones; Network architecture; Radio; Computer hardware
"Grosvenor M.P., Schwarzkopf M., Moore A.W.",3,"R2D2: Bufferless, switchless data center networks using commodity ethernet hardware",2013,0,"University of Cambridge, Computer Laboratory, Cambridge, United Kingdom",University of Cambridge,1,UK,1,24,19,"Modern data centers commonly run distributed applications that require low-latency communication, and whose performance is critical to service revenue. If as little as one machine in 10,000 is a latency outlier, around 18% of requests will experience high latency. The sacrifice of latency determinism for bandwidth, however, is not an inevitable one. In our R2D2 architecture, we conceptually split the data centre network into an unbuffered, unswitched low-latency network (LLNet) and a deeply buffered bandwidth centric network (BBNet). Through explicitly scheduling network multiplexing in software, our prototype implementation achieves 99.995% and 99.999% messaging latencies of 35us and 75us respectively for 1514-byte packets on a fully loaded network. Furthermore, we show that it is possible to merge the conceptually separate LLNet and BBNet networks onto the same physical infrastructure using commodity switched Ethernet hardware. © 2013 Authors.",broadcast; data centers; ethernet; latency; scheduling,Buffered bandwidth; Data center networks; Data centers; Distributed applications; latency; Low-latency communication; Low-latency networks; Prototype implementations; Broadcasting; Communication; Computer architecture; Computer hardware; Ethernet; Hardware; Scheduling; Software prototyping; Network architecture
"Han D., Grandl R., Akella A., Seshan S.",4,FCP: A flexible transport framework for accommodating diversity,2013,11,"Korea Advanced Institute of Science and Technology, Daejon, South Korea; University of Wisconsin-Madison, Madison, WI, United States; Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University;KAIST;;University of Wisconsin-Madison,4,South Korea;USA,2,21,16,"Transport protocols must accommodate diverse application and network requirements. As a result, TCP has evolved over time with new congestion control algorithms such as support for generalized AIMD, background flows, and multipath. On the other hand, explicit congestion control algorithms have been shown to be more efficient. However, they are inherently more rigid because they rely on in-network components. Therefore, it is not clear whether they can be made flexible enough to support diverse application requirements. This paper presents a flexible framework for network resource allocation, called FCP, that accommodates diversity by exposing a simple abstraction for resource allocation. FCP incorporates novel primitives for end-point flexibility (aggregation and preloading) into a single framework and makes economics-based congestion control practical by explicitly handling load variations and by decoupling it from actual billing. We show that FCP allows evolution by accommodating diversity and ensuring coexistence, while being as efficient as existing explicit congestion control algorithms. © 2013 ACM.",congestion control; end-point flexibility; transport protocol,Background flow; Diverse applications; End points; Explicit congestion controls; Flexible framework; Network requirements; Network resource allocations; Transport protocols; Algorithms; Communication; Computer architecture; Congestion control (communication); Economics; Point contacts; Queueing networks; Resource allocation; Transmission control protocol; Network architecture
"Xia N., Song H.H., Liao Y., Iliofotou M., Nucci A., Zhang Z.-L., Kuzmanovic A.",7,Mosaic: Quantifying privacy leakage in mobile networks,2013,15,"Northwestern University, Evanston, IL, United States; Narus Inc., Sunnyvale, CA, United States; University of Minnesota, Minneapolis, MN, United States",Narus Inc.;Northwestern University;University of Minnesota,3,USA,1,12,11,"With the proliferation of online social networking (OSN) and mobile devices, preserving user privacy has become a great challenge. While prior studies have directly focused on OSN services, we call attention to the privacy leakage in mobile network data. This concern is motivated by two factors. First, the prevalence of OSN usage leaves identifiable digital footprints that can be traced back to users in the real-world. Second, the association between users and their mobile devices makes it easier to associate traffic to its owners. These pose a serious threat to user privacy as they enable an adversary to attribute significant portions of data traffic including the ones with NO identity leaks to network users' true identities. To demonstrate its feasibility, we develop the Tessellation methodology. By applying Tessellation on traffic from a cellular service provider (CSP), we show that up to 50% of the traffic can be attributed to the names of users. In addition to revealing the user identity, the reconstructed profile, dubbed as ""mosaic,"" associates personal information such as political views, browsing habits, and favorite apps to the users. We conclude by discussing approaches for preventing and mitigating the alarming leakage of sensitive user information. © 2013 ACM.",mobile network; online social network; privacy; security; user profile,Cellular services; On-line social networks; Online social networkings (OSN); Personal information; Privacy leakages; security; User information; User profile; Communication; Computer architecture; Data privacy; Mobile devices; Mobile telecommunication systems; Social networking (online); Wireless networks; Network architecture
"Shen W.-L., Lin K.C.-J., Chen M.-S.",3,An empirical study of analog channel feedback,2013,0,"Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taiwan",National Taiwan University,1,Taiwan,1,52,29,"Exchanging the channel state information (CSI) in a multiuser WLAN is considered an extremely expensive overhead. A possible solution to reduce the overhead is to notify the analog value of the CSI, which is also known as analog channel feedback. It however only allows nodes to overhear an imperfect channel information. While some previous studies have theoretically analyzed the performance of analog channel feedback, this work aims at addressing issues of realizing it in practice and empirically demonstrating its effectiveness. Our prototype implementation using USRP-N200 shows that analog channel feedback produces a small error comparable to that of estimating CSI using reciprocity, but however can be applied to more general scenarios. © 2013 Authors.",analog channel feedback; mimo,Analog channels; Analog values; Empirical studies; Imperfect channel informations; Multi-user; Prototype implementations; Communication; Computer architecture; MIMO systems; Network architecture; Channel state information
"Chen Y., Mahajan R., Sridharan B., Zhang Z.-L.",4,A provider-side view of web search response time,2013,14,"Microsoft Corporation, Redmond, WA, United States; University of Minnesota - Twin Cities, Minneapolis, MN, United States",Microsoft;University of Minnesota Twin Cities,2,USA,1,31,28,"Using a large Web search service as a case study, we highlight the challenges that modern Web services face in understanding and diagnosing the response time experienced by users. We show that search response time (SRT) varies widely over time and also exhibits counter-intuitive behavior. It is actually higher during off-peak hours, when the query load is lower, than during peak hours. To resolve this paradox and explain SRT variations in general, we develop an analysis framework that separates systemic variations due to periodic changes in service usage and anomalous variations due to unanticipated events such as failures and denial-of-service attacks. We find that systemic SRT variations are primarily caused by systemic changes in aggregate network characteristics, nature of user queries, and browser types. For instance, one reason for higher SRTs during off-peak hours is that during those hours a greater fraction of queries come from slower, mainly-residential networks. We also develop a technique that, by factoring out the impact of such variations, robustly detects and diagnoses performance anomalies in SRT. Deployment experience shows that our technique detects three times more true (operator-verified) anomalies than existing techniques. © 2013 ACM.",anomaly detection and diagnosis; performance monitoring; search response time; web services,Analysis frameworks; Anomaly detection; Denial of service attacks; Network characteristics; Performance anomaly; Performance monitoring; Periodic changes; Service usage; Communication; Computer architecture; Information retrieval; Web services; Websites; Network architecture
"Dietrich D., Rizk A., Papadimitriou P.",3,AutoEmbed: Automated multi-provider virtual network embedding,2013,3,"Leibniz UniversitŠt Hannover, Hannover, Germany",Leibniz University of Hannover,1,Germany,1,3,3,"We present AutoEmbed, a fully-automated framework for VN embedding across multiple substrate networks. To automate VN embedding, AutoEmbed deploys functions over three layers: (i) Service Providers, (ii) VN Providers, and (iii) Infrastructure Providers (InPs). AutoEmbed enables VN Providers to partition VN requests among multiple substrate networks based on resource and network topology information that is not treated as confidential by InPs. Subsequently, each VN segment is mapped by the corresponding InP onto its substrate network. AutoEmbed enables the evaluation of various aspects of multi-provider VN embedding, such as the efficiency and scalability of embedding algorithms, the impact of different levels of information disclosure on VN embedding efficiency, and the suitability of VN request specifications. © 2013 Authors.",network virtualization; performance evaluation; resource assignment,Embedding algorithms; Embedding efficiency; Information disclosure; Infrastructure providers; Network virtualization; performance evaluation; Resource assignment; Virtual network embedding; Communication; Computer architecture; Electric network topology; Network architecture
"Roy S., Feamster N.",2,Characterizing correlated latency anomalies in broadband access networks,2013,5,"School of Computer Science, Georgia Tech., Atlanta, GA, United States",Georgia Tech,1,USA,1,34,22,"The growing prevalence of broadband Internet access around the world has made understanding the performance and reliability of broadband access networks extremely important. To better understand the performance anomalies that arise in broadband access networks, we have deployed hundreds of routers in home broadband access networks around the world and are studying the performance of these networks. One of the performance pathologies that we have observed is correlated, sudden latency increases simultaneously and to multiple destinations. In this work, we provide an preliminary glimpse into these sudden latency increases and attempt to understand their causes. Although we do not isolate root cause in this study, observing the sets of destinations that experience correlated latency increases can provide important clues as to the locations in the network that may be inducing these pathologies. We present an algorithm to better identify the network locations that are likely responsible for these pathologies. We then analyze latency data from one month across our home router deployment to determine where in the network latency issues are arising, and how those pathologies differ across regions, ISPs, and countries. Our preliminary analysis suggests that most latency pathologies are to a single destination and a relatively small percentage of these pathologies are likely in the last mile, suggesting that peering within the network may be a more likely culprit for these pathologies than access link problems. © 2013 Authors.",active probing; measurement; performance,Active probing; Broad-band access networks; Broadband internet access; Multiple destinations; performance; Performance and reliabilities; Performance anomaly; Preliminary analysis; Communication; Computer architecture; Measurements; Pathology; Routers; Network architecture
"Fayazbakhsh S.K., Lin Y., Tootoonchian A., Ghodsi A., Koponen T., Maggs B., Ng K.C., Sekar V., Shenker S.",9,"Less pain, most of the gain: Incrementally deployable ICN",2013,110,"Stony Brook University, Stony Brook, NY, United States; Duke University, Durham, United States; University of Toronto, Toronto, ON, Canada; ICSI, United States; UC Berkeley, Berkeley, CA, United States; KTH, United States; VMware, San Francisco, CA, United States; Akamai, Cambridge, United States",Duke University;Stony Brook University;University of California Berkeley;University of Toronto,4,Canada;USA,2,8,6,"Information-Centric Networking (ICN) has seen a significant resurgence in recent years. ICN promises benefits to users and service providers along several dimensions (e.g., performance, security, and mobility). These benefits, however, come at a non-trivial cost as many ICN proposals envision adding significant complexity to the network by having routers serve as content caches and support nearest-replica routing. This paper is driven by the simple question of whether this additional complexity is justified and if we can achieve these benefits in an incrementally deployable fashion. To this end, we use trace-driven simulations to analyze the quantitative benefits attributed to ICN (e.g., lower latency and congestion). Somewhat surprisingly, we find that pervasive caching and nearest-replica routing are not fundamentally necessary - -most of the performance benefits can be achieved with simpler caching architectures. We also discuss how the qualitative benefits of ICN (e.g., security, mobility) can be achieved without any changes to the network. Building on these insights, we present a proof-of-concept design of an incrementally deployable ICN architecture. © 2013 ACM.",information-centric networking; internet architecture,Caching architecture; Information-centric networkings; Information-centric networkings (ICN); Internet architecture; Performance benefits; Proof-of-concept design; Quantitative benefits; Trace driven simulation; Communication; Complex networks; Computer architecture; Network architecture
"Hua Y., Liu X., Feng D.",3,Smart in-network deduplication for storage-aware SDN,2013,4,"WNLO, School of Computer, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science, McGill University, Montreal, QC, Canada",Huazhong University of Science and Technology;McGill University,2,Canada;China,2,2,1,"In order to efficiently handle the rapid growth of data and reduce the overhead of network transmission, we propose an in-network deduplication for storage-aware Software Defined Network (SDN), called SMIND. Unlike conventional source or destination deduplication schemes, SMIND implements in-network deduplication via SDN. Moreover, to address the performance bottleneck of accessing and indexing SDN controller, we implement an SDN-enabled Flash Translation Layer (FTL) in a real prototype of Solid State Disk (SSD). Experimental results demonstrate the efficiency and efficacy of SMIND. © 2013 Authors.",deduplication; software defined network; storage systems,De duplications; Flash translation layer; Network transmission; Performance bottlenecks; Rapid growth; Software-defined networks; Solid state disks (SSD); Storage systems; Communication; Computer architecture; Data storage equipment; Network architecture
"Wang L., Bayhan S., Kangasharju J.",3,Cooperation policies for efficient in-network caching,2013,0,"University of Helsinki, Helsinki, Finland; HIIT, Aalto University, Helsinki, Finland",Aalto University;University of Helsinki,2,Finland,1,53,34,"Caching is a key component of information-centric networking, but most of the work in the area focuses on simple en-route caching with limited cooperation between the caches. In this paper we model cache cooperation under a game theoretical framework and show how cache cooperation policy can allow the system to converge to a Pareto optimal configuration. Our work shows how cooperation impacts network caching performance and how it takes advantage of the structural properties of the underlying network. © 2013 Authors.",cooperative caching; game theory; in-network caching,Cooperative caching; En-route; Game-theoretical framework; In networks; Information-centric networkings; Network caching; Pareto-optimal configurations; Underlying networks; Communication; Computer architecture; Game theory; Network architecture
"Qazi Z.A., Lee J., Jin T., Bellala G., Arndt M., Noubir G.",6,Application-awareness in SDN,2013,26,"Stony Brook University, Stony Brook, NY, United States; HP Labs., Palo Alto, CA, United States; Qualcomm Research, San Diego, CA, United States; HP Networking, Sacramento, CA, United States; Northeastern University, Boston, MA, United States",HP Labs;Northeastern University;Qualcomm Research;Stony Brook University,4,USA,1,5,4,"We present a framework, Atlas, which incorporates application-awareness into Software-Defined Networking (SDN), which is currently capable of L2/3/4-based policy enforcement but agnostic to higher layers. Atlas enables fine-grained, accurate and scalable application classification in SDN. It employs a machine learning (ML) based traffic classification technique, a crowd-sourcing approach to obtain ground truth data and leverages SDN's data reporting mechanism and centralized control. We prototype Atlas on HP Labs wireless networks and observe 94% accuracy on average, for top 40 Android applications. © 2013 Authors.",application awareness; software-defined networking (sdn),Android applications; Application awareness; Application classifications; Centralized control; Ground truth data; Policy enforcement; Software-defined networkings; Traffic classification; Communication; Network architecture; Telecommunication traffic; Computer architecture
"Lychev R., Goldberg S., Schapira M.",3,BGP security in partial deployment: Is the juice worth the squeeze?,2013,22,"Georgia Tech., Atlanta, GA, United States; Boston University, Boston, MA, United States; Hebrew University, Jerusalem, Israel",Boston University;Georgia Tech;Hebrew University of Jerusalem,3,Israel;USA,2,5,5,"As the rollout of secure route origin authentication with the RPKI slowly gains traction among network operators, there is a push to standardize secure path validation for BGP (i.e., S*BGP: S-BGP, soBGP, BGPSEC, etc.). Origin authentication already does much to improve routing security. Moreover, the transition to S*BGP is expected to be long and slow, with S*BGP coexisting in ""partial deployment"" alongside BGP for a long time. We therefore use theoretical and experimental approach to study the security benefits provided by partially-deployed S*BGP, vis-a-vis those already provided by origin authentication. Because routing policies have a profound impact on routing security, we use a survey of 100 network operators to find the policies that are likely to be most popular during partial S*BGP deployment. We find that S*BGP provides only meagre benefits over origin authentication when these popular policies are used. We also study the security benefits of other routing policies, provide prescriptive guidelines for partially-deployed S*BGP, and show how interactions between S*BGP and BGP can introduce new vulnerabilities into the routing system. © 2013 ACM.",bgp; partial deployment; routing; security,bgp; Experimental approaches; Network operator; Origin authentications; Partial deployment; routing; Routing policies; security; Authentication; Communication; Computer architecture; Network architecture
"Wang K., Li J.",2,Towards fast regular expression matching in practice,2013,2,"Department of Automation, Tsinghua University, Beijing, 10084, China; Research Institute of Information Technology, Tsinghua University, Beijing, 10084, China; Tsinghua National Lab. for Information Science and Technology, Beijing, 10084, China",Research Institute of Information Technology;Tsinghua University,2,China,1,3,2,"Regular expression matching is popular in today's network devices with deep inspection function, but due to lack of algorithmic scalability, it is still the performance bottleneck in practical network processing. To address this problem, our method first partition regular expression patterns into simple segments to avoid state explosion, and then compile these segments into a compact data structure to achieve fast matching. Preliminary experiments illustrate that our matching engine scales linearly with the size of the real-world pattern set, and outperforms state-of-the-art solutions. © 2013 Authors.",deep inspection; dfa; regular expression matching,Compact data structure; Deep inspection; dfa; Matching engines; Performance bottlenecks; Practical networks; Regular expressions; Regular-expression matching; Communication; Computer architecture; Network architecture; Pattern matching
"Balachandran A., Sekar V., Akella A., Seshan S., Stoica I., Zhang H.",6,Developing a predictive model of quality of experience for internet video,2013,121,"Carnegie Mellon University, Pittsburgh, PA, United States; University of Wisconsin-Madison, Madison, WI, United States; Stony Brook University, Stony Brook, NY, United States; University of California, Berkeley, Berkeley, CA, United States",Carnegie Mellon University;Stony Brook University;University of California Berkeley;;University of Wisconsin-Madison,5,USA,1,46,37,"Improving users' quality of experience (QoE) is crucial for sustaining the advertisement and subscription based revenue models that enable the growth of Internet video. Despite the rich literature on video and QoE measurement, our understanding of Internet video QoE is limited because of the shift from traditional methods of measuring video quality (e.g., Peak Signal-to-Noise Ratio) and user experience (e.g., opinion scores). These have been replaced by new quality metrics (e.g., rate of buffering, bitrate) and new engagement centric measures of user experience (e.g., viewing time and number of visits). The goal of this paper is to develop a predictive model of Internet video QoE. To this end, we identify two key requirements for the QoE model: (1) it has to be tied in to observable user engagement and (2) it should be actionable to guide practical system design decisions. Achieving this goal is challenging because the quality metrics are interdependent, they have complex and counter-intuitive relationships to engagement measures, and there are many external factors that confound the relationship between quality and engagement (e.g., type of video, user connectivity). To address these challenges, we present a data-driven approach to model the metric interdependencies and their complex relationships to engagement, and propose a systematic framework to identify and account for the confounding factors. We show that a delivery infrastructure that uses our proposed model to choose CDN and bitrates can achieve more than 20\% improvement in overall user engagement compared to strawman approaches. © 2013 ACM.",human factors; measurement; peformance; video quality,Complex relationships; Data-driven approach; Peak signal-to-noise ratio; peformance; Predictive modeling; Quality of experience (QoE); Systematic framework; Video quality; Communication; Computer architecture; Human computer interaction; Human engineering; Internet; Measurements; Network architecture; Quality of service
"Alizadeh M., Yang S., Sharif M., Katti S., McKeown N., Prabhakar B., Shenker S.",7,pFabric: Minimal near-optimal datacenter transport,2013,171,"Stanford University, Stanford, CA, United States; Insieme Networks, United States; U.C. Berkeley, ICSI, Berkeley, CA, United States",Stanford University,1,USA,1,5,3,"In this paper we present pFabric, a minimalistic datacenter transport design that provides near theoretically optimal flow completion times even at the 99th percentile for short flows, while still minimizing average flow completion time for long flows. Moreover, pFabric delivers this performance with a very simple design that is based on a key conceptual insight: datacenter transport should decouple flow scheduling from rate control. For flow scheduling, packets carry a single priority number set independently by each flow; switches have very small buffers and implement a very simple priority-based scheduling/dropping mechanism. Rate control is also correspondingly simpler; flows start at line rate and throttle back only under high and persistent packet loss. We provide theoretical intuition and show via extensive simulations that the combination of these two simple mechanisms is sufficient to provide near-optimal performance. © 2013 ACM.",datacenter network; flow scheduling; packet transport,Data center networks; Extensive simulations; Flow scheduling; Near-optimal performance; packet transport; Priority number; Priority-based scheduling; Transport design; Communication; Computer architecture; Optimization; Scheduling; Network architecture
"Han S., Liu V., Pu Q., Peter S., Anderson T., Krishnamurthy A., Wetherall D.",7,Expressive privacy control with pseudonyms,2013,6,"University of Washington, Seattle, WA, United States",University of Washington at Seattle,1,USA,1,41,26,"As personal information increases in value, the incentives for remote services to collect as much of it as possible increase as well. In the current Internet, the default assumption is that all behavior can be correlated using a variety of identifying information, not the least of which is a user's IP address. Tools like Tor, Privoxy, and even NATs, are located at the opposite end of the spectrum and prevent any behavior from being linked. Instead, our goal is to provide users with more control over linkability - -which activites of the user can be correlated at the remote services - -not necessarily more anonymity. We design a cross-layer architecture that provides users with a pseudonym abstraction. To the user, a pseudonym represents a set of activities that the user is fine with linking, and to the outside world, a pseudonym gives the illusion of a single machine. We provide this abstraction by associating each pseudonym with a unique, random address drawn from the IPv6 address space, which is large enough to provide each device with multiple globally-routable addresses. We have implemented and evaluated a prototype that is able to provide unlinkable pseudonyms within the Chrome web browser in order to demonstrate the feasibility, efficacy, and expressiveness of our approach. © 2013 ACM.",ipv6; privacy; pseudonym; web tracking,Cross-layer architecture; ipv6; Ipv6 address; Personal information; Privacy control; pseudonym; Remote services; Single- machines; Abstracting; Communication; Data privacy; Internet protocols; Network architecture; Computer architecture
"Pu Q., Jiang S., Gollakota S.",3,Whole-home gesture recognition using wireless signals (demo),2013,14,"University of Washington, Seattle, WA, United States",University of Washington at Seattle,1,USA,1,22,17,"This demo presents WiSee, a novel human-computer interaction system that leverages wireless networks (e.g., Wi-Fi), to enable sensing and recognition of human gestures and motion. Since wire- less signals do not require line-of-sight and can traverse through walls, WiSee enables novel human-computer interfaces for remote device control and building automation. Further, it achieves this goal without requiring instrumentation of the human body with sensing devices. We integrate WiSee with applications and demonstrate how WiSee enables users to use gestures and control applications including music players and gaming systems. Specifically, our demo will allow SIGCOMM attendees to control a music player and a lighting control device using gestures. © 2013 Authors.",gestures; user interface; wireless,Building automation; Control applications; gestures; Human computer interfaces; Human-computer interaction system; Lighting controls; Sensing devices; Wireless signals; Communication; Gesture recognition; Intelligent buildings; Network architecture; Radio; Sensors; User interfaces; Computer architecture
"Liu H.H., Wu X., Zhang M., Yuan L., Wattenhofer R., Maltz D.",6,zUpdate: Updating data center networks with zero loss,2013,83,"Yale University, New Haven, CT, United States; Duke University, Durham, NC, United States; Microsoft Research, Redmond, WA, United States",Duke University;Microsoft;Yale University,3,USA,1,27,22,"Datacenter networks (DCNs) are constantly evolving due to various updates such as switch upgrades and VM migrations. Each update must be carefully planned and executed in order to avoid disrupting many of the mission-critical, interactive applications hosted in DCNs. The key challenge arises from the inherent difficulty in synchronizing the changes to many devices, which may result in unforeseen transient link load spikes or even congestions. We present one primitive, zUpdate, to perform congestion-free network updates under asynchronous switch and traffic matrix changes. We formulate the update problem using a network model and apply our model to a variety of representative update scenarios in DCNs. We develop novel techniques to handle several practical challenges in realizing zUpdate as well as implement the zUpdate prototype on OpenFlow switches and deploy it on a testbed that resembles real DCN topology. Our results, from both real-world experiments and large-scale trace-driven simulations, show that zUpdate can effectively perform congestion-free updates in production DCNs. © 2013 ACM.",congestion; data center network; network update,congestion; Data center networks; Interactive applications; Network modeling; Openflow switches; Real world experiment; Trace driven simulation; Traffic matrices; Communication; Computer architecture; Switching circuits; Network architecture
"Ion M., Zhang J., Schooler E.M.",3,Toward content-centric privacy in ICN: Attribute-based encryption and routing,2013,17,"University of Trento, CREATE-NET, Via Alla Cascata 56D, Trento, 38123, Italy; Intel Labs., 3600 Juliette Lane, Santa Clara, CA 95054, United States",University of Trento,1,Italy;USA,2,5,5,"We design a content-centric privacy scheme for Information-Centric Networking (ICN). We enhance ICN's ability to support data confidentiality by introducing attribute-based encryption into ICN and making it specific to the data attributes. Our approach is unusual in that it preserves ICN's goal to decouple publishers and subscribers for greater data accessibility, scalable multiparty communication and efficient data distribution. Inspired by application-layer publish-subscribe, we enable fine-grained access control with more expressive policies. Moreover, we propose an attribute-based routing scheme that offers interest confidentiality. A prototype system is implemented based on CCNx, a popular open source version of ICN, to showcase privacy preservation in Smart Neighborhood and Smart City applications. © 2013 Authors.",attribute-based encryption; icn; privacy; security,Attribute-based encryptions; Data accessibility; Data confidentiality; icn; Information-centric networkings (ICN); Multi-party communication; Privacy preservation; security; Communication; Computer architecture; Data privacy; Network architecture; Open systems; Cryptography
"Kumar S., Cifuentes D., Gollakota S., Katabi D.",4,Bringing cross-layer MIMO to today's wireless LANs,2013,42,"Massachusetts Institute of Technology, Cambridge, MA, United States; University of Washington, Seattle, WA, United States",MIT;University of Washington at Seattle,2,USA,1,19,2,"Recent years have seen major innovations in cross-layer wireless designs. Despite demonstrating significant throughput gains, hardly any of these technologies have made it into real networks. Deploying cross-layer innovations requires adoption from Wi-Fi chip manufacturers. Yet, manufacturers hesitate to undertake major investments without a better understanding of how these designs interact with real networks and applications. This paper presents the first step towards breaking this stalemate, by enabling the adoption of cross-layer designs in today's networks with commodity Wi-Fi cards and actual applications. We present OpenRF, a cross-layer architecture for managing MIMO signal processing. OpenRF enables access points on the same channel to cancel their interference at each other's clients, while beamforming their signal to their own clients. OpenRF is self-configuring, so that network administrators need not understand MIMO or physical layer techniques. We patch the iwlwifi driver to support OpenRF on off-the-shelf Intel cards. We deploy OpenRF on a 20-node network, showing how it manages the complex interaction of cross-layer design with a real network stack, TCP, bursty traffic, and real applications. Our results demonstrate an average gain of 1.6x for TCP traffic and a significant reduction in response time for real-time applications, like remote desktop. © 2013 ACM.",cross-layer; mimo; sdn; wireless,Chip manufacturers; Cross-layer; Cross-layer architecture; Cross-layer design; Network administrator; Real applications; Real-time application; sdn; Communication; Complex networks; Computer architecture; Design; Manufacture; MIMO systems; Network layers; Radio; Signal processing; Transmission control protocol; Wi-Fi; Network architecture
"Roverso R., El-Ansary S., Hšgqvist M.",3,On HTTP live streaming in large enterprises,2013,2,"Peerialism AB, Stockholm, Sweden; KTH - Royal Institute of Technology, Stockholm, Sweden",KTH Royal Institute of Technology,1,Sweden,1,7,6,"In this work, we present a distributed caching solution which addresses the problem of efficient delivery of HTTP live streams in large private networks. With our system, we have conducted tests on a number of pilot deployments. The largest of them, with 3000 concurrent viewers, consistently showed that our system saves more than 90% of traffic towards the source of the stream while providing the same quality of user experience of a CDN. Another result is that our solution was able to reduce the load on the bottlenecks in the network by an average of 91.6%. © 2013 Authors.",content delivery network; distributed caching; http live; private networks,Content delivery network; Distributed caching; Http-live streaming; Large enterprise; Private networks; User experience; Communication; Computer architecture; HTTP; Video streaming; Network architecture
"Huang H., Liao X., Li S., Peng S., Liu X., Lin B.",6,The architecture and traffic management of wireless collaborated hybrid data center network,2013,1,"School of Computer Science, National University of Defense Technology, Changsha, China",National University of Defense Technology,1,China,1,35,30,"This paper introduces a novel wireless collaborated hybrid data center architecture called RF-HYBRID that could optimize the effect of wireless transmission while reduce the complexity of wired network. RF-HYBRID improves throughput and packet delivery latency through flexible wireless detours and shortcuts, with a comprehensive routing and congestion control method. © 2013 Authors.",data center network; wireless technology,Data center networks; Hybrid datum; Packet Delivery; Traffic management; Wired networks; Wireless technologies; Wireless transmissions; Communication; Complex networks; Computer architecture; Information management; Wireless telecommunication systems; Network architecture
"Chen B.-S., Lin K.C.-J., Wei H.-Y.",3,Harnessing receive diversity in distributed multi-user MIMO networks,2013,2,"National Taiwan University, Taipei, Taiwan; Academia Sinica, Taipei, Taiwan",National Taiwan University,1,Taiwan,1,5,4,"In existing multiuser MIMO (MU-MIMO) MAC protocols, a multi-antenna node sends as many concurrent streams as possible once it wins the contention. Though such a scheme allows nodes to utilize the multiplex gain of a MIMO system, it however fails to leverage receive diversity gains provided by multiple receive antennas across nodes. We introduce Multiplex-Diversity Medium Access (MDMA), a MU-MIMO MAC protocol that achieves both the multiplex gain and the receive diversity gain at the same time. Instead of letting a node pair use all the available degrees of freedom, MDMA allows as many contending node pairs to communicate concurrently as possible and share all the degrees of freedom. It hence can exploit the antennas equipped on different receivers to further provide some of concurrent streams more receive diversity, without losing the achievable multiplex gain. We implement a prototype on software radios to demonstrate the throughput gain of MDMA. © 2013 Authors.",diversity gain; medium access control; multi-user mimo,Diversity gain; MAC protocol; Medium access; Multi-antenna; Multi-user MIMO; Multiple receive antennas; Node pairs; Receive diversity; Communication; Computer architecture; Mechanics; Medium access control; MIMO systems; Multipath propagation; Multiplexing; Receiving antennas; Network architecture
"Chen Y., Crespi N., Lv L., Li M., Ortiz A.M., Shu L.",6,Locating using prior information: Wireless indoor localization algorithm,2013,6,"Institute Mines-Telecom, Evry, France; Dalian University of Technology, Liaoning, China; Guangdong University of Petrochemical Technology, Guangdong, China",Dalian University of Technology;Guangdong University of Petrochemical Technology;Institute Mines Telecom,3,China;France,2,3,2,"Most indoor localization algorithms are based on Received Signal Strength (RSS), in which RSS signatures of an interested area are annotated with their real recorded locations. However, according to our experiments, RSS signatures are not suitable as the unique annotations (like Fingerprints) of recorded locations. In this study, we investigate the characteristics of RSS (e.g., how the RSS values change as time goes on and between consecutive positions?). On this basis, we design LuPI (Locating using Prior Information) that exploits the characteristics of RSS: with user motion, LuPI uses novel sensors integrated in smartphones to construct the RSS variation space (like radio map) of a floor plan as prior information. The deployment of LuPI is easy and rapid since little human intervention is needed. In LuPI, the calibration of ""radio map"" is crowd-sourced, automatic and scheduled. Experimental results show that LuPI achieves comparable location accuracy to previous approaches, even without the statistical information of site survey. © 2013 Authors.",floor plan; indoor localization; smart devices; wireless networks,Floorplans; Human intervention; Indoor localization; Location accuracy; Prior information; Received signal strength; Smart devices; Statistical information; Algorithms; Communication; Computer architecture; Floors; Information use; Network architecture; Telecommunication networks; Wireless networks; RSS
"NŽmeth F., Sonkoly B., Csikor L., Guly‡s A.",4,A large-scale multipath playground for experimenters and early adopters,2013,6,"HSN Lab., Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary; MTA-BME Future Internet Research Group, Hungary; MTA-BME Information Systems Research Group, Hungary",Budapest University of Technology and Economics;MTA-BME,2,Hungary,1,2,2,"Multipath TCP is an experimental transport protocol with remarkable recent past and non-negligible future potential. However the lack of available large-scale testbeds and publicly accessible multiple paths grossly prohibits the adoption of the technology. Here, we demonstrate a large-scale multipath playground deployed on PlanetLab Europe, which can be used either by experimenters and researchers to test and verify their multipath-related ideas (e.g. enhancing congestion control, fairness or even the arrangement of multiple paths) and also by early adopters to enhance their Internet connection even if single-homed. © 2013 Authors.",multipath tcp; openflow; planetlab; sdn,Internet connection; Multipath TCP; Openflow; PlanetLab; Publicly accessible; sdn; Test and verify; Transport protocols; Communication; Computer architecture; Transmission control protocol; Network architecture
"Gao H., Yegneswaran V., Chen Y., Porras P., Ghosh S., Jiang J., Duan H.",7,An empirical reexamination of global DNS behavior,2013,23,"Northwestern University, Evanston, IL, United States; SRI International, Menlo Park, CA, United States; Tsinghua University, Beijing, China",Northwestern University;Tsinghua University,2,China;USA,2,3,3,"The performance and operational characteristics of the DNS protocol are of deep interest to the research and network operations community. In this paper, we present measurement results from a unique dataset containing more than 26 billion DNS query-response pairs collected from more than 600 globally distributed recursive DNS resolvers. We use this dataset to reaffirm findings in published work and notice some significant differences that could be attributed both to the evolving nature of DNS traffic and to our differing perspective. For example, we find that although characteristics of DNS traffic vary greatly across networks, the resolvers within an organization tend to exhibit similar behavior. We further find that more than 50% of DNS queries issued to root servers do not return successful answers, and that the primary cause of lookup failures at root servers is malformed queries with invalid TLDs. Furthermore, we propose a novel approach that detects malicious domain groups using temporal correlation in DNS queries. Our approach requires no comprehensive labeled training set, which can be difficult to build in practice. Instead, it uses a known malicious domain as anchor, and identifies the set of previously unknown malicious domains that are related to the anchor domain. Experimental results illustrate the viability of this approach, i.e. , we attain a true positive rate of more than 96%, and each malicious anchor domain results in a malware domain group with more than 53 previously unknown malicious domains on average. © 2013 ACM.",dns; malicious domain detection; measurement,dns; DNS traffics; Domain detections; Network operations; Operational characteristics; Temporal correlations; Training sets; True positive rates; Communication; Computer architecture; Intrusion detection; Measurements; Network architecture; Internet protocols
"Wette P., Karl H.",2,Which flows are hiding behind my wildcard rule? Adding packet sampling to OpenFlow,2013,3,"University of Paderborn, Warburger Stra§e 100, 33098 Paderborn, Germany",University of Paderborn,1,Germany,1,6,4,"In OpenFlow, multiple switches share the same control plane which is centralized at what is called the OpenFlow controller. A switch only consists of a forwarding plane. Rules for forwarding individual packets (called flow entries in OpenFlow) are pushed from the controller to the switches. In a network with a high arrival rate of new flows, such as in a data center, the control traffic between the switch and controller can become very high. As a consequence, routing of new flows will be slow. One way to reduce control traffic is to use wildcarded flow entries. Wildcard flow entries can be used to create default routes in the network. However, since switches do not keep track of flows covered by a wildcard flow entry, the controller no longer has knowledge about individual flows. To find out about these individual flows we propose an extension to the current OpenFlow standard to enable packet sampling of wildcard flow entries. © 2013 Authors.",openflow,Arrival rates; Control planes; Control traffic; Forwarding planes; Keep track of; Multiple switches; Openflow; Packet sampling; Communication; Computer architecture; Controllers; Network architecture
"Biswas T., Chakraborti A., Ravindran R., Zhang X., Wang G.",5,Contextualized information-centric home network,2013,3,"North Carolina State University, Raleigh, NC, United States; Huawei Research Center, Santa Clara, CA, United States",Huawei Technologies;North Carolina State University,2,USA,1,46,29,"We deploy information-centric networks (ICN) to serve several applications including content distribution, vehicle-to-vehicle communication (V2V), home networks (homenet), and sensor networks. These applications require policy and context-based interaction between service producers and consumers. We visualize the ICN service layer as a contextualized information-centric bus (CIBUS), over which diverse sets of service producers and consumers co-exist. We develop a prototype and demonstrate several desirable features of ICN for homenets such as contextual service publishing and subscription, zero-configuration based node and service discovery, policy based routing and forwarding with name-based firewall, and device-to-device communication. Furthermore the prototype is applicable to both ad hoc and infrastructure settings, and can deal with diverse devices and services. © 2013 Authors.",content centric networking; home networks; information-centric networks; named data networks; node discovery; policy based routing; service discovery; zero-configuration,Content-centric networkings; Information-centric; Named data networks; Node discovery; Policy based routing; Service discovery; zero-configuration; Carrier communication; Communication; Computer architecture; Home networks; Personal communication systems; Sensor networks; Vehicle to vehicle communications; Network architecture
"Liu B., Zhao B., Wei Z., Wu C., Su J., Yu W., Wang F., Sun S.",8,Qphone: A quantum security VoIP phone,2013,6,"School of Computer, National University of Defense Technology, Changsha, Hunan, China; Department of Physics, National University of Defense Technology, Changsha, Hunan, China",National University of Defense Technology,1,China,1,2,2,"This work presents a novel quantum security VoIP phone, called Qphone. Qphone integrates quantum key distribution (QKD) and VoIP steganography, and achieves peer-to-peer communication with information-theoretical security (ITS) guaranteeing. Qphone consists of three parts, a real-time QKD system, RT-QKD, a steganography software, VS-Phone, and an audio encryption and authentication hardware, AE-KEY. RT-QKD explores QKD technologies, and is able establish a shared key between two peers ensuring ITS. VS-Phone utilizes VoIP steganography to protect transmission channels of sensitive information. Qphone can provide efficient and real-time security protections to meet different security demands. © 2013 Authors.",quantum communication; security; steganography; voip,Audio encryption; Peer-to-peer communications; Real-time security; security; Sensitive informations; Steganography software; Transmission channels; voip; Authentication; Communication; Computer architecture; Internet telephony; Quantum communication; Quantum cryptography; Steganography; Telephone sets; Telephone systems; Voice/data communication systems; Network architecture
"So W., Narayanan A., Oran D., Stapp M.",4,Named data networking on a router: Forwarding at 20gbps and beyond,2013,12,"Cisco Systems, Inc., Boxborough, MA, United States",Cisco,1,USA,1,3,2,"Named data networking (NDN) is a new networking paradigm using named data instead of named hosts for communication. Implementation of scalable NDN packet forwarding remains a challenge because NDN requires fast variable-length hierarchical name-based lookup, per-packet data plane state update, and large-scale forwarding tables. We have designed and implemented an NDN data plane with a software forwarding engine on an Intel Xeon-based line card in a Cisco ASR9000 router. In order to achieve high-speed forwarding, our design features (1) name lookup via hash tables with fast collision-resistant hash computation, (2) an efficient and secure FIB lookup algorithm that provides good average and bounded worst-case FIB lookup time, (3) PIT partitioning that enables linear multi-core speedup, and (4) an optimized data structure and software prefetching to maximize data cache utilization. In this demonstration, we showcase our NDN router implementation on the ASR9000 and demonstrate that it can forward real NDN traffic at 20Gbps or higher. © 2013 Authors.",named data networking; packet forwarding engine; router,Design features; Forwarding tables; Hash computation; Lookup algorithms; Named data networkings; Packet forwarding; Packet forwarding engines; Software prefetching; Communication; Computational efficiency; Engines; Microprocessor chips; Network architecture; Routers; Computer architecture
"Wu Z., Butkiewicz M., Perkins D., Katz-Bassett E., Madhyastha H.V.",5,CSPAN: Cost-effective geo-replicated storage spanning multiple cloud services,2013,4,"University of California, Riverside, Riverside, CA, United States; University of Southern California, Los Angeles, CA, United States",University of California Riverside;University of Southern California,2,USA,1,5,4,"Existing cloud computing platforms leave it up to applications to deal with the complexities associated with data replication and propagation across data centers. In our work, we propose the CSPAN key-value store to instead export a unified view of storage services in several geographically distributed data centers. To minimize the cost incurred by application providers, we combine two principles. First, CSPAN spans the data centers of multiple cloud providers. Second, CSPAN judiciously trades off the lower latencies and the higher storage and data propagation costs based on an application's anticipated workload, latency goals, and consistency requirements. © 2013 Authors.",cloud services; optimization; storage system;,Application providers; Cloud computing platforms; Cloud services; Consistency requirements; Data propagation; Distributed data; Storage services; Storage systems; Communication; Computer architecture; Distributed database systems; Network architecture; Optimization; Web services; Digital storage
"Yang Q., Li X., Yao H., Fang J., Tan K., Hu W., Zhang J., Zhang Y.",8,BigStation: Enabling scalable real-time signal processingin large MU-MIMO systems,2013,35,"Microsoft Research Asia, Beijing, China; CUHK, China; Tsinghua University, China; UTSC, China; BJTU, China",Microsoft;Tsinghua University,2,China,1,3,3,"Multi-user multiple-input multiple-output (MU-MIMO) is the latest communication technology that promises to linearly increase the wireless capacity by deploying more antennas on access points (APs). However, the large number of MIMO antennas will generate a huge amount of digital signal samples in real time. This imposes a grand challenge on the AP design by multiplying the computation and the I/O requirements to process the digital samples. This paper presents BigStation, a scalable architecture that enables realtime signal processing in large-scale MIMO systems which may have tens or hundreds of antennas. Our strategy to scale is to extensively parallelize the MU-MIMO processing on many simple and low-cost commodity computing devices. Our design can incrementally support more antennas by proportionally adding more computing devices. To reduce the overall processing latency, which is a critical constraint for wireless communication, we parallelize the MU-MIMO processing with a distributed pipeline based on its computation and communication patterns. At each stage of the pipeline, we further use data partitioning and computation partitioning to increase the processing speed. As a proof of concept, we have built a BigStation prototype based on commodity PC servers and standard Ethernet switches. Our prototype employs 15 PC servers and can support real-time processing of 12 software radio antennas. Our results show that the BigStation architecture is able to scale to tens to hundreds of antennas. With 12 antennas, our BigStation prototype can increase wireless capacity by 6.8x with a low mean processing delay of 860_s. While this latency is not yet low enough for the 802.11 MAC, it already satisfies the real-time requirements of many existing wireless standards, e.g., LTE and WCDMA. © 2013 ACM.",bigstation; mu-mimo; parallel signal processing; software radio,bigstation; Communication technologies; MU-MIMO; Multi user multiple input multiple outputs; Parallel signal processing; Real-time signal processing; Scalable architectures; Wireless communications; Antennas; Communication; Computer architecture; MIMO systems; Mobile telecommunication systems; Network architecture; Personal computers; Pipelines; Signal processing; Software radio; Wireless telecommunication systems; Pipeline processing systems
"Flach T., Dukkipati N., Terzis A., Raghavan B., Cardwell N., Cheng Y., Jain A., Hao S., Katz-Bassett E., Govindan R.",10,Reducing web latency: The virtue of gentle aggression,2013,56,"Department of Computer Science, University of Southern California, Los Angeles, CA, United States; Google Inc., Mountain View, CA, United States",Google;University of Southern California,2,USA,1,4,1,"To serve users quickly, Web service providers build infrastructure closer to clients and use multi-stage transport connections. Although these changes reduce client-perceived round-trip times, TCP's current mechanisms fundamentally limit latency improvements. We performed a measurement study of a large Web service provider and found that, while connections with no loss complete close to the ideal latency of one round-trip time, TCP's timeout-driven recovery causes transfers with loss to take five times longer on average. In this paper, we present the design of novel loss recovery mechanisms for TCP that judiciously use redundant transmissions to minimize timeout-driven recovery. Proactive, Reactive, and Corrective are three qualitatively-different, easily-deployable mechanisms that (1) proactively recover from losses, (2) recover from them as quickly as possible, and (3) reconstruct packets to mask loss. Crucially, the mechanisms are compatible both with middleboxes and with TCP's existing congestion control and loss recovery. Our large-scale experiments on Google's production network that serves billions of flows demonstrate a 23% decrease in the mean and 47% in 99th percentile latency over today's TCP. © 2013 ACM.",congestion control; internet measurements; packet loss; recovery; redundancy; tcp; web latency,Current mechanisms; Internet measurement; Large scale experiments; Production network; tcp; Transport connections; web latency; Web service providers; Communication; Computer architecture; Congestion control (communication); Packet loss; Recovery; Redundancy; Telecommunication networks; Transmission control protocol; Web services; Websites; Network architecture
"Xue L., Mok R.K.P., Chang R.K.C.",3,OMware: An open measurement ware for stable residential broadband measurement,2013,1,"Department of Computing, Hong Kong Polytechnic University, Hong Kong, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,26,19,"A number of home-installed middleboxes, e.g., BISMark and SamKnows, and web-based tools, e.g., Netalyzr and Ookla's speedtest service, have been developed recently to enable residential broadband users to gauge their network service quality. One challenge to designing these systems is to provide stable network measurement. That is, the measurement results will not be fluctuated by sporadic overheads incurred inside the middlebox or web browser. In this poster, we propose a network measurement ware, OMware, to increase the stability of residential broadband measurement. The key feature is to implement the send and receive functions for measurement packets in the kernel. Our preliminary evaluation for an OpenWrt implementation shows that OMware provides very stable throughput and delay measurement, compared with typical socket-based measurement at the user level. © 2013 Authors.",high performance; network measurement; openwrt kernel module,Broadband measurements; Broadband users; Delay measurements; high performance; Kernel modules; Network measurement; Network services; Stable throughput; Communication; Computer architecture; Housing; Network architecture; Measurements
"Ming Z., Xu M., Wang D.",3,In-network caching assisted wireless AP storage management: Challenges and algorithms,2013,1,"Tsinghua University, 4-104 FIT Building, Haidian, Beijing, 100084, China; Hong Kong Polytechnic University, Hung Hom, KL, Hong Kong",Hong Kong Polytechnic University;Tsinghua University,2,China;Hong Kong,2,46,32,"The goal of this paper is to improve wireless AP caching by leveraging in-network caching. We observe that by treating routers as an in-network storage extension, we can relieve the storage limitation of APs. The unique challenge is that APs and routers cannot have a full collaboration, which makes the problem different from traditional cooperative caching problems. We study how APs can optimize caching decisions by using in-network caching information without controlling routers. © 2013 Authors.",algorithm; information-centric networking; wireless caching,Caching decisions; Cooperative caching; In networks; In-network storages; Information-centric networkings; Storage limitation; Algorithms; Communication; Computer architecture; Network architecture
Knight S.,1,Automated configuration and measurement of emulated networks with AutoNetkit,2013,0,"University of Adelaide, Cisco Systems, Adelaide, SA, Australia",University of Adelaide,1,Australia,1,5,2,"Emulated networks enable educators, researchers, and operators to conduct realistic network scenarios on commodity hardware. However each network device must be configured, typically in a low-level syntax. This time-consuming and error-prone process limits scalability and discourages repeated experimentation. This demonstration will show a platform to automate emulated network configuration and measurement, making large-scale network experimentation accessible. © 2013 Author.",configuration management; emulation,Automated configuration; Commodity hardware; Configuration management; emulation; Error-prone process; Large-scale network; Network configuration; Network scenario; Communication; Computer architecture; Experiments; Network architecture
"Chen R., Akkus I.E., Francis P.",3,SplitX: High-performance private analytics,2013,11,"Bell Labs./Alcatel-Lucent, Stuttgart, Germany; MPI-SWS, Kaiserslautern, Germany",Bell Labs,1,Germany,1,5,5,"There is a growing body of research on mechanisms for preserving online user privacy while still allowing aggregate queries over private user data. A common approach is to store user data at users' devices, and to query the data in such a way that a differentially private noisy result is produced without exposing individual user data to any system component. A particular challenge is to design a system that scales well while limiting how much the malicious users can distort the result. This paper presents SplitX, a high-performance analytics system for making differentially private queries over distributed user data. SplitX is typically two to three orders of magnitude more efficient in bandwidth, and from three to five orders of magnitude more efficient in computation than previous comparable systems, while operating under a similar trust model. SplitX accomplishes this performance by replacing public-key operations with exclusive-or operations. This paper presents the design of SplitX, analyzes its security and performance, and describes its implementation and deployment across 416 users. © 2013 ACM.",analytics; differential privacy; xor cryptography,Aggregate queries; analytics; Analytics systems; Differential privacies; Orders of magnitude; Security and performance; System components; Three orders of magnitude; Communication; Computer architecture; Network architecture; Search engines
"Xia W., Tsou T., Lopez D.R., Sun Q., Lu F., Xie H.",6,A software defined approach to unified IPv6 transition,2013,6,"University of Science and Technology of China, Hefei, China; Huawei, Santa Clara, CA, United States; Telef—nica I+D, Madrid, Spain; China Telecom, Beijing, China",University of Science and Technology of China,1,China;Spain;USA,3,8,5,"The IPv6 transition has been an ongoing process throughout the world due to the exhaustion of the IPv4 address space. However, this transition leads to costly end-to-end network upgrades and poses new challenges of managing a large number of devices with a variety of transitioning protocols. Recognizing these difficulties, we propose an software defined approach to unifying the deployment of IPv6 in a cost-effective, flexible manner. Our deployment and experiments demonstrate significant benefits of this approach, including low complexity, low cost and high flexibility of adopting different existing transition mechanisms. © 2013 Authors.",ipv6 transition; software defined network,Address space; End-to-end network; High flexibility; IPv6 transition; Low costs; Software-defined networks; Transition mechanism; Communication; Complex networks; Computer architecture; Network architecture
"Bosshart P., Gibb G., Kim H.-S., Varghese G., McKeown N., Izzard M., Mujica F., Horowitz M.",8,Forwarding metamorphosis: Fast programmable match-action processing in hardware for SDN,2013,155,"Texas Instruments, Dallas, TX, United States; Stanford University, Stanford, CA, United States; Microsoft Research, Mountain View, CA, United States",Microsoft;Stanford University,2,USA,1,33,26,"In Software Defined Networking (SDN) the control plane is physically separate from the forwarding plane. Control software programs the forwarding plane (e.g., switches and routers) using an open interface, such as OpenFlow. This paper aims to overcomes two limitations in current switching chips and the OpenFlow protocol: i) current hardware switches are quite rigid, allowing ""Match-Action"" processing on only a fixed set of fields, and ii) the OpenFlow specification only defines a limited repertoire of packet processing actions. We propose the RMT (reconfigurable match tables) model, a new RISC-inspired pipelined architecture for switching chips, and we identify the essential minimal set of action primitives to specify how headers are processed in hardware. RMT allows the forwarding plane to be changed in the field without modifying hardware. As in OpenFlow, the programmer can specify multiple match tables of arbitrary width and depth, subject only to an overall resource limit, with each table configurable for matching on arbitrary fields. However, RMT allows the programmer to modify all header fields much more comprehensively than in OpenFlow. Our paper describes the design of a 64 port by 10 Gb/s switch chip implementing the RMT model. Our concrete design demonstrates, contrary to concerns within the community, that flexible OpenFlow hardware switch implementations are feasible at almost no additional cost or power. © 2013 ACM.",reconfigurable match tables; rmt model; sdn,Additional costs; Current switching; Forwarding planes; Packet processing; Pipelined architecture; Reconfigurable; sdn; Software defined networking (SDN); Communication; Computer architecture; Hardware; Network architecture; Reconfigurable hardware; Computer hardware
"Huang J., Qian F., Guo Y., Zhou Y., Xu Q., Mao Z.M., Sen S., Spatscheck O.",8,An in-depth study of LTE: Effect of network protocol and application behavior on performance,2013,135,"University of Michigan, Ann Arbor, MI, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,4,4,"With lower latency and higher bandwidth than its predecessor 3G networks, the latest cellular technology 4G LTE has been attracting many new users. However, the interactions among applications, network transport protocol, and the radio layer still remain unexplored. In this work, we conduct an in-depth study of these interactions and their impact on performance, using a combination of active and passive measurements. We observed that LTE has significantly shorter state promotion delays and lower RTTs than those of 3G networks. We discovered various inefficiencies in TCP over LTE such as undesired slow start. We further developed a novel and lightweight passive bandwidth estimation technique for LTE networks. Using this tool, we discovered that many TCP connections significantly under-utilize the available bandwidth. On average, the actually used bandwidth is less than 50% of the available bandwidth. This causes data downloads to be longer, and incur additional energy overhead. We found that the under-utilization can be caused by both application behavior and TCP parameter setting. We found that 52.6% of all downlink TCP flows have been throttled by limited TCP receive window, and that data transfer patterns for some popular applications are both energy and network unfriendly. All these findings highlight the need to develop transport protocol mechanisms and applications that are more LTE-friendly. © 2013 ACM.",4g; bandwidth estimation; lte; resource underutilization; tcp performance,4g; Bandwidth estimation; lte; resource underutilization; TCP performance; 3G mobile communication systems; Bandwidth; Communication; Computer architecture; Data transfer; Network protocols; Transmission control protocol; Wireless telecommunication systems; Network architecture
"Winstein K., Balakrishnan H.",2,TCP ex machina: Computer-generated congestion control,2013,61,"Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,35,18,"This paper describes a new approach to end-to-end congestion control on a multi-user network. Rather than manually formulate each endpoint's reaction to congestion signals, as in traditional protocols, we developed a program called Remy that generates congestion-control algorithms to run at the endpoints. In this approach, the protocol designer specifies their prior knowledge or assumptions about the network and an objective that the algorithm will try to achieve, e.g., high throughput and low queueing delay. Remy then produces a distributed algorithm - -the control rules for the independent endpoints - -that tries to achieve this objective. In simulations with ns-2, Remy-generated algorithms outperformed human-designed end-to-end techniques, including TCP Cubic, Compound, and Vegas. In many cases, Remy's algorithms also outperformed methods that require intrusive in-network changes, including XCP and Cubic-over-sfqCoDel (stochastic fair queueing with CoDel for active queue management). Remy can generate algorithms both for networks where some parameters are known tightly a priori, e.g. datacenters, and for networks where prior knowledge is less precise, such as cellular networks. We characterize the sensitivity of the resulting performance to the specificity of the prior knowledge, and the consequences when real-world conditions contradict the assumptions supplied at design-time. © 2013 ACM.",computer-designed algorithms; congestion control,Active Queue Management; Cellular network; End-to-end congestion control; High throughput; Multi-user networks; Prior knowledge; Protocol designers; Queueing delays; Algorithms; Communication; Computer architecture; Congestion control (communication); Queueing networks; Transmission control protocol; Network architecture
"Calder M., Miao R., Zarifis K., Katz-Bassett E., Yu M., Padhye J.",6,"Don't drop, detour!",2013,0,"University of Southern California, Los Angeles, CA, United States; Microsoft Research, Redmond, United States",Microsoft;University of Southern California,2,USA,1,37,27,"Today's data centers must support a range of workloads with different demands. While existing approaches handle routine traffic smoothly, ephemeral but intense hotspots cause excessive packet loss and severely degrade performance. This loss occurs even though the congestion is typically highly localized, with spare buffer capacity available at nearby switches. We argue that switches should share buffer capacity to effectively handle this spot congestion without the latency or monetary hit of deploying large buffers at individual switches. We present detour-induced buffer sharing (DIBS), a mechanism that achieves a near lossless network without requiring additional buffers. Using DIBS, a congested switch detours packets randomly to neighboring switches to avoid dropping the packets. We implement DIBS in hardware, on software routers in a testbed, and in simulation, and we demonstrate that it reduces the 99th percentile of query completion time by 85%, with very little impact on background traffic. © 2013 Authors.",buffers; data center; packet loss,Background traffic; Buffer capacity; Buffer sharing; Completion time; Congested switches; Data centers; Near-lossless; Software routers; Buffer storage; Communication; Network architecture; Packet loss; Railroad car buffers; Satellite communication systems; Computer architecture
"RŽtv‡ri G., Tapolcai J., Koršsi A., Majd‡n A., Heszberger Z.",5,Compressing IP forwarding tables: Towards entropy bounds and beyond,2013,36,"Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary",Budapest University of Technology and Economics,1,Hungary,1,46,21,"Lately, there has been an upsurge of interest in compressed data structures, aiming to pack ever larger quantities of information into constrained memory without sacrificing the efficiency of standard operations, like random access, search, or update. The main goal of this paper is to demonstrate how data compression can benefit the networking community, by showing how to squeeze the IP Forwarding Information Base (FIB), the giant table consulted by IP routers to make forwarding decisions, into information- theoretical entropy bounds, with essentially zero cost on longest prefix match and FIB update. First, we adopt the state-of-the-art in compressed data structures, yielding a static entropy-compressed FIB representation with asymptotically optimal lookup. Then, we re-design the venerable prefix tree, used commonly for IP lookup for at least 20 years in IP routers, to also admit entropy bounds and support lookup in optimal time and update in nearly optimal time. Evaluations on a Linux kernel prototype indicate that our compressors encode a FIB comprising more than 440K prefixes to just about 100 - 400 KBytes of memory, with a threefold increase in lookup throughput and no penalty on FIB updates. © 2013 ACM.",data compression; ip forwarding table lookup; prefix tree,Asymptotically optimal; Compressed data structures; Forwarding tables; Information base; Longest prefix matches; Lookups; Networking community; Prefix trees; Communication; Computer architecture; Data compression; Data structures; Forestry; Network architecture; Optimization; Routers; Table lookup; Entropy; Communication; Data Processing; Entropy; Forestry; Optimization
"Yang M., Li Y., Jin D., Su L., Ma S., Zeng L.",6,OpenRAN: A software-defined ran architecture via virtualization,2013,31,"Department of Electronic Engineering, Tsinghua University, Beijing 100084, China; Research Institution of China Unicom, Beijing 100084, China",Tsinghua University,1,China,1,8,7,"With the rapid growth of the demands for mobile data, wireless network faces several challenges, such as lack of efficient interconnection among heterogeneous wireless networks, and shortage of customized QoS guarantees between services. The fundamental reason for these challenges is that the radio access network (RAN) is closed and ossified. We propose OpenRAN, an architecture for software-defined RAN via virtualization. It achieves complete virtualization and programmability vertically, and benefits the convergence of heterogeneous network horizontally. It provides open, controllable, flexible and evolvable wireless networks. © 2013 Authors.",radio access network; software-defined network; wireless virtualization,Heterogeneous wireless network; Programmability; QoS guarantee; Radio access networks; RAN architecture; Software-defined networks; Virtualizations; Wireless virtualization; Communication; Computer architecture; Heterogeneous networks; Quality of service; Virtual reality; Wireless networks; Network architecture
"Ferguson A.D., Guha A., Liang C., Fonseca R., Krishnamurthi S.",5,Participatory networking: An API for application control of SDNs,2013,118,"Brown University, Providence, RI, United States; Cornell University, Ithaca, NY, United States",Brown University;Cornell University,2,USA,1,62,33,"We present the design, implementation, and evaluation of an API for applications to control a software-defined network (SDN). Our API is implemented by an OpenFlow controller that delegates read and write authority from the network's administrators to end users, or applications and devices acting on their behalf. Users can then work with the network, rather than around it, to achieve better performance, security, or predictable behavior. Our API serves well as the next layer atop current SDN stacks. Our design addresses the two key challenges: how to safely decompose control and visibility of the network, and how to resolve conflicts between untrusted users and across requests, while maintaining baseline levels of fairness and security. Using a real OpenFlow testbed, we demonstrate our API's feasibility through microbenchmarks, and its usefulness by experiments with four real applications modified to take advantage of it. © 2013 ACM.",openflow; participatory networking; software-defined networks,Application-control; Better performance; Micro-benchmarks; Openflow; OR applications; Participatory networkings; Real applications; Software-defined networks; Application programming interfaces (API); Communication; Computer architecture; Network architecture
"Patel P., Bansal D., Yuan L., Murthy A., Greenberg A., Maltz D.A., Kern R., Kumar H., Zikos M., Wu H., Kim C., Karri N.",12,Ananta: Cloud scale load balancing,2013,44,"Microsoft, Redmond, WA, United States",Microsoft,1,USA,1,6,6,"Layer-4 load balancing is fundamental to creating scale-out web services. We designed and implemented Ananta, a scale-out layer-4 load balancer that runs on commodity hardware and meets the performance, reliability and operational requirements of multi-tenant cloud computing environments. Ananta combines existing techniques in routing and distributed systems in a unique way and splits the components of a load balancer into a consensus-based reliable control plane and a decentralized scale-out data plane. A key component of Ananta is an agent in every host that can take over the packet modification function from the load balancer, thereby enabling the load balancer to naturally scale with the size of the data center. Due to its distributed architecture, Ananta provides direct server return (DSR) and network address translation (NAT) capabilities across layer-2 boundaries. Multiple instances of Ananta have been deployed in the Windows Azure public cloud with combined bandwidth capacity exceeding 1Tbps. It is serving traffic needs of a diverse set of tenants, including the blob, table and relational storage services. With its scale-out data plane we can easily achieve more than 100Gbps throughput for a single public IP address. In this paper, we describe the requirements of a cloud-scale load balancer, the design of Ananta and lessons learnt from its implementation and operation in the Windows Azure public cloud. © 2013 ACM.",distributed systems; server load balancing; software defined networking,Cloud computing environments; Distributed architecture; Distributed systems; Network address translations; Operational requirements; Packet modifications; Server loads; Software-defined networkings; Communication; Computer architecture; Computer supported cooperative work; Computer systems; Digital storage; Parallel architectures; Web services; Windows operating system; Network architecture
"Liu Z., Li Y., Su L., Jin D., Zeng L.",5,M2cloud: Software defined multi-site data center network control framework for multi-tenant,2013,5,"Department of Electronic Engineering, Tsinghua University, Beijing 100084, China",Tsinghua University,1,China,1,52,7,"A significant concern for cloud operators is to provide global network performance isolation for concurrent tenants. To address this, we propose M2cloud, a software defined framework providing scalable network control for multi-site data centers (DCs). M2cloud employs two-level controllers with decoupled functions, providing each tenant with flexible virtualization support in both intra- and inter-DC networks. © 2013 Authors.",data center networks; multi-site; multi-tenant; sdn,Data center (DCs); Data center networks; Multi tenants; Multi-site; Scalable networks; sdn; Virtualizations; Communication; Computer architecture; Network architecture
"Jiang X., Bi J.",2,Interest set mechanism to improve the transport of named data networking,2013,0,"Institute for Network Sciences and Cyberspace, Department of Computer Science, Tsinghua University, China",Tsinghua University,1,China,1,31,10,"In this paper, we proposal an Interest Set mechanism which aggregate similar Interest packets from same flow to one packet to improve the efficient of transport of NDN. The trick here is to reset lifetime of corresponding PIT entry in the immediate routers every time when valid Data packet is passed by. This mechanism covers the time and space uncertainty of data generating, reduce the cost of maintaining the pipeline and improve the transport of NDN. © 2013 Authors.",icn; ndn; transport,Data packet; icn; Named data networkings; ndn; Set mechanism; Similar Interests; transport; Communication; Computer architecture; Network architecture
"Woo J., Kang A.R., Kim H.K.",3,The contagion of malicious behaviors in online games,2013,5,"Korea University, Graduate School of Information Security, 5-Ga Anam-Dong, Seongbuk-Gu, Seoul, 136-701, South Korea",Korea University,1,South Korea,1,4,4,"This article investigates whether individual users are more likely to display malicious behavior after receiving social reinforcement from friends in their online social networks. We analyze the dynamics of game bot diffusion on the basis of real data supplied by a major massively multiplayer online role-playing game company. We find that the social reinforcement, measured by the ratio of bot friends over total friends, affects the likelihood of game bot adoption and the commitment in terms of usage time. © 2013 Authors.",diffusion model; game bot; online game; social contagion,Diffusion model; Game bots; Malicious behavior; Massively multiplayer online role-playing games; On-line games; On-line social networks; social contagion; Social reinforcement; Communication; Computer architecture; Internet; Reinforcement; Social networking (online); Network architecture
"Wang T., Wang G., Li X., Zheng H., Zhao B.Y.",5,Characterizing and detecting malicious crowdsourcing,2013,4,"Electronic Engineering, Tsinghua University, Beijing, China; Department of Computer Science, University of California, Santa Barbara, Santa Barbara, CA, United States",Tsinghua University;University of California Santa Barbara,2,China;USA,2,3,2,"Popular Internet services in recent years have shown that remarkable things can be achieved by harnessing the power of the masses. However, crowd-sourcing systems also pose a real challenge to existing security mechanisms deployed to protect Internet services, particularly those tools that identify malicious activity by detecting activities of automated programs such as CAPTCHAs. In this work, we leverage access to two large crowdturfing sites to gather a large corpus of ground-truth data generated by crowdturfing campaigns. We compare and contrast this data with ""organic"" content generated by normal users to identify unique characteristics and potential signatures for use in real-time detectors. This poster describes first steps taken focused on crowdturfing campaigns targeting the Sina Weibo microblogging system. We describe our methodology, our data (over 290K campaigns, 34K worker accounts, 61 million tweets...), and some initial results. © 2013 Authors.",crowdturfing; malicious crowdsourcing; user behavior,Crowdsourcing; crowdturfing; Detecting activities; Internet services; Malicious activities; Microblogging; Security mechanism; User behaviors; Communication; Computer architecture; Internet; Network architecture; Network security; Behavioral research
"Wang J., Katabi D.",2,"Dude, where's my card? RFID positioning that works with multipath and non-line of sight",2013,139,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,5,4,"RFIDs are emerging as a vital component of the Internet of Things. In 2012, billions of RFIDs have been deployed to locate equipment, track drugs, tag retail goods, etc. Current RFID systems, however, can only identify whether a tagged object is within radio range (which could be up to tens of meters), but cannot pinpoint its exact location. Past proposals for addressing this limitation rely on a line-of-sight model and hence perform poorly when faced with multipath effects or non-line-of-sight, which are typical in real-world deployments. This paper introduces the first fine-grained RFID positioning system that is robust to multipath and non-line-of-sight scenarios. Unlike past work, which considers multipath as detrimental, our design exploits multipath to accurately locate RFIDs. The intuition underlying our design is that nearby RFIDs experience a similar multipath environment (e.g., reflectors in the environment) and thus exhibit similar multipath profiles. We capture and extract these multipath profiles by using a synthetic aperture radar (SAR) created via antenna motion. We then adapt dynamic time warping (DTW) techniques to pinpoint a tag's location. We built a prototype of our design using USRP software radios. Results from a deployment of 200 commercial RFIDs in our university library demonstrate that the new design can locate misplaced books with a median accuracy of 11_cm. © 2013 ACM.",dtw; localization; RFID; sar,dtw; Dynamic time warping; Internet of Things (IOT); localization; Multi-path effect; Multi-path environments; sar; University libraries; Antennas; Communication; Design; Network architecture; Radar antennas; Radio frequency identification (RFID); Synthetic aperture radar; Computer architecture
"Angel S., Walfish M.",2,Verifiable auctions for online ad exchanges,2013,10,"University of Texas at Austin, Austin, TX, United States",University of Texas at Austin,1,USA,1,5,5,"This paper treats a critical component of the Web ecosystem that has so far received little attention in our community: ad exchanges. Ad exchanges run auctions to sell publishers' inventory-space on Web pages-to advertisers who want to display ads in those spaces. Unfortunately, under the status quo, the parties to an auction cannot check that the auction was carried out correctly, which raises the following more general question: how can we create verifiability in low-latency, high-frequency auctions where the parties do not know each other? We address this question with the design, prototype implementation, and experimental evaluation of VEX. VEX introduces a technique for efficient, privacy-preserving integer comparisons; couples these with careful protocol design; and adds little latency and tolerable overhead. © 2013 ACM.",ad exchanges; online advertising; verifiable auctions,Ad exchanges; Critical component; Experimental evaluation; High frequency HF; Online advertising; Privacy preserving; Prototype implementations; verifiable auctions; Commerce; Communication; Computer architecture; Network architecture
"Yen Y.-C., Chu C.-Y., Chen C.-N., Yeh S.-L., Chu H.-H., Huang P.",6,Exponential quantization: User-centric rate control for Skype calls,2013,1,"National Taiwan University, Taipei, Taiwan; University of Illinois at Urbana-Champaign, Urbana, IL, United States",National Taiwan University;UIUC,2,Taiwan;USA,2,45,26,"As Skype has become popular and a profitable business, the long-standing problem of how to deliver Skype calls deserves a serious revisit from an economic viewpoint. This study proposes a rate control mechanism for Skype calls that satisfies more users and satisfies users more than the greedy-na•ve mechanism, as well as the mechanism implemented in Skype. © 2013 Authors.",proportional fairness; qoe; rate control; skype; voip,Proportional fairness; qoe; Rate controls; skype; voip; Communication; Computer architecture; Internet telephony; Network architecture
"Quan L., Heidemann J., Pradkin Y.",3,Trinocular: Understanding internet reliability through adaptive probing,2013,34,"USC/Information Sciences Institute, Marina del Rey, CA, United States",University of Southern California,1,USA,1,61,37,"Natural and human factors cause Internet outages - from big events like Hurricane Sandy in 2012 and the Egyptian Internet shutdown in Jan. 2011 to small outages every day that go unpublicized. We describe Trinocular, an outage detection system that uses active probing to understand reliability of edge networks. Trinocular is principled: deriving a simple model of the Internet that captures the information pertinent to outages, and populating that model through long-term data, and learning current network state through ICMP probes. It is parsimonious, using Bayesian inference to determine how many probes are needed. On average, each Trinocular instance sends fewer than 20 probes per hour to each /24 network block under study, increasing Internet ""background radiation"" by less than 0.7%. Trinocular is also predictable and precise: we provide known precision in outage timing and duration. Probing in rounds of 11 minutes, we detect 100% of outages one round or longer, and estimate outage duration within one-half round. Since we require little traffic, a single machine can track 3.4M /24 IPv4 blocks, all of the Internet currently suitable for analysis. We show that our approach is significantly more accurate than the best current methods, with about one-third fewer false conclusions, and about 30% greater coverage at constant accuracy. We validate our approach using controlled experiments, use Trinocular to analyze two days of Internet outages observed from three sites, and re-analyze three years of existing data to develop trends for the Internet. © 2013 ACM.",adaptive probing; bayesian inference; internet reliability; network outages,adaptive probing; Background radiation; Bayesian inference; Controlled experiment; Detection system; Internet reliabilities; Network outages; Single- machines; Bayesian networks; Communication; Computer architecture; Inference engines; Internet; Network architecture; Outages; Probes; Reliability; Internet protocols
"Bharadia D., McMilin E., Katti S.",3,Full duplex radios,2013,466,"Stanford University, Stanford, CA, United States",Stanford University,1,USA,1,5,3,"This paper presents the design and implementation of the first in-band full duplex WiFi radios that can simultaneously transmit and receive on the same channel using standard WiFi 802.11ac PHYs and achieves close to the theoretical doubling of throughput in all practical deployment scenarios. Our design uses a single antenna for simultaneous TX/RX (i.e., the same resources as a standard half duplex system). We also propose novel analog and digital cancellation techniques that cancel the self interference to the receiver noise floor, and therefore ensure that there is no degradation to the received signal. We prototype our design by building our own analog circuit boards and integrating them with a fully WiFi-PHY compatible software radio implementation. We show experimentally that our design works robustly in noisy indoor environments, and provides close to the expected theoretical doubling of throughput in practice. © 2013 ACM.",full duplex; interference cancellation; non-linear cancellation,Compatible software; Deployment scenarios; Design and implementations; Digital cancellation; Full-duplex; Indoor environment; Interference cancellation; non-linear cancellation; Communication; Design; Network architecture; Signal receivers; Computer architecture
"Zhang X., Niu T., Lao F., Guo Z.",4,Topology-aware content-centric networking,2013,0,"Institute of Computer Science and Technology, Peking University, Beijing, 100871, China",Peking University,1,China,1,35,32,"Making data the first class entity, Information-Centric Networking (ICN) replaces conventional host-to-host model with content sharing model. However, the huge amount of content and the volatility of replicas cached across the Internet pose significant challenges for addressing content only by name. In this paper, we propose a topology-aware name-based routing protocol which combines the benefits of location-oriented routing and content-centric routing together. We adopt a URL-like naming scheme, which defines register locations and content identifier. Node with copies sends Register messages towards a register using location-oriented routing protocols. All en-path routers record forwarding entries in forwarding table (FIB) as the ""bread crumb"" to this content. Following the bread crumb, routers know the ""best"" topology path to the available copies. An Interest is either forwarded towards a ""known"" copy by the content identifier, or towards the register nodes where it would find the bread crumb to the ""best"" copies. Compared with the existing flooding or name resolution methods, Our design shows a good potential in terms of scalability, availability and overhead. © 2013 Authors.",distributed registration; information-centric networking; name-based routing; topology-aware fib; url-like naming,distributed registration; Information-centric networkings; name-based routing; Topology aware; url-like naming; Communication; Computer architecture; Food products; Network architecture; Routers; Routing protocols; Topology
"Javed U., Cunha I., Choffnes D., Katz-Bassett E., Anderson T., Krishnamurthy A.",6,PoiRoot: Investigating the root cause of interdomain path changes,2013,19,"University of Washington, Seattle, WA, United States; Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Northeastern University, United States; University of Southern California, Los Angeles, CA, United States",Northeastern University;Universidade Federal de Minas Gerais;University of Southern California;University of Washington at Seattle,4,Brazil;USA,2,21,17,"Interdomain path changes occur frequently. Because routing protocols expose insufficient information to reason about all changes, the general problem of identifying the root cause remains unsolved. In this work, we design and evaluate PoiRoot, a real-time system that allows a provider to accurately isolate the root cause (the network responsible) of path changes affecting its prefixes. First, we develop a new model describing path changes and use it to provably identify the set of all potentially responsible networks. Next, we develop a recursive algorithm that accurately isolates the root cause of any path change. We observe that the algorithm requires monitoring paths that are generally not visible using standard measurement tools. To address this limitation, we combine existing measurement tools in new ways to acquire path information required for isolating the root cause of a path change. We evaluate PoiRoot on path changes obtained through controlled Internet experiments, simulations, and ""in-the-wild"" measurements. We demonstrate that PoiRoot is highly accurate, works well even with partial information, and generally narrows down the root cause to a single network or two neighboring ones. On controlled experiments PoiRoot is 100% accurate, as opposed to prior work which is accurate only 61.7% of the time. © 2013 ACM.",bgp; measurement; monitoring; path changes; root cause analysis,bgp; Controlled experiment; Internet experiments; Isolating the roots; path changes; Recursive algorithms; Root cause analysis; Standard measurements; Algorithms; Communication; Computer architecture; Experiments; Monitoring; Network architecture; Real time systems; Tools; Measurements
"Popa L., Yalagandula P., Banerjee S., Mogul J.C., Turner Y., Santos J.R.",6,ElasticSwitch: Practical work-conserving bandwidth guarantees for cloud computing,2013,64,"HP Labs., Palo Alto, CA, United States; Avi Networks, Sunnyvale, CA, United States; Google, Mountain View, CA, United States",Google;HP Labs,2,USA,1,4,3,"While cloud computing providers offer guaranteed allocations for resources such as CPU and memory, they do not offer any guarantees for network resources. The lack of network guarantees prevents tenants from predicting lower bounds on the performance of their applications. The research community has recognized this limitation but, unfortunately, prior solutions have significant limitations: either they are inefficient, because they are not work-conserving, or they are impractical, because they require expensive switch support or congestion-free network cores. In this paper, we propose ElasticSwitch, an efficient and practical approach for providing bandwidth guarantees. ElasticSwitch is efficient because it utilizes the spare bandwidth from unreserved capacity or underutilized reservations. ElasticSwitch is practical because it can be fully implemented in hypervisors, without requiring a specific topology or any support from switches. Because hypervisors operate mostly independently, there is no need for complex coordination between them or with a central controller. Our experiments, with a prototype implementation on a 100-server testbed, demonstrate that ElasticSwitch provides bandwidth guarantees and is work-conserving, even in challenging situations. © 2013 ACM.",bandwidth guarantees; cloud computing; work-conserving,Bandwidth guarantee; Hypervisors; Lower bounds; Network core; Network resource; Prototype implementations; Research communities; work-conserving; Bandwidth; Cloud computing; Communication; Complex networks; Computer architecture; Coordination reactions; Network architecture
"Porter G., Strong R., Farrington N., Forencich A., Pang C.-S., Rosing T., Fainman Y., Papen G., Vahdat A.",9,Integrating microsecond circuit switching into the data center,2013,104,"UC San Diego, San Diego, CA, United States; Google, Inc., United States",Google;University of California San Diego,2,USA,1,44,32,"Recent proposals have employed optical circuit switching (OCS) to reduce the cost of data center networks. However, the relatively slow switching times (10 - 100 ms) assumed by these approaches, and the accompanying latencies of their control planes, has limited its use to only the largest data center networks with highly aggregated and constrained workloads. As faster switch technologies become available, designing a control plane capable of supporting them becomes a key challenge. In this paper, we design and implement an OCS prototype capable of switching in 11.5 us, and we use this prototype to expose a set of challenges that arise when supporting switching at microsecond time scales. In response, we propose a microsecond-latency control plane based on a circuit scheduling approach we call Traffic Matrix Scheduling (TMS) that proactively communicates circuit assignments to communicating entities so that circuit bandwidth can be used efficiently. © 2013 ACM.",data center networks; optical networks,Circuit switching; Control planes; Data center networks; Design and implements; Optical circuit switching; Switch technologies; Switching time; Traffic matrices; Communication; Computer architecture; Fiber optic networks; Scheduling; Switching; Network architecture
"Adib F., Katabi D.",2,See through walls with WiFi!,2013,154,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,27,22,"Wi-Fi signals are typically information carriers between a transmitter and a receiver. In this paper, we show that Wi-Fi can also extend our senses, enabling us to see moving objects through walls and behind closed doors. In particular, we can use such signals to identify the number of people in a closed room and their relative locations. We can also identify simple gestures made behind a wall, and combine a sequence of gestures to communicate messages to a wireless receiver without carrying any transmitting device. The paper introduces two main innovations. First, it shows how one can use MIMO interference nulling to eliminate reflections off static objects and focus the receiver on a moving target. Second, it shows how one can track a human by treating the motion of a human body as an antenna array and tracking the resulting RF beam. We demonstrate the validity of our design by building it into USRP software radios and testing it in office buildings. © 2013 ACM.",gesture-based user interface; mimo; seeing through walls; wireless,Information carriers; Moving objects; Moving targets; Number of peoples; Relative location; Static objects; Through walls; Wireless receivers; Antenna arrays; Communication; Computer architecture; MIMO systems; Network architecture; Office buildings; Radio; User interfaces; Walls (structural partitions)
"Pupatwibul P., Banjar A., Braun R.",3,Using DAIM as a reactive interpreter for openflow networks to enable autonomic functionality,2013,1,"CRIN, University of Technology Sydney, Sydney, NSW, Australia",University of Technology Sydney,1,Australia,1,25,16,"OpenFlow is the first standardization of Software Defined Networks. OpenFlow approach, however, has number of limitations: it restricts its use within a single-domain, it is not scalable, and it does not adapt well to changes in local environments. We evaluate the number of approaches to solve these limitations, and propose DAIM model (Distributed Active information Model) which can be integrated into the OpenFlow structure at the level of the switches to provide a reactive interpreter that will manage the flow tables autonomically. © 2013 Authors.",autonomic functionality; distributed systems; openflow,autonomic functionality; Distributed systems; Information Modeling; Local environments; Openflow; Openflow networks; Single domains; Software-defined networks; Communication; Computer architecture; Network architecture
"Chowdhury M., Kandula S., Stoica I.",3,Leveraging endpoint flexibility in data-intensive clusters,2013,52,"UC Berkeley, Berkeley, CA, United States; Microsoft Research, Redmond, WA, United States",Microsoft;University of California Berkeley,2,USA,1,41,28,"Many applications do not constrain the destinations of their network transfers. New opportunities emerge when such transfers contribute a large amount of network bytes. By choosing the endpoints to avoid congested links, completion times of these transfers as well as that of others without similar flexibility can be improved. In this paper, we focus on leveraging the flexibility in replica placement during writes to cluster file systems (CFSes), which account for almost half of all cross-rack traffic in data-intensive clusters. The replicas of a CFS write can be placed in any subset of machines as long as they are in multiple fault domains and ensure a balanced use of storage throughout the cluster. We study CFS interactions with the cluster network, analyze optimizations for replica placement, and propose Sinbad - a system that identifies imbalance and adapts replica destinations to navigate around congested links. Experiments on EC2 and trace-driven simulations show that block writes complete 1.3X (respectively, 1.58X) faster as the network becomes more balanced. As a collateral benefit, end-to-end completion times of data-intensive jobs improve as well. Sinbad does so with little impact on the long-term storage balance. © 2013 ACM.",cluster file systems; constrained anycast; data-intensive applications; datacenter networks; replica placement,Anycast; Cluster File Systems; Data center networks; Data-intensive application; Replica placement; Communication; Computer architecture; Computer simulation; Digital storage; File organization; Network architecture
"Shankaranarayanan P.N., Sivakumar A., Rao S., Tawarmalani M.",4,D-tunes: Self tuning datastores for geo-distributed interactive applications,2013,1,"Purdue University, West Lafayette, IN, United States",Purdue University,1,USA,1,6,6,"Modern internet applications have resulted in users sharing data with each other in an interactive fashion. These applications have very stringent service level agreements (SLAs) which place tight constraints on the performance of the underlying geo-distributed datastores. Deploying these systems in the cloud to meet such constraints is a challenging task, as application architects have to strike an optimal balance among different contrasting objectives such as maintaining consistency between multiple replicas, minimizing access latency and ensuring high availability. Achieving these objectives requires carefully configuring a number of low-level parameters of the datastores, such as the number of replicas, which DCs contain which data, and the underlying consistency protocol parameters. In this work, we adopt a systematic approach where we develop analytical models that capture the performance of a datastore based on application workload and build a system that can automatically configure the datastore for optimal performance. © 2013 Authors.",storage networks; wide-area replication,Consistency protocol; High availability; Interactive applications; Internet application; Optimal performance; Service level agreement (SLAs); Storage networks; wide-area replication; Communication; Computer architecture; Digital storage; Optimization; Network architecture
"Qazi Z.A., Tu C.-C., Chiang L., Miao R., Sekar V., Yu M.",6,SIMPLE-fying middlebox policy enforcement using SDN,2013,241,"Stony Brook University, Stony Brook, NY, United States; University of Southern California, Los Angeles, CA, United States",Stony Brook University;University of Southern California,2,USA,1,45,33,"Networks today rely on middleboxes to provide critical performance, security, and policy compliance capabilities. Achieving these benefits and ensuring that the traffic is directed through the desired sequence of middleboxes requires significant manual effort and operator expertise. In this respect, Software-Defined Networking (SDN) offers a promising alternative. Middleboxes, however, introduce new aspects (e.g., policy composition, resource management, packet modifications) that fall outside the purvey of traditional L2/L3 functions that SDN supports (e.g., access control or routing). This paper presents SIMPLE, a SDN-based policy enforcement layer for efficient middlebox-specific ""traffic steering"". In designing SIMPLE, we take an explicit stance to work within the constraints of legacy middleboxes and existing SDN interfaces. To this end, we address algorithmic and system design challenges to demonstrate the feasibility of using SDN to simplify middlebox traffic steering. In doing so, we also take a significant step toward addressing industry concerns surrounding the ability of SDN to integrate with existing infrastructure and support L4-L7 capabilities. © 2013 ACM.",middlebox; network management; software-defined networking,Design challenges; Middleboxes; Packet modifications; Policy compliance; Policy compositions; Policy enforcement; Resource management; Software-defined networkings; Communication; Computer architecture; Network management; Network architecture
"Awara K., Jamjoom H., Kanlis P.",3,"To 4,000 compute nodes and beyond: Network-aware vertex placement in large-scale graph processing systems",2013,0,"King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; IBM T. J. Watson Research Center, Yorktown Heights, NY, United States",IBM;King Abdullah University of Science and Technology,2,Saudi Arabia;USA,2,9,6,"The explosive growth of ""big data"" is giving rise to a new breed of large scale graph systems, such as Pregel. This poster describes our ongoing work in characterizing and minimizing the communication cost of Bulk Synchronous Parallel (BSP) graph mining systems, like Pregel, when scaling to 4,096 compute nodes. Existing implementations generally assume a fixed communication cost. This is sufficient in small deployments as the BSP programming model (i.e., overlapping computation and communication) masks small variations in the underlying network. In large scale deployments, such variations can dominate the overall runtime characteristics. In this poster, we first quantify the impact of network communication on the total compute time of a Pregel system. We then propose an efficient vertex placement strategy that subsamples highly connected vertices and applies the Reverse Cuthill-McKee (RCM) algorithm to efficiently partition the input graph and place partitions closer to each other based on their expected communication patterns. We finally describe a vertex replication strategy to further reduce communication overhead. © 2013 Authors.",bulk synchronous parallel; extreme scaling; graph mining systems; network topology; vertex placement,Bulk synchronous parallel; extreme scaling; Graph mining; Network topology; vertex placement; Communication; Computer architecture; Electric network topology; Mining machinery; Network architecture; Graph theory
"Hong C.-Y., Kandula S., Mahajan R., Zhang M., Gill V., Nanduri M., Wattenhofer R.",7,Achieving high utilization with software-driven WAN,2013,270,"University of Illinois at Urbana-Champaign, Urbana, IL, United States; Microsoft, Redmond, WA, United States; ETH Zurich, Zurich, Switzerland",ETH Zurich;Microsoft;UIUC,3,Switzerland;USA,2,46,31,"We present SWAN, a system that boosts the utilization of inter-datacenter networks by centrally controlling when and how much traffic each service sends and frequently re-configuring the network's data plane to match current traffic demand. But done simplistically, these re-configurations can also cause severe, transient congestion because different switches may apply updates at different times. We develop a novel technique that leverages a small amount of scratch capacity on links to apply updates in a provably congestion-free manner, without making any assumptions about the order and timing of updates at individual switches. Further, to scale to large networks in the face of limited forwarding table capacity, SWAN greedily selects a small set of entries that can best satisfy current demand. It updates this set without disrupting traffic by leveraging a small amount of scratch capacity in forwarding tables. Experiments using a testbed prototype and data-driven simulations of two production networks show that SWAN carries 60% more traffic than the current practice. © 2013 ACM.",inter-dc wan; software-defined networking,Current practices; Data-driven simulation; Forwarding tables; High utilizations; Novel techniques; Production network; Re-configurations; Software-defined networkings; Communication; Computer architecture; Network architecture
"Jain S., Kumar A., Mandal S., Ong J., Poutievski L., Singh A., Venkata S., Wanderer J., Zhou J., Zhu M., Zolla J., Hšlzle U., Stuart S., Vahdat A.",14,B4: Experience with a globally-deployed software defined WAN,2013,556,"Google, Inc., Mountain View, United States",Google,1,USA,1,5,5,"We present the design, implementation, and evaluation of B4, a private WAN connecting Google's data centers across the planet. B4 has a number of unique characteristics: i) massive bandwidth requirements deployed to a modest number of sites, ii) elastic traffic demand that seeks to maximize average bandwidth, and iii) full control over the edge servers and network, which enables rate limiting and demand measurement at the edge. These characteristics led to a Software Defined Networking architecture using OpenFlow to control relatively simple switches built from merchant silicon. B4's centralized traffic engineering service drives links to near 100% utilization, while splitting application flows among multiple paths to balance capacity against application priority/demands. We describe experience with three years of B4 production deployment, lessons learned, and areas for future work. © 2013 ACM.",centralized traffic engineering; openflow; routing; software- defined networking; wide-area networks,Bandwidth requirement; Centralized traffic; Elastic traffic; Multiple-path; Openflow; Rate limiting; routing; Software-defined networkings; Bandwidth; Communication; Computer architecture; Wide area networks; Network architecture
"Sharma S., Staessens D., Colle D., Pickavet M., Demeester P.",5,Automatic configuration of routing control platforms in OpenFlow networks,2013,7,"Department of Information Technology (INTEC), Ghent University - iMinds, Ghent, Belgium",Ghent University,1,Belgium,1,36,28,"RouteFlow provides a way to run routing control platforms (e.g. Quagga) in OpenFlow networks. One of the issues of RouteFlow is that an administrator needs to devote a lot of time (typically 7 hours for 28 switches) in manual configurations. We propose and demonstrate a framework that can automatically configure RouteFlow. For this demonstration, we use an emulated pan-European topology of 28 switches. In the demonstration, we stream a video clip from a server to a remote client, and show that the video clip reaches at the remote client within 4 minutes (including the configuration time). In addition, we show automatic configuration of RouteFlow using a GUI (Graphical User Interface). © 2013 Authors.",openflow; quagga; virtualization,Automatic configuration; GUI (graphical user interface); Openflow; Openflow networks; quagga; Remote clients; Routing control platforms; Virtualizations; Communication; Computer architecture; Graphical user interfaces; Network routing; Time switches; Video cameras; Network architecture
"Yin J., Sun P., Wen Y., Gong H., Liu M., Li X., You H., Gao J., Lin C.",9,Cloud3DView: An interactive tool for cloud data center operations,2013,6,"Nanyang Tech. Univ., 50 Nanyang Avenue, Singapore 639798, Singapore; Univ. of Elec. Sci. and Tech. of China, Chengdu 610054, China; Center for OPTical IMagery Analysis and Learning, Xi'an 710119, China",Center for OPTical IMagery Analysis and Learning,1,China;Singapore,2,40,30,"The emergence of cloud computing has promoted growing demand and rapid deployment of data centers. However, data center operations require a set of sophisticated skills (e.g., command-line-interface), resulting in a high operational cost. In this demo, to reduce the data center operational cost, we design and build a novel cloud data center management system, based on the concept of 3D gamification. In particular, we apply data visualization techniques to overlay operational status upon a data center 3D model, allowing the operators to monitor the real-time situation and control the data center from a friendly user interface. This demo highlights: (1)a data center 3D view from a First Person Shooter (FPS) camera, (2)a run-time presentation of visualized infrastructures information. Moreover, to improve the user experience, we employ cutting-edge HCI technologies from multi-touch, for remote access to Cloud3DView. © 2013 Authors.",data center operation; data visualization,Cloud data centers; Data center operations; Design and build; First person shooter; Interactive tool; Rapid deployments; User experience; Visualization technique; Communication; Computer architecture; Data visualization; Network architecture; Three dimensional; Three dimensional computer graphics; User interfaces; Information management
"Liu V., Parks A., Talla V., Gollakota S., Wetherall D., Smith J.R.",6,Ambient backscatter: Wireless communication out of thin air,2013,168,"University of Washington, Seattle, WA, United States",University of Washington at Seattle,1,USA,1,5,1,"We present the design of a communication system that enables two devices to communicate using ambient RF as the only source of power. Our approach leverages existing TV and cellular transmissions to eliminate the need for wires and batteries, thus enabling ubiquitous communication where devices can communicate among themselves at unprecedented scales and in locations that were previously inaccessible. To achieve this, we introduce ambient backscatter, a new communication primitive where devices communicate by backscattering ambient RF signals. Our design avoids the expensive process of generating radio waves; backscatter communication is orders of magnitude more power-efficient than traditional radio communication. Further, since it leverages the ambient RF signals that are already around us, it does not require a dedicated power infrastructure as in traditional backscatter communication. To show the feasibility of our design, we prototype ambient backscatter devices in hardware and achieve information rates of 1 kbps over distances of 2.5 feet and 1.5 feet, while operating outdoors and indoors respectively. We use our hardware prototype to implement proof-of-concepts for two previously infeasible ubiquitous communication applications. © 2013 ACM.",backscatter; energy harvesting; internet of things; wireless,Communication primitives; Hardware prototype; Information rates; Internet of Things (IOT); Orders of magnitude; Power infrastructures; Ubiquitous communication; Wireless communications; Communication systems; Computer architecture; Computer hardware; Design; Energy harvesting; Hardware; Network architecture; Radio; Ubiquitous computing; Wireless telecommunication systems; Backscattering
"Crisan D., Birke R., Cressier G., Minkenberg C., Gusat M.",5,Got loss? Get zOVN!,2013,7,"IBM Research, Zurich Research Laboratory, SŠumerstrasse 4, CH-8803 RŸschlikon, Switzerland",IBM;Zurich Research Laboratory,2,Switzerland,1,2,2,"Datacenter networking is currently dominated by two major trends. One aims toward lossless, flat layer-2 fabrics based on Converged Enhanced Ethernet or InfiniBand, with benefits in efficiency and performance. The other targets flexibility based on Software Defined Networking, which enables Overlay Virtual Networking. Although clearly complementary, these trends also exhibit some conflicts: In contrast to physical fabrics, which avoid packet drops by means of flow control, practically all current virtual networks are lossy. We quantify these losses for several common combinations of hypervisors and virtual switches, and show their detrimental effect on application performance. Moreover, we propose a zero-loss Overlay Virtual Network (zOVN) designed to reduce the query and flow completion time of latency-sensitive datacenter applications. We describe its architecture and detail the design of its key component, the zVALE lossless virtual switch. As proof of concept, we implemented a zOVN prototype and benchmark it with Partition-Aggregate in two testbeds, achieving an up to 15-fold reduction of the mean completion time with three widespread TCP versions. For larger-scale validation and deeper introspection into zOVN, we developed an OMNeT++ model for accurate cross-layer simulations of a virtualized datacenter, which confirm the validity of our results. © 2013 ACM.",datacenter networking; lossless; overlay networks; partition-aggregate; virtualization,Application performance; Datacenter; Efficiency and performance; Lossless; Mean completion time; partition-aggregate; Software-defined networkings; Virtualizations; Aggregates; Communication; Computer architecture; Computer simulation; Overlay networks; Transmission control protocol; Network architecture
"Chanda A., Westphal C.",2,A Content Management Layer for Software-Defined Information Centric Networks,2013,5,"WINLAB, Rutgers University, United States; Huawei Innovation Center, United States; University of California, Santa Cruz, United States",Huawei Technologies;Rutgers University;University of California Santa Cruz,3,USA,1,39,24,"The traditional abstraction mechanism in Software Defined Networking does not support including non forwarding elements (proxy and cache for example) in a network. Thus, an OpenFlow network cannot support any content centric functionality natively. We propose an extension of the SDN abstractions to allow these functionalities. We describe our demonstration setup which works by extending OpenFlow to support content identification and management. Copyright © 2013 ACM.",Content distribution; Information-centric networking; OpenFlow; Software defined networking,Abstracting; Copyrights; Proxy caches; Software defined networking; Abstraction mechanism; Content distribution; Content identifications; Content management; Information Centric Networks; Information-centric networkings; Openflow; Openflow networks; Network function virtualization
"Alcock S., Nelson R.",2,Measuring the impact of the copyright amendment act on New Zealand residential DSL users,2012,4,"University of Waikato, Hamilton, New Zealand",University of Waikato,1,New Zealand,1,42,32,"The Copyright (Infringing File Sharing) Amendment Act 2011 (CAA) is a New Zealand law that aims to provide copyright holders with legal recourse when content is illegally shared over the Internet. This paper presents a study of residential DSL user behaviour using packet traces captured at a New Zealand ISP before, shortly after and several months after the CAA coming into effect. We use libprotoident to classify the observed traffic based on the application protocol being used to identify and examine any changes in traffic patterns that may be a result of the new law. We find that the use of peer-to-peer applications declined significantly once the CAA was in effect, suggesting a strong correlation. We also found that there were increases in tunneling, secure file transfer and remote access traffic amongst a small segment of the user population, which may indicate an increased uptake in the use of foreign seedboxes to bypass the jurisdiction of the CAA. © 2012 ACM.",internet law; p2p; residential dsl; seedbox; traffic classification,Application protocols; Copyright holders; File Sharing; File transfers; New zealand; p2p; Peer-to-peer application; Remote access; seedbox; Strong correlation; Traffic classification; Traffic pattern; User behaviour; Behavioral research; Distributed computer systems; Internet protocols; Internet service providers; Peer to peer networks; Telecommunication traffic; Copyrights
"Pitsillidis A., Kanich C., Voelker G.M., Levchenko K., Savage S.",5,Taster's choice: A comparative analysis of spam feeds,2012,16,"Department of Computer Science and Engineering, University of California, San Diego, CA, United States; Department of Computer Science, University of Illinois, Chicago, IL, United States",University of California San Diego;UIUC,2,USA,1,7,6,"E-mail spam has been the focus of a wide variety of measurement studies, at least in part due to the plethora of spam data sources available to the research community. However, there has been little attention paid to the suitability of such data sources for the kinds of analyses they are used for. In spite of the broad range of data available, most studies use a single ""spam feed"" and there has been little examination of how such feeds may differ in content. In this paper we provide this characterization by comparing the contents of ten distinct contemporaneous feeds of spam-advertised domain names. We document significant variations based on how such feeds are collected and show how these variations can produce differences in findings as a result. © 2012 ACM.",domain blacklists; measurement; spam e-mail,Comparative analysis; Data-sources; domain blacklists; Domain names; E-mail spam; Measurement study; Research communities; Electronic mail; Measurements; Internet
"Halepovic E., Pang J., Spatscheck O.",3,Can you GET me now? Estimating the time-to-first-byte of HTTP transactions with passive measurements,2012,21,"AT and T Labs. - Research, 180 Park Avenue, Florham Park, NJ, United States",AT and T Labs,1,USA,1,19,16,"Cellular network operators have a compelling interest to monitor HTTP transaction latency because it is an important component of the user experience. Existing techniques to monitor latency require active probing or use passive analysis to estimate round trip time (RTT). Unfortunately, it is impractical to use active probing to monitor entire cellular networks, and RTT is only one component of HTTP latency in cellular networks. This paper presents a new passive technique to estimate HTTP transaction latency that overcomes the scaling and completeness limitations of prior approaches. We validate our technique in an operational cellular network and present results for traffic in the wild. © 2012 ACM.",measurement; performance; round trip time; time to first byte,Active probing; Cellular network; HTTP transaction; Passive measurements; Passive technique; performance; Round-trip time; time to first byte; User experience; HTTP; Measurements; Estimation
"Vallina-Rodriguez N., Shah J., Finamore A., Grunenberger Y., Haddadi H., Papagiannaki K., Crowcroft J.",7,Breaking for commercials: Characterizing mobile advertising,2012,70,"University of Cambridge, Cambridge, United Kingdom; Politecnico di Torino, Torino, Italy; Telefonica Research, Barcelona, Spain; Queen Mary, University of London, London, United Kingdom",Telefonica Research;University of Cambridge;University of London,3,Italy;Spain;UK,3,44,41,"Mobile phones and tablets can be considered as the first incarnation of the post-PC era. Their explosive adoption rate has been driven by a number of factors, with the most signifcant influence being applications (apps) and app markets. Individuals and organizations are able to develop and publish apps, and the most popular form of monetization is mobile advertising. The mobile advertisement (ad) ecosystem has been the target of prior research, but these works typically focused on a small set of apps or are from a user privacy perspective. In this work we make use of a unique, anonymized data set corresponding to one day of traffic for a major European mobile carrier with more than 3 million subscribers. We further take a principled approach to characterize mobile ad traffic along a number of dimensions, such as overall traffic, frequency, as well as possible implications in terms of energy on a mobile device. Our analysis demonstrates a number of inefficiencies in today's ad delivery. We discuss the benefits of well-known techniques, such as pre-fetching and caching, to limit the energy and network signalling overhead caused by current systems. A prototype implementation on Android devices demonstrates an improvement of 50 % in terms of energy consumption for offline ad-sponsored apps while limiting the amount of ad related traffic. © 2012 ACM.",advertisement; caching; cellular; energy; smartphones; traffic,advertisement; caching; cellular; Data sets; energy; Mobile advertisement; Mobile advertising; Mobile carriers; Offline; Prefetching; Prototype implementations; User privacy; Energy utilization; Mobile devices; Smartphones; Telecommunication traffic; Marketing
"Dhamdhere A., Luckie M., Huffaker B., Claffy K., Elmokashfi A., Aben E.",6,"Measuring the deployment of IPv6: Topology, routing and performance",2012,55,"CAIDA, Univ. of California, San Diego, CA, United States; Simula Research, Oslo, Norway; RIPE NCC, Amsterdam, Netherlands",Simula Research,1,Netherlands;Norway;USA,3,18,13,"We use historical BGP data and recent active measurements to analyze trends in the growth, structure, dynamics and performance of the evolving IPv6 Internet, and compare them to the evolution of IPv4. We find that the IPv6 network is maturing, albeit slowly. While most core Internet transit providers have deployed IPv6, edge networks are lagging. Early IPv6 network deployment was stronger in Europe and the Asia-Pacific region, than in North America. Current IPv6 network deployment still shows the same pattern. The IPv6 topology is characterized by a single dominant player - Hurricane Electric - which appears in a large fraction of IPv6 AS paths, and is more dominant in IPv6 than the most dominant player in IPv4. Routing dynamics in the IPv6 topology are largely similar to those in IPv4, and churn in both networks grows at the same rate as the underlying topologies. Our measurements suggest that performance over IPv6 paths is comparable to that over IPv4 paths if the AS-level paths are the same, but can be much worse than IPv4 if the AS-level paths differ. © 2012 ACM.",IPv6; performance; routing; topology,Active measurement; AS paths; Asia Pacific region; Core Internet; EDGE Networks; IPv6; IPv6 networks; performance; routing; Routing dynamics; Dynamics; Internet; Topology; Internet protocols
"Glatz E., Dimitropoulos X.",2,Classifying internet one-way traffic,2012,29,"ETH Zurich, Zurich, Switzerland",ETH Zurich,1,Switzerland,1,19,19,"Internet background radiation (IBR) is a very interesting piece of Internet traffic as it is the result of attacks and misconfigurations. Previous work has primarily analyzed IBR traffic to large unused IP address blocks called network telescopes. In this work, we build new techniques for monitoring one-way traffic in live networks with the main goals of 1) expanding our understanding of this interesting type of traffic towards live networks as well as of 2) making it useful for detecting and analyzing the impact of outages. Our first contribution is a classification scheme for dissecting one-way traffic into useful classes, including one-way traffic due to unreachable services, scanning, peer-to-peer applications, and backscatter. Our classification scheme is helpful for monitoring IBR traffic in live networks solely based on flow level data. After thoroughly validating our classifier, we use it to analyze a massive data-set that covers 7.41 petabytes of traffic from a large backbone network to shed light into the composition of one-way traffic. We find that the main sources of one-way traffic are malicious scanning, peer-to-peer applications, and outages. In addition, we report a number of interesting observations including that one-way traffic makes a very large fraction, i.e., between 34% and 67%, of the total number of flows to the monitored network, although it only accounts for only 3.4% of the number of packets, which suggests a new conceptual model for Internet traffic in which IBR is dominant in terms of flows. Finally, we demonstrate the utility of one-way traffic of the particularly interesting class of unreachable services for monitoring network and service outages by analyzing the impact of interesting events we detected in the network of our university. © 2012 ACM.","measurement methods; traffic analysis (anomaly detection,classification)",Anomaly detection; Back-bone network; Classification scheme; Conceptual model; Data sets; Internet background radiation; Internet traffic; IP addresss; Live networks; Measurement methods; Misconfigurations; Monitoring network; Network telescopes; On flow; Peer-to-peer application; Petabytes; Service outage; Internet; Peer to peer networks
"Magno G., Comarela G., Saez-Trumper D., Cha M., Almeida V.",5,New kid on the block: Exploring the Google+ social graph,2012,44,"UFMG, Belo Horizonte, Brazil; Universitat Pompeu Fabra, Barcelona, Spain; KAIST, South Korea",KAIST;Universitat Pompeu Fabra,2,Brazil;South Korea;Spain,3,51,41,"This paper presents a detailed analysis of the Google+ social network. We identify the key differences and similarities with other popular networks like Facebook and Twitter, in order to determine whether Google+ is a new paradigm or yet another social network. This work is based on large-scale crawls of over 27 million user profiles that represented nearly 50% of the entire network in 2011. We observe that the average path length between users is slightly higher than other networks, possibly because Google+ is a new system where relationships are still rapidly growing. Google+ shows a higher level of reciprocity than Twitter, which also has directed social links. The newly available ""places lived"" field could be used to study how users are distributed around the world and how aggressively the service has been adopted in different countries. We find that Google+ is popular in countries with relatively low Internet penetration rate. Based on the amount and types of information publicly shared in user profiles, we also find that the notion of privacy varies significantly across different cultures. © 2012 ACM.",geo-location; google+; online social network,Average path length; Facebook; Geolocations; google; Online social networks; Penetration rates; Social graphs; Social Networks; User profile; Online systems; Social networking (online)
"Xu Y., Yu C., Li J., Liu Y.",4,"Video telephony for end-consumers: Measurement study of Google+, iChat, and Skype",2012,55,"Department of Electrical and Computer Engineering, Polytechnic Institute, New York University, Brooklyn, NY 11201, United States",NYU,1,USA,1,41,35,"Video telephony requires high-bandwidth and low-delay voice and video transmissions between geographically distributed users. It is challenging to deliver high-quality video telephony to end-consumers through the best-effort Internet. In this paper, we present our measurement study on three popular video telephony systems on the Internet: Google+, iChat, and Skype. Through a series of carefully designed active and passive measurements, we are able to unveil important information about their key design choices and performance, including application architecture, video generation and adaptation schemes, loss recovery strategies, end-to-end voice and video delays, resilience against random and bursty losses, etc. Obtained insights can be used to guide the design of applications that call for high-bandwidth and low-delay data transmissions under a wide range of ""best-effort"" network conditions. © 2012 ACM.",measurement; video conferencing,Adaptation scheme; Application architecture; Best-effort; Bursty loss; High bandwidth; High quality; Loss recovery; Low delay; Measurement study; Network condition; Passive measurements; Video generation; Video telephony; Voice and video; Image communication systems; Measurements; Video conferencing; Internet
"Dainotti A., King A., Claffy K., Papale F., Pescap A.",5,"Analysis of a ""/0"" stealth scan from a botnet",2012,44,"CAIDA, University of California, San Diego, San Diego, CA, United States; University of Napoli Federico II, Naples, Italy",University of California San Diego;University of Napoli Federico II,2,Italy;USA,2,42,40,"Botnets are the most common vehicle of cyber-criminal activity. They are used for spamming, phishing, denial of service attacks, brute-force cracking, stealing private information, and cyber warfare. Botnets carry out network scans for several reasons, including searching for vulnerable machines to infect and recruit into the botnet, probing networks for enumeration or penetration, etc. We present the measurement and analysis of a horizontal scan of the entire IPv4 address space conducted by the Sality botnet in February of last year. This 12-day scan originated from approximately 3 million distinct IP addresses, and used a heavily coordinated and unusually covert scanning strategy to try to discover and compromise VoIP-related (SIP server) infrastructure. We observed this event through the UCSD Network Telescope, a /8 darknet continuously receiving large amounts of unsolicited traffic, and we correlate this traffic data with other public sources of data to validate our inferences. Sality is one of the largest botnets ever identified by researchers, its behavior represents ominous advances in the evolution of modern malware: the use of more sophisticated stealth scanning strategies by millions of coordinated bots, targeting critical voice communications infrastructure. This work offers a detailed dissection of the botnet's scanning behavior, including general methods to correlate, visualize, and extrapolate botnet behavior across the global Internet. © 2012 ACM.",bot; botnet; coordination; covert; darknet; internet background radiation; network telescope; probing; sality; scan; sip; stealth; voip,bot; botnet; coordination; covert; Darknet; Internet background radiation; Network telescopes; probing; sality; scan; sip; stealth; voip; Behavioral research; Internet; Internet protocols; Internet telephony; Optical telescopes; Scanning; Telescopes; Voice/data communication systems; Computer crime
"Hu Z., Heidemann J., Pradkin Y.",3,Towards geolocation of millions of IP addresses,2012,19,"USC, Information Sciences Institute, Los Angeles, CA, United States",University of Southern California,1,USA,1,34,15,"Previous measurement-based IP geolocation algorithms have focused on accuracy, studying a few targets with increasingly sophisticated algorithms taking measurements from tens of vantage points (VPs). In this paper, we study how to scale up existing measurement-based geolocation algorithms like Shortest Ping and CBG to cover the whole Internet. We show that with many vantage points, VP proximity to the target is the most important factor affecting accuracy. This observation suggests our new algorithm that selects the best few VPs for each target from many candidates. This approach addresses the main bottleneck to geolocation scalability: minimizing traffic into each target (and also out of each VP) while maintaining accuracy. Using this approach we have currently geolocated about 35% of the allocated, unicast, IPv4 address-space (about 85% of the addresses in the Internet that can be directly geolocated). We visualize our geolocation results on a web-based address-space browser. © 2012 ACM.",ip geolocation; ipv4,Geolocation algorithm; Geolocations; IP addresss; Ip geolocation; ipv4; Measurement-based; Scale-up; Unicast; Algorithms; Internet; Internet protocols
"Dhawan M., Samuel J., Teixeira R., Kreibich C., Allman M., Weaver N., Paxson V.",7,Fathom: A browser-based network measurement platform,2012,31,"Rutgers University, Piscataway, NJ, United States; UC Berkeley, Berkeley, CA, United States; CNRS, UPMC, Paris, France; ICSI, UC San Diego, San Diego, CA, United States; ICSI, Berkeley, CA, United States; ICSI, UC Berkeley, Berkeley, CA, United States",Rutgers University;University of California Berkeley;University of California San Diego,3,France;USA,2,67,54,"For analyzing network performance issues, there can be great utility in having the capability to measure directly from the perspective of end systems. Because end systems do not provide any external programming interface to measurement functionality, obtaining this capability today generally requires installing a custom executable on the system, which can prove prohibitively expensive. In this work we leverage the ubiquity of web browsers to demonstrate the possibilities of browsers themselves offering such a programmable environment. We present Fathom, a Firefox extension that implements a number of measurement primitives that enable websites or other parties to program network measurements using JavaScript. Fathom is lightweight, imposing Netalyzr network characterization tool, debugging web access failures, and enabling web sites to diagnose performance problems of their clients. © 2012 ACM.",browser extension; end-host network measurement; network performance; network troubleshooting; web browser,browser extension; End systems; Firefox; Javascript; Network characterization; Network measurement; Network troubleshooting; Performance problems; Programming interface; Web access; Network performance; Websites; Web browsers
"Jiang H., Wang Y., Lee K., Rhee I.",4,Tackling bufferbloat in 3G/4G networks,2012,76,"North Carolina State University, Raleigh, NC, United States; Ulsan National Institute of Science and Technology, Ulsan, South Korea",North Carolina State University;Ulsan National Institute of Science and Technology,2,South Korea;USA,2,21,13,"The problem of overbuffering in the current Internet (termed as bufferbloat) has drawn the attention of the research community in recent years. Cellular networks keep large buffers at base stations to smooth out the bursty data traffic over the time-varying channels and are hence apt to bufferbloat. However, despite their growing importance due to the boom of smart phones, we still lack a comprehensive study of bufferbloat in cellular networks and its impact on TCP performance. In this paper, we conducted extensive measurement of the 3G/4G networks of the four major U.S. carriers and the largest carrier in Korea. We revealed the severity of bufferbloat in current cellular networks and discovered some ad-hoc tricks adopted by smart phone vendors to mitigate its impact. Our experiments show that, due to their static nature, these ad-hoc solutions may result in performance degradation under various scenarios. Hence, a dynamic scheme which requires only receiver-side modification and can be easily deployed via over-the-air (OTA) updates is proposed. According to our extensive real-world tests, our proposal may reduce the latency experienced by TCP flows by 25% _ 49% and increase TCP throughput by up to 51% in certain scenarios. © 2012 ACM.",buerbloat; cellular networks; receive window; tcp,buerbloat; Cellular network; Comprehensive studies; Data traffic; Large buffer; Performance degradation; Real-world tests; Research communities; tcp; TCP flows; TCP performance; TCP throughput; Time varying channel; Smartphones; Wireless ad hoc networks
"Mirkovic J., Shi H., Hussain A.",3,Reducing allocation errors in network testbeds,2012,3,"USC/ISI, 4676 Admiralty Way, Ste 1001, Marina Del Rey, CA, United States",University of Southern California,1,USA,1,55,34,"Network testbeds have become widely used in computer science, both for evaluation of research technologies and for hands-on teaching. This can naturally lead to oversubscription and resource allocation failures, as limited testbed resources cannot meet the increasing demand. This paper examines the causes of resource allocation failures on DeterLab testbed and finds three main culprits that create perceived resource oversubscription, even when available nodes exist: (1) overuse of mapping constraints by users, (2) testbed software errors and (3) suboptimal resource allocation. We propose solutions that could resolve these issues and reduce allocation failures to 57.3% of the baseline. In the remaining cases, real resource oversubscription occurs. We examine testbed usage patterns and show that a small fraction of unfair projects starve others for resources under the current first-come-first-served allocation policy. Due to interactive use of testbeds traditional fair-sharing techniques are not suitable solutions. We then propose two novel approaches - Take-a-Break and Borrow-and-Return - that temporarily pause long-running experiments. These approaches can reduce resource allocation failures to 25% of the baseline case by gently prolonging 1-2.5% of instances. While our investigation is done on DeterLab testbed's data, it should apply to all testbeds that run Emulab software. © 2012 ACM.",emulab; network testbeds; resource allocation,Allocation policies; emulab; First-come-first-served; Network testbeds; Research technologies; Software errors; Suitable solutions; Usage patterns; Errors; Resource allocation; Testbeds
"Murynets I., Piqueras Jover R.",2,Crime scene investigation: SMS spam data analysis,2012,19,"AT and T Security Research Center, New York, NY, United States",AT and T Labs,1,USA,1,32,24,"The Short Messaging Service (SMS), one of the most successful cellular services, generates millions of dollars in revenue for mobile operators. Estimates indicate that billions of text messages are traveling the airwaves daily. Nevertheless, text messaging is becoming a source of customer dissatisfaction due to the rapid surge of messaging abuse activities. Although spam is a well tackled problem in the email world, SMS spam experiences a yearly growth larger than 500%. In this paper we present, to the best of our knowledge, the first analysis of SMS spam traffic from a tier-1 cellular operator. Communication patterns of spammers are compared to those of legitimate cell-phone users and Machine to Machine (M2M) connected appliances. The results indicate that M2M systems exhibit communication profiles similar to spammers, which could mislead spam filters. Beyond the expected results, such as a large load of text messages sent out to a wide target list, other interesting findings are made. For example, the results indicate that the great majority of the spammers connect to the network with just a handful of different hardware models. We find the main geographical sources of messaging abuse in the US. We also find evidence of spammer mobility, voice and data traffic resembling the behavior of legitimate customers. © 2012 ACM.",abuse; cellular networks; SMS; spam; traffic analysis,abuse; Cellular network; SMS; spam; Traffic analysis; Internet; Telephone systems; Message passing
"Khare V., Ju Q., Zhang B.",3,Concurrent prefix hijacks: Occurrence and impacts,2012,11,"University of Arizona, Tucson, AZ, United States",University of Arizona,1,USA,1,25,19,"A concurrent prefix hijack happens when an unauthorized network originates IP prefixes of multiple other networks. Its extreme case is leaking the entire routing table, i.e., hijacking all the prefixes in the table. This is a well-known problem and there exists a preventive measure in practice to safeguard against it. However, we investigated and uncovered many concurrent prefix hijacks that didn't involve a full-table leak. We report these events and their impact on Internet routing. y correlating suspicious routing announcements and comparing it with a network's past routing announcements, we develop a method to detect a network's abnormal behavior of offending multiple other networks simultaneously. Applying the detection algorithm to BGP routing updates from 2003 through 2010, we identify five to twenty concurrent prefix hijacks every year, most of which are previously unknown to the research and operation communities at large. They typically hijack prefixes owned by a few tens of networks, last from a few minutes to a few hours, and pollute routes at most vantage points. © 2012 ACM.",bgp security; prefix hijacking,Abnormal behavior; Bgp securities; Detection algorithm; Internet routing; Prefix hijacking; Preventive measures; Routing table; Measurements; Internet protocols
"GŸrsun G., Crovella M.",2,On traffic matrix completion in the internet,2012,14,"Department of Computer Science, Boston University, Boston, MA, United States",Boston University,1,USA,1,26,24,"The ability of an ISP to infer traffic volumes that are not directly measurable can be useful for research, engineering, and business intelligence. Previous work has shown that traffic matrix completion is possible, but there is as yet no clear understanding of which ASes are likely to be able to perform TM completion, and which traffic flows can be inferred. In this paper we investigate the relationship between the AS-level topology of the Internet and the ability of an individual AS to perform traffic matrix completion. We take a three-stage approach, starting from abstract analysis on idealized topologies, and then adding realistic routing and topologies, and finally incorporating realistic traffic on which we perform actual TM completion. Our first set of results identifies which ASes are best-positioned to perform TM completion. We show, surprisingly, that for TM completion it does not help for an AS to have many peering links. Rather, the most important factor enabling an AS to perform TM completion is the number of direct customers it has. Our second set of results focuses on which flows can be inferred. We show that topologically close flows are easier to infer, and that flows passing through customers are particularly well suited for inference. © 2012 ACM.",interdoman routing; matrix completion,interdoman routing; Matrix completion; Traffic flow; Traffic matrices; Traffic volumes; Topology; Internet service providers
"Lumezanu C., Feamster N.",2,Observing common spam in Twitter and email,2012,9,"NEC Laboratories America, Princeton, NJ, United States; University of Maryland, College Park, MD, United States",NEC;University of Maryland College Park,2,USA,1,34,18,"Spam is pervasive across many types of electronic communication, including email, instant messaging, and social networks. To reach more users and increase financial gain, many spammers now use multiple content-sharing platforms - -including online social networks - -to disseminate spam. In this paper, we perform a joint analysis of spam in email and social networks. We use spam data from Yahoo's web-based email service and from Twitter to characterize the publishing behavior and effectiveness of spam advertised across both platforms. We show that email spammers that also advertise on Twitter tend to send more email spam than those advertising exclusively through email. Further, we use DNS lookup information to show that sending spam on both email and Twitter correlates with a significant increase in coverage: spam domains appearing on both platforms are looked up by an order of magnitude more networks than domains using just one of the two platforms. © 2012 ACM.",dns; email; multiple platform spam; spam; twitter,dns; E-mail spam; Electronic communications; Financial gains; Instant messaging; Joint analysis; Lookups; Multiple platforms; Online social networks; Social Networks; spam; Spammers; twitter; Web-based emails; Electronic mail; Internet protocols; Online systems; Social networking (online); Internet
"Huang J., Qian F., Mao Z.M., Sen S., Spatscheck O.",5,Screen-off traffic characterization and optimization in 3G/4G networks,2012,46,"University of Michigan, Ann Arbor, MI, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,27,23,"Today's cellular systems operate under diverse resource constraints: limited frequency spectrum, network processing capability, and handset battery life. We consider a novel and important factor, handset screen status, i.e., whether the screen is on or off, which was ignored by previous approaches for optimizing cellular resource utilization. Based on analyzing real smartphone traffic collected from 20 users over five months, we find that off-screen traffic accounts for 58.5% of the total radio energy consumption although their traffic volume contribution is much smaller. Such unexpected results are attributed to the unique cellular resource management policy that is not well understood by developers, leading to cellular-unfriendly mobile apps. We then make a further step by proposing screen-aware optimization, by leveraging the key observation that screen-off traffic is much more delay-tolerant than its screen-on counterpart due to a lack of user interaction. Our proposal can better balance the key tradeoffs in cellular networks. It saves up to 60.92% of the network energy and reduces signaling and delay overhead by 25.33% and 30.59%, respectively. © 2012 ACM.",batching; cellular network; fast dormancy; lte; radio resource optimization; screen-off traffic; traffic optimization,batching; Cellular network; fast dormancy; lte; Radio resource optimization; Traffic optimization; Energy utilization; Telephone sets; Optimization
"Abrahamsson H., Nordmark M.",2,Program popularity and viewer behaviour in a large TV-on-demand system,2012,34,"Swedish Institute of Computer Science, Box 1263, Kista, Sweden; TeliaSonera AB, Stockholm, Sweden",Swedish Institute of Computer Science,1,Sweden,1,20,14,"Today increasingly large volumes of TV and video are distributed over IP-networks and over the Internet. It is therefore essential for traffic and cache management to understand TV program popularity and access patterns in real networks. In this paper we study access patterns in a large TV-on-Demand system over four months. We study user behaviour and program popularity and its impact on caching. The demand varies a lot in daily and weekly cycles. There are large peaks in demand, especially on Friday and Saturday evenings, that need to be handled. We see that the cacheability, the share of requests that are not first-time requests, is very high. Furthermore, there is a small set of programs that account for a large fraction of the requests. We also find that the share of requests for the top most popular programs grows during prime time, and the change rate among them decreases. This is important for caching. The cache hit ratio increases during prime time when the demand is the highest, and aching makes the biggest difference when it matters most. We also study the popularity (in terms of number of requests and rank) of individual programs and how that changes over time. Also, we see that the type of programs offered determines what the access pattern will look like. © 2012 ACM.",iptv; program popularity; tv-on-demand,Access patterns; Cache hit ratio; Cache management; IP networks; Prime time; program popularity; Real networks; TV programs; tv-on-demand; User behaviour; IPTV; Measurements; Behavioral research
"Nazir A., Waagen A., Vijayaraghavan V.S., Chuah C.-N., D'Souza R.M., Krishnamurthy B.",6,Beyond friendship: Modeling user activity graphs on social network-based gifting applications,2012,10,"Dept. of Computer Science, University of California - Davis, Davis, CA, United States; Dept. of Applied Math, University of California - Davis, Davis, CA, United States; Dept. of Physics, University of California - Davis, Davis, CA, United States; Dept. of Elecrical Engineering, University of California - Davis, Davis, CA, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;University of California Davis,2,USA,1,21,19,"We employ user activity data from three highly popular gifting applications on Facebook to study the evolution of user activity on applications through the most commonly-used growth mechanism, namely Application Requests. We find user activity graphs differ from friendship graphs in large part due to the inherent directionality of user activity, and node transience. Our results show that, unlike degree distributions in friendship graphs, activity graphs exhibit strong asymmetry in in- and out-degree distributions, and that out-degrees are not accurately described by currently known parametric distributions. As such, user activity graphs cannot be simulated through existing intent- and feature-driven algorithms that can model friendship graphs. We present a novel probabilistic growth model for user activity on the gifting genre of social applications. Our model decouples in- and out-degrees based on their distinct nature exhibited by our empirical data. We use the insight that regardless of increasing, declining or stable user activity, gifting application user activity exhibits the same graph structure. Our model produces synthetic graphs that consist of disconnected components with low clustering of nodes, and exhibit degree structures very similar to our real activity data. We discuss the benefits and shortfalls of our model and its applicability to other types of OSN-based applications, such as social games. To the best of our knowledge this study is the first to explore and model user activity growth processes on OSN-based applications. © 2012 ACM.",algorithms; applications,Degree distributions; Degree structure; Empirical data; Facebook; Friendship graphs; Graph structures; Growth mechanisms; Growth models; Growth process; Large parts; Network-based; Parametric distributions; Synthetic graphs; User activity; User activity data; Algorithms; Applications; Computer simulation; Digital storage; Social networking (online); Graphic methods
"Zhao X., Sala A., Wilson C., Wang X., Gaito S., Zheng H., Zhao B.Y.",7,Multi-scale dynamics in a massive online social network,2012,39,"Department of Computer Science, UC Santa Barbara, Santa Barbara, CA, United States; Bell Labs., Dublin, Ireland; Peking University, Beijing, China; Universitˆ degli Studi di Milano, Milan, Italy",Bell Labs;Peking University;University of California Santa Barbara;Universitˆ degli Studi di Milano,4,China;Ireland;Italy;USA,4,26,23,"Data confidentiality policies at major social network providers have severely limited researchers' access to large-scale datasets. The biggest impact has been on the study of network dynamics, where researchers have studied citation graphs and content-sharing networks, but few have analyzed detailed dynamics in the massive social networks that dominate the web today. In this paper, we present results of analyzing detailed dynamics in a large Chinese social network, covering a period of 2 years when the network grew from its first user to 19 million users and 199 million edges. Rather than validate a single model of network dynamics, we analyze dynamics at different granularities (per-user, per-community, and network-wide) to determine how much, if any, users are influenced by dynamics processes at different scales. We observe independent predictable processes at each level, and find that the growth of communities has moderate and sustained impact on users. In contrast, we find that significant events such as network merge events have a strong but short-lived impact on users, and they are quickly eclipsed by the continuous arrival of new users. © 2012 ACM.",dynamic graphs; online social networks,Citation graphs; Data confidentiality; Different scale; Dynamic graph; Large-scale datasets; Multi-scale dynamics; Network dynamics; Online social networks; Social Networks; Online systems; Social networking (online); Dynamics
"Fusco F., Vlachos M., Dimitropoulos X.",3,RasterZip: Compressing network monitoring data with support for partial decompression,2012,8,"ETH Zurich, Zurich, Switzerland; IBM Research, Zurich, Switzerland",ETH Zurich;IBM,2,Switzerland,1,29,26,"Network traffic archival solutions are fundamental for a number of emerging applications that require: a) efficient storage of high-speed streams of traffic records and b) support for interactive exploration of massive datasets. Compression is a fundamental building block for any traffic archival solution. However, present solutions are tied to general-purpose compressors, which do not exploit patterns of network traffic data and require to decompress a lot of redundant data for high selectivity queries. In this work we introduce RasterZIP, a novel domain-specific compressor designed for network traffic monitoring data. RasterZIP uses an optimized lossless encoding that exploits patterns of traffic data, like the fact that IP addresses tend to share a common prefix. RasterZIP also introduces a novel decompression scheme that accelerates highly selective queries targeting a small portion of the dataset. With our solution we can achieve high-speed on-the-fly compression of more than half a million traffic records per second. We compare RasterZIP with the fastest Lempel-Ziv-based compressor and show that our solution improves the state-of-the-art both in terms of compression ratios and query response times without introducing penalty in any other performance metric. © 2012 ACM.",data compression; netflow; network monitoring; network traffic archives,Data sets; Domain specific; Emerging applications; Fundamental building blocks; High selectivity; Interactive exploration; IP addresss; Lossless encoding; Massive data sets; NetFlows; Network Monitoring; Network traffic; On-the-fly; Performance metrices; Query response; Redundant data; Traffic data; Traffic records; Compressors; Digital storage; Data compression
"Li Z., Lin J., Akodjenou M.-I., Xie G., Kaafar M.A., Jin Y., Peng G.",7,Watching videos from everywhere: A study of the PPTV mobile VoD system,2012,52,"ICT, CAS, Beijing, China; INRIA, Grenoble, France; National ICT Australia, Australia; PPlive, Shanghai, China",INRIA,1,Australia;China;France,3,40,37,"In this paper, we examine mobile users' behavior and their corresponding video viewing patterns from logs extracted from the servers of a large scale VoD system. We focus on the analysis of the main discrepancies that might exist when users access the VoD system catalog from WiFi or 3G connections. We also study factors that might impact mobile users' interests and video popularity. The users' behavior exhibits strong daily and weekly patterns, with mobile users' interests being surprisingly spread across almost all categories and video lengths, independently of the connection type. However, by examining the activity of users individually, we observed a concentration of interests and peculiar access patterns, which allows to classify the users and thus better predict their behavior. We also find a skewed video popularity distribution and then demonstrate that the popularity of a video can be predicted using its very early popularity level. We further analyzed the sources of video viewing and found that even if search engines are the dominant sources for a majority of videos, they represent less than 10% (resp. 20%) of the sources for the highly popular videos in 3G (resp. WiFi) network. We report that both the type of connections and mobile devices in use have an impact on the viewing time and the source of viewing. Based on our findings, we provide insights and recommendations that can be used to design intelligent mobile VoD systems and help improving personalized services on these platforms. © 2012 ACM.",mobile vod; user behavior; video popularity; view source,Access patterns; Mobile users; mobile vod; Personalized service; Popularity distribution; System catalogs; User behaviors; Users access; video popularity; view source; Behavioral research; Global system for mobile communications; Mobile devices; Search engines; Wi-Fi; Video on demand
"Otto J.S., S‡nchez M.A., Rula J.P., Bustamante F.E.",4,"Content delivery and the natural evolution of DNS: Remote DNS trends, performance issues and alternative solutions",2012,38,"Northwestern University, Evanston, IL, United States",Northwestern University,1,USA,1,28,18,"Content Delivery Networks (CDNs) rely on the Domain Name System (DNS) for replica server selection. DNS-based server selection builds on the assumption that, in the absence of information about the client's actual network location, the location of a client's DNS resolver provides a good approximation. The recent growth of remote DNS services breaks this assumption and can negatively impact client's web performance. In this paper, we assess the end-to-end impact of using remote DNS services on CDN performance and present the first evaluation of an industry-proposed solution to the problem. We find that remote DNSusage can indeed significantly impact client's web performance and that the proposed solution, if available, can effectively address the problem for most clients. Considering the performance cost of remote DNS usage and the limited adoption base of the industry-proposed solution, we present and evaluate an alternative approach, Direct Resolution, to readily obtain comparable performance improvements without requiring CDN or DNS participation. © 2012 ACM.",cdn; content distribution; dns; dns extension; internet; measurement,Alternative approach; cdn; Content delivery; Content delivery network; Content distribution; dns; dns extension; Domain name system; Natural evolution; Network location; Performance costs; Performance improvements; Performance issues; Replica servers; Server selection; Web performance; Internet; Measurements; Internet protocols
"GŸrsun G., Ruchansky N., Terzi E., Crovella M.",4,Routing state distance: A path-based metric for network analysis,2012,7,"Department of Computer Science, Boston University, Boston, MA, United States",Boston University,1,USA,1,16,11,"Characterizing the set of routes used between domains is an important and difficult problem. The size and complexity of the millions of BGP paths in use at any time can hide important phenomena and hinder attempts to understand the path selection behavior of ASes. In this paper we introduce a new approach to analysis of the interdomain routing system designed to shed light on collective routing policies. Our approach starts by defining a new metric for 'distance' between prefixes, which we call routing state distance (RSD). We show that RSD has a number of properties that make it attractive for use in visualizing and analyzing the state of the BGP system. Further, since RSD is a metric, it lends itself naturally to use in clustering prefixes or ASes. In fact, the properties of RSD allow us to define a natural clustering criterion, and we show that this criterion admits to a simple clustering algorithm with provable approximation guarantees. We then show that by clustering ASes using RSD, one can uncover macroscopic behavior in BGP that was previously hidden. For example, we show how to identify groups of ASes having similar routing policies with respect to certain destinations, which apparently reflects shared sensitivity to economic or performance considerations. These routing patterns represent a considerable generalization and extension of the notion of BGP atoms to the case where routing policies are only locally and approximately similar across a set of prefixes. © 2012 ACM.",bgp; interdomain routing,bgp; Call routing; Interdomain Routing; Interdomain-routing system; Macroscopic behaviors; Natural clustering; Path selection; Path-based; Routing policies; Measurements; Clustering algorithms
"Bermudez I.N., Mellia M., Munaf˜ M.M., Keralapura R., Nucci A.",5,DNS to the rescue: Discerning content and services in a tangled web,2012,46,"Politecnico di Torino, Torino, Italy; Narus Inc., Sunnyvale, CA, United States",Narus Inc.,1,Italy;USA,2,35,21,"A careful perusal of the Internet evolution reveals two major trends - explosion of cloud-based services and video streaming applications. In both of the above cases, the owner (e.g., CNN, YouTube, or Zynga) of the content and the organization serving it (e.g., Akamai, Limelight, or Amazon EC2) are decoupled, thus making it harder to understand the association between the content, owner, and the host where the content resides. This has created a tangled world wide web that is very hard to unwind, impairing ISPs' and network administrators' capabilities to control the traffic flowing in their networks. In this paper, we present DN-Hunter, a system that leverages the information provided by DNS traffic to discern the tangle. Parsing through DNS queries, DN-Hunter tags traffic flows with the associated domain name. This association has several applications and reveals a large amount of useful information: (i) Provides a fine-grained traffic visibility even when the traffic is encrypted (i.e., TLS/SSL flows), thus enabling more effective policy controls,(ii) Identifies flows even before the flows begin, thus providing superior network management capabilities to administrators, $(iii)$ Understand and track (over time) different CDNs and cloud providers that host content for a particular resource, (iv) Discern all the services/content hosted by a given CDN or cloud provider in a particular geography and time interval, and (v) Provides insights into all applications/services running on any given layer-4 port number. We conduct extensive experimental analysis and show results from real traffic traces (including FTTH and 4G ISPs) that support our hypothesis. Simply put, the information provided by DNS traffic is one of the key components required for understanding the tangled web, and bringing the ability to effectively manage network traffic back to the operators. © 2012 ACM.",DNS; service identification,Amazon ec2; Cloud providers; DNS; Domain names; Experimental analysis; Network administrator; Network traffic; Policy control; Port numbers; Real traffic; Service identification; Streaming applications; Time interval; TLS/SSL; Traffic flow; Traffic flowing; YouTube; Internet protocols; Internet service providers; Network management; World Wide Web; Information management
"Gember A., Akella A., Pang J., Varshavsky A., Caceres R.",5,Obtaining in-context measurements of cellular network performance,2012,39,"University of Wisconsin-Madison, Madison, WI, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;;University of Wisconsin-Madison,3,USA,1,19,11,"Network service providers, and other parties, require an accurate understanding of the performance cellular networks deliver to users. In particular, they often seek a measure of the network performance users experience solely when they are interacting with their device - -a measure we call in-context. Acquiring such measures is challenging due to the many factors, including time and physical context, that influence cellular network performance. This paper makes two contributions. First, we conduct a large scale measurement study, based on data collected from a large cellular provider and from hundreds of controlled experiments, to shed light on the issues underlying in-context measurements. Our novel observations show that measurements must be conducted on devices which (i) recently used the network as a result of user interaction with the device, (ii) remain in the same macro-environment (e.g., indoors and stationary), and in some cases the same micro-environment (e.g., in the user's hand), during the period between normal usage and a subsequent measurement, and (iii) are currently sending/ receiving little or no user-generated traffic. Second, we design and deploy a prototype active measurement service for Android phones based on these key insights. Our analysis of 1650 measurements gathered from 12 volunteer devices shows that the system is able to obtain average throughput measurements that accurately quantify the performance experienced during times of active device and network usage. © 2012 ACM.",active measurement; cellular network performance; device context,Active devices; Active measurement; Average throughput; Cellular network; Controlled experiment; device context; Large-scale measurement; Macro-environment; Network service providers; Network usage; User interaction; Network performance; Measurements
"Zarifzadeh S., Gowdagere M., Dovrolis C.",3,Range tomography: Combining the practicality of boolean tomography with the resolution of analog tomography,2012,15,"Georgia Tech., Atlanta, GA, United States",Georgia Tech,1,USA,1,14,14,"The objective of early network tomography approaches was to produce a point estimate for the performance of each network link (Analog tomography). When it became clear that the previous approach is error-prone in practice, research shifted to Boolean tomography where each link is estimated as either ""good"" or ""bad"". The Boolean approach is more practical but its resolution is too coarse. We propose a new tomography framework that combines the best of both worlds: we still distinguish between good and bad links (for practicality reasons) but we also infer a range estimate for the performance of each bad link. We apply the Range tomography framework in two path performance metric functions (Min and Sum) and propose an efficient algorithm for each problem. Together with simulations, we have also applied Range tomography in three operational networks allowing us to identify the location of bad links and to estimate their performance during congestion episodes. We also compare the proposed method with existing Analog and Boolean tomography algorithms. © 2012 ACM.",localization; Network tomography; performance metric,Error prones; localization; Network links; Network tomography; Operational network; Performance metrices; Point estimate; Range estimates; Tomography algorithm; Algorithms; Estimation; Computer simulation
"Huang T.-Y., Handigol N., Heller B., McKeown N., Johari R.",5,"Confused, timid, and unstable: Picking a video streaming rate is hard",2012,174,"Stanford University, Stanford, CA, United States",Stanford University,1,USA,1,38,29,"Today's commercial video streaming services use dynamic rate selection to provide a high-quality user experience. Most services host content on standard HTTP servers in CDNs, so rate selection must occur at the client. We measure three popular video streaming services - Hulu, Netflix, and Vudu - and find that accurate client-side bandwidth estimation above the HTTP layer is hard. As a result, rate selection based on inaccurate estimates can trigger a feedback loop, leading to undesirably variable and low-quality video. We call this phenomenon the ""downward spiral effect"", and we measure it on all three services, present insights into its root causes, and validate initial solutions to prevent it. © 2012 ACM.",http-based video streaming; video rate adaptation,Bandwidth estimation; Commercial video; Dynamic rate selection; Feed-back loop; High quality; Initial solution; Low qualities; Root cause; Selection based; User experience; Video rate adaptation; Video streaming services; Bandwidth; HTTP; Video streaming
"Drago I., Mellia M., Munaf˜ M.M., Sperotto A., Sadre R., Pras A.",6,Inside dropbox: Understanding personal cloud storage services,2012,210,"University of Twente, Enschede, Netherlands; Politecnico di Torino, Torino, Italy",University of Twente,1,Italy;Netherlands,2,26,19,"Personal cloud storage services are gaining popularity. With a rush of providers to enter the market and an increasing offer of cheap storage space, it is to be expected that cloud storage will soon generate a high amount of Internet traffic. Very little is known about the architecture and the performance of such systems, and the workload they have to face. This understanding is essential for designing efficient cloud storage systems and predicting their impact on the network. This paper presents a characterization of Dropbox, the leading solution in personal cloud storage in our datasets. By means of passive measurements, we analyze data from four vantage points in Europe, collected during 42 consecutive days. Our contributions are threefold: Firstly, we are the first to study Dropbox, which we show to be the most widely-used cloud storage system, already accounting for a volume equivalent to around one third of the YouTube traffic at campus networks on some days. Secondly, we characterize the workload users in different environments generate to the system, highlighting how this reflects on network traffic. Lastly, our results show possible performance bottlenecks caused by both the current system architecture and the storage protocol. This is exacerbated for users connected far from storage data-centers. All measurements used in our analyses are publicly available in anonymized form at the SimpleWeb trace repository: http://traces.simpleweb.org/dropbox/. © 2012 ACM.",cloud storage; dropbox; internet measurement,Campus network; Data centers; Data sets; dropbox; Internet measurement; Internet traffic; Network traffic; Passive measurements; Performance bottlenecks; Storage services; Storage spaces; Storage systems; System architectures; YouTube; Internet protocols; Network architecture; Digital storage
"Gyarmati L., Stanojevic R., Sirivianos M., Laoutaris N.",4,Sharing the cost of backbone networks: Cui bono?,2012,7,"Telefonica Research, Barcelona, Spain; Cyprus University of Technology, Limassol, Cyprus",Cyprus University of Technology;Telefonica Research,2,Cyprus;Spain,2,24,21,"We study the problem of how to share the cost of a backbone network among its customers. A variety of empirical cost-sharing policies are used in practice by backbone network operators but very little ever reaches the research literature about their properties. Motivated by this, we present a systematic study of such policies focusing on the discrepancies between their cost allocations. We aim at quantifying how the selection of a particular policy biases an operator's understanding of cost generation. We identify F-discrepancies due to the specific function used to map traffic into cost (e.g., volume vs. peak rate vs. 95-percentile) and M-discrepancies, which have to do with where traffic is metered (per device vs. ingress metering). We also identify L-discrepancies relating to the liability of individual customers for triggered upgrades and consequent costs (full vs. proportional), and finally, TCO-discrepancies emanating from the fact that the cost of carrying a bit is not uniform across the network (old vs. new equipment, high vs. low energy or real estate costs, etc.). Using extensive traffic, routing, and cost data from a tier-1 network we show that F-discrepancies are large when looking at individual links but cancel out when considering network-wide cost-sharing. Metering at ingress points is convenient but leads to large M-discrepancies, while TCO-discrepancies are huge. Finally, L-discrepancies are intriguing and esoteric but understanding them is central to determining the cost a customer inflicts on the network. © 2012 ACM.",backbone network; cost sharing; fairness; network economics,Back-bone network; Cost allocation; Cost data; Cost sharing; fairness; Individual customers; Network economics; Real estate; Systematic study; Cost accounting; Cost effectiveness; Costs
"Allamanis M., Scellato S., Mascolo C.",3,Evolution of a location-based online social network: Analysis and models,2012,57,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,19,19,"Connections established by users of online social networks are influenced by mechanisms such as preferential attachment and triadic closure. Yet, recent research has found that geographic factors also constrain users: spatial proximity fosters the creation of online social ties. While the effect of space might need to be incorporated to these social mechanisms, it is not clear to which extent this is true and in which way this is best achieved. To address these questions, we present a measurement study of the temporal evolution of an online location-based social network. We have collected longitudinal traces over 4 months, including information about when social links are created and which places are visited by users, as revealed by their mobile check-ins. Thanks to this fine-grained temporal information, we test and compare whether different probabilistic models can explain the observed data adopting an approach based on likelihood estimation, quantitatively comparing their statistical power to reproduce real events. We demonstrate that geographic distance plays an important role in the creation of new social connections: node degree and spatial distance can be combined in a gravitational attachment process that reproduces real traces. Instead, we find that links arising because of triadic closure, where users form new ties with friends of existing friends, and because of common focus, where connections arise among users visiting the same place, appear to be mainly driven by social factors. We exploit our findings to describe a new model of network growth that combines spatial and social factors. We extensively evaluate our model and its variations, demonstrating that it is able to reproduce the social and spatial properties observed in our traces. Our results offer useful insights for systems that take advantage of the spatial properties of online social services. © 2012 ACM.",graph evolution; gravity models; social network,Analysis and models; Attachment process; graph evolution; Gravity model; Likelihood estimation; Location based; Measurement study; Network growth; Node degree; Observed data; Online social networks; Preferential attachments; Probabilistic models; Real trace; Social connection; Social factor; Social Networks; Social service; Social ties; Spatial distance; Spatial properties; Spatial proximity; Statistical power; Temporal evolution; Temporal information; Digital storage; Online systems; Social networking (online)
"Krishnan S.S., Sitaraman R.K.",2,Video stream quality impacts viewer behavior: Inferring causality using quasi-experimental designs,2012,117,"Akamai Technologies, Bangalore, India; University of Massachusetts, Akamai Technologies, Amherst, MA, United States",University of Massachusetts Amherst,1,India;USA,2,30,23,"The distribution of videos over the Internet is drastically transforming how media is consumed and monetized. Content providers, such as media outlets and video subscription services, would like to ensure that their videos do not fail, startup quickly, and play without interruptions. In return for their investment in video stream quality, content providers expect less viewer abandonment, more viewer engagement, and a greater fraction of repeat viewers, resulting in greater revenues. The key question for a content provider or a CDN is whether and to what extent changes in video quality can cause changes in viewer behavior. Our work is the first to establish a causal relationship between video quality and viewer behavior, taking a step beyond purely correlational studies. To establish causality, we use Quasi-Experimental Designs, a novel technique adapted from the medical and social sciences. We study the impact of video stream quality on viewer behavior in a scientific data-driven manner by using extensive traces from Akamai's streaming network that include 23 million views from 6.7 million unique viewers. We show that viewers start to abandon a video if it takes more than 2 seconds to start up, with each incremental delay of 1 second resulting in a 5.8%increase in the abandonment rate. Further, we show that a moderate amount of interruptions can decrease the average play time of a viewer by a significant amount. A viewer who experiences a rebuffer delay equal to 1% of the video duration plays 5% less of the video in comparison to a similar viewer who experienced no rebuffering. Finally, we show that a viewer who experienced failure is 2.32% less likely to revisit the same site within a week than a similar viewer who did not experience a failure. © 2012 ACM.",causal inference; internet content delivery; multimedia; quasi-experimental design; streaming video; user behavior; video quality,causal inference; Internet content; multimedia; Streaming videos; User behaviors; Video quality; Content based retrieval; Design of experiments; Economics; Internet; Statistics; Video streaming; Behavioral research
"Gregori E., Improta A., Lenzini L., Rossi L., Sani L.",5,On the incompleteness of the AS-level graph: A novel methodology for BGP route collector placement,2012,24,"Institute of Informatics and Telematics, Italian National Research Council, Pisa, Italy; Information Engineering Department, University of Pisa, Pisa, Italy; IMT, Institute for Advanced Studies, Lucca, Italy",Italian National Research Council;University of Pisa,2,Italy,1,32,27,"In the last decade many studies have used the Internet AS-level topology to perform several analyses, from discovering its graph properties to assessing its impact on the effectiveness of worm-containment strategies. Yet, the BGP data typically used to reveal the topologies are far from being complete. Our contribution is three-fold. Firstly, we analyse BGP data currently gathered by RouteViews, RIS and PCH route collectors, and investigate the reasons for its incompleteness. We found that large areas of the Internet are not properly captured due to the geographic placement of the current route collector feeders and due to BGP filters, such as BGP export policies and BGP decision processes. Secondly, we propose a methodology to select the optimal number of ASes that should join a route collector project to obtain a view of the Internet AS level topology closer to reality. We applied this methodology to the global AS-level topology and to five regional AS-level topologies, highlighting that the particular characteristics of the Internet at a regional level cannot be ignored during this process. Thirdly, we provide a characterization of the ASes that we found to be part of at least one optimal solution set. By analysing these ASes we found that the current route collector infrastructure is rarely connected to them, highlighting that much more effort should be made in devising a route collector infrastructure that ideally would be able to capture a complete view of the Internet. © 2012 ACM.",autonomous systems; BGP; incompleteness; internet; measurement; topology,Autonomous systems; BGP; Decision process; Export policy; Graph properties; incompleteness; Novel methodology; Optimal number; Optimal solutions; Regional levels; Computer crime; Internet; Measurements; Topology
"Canadi I., Barford P., Sommers J.",3,Revisiting broadband performance,2012,21,"University of Wisconsin, Madison, WI, United States; Colgate University, Hamilton, NY, United States",Colgate University;University of Wisconsin-Madison,2,USA,1,27,18,"Understanding the empirical characteristics of broadband performance is of intrinsic importance to users and providers, and has been a significant focus of recent efforts by the Federal Communications Commission (FCC) [9]. A series of recent studies have reported results of empirical studies of broadband performance (e.g., [11, 15, 22]). In this paper, we reappraise previous empirical findings on broadband performance. Our study is based on a unique corpus of crowd-sourced data consisting of over 54 million individual tests collected from 59 metropolitan markets over a 6 month period by Speedtest.net. Following analytic approaches from prior studies, our results confirm many of the raw performance results (upload/download/latency) for ISPs in specific US markets. However, the size and scope of our data enable us to examine the details of characteristics that were not identified in prior studies, thereby providing a more comprehensive view of broadband performance. Furthermore, we also report results of broadband performance characteristics in 35 metropolitan markets outside of the US. This not only provides an important baseline for future study in those markets, but also enables relative comparison of broadband performance between markets world wide. © 2012 ACM.",access networks; broadband access,Access network; Analytic approach; Broadband access; Broadband performance; Empirical findings; Empirical studies; Federal communications commission; US markets; Internet service providers; Wireless telecommunication systems; Commerce
"Zander S., Andrew L.L.H., Armitage G., Huston G., Michaelson G.",5,Mitigating sampling error when measuring internet client IPv6 capabilities,2012,19,"CAIA, Swinburne University of Technology, Melbourne, VIC, Australia; Asia Pacific Network Information Centre (APNIC), Brisbane, QLD, Australia",Swinburne University of Technology,1,Australia,1,32,21,"Despite the predicted exhaustion of unallocated IPv4 addresses between 2012 and 2014, it remains unclear how many current clients can use its successor, IPv6, to access the Internet. We propose a refinement of previous measurement studies that mitigates intrinsic measurement biases, and demonstrate a novel web-based technique using Google ads to perform IPv6 capability testing on a wider range of clients. After applying our sampling error reduction, we find that 6% of world-wide connections are from IPv6-capable clients, but only 1 - 2% of connections preferred IPv6 in dual-stack (dual-stack failure rates less than 1%). Except for an uptick around IPv6-day 2011 these proportions were relatively constant, while the percentage of connections with IPv6-capable DNS resolvers has increased to nearly 60%. The percentage of connections from clients with native IPv6 using happy eyeballs has risen to over 20%. © 2012 ACM.",banner-ad-based measurement; ipv6 deployment,Failure rate; ipv6 deployment; Measurement bias; Measurement study; Sampling errors; Internet; Internet protocols
"Flach T., Katz-Bassett E., Govindan R.",3,Quantifying violations of destination-based forwarding on the internet,2012,14,"University of Southern California, Los Angeles, CA 90089, United States",University of Southern California,1,USA,1,22,22,"Initially, packet forwarding in the Internet was destination-based - that is, a router would forward all packets with the same destination address to the same next hop. In this paper, we use active probing methods to quantify and characterize deviations from destination-based forwarding in today's Internet. From over a quarter million probes, we analyze the forwarding behavior of almost 40,000 intermediate routers. We find that, for 29% of the targeted routers, the router forwards traffic going to a single destination via different next hops, and 1.3% of the routers even select next hops in different ASes. Load balancers are unlikely to explain these AS-level variations, and in fact we uncover causes including routers inside MPLS tunnels that otherwise employ default routes. We also find that these violations can significantly affect the results of measurement tools that rely on destination-based forwarding, and we discuss some ideas for making these tools more robust against these violations. © 2012 ACM.",forwarding; measurements; ping; routing; traceroute,Active probing; forwarding; Intermediate routers; Load balancer; Measurement tools; Next-hop; Packet forwarding; ping; routing; Traceroute; Internet; Routers; Measurements
"Lee M., Duffield N., Kompella R.R.",3,MAPLE: A scalable architecture for maintaining packet latency measurements,2012,11,"Purdue University, West Lafayette, IN, United States; AT and T Labs.-Research, Florham Park, NJ, United States",AT and T Labs;Purdue University,2,USA,1,39,27,"Latency has become an important metric for network monitoring since the emergence of new latency-sensitive applications (e.g., algorithmic trading and high-performance computing). To satisfy the need, researchers have proposed new architectures such as LDA and RLI that can provide fine-grained latency measurements. However, these architectures are fundamentally ossified in their design as they are designed to provide only a specific pre-configured aggregate measurement - -either average latency across all packets (LDA) or per-flow latency measurements (RLI). Network operators, however, need latency measurements at both finer (e.g., packet) as well as flexible (e.g., flow subsets) levels of granularity. To bridge this gap, we propose an architecture called MAPLE that essentially stores packet-level latencies in routers and allows network operators to query the latency of arbitrary traffic sub-populations. MAPLE is built using scalable data structures with small storage needs (uses only 12.8 bits/packet), and uses a novel mechanism to reduce the query bandwidth significantly (by a factor of 17 compared to the naive method of sending packet queries individually). © 2012 ACM.",approximation; bloom filter; latency,Algorithmic trading; approximation; Bloom filters; High-performance computing; latency; Network Monitoring; Network operator; Packet latencies; Scalable architectures; Sub-populations; Computer architecture; Computer software selection and evaluation; Data structures; Network architecture
"Gong N.Z., Xu W., Huang L., Mittal P., Stefanov E., Sekar V., Song D.",7,"Evolution of social-attribute networks: Measurements, modeling, and implications using Google+",2012,86,"EECS, UC Berkeley, Berkeley, CA, United States; CS, Tsinghua University, Beijing, China; Intel Labs., Berkeley, CA, United States; CS, Stony Brook University, Stony Brook, NY, United States",Stony Brook University;Tsinghua University;University of California Berkeley,3,China;USA,2,19,14,"Understanding social network structure and evolution has important implications for many aspects of network and system design including provisioning, bootstrapping trust and reputation systems via social networks, and defenses against Sybil attacks. Several recent results suggest that augmenting the social network structure with user attributes (e.g., location, employer, communities of interest) can provide a more fine-grained understanding of social networks. However, there have been few studies to provide a systematic understanding of these effects at scale. We bridge this gap using a unique dataset collected as the Google+ social network grew over time since its release in late June 2011. We observe novel phenomena with respect to both standard social network metrics and new attribute-related metrics (that we define). We also observe interesting evolutionary patterns as Google+ went from a bootstrap phase to a steady invitation-only stage before a public release. Based on our empirical observations, we develop a new generative model to jointly reproduce the social structure and the node attributes. Using theoretical analysis and empirical evaluations, we show that our model can accurately reproduce the social and attribute structure of real social networks. We also demonstrate that our model provides more accurate predictions for practical application contexts. © 2012 ACM.",google+; heterogeneous network measurement and modeling; node attributes; social network evolution; social network measurement,Accurate prediction; Application contexts; Communities of interest; Data sets; Empirical evaluations; Generative model; google; Node attribute; Social network evolution; Social network structures; Social Networks; Social structure; Sybil attack; Trust and reputation; Computer crime; Heterogeneous networks; Social networking (online)
"Santiago Del Rio P.M., Rossi D., Gringoli F., Nava L., Salgarelli L., Aracil J.",6,Wire-speed statistical classification of network traffic on commodity hardware,2012,23,"UAM, Madrid, Spain; Telecom ParisTech, Paris, France; UNIBS, Brescia, Italy",Telecom ParisTech,1,France;Italy;Spain,3,39,18,"In this paper we present a software-based traffic classification engine running on commodity multi-core hardware, able to process in real-time aggregates of up to 14.2 Mpps over a single 10 Gbps interface - i.e., the maximum possible packet rate over a 10 Gbps Ethernet links given the minimum frame size of 64 Bytes. This significant advance with respect to the current state of the art in terms of achieved classification rates are made possible by:(i) the use of an improved network driver, PacketShader, to efficiently move batches of packets from the NIC to the main CPU;(ii) the use of lightweight statistical classification techniques exploiting the size of the first few packets of every observed flow;(iii) a careful tuning of critical parameters of the hardware environment and the software application itself. © 2012 ACM.",commodity hardware; statistical identification; traffic monitoring,10 Gbps; 10 Gbps Ethernet; Classification rates; Commodity hardware; Critical parameter; Frame size; Hardware environment; Multi core; Network driver; Network traffic; Packet rate; Software applications; Software-based; State of the art; Statistical classification; Statistical classification techniques; Traffic classification; Traffic monitoring; Telecommunication traffic; Hardware
"Hohlfeld O., Graf T., Ciucu F.",3,Longtime behavior of harvesting spam bots,2012,6,"TU Berlin, Telekom Innovation Laboratories, Berlin, Germany; Modas GmbH, Berlin, Germany",Modas GmbH;TU Berlin;Telekom Innovation Laboratories,3,Germany,1,62,49,"This paper investigates the origins of the spamming process, specifically concerning address harvesting on the web, by relying on an extensive measurement data set spanning over three years. Concretely, we embedded more than 23 million unique spamtrap addresses in web pages. 0.5% of the embedded trap addresses received a total of 620,000 spam messages. Besides the scale of the experiment, the critical aspect of our methodology is the uniqueness of the issued spamtrap addresses, which enables the mapping of crawling activities to the actual spamming process. Our observations suggest that simple obfuscation methods are still efficient for protecting addresses from being harvested. A key finding is that search engines are used as proxies, either to hide the identity of the harvester or to optimize the harvesting process. © 2012 ACM.",address harvesting; comment spam; e-mail; spam,23 million; comment spam; Long time behavior; Measurement data; spam; Spam messages; Electronic mail; Harvesting; Search engines; Spamming; Internet
"Papapanagiotou I., Nahum E.M., Pappas V.",3,Configuring DHCP leases in the smartphone era,2012,14,"ECE, NC State University, Raleigh, NC, United States; IBM Research, Hawthorne, NY, United States",IBM;North Carolina State University,2,USA,1,31,26,"The Dynamic Host Configuration Protocol (DHCP) was introduced nearly 20 years ago as a mechanism for hosts to automatically acquire IP addresses. While the protocol remains the same, its usage has evolved, especially in the last decade with the introduction of mobile devices and wireless local area networks. In this paper we investigate the impact that new types of wireless devices, such as smartphones, have on DHCP. We use two one-month long traces, collected at a corporate and an educational network, and we compare side-by-side DHCP usage patterns. We develop a novel passive fingerprinting technique based on DHCP messages to determine the device type and operating system. We show that DHCP implementations vary among device types and have an effect on DHCP lease durations. To improve network address utilization, without introducing any protocol changes, we propose a new leasing strategy which takes into account device types. This strategy, compared to current approaches, improves the address utilization without considerably increasing DHCP overhead. © 2012 ACM.",dhcp; lease time; os fingerprinting; smartphones,dhcp; Dynamic host configuration protocols; IP addresss; lease time; Network address; Passive fingerprinting; Usage patterns; Wireless devices; Internet protocols; Mobile devices; Wireless local area networks (WLAN); Smartphones
"Sommers J., Barford P.",2,Cell vs. WiFi: On the performance of metro area mobile connections,2012,81,"Colgate University, Hamilton, NY, United States; University of Wisconsin, Madison, WI, United States",Colgate University;University of Wisconsin-Madison,2,USA,1,31,30,"Cellular and 802.11 WiFi are compelling options for mobile Internet connectivity. The goal of our work is to understand the performance afforded by each of these technologies in diverse environments and use conditions. In this paper, we compare and contrast cellular and WiFi performance using crowd-sourced data from Speedtest.net. Our study considers spatio-temporal performance (upload/download throughput and latency) using over 3 million user-initiated tests from iOS and Android apps in 15 different metro areas collected over a 15 week period. Our basic performance comparisons show that (i) WiFi provides better absolute download/upload throughput, and a higher degree of consistency in performance; (ii) WiFi networks generally deliver lower absolute latency, but the consistency in latency is often better with cellular access; (iii) throughput and latency vary widely depending on the particular access type e.g., HSPA, EVDO, LTE, WiFi, etc.) and service provider. More broadly, our results show that performance consistency for cellular and WiFi is much lower than has been reported for wired broadband. Temporal analysis shows that average performance for cell and WiFi varies with time of day, with the best performance for large metro areas coming at non-peak hours. Spatial analysis shows that performance is highly variable across metro areas, but that there are subregions that offer consistently better performance for cell or WiFi. Comparisons between metro areas show that larger areas provide higher throughput and lower latency than smaller metro areas, suggesting where ISPs have focused their deployment efforts. Finally, our analysis reveals diverse performance characteristics resulting from the rollout of new cell access technologies and service differences among local providers. © 2012 ACM.",cellular; WiFi,Access technology; Access types; cellular; Mobile connection; Mobile Internet; Performance characteristics; Performance comparison; Service provider; Spatial analysis; Spatio-temporal; Temporal analysis; Time of day; Wi Fi networks; Cells; Cytology; Internet service providers; Throughput; Wireless telecommunication systems; Wi-Fi
"Chen X., Jin R., Suh K., Wang B., Wei W.",5,Network performance of smart mobile handhelds in a university campus WiFi network,2012,29,"University of Connecticut, Storrs, CT, United States; Illinois State University, Normal, IL, United States",Illinois State University;University of Connecticut,2,USA,1,13,7,"Smart mobile handheld devices (MHDs) such as smartphones have been used for a wide range of applications. Despite the recent flurry of research on various aspects of smart MHDs, little is known about their network performance in WiFi networks. In this paper, we measure the network performance of smart MHDs inside a university campus WiFi network, and identify the dominant factors that affect the network performance. Specifically, we analyze 2.9TB of data collected over three days by a monitor that is located at a gateway router of the network, and make the following findings: (1) Compared to non-handheld devices (NHDs), MHDs use well provisioned Akamai and Google servers more heavily, which boosts the overall network performance of MHDs. Furthermore, MHD flows, particularly short flows, benefit from the large initial congestion window that has been adopted by Akamai and Google servers. (2) MHDs tend to have larger local delays inside the WiFi network and are more adversely affected by the number of concurrent flows. (3) Earlier versions of Android OS (before 4.X) cannot take advantage of the large initial congestion window adopted by many servers. On the other hand, the large receive window adopted by iOS is not fully utilized by most flows, potentially leading to waste of resources. (4) Some application-level protocols cause inefficient use of network and operating system resources of MHDs in WiFi networks. Our observations provide valuable insights on content distribution, server provisioning, MHD system design, and application-level protocol design. © 2012 ACM.",performance measurement; smart mobile handhelds; wifi networks,Application-level protocol; Congestion window; Content distribution; Dominant factor; Handhelds; MHD flow; Mobile handheld devices; Performance measurements; University campus; Wi Fi networks; Gateways (computer networks); Hand held computers; Magnetohydrodynamics; Network performance; Wi-Fi
"Shi X., Xiang Y., Wang Z., Yin X., Wu J.",5,Detecting prefix hijackings in the internet with argus,2012,47,"Institute for Network Sciences and Cyberspace, Tsinghua University, Beijng, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology (TNList), China",Tsinghua University,1,China,1,34,32,"Border Gateway Protocol (BGP) plays a critical role in the Internet inter-domain routing reliability. Invalid routes generated by mis-configurations or forged by malicious attacks may hijack the traffic and devastate the Internet routing system, but it is unlikely that a secure BGP can be deployed in the near future to completely prevent them. Although many hijacking detection systems have been developed, they more or less have weaknesses such as long detection delay, high false alarm rate and deployment difficulty, and no systematic detection results have been studied. This paper proposes Argus, an agile system that can accurately detect prefix hijackings and deduce the underlying cause of route anomalies in a very fast way. Argus is based on correlating the control and data plane information closely and pervasively, and has been continuously monitoring the Internet for more than one year. During this period, around 40K routing anomalies were detected, from which 220 stable prefix hijackings were identified. Our analysis on these events shows that, hijackings that have only been theoretically studied before do exist in the Internet. Although the frequency of new hijackings is nearly stable, more specific prefixes are hijacked more frequently. Around 20% of the hijackings last less than ten minutes, and some can pollute 90% of the Internet in less than two minutes. These characteristics make \emph{Argus} especially useful in practice. We further analyze some representative cases in detail to help increase the understanding of prefix hijackings in the Internet. © 2012 ACM.",bgp; hijacking detection; prefix hijacking; security,bgp; Border gateway protocol; Data planes; Detection system; False alarm rate; Interdomain Routing; Internet routing; Malicious attack; Prefix hijacking; Representative case; Routing anomalies; security; Underlying cause; Internet; Internet protocols; Network security; Gateways (computer networks)
"Suresh L., Schulz-Zander J., Merz R., Feldmann A.",4,Demo: Programming enterprise WLANs with odin,2012,4,"INESC-ID, Instituto Superior Tecnico, Lisbon, Portugal; Telekom Innovation Laboratories, TU Berlin, Berlin, Germany",TU Berlin;Telekom Innovation Laboratories,2,Germany;Portugal,2,34,28,"We present a demo of Odin, an SDN framework to program enterprise wireless local area networks (WLANs). Enterprise WLANs need to support a wide range of services and functionalities. This includes authentication, authorization and accounting, policy, mobility and interference management, and load balancing. WLANs also exhibit unique challenges. In particular, access point (AP) association decisions are not made by the infrastructure, but by clients. In addition, the association state machine combined with the broadcast nature of the wireless medium requires keeping track of a large amount of state changes. To this end, Odin builds on a light virtual AP abstraction that greatly simplifies client management. Odin does not require any client side modifications and its design supports WPA2 Enterprise. With Odin, a network operator can implement enterprise WLAN services as network applications. © 2012 Authors.",enterprise wlans; odin; sdn,"Access points; Association state; Authentication , authorization and accountings; Design support; Interference management; Network applications; Network operator; odin; sdn; Wireless medium; Authentication; Communication; Computer architecture; Network architecture; Wireless local area networks (WLAN); Industry"
"Zhang X., Ansari J., MŠhšnen P.",3,Demo: Runtime MAC reconfiguration using a meta-compiler assisted toolchain,2012,2,"RWTH Aachen University, Institute for Networked Systems, Kackertstrasse 9, D-52072 Aachen, Germany",RWTH Aachen University,1,Germany,1,36,25,"A rapid reconfiguration of medium access scheme is required in order to achieve runtime performance optimization for dynamic spectrum access and fulfilling varying Quality of Service (QoS) demands. We have developed TRUMP, a toolchain which allows composing MAC solutions at runtime. In this demonstration, we will show how MAC reconfiguration can be achieved efficiently using TRUMP. Inspired by the optimum route calculation method used in car navigation systems, the compiler toolchain in TRUMP realizes an appropriate MAC solution at runtime. TRUMP allows expressing various types of constraints and options such as speed, energy consumption and packet delivery rate which leads to different MAC compositions. The live demonstration of MAC reconfiguration will be carried out on WARP SDR platform. © 2012 Authors.",compiler assisted; mac; reconfiguration; sdr platform,Compiler-assisted; Dynamic spectrum access; In-car navigation systems; mac; Medium access; Optimum route; Packet Delivery; reconfiguration; Runtime performance; Runtimes; sdr platform; Communication; Computer architecture; Energy utilization; Navigation systems; Program compilers; Quality of service; Tools; Network architecture
"Bod’k P., Menache I., Chowdhury M., Mani P., Maltz D.A., Stoica I.",6,Surviving failures in bandwidth-constrained datacenters,2012,88,"Microsoft Research, United States; UC Berkeley, United States; Microsoft, United States",Microsoft;University of California Berkeley,2,USA,1,4,4,"Datacenter networks have been designed to tolerate failures of network equipment and provide sufficient bandwidth. In practice, however, failures and maintenance of networking and power equipment often make tens to thousands of servers unavailable, and network congestion can increase service latency. Unfortunately, there exists an inherent tradeoff between achieving high fault tolerance and reducing bandwidth usage in network core; spreading servers across fault domains improves fault tolerance, but requires additional bandwidth, while deploying servers together reduces bandwidth usage, but also decreases fault tolerance. We present a detailed analysis of a large-scale Web application and its communication patterns. Based on that, we propose and evaluate a novel optimization framework that achieves both high fault tolerance and significantly reduces bandwidth usage in the network core by exploiting the skewness in the observed communication patterns. © 2012 ACM.",bandwidth; datacenter networks; fault tolerance,Bandwidth usage; Bandwidth-constrained; Communication pattern; Data centers; Fault domains; Network congestions; Network core; Network equipment; Optimization framework; Power equipment; Service latency; WEB application; Bandwidth; Communication; Computer architecture; Fault tolerance; Network architecture
"Katz-Bassett E., Scott C., Choffnes D.R., Cunha ê., Valancius V., Feamster N., Madhyastha H.V., Anderson T., Krishnamurthy A.",9,LIFEGUARD: Practical repair of persistent route failures,2012,36,"Univ. of Southern California, United States; Univ. of Washington, United States; UC Berkeley, United States; UFMG, Brazil; Georgia Tech., United States; UC Riverside, United States",Georgia Tech;University of California Berkeley;University of California Riverside,3,Brazil;USA,2,9,9,"The Internet was designed to always find a route if there is a policy-compliant path. However, in many cases, connectivity is disrupted despite the existence of an underlying valid path. The research community has focused on short-term outages that occur during route convergence. There has been less progress on addressing avoidable long-lasting outages. Our measurements show that long-lasting events contribute significantly to overall unavailability. To address these problems, we develop LIFEGUARD, a system for automatic failure localization and remediation. LIFEGUARD uses active measurements and a historical path atlas to locate faults, even in the presence of asymmetric paths and failures. Given the ability to locate faults, we argue that the Internet protocols should allow edge ISPs to steer traffic to them around failures, without requiring the involvement of the network causing the failure. Although the Internet does not explicitly support this functionality today, we show how to approximate it using carefully crafted BGP messages. LIFEGUARD employs a set of techniques to reroute around failures with low impact on working routes. Deploying LIFEGUARD on the Internet, we find that it can effectively route traffic around an AS without causing widespread disruption. © 2012 ACM.",availability; bgp; internet; measurement; outages; repair; routing,Active measurement; Automatic failure; bgp; BGP messages; Long lasting; Research communities; Route failure; Route traffic; routing; Availability; Communication; Computer architecture; Internet; Internet protocols; Internet service providers; Measurements; Outages; Repair; Network architecture
"Farrington N., Porter G., Sun P.-C., Forencich A., Ford J., Fainman Y., Papen G., Vahdat A.",8,A demonstration of ultra-low-latency data center optical circuit switching,2012,10,"UC San Diego, United States",University of California San Diego,1,USA,1,38,32,"We designed and constructed a 24x24-port optical circuit switch (OCS) prototype with a programming time of 68.5 _s, a switching time of 2.8 _s, and a receiver electronics initialization time of 8.7 _s [1]. We demonstrate the operation of this prototype switch in a data center testbed under various workloads.",data center networks; optical circuit switching,Data centers; Optical circuit switching; Optical circuits; Programming time; Switching time; Communication; Computer architecture; Software prototyping; Network architecture
"Grandl R., Han D., Lee S.-B., Lim H., MacHado M., Mukerjee M., Naylor D.",7,Supporting network evolution and incremental deployment with XIA,2012,2,"University of Wisconsin-Madison, United States; Carnegie Mellon University, United States; Boston University, United States",Boston University;Carnegie Mellon University;;University of Wisconsin-Madison,4,USA,1,39,22,"eXpressive Internet Architecture (XIA) [1] is an architecture that natively supports multiple communication types and allows networks to evolve their abstractions and functionality to accommodate new styles of communication over time. XIA embeds an elegant mechanism for handling unforeseen communication types for legacy routers. In this demonstration, we show that XIA overcomes three key barriers in network evolution (outlined below) by (1) allowing end-hosts and applications to start using new communication types (e.g., service and content) before the network supports them, (2) ensuring that upgrading a subset of routers to support new functionalities immediately benefits applications, and (3) using the same mechanisms we employ for 1 and 2 to incrementally deploy XIA in IP networks.",evolution; internet architecture; multiple communication styles,Communication styles; evolution; Incremental deployment; Internet architecture; IP networks; Legacy routers; Network evolution; Network support; Communication; Computer architecture; Internet; Network architecture
"Wang J., Hassanieh H., Katabi D., Indyk P.",4,Efficient and reliable low-power backscatter networks,2012,96,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,7,0,"There is a long-standing vision of embedding backscatter nodes like RFIDs into everyday objects to build ultra-low power ubiquitous networks. A major problem that has challenged this vision is that backscatter communication is neither reliable nor efficient. Backscatter nodes cannot sense each other, and hence tend to suffer from colliding transmissions. Further, they are ineffective at adapting the bit rate to channel conditions, and thus miss opportunities to increase throughput, or transmit above capacity causing errors. This paper introduces a new approach to backscatter communication. The key idea is to treat all nodes as if they were a single virtual sender. One can then view collisions as a code across the bits transmitted by the nodes. By ensuring only a few nodes collide at any time, we make collisions act as a sparse code and decode them using a new customized compressive sensing algorithm. Further, we can make these collisions act as a rateless code to automatically adapt the bit rate to channel quality - i.e., nodes can keep colliding until the base station has collected enough collisions to decode. Results from a network of backscatter nodes communicating with a USRP backscatter base station demonstrate that the new design produces a 3.5_ throughput gain, and due to its rateless code, reduces message loss rate in challenging scenarios from 50% to zero. © 2012 ACM.",backscatter; compressive sensing; rfid; wireless,backscatter; Bit rates; Channel conditions; Channel quality; Compressive sensing; Low Power; Message loss; New design; Rateless codes; Sparse codes; Ubiquitous networks; Ultra-low power; Backscattering; Base stations; Communication; Computer architecture; Radio; Radio frequency identification (RFID); Signal reconstruction; Network architecture
"Niemi O.-P., LevomŠki A., Manner J.",3,Dismantling intrusion prevention systems,2012,3,"Stonesoft Corporation, Helsinki, Finland; Aalto University, Helsinki, Finland",Aalto University,1,Finland,1,1,1,"This paper introduces a serious security problem that people believe has been fixed, but which is still very much existing and evolving, namely evasions. We describe how protocols can still be misused to fool network security devices, such as intrusion prevention systems. © 2012 Authors.",evasion; ids; intrusion prevention; ips; network,evasion; ids; Intrusion prevention; Intrusion prevention systems; ips; Security problems; Communication; Computer architecture; Network architecture; Network protocols; Networks (circuits); Network security
"Kumar S., Shi L., Ahmed N., Gil S., Katabi D., Rus D.",6,CarSpeak: A content-centric network for autonomous driving,2012,20,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,52,39,"This paper introduces CarSpeak, a communication system for autonomous driving. CarSpeak enables a car to query and access sensory information captured by other cars in a manner similar to how it accesses information from its local sensors. CarSpeak adopts a content-centric approach where information objects - i.e., regions along the road - are first class citizens. It names and accesses road regions using a multi-resolution system, which allows it to scale the amount of transmitted data with the available bandwidth. CarSpeak also changes the MAC protocol so that, instead of having nodes contend for the medium, contention is between road regions, and the medium share assigned to any region depends on the number of cars interested in that region. CarSpeak is implemented in a state-of-the-art autonomous driving system and tested on indoor and outdoor hardware testbeds including an autonomous golf car and 10 iRobot Create robots. In comparison with a baseline that directly uses 802.11, CarSpeak reduces the time for navigating around obstacles by 2.4x, and reduces the probability of a collision due to limited visibility by 14x. © 2012 ACM.",autonomous vehicles; content-centric; wireless,Autonomous driving; Autonomous Vehicles; Available bandwidth; content-centric; Hardware testbeds; Information object; Limited visibility; Local sensors; MAC protocol; Multi-resolutions; Sensory information; Communication systems; Computer architecture; Medium access control; Radio; Roads and streets; Network architecture
"Fu W., Song T.",2,A frequency adjustment architecture for energy efficient router,2012,9,"Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, 100081, China",Beijing Institute of Technology,1,China,1,13,8,"With the rapid expansion of customer population and link bandwidth, energy expenditures of the Internet have been rising dramatically. To gain energy efficiency, we propose a novel router architecture, which allows each of its modules to adjust frequency according to traffic loads. Several modulation strategies are also discussed to ensure dwell time on low energy states and reduce blind switches. Our preliminary results show that the frequency adjustment router could save up to 40% of the total energy consumption. © 2012 Authors.",energy efficient router architecture; energy efficient strategy; frequency adjustment,Dwell time; Energy efficient; Energy expenditure; Frequency adjustment; Link bandwidth; Low-energy state; Modulation strategy; Rapid expansion; Router architecture; Total energy consumption; Traffic loads; Communication; Energy efficiency; Energy utilization; Network architecture; Time switches; Computer architecture
"Rahul H.S., Kumar S., Katabi D.",3,JMB: Scaling wireless capacity with user demands,2012,106,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,31,29,"We present joint multi-user beamforming (JMB), a system that enables independent access points (APs) to beamform their signals, and communicate with their clients on the same channel as if they were one large MIMO transmitter. The key enabling technology behind JMB is a new low-overhead technique for synchronizing the phase of multiple transmitters in a distributed manner. The design allows a wireless LAN to scale its throughput by continually adding more APs on the same channel. JMB is implemented and tested with both software radio clients and off-the-shelf 802.11n cards, and evaluated in a dense congested deployment resembling a conference room. Results from a 10-AP software-radio testbed show a linear increase in network throughput with a median gain of 8.1 to 9.4x. Our results also demonstrate that JMB's joint multi-user beamforming can provide throughput gains with unmodified 802.11n cards. © 2012 ACM.",distributed mimo; multi-user mimo; wireless networks,802.11n; Access points; Beamform; Conference rooms; Distributed MIMO; Enabling technologies; Multi-user; Multi-user MIMO; Network throughput; User demands; Wireless capacity; Beamforming; Communication; Computer architecture; MIMO systems; Software radio; Throughput; Transmitters; Wireless networks; Network architecture
"Liu X., Dobrian F., Milner H., Jiang J., Sekar V., Stoica I., Zhang H.",7,A case for a coordinated internet video control plane,2012,101,"Conviva, United States; CMU, United States; Intel Labs., United States; UC Berkeley, United States",University of California Berkeley,1,USA,1,4,3,"Video traffic already represents a significant fraction of today's traffic and is projected to exceed 90% in the next five years. In parallel, user expectations for a high quality viewing experience (e.g., low startup delays, low buffering, and high bitrates) are continuously increasing. Unlike traditional workloads that either require low latency (e.g., short web transfers) or high average throughput (e.g., large file transfers), a high quality video viewing experience requires sustained performance over extended periods of time (e.g., tens of minutes). This imposes fundamentally different demands on content delivery infrastructures than those envisioned for traditional traffic patterns. Our large-scale measurements over 200 million video sessions show that today's delivery infrastructure fails to meet these requirements: more than 20% of sessions have a rebuffering ratio ³ 10% and more than 14% of sessions have a video startup delay ³ 10s. Using measurement-driven insights, we make a case for a video control plane that can use a global view of client and network conditions to dynamically optimize the video delivery in order to provide a high quality viewing experience despite an unreliable delivery infrastructure. Our analysis shows that such a control plane can potentially improve the rebuffering ratio by up to 2x in the average case and by more than one order of magnitude under stress. © 2012 ACM.",cdns; control plane; video,Average case; Average throughput; Bitrates; cdns; Content delivery; Control planes; File transfers; Global view; High quality; High quality video; Internet video; Large-scale measurement; Low latency; Network condition; Sustained performance; Traffic pattern; User expectations; video; Video control; Video delivery; Video sessions; Video traffic; Communication; Computer architecture; Electronic document exchange; Network architecture
Eittenberger P.M.,1,RaptorStream: Boosting mobile peer-to-peer streaming with raptor codes,2012,4,"University of Bamberg, Germany",University of Bamberg,1,Germany,1,43,33,"As mobile devices and cellular networks become ubiquitous, first apps for popular P2P video streaming networks emerge. We have observed that when these applications operate in cellular networks, they don't upload video traffic back to other peers. This paper presents a reason for this behavior and proposes a viable solution to exploit the uplink capacity of mobile devices more efficiently. To the best of our knowledge, this paper is the first to propose the usage of Raptor codes to increase the upload throughput of mobile P2P applications. © 2012 Author.",android; mobile p2p streaming; raptor codes,android; Cellular network; Mobile P2P; Peer-to-peer streaming; Raptor codes; Streaming networks; Uplink capacity; Viable solutions; Video traffic; Communication; Computer architecture; Mobile devices; Network architecture; Peer to peer networks
"Li Y., Jin D., Hui P., Su L., Zeng L.",5,Revealing contact interval patterns in large scale urban vehicular ad hoc networks,2012,8,"Electronic Engineering Dept., Tsinghua University, Beijing 100084, China; Deutsche Telekom Lab., TU-Berlin, Berlin 10587, Germany",TU Berlin;Tsinghua University,2,China;Germany,2,43,32,"Contact interval between moving vehicles is one of the key metrics in vehicular ad hoc networks (VANETs), which is important to routing schemes and network capacity. In this work, by carrying out an extensive experiment involving tens of thousands of operational taxis in Beijing city, we find an invariant character that the contact interval can be modeled by a three-segmented distribution, and there exists a characteristic time point, up to which the contact interval obeys a power law distribution, while beyond which it decays as an exponential one. This property is in sharp contrast to the recent empirical data studies based on Shanghai vehicular mobility, where the contact interval exhibits only exponential distribution. © 2012 Authors.",contact interval patterns; mobility trace; vehicular networks,Beijing city; Characteristic time; Empirical data; Exponential distributions; Moving vehicles; Network Capacity; Power law distribution; Routing scheme; Sharp contrast; Vehicular networks; Communication; Computer architecture; Vehicular ad hoc networks; Network architecture
"Ha S., Sen S., Joe-Wong C., Im Y., Chiang M.",5,TUBE: Time-dependent pricing for mobile data,2012,122,"Princeton University, United States; Seoul National University, South Korea",Princeton University;Seoul National University,2,South Korea;USA,2,4,4,"The two largest U.S. wireless ISPs have recently moved towards usage-based pricing to better manage the growing demand on their networks. Yet usage-based pricing still requires ISPs to over-provision capacity for demand at peak times of the day. Time-dependent pricing (TDP) addresses this problem by considering when a user consumes data, in addition to how much is used. We present the architecture, implementation, and a user trial of an end-to-end TDP system called TUBE. TUBE creates a price-based feedback control loop between an ISP and its end users. On the ISP side, it computes TDP prices so as to balance the cost of congestion during peak periods with that of offering lower prices in less congested periods. On mobile devices, it provides a graphical user interface that allows users to respond to the offered prices either by themselves or using an ""autopilot"" mode. We conducted a pilot TUBE trial with 50 iPhone or iPad 3G data users, who were charged according to our TDP algorithms. Our results show that TDP benefits both operators and customers, flattening the temporal fluctuation of demand while allowing users to save money by choosing the time and volume of their usage. © 2012 ACM.",time-dependent pricing; user trial; wireless,Data users; End users; Growing demand; Mobile data; Peak period; Peak time; Pilot tubes; Price-based feedback; Temporal fluctuation; Time-dependent; user trial; Communication; Computer architecture; Graphical user interfaces; Mobile devices; Network architecture; Radio; Traffic congestion; Tubes (components); Costs
"Wu X., Turner D., Chen C.-C., Maltz D.A., Yang X., Yuan L., Zhang M.",7,NetPilot: Automating datacenter network failure mitigation,2012,29,"Duke University, United States; U.C. San Diego, United States; Microsoft, United States",Duke University;Microsoft,2,USA,1,3,3,"Driven by the soaring demands for always-on and fast-response online services, modern datacenter networks have recently undergone tremendous growth. These networks often rely on commodity hardware to reach immense scale while keeping capital expenses under check. The downside is that commodity devices are prone to failures, raising a formidable challenge for network operators to promptly handle these failures with minimal disruptions to the hosted services. Recent research efforts have focused on automatic failure localization. Yet, resolving failures still requires significant human interventions, resulting in prolonged failure recovery time. Unlike previous work, NetPilot aims to quickly mitigate rather than resolve failures. NetPilot mitigates failures in much the same way operators do - by deactivating or restarting suspected offending components. NetPilot circumvents the need for knowing the exact root cause of a failure by taking an intelligent trial-and-error approach. The core of NetPilot is comprised of an Impact Estimator that helps guard against overly disruptive mitigation actions and a failure-specific mitigation planner that minimizes the number of trials. We demonstrate that NetPilot can effectively mitigate several types of critical failures commonly encountered in production datacenter networks. © 2012 ACM.",automated failure mitigation; datacenter networks,Automatic failure; Capital expense; Commodity hardware; Critical failures; Failure mitigation; Failure recovery time; Human intervention; Network failure; Network operator; On-line service; Research efforts; Root cause; Trial-and-error approach; Communication; Computer architecture; Network architecture
"Aucinas A., Chaudhry A., Crowcroft J., Eide S.P., Hand S., Madhavapeddy A., Moore A.W., Rotsos C., Vallina-Rodriguez N., Mortier R.",10,Signposts: End-to-end networking in a world of middleboxes,2012,0,"University of Cambridge, United Kingdom; University of Nottingham, United Kingdom",University of Cambridge;University of Nottingham,2,UK,1,28,15,"This demo presents Signposts, a system to provide users with a secure, simple mechanism to establish and maintain communication channels between their personal cloud of named devices. Signpost names exist in the DNSSEC hierarchy, and resolve to secure end-points when accessed by existing DNS clients. Signpost clients intercept user connection intentions while adding privacy and multipath support. Signpost servers co-ordinate clients to dynamically discover routes and overcome the middleboxes that pervade modern edge networks. The demo will show a simple scenario where an individual's personal devices (phone, laptop) are interconnected via Signposts while sitting on different networks behind various middleboxes. As a result they will be able to fetch and push data between each other, demonstrated by, e.g., simple web browsing, even as the network configuration changes. © 2012 Authors.",dns; edge network; middlebox; naming; user-centered,dns; EDGE Networks; Middleboxes; naming; User-centered; Communication; Computer architecture; Internet protocols; Laptop computers; Network architecture
"Huici F., Di Pietro A., Trammell B., Gomez Hidalgo J.M., Martinez Ruiz D., D'Heureuse N.",6,Blockmon: A high-performance composable network traffic measurement system,2012,15,"NEC Europe Ltd., United Kingdom; CNIT, Italy; ETH Zurich, Switzerland; OPTENET, United Kingdom",ETH Zurich,1,Italy;Switzerland;UK,3,32,3,"Passive network monitoring and data analysis, crucial to the correct operation of networks and the systems that rely on them, has become an increasingly difficult task given continued growth and diversification of the Internet. In this demo we present Blockmon, a novel composable measurement system with the flexibility to allow for a wide range of traffic monitoring and data analysis, as well as the necessary mechanisms to yield high performance on today's modern multi-core hardware. In this demo we use Blockmon's GUI to show how to easily create Blockmon applications and display data exported by them. We present a simple flow meter application and a more involved VoIP nomaly detection one. © 2012 Authors.",data processing; high performance; network monitoring,Composable networks; high performance; Measurement system; Multi core; Network Monitoring; Traffic monitoring; Communication; Computer architecture; Data processing; Internet telephony; Measurements; Passive networks; Network architecture
"Ager B., Chatzis N., Feldmann A., Sarrar N., Uhlig S., Willinger W.",6,Anatomy of a large european IXP,2012,124,"ETH Zurich, Switzerland; TU Berlin, T-Labs., Germany; Queen Mary, University of London, United Kingdom; AT and T Labs.-Research, United States",AT and T Labs;ETH Zurich;TU Berlin;University of London,4,Germany;Switzerland;UK;USA,4,7,4,"The largest IXPs carry on a daily basis traffic volumes in the petabyte range, similar to what some of the largest global ISPs reportedly handle. This little-known fact is due to a few hundreds of member ASes exchanging traffic with one another over the IXP's infrastructure. This paper reports on a first-of-its-kind and in-depth analysis of one of the largest IXPs worldwide based on nine months' worth of sFlow records collected at that IXP in 2011. A main finding of our study is that the number of actual peering links at this single IXP exceeds the number of total AS links of the peer-peer type in the entire Internet known as of 2010! To explain such a surprisingly rich peering fabric, we examine in detail this IXP's ecosystem and highlight the diversity of networks that are members at this IXP and connect there with other member ASes for reasons that are similarly diverse, but can be partially inferred from their business types and observed traffic patterns. In the process, we investigate this IXP's traffic matrix and illustrate what its temporal and structural properties can tell us about the member ASes that generated the traffic in the first place. While our results suggest that these large IXPs can be viewed as a microcosm of the Internet ecosystem itself, they also argue for a re-assessment of the mental picture that our community has about this ecosystem. © 2012 ACM.",internet exchange points; internet topology; traffic characterization,AS-links; In-depth analysis; Internet Exchange; Internet topologies; Peer-peer; Traffic characterization; Traffic matrices; Traffic pattern; Traffic volumes; Communication; Computer architecture; Ecosystems; Internet service providers; Network architecture
"Voellmy A., Wang J.",2,Scalable software defined network controllers,2012,36,"Yale University, New Haven, CT, United States; University of Science and Technology of China, Hefei, China",University of Science and Technology of China;Yale University,2,China;USA,2,5,4,"Software defined networking (SDN) introduces centralized controllers to dramatically increase network programmability. The simplicity of a logical centralized controller, however, can come at the cost of control-plane scalability. In this demo, we present McNettle, an extensible SDN control system whose control event processing throughput scales with the number of system CPU cores and which supports control algorithms requiring globally visible state changes occurring at flow arrival rates. Programmers extend McNettle by writing event handlers and background programs in a high-level functional programming language extended with shared state and memory transactions. We implement our framework in Haskell and leverage the multicore facilities of the Glasgow Haskell Compiler (GHC) and runtime system. Our implementation schedules event handlers, allocates memory, optimizes message parsing and serialization, and reduces system calls in order to optimize cache usage, OS processing, and runtime system overhead. Our experiments show that McNettle can serve up to 5000 switches using a single controller with 46 cores, achieving throughput of over 14 million flows per second, near-linear scaling up to 46 cores, and latency under 200 _s for light loads and 10 ms with loads consisting of up to 5000 switches. © 2012 Authors.",haskell; multicore; openflow; software-defined networking,CPU cores; Event-handlers; Flow arrival rate; Glasgow haskell compilers; Haskell; Light loads; Multi core; openflow; Programmability; Runtime systems; Scaling-up; Single controllers; software-defined networking; System calls; Algorithms; Cache memory; Communication; Computer architecture; Controllers; Flight control systems; Integrated control; Network architecture
"Riggio R., Sengul C., Mabell Gomez K., Rasheed T.",4,Energino: Energy saving tips for your wireless network,2012,3,"CREATE-NET, Trento, Italy; Telekom Innovation Labs., TU-Berlin, Berlin, Germany",TU Berlin,1,Germany;Italy,2,53,42,"The energy wasted in wireless networks is a serious concern and the main challenge lies in determining when and where the energy is wasted. In this demo, we present Energino, an energy measurement and control system designed to deliver high performance while remaining a cheap solution. © 2012 Authors.",arduino; energy consumption monitoring; open hardware; wireless,arduino; Measurement and control; Open hardware; Communication; Energy utilization; Network architecture; Radio; Wireless networks; Computer architecture
"Knight S., Jaboldinov A., Maennel O., Phillips I., Roughan M.",5,"AutoNetkit: Simplifying large scale, open-source network experimentation",2012,1,"University of Adelaide, Australia; Loughborough University, United Kingdom",Loughborough University;University of Adelaide,2,Australia;UK,2,10,8,"We present a methodology that brings simplicity to large and complex test labs by using abstraction. The networking community has appreciated the value of large scale test labs to explore complex network interactions, as seen in projects such as PlanetLab, GENI, DETER, Emulab, and SecSI. Virtualization has enabled the creation of many more such labs. However, one problem remains: it is time consuming, tedious and error prone to setup and configure large scale test networks. Separate devices need to be configured in a coordinated way, even in a virtual lab. AutoNetkit, an open source tool, uses abstractions and defaults to achieve both configuration and deployment and create such large-scale virtual labs. This allows researchers and operators to explore new protocols, create complex models of networks and predict consequences of configuration changes. However, our abstractions could also allow the discussion of the broader configuration management problem. Abstractions that currently configure networks in a test lab can, in the future, be employed in configuration management tools for real networks. © 2012 Authors.",automated configuration; emulation; network management,Automated configuration; Complex model; Complex networks; Configuration management; Configuration management tools; emulation; Error prones; Large scale tests; Networking community; New protocol; Open source tools; Open-source network; PlanetLab; Real networks; Separate devices; Virtual lab; Virtualizations; Abstracting; Chemical laboratories; Communication; Computer architecture; Network management; Network architecture
"Kang N., Reich J., Rexford J., Walker D.",4,Policy transformation in software defined networks,2012,6,"Princeton University, United States",Princeton University,1,USA,1,2,2,"A Software Defined Network (SDN) enforces network-wide policies by installing packet-handling rules across a distributed collection of switches. Today's SDN platforms force programmers to decide how to decompose a high-level policy into the low-level rules in each switch. We argue that future SDN platforms should support automatic transformation of policies by moving, merging, or splitting rules across multiple switches. This would simplify programming by allowing programs written on one abstract switch to run over a more complex network topology, and simplify analysis by consolidating a policy spread over multiple switches into a single list of rules. This poster presents our ongoing work on a sound and complete set of axioms for policy transformation, to enable rewriting of rules across multiple switches while preserving the forwarding policy. These axioms are invaluable for creating and analyzing algorithms for optimizing the rewriting of rules. © 2012 Authors.",network virtualization; openflow; software defined networks,Automatic transformations; Complex networks; High level policies; Network virtualization; openflow; Policy transformation; Communication; Computer architecture; Electric network topology; Network architecture
"Mineraud J., Balasubramaniam S., Kangasharju J., Donnelly W.",4,fs-PGBR: A scalable and delay sensitive cloud routing protocol,2012,0,"Telecommunications Software and Systems Group, Waterford Institute of Technology, Ireland; Department of Computer Science, University of Helsinki, Finland",University of Helsinki;Waterford Institute of Technology,2,Finland;Ireland,2,7,4,"This paper proposes an improved version of a fully distributed routing protocol, that is applicable for cloud computing infrastructure. Simulation results shows the protocol is ideal for discovering cloud services in a scalable manner with minimum latency. © 2012 Authors.",cloud computing infrastructure; scalable route discovery,Cloud services; Computing infrastructures; Delay sensitive; Distributed routing protocols; Route discovery; Cloud computing; Communication; Computer architecture; Routing protocols; Network architecture
"WŠhlisch M., Trapp S., Schiller J., Jochheim B., Nolte T., Schmidt T.C., Ugus O., Westhoff D., Kutscher M., KŸster M., Keil C., Schšnfelder J.",12,Vitamin C for your smartphone: The SKIMS approach for cooperative and lightweight security at mobiles,2012,0,"Institut fŸr Informatik, Freie UniversitŠt Berlin, Berlin, Germany; Dept. Informatik, Hamburg University of Applied Sciences, Hamburg, Germany; Escrypt GmbH, Bochum, Germany; DFN-CERT Services GmbH, Hamburg, Germany",Bochum;DFN-CERT Services GmbH;Escrypt GmbH;Freie UniversitŠt Berlin;Hamburg University of Applied Sciences,5,Germany,1,4,4,"Smartphones are popular attack targets, but usually too weak in applying common protection concepts. SKIMS designs and implements a cooperative, cross-layer security system for mobile devices. Detection mechanisms as well as a proactive and reactive defense of attacks are core components of this project. In this demo, we show a comprehensive proof-of-concept of our approaches, which include entropy-based malware detection, a mobile honeypot, and spontaneous, socio-inspired trust establishment. © 2012 Authors.",ad hoc trust; malware detection; mobile honeypot; mobile security,ad hoc trust; Attack target; Core components; Cross-layer; Detection mechanism; Entropy-based; Honeypots; Malware detection; Mobile security; Proof of concept; Protection concepts; Trust establishment; Vitamin C; Communication; Computer crime; Mobile devices; Network architecture; Smartphones; Computer architecture
"Gill H., Lin D., Sarna L., Mead R., Lee K.C.T., Loo B.T.",6,SP4: Scalable programmable packet processing platform,2012,4,"University of Pennsylvania, Philadelphia, PA, United States",University of Pennsylvania,1,USA,1,3,3,"We propose the demonstration of SP4, a software-based programmable packet processing platform that supports (1) stateful packet processing useful for analyzing traffic flows with session semantics, (2) uses a task-stealing architecture that automatically leverages multi-core processing capabilities in a load-balanced manner without the need for explicit performance profiling, and (3) a declarative language for rapidly specifying and composing new packet processing functionalities from reusable modules. Our demonstration showcases the use of SP4 for performing high-throughput analysis of traffic traces for a variety of applications, such as filtering out unwanted traffic and detection of DDoS attacks using machine learning based analysis. © 2012 Authors.",declarative networking; multicore; packet analysis,DDoS Attack; Declarative Languages; Declarative networkings; High-throughput analysis; Load-balanced; Multi core; Packet analysis; Packet processing; Processing capability; Software-based; Traffic flow; Traffic traces; Unwanted traffic; Communication; Network architecture; Packet networks; Semantics; Computer architecture
"Nychis G.P., Fallin C., Moscibroda T., Mutlu O., Seshan S.",5,On-chip networks from a networking perspective: Congestion and scalability in many-core interconnects,2012,41,"Carnegie Mellon University, United States; Microsoft Research Asia, United States",Carnegie Mellon University;Microsoft,2,USA,1,4,4,"In this paper, we present network-on-chip (NoC) design and contrast it to traditional network design, highlighting similarities and differences between the two. As an initial case study, we examine network congestion in bufferless NoCs. We show that congestion manifests itself differently in a NoC than in traditional networks. Network congestion reduces system throughput in congested workloads for smaller NoCs (16 and 64 nodes), and limits the scalability of larger bufferless NoCs (256 to 4096 nodes) even when traffic has locality (e.g., when an application's required data is mapped nearby to its core in the network). We propose a new source throttling-based congestion control mechanism with application-level awareness that reduces network congestion to improve system performance. Our mechanism improves system performance by up to 28% (15% on average in congested workloads) in smaller NoCs, achieves linear throughput scaling in NoCs up to 4096 cores (attaining similar performance scalability to a NoC with large buffers), and reduces power consumption by up to 20%. Thus, we show an effective application of a network-level concept, congestion control, to a class of networks - bufferless on-chip networks - that has not been studied before by the networking community. © 2012 ACM.",congestion control; multi-core; on-chip networks,Congestion control mechanism; Large buffer; Many-core; Multi core; Network congestions; Network design; Network-on-chip design; Networking community; New sources; On-chip networks; Performance scalability; System throughput; Communication; Computer architecture; Congestion control (communication); Scalability; VLSI circuits; Network architecture
"Wang A., Gurney A.J.T., Han X., Cao J., Talcot C., Loo B.T., Scedrov A.",7,Reduction-based analysis of BGP systems with BGPVerif,2012,0,"University of Pennsylvania, United States; SRI International, United States",University of Pennsylvania,1,USA,1,11,6,"Today's inter-domain routing protocol, the Border Gateway Protocol (BGP), is increasingly complicated and fragile due to policy misconfiguration by individual autonomous systems (ASes). Existing configuration analysis techniques are either manual and tedious, or do not scale beyond a small number of nodes due to the state explosion problem. To aid the diagnosis of misconfigurations in real-world large BGP systems, this paper presents BGPVerif , a reduction based analysis toolkit. The key idea is to reduce BGP system size prior to analysis while preserving crucial correctness properties. BGPVerif consists of two components, NetReducer that simplifies BGP configurations, and NetAnalyzer that automatically detects routing oscillation. BGPVerif accepts a wide range of BGP configuration inputs ranging from real-world traces (Rocketfuel network topologies), randomly generated BGP networks (GT-ITM), Cisco configuration guidelines, as well as arbitrary user-defined networks. BGPVerif illustrates the applicability, efficiency, and benefits of the reduction technique, it also introduces an infrastructure that enables networking researchers to interact with advanced formal method tool. © 2012 Authors.",border gateway protocol; formal analysis; reduction,Autonomous systems; Border gateway protocol; Configuration analysis; Correctness properties; Formal analysis; Interdomain Routing; Misconfigurations; Network topology; Networking researchers; Reduction techniques; State explosion problems; System size; Two-component; Communication; Computer architecture; Electric network topology; Formal methods; Network architecture; Reduction; Gateways (computer networks)
"Hong S.S., Mehlman J., Katti S.",3,Picasso: Flexible RF and spectrum slicing,2012,66,"Stanford University, United States",Stanford University,1,USA,1,71,50,"This paper presents the design, implementation and evaluation of Picasso, a novel radio design that allows simultaneous transmission and reception on separate and arbitrary spectrum fragments using a single RF frontend and antenna. Picasso leverages this capability to flexibly partition fragmented spectrum into multiple slices that share the RF frontend and antenna, yet operate concurrent and independent PHY/MAC protocols. We show how this capability provides a general and clean abstraction to exploit fragmented spectrum in WiFi networks, handle coexistence in dense deployments as well as many other applications. We prototype Picasso, and demonstrate experimentally that a Picasso radio partitioned into four slices, each concurrently operating four standard WiFi OFDM PHY and CSMA MAC stacks, can achieve the same sum throughput as four physically separate radios individually configured to operate on the spectrum fragments. We also demonstrate experimentally how Picasso's slicing abstraction provides a clean mechanism to enable multiple diverse networks to coexist and achieve higher throughput, better video quality and latency than the best known state of the art approaches. © 2012 Authors.",interference cancellation; radio virtualization,Interference cancellation; Radio design; RF front end; Simultaneous transmission; Spectrum fragments; Spectrum slicing; State-of-the-art approach; Video quality; Virtualizations; Wi Fi networks; Abstracting; Antennas; Communication; Computer architecture; Separation; Wi-Fi; Network architecture
"Cidon A., Nagaraj K., Katti S., Viswanath P.",4,Flashback: Decoupled lightweight wireless control,2012,31,"Stanford University, United States; University of Illinois at Urbana-Champaign, United States",Stanford University;UIUC,2,USA,1,11,6,"Unlike their cellular counterparts, Wi-Fi networks do not have the luxury of a dedicated control plane that is decoupled from the data plane. Consequently, Wi-Fi struggles to provide many of the capabilities that are taken for granted in cellular networks, including efficient and fair resource allocation, QoS and handoffs. The reason for the lack of a control plane with designated spectrum is that it would impose significant overhead. This is at odds with Wi-Fi's goal of providing a simple, plug-and-play network. In this paper we present Flashback, a novel technique that provides a decoupled low overhead control plane for wireless networks that retains the simplicity of Wi-Fi's distributed asynchronous operation. Flashback allows nodes to reliably send short control messages concurrently with data transmissions, while ensuring that data packets are decoded correctly without harming throughput. We utilize Flashback's novel messaging capability to design, implement and experimentally evaluate a reliable control plane for Wi-Fi with rates from 175Kbps to 400Kbps depending on the environment. Moreover, to demonstrate its broad applicability, we design and implement a novel resource allocation mechanism that utilizes Flashback to provide efficient, QoS-aware and fair medium access, while eliminating control overheads including data plane contention, RTS/CTS and random back offs. © 2012 ACM.",wireless control,Allocation mechanism; Asynchronous operation; Backoffs; Cellular network; Control messages; Control overhead; Control planes; Data packet; Data planes; Fair resource allocation; Low overhead; Medium access; Novel techniques; Plug-and-play networks; Reliable control; RTS/CTS; Wi Fi networks; Wireless control; Communication; Computer architecture; Computer resource management; Medium access control; Network architecture; Wi-Fi
"Steiner M., Gaglianello B.G., Gurbani V., Hilt V., Roome W.D., Scharf M., Voith T.",7,Network-aware service placement in a distributed cloud environment,2012,31,"Bell Labs., Alcatel-Lucent, Germany",Bell Labs,1,Germany,1,40,35,"We consider a system of compute and storage resources geographically distributed over a large number of locations connected via a wide-area network. By distributing the resources, latency to users can be decreased, bandwidth costs reduced and availablility increased. The challenge is to distribute services with varying characteristics among the data centers optimally. Some services are very latency sensitive, others need vast amounts of storage, and yet others are computationally complex but do not require hard deadlines on execution. We propose efficient algorithms for the placement of services to get the maximum benefit from a distributed cloud systems. The algorithms need input on the status of the network, compute resources and data resources, which are matched to application requirements. This demonstration shows how a network-aware cloud can combine all three resource types - computation, storage, and network connectivity - in distributed cloud environments. Our dynamic service placement algorithm monitors the network and data center resources in real-time. Our prototype uses the information gathered to place or migrate services to provide the best user experience for a service. © 2012 Authors.",cloud; service placement,Application requirements; Cloud systems; Compute resources; Data centers; Data resources; Dynamic services; Network connectivity; Network-aware services; Placement algorithm; service placement; Storage resources; User experience; Algorithms; Clouds; Communication; Computer architecture; Network architecture; Wide area networks; Distributed computer systems
"Ciucu F., Schmitt J.",2,"Perspectives on network calculus: No free lunch, but still good value",2012,33,"T-Labs., TU Berlin, Germany; University of Kaiserslautern, Germany",TU Berlin;University of Kaiserslautern,2,Germany,1,21,13,"ACM Sigcomm 2006 published a paper [26] which was perceived to unify the deterministic and stochastic branches of the network calculus (abbreviated throughout as DNC and SNC) [39]. Unfortunately, this seemingly fundamental unification - which has raised the hope of a straightforward transfer of all results from DNC to SNC - is invalid. To substantiate this claim, we demonstrate that for the class of stationary and ergodic processes, which is prevalent in traffic modelling, the probabilistic arrival model from [26] is quasi-deterministic, i.e., the underlying probabilities are either zero or one. Thus, the probabilistic framework from [26] is unable to account for statistical multiplexing gain, which is in fact the raison d'tre of packet-switched networks. Other previous formulations of SNC can capture statistical multiplexing gain, yet require additional assumptions [12], [22] or are more involved [14], [9] [28], and do not allow for a straightforward transfer of results from DNC. So, in essence, there is no free lunch in this endeavor. Our intention in this paper is to go beyond presenting a negative result by providing a comprehensive perspective on network calculus. To that end, we attempt to illustrate the fundamental concepts and features of network calculus in a systematic way, and also to rigorously clarify some key facts as well as misconceptions. We touch in particular on the relationship between linear systems, classical queueing theory, and network calculus, and on the lingering issue of tightness of network calculus bounds. We give a rigorous result illustrating that the statistical multiplexing gain scales as ½(ÃN), as long as some small violations of system performance constraints are tolerable. This demonstrates that the network calculus can capture actual system behavior tightly when applied carefully. Thus, we positively conclude that it still holds promise as a valuable systematic methodology for the performance analysis of computer and communication systems, though the unification of DNC and SNC remains an open, yet quite elusive task. Copyright 2012 ACM.",network calculus; queueing theory; statistical multiplexing gain,Actual system; Arrival models; Ergodic process; Fundamental concepts; Network calculus; No free lunch; Performance analysis; Performance constraints; Probabilistic framework; Systematic methodology; Traffic modelling; Calculations; Communication systems; Computer architecture; Linear systems; Multiplexing; Queueing theory; Network architecture
"Saarinen A., Siekkinen M., Xiao Y., Nurminen J.K., Kemppainen M., Hui P.",6,SmartDiet: Offloading popular apps to save energy,2012,12,"Aalto University, School of Science, Finland; Deutsche Telekom Labs., Berlin, Germany",Aalto University,1,Finland;Germany,2,5,1,"Offloading computation to cloud has been widely used for extending battery life of mobile devices. However, little effort has been invested in applying the offloading techniques to communication-related tasks. We propose SmartDiet, a toolkit to identify the constraints that reduce offloading opportunities and to calculate the energy-saving potential of offloading communication-related tasks. SmartDiet traces the method-level application execution and estimates the allocation of communication energy cost from traffic traces. We discuss key features of SmartDiet and show some preliminary results using a prototype implementation. © 2012 Authors.",constraint analysis; energy consumption; offloading,Application execution; Battery life; Communication energy; Communication-related tasks; Constraint analysis; Energy saving potential; Key feature; offloading; Prototype implementations; Save energy; Traffic traces; Computer architecture; Energy utilization; Mobile devices; Network architecture; Communication
"Zhao M., Zhou W., Gurney A.J.T., Haeberlen A., Sherr M., Loo B.T.",6,Private and verifiable interdomain routing decisions,2012,20,"University of Pennsylvania, United States; Georgetown University, United States",Georgetown University;University of Pennsylvania,2,USA,1,51,25,"Existing secure interdomain routing protocols can verify validity properties about individual routes, such as whether they correspond to a real network path. It is often useful to verify more complex properties relating to the route decision procedure - for example, whether the chosen route was the best one available, or whether it was consistent with the network's peering agreements. However, this is difficult to do without knowing a network's routing policy and full routing state, which are not normally disclosed. In this paper, we show how a network can allow its peers to verify a number of nontrivial properties of its interdomain routing decisions without revealing any additional information. If all the properties hold, the peers learn nothing beyond what the interdomain routing protocol already reveals; if a property does not hold, at least one peer can detect this and prove the violation. We present SPIDeR, a practical system that applies this approach to the Border Gateway Protocol, and we report results from an experimental evaluation to demonstrate that SPIDeR has a reasonable overhead. © 2012 ACM.",accountability; fault detection; privacy; routing; security,accountability; Border gateway protocol; Complex properties; Decision procedure; Experimental evaluation; Interdomain Routing; Nontrivial properties; Practical systems; Real networks; routing; Routing policies; security; Communication; Computer architecture; Data privacy; Fault detection; Gateways (computer networks); Network architecture; Network security; Routing protocols; Peer to peer networks
"Ma Y., Banerjee S.",2,A smart pre-classifier to reduce power consumption of TCAMs for multi-dimensional packet classification,2012,31,"University of Wisconsin, Madison, WI, United States",University of Wisconsin-Madison,1,USA,1,9,9,"Ternary Content-Addressable Memories (TCAMs) has become the industrial standard for high-throughput packet classification. However, one major drawback of TCAMs is their high power consumption, which is becoming critical with the boom of data centers, the growing classifiers and the deployment of IPv6. In this paper, we propose a practical and efficient solution which introduces a smart pre-classifier to reduce power consumption of TCAMs for multi-dimensional packet classification. We reduce the dimension of the problem through the pre-classifier which pre-classifies a packet on two header fields, source and destination IP addresses. We then return to the high dimension problem where only a small portion of a TCAM is activated and searched for a given packet. The smart pre-classifier is built in a way such that a given packet matches at most one entry in the pre-classifier, which make commodity TCAMs sufficient to implement the pre-classifier. Furthermore, each rule is stored only once in one of the TCAM blocks, which avoids rule replication. The presented solution uses commodity TCAMs, and the proposed algorithms are easy to implement. Our scheme achieves a median power reduction of 91% and an average power reduction of 88% on real and synthetic classifiers respectively. © 2012 ACM.",packet classification; power consumption; smartpc,Average power; Data centers; High dimension problems; High power consumption; High-throughput; Industrial standards; IP addresss; Multi-dimensional packets; Packet classification; Power reductions; smartpc; Ternary content addressable memories; Algorithms; Communication; Computer architecture; Electric power utilization; Logic gates; Network architecture; Packet networks; Ternary content adressable memory
"Otto J.S., S‡nchez M.A., Rula J.P., Stein T., Bustamante F.E.",5,Namehelp: Intelligent client-side DNS resolution,2012,3,"Northwestern University, United States",Northwestern University,1,USA,1,43,29,"The Domain Name System (DNS) is a fundamental component of today's Internet. Recent years have seen radical changes to DNS with increases in usage of remote DNS and public DNS services such as OpenDNS. Given the close relationship between DNS and Content Delivery Networks (CDNs) and the pervasive use of CDNs by many popular applications including web browsing and real-time entertainment services, it is important to understand the impact of remote and public DNS services on users' overall experience on the Web. This work presents a tool, namehelp, which comparatively evaluates DNS services in terms of the web performance they provide, and implements an end-host solution to address the performance impact of remote DNS on CDNs. The demonstration will show the functionality of namehelp with online results for its performance improvements. © 2012 Authors.",content delivery networks; domain name system,Content delivery network; Domain name system; Entertainment services; Fundamental component; Performance impact; Performance improvements; Web performance; Communication; Computer architecture; Network architecture; Internet protocols
"Popa L., Kumar G., Chowdhury M., Krishnamurthy A., Ratnasamy S., Stoica I.",6,FairCloud: Sharing the network in cloud computing,2012,163,"HP Labs., United States; UC Berkeley, United States; U. Washington, United States",HP Labs;University of California Berkeley,2,USA,1,26,17,"The network, similar to CPU and memory, is a critical and shared resource in the cloud. However, unlike other resources, it is neither shared proportionally to payment, nor do cloud providers offer minimum guarantees on network bandwidth. The reason networks are more difficult to share is because the network allocation of a virtual machine (VM) X depends not only on the VMs running on the same machine with X, but also on the other VMs that X communicates with and the cross-traffic on each link used by X. In this paper, we start from the above requirements - payment proportionality and minimum guarantees - and show that the network-specific challenges lead to fundamental tradeoffs when sharing cloud networks. We then propose a set of properties to explicitly express these tradeoffs. Finally, we present three allocation policies that allow us to navigate the tradeoff space. We evaluate their characteristics through simulation and testbed experiments to show that they can provide minimum guarantees and achieve better proportionality than existing solutions. © 2012 ACM.",cloud computing; network sharing,Allocation policies; Cloud providers; Cross-traffic; Network bandwidth; Network sharing; Shared resources; Virtual machines; Cloud computing; Commerce; Communication; Computer architecture; Network architecture
"WŠhlisch M., Maennel O., Schmidt T.C.",3,Towards detecting BGP route hijacking using the RPKI,2012,17,"Freie UniversitŠt Berlin, Germany; Loughborough University, United Kingdom; HAW Hamburg, Germany",Freie UniversitŠt Berlin;Loughborough University,2,Germany;UK,2,7,5,"Prefix hijacking has always been a big concern in the Internet. Some events made it into the international world-news, but most of them remain unreported or even unnoticed. The scale of the problem can only be estimated. The Resource Publication Infrastructure (RPKI) is an effort by the IETF to secure the inter-domain routing system. It includes a formally verifiable way of identifying who owns legitimately which portion of the IP address space. The RPKI has been standardized and prototype implementations are tested by Internet Service Providers (ISPs). Currently the system holds already about 2% of the Internet routing table. Therefore, in theory, it should be easy to detect hijacking of prefixes within that address space. We take an early look at BGP update data and check those updates against the RPKI - -in the same way a router would do, once the system goes operational. We find many interesting dynamics, not all can be easily explained as hijacking, but a significant number are likely operational testing or misconfigurations. © 2012 Authors.",bgp; deployment; rpki; secure inter-domain routing,Address space; bgp; deployment; Interdomain Routing; Internet routing; IP addresss; Misconfigurations; Operational testing; Prefix hijacking; Prototype implementations; rpki; Communication; Computer architecture; Dense wavelength division multiplexing; Network architecture; Internet service providers
"NŽmeth F., Stipkovits ç., Sonkoly B., Guly‡s A.",4,Towards SmartFlow: Case studies on enhanced programmable forwarding in OpenFlow switches,2012,1,"HSN Lab., Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Hungary",Budapest University of Technology and Economics,1,Hungary,1,26,17,"The limited capabilities of the switches renders the implementation of unorthodox routing and forwarding mechanisms as a hard task in OpenFlow. Our high level goal is therefore to inspect the possibilities of slightly smartening up the OpenFlow switches. As a first step in this direction we demonstrate (with Bloom filters, greedy routing and network coding) that a very limited computational capability enables us to natively support experimental technologies while preserving performance. We distribute the demos in source files and as a ready-to-experiment VM image to promote further improvements and evaluations. © 2012 Authors.",bloom filters; greedy routing; network coding; openflow; sdn,Bloom filters; Computational capability; Greedy routing; Hard task; openflow; sdn; Source files; Blooms (metal); Communication; Computer architecture; Network coding; Network architecture
"Lee C., Jang K., Moon S.",3,Reviving delay-based TCP for data centers,2012,9,"KAIST, Daejeon, South Korea; Microsoft Research, Cambridge, United Kingdom",KAIST;Microsoft,2,South Korea;UK,2,6,4,"With the rapid growth of data centers, minimizing the queueing delay at network switches has been one of the key challenges. In this work, we analyze the shortcomings of the current TCP algorithm when used in data center networks, and we propose to use latency-based congestion detection and rate-based transfer to achieve ultra-low queueing delay in data centers. © 2012 Authors.",data centers; latency; tcp,Congestion detection; Data centers; latency; Network switches; Queueing delays; Rapid growth; tcp; Communication; Computer architecture; Queueing networks; Transmission control protocol; Network architecture
"WŠhlisch M., Trapp S., Keil C., Schšnfelder J., Schmidt T.C., Schiller J.",6,First insights from a mobile honeypot,2012,4,"Institut fŸr Informatik, Freie UniversitŠt Berlin, Germany; DFN-CERT Services GmbH, Hamburg, Germany; Dept. Informatik, Hamburg University of Applied Sciences, Hamburg, Germany",DFN-CERT Services GmbH;Freie UniversitŠt Berlin;Hamburg University of Applied Sciences,3,Germany,1,5,5,"Computer systems are commonly attacked by malicious transport contacts. We present a comparative study that analyzes to what extent those attacks depend on the network access, in particular if an adversary targets specifically on mobile or non-mobile devices. Based on a mobile honeypot that extracts first statistical results, our findings indicate that a few topological domains of the Internet have started to place particular focus on attacking mobile networks. © 2012 Authors.",mobile honeypot; mobile vs. non-mobile attacks,Comparative studies; Honeypots; mobile vs. non-mobile attacks; Network access; Communication; Computer architecture; Mobile devices; Mobile telecommunication systems; Network architecture
"Zats D., Das T., Mohan P., Borthakur D., Katz R.",5,DeTail: Reducing the flow completion time tail in datacenter networks,2012,153,"University of California, Berkeley, CA, United States; Facebook, United States",Facebook;University of California Berkeley,2,USA,1,5,4,"Web applications have now become so sophisticated that rendering a typical page may require hundreds of intra-datacenter flows. At the same time, web sites must meet strict page creation deadlines of 200-300ms to satisfy user demands for interactivity. Long-tailed flow completion times make it challenging for web sites to meet these constraints. They are forced to choose between rendering a subset of the complex page, or delay its rendering, thus missing deadlines and sacrificing either quality or responsiveness. Either option leads to potential financial loss. In this paper, we present a new cross-layer network stack aimed at reducing the long tail of flow completion times. The approach exploits cross-layer information to reduce packet drops, prioritize latency-sensitive flows, and evenly distribute network load, effectively reducing the long tail of flow completion times. We evaluate our approach through NS-3 based simulation and Click-based implementation demonstrating our ability to consistently reduce the tail across a wide range of workloads. We often achieve reductions of over 50% in 99.9th percentile flow completion times. © 2012 ACM.",datacenter network; flow statistics; multi-path,Completion time; Cross-layer; Cross-layer networks; Financial loss; Flow statistics; Interactivity; Long tail; multi-path; Network load; Packet drops; User demands; WEB application; Communication; Computer architecture; Computer network performance evaluation; Losses; Network layers; Websites; Network architecture
"Zhou X., Zhang Z., Zhu Y., Li Y., Kumar S., Vahdat A., Zhao B.Y., Zheng H.",8,Mirror mirror on the ceiling: Flexible wireless links for data centers,2012,91,"Department of Computer Science, U. C. Santa Barbara, United States; Xi'an Jiaotong University, China; Google, U. C. San Diego, United States",Google;University of California San Diego;University of California Santa Barbara;Xian JiaoTong University,4,China;USA,2,3,3,"Modern data centers are massive, and support a range of distributed applications across potentially hundreds of server racks. As their utilization and bandwidth needs continue to grow, traditional methods of augmenting bandwidth have proven complex and costly in time and resources. Recent measurements show that data center traffic is often limited by congestion loss caused by short traffic bursts. Thus an attractive alternative to adding physical bandwidth is to augment wired links with wireless links in the 60 GHz band. We address two limitations with current 60 GHz wireless proposals. First, 60 GHz wireless links are limited by line-of-sight, and can be blocked by even small obstacles. Second, even beamforming links leak power, and potential interference will severely limit concurrent transmissions in dense data centers. We propose and evaluate a new wireless primitive for data centers, 3D beamforming, where 60 GHz signals bounce off data center ceilings, thus establishing indirect line-of-sight between any two racks in a data center. We build a small 3D beamforming testbed to demonstrate its ability to address both link blockage and link interference, thus improving link range and number of concurrent transmissions in the data center. In addition, we propose a simple link scheduler and use traffic simulations to show that these 3D links significantly expand wireless capacity compared to their 2D counterparts. © 2012 ACM.",60 ghz wireless; data centers; wireless beamforming,3D beamforming; 60 GHz band; Concurrent transmission; Congestion loss; Data centers; Distributed applications; Line-of-sight; Link interference; Potential interferences; Traffic simulations; Wired links; Wireless capacity; Wireless link; Bandwidth; Beamforming; Communication; Computer architecture; Mirrors; Three dimensional; Three dimensional computer graphics; Ultrasonic devices; Network architecture
"Reitblatt M., Foster N., Rexford J., Schlesinger C., Walker D.",5,Abstractions for network update,2012,270,"Cornell University, United States; Princeton University, United States",Cornell University;Princeton University,2,USA,1,33,17,"Configuration changes are a common source of instability in networks, leading to outages, performance disruptions, and security vulnerabilities. Even when the initial and final configurations are correct, the update process itself often steps through intermediate configurations that exhibit incorrect behaviors. This paper introduces the notion of consistent network updates - updates that are guaranteed to preserve well-defined behaviors when transitioning mbetween configurations. We identify two distinct consistency levels, per-packet and per-flow, and we present general mechanisms for implementing them in Software-Defined Networks using switch APIs like OpenFlow. We develop a formal model of OpenFlow networks, and prove that consistent updates preserve a large class of properties. We describe our prototype implementation, including several optimizations that reduce the overhead required to perform consistent updates. We present a verification tool that leverages consistent updates to significantly reduce the complexity of checking the correctness of network control software. Finally, we describe the results of some simple experiments demonstrating the effectiveness of these optimizations on example applications. © 2012 ACM.",consistency; frenetic; network programming languages; openflow; planned change; software-defined networking,consistency; frenetic; Network programming language; openflow; planned change; software-defined networking; Communication; Computer architecture; Optimization; Switching circuits; Verification; Network architecture
"WŠhlisch M., Schmidt T.C., Vahlenkamp M.",3,Bulk of interest: Performance measurement of content-centric routing,2012,5,"Freie UniversitŠt Berlin, Germany; HAW Hamburg, Informatik, Germany",Freie UniversitŠt Berlin,1,Germany,1,46,32,"The paradigm of information-centric networking subsumes recent approaches to integrate content replication services into a future Internet layer. Current concepts foster either a dynamic mapping that directs content requests to a nearby copy, or an immediate routing on content identifiers. In this paper, we evaluate in practical experiments the performance of content routing, which we analyze with a focus on conceptual aspects. Our findings indicate that the performance of the content distribution system is threatened by a heavy management of states that arise from the strong coupling of the control to the data plane in the underlying routing infrastructure. © 2012 Authors.",experimental evaluation; performance; routing,Content distribution systems; Content identifiers; Content replication; Content routing; Data planes; Dynamic mapping; Experimental evaluation; Future internet; performance; Performance measurements; routing; Routing infrastructure; Strong coupling; Communication; Computer architecture; Network architecture
"Sherry J., Hasan S., Scott C., Krishnamurthy A., Ratnasamy S., Sekar V.",6,Making middleboxes someone else's problem: Network processing as a cloud service,2012,224,"UC Berkeley, United States; University of Washington, United States; Intel Labs., United States",University of California Berkeley;University of Washington at Seattle,2,USA,1,24,21,"Modern enterprises almost ubiquitously deploy middlebox processing services to improve security and performance in their networks. Despite this, we find that today's middlebox infrastructure is expensive, complex to manage, and creates new failure modes for the networks that use them. Given the promise of cloud computing to decrease costs, ease management, and provide elasticity and fault-tolerance, we argue that middlebox processing can benefit from outsourcing the cloud. Arriving at a feasible implementation, however, is challenging due to the need to achieve functional equivalence with traditional middlebox deployments without sacrificing performance or increasing network complexity. In this paper, we motivate, design, and implement APLOMB, a practical service for outsourcing enterprise middlebox processing to the cloud. Our discussion of APLOMB is data-driven, guided by a survey of 57 enterprise networks, the first large-scale academic study of middlebox deployment. We show that APLOMB solves real problems faced by network administrators, can outsource over 90% of middlebox hardware in a typical large enterprise network, and, in a case study of a real enterprise, imposes an average latency penalty of 1.1ms and median bandwidth inflation of 3.8%. © 2012 ACM.",cloud; middlebox; outsourcing,Cloud services; Enterprise networks; Functional equivalence; Middleboxes; Network administrator; Network complexity; Network processing; Outsource; Real problems; Security and performance; Clouds; Communication; Computer architecture; Elasticity; Fault tolerance; Industry; Outsourcing; Network architecture
"Ghodsi A., Sekar V., Zaharia M., Stoica I.",4,Multi-resource fair queueing for packet processing,2012,73,"University of California, Berkeley, CA, United States; Intel ISTC, United States; KTH/Royal Institute of Technology, Sweden",KTH Royal Institute of Technology;University of California Berkeley,2,Sweden;USA,2,4,4,"Middleboxes are ubiquitous in today's networks and perform a variety of important functions, including IDS, VPN, firewalling, and WAN optimization. These functions differ vastly in their requirements for hardware resources (e.g., CPU cycles and memory bandwidth). Thus, depending on the functions they go through, different flows can consume different amounts of a middlebox's resources. While there is much literature on weighted fair sharing of link bandwidth to isolate flows, it is unclear how to schedule multiple resources in a middlebox to achieve similar guarantees. In this paper, we analyze several natural packet scheduling algorithms for multiple resources and show that they have undesirable properties. We propose a new algorithm, Dominant Resource Fair Queuing (DRFQ), that retains the attractive properties that fair sharing provides for one resource. In doing so, we generalize the concept of virtual time in classical fair queuing to multi-resource settings. The resulting algorithm is also applicable in other contexts where several resources need to be multiplexed in the time domain. © 2012 ACM.",fair queueing; fairness; middleboxes; scheduling,CPU cycles; Fair queueing; Fair queuing; Fair sharing; fairness; Hardware resources; Link bandwidth; Memory bandwidths; Middleboxes; Multi-resource; Multiple resources; Packet processing; Packet scheduling algorithm; Time domain; Virtual-time; Algorithms; Communication; Computer architecture; Distributed computer systems; Packet networks; Queueing theory; Scheduling; Network architecture
"Perry J., Iannucci P.A., Fleming K.E., Balakrishnan H., Shah D.",5,Spinal codes,2012,24,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,47,24,"Spinal codes are a new class of rateless codes that enable wireless networks to cope with time-varying channel conditions in a natural way, without requiring any explicit bit rate selection. The key idea in the code is the sequential application of a pseudo-random hash function to the message bits to produce a sequence of coded symbols for transmission. This encoding ensures that two input messages that differ in even one bit lead to very different coded sequences after the point at which they differ, providing good resilience to noise and bit errors. To decode spinal codes, this paper develops an approximate maximum-likelihood decoder, called the bubble decoder, which runs in time polynomial in the message size and achieves the Shannon capacity over both additive white Gaussian noise (AWGN) and binary symmetric channel (BSC) models. Experimental results obtained from a software implementation of a linear-time decoder show that spinal codes achieve higher throughput than fixed-rate LDPC codes, rateless Raptor codes, and the layered rateless coding approach of Strider, across a range of channel conditions and message sizes. An early hardware prototype that can decode at 10 Mbits/s in FPGA demonstrates that spinal codes are a practical construction. © 2012 ACM.",capacity; channel code; practical decoder; rateless; spinal code; wireless,capacity; Channel code; practical decoder; rateless; spinal code; Communication; Computer architecture; Hash functions; Radio; White noise; Network architecture
"Hong C.-Y., Caesar M., Godfrey P.B.",3,Finishing flows quickly with preemptive scheduling,2012,179,"UIUC, United States",UIUC,1,USA,1,33,24,"Today's data centers face extreme challenges in providing low latency. However, fair sharing, a principle commonly adopted in current congestion control protocols, is far from optimal for satisfying latency requirements. We propose Preemptive Distributed Quick (PDQ) flow scheduling, a protocol designed to complete flows quickly and meet flow deadlines. PDQ enables flow preemption to approximate a range of scheduling disciplines. For example, PDQ can emulate a shortest job first algorithm to give priority to the short flows by pausing the contending flows. PDQ borrows ideas from centralized scheduling disciplines and implements them in a fully distributed manner, making it scalable to today's data centers. Further, we develop a multipath version of PDQ to exploit path diversity. Through extensive packet-level and flow-level simulation, we demonstrate that PDQ significantly outperforms TCP, RCP and D3 in data center environments. We further show that PDQ is stable, resilient to packet loss, and preserves nearly all its performance gains even given inaccurate flow information. © 2012 ACM.",data center; deadline; flow scheduling,Centralized scheduling; Congestion control protocols; Data centers; deadline; Fair sharing; Flow informations; Flow-level simulation; Low latency; Path diversity; Performance Gain; Pre-emptive scheduling; Scheduling discipline; Communication; Computer architecture; Scheduling; Transmission control protocol; Network architecture
"Marchetta P., De Donato W., PescapŽ A.",3,Detecting third-party addresses in traceroute IP paths,2012,4,"University of Napoli Federico II, Napoli, Italy",University of Napoli Federico II,1,Italy,1,43,26,"Traceroute is probably the most famous computer networks diagnostic tool, widely adopted for both performance troubleshooting and research. Unfortunately, traceroute is not free of inaccuracies. In this poster, we present our ongoing work to address the inaccuracy caused by third-party addresses.We discuss the impact of third-party addresses on traceroute applications and present a novel active probing technique able to identify such addresses in traceroute traces. Finally, we detail preliminary results suggesting how this phenomenon has been largely underestimated. © 2012 Authors.",as-level path; internet topology; traceroute,Active probing techniques; as-level path; Diagnostic tools; Internet topologies; IP paths; Traceroute; Communication; Computer architecture; Network architecture
"Tian C., Alimi R., Yang Y.R., Zhang D.",4,ShadowStream: Performance evaluation as a capability in production internet live streaming networks,2012,10,"Yale University, United States; Google, United States; PPLive, United States; SplendorStream, United States",Google;Yale University,2,USA,1,24,17,"As live streaming networks grow in scale and complexity, they are becoming increasingly difficult to evaluate. Existing evaluation methods including lab/testbed testing, simulation, and theoretical modeling, lack either scale or realism. The industrial practice of gradually-rolling-out in a testing channel is lacking in controllability and protection when experimental algorithms fail, due to its passive approach. In this paper, we design a novel system called ShadowStream that introduces evaluation as a built-in capability in production Internet live streaming networks. ShadowStream introduces a simple, novel, transparent embedding of experimental live streaming algorithms to achieve safe evaluations of the algorithms during large-scale, real production live streaming, despite the possibility of large performance failures of the tested algorithms. ShadowStream also introduces transparent, scalable, distributed experiment orchestration to resolve the mismatch between desired viewer behaviors and actual production viewer behaviors, achieving experimental scenario controllability. We implement ShadowStream based on a major Internet live streaming network, build additional evaluation tools such as deterministic replay, and demonstrate the benefits of ShadowStream through extensive evaluations. © 2012 ACM.",live testing; performance evaluation; streaming,Evaluation Method; Evaluation tool; Experimental algorithms; Industrial practices; Live streaming; Performance evaluation; Performance failure; Theoretical modeling; Acoustic streaming; Algorithms; Communication; Computer architecture; Internet; Video streaming; Network architecture
"Zhang D., Vasilakos A.V., Xiong H.",3,Predicting location using mobile phone calls,2012,9,"Nanjing Normal Univeristy, Nanjing, 210046, China; National Technical University, Athens, 15780, Greece; Institute Mines Telecom, Paris, 91011, France",Institute Mines Telecom;Nanjing Normal Univeristy;National Technical University of Athens,3,China;France;Greece,3,10,10,"Location prediction using mobile phone traces has attracted increasing attention. Owing to the irregular user mobility patterns, it still remains challenging to predict user location. Our empirical study in this paper shows that the call patterns are strongly correlated with co-locate patterns (i.e., visiting the same cell tower at the same period), and the call patterns mainly affect user short-time mobility. On top of these findings, we propose NextMe - - a novel scheme to enhance the location prediction accuracy by leveraging the social interplay revealed in the cellular calls. To identify when the social interplay will affect user mobility, we introduce the concepts of the Critical Call Pattern (CCP), and the Critical Call (CC). We validate NextMe with the MIT Reality Mining dataset, involving 350,000-hour activity logs of 106 persons, and 112,508 cellular calls. Experimental results show that the social interplay significantly improves the accuracy. © 2012 Authors.",mobile phone calls; social interplay; social networks,Data sets; Empirical studies; Location prediction; Reality minings; social interplay; Social Networks; User location; User mobility; User mobility pattern; Cellular telephones; Communication; Computer architecture; Mobile phones; Network architecture; Telephone; Forecasting
"Gao P.X., Curtis A.R., Wong B., Keshav S.",4,It's not easy being green,2012,140,"Cheriton School of Computer Science, University of Waterloo, Canada",University of Waterloo,1,Canada,1,46,35,"Large-scale Internet applications, such as content distribution networks, are deployed across multiple datacenters and consume massive amounts of electricity. To provide uniformly low access latencies, these datacenters are geographically distributed and the deployment size at each location reflects the regional demand for the application. Consequently, an application's environmental impact can vary significantly depending on the geographical distribution of end-users, as electricity cost and carbon footprint per watt is location specific. In this paper, we describe FORTE: Flow Optimization based framework for request-Routing and Traffic Engineering. FORTE dynamically controls the fraction of user traffic directed to each datacenter in response to changes in both request workload and carbon footprint. It allows an operator to navigate the three-way tradeoff between access latency, carbon footprint, and electricity costs and to determine an optimal datacenter upgrade plan in response to increases in traffic load. We use FORTE to show that carbon taxes or credits are impractical in incentivizing carbon output reduction by providers of large-scale Internet applications. However, they can reduce carbon emissions by 10% without increasing the mean latency nor the electricity bill. © 2012 ACM.",energy; green computing,Access latency; Carbon emissions; Carbon taxes; Content distribution networks; Data centers; Electricity bill; Electricity costs; End-users; energy; Flow optimization; green computing; Internet application; Traffic Engineering; Traffic loads; User traffics; Carbon footprint; Communication; Computer architecture; Electricity; Emission control; Internet; Network architecture; Optimization; Environmental impact
"Dandapat S.K., Jain S., Choudhury R.R., Ganguly N.",4,Distributed content storage for just-in-time streaming,2012,1,"Department of CSE, IIT Kharagpur, India; Department of ECE and CS, Duke University, United States",Duke University,1,India;USA,2,2,2,"We propose a content distribution strategy over municipal WiFi networks where Access Points (APs) collaboratively cache popular multimedia content, and disseminate them in a manner that each mobile device has the portion of the content just-in-time for playback. If successful, we envision that a child will be able to seamlessly watch a movie in a car, as her tablet downloads different parts of the movie over different WiFi APs at different times. © 2012 Authors.",content distribution; distributed content storage; municipal wifi network,Access points; Content distribution; Distributed content; Just in time; Multimedia contents; Wi Fi networks; Communication; Computer architecture; Content based retrieval; Mobile devices; Network architecture; Wi-Fi
"Escriva R., Wong B., Sirer E.G.",3,"HyperDex: A distributed, searchable key-value store",2012,48,"Computer Science Department, Cornell University, United States; Cheriton School of Computer Science, University of Waterloo, Canada",Cornell University;University of Waterloo,2,Canada;USA,2,43,38,"Distributed key-value stores are now a standard component of high-performance web services and cloud computing applications. While key-value stores offer significant performance and scalability advantages compared to traditional databases, they achieve these properties through a restricted API that limits object retrieval - -an object can only be retrieved by the (primary and only) key under which it was inserted. This paper presents HyperDex, a novel distributed key-value store that provides a unique search primitive that enables queries on secondary attributes. The key insight behind HyperDex is the concept of hyperspace hashing in which objects with multiple attributes are mapped into a multidimensional hyperspace. This mapping leads to efficient implementations not only for retrieval by primary key, but also for partially-specified secondary attribute searches and range queries. A novel chaining protocol enables the system to achieve strong consistency, maintain availability and guarantee fault tolerance. An evaluation of the full system shows that HyperDex is 12-13x faster than Cassandra and MongoDB for finding partially specified objects. Additionally, HyperDex achieves 2-4x higher throughput for get/put operations. © 2012 ACM.",fault-tolerance; key-value store; nosql; performance; strong consistency,Computing applications; Efficient implementation; key-value store; Multiple attributes; nosql; Object retrieval; performance; Primary keys; Range query; Standard components; Strong consistency; Communication; Computer architecture; Fault tolerance; Web services; Network architecture
"Dave V., Guha S., Zhang Y.",3,Measuring and fingerprinting click-spam in ad networks,2012,30,"Microsoft Research India, India; Univ. of Texas at Austin, United States",Microsoft,1,India;USA,2,3,1,"Advertising plays a vital role in supporting free websites and smartphone apps. Click-spam, i.e., fraudulent or invalid clicks on online ads where the user has no actual interest in the advertiser's site, results in advertising revenue being misappropriated by click-spammers. While ad networks take active measures to block click-spam today, the effectiveness of these measures is largely unknown. Moreover, advertisers and third parties have no way of independently estimating or defending against click-spam. In this paper, we take the first systematic look at click-spam. We propose the first methodology for advertisers to independently measure click-spam rates on their ads. We also develop an automated methodology for ad networks to proactively detect different simultaneous click-spam attacks. We validate both methodologies using data from major ad networks. We then conduct a large-scale measurement study of click-spam across ten major ad networks and four types of ads. In the process, we identify and perform in-depth analysis on seven ongoing click-spam attacks not blocked by major ad networks at the time of this writing. Our findings highlight the severity of the click-spam problem, especially for mobile ads. © 2012 ACM.",advertising fraud; click fraud; click-spam; invalid clicks; traffic quality,Advertising revenues; Click fraud; click-spam; In-depth analysis; invalid clicks; Large-scale measurement; Online ads; Third parties; Traffic quality; Communication; Computer architecture; Computer crime; Crime; Internet; Marketing; Network architecture
"Twigg N.A., Fayed M., Perkins C., Pezaros D., Tso P.",5,User-level data center tomography,2012,0,"University of Stirling, United Kingdom; University of Glasgow, United Kingdom",University of Glasgow;University of Stirling,2,UK,1,58,31,"Measurement and inference in data centers present a set of opportunities and challenges distinct from the Internet domain. Existing toolsets may be perturbed or be mislead by issues related to virtualization. Yet, while equally confronted by scale, data centers are relatively homogenous and symmetric. We believe these may be attributes to be exploited. However, data is required to better evaluate our hypotheses. Therefore, we introduce our efforts to gather data using a single framework from which we can launch tests of our choosing. Our observations reinforce recent claims, but indicate changes in the network. They also reveal additional obfuscations stemming from virtualization. © 2012 Authors.",data centers; network measurement; tomography,Data centers; Internet domains; Network measurement; Toolsets; Virtualizations; Communication; Computer architecture; Tomography; Virtual reality; Network architecture
"Xie D., Ding N., Hu Y.C., Kompella R.",4,The only constant is change: Incorporating time-varying network reservations in data centers,2012,107,"Purdue University, United States",Purdue University,1,USA,1,41,26,"In multi-tenant datacenters, jobs of different tenants compete for the shared datacenter network and can suffer poor performance and high cost from varying, unpredictable network performance. Recently, several virtual network abstractions have been proposed to provide explicit APIs for tenant jobs to specify and reserve virtual clusters (VC) with both explicit VMs and required network bandwidth between the VMs. However, all of the existing proposals reserve a fixed bandwidth throughout the entire execution of a job. In the paper, we first profile the traffic patterns of several popular cloud applications, and find that they generate substantial traffic during only 30%-60% of the entire execution, suggesting existing simple VC models waste precious networking resources. We then propose a fine-grained virtual network abstraction, Time-Interleaved Virtual Clusters (TIVC), that models the time-varying nature of the networking requirement of cloud applications. To demonstrate the effectiveness of TIVC, we develop Proteus, a system that implements the new abstraction. Using large-scale simulations of cloud application workloads and prototype implementation running actual cloud applications, we show the new abstraction significantly increases the utilization of the entire datacenter and reduces the cost to the tenants, compared to previous fixed-bandwidth abstractions. © 2012 ACM.",allocation; bandwidth; datacenter; network reservation; profiling,allocation; Data centers; datacenter; High costs; Large scale simulations; Multi tenants; Network bandwidth; Poor performance; profiling; Prototype implementations; Time varying; Time-interleaved; Traffic pattern; Virtual clusters; Virtual networks; Abstracting; Bandwidth; Communication; Computer architecture; Network performance; Time varying networks; Network architecture
"Brown A., Mortier R., Rodden T.",3,MultiNet: Usable and secure WiFi device association,2012,1,"School of Computer Science, University of Nottingham, United Kingdom",University of Nottingham,1,UK,1,3,2,"This demo presents MultiNet, a novel method for joining devices to a domestic Wi-Fi network. MultiNet dynamically reconfigures the network to accept each device, rather than configuring each device to fit the network as is the norm. It does so by assuming that each device is pre-configured with a cryptographically generated WPA2 network SSID/passphrase pair, and then providing a lightweight interaction through which the user creates a new network for each device. This approach makes securely adding devices to a wireless network straightforward without compromising security or burdening the user, and maintaining backward compatibility with existing deployed standards and protocols. The demo deploys a MultiNet Access Point (AP) and a number of Wi-Fi enabled consumer devices to allow viewers to dynamically construct and deconstruct the network via the MultiNet controller currently implemented as an app on an Android phone (Figure 1). The code for MultiNet is publicly available under open-source licenses. © 2012 Authors.",802.11; domestic environments; infrastructure intervention; usable security,802.11; Access points; Backward compatibility; Consumer devices; Domestic environments; infrastructure intervention; Open-source; Usable security; Wi Fi networks; Communication; Computer architecture; Network architecture; Wi-Fi
"GŸrsun G., Ruchansky N., Terzi E., Crovella M.",4,Inferring visibility: Who's (not) talking to whom?,2012,2,"Department of Computer Science, Boston University, United States",Boston University,1,USA,1,36,27,"Consider this simple question: how can a network operator identify the set of routes that pass through its network? Answering this question is surprisingly hard: BGP only informs an operator about a limited set of routes. By observing traffic, an operator can only conclude that a particular route passes through its network - but not that a route does not pass through its network. We approach this problem as one of statistical inference, bringing varying levels of additional information to bear: (1) the existence of traffic, and (2) the limited set of publicly available routing tables. We show that the difficulty depends critically on the position of the network in the overall Internet topology, and that the operators with the greatest incentive to solve this problem are those for which the problem is hardest. Nonetheless, we show that suitable application of nonparametric inference techniques can solve this problem quite accurately. For certain networks, traffic existence information yields good accuracy, while for other networks an accurate approach uses the ""distance"" between prefixes, according to a new network distance metric that we define. We then show how solving this problem leads to improved solutions for a particular application: traffic matrix completion. © 2012 ACM.",bgp; matrix completion,bgp; Internet topologies; Matrix completion; Network distance; Network operator; Nonparametric inference; Routing table; Statistical inference; Traffic matrices; Communication; Computer architecture; Problem solving; Statistical methods; Network architecture
"Liu H.H., Wang Y., Yang Y.R., Wang H., Tian C.",5,Optimizing cost and performance for content multihoming,2012,61,"Yale University, United States; Google, United States; SplendorStream, United States",Google;Yale University,2,USA,1,3,3,"Many large content publishers use multiple content distribution networks to deliver their content, and many commercial systems have become available to help a broader set of content publishers to benefit from using multiple distribution networks, which we refer to as content multihoming. In this paper, we conduct the first systematic study on optimizing content multihoming, by introducing novel algorithms to optimize both performance and cost for content multihoming. In particular, we design a novel, efficient algorithm to compute assignments of content objects to content distribution networks for content publishers, considering both cost and performance. We also design a novel, lightweight client adaptation algorithm executing at individual content viewers to achieve scalable, fine-grained, fast online adaptation to optimize the quality of experience (QoE) for individual viewers. We prove the optimality of our optimization algorithms and conduct systematic, extensive evaluations, using real charging data, content viewer demands, and performance data, to demonstrate the effectiveness of our algorithms. We show that our content multihoming algorithms reduce publishing cost by up to 40%. Our client algorithm executing in browsers reduces viewer QoE degradation by 51%. © 2012 ACM.",content delivery; multiple cdns; optimization,Adaptation algorithms; Commercial systems; Content delivery; Content distribution networks; Multi-homing; multiple cdns; Multiple distribution; Novel algorithm; On-line adaptation; Optimality; Optimization algorithms; Performance data; Publishing costs; Quality of experience (QoE); Systematic study; Communication; Computer architecture; Costs; Degradation; Network architecture; Optimization; Quality of service; Algorithms
"Poese I., Frank B., Knight S., Semmler N., Smaragdakis G.",5,PaDIS emulator: An emulator to evaluate CDN-ISP collaboration,2012,8,"T-Labs., TU Berlin, Germany; University of Adelaide, Australia; TU Berlin, Germany",TU Berlin;University of Adelaide,2,Australia;Germany,2,16,12,"We present PaDIS Emulator, a fully automated platform to evaluate CDN-ISP collaboration for better content delivery, traffic engineering, and cost reduction. The PaDIS Emulator enables researchers as well as CDN and ISP operators to evaluate the benefits of collaboration using their own operational networks, configuration, and cost functions. The PaDIS Emulator consists of three components: the network emulation, the collaboration mechanism, and the performance monitor. These layers provide scalable emulation of the interaction between an ISP or a number of ISPs with multiple CDNs and vice versa. PaDIS Emulator design is flexible in order to implement a wide range of collaboration mechanisms on virtualized or real hardware, and evaluate them before introduction to operational networks. © 2012 Authors.",cdn-isp collaboration; traffic engineering,cdn-isp collaboration; Collaboration mechanisms; Content delivery; Emulator designs; Network emulation; Operational network; Performance monitors; Three component; Traffic Engineering; Communication; Computer architecture; Network architecture
"Gurney A.J.T., Han X., Li Y., Loo B.T.",4,Route shepherd: Stability hints for the control plane,2012,0,"University of Pennsylvania, Philadelphia, PA, United States",University of Pennsylvania,1,USA,1,27,6,"The Route Shepherd tool demonstrates applications of choosing between routing protocol configurations on the basis of rigorously-supported theory. Splitting the configuration space into equivalence classes allows the identification of which parameter combinations lead to protocol stability, and which do not. This ahead-of-time analysis generates a predicate, in the form of a combination of linear integer inequalities, which can be used in several complementary ways by downstream applications. Examples presented include warning operators about errors in advance, recovery from protocol oscillation, plotting a series of safe parameter changes, and understanding the dynamics of the routing system. © 2012 Authors.",border gateway protocol; partial specification; routing policy; stable path problems,Border gateway protocol; Configuration space; Control planes; Downstream applications; Integer inequalities; Parameter changes; Parameter combination; Partial specifications; Path problems; Protocol configurations; Protocol stability; Routing policies; Routing system; Communication; Computer architecture; Equivalence classes; Network architecture; Gateways (computer networks)
"Hong S., Mehlman J., Katti S.",3,Picasso: Flexible RF and spectrum slicing,2012,10,"Stanford University, United States",Stanford University,1,USA,1,9,8,"Many applications can benefit from the capability to simultaneously and independently use arbitrarily sized but separate spectrum fragments with a single radio and antenna. By this capability we mean that the radio can simultaneously transmit, simultaneously receive, or simultaneously transmit and receive on arbitrary but separate spectrum fragments. For example, we can use it for spectrum aggregation in fragmented ISM bands as shown in as shown in Fig. 2(A). A WiFi AP can run independent OFDM PHY and CSMA MAC protocols on two WiFi channels to simultaneously serve two legacy WiFi clients assigned to different channels and achieve significantly higher throughput than a legacy AP that is restricted to use only one channel at a time. Similarly, a WiFi client radio with such a capability can use it to simultaneously connect to multiple WiFi APs on different channels and obtain a much higher aggregate throughput than current radios that can transmit or receive on only one channel at a time. © 2012 Authors.",interference cancellation; radio virtualization,Aggregate throughput; Interference cancellation; ISM bands; MAC protocol; Spectrum Aggregation; Spectrum fragments; Spectrum slicing; Virtualizations; Communication; Computer architecture; Medium access control; Network architecture; Separation; Wi-Fi
"Vamanan B., Hasan J., Vijaykumar T.N.",3,Deadline-aware datacenter TCP (D 2TCP),2012,199,"Purdue University, United States; Google Inc., United States",Google;Purdue University,2,USA,1,8,8,"An important class of datacenter applications, called Online Data-Intensive (OLDI) applications, includes Web search, online retail, and advertisement. To achieve good user experience, OLDI applications operate under soft-real-time constraints (e.g., 300 ms latency) which imply deadlines for network communication within the applications. Further, OLDI applications typically employ tree-based algorithms which, in the common case, result in bursts of children-to-parent traffic with tight deadlines. Recent work on datacenter network protocols is either deadline-agnostic (DCTCP) or is deadline-aware (D3) but suffers under bursts due to race conditions. Further, D3 has the practical drawbacks of requiring changes to the switch hardware and not being able to coexist with legacy TCP. We propose Deadline-Aware Datacenter TCP (D2TCP), a novel transport protocol, which handles bursts, is deadline-aware, and is readily deployable. In designing D2TCP, we make two contributions: (1) D2TCP uses a distributed and reactive approach for bandwidth allocation which fundamentally enables D2TCP's properties. (2) D2TCP employs a novel congestion avoidance algorithm, which uses ECN feedback and deadlines to modulate the congestion window via a gamma-correction function. Using a small-scale implementation and at-scale simulations, we show that D2TCP reduces the fraction of missed deadlines compared to DCTCP and D3 by 75% and 50%, respectively. © 2012 ACM.",cloud services; datacenter; deadline; ecn; oldi; sla; tcp,Cloud services; datacenter; deadline; ecn; oldi; sla; tcp; Communication; Computer architecture; Network protocols; Transmission control protocol; Network architecture
"Le Blond S., Zhang C., Legout A., Ross K., Dabbous W.",5,I know where you are and what you are sharing: Exploiting P2P communications to invade users' privacy,2011,22,"MPI-SWS, Germany; NYU-Poly, United States; INRIA, France",INRIA;NYU,2,France;Germany;USA,3,4,3,"In this paper, we show how to exploit real-time communication applications to determine the IP address of a targeted user. We focus our study on Skype, although other real-time communication applications may have similar privacy issues. We first design a scheme that calls an identified-targeted user inconspicuously to find his IP address, which can be done even if he is behind a NAT. By calling the user periodically, we can then observe the mobility of the user. We show how to scale the scheme to observe the mobility patterns of tens of thousands of users. We also consider the linkability threat, in which the identified user is linked to his Internet usage. We illustrate this threat by combining Skype and BitTorrent to show that it is possible to determine the filesharing usage of identified users. We devise a scheme based on the identification field of the IP datagrams to verify with high accuracy whether the identified user is participating in specific torrents. We conclude that any Internet user can leverage Skype, and potentially other real-time communication systems, to observe the mobility and filesharing usage of tens of millions of identified users. © 2011 ACM.",file sharing; mobility; privacy; skype,BitTorrent; Datagrams; File Sharing; Internet usage; Internet users; IP addresss; Linkability; Mobility pattern; P2p communications; Privacy issue; Real-time communication; Real-time communication system; skype; Carrier mobility; Communication systems; Data privacy; Distributed computer systems; Internet; Internet protocols; Real time systems
"Ihm S., Pai V.S.",2,Towards understanding modern web traffic,2011,97,"Department of Computer Science, Princeton University, United States; Google Inc., United States",Google;Princeton University,2,USA,1,27,15,"As Web sites move from relatively static displays of simple pages to rich media applications with heavy client-side interaction, the nature of the resulting Web traffic changes as well. Understanding this change is necessary in order to improve response time, evaluate caching effectiveness, and design intermediary systems, such as firewalls, security analyzers, and reporting/management systems. Unfortunately, we have little understanding of the underlying nature of today's Web traffic. In this paper, we analyze five years (2006-2010) of real Web traffic from a globally-distributed proxy system, which captures the browsing behavior of over 70,000 daily users from 187 countries. Using this data set, we examine major changes in Web traffic characteristics that occurred during this period. We also present a new Web page analysis algorithm that is better suited for modern Web page interactions by grouping requests into streams and exploiting the structure of the pages. Using this algorithm, we analyze various aspects of page-level changes, and characterize modern Web pages. Finally, we investigate the redundancy of this traffic, using both traditional object-level caching as well as content-based approaches. © 2011 ACM.",content-based caching; web caching; web traffic analysis,Browsing behavior; Content-based; Content-based approach; Data sets; Rich medias; Security analyzers; Static displays; Web caching; Web page; Web traffic; web traffic analysis; Web-page analysis; Algorithms; Computer system firewalls; Computer viruses; Internet; Websites
"Rodrigues T., Benevenuto F., Cha M., Gummadi K., Almeida V.",5,On word-of-mouth based discovery of the web,2011,75,"Universidade Federal de Minas Gerais, UFMG, Belo Horizonte, Brazil; Universidade Federal de Ouro Preto, UFOP, Ouro Preto, Brazil; Graduate School of Culture Technology, KAIST, Daejeon, South Korea; Max Planck Institute for Software Systems, MPI-SWS, Saarbrucken, Germany","KAIST;Max Planck Institute,Germany;Universidade Federal de Minas Gerais;Universidade Federal de Ouro Preto",4,Brazil;Germany;South Korea,3,33,21,"Traditionally, users have discovered information on the Web by browsing or searching. Recently, word-of-mouth has emerged as a popular way of discovering the Web, particularly on social networking sites like Facebook and Twitter. On these sites, users discover Web content by following URLs posted by their friends. Such word-of-mouth based content discovery has become a major driver of traffic to many Web sites today. To better understand this popular phenomenon, in this paper we present a detailed analysis of word-of-mouth exchange of URLs among Twitter users. Among our key findings, we show that Twitter yields propagation trees that are wider than they are deep. Our analysis on the geolocation of users indicates that users who are geographically close together are more likely to share the same URL. © 2011 ACM.",information diffusion; social networks; web content discovery; word-of-mouth,Facebook; Geolocations; Information diffusion; Social networking sites; Social Networks; Web content; web content discovery; word-of-mouth; World Wide Web; Social networking (online)
"Li Y., Zhang Y., Yuan R.",3,Measurement and analysis of a large scale commercial mobile internet TV system,2011,49,"Tsinghua University, Beijing, China; Shandong Technology, Beijing, China",Tsinghua University,1,China,1,63,34,"Large scale, Internet based mobile TV deployment presents both tremendous opportunities and challenges for mobile operators and technology providers. This paper presents a measurement based study on a large scale mobile TV service offering in China. Within the one month measurement period, our dataset captured over 1 million unique mobile devices and more than 49 million video sessions. Analysis showed that mobile viewing patterns are different from that of landline based IPTV and VoD systems. In particular, the average viewing time is significantly shorter, and the channel popularity distribution is more skewed towards top ranked channels than that of landline based systems. For the channel sojourn time, the distribution follows a piecewise model, which combines lognormal and pareto distribution. The lognormal part, which fits the majority of video sessions, more closely resembles the mobile phone call holding time, rather than the power law distribution in the landline IPTV case. In comparing the 3G and WiFi access methods, we found that users exhibit different behaviors when accessing from different networks. In 3G networks, where users are subject to data charge, users tend to have shorter channel sojourn time and prefer lower bit-rate channels. The parameters of the distributions are also different. Understanding these user behaviors and their implications on network traffic are critical for the success of future mobile TV industry. © 2011 ACM.",distribution; human behavior; mobile video; sojourn time,3G Networks; Access methods; Bit-rate channels; Data sets; distribution; Human behaviors; Internet based; Landline; Log-normal; Measurement and analysis; Measurement-based studies; Mobile Internet; Mobile operators; Mobile TV; mobile video; Network traffic; Pareto distributions; Phone calls; Piece-wise; Popularity distribution; Power law distribution; Sojourn time; Technology providers; TV systems; User behaviors; Video sessions; Behavioral research; Codes (symbols); Internet; Mobile devices; Mobile telecommunication systems; Television broadcasting; Wi-Fi; IPTV
"Kanuparthy P., Dovrolis C.",2,ShaperProbe: End-to-end detection of ISP traffic shaping using active methods,2011,37,"School of Computer Science, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,44,30,"We present an end-to-end measurement method for the detection of traffic shaping. Traffic shaping is typically implemented using token buckets, allowing a maximum burst of traffic to be serviced at the peak capacity of the link, while any remaining traffic is serviced at a lower shaping rate. The contribution of this paper is twofold. First, we develop an active end-to-end detection mechanism, referred to as ShaperProbe, that can infer whether a particular path is subject to traffic shaping, and in that case, estimate the shaper characteristics. Second, we analyze results from a large-scale deployment of ShaperProbe on M-Lab over the last 24 months, detecting traffic shaping in several major ISPs. Our deployment has received more than one million runs so far from 5,700 ISPs. © 2011 ACM.",active probing; inference; traffic shaping,Active method; Active probing; Detection mechanism; End-to-end measurement; inference; Large-scale deployment; Peak capacity; Token bucket; traffic shaping; Measurements; Internet service providers
"Stone-Gross B., Stevens R., Zarras A., Kemmerer R., Kruegel C., Vigna G.",6,Understanding fraudulent activities in online ad exchanges,2011,49,"Department of Computer Science, University of California, Santa Barbara, CA, United States; Institute of Computer Science, Foundation of Research and Technology, Hellas, Greece","Foundation of Research and Technology,South Korea;University of California Santa Barbara",2,Greece;USA,2,34,32,"Online advertisements (ads) provide a powerful mechanism for advertisers to effectively target Web users. Ads can be customized based on a user's browsing behavior, geographic location, and personal interests. There is currently a multi-billion dollar market for online advertising, which generates the primary revenue for some of the most popular websites on the Internet. In order to meet the immense market demand, and to manage the complex relationships between advertisers and publishers (i.e., the websites hosting the ads), marketplaces known as ""ad exchanges"" are employed. These exchanges allow publishers (sellers of ad space) and advertisers(buyers of this ad space) to dynamically broker traffic through ad networks to efficiently maximize profits for all parties. Unfortunately, the complexities of these systems invite a considerable amount of abuse from cybercriminals, who profit at the expense of the advertisers. In this paper, we present a detailed view of how one of the largest ad exchanges operates and the associated security issues from the vantage point of a member ad network. More specifically, we analyzed a dataset containing transactions for ingress and egress ad traffic from this ad network. In addition, we examined information collected from a command-and-control server used to operate a botnet that is leveraged to perpetrate ad fraud against the same ad exchange. © 2011 ACM.",ad fraud; ad networks; online advertising,Ad exchanges; ad fraud; Browsing behavior; Command-and-control; Complex relationships; Cybercriminals; Data sets; Dollar market; Geographic location; Market demand; Online advertisements; online advertising; Security issues; Web users; Behavioral research; Crime; Internet; Marketing; Profitability; Websites; Computer crime
"Holz R., Braun L., Kammenhuber N., Carle G.",4,The SSL landscape: A thorough analysis of the X.509 PKI using active and passive measurements,2011,72,"Technische UniversitŠt MŸnchen, Faculty of Informatics, Network Architectures and Services, Germany",TU Munich,1,Germany,1,26,21,"The SSL and TLS infrastructure used in important protocols like HTTPs and IMAPs is built on an X.509 public-key infrastructure (PKI). X.509 certificates are thus used to authenticate services like online banking, shopping, e-mail, etc. However, it always has been felt that the certification processes of this PKI may lack in stringency, resulting in a deployment where many certificates do not meet the requirements of a secure PKI. This paper presents a comprehensive analysis of X.509 certificates in the wild. To shed more light on the state of the deployed and actually used X.509 PKI, we obtained and evaluated data from many different sources. We conducted HTTPs scans of a large number of popular HTTPs servers over a 1.5-year time span, including scans from nine locations distributed over the globe. To compare certification properties of highly ranked hosts with the global picture, we included a third-party scan of the entire IPv4 space in our analyses. Furthermore, we monitored live SSL/TLS traffic on a 10Gbps uplink of a large research network. This allows us to compare the properties of the deployed PKI with the part of the PKI that is being actively accessed by users. Our analysis reveals that the quality of certification lacks in stringency, due to a number of reasons among which incorrect certification chains or invalid certificate subjects give the most cause for concern. Similar concerns can be raised for the properties of certification chains and many self-signed certificates used in the deployed X.509 PKI. Our findings confirm what has long been believed - namely that the X.509 PKI we often use in our everyday's lives is in a sorry state. © 2011 ACM.",certificates; HTTPS; public key infrastructure; SSL; TLS; X.509,certificates; HTTPS; public key infrastructure; SSL; TLS; X.509; HTTP; Internet; Internet protocols; Public key cryptography; Quality control
"Sanjuˆs-Cuxart J., Barlet-Ros P., Duffield N., Kompella R.R.",4,Sketching the delay: Tracking temporally uncorrelated flow-level latencies,2011,5,"UPC BarcelonaTech, Jordi Girona 1-3, Barcelona 08034, Spain; AT and T Labs. - Research, 180 Park Avenue, Florham Park, NJ 07932, United States; Dept. of Computer Science, Purdue University, West Lafayette, IN 47907, United States",AT and T Labs;Purdue University,2,Spain;USA,2,26,24,"Packet delay is a crucial performance metric for real-time, network-based applications. Obtaining per-flow delay measurements is particularly important to network operators, but is computationally challenging in high-speed links. Recently, passive delay measurement techniques have been proposed that outperform traditional active probing in terms of accuracy and network overhead. However, such techniques rely on the empirical observation that packet delays across different flows are temporally correlated, an assumption that is not met in presence of traffic prioritization, load balancing policies, or due to intricacies of the switch fabric. We present a novel data structure called Lossy Difference Sketch (LDS) that provides per-flow delay measurements without relying on any specific delay model. LDS obtains a notable accuracy improvement compared to the state of the art with a small memory footprint and network overhead. The data structure can be sized according to target accuracy requirements or to fit a low memory budget. We deploy an actual implementation of LDS in an operational research and education network and show that it obtains higher accuracy than temporal correlation-based techniques without exploiting any knowledge about the underlying delay model. © 2011 ACM.",delay sketch; network latency; network measurement; one-way packet delay,Accuracy Improvement; Active probing; Correlation-based techniques; Delay measurements; Delay models; delay sketch; Flow-level; High-speed links; Load balancing policies; Low memory; Network latencies; network measurement; Network operator; Network overhead; Network-based; Operational research; Packet delay; Performance metrices; Prioritization; Small memory footprint; State of the art; Switch fabric; Data structures; Internet; Packet networks; Arts computing
"Kreibich C., Weaver N., Kanich C., Cui W., Paxson V.",5,GQ: Practical containment for measuring modern malware systems,2011,27,"ICSI and UC Berkeley, United States; UC San Diego, United States; Microsoft Research, United States",University of California Berkeley;Microsoft;University of California San Diego,3,USA,1,44,41,"Measurement and analysis of modern malware systems such as botnets relies crucially on execution of specimens in a setting that enables them to communicate with other systems across the Internet. Ethical, legal, and technical constraints however demand containment of resulting network activity in order to prevent the malware from harming others while still ensuring that it exhibits its inherent behavior. Current best practices in this space are sorely lacking: measurement researchers often treat containment superficially, sometimes ignoring it altogether. In this paper we present GQ, a malware execution ""farm"" that uses explicit containment primitives to enable analysts to develop containment policies naturally, iteratively, and safely. We discuss GQ's architecture and implementation, our methodology for developing containment policies, and our experiences gathered from six years of development and operation of the system. © 2011 ACM.",botnets; command-and-control; honeyfarm; malware containment; malware execution,Botnets; Command-and-control; honeyfarm; Malwares; Measurement and analysis; Network activities; Technical constraints; Internet; Computer crime
"Yang Z., Wilson C., Wang X., Gao T., Zhao B.Y., Dai Y.",6,Uncovering social network sybils in the wild,2011,99,"Computer Science Dept., Peking University, Beijing, China; Computer Science Dept., UC Santa Barbara, Santa Barbara, CA 93106, United States; Renren Inc., Beijing, China",Peking University;Renren Inc.;University of California Santa Barbara,3,China;USA,2,29,20,"Sybil accounts are fake identities created to unfairly increase the power or resources of a single user. Researchers have long known about the existence of Sybil accounts in online communities such as file-sharing systems, but have not been able to perform large scale measurements to detect them or measure their activities. In this paper, we describe our efforts to detect, characterize and understand Sybil account activity in the Renren online social network (OSN). We use ground truth provided by Renren Inc. to build measurement based Sybil account detectors, and deploy them on Renren to detect over 100,000 Sybil accounts. We study these Sybil accounts, as well as an additional 560,000 Sybil accounts caught by Renren, and analyze their link creation behavior. Most interestingly, we find that contrary to prior conjecture, Sybil accounts in OSNs do not form tight-knit communities. Instead, they integrate into the social graph just like normal users. Using link creation timestamps, we verify that the large majority of links between Sybil accounts are created accidentally, unbeknownst to the attacker. Overall, only a very small portion of Sybil accounts are connected to other Sybils with social links. Our study shows that existing Sybil defenses are unlikely to succeed in today's OSNs, and we must design new techniques to effectively detect and defend against Sybil attacks. © 2011 ACM.",online social networks; sybil accounts,File-sharing system; Ground truth; Large-scale measurement; Measurement-based; Online communities; Online social networks; Single users; Social graphs; Social Networks; sybil accounts; Sybil attack; Time stamps; Electronic document exchange; Internet; Online systems; Social networking (online); Computer crime
"Sen S., Yoon J., Hare J., Ormont J., Banerjee S.",5,Can they hear me now?: A case for a client-assisted approach to monitoring wide-area wireless networks,2011,32,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,31,25,"We present WiScape, a framework for measuring and understanding the behavior of wide-area wireless networks, e.g., city-wide or nation-wide cellular data networks using active participation from clients. The goal of WiScape is to provide a coarse-grained view of a wide-area wireless landscape that allows operators and users to understand broad performance characteristics of the network. In this approach a centralized controller instructs clients to collect measurement samples over time and space in an opportunistic manner. To limit the overheads of this measurement framework, WiScape partitions the world into zones, contiguous areas with relatively similar user experiences, and partitions time into zone-specific epochs over which network statistics are relatively stable. For each epoch in each zone, WiScape takes a minimalistic view - it attempts to collect a small number of measurement samples to adequately characterize the client experience in that zone and epoch, thereby limiting the bandwidth and energy overheads at client devices. For this effort, we have collected ground truth measurements for up to three different commercial cellular wireless networks across (i) an area of more than 155 square kilometer in and around Madison, WI, in the USA, (ii) a road stretch of more than 240 kilometers between Madison and Chicago, and (iii) locations in New Brunswick and Princeton, New Jersey, USA, for a period of more than 1 year. We justify various design choices of WiScape through this data, demonstrate that WiScape can provide an accurate performance characterization of these networks over a wide area (within 4% error for more than 70% of instances) with a low overhead on the clients, and illustrate multiple applications of this framework through a sustained and ongoing measurement study. © 2011 ACM.",cellular networks; client assisted; measurement,"Accurate performance; Cellular data networks; Cellular network; Cellular wireless networks; Chicago; client assisted; Client devices; Coarse-grained; Contiguous area; Ground truth; Low overhead; Measurement study; Multiple applications; Network statistics; New Jersey , USA; Performance characteristics; User experience; Wide area; Cellular neural networks; Internet; Measurements; Wide area networks"
"Pathak A., Zhang M., Hu Y.C., Mahajan R., Maltz D.",5,Latency inflation with MPLS-based traffic engineering,2011,18,"Purdue University, United States; Microsoft Research, United States",Microsoft;Purdue University,2,USA,1,24,24,"While MPLS has been extensively deployed in recent years, little is known about its behavior in practice. We examine the performance of MPLS in Microsoft's online service network (MSN), a well-provisioned multi-continent production network connecting tens of data centers. Using detailed traces collected over a 2-month period, we find that many paths experience significantly inflated latencies. We correlate occurrences of latency inflation with routers, links, and DC-pairs. This analysis sheds light on the causes of latency inflation and suggests several avenues for alleviating the problem. © 2011 ACM.",autobandwidth; latency; LSP; MLPS,autobandwidth; Data centers; latency; LSP; MicroSoft; MLPS; On-line service; Production network; Traffic Engineering; Measurements; Internet
"Erman J., Gerber A., Ramadrishnan K.K., Sen S., Spatscheck O.",5,Over the top video: The gorilla in cellular networks,2011,82,"AT and T Labs. - Research, NJ, United States",AT and T Labs,1,USA,1,39,25,"Cellular networks have witnessed tremendous traffic growth recently, fueled by smartphones, tablets and new high speed broadband cellular access technologies. A key application driving that growth is video streaming. Yet very little is known about the characteristics of this traffic class. In this paper, we examine video traffic generated by three million users across one of the world's largest 3G cellular networks. This first deep dive into cellular video streaming shows that HLS, an adaptive bitrate streaming protocol, accounts for one third of the streaming video traffic and that it is common to see changes in encoding bitrates within a session. We also observe that most of the content is streamed at less than 255 Kbps and that only 40% of the videos are fully downloaded. Another key finding is that there exists significant potential for caching to deliver this content. © 2011 ACM.",network optimization,3G cellular networks; Access technology; Bit rates; Cellular network; Deep dives; Network optimization; New high; Smartphones; STreaming protocols; Streaming videos; Traffic class; Traffic growth; Video traffic; Internet; Internet protocols; Video streaming; Videotex; Cellular neural networks
"Kim H., Benson T., Akella A., Feamster N.",4,The evolution of network configuration: A tale of two campuses,2011,33,"Georgia Tech., Atlanta, GA, United States; University of Wisconsin, Madison, WI, United States",Georgia Tech;University of Wisconsin-Madison,2,USA,1,10,7,"Studying network configuration evolution can improve our understanding of the evolving complexity of networks and can be helpful in making network configuration less error-prone. Unfortunately, the nature of changes that operators make to network configuration is poorly understood. Towards improving our understanding, we examine and analyze five years of router, switch, and firewall configurations from two large campus networks using the logs from version control systems used to store the configurations. We study how network configuration is distributed across different network operations tasks and how the configuration for each task evolves over time, for different types of devices and for different locations in the network. To understand the trends of how configuration evolves over time, we study the extent to which configuration for various tasks are added, modified, or deleted. We also study whether certain devices experience configuration changes more frequently than others, as well as whether configuration changes tend to focus on specific portions of the configuration (or on specific tasks). We also investigate when network operators make configuration changes of various types. Our results concerning configuration changes can help the designers of configuration languages understand which aspects of configuration might be more automated or tested more rigorously and may ultimately help improve configuration languages. © 2011 ACM.",longitudinal analysis; network configuration; network evolution,Campus network; Configuration languages; Error prones; Longitudinal analysis; Network configuration; network evolution; Network operations; Network operator; Specific tasks; Version control system; Computer system firewalls; Internet; Computer aided network analysis
"Hao S., Feamster N., Pandrangi R.",3,Monitoring the initial DNS behavior of malicious domains,2011,39,"Georgia Tech., Atlanta, GA, United States; Verisign, Inc., Dulles, VA, United States",Georgia Tech;Verisign Inc.,2,USA,1,19,19,"Attackers often use URLs to advertise scams or propagate malware. Because the reputation of a domain can be used to identify malicious behavior, miscreants often register these domains ""just in time"" before an attack. This paper explores the DNS behavior of attack domains, as identified by appearance in a spam trap, shortly after the domains were registered. We explore the behavioral properties of these domains from two perspectives: (1) the DNS infrastructure associated with the domain, as is observable from the resource records; and (2) the DNS lookup patterns from networks who are looking up the domains initially. Our analysis yields many findings that may ultimately be useful for early detection of malicious domains. By monitoring the infrastructure for these malicious domains, we find that about 55% of scam domains occur in attacks at least one day after registration, suggesting the potential for early discovery of malicious domains, solely based on properties of the DNS infrastructure that resolves those domains. We also find that there are a few regions of IP address space that host name servers and other types of servers for only malicious domains. Malicious domains have resource records that are distributed more widely across IP address space, and they are more quickly looked up by a variety of different networks. We also identify a set of ""tainted"" ASes that are used heavily by bad domains to host resource records. The features we observe are often evident before any attack even takes place; ultimately, they might serve as the basis for a DNS-based early warning system for attacks. © 2011 ACM.",DNS; domain registration; malicious domain; spam,Behavioral properties; DNS; domain registration; Early detection; Early Warning System; IP addresss; Just in time; Lookups; Malicious behavior; malicious domain; Malwares; Name servers; spam; Internet; Monitoring; Internet protocols
"Dainotti A., Squarcella C., Aben E., Claffy K.C., Chiesa M., Russo M., PescapŽ A.",7,Analysis of country-wide internet outages caused by censorship,2011,79,"University of Napoli Federico II, Italy; Roma Tre University, Italy; RIPE NCC, Italy; CAIDA/UCSD, Italy",Roma Tre University;University of Napoli Federico II,2,Italy,1,19,15,"In the first months of 2011, Internet communications were disrupted in several North African countries in response to civilian protests and threats of civil war. In this paper we analyze episodes of these disruptions in two countries: Egypt and Libya. Our analysis relies on multiple sources of large-scale data already available to academic researchers: BGP interdomain routing control plane data; unsolicited data plane traffic to unassigned address space; active macroscopic traceroute measurements; RIR delegation files; and MaxMind's geolocation database. We used the latter two data sets to determine which IP address ranges were allocated to entities within each country, and then mapped these IP addresses of interest to BGP-announced address ranges (prefixes) and origin ASes using publicly available BGP data repositories in the U.S. and Europe. We then analyzed observable activity related to these sets of prefixes and ASes throughout the censorship episodes. Using both control plane and data plane data sets in combination allowed us to narrow down which forms of Internet access disruption were implemented in a given region over time. Among other insights, we detected what we believe were Libya's attempts to test firewall-based blocking before they executed more aggressive BGP-based disconnection. Our methodology could be used, and automated, to detect outages or similar macroscopically disruptive events in other geographic or topological regions. © 2011 ACM.",censorship; connectivity disruption; darknet; internet background radiation; network telescope; outages,censorship; connectivity disruption; darknet; internet background radiation; network telescope; Internet; Outages; Uncertainty analysis; Internet protocols
"Liu Y., Gummadi K.P., Krishnamurthy B., Mislove A.",4,Analyzing facebook privacy settings: User expectations vs. reality,2011,224,"Northeastern University, Boston, MA, United States; MPI-SWS, SaarbrŸcken/Kaiserslautern, Germany; AT and T Labs.-Research, Florham Park, NJ, United States",AT and T Labs;Northeastern University,2,Germany;USA,2,18,12,"The sharing of personal data has emerged as a popular activity over online social networking sites like Facebook. As a result, the issue of online social network privacy has received significant attention in both the research literature and the mainstream media. Our overarching goal is to improve defaults and provide better tools for managing privacy, but we are limited by the fact that the full extent of the privacy problem remains unknown; there is little quantification of the incidence of incorrect privacy settings or the difficulty users face when managing their privacy. In this paper, we focus on measuring the disparity between the desired and actual privacy settings, quantifying the magnitude of the problem of managing privacy. We deploy a survey, implemented as a Facebook application, to 200 Facebook users recruited via Amazon Mechanical Turk. We find that 36% of content remains shared with the default privacy settings. We also find that, overall, privacy settings match users' expectations only 37% of the time, and when incorrect, almost always expose content to more users than expected. Finally, we explore how our results have potential to assist users in selecting appropriate privacy settings by examining the user-created friend lists. We find that these have significant correlation with the social network, suggesting that information from the social network may be helpful in implementing new tools for managing privacy. © 2011 ACM.",facebook; measurement; online social networks; privacy,Facebook; Mainstream media; Mechanical turks; online social networks; Privacy problems; Social networking sites; Social Networks; User expectations; Internet; Measurements; Online systems; Social networking (online); Data privacy
"Gopalakrishnan V., Jana R., Ramakrishnan K.K., Swayne D.F., Vaishampayan V.A.",5,Understanding couch potatoes: Measurement and modeling of interactive usage of IPTV at large scale,2011,21,"AT and T Labs. - Research, 180 Park Ave, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,69,56,"We investigate how consumers view content using Video on Demand (VoD) in the context of an IP-based video distribution environment. Users today can use interactive stream control functions such as skip, replay, fast-forward, pause, and rewind to control their viewing. The use of these functions can place additional demands on the distribution infrastructure (servers, network, and set top boxes) and can be challenging to manage with a large subscriber base. A model of user interaction provides insight into the impact of stream control on server and bandwidth requirements, client responsiveness, etc. We capture the activity users in a natural setting, viewing video at home. We first develop a model for the arrival process of requests for content. We then develop two stream control models that accurately capture user interaction. We show that stream control events can be characterized by a finite state machine and a sojourn time model, parametrized for major periods of usage (weekend and weekday). Our semi-Markov (SM) model for the sojourn time in each stream control state uses a novel technique based on a polynomial fit to the logarithm of the Inverse CDF. A second constrained model(CM) uses a stick-breaking approach familiar in machine learning to model the individual state sojourn time distributions. The SM model seeks to preserve the sojourn time distribution for each state while the CM model puts a greater emphasis on preserving the overall session duration distribution. Using traces across a period of 2 years from a large-scale operational IPTV environment, we validate the proposed model and show that we are able to faithfully predict the workload presented to a video server. We also provide a synthetic trace developed from the model enabling researchers to also study other problems of interest. We also use the techniques to model consumer viewing of video content recorded on their personal Digital Video Recorder (DVR). © 2011 ACM.",IPTV; modelling; video-on-demand,Arrival process; Bandwidth requirement; Constrained models; Fast forward; modelling; Novel techniques; Personal digital video; Polynomial fit; Semi-Markov; Set top box; Sojourn time; Sojourn time distributions; Stream control; Two-stream; User interaction; Video contents; Video distribution; Video servers; Computer graphics; Finite automata; Internet; Internet protocols; Multimedia systems; Video on demand; Video recording; Video streaming; Videocassette recorders; Videodisks; IPTV
"Sommers J., Eriksson B., Barford P.",3,On the prevalence and characteristics of MPLS deployments in the open internet,2011,20,"Colgate University, United States; Boston University, United States; University of Wisconsin, Madison, WI, United States; Qualys, Inc., United States",Boston University;Colgate University;Qualys Inc.;University of Wisconsin-Madison,4,USA,1,41,40,"Multi-Protocol Label Switching (MPLS) is a mechanism that enables service providers to specify virtual paths through IP networks. The use of MPLS in the open Internet (i.e., public end-to-end paths) has important implications for users and network neutrality since MPLS is frequently used in traffic engineering applications today. In this paper we present a longitudinal study of the prevalence and characteristics of MPLS deployments in the open Internet. We use path measurement data collected over the past 3.5 years by the CAIDA Archipelago project (Ark), which consist of over 10 billion individual traceroutes between hosts throughout the Internet. We use two different techniques for identifying MPLS paths in Ark data: direct observation via ICMP extensions that include MPLS label information, and inference using a Bayesian data fusion methodology. Our direct observation method can only identify uniform-mode tunnels, which very likely underestimates MPLS deployments. Nonetheless, our results show that the total number of tunnels observed in a given measurement period has varied widely over time with the largest deployments in tier-1 providers. About 7% of all autonomous systems deploy MPLS and this level of deployment has been consistent over the past three years. The average length of an MPLS tunnel has decreased from 4 hops in 2008 to 3 hops in 2011, and the path length distribution is heavily skewed. About 25% of all paths in 2011 cross at least one MPLS tunnel, while 4% cross more than one. Finally, data observed in MPLS headers suggest that many ASes employ some types of traffic classification and engineering in their tunnels. © 2011 ACM.",MPLS; traceroute; traffic engineering tunnels,Autonomous systems; Average length; Bayesian data fusions; End-to-end path; IP networks; Longitudinal study; MPLS; MPLS label; Multi protocol label switching; Observation method; Path length distribution; Path measurement; Service provider; Traceroute; Traffic classification; Traffic Engineering; Virtual paths; Data fusion; Internet; Telecommunication traffic; Internet protocols
"Thomas K., Grier C., Song D., Paxson V.",4,Suspended accounts in retrospect: An analysis of twitter spam,2011,222,"University of California, Berkeley, CA, United States; International Computer Science Institute, United States",University of California Berkeley,1,USA,1,23,17,"In this study, we examine the abuse of online social networks at the hands of spammers through the lens of the tools, techniques, and support infrastructure they rely upon. To perform our analysis, we identify over 1.1 million accounts suspended by Twitter for disruptive activities over the course of seven months. In the process, we collect a dataset of 1.8 billion tweets, 80 million of which belong to spam accounts. We use our dataset to characterize the behavior and lifetime of spam accounts, the campaigns they execute, and the wide-spread abuse of legitimate web services such as URL shorteners and free web hosting. We also identify an emerging marketplace of illegitimate programs operated by spammers that include Twitter account sellers, ad-based URL shorteners, and spam affiliate programs that help enable underground market diversification. Our results show that 77% of spam accounts identified by Twitter are suspended within on day of their first tweet. Because of these pressures, less than 9% of accounts form social relationships with regular Twitter users. Instead, 17% of accounts rely on hijacking trends, while 52% of accounts use unsolicited mentions to reach an audience. In spite of daily account attrition, we show how five spam campaigns controlling 145 thousand accounts combined are able to persist for months at a time, with each campaign enacting a unique spamming strategy. Surprisingly, three of these campaigns send spam directing visitors to reputable store fronts, blurring the line regarding what constitutes spam on social networks. © 2011 ACM.",account abuse; social networks; spam,account abuse; Data sets; Online social networks; Social Networks; Social relationships; spam; Spammers; Through the lens; Web hosting; Internet; Online systems; Web services; Social networking (online)
"Schulman A., Spring N.",2,Pingin' in the rain,2011,25,"University of Maryland, United States",University of Maryland College Park,1,USA,1,37,25,"Residential Internet connections are susceptible to weather-caused outages: Lightning and wind cause local power failures, direct lightning strikes destroy equipment, and water in the atmosphere degrades satellite links. Outages caused by severe events such as fires and undersea cable cuts are often reported upon by operators and studied by researchers. In contrast, outages cause by ordinary weather are typically limited in scope, and because of their small scale, there has not been comparable effort to understand how weather affects everyday last-mile Internet connectivity. We design and deploy a measurement tool called ThunderPing that measures the connectivity of residential Inter- net hosts before, during, and after forecast periods of severe weather. ThunderPing uses weather alerts from the US National Weather Service to choose a set of residential host addresses to ping from several vantage points on the Internet. We then process this ping data to determine when hosts lose connectivity, completely or partially, and categorize whether these failures occur during periods of severe weather or when the skies are clear. In our preliminary results, we find that compared to clear weather, failures are four times as likely during thunderstorms and two times as likely during rain. We also find that the duration of weather induced outages is relatively small for a satellite provider we focused on. © 2011 ACM.",outage; ping; ThunderPing; weather,Direct lightning strikes; Internet connection; Internet connectivity; Measurement tools; ping; Ping data; Power failure; Satellite providers; Severe weather; Small scale; ThunderPing; Undersea cable; US National Weather Service; weather; Weather alerts; Internet; Lightning; Outages; Rain; Satellite links; Thunderstorms; Measurements
"Finamore A., Mellia M., Munaf˜ M.M., Torres R., Rao S.G.",5,YouTube everywhere: Impact of device and infrastructure synergies on user experience,2011,182,"Politecnico di Torino, Italy; Purdue University, United States",Purdue University,1,Italy;USA,2,26,26,"In this paper we present a complete measurement study that compares YouTube traffic generated by mobile devices (smart-phones,tablets) with traffic generated by common PCs (desktops, notebooks, netbooks). We investigate the users' behavior and correlate it with the system performance. Our measurements are performed using unique data sets which are collected from vantage points in nation-wide ISPs and University campuses from two countries in Europe and the U.S. Our results show that the user access patterns are similar across a wide range of user locations, access technologies and user devices. Users stick with default player configurations, e.g., not changing video resolution or rarely enabling full screen playback. Furthermore it is very common that users abort video playback, with 60% of videos watched for no more than 20% of their duration. We show that the YouTube system is highly optimized for PC access and leverages aggressive buffering policies to guarantee excellent video playback. This however causes 25%-39% of data to be unnecessarily transferred, since users abort the playback very early. This waste of data transferred is even higher when mobile devices are considered. The limited storage offered by those devices makes the video download more complicated and overall less efficient, so that clients typically download more data than the actual video size. Overall, this result calls for better system optimization for both, PC and mobile accesses. © 2011 ACM.",internet measurement; mobile performance; quality of experience; video streaming; YouTube,Access technology; Data sets; Infrastructure synergies; Internet measurement; Limited storage; Measurement study; Mobile access; mobile performance; quality of experience; System optimizations; University campus; User access patterns; User devices; User experience; User location; Video Playback; Video resolutions; YouTube; Laptop computers; Microcomputers; Mobile devices; Optimization; Video streaming; Videotex; Internet service providers
"Ding Y., Du Y., Hu Y., Liu Z., Wang L., Ross K., Ghose A.",7,Broadcast yourself: Understanding YouTube uploaders,2011,36,"Computer Science and Engineering, Polytechnic Institute of NYU, United States; AT and T Labs., San Ramon, CA, United States; Stern School of Business, New York University, United States",AT and T Labs;NYU,2,USA,1,13,9,"YouTube uploaders are the central agents in the YouTube phenomenon. We conduct extensive measurement and analysis of YouTube uploaders. We estimate YouTube scale and examine the uploading behavior of YouTube users. We demonstrate the positive reinforcement between on-line social behavior and uploading behavior. Furthermore, we examine whether YouTube users are truly broadcasting themselves, via characterizing and classifying videos as either user generated or user copied. © 2011 ACM.",content classification; social network; system scale; YouTube,Central agent; Content classification; Measurement and analysis; Social behavior; Social Networks; system scale; YouTube; Measurements; Internet
"Rayanchu S., Patro A., Banerjee S.",3,Airshark: Detecting non-WiFi RF devices using commodity WiFi hardware,2011,63,"University of Wisconsin, Madison, WI, United States",University of Wisconsin-Madison,1,USA,1,17,15,"In this paper, we propose Airshark - a system that detects multiple non-WiFi RF devices in real-time and using only commodity WiFi hardware. To motivate the need for systems like Airshark, we start with measurement study that characterizes the usage and prevalence of non-WiFi devices across many locations. We then present the design and implementation of Airshark. Airshark extracts unique features using the functionality provided by a WiFi card to detect multiple non-WiFi devices including fixed frequency devices (e.g., ZigBee, analog cordless phone), frequency hoppers (e.g., Bluetooth, game controllers like Xbox), and broadband interferers (e.g., microwave ovens). Airshark has an average detection accuracy of 91-96%, even in the presence of multiple simultaneously active RF devices operating at a wide range of signal strengths (-80 to -30 dBm), while maintaining a low false positive rate. Through a deployment in two production WLANs, we show that Airshark can be a useful tool to the WLAN administrators in understanding non-WiFi interference. © 2011 ACM.",802.11; interference; non-wifi; rf device detection; spectrum; WiFi; wireless network monitoring,802.11; non-wifi; RF devices; spectrum; wireless network monitoring; Equipment; Internet; Wave interference; Wi-Fi
"Ager B., MŸhlbauer W., Smaragdakis G., Uhlig S.",4,Web content cartography,2011,25,"T-Labs./TU Berlin, Germany; ETH ZŸrich, Switzerland",ETH Zurich;TU Berlin,2,Germany;Switzerland,2,19,17,"Recent studies show that a significant part of Internet traffic is delivered through Web-based applications. To cope with the increasing demand for Web content, large scale content hosting and delivery infrastructures, such as data-centers and content distribution networks, are continuously being deployed. Being able to identify and classify such hosting infrastructures is helpful not only to content producers, content providers, and ISPs, but also to the research community at large. For example, to quantify the degree of hosting infrastructure deployment in the Internet or the replication of Web content. In this paper, we introduce Web Content Cartography, i.e., the identification and classification of content hosting and delivery infrastructures. We propose a lightweight and fully automated approach to discover hosting infrastructures based only on DNS measurements and BGP routing table snapshots. Our experimental results show that our approach is feasible even with a limited number of well-distributed vantage points. We find that some popular content is served exclusively from specific regions and ASes. Furthermore, our classification enables us to derive content-centric AS rankings that complement existing AS rankings and shed light on recent observations about shifts in inter-domain traffic and the AS topology. © 2011 ACM.",content delivery; DNS; hosting infrastructures; measurement,Automated approach; Content delivery; Content distribution networks; Content producers; Content providers; Data centers; DNS; hosting infrastructures; Inter-domain traffic; Internet traffic; Research communities; Routing table; Web content; Web-based applications; Internet protocols; Mapping; Maps; Measurements; Websites; Internet service providers
"Isacenkova J., Balzarotti D.",2,Measurement and evaluation of a real world deployment of a challenge-response spam filter,2011,4,"Eurecom, Sophia Antipolis, France",EURECOM,1,France,1,28,4,"Despite the number of existing solutions, spam still accounts for a large percentage of the email traffic on the Internet. Both the effectiveness and the impact of many common anti-spam techniques have already been largely studied and evaluated against multiple datasets. However, some of the less known solutions still lack a proper experimental validation. For example, Challenge-Response (CR) systems have been largely discussed, and often criticized, because they shift the effort to protect the user's mailbox from the recipient to the sender of the messages. In addition, these systems are believed to produce a lot of backscattered emails that further deteriorate the global Internet situation. In this paper we present the first comprehensive measurement study of a real anti-spam system based on a challenge-response technique. In our work we analyze a large amount of data, collected for a period of six months from over forty companies protected by a commercial challenge-response product. We designed our experiments from three different point of views: the end user, the system administrator, and the entire Internet community. Our results cover many different aspects such as the amount of challenges sent, the delay on the message delivery, and the likelihood of getting the challenge server blacklisted. Our aim is neither to attack nor to defend CR-based solutions. Instead, we hope that our findings will shed some light on some of the myths about these kind of systems, and will help both users and companies to take an informed decision on the topic. © 2011 ACM.",blacklisting; challenge-response; spam; whitelist,Anti-spam; Anti-spam systems; Back-scattered; blacklisting; Challenge response; Comprehensive measurement; Data sets; E-mail traffic; End users; Experimental validations; Global Internet; Informed decision; Internet communities; Message delivery; Real world deployment; spam; SPAM filter; System administrators; whitelist; Distributed computer systems; Electronic mail; Human computer interaction; Industry; Internet
"Motoyama M., McCoy D., Levchenko K., Savage S., Voelker G.M.",5,An analysis of underground forums,2011,120,"Department of Computer Science and Engineering, University of California, San Diego, CA, United States",University of California San Diego,1,USA,1,40,27,"Underground forums, where participants exchange information on abusive tactics and engage in the sale of illegal goods and services, are a form of online social network (OSN). However, unlike traditional OSNs such as Facebook, in underground forums the pattern of communications does not simply encode pre-existing social relationships, but instead captures the dynamic trust relationships forged between mutually distrustful parties. In this paper, we empirically characterize six different underground forums - - BlackHatWorld, Carders, HackSector, HackE1ite, Freehack, and L33tCrew - - examining the properties of the social networks formed within, the content of the goods and services being exchanged, and lastly, how individuals gain and lose trust in this setting. © 2011 ACM.",online social networks; underground forums,Facebook; Online social networks; Social Networks; Social relationships; Trust relationship; underground forums; Computer crime; Internet; Online systems; Social networking (online); Computer aided network analysis
"Song H.H., Ge Z., Mahimkar A., Wang J., Yates J., Zhang Y., Basso A., Chen M.",8,Q-score: Proactive service quality assessment in a large IPTV system,2011,25,"University of Texas at Austin, Austin, TX, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;University of Texas at Austin,2,USA,1,36,18,"In large-scale IPTV systems, it is essential to maintain high service quality while providing a wider variety of service features than typical traditional TV. Thus service quality assessment systems are of paramount importance as they monitor the user-perceived service quality and alert when issues occurs. For IPTV systems, however, there is no simple metric to represent user-perceived service quality and Quality of Experience (QoE). Moreover, there is only limited user feedback, often in the form of noisy and delayed customer calls. Therefore, we aim to approximate the QoE through a selected set of performance indicators in a proactive (i.e., detect issues before customers reports to call centers) and scalable fashion. In this paper, we present a service quality assessment framework, Q-score, which accurately learns a small set of performance indicators most relevant to user-perceived service quality, and proactively infers service quality in a single score. We evaluate Q-score using network data collected from a commercial IPTV service provider and show that Q-score is able to predict 60% of the service problems that are reported by customers with 0.1% false positives. Through Q-score, we have (i) gained insight into various types of service problems causing user dissatisfaction, including why users tend to react promptly to sound issues while late to video issues; (ii) identified and quantified the opportunity to proactively detect the service quality degradation of individual customers before severe performance impact occurs; and (iii) observed possibility to allocate customer care workforce to potentially troubling service areas before issues break out. © 2011 ACM.",analysis; assessment; IPTV; QoE; quality; service; video,analysis; assessment; QoE; service; video; Benchmarking; Customer satisfaction; Image quality; Internet; IPTV; Rating; Sales; Television broadcasting; Quality of service
"Al-Fares M., Elmeleegy K., Reed B., Gashinsky I.",4,Overclocking the Yahoo!: CDN for faster web page loads,2011,17,"Computer Science and Engineering, UC San Diego, United States; Yahoo Research, UC San Diego, United States; Yahoo Inc., UC San Diego, United States",University of California San Diego;Yahoo Research,2,USA,1,12,10,"Fast-loading web pages are key for a positive user experience. Unfortunately, a large number of users suffer from page load times of many seconds, especially for pages with many embedded objects. Most of this time is spent fetching the page and its objects over the Internet. This paper investigates the impact of optimizations that improve the delivery of content from edge servers at the Yahoo! Content Delivery Network (CDN) to the end users. To this end, we analyze packet traces of 12.3M TCP connections originating from users across the world and terminating at the Yahoo! CDN. Using these traces, we characterize key user-connection metrics at the network, transport, and the application layers. We observe high Round Trip Times (RTTs) and inflated number of round trips per page download (RTT multipliers). Due to inefficiencies in TCP's slow start and the HTTP protocol, we found several opportunities to reduce the RTT multiplier, e.g. increasing TCP's Initial Congestion Window (ICW), using TCP Appropriate Byte Counting (ABC), and using HTTP pipelining. Using live workloads, we experimentally study the micro effects of these optimizations on network connectivity, e.g. packet loss rate. To evaluate the macro effects of these optimizations on the overall page load time, we use realistic synthetic workloads in a closed laboratory environment. We find that compounding HTTP pipelining with increasing the ICW size can lead to reduction in page load times by up to 80%. We also find that no one configuration fits all users, e.g. increasing the TCP ICW to a certain size may help some users while hurting others. © 2011 ACM.",content delivery networks; TCP tuning; traffic analysis; web page load time,Application layers; Closed laboratories; Congestion window; Content delivery network; Edge server; Embedded object; End users; HTTP protocols; Network connectivity; Overclocking; Packet loss rates; Round trip; Round trip time; Slow start; Synthetic workloads; TCP connections; traffic analysis; User experience; Web page; Hypertext systems; Internet; Lead compounds; Optimization; Transmission control protocol; HTTP
"Sala A., Zhao X., Wilson C., Zheng H., Zhao B.Y.",5,Sharing graphs using differentially private graph models,2011,84,"Computer Science Dept., UC Santa Barbara, Santa Barbara, CA 93106, United States",University of California Santa Barbara,1,USA,1,29,24,"Continuing success of research on social and computer networks requires open access to realistic measurement datasets. While these datasets can be shared, generally in the form of social or Internet graphs, doing so often risks exposing sensitive user data to the public. Unfortunately, current techniques to improve privacy on graphs only target specific attacks, and have been proven to be vulnerable against powerful de-anonymization attacks. Our work seeks a solution to share meaningful graph datasets while preserving privacy. We observe a clear tension between strength of privacy protection and maintaining structural similarity to the original graph. To navigate the tradeoff, we develop a differentially-private graph model we call Pygmalion. Given a graph G and a desired level of e-differential privacy guarantee, Pygmalion extracts a graph's detailed structure into degree correlation statistics, introduces noise into the resulting dataset, and generates a synthetic graph G'. G' maintains as much structural similarity to G as possible, while introducing enough differences to provide the desired privacy guarantee. We show that simply applying differential privacy to graphs results in the addition of significant noise that may disrupt graph structure, making it unsuitable for experimental study. Instead, we introduce a partitioning approach that provides identical privacy guarantees using much less noise. Applied to real graphs, this technique requires an order of magnitude less noise for the same privacy guarantees. Finally, we apply our graph model to Internet, web, and Facebook social graphs, and show that it produces synthetic graphs that closely match the originals in both graph structure metrics and behavior in application-level tests. © 2011 ACM.",differential privacy; graph models; online social networks,Data sets; Degree correlation; Differential privacies; Experimental studies; Facebook; Graph G; Graph model; graph models; Graph structures; Internet graphs; online social networks; Open Access; Privacy protection; Sharing graphs; Social graphs; Structural similarity; Synthetic graphs; User data; Data processing; Graph theory; Internet; Online systems; Public risks; Social networking (online); Graphic methods
"Zhou J., Li Y., Adhikari V.K., Zhang Z.-L.",4,Counting YouTube videos via random prefix sampling,2011,38,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55414, United States",University of Minnesota,1,USA,1,25,20,"Leveraging the characteristics of YouTube video id space and exploiting a unique property of YouTube search API, in this paper we develop a random prefix sampling method to estimate the total number of videos hosted by YouTube. Through theoretical modeling and analysis, we demonstrate that the estimator based on this method is unbiased, and provide bounds on its variance and confidence interval. These bounds enable us to judiciously select sample sizes to control estimation errors. We evaluate our sampling method and validate the sampling results using two distinct collections of YouTube video id's (namely, treating each collection as if it were the ""true"" collection of YouTube videos). We then apply our sampling method to the live YouTube system, and estimate that there are a total of roughly 500 millions YouTube videos by May, 2011. Finally, using an unbiased collection of YouTube videos sampled by our method, we show that YouTube video view count statistics collected by prior methods (e.g., through crawling of related video links) are highly skewed, significantly under-estimating the number of videos with very small view counts ( © 2011 ACM.",online social networks; sampling; YouTube,Confidence interval; Estimation errors; Online social networks; Sample sizes; Sampling method; Sampling results; Search API; Theoretical modeling; YouTube; Internet; Online systems; Sampling; Social networking (online); Estimation
"Bauer S., Beverly R., Berger A.",3,"Measuring the state of ECN readiness in servers, clients, and routers",2011,26,"MIT CSAIL, United States; Naval Postgraduate School, United States; MIT CSAIL / Akamai, United States",MIT;Akamai Technologies;Naval Postgraduate School,3,USA,1,48,46,"Better exposing congestion can improve traffic management in the wide-area, at peering points, among residential broadband connections, and in the data center. TCP's network utilization and efficiency depends on congestion information, while recent research proposes economic and policy models based on congestion. Such motivations have driven widespread support of Explicit Congestion Notification (ECN)in modern operating systems. We reappraise the Internet's ECN readiness, updating and extending previous measurements. Across large and diverse server populations, we find a three-fold increase in ECN support over prior studies. Using new methods, we characterize ECN within mobile infrastructure and at the client-side, populations previously unmeasured. Via large-scale path measurements, we find the ECN feedback loop failing in the core of the network 40% of the time, typically at AS boundaries. Finally, we discover new examples of infrastructure violating ECN Internet standards, and discuss remaining impediments to running ECN while suggesting mechanisms to aid adoption. © 2011 ACM.",ecn; explicit congestion notification; router-assisted congestion control,Broadband connection; Data centers; ecn; Explicit congestion notification; Feed-back loop; Internet Standard; Mobile infrastructure; Net work utilization; Path measurement; Policy model; Traffic management; Wide area; Routers; Transmission control protocol; Internet
"Butkiewicz M., Madhyastha H.V., Sekar V.",3,"Understanding website complexity: Measurements, metrics, and implications",2011,100,"UC Riverside, United States; Intel Labs., United States",University of California Riverside,1,USA,1,26,14,"Over the years, the web has evolved from simple text content from one server to a complex ecosystem with different types of content from servers spread across several administrative domains. There is anecdotal evidence of users being frustrated with high page load times or when obscure scripts cause their browser windows to freeze. Because page load times are known to directly impact user satisfaction, providers would like to understand if and how the complexity of their websites affects the user experience. While there is an extensive literature on measuring web graphs, website popularity, and the nature of web traffic, there has been little work in understanding how complex individual websites are, and how this complexity impacts the clients' experience. This paper is a first step to address this gap. To this end, we identify a set of metrics to characterize the complexity of websites both at a content-level (e.g., number and size of images) and service-level (e.g., number of servers/origins). We find that the distributions of these metrics are largely independent of a website's popularity rank. However, some categories (e.g., News) are more complex than others. More than 60% of websites have content from at least 5 non-origin sources and these contribute more than 35% of the bytes downloaded. In addition, we analyze which metrics are most critical for predicting page render and load times and find that the number of objects requested is the most important factor. With respect to variability in load times, however, we find that the number of servers is the best indicator. © 2011 ACM.",page load times; web page complexity,Anecdotal evidences; Number and size; page load times; Text content; User experience; User satisfaction; Web graphs; Web page; Web traffic; Website popularity; Internet; Websites
"Dukkipati N., Mathis M., Cheng Y., Ghobadi M.",4,Proportional rate reduction for TCP,2011,23,"Google, Inc., Mountain View, CA, United States",Google,1,USA,1,26,25,"Packet losses increase latency for Web users. Fast recovery is a key mechanism for TCP to recover from packet losses. In this paper, we explore some of the weaknesses of the standard algorithm described in RFC 3517 and the non-standard algorithms implemented in Linux. We find that these algorithms deviate from their intended behavior in the real world due to the combined effect of short flows, application stalls, burst losses, acknowledgment (ACK) loss and reordering, and stretch ACKs. Linux suffers from excessive congestion window reductions while RFC 3517 transmits large bursts under high losses, both of which harm the rest of the flow and increase Web latency. Our primary contribution is a new design to control transmission in fast recovery called proportional rate reduction (PRR). PRR recovers from losses quickly, smoothly and accurately by pacing out retransmissions across received ACKs. In addition to PRR, we evaluate the TCP early retransmit (ER) algorithm which lowers the duplicate acknowledgment threshold for short transfers, and show that delaying early retransmissions for a short interval is effective in avoiding spurious retransmissions in the presence of a small degree of reordering. PRR and ER reduce the TCP latency of connections experiencing losses by 3-10% depending on the response size. Based on our instrumentation on Google Web and YouTube servers in U.S. and India, we also present key statistics on the nature of TCP retransmissions. © 2011 ACM.",early re-transmit; fast recovery; proportional rate reduction; retransmission statistics; TCP,early re-transmit; Fast recovery; proportional rate reduction; Retransmissions; TCP; Algorithms; Computer operating systems; Internet; Packet loss; Recovery; Websites; Transmission control protocol
"Kim W., Roopakalu A., Li K.Y., Pai V.S.",4,Understanding and characterizing PlanetLab resource usage for federated network testbeds,2011,13,"Department of Computer Science, Princeton University, United States",Princeton University,1,USA,1,44,22,"Global network testbeds are crucial for innovative network research. Built on the success of PlanetLab, the next generation of federated testbeds are under active development, but very little is known about resource usage in the shared infrastructures. In this paper, we conduct an extensive study of the usage profiles in PlanetLab that we collected for six years by running CoMon, a PlanetLab monitoring service. We examine various aspects of node-level behavior as well as experiment-centric behavior, and describe their implications for resource management in the federated testbeds. Our main contributions are threefold: (1) Contrary to common belief, our measurements show there is no tragedy of the commons in PlanetLab, since most PlanetLab experiments exploit the system's network reach more than just its hardware resources; (2) We examine resource allocation systems proposed for the federated testbeds, such as bartering and central banking schemes, and show that they would handle only a small percentage of the total usage in PlanetLab; and (3) Lastly, we identify factors that account for high resource contention or poor utilization in PlanetLab nodes. We analyze workload imbalance and problematic slices in PlanetLab, and describe the implications of our measurements for improving overall utility of the testbed. © 2011 ACM.",characterization; network testbeds; PlanetLab,Global networks; Hardware resources; Monitoring services; Network testbeds; PlanetLab; Planetlab nodes; Resource allocation systems; Resource contention; Resource management; Resource usage; Shared infrastructure; Tragedy of the commons; Characterization; Experiments; Internet; Resource allocation; Telecommunication networks; Testbeds
"Raftopoulos E., Dimitropoulos X.",2,"Detecting, validating and characterizing computer infections in the wild",2011,9,"ETH Zurich, Zurich, Switzerland",ETH Zurich,1,Switzerland,1,29,15,"Although network intrusion detection systems (IDSs) have been studied for several years, their operators are still overwhelmed by a large number of false-positive alerts. In this work we study the following problem: from a large archive of intrusion alerts collected in a production network, we want to detect with a small number of false positives hosts within the network that have been infected by malware. Solving this problem is essential not only for reducing the false-positive rate of IDSs, but also for labeling traces collected in the wild with information about validated security incidents. We use a 9-month long dataset of IDS alerts and we first build a novel heuristic to detect infected hosts from the on average 3 million alerts we observe per day. Our heuristic uses a statistical measure to find hosts that exhibit a repeated multi-stage malicious footprint involving specific classes of alerts. A significant part of our work is devoted to the validation of our heuristic. We conduct a complex experiment to assess the security of suspected infected systems in a production environment using data from several independent sources, including intrusion alerts, blacklists, host scanning logs, vulnerability reports, and search engine queries. We find that the false positive rate of our heuristic is 15% and analyze in-depth the root causes of the false positives. Having validated our heuristic, we apply it to our entire trace, and characterize various important properties of 9 thousand infected hosts in total. For example, we find that among the infected hosts, a small number of heavy hitters originate most outbound attacks and that future infections are more likely to occur close to already infected hosts. © 2011 ACM.",alert correlation; intrusion detection; j-measure; malware; network security; snort,Alert correlation; Data sets; False positive; False positive rates; Following problem; Heavy-hitter; Infected systems; Intrusion alerts; j-measure; Malwares; Multi-stage; Network intrusion detection systems; Production environments; Production network; Root cause; Security incident; snort; Statistical measures; Computer crime; Internet; Network security; Search engines; Intrusion detection
"Xu Q., Erman J., Gerber A., Mao Z., Pang J., Venkataraman S.",6,Identifying diverse usage behaviors of smartphone apps,2011,222,"University of Michigan, Ann Arbor, MI, United States; AT and T Labs. Research, Florham Park, NJ, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,30,19,"Smartphone users are increasingly shifting to using apps as ""gateways"" to Internet services rather than traditional web browsers. App marketplaces for iOS, Android, and Windows Phone platforms have made it attractive for developers to deploy apps and easy for users to discover and start using many network-enabled apps quickly. For example, it was recently reported that the iOS AppStore has more than 350K apps and more than 10 billion downloads. Furthermore, the appearance of tablets and mobile devices with other form factors, which also use these marketplaces, has increased the diversity in apps and their user population. Despite the increasing importance of apps as gateways to network services, we have a much sparser understanding of how, where, and when they are used compared to traditional web services, particularly at scale. This paper takes a first step in addressing this knowledge gap by presenting results on app usage at a national level using anonymized network measurements from a tier-1 cellular carrier in the U.S. We identify traffic from distinct marketplace apps based on HTTP signatures and present aggregate results on their spatial and temporal prevalence, locality, and correlation. © 2011 ACM.",app usage behavior; smartphone apps,app usage behavior; Form factors; Internet services; Knowledge gaps; National level; Network measurement; Network services; Phone platforms; Smart phones; Approximation theory; Gateways (computer networks); HTTP; Internet; Mobile devices; Signal encoding; Web browsers; Web services
"Cardigliano A., Deri L., Gasparakis J., Fusco F.",4,vPF-RING: Towards wire-speed network monitoring using virtual machines,2011,12,"ntop, Pisa, Italy; IIT-CNR, Pisa, Italy; Intel Corporation, Hillsboro, OR, United States; IBM Research, RŸschlikon, Switzerland",IBM,1,Italy;Switzerland;USA,3,53,26,"The demand of highly flexible and easy to deploy network monitoring systems has pushed companies toward software based network monitoring probes implemented with commodity hardware rather than with expensive and highly specialized network devices. Deploying software probes under virtual machines executed on the same physical box is attractive for reducing deployment costs and for simplifying the management of advanced network monitoring architectures built on top of heterogeneous monitoring tools (i.e. Intrusion Detection Systems and Performance Monitoring Systems). Unfortunately, software probes are usually not able to meet the performance requirements when deployed in virtualized environments as virtualization introduces severe performance bottlenecks when performing packet capture, which is the core activity of passive network monitoring systems. This paper covers the design and implementation of vPF-RING, a novel framework for efficiently capturing packets on virtual machines running on commodity hardware. This solution allows network administrators to exploit the benefits of virtualization such as reduced costs and centralized administration, while preserving the ability to capture packets at wire speed even when deploying applications in virtual machines. The validation process has demonstrated that this solution can be profitably used for multi-gigabit network monitoring, paving the way to low-cost virtualized monitoring systems. © 2011 ACM.",packet capture; passive traffic monitoring.; virtualization,Advanced networks; Centralized administration; Commodity hardware; Core activity; Deployment costs; Intrusion Detection Systems; Monitoring system; Monitoring tools; Multi-gigabit networks; Network administrator; Network Monitoring; Network monitoring systems; Packet capture; Performance bottlenecks; Performance monitoring systems; Performance requirements; Reduced cost; Software-based; Specialized networks; Traffic monitoring; Validation process; Virtual machines; virtualization; Virtualizations; Virtualized environment; Advanced traffic management systems; Cost reduction; Hardware; Internet; Intrusion detection; Network management; Passive networks; Probes; Virtual reality; Wire; Monitoring
"Chen Y., Jain S., Adhikari V.K., Zhang Z.-L.",4,Characterizing roles of front-end servers in end-to-end performance of dynamic content distribution,2011,17,"Department of Computer Science and Engineering, University of Minnesota - Twin Cities, Minneapolis, MN 55414, United States",University of Minnesota Twin Cities,1,USA,1,30,26,"This paper investigates the roles of front-end (proxy) servers in improving user-perceived performance of dynamic content distribution. Using Bing and Google search services as two case studies, we perform extensive network measurement and analysis to understand several key factors that affect the overall user-perceived performance. In particular, we develop a simple model-based inference framework to indirectly measure and quantify the (directly unobservable) ""frontend-to-backend fetching time"" comprised of the query processing time at back-end data centers and the delivery time between the back-end data centers and front-end servers. We show that this fetching time plays a critical role in the end-to-end performance of dynamic content delivery. © 2011 ACM.",dynamic content distribution; search service; TCP-splitting,Data centers; Delivery time; Dynamic content; End-to-end performance; Key factors; Network measurement; search service; Search services; TCP-splitting; Unobservable; Internet; Data processing
"Honda M., Nishida Y., Raiciu C., Greenhalgh A., Handley M., Tokuda H.",6,Is it still possible to extend TCP?,2011,111,"Keio University, Japan; Universitatea Politehnica Bucuresti, Romania; University College London, United Kingdom",Keio University;Universitatea Politehnica Bucuresti;University College London,3,Japan;Romania;UK,3,47,45,"We've known for a while that the Internet has ossified as a result of the race to optimize existing applications or enhance security. NATs, performance-enhancing-proxies,firewalls and traffic normalizers are only a few of the middleboxes that are deployed in the network and look beyond the IP header to do their job. IP itself can't be extended because ""IP options are not an option"". Is the same true for TCP? In this paper we develop a measurement methodology for evaluating middlebox behavior relating to TCP extensions and present the results of measurements conducted from multiple vantage points. The short answer is that we can still extend TCP, but extensions' design is very constrained as it needs to take into account prevalent middlebox behaviors. For instance, absolute sequence numbers cannot be embedded in options, as middleboxes can rewrite ISN and preserve undefined options. Sequence numbering also must be consistent for a TCP connection, because many middleboxes only allow through contiguous flows. We used these findings to analyze three proposed extensions to TCP. We find that MPTCP is likely to work correctly in the Internet or fallback to regular TCP. TcpCrypt seems ready to be deployed, however it is fragile if resegmentation does happen - -for instance with hardware offload. Finally, TCP extended options in its current form is not safe to deploy. © 2011 ACM.",measurements; middleboxes; protocol design; TCP,IP option; Measurement methodology; Middleboxes; Multiple vantage points; protocol design; Sequence number; TCP; TCP connections; Computer system firewalls; Internet; Measurements; Transmission control protocol
"Wendell P., Freedman M.J.",2,Going viral: Flash crowds in an open CDN,2011,35,"U.C. Berkeley, Berkeley, CA, United States; Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,12,9,"Handling flash crowds poses a difficult task for web services. Content distribution networks (CDNs), hierarchical web caches, and peer-to-peer networks have all been proposed as mechanisms for mitigating the effects of these sudden spikes in traffic to under-provisioned origin sites. Other than a few anecdotal examples of isolated events to a single server, however, no large-scale analysis of flash-crowd behavior has been published to date. In this paper, we characterize and quantify the behavior of thousands of flash crowds on CoralCDN, an open content distribution network running at several hundred POPs. Our analysis considers over four years of CDN traffic, comprising more than 33 billion HTTP requests. We draw conclusions in several areas, including (i) the potential benefits of cooperative vs. independent caching by CDN nodes, (ii) the efficacy of elastic redirection and resource provisioning, and (iii) the ecosystem of portals, aggregators, and social networks that drive traffic to third-party websites. © 2011 ACM.",content distribution networks; flash crowds,Content distribution networks; Flash crowd; flash crowds; Large-scale analysis; Open content; Peer to peer; Potential benefits; Resource provisioning; Single server; Social Networks; Web Cache; Behavioral research; Distributed computer systems; HTTP; Internet; Online systems; Portals; Web services; Peer to peer networks
"Chen Y., Berg J.O., Ammar M., Zegura E.",4,Evaluation of data communication opportunities from oil field locations at remote areas,2011,0,"Schlumberger PPCU, Sugar Land, TX, United States; College of Computing, Georgia Tech., Atlanta, GA, United States",Georgia Tech,1,USA,1,30,17,"Cellular data links are an effective outdoor Internet access solution in urban environments. In this paper, we evaluate cellular data service as a potential data communication solution for oil field crews operating at remote areas in the United States. In our study, we first record the performance of cellular data service at twelve oil field locations. Measurement results show extensive availability of cellular service at those locations making it potentially a data communication solution at field locations. Spatial diversity from multiple antennas is shown to improve the cellular data link's speed but quality of the link varies significantly due to attenuated/faded cellular signal. We then design a measurement framework and deploy measurement units to five oil field crews and carry out a side-by-side comparison of two different satellite links and cellular links from two service providers. Analysis of data sets consisting of more than 300 days' measurement shows that the cellular link has comparable or even higher availability than conventional satellite link at many field operations. However, the quality of its coverage is location dependent. This indicates that both cellular and satellite links should be used to provide highly available and cost-effective data communication for such operations. © 2011 ACM.",cellular; satellite,Analysis of data; cellular; Cellular links; Cellular services; Cellular signals; Data link; Data services; Data-communication; Field crews; Field operation; Internet access solutions; Location dependents; Measurement results; Multiple antenna; Remote areas; Service provider; Spatial diversity; Urban environments; Communication; Convolutional codes; Internet; Local area networks; Oil fields; Satellites; Units of measurement; Satellite links
"L—pez-PŽrez D., Chu X., Vasilakos A.V., Claussen H.",4,Minimising cell transmit power: Towards self-organized resource allocation in OFDMA femtocells,2011,15,"King's College London, London, United Kingdom; National Technical University of Athens, Athens, Greece; Alcatel-Lucent Bell-Labs., Dublin, Ireland",Bell Labs;Kings College London;National Technical University of Athens,3,Greece;Ireland;UK,3,14,12,"With the introduction of femtocells, cellular networks are moving from the conventional centralised architecture to a distributed one, where each network cell should make its own radio resource management decisions, while providing inter-cell interference mitigation. However, realising this distributed cellular network architecture is not a trivial task. In this paper, we first introduce a simple self-organisation rule under which a distributed cellular network is able to converge into an efficient resource allocation pattern, then propose a novel resource allocation model taking realistic resource allocation constraints into account, and finally evaluate the performance of the proposed self-organisation rule and resource allocation model using system-level simulations.",Femtocell; Interference; Resource Allocation,Cellular network; Efficient resource allocation; Femtocell; Intercell interference; Network cells; Radio resource management; Resource allocation constraints; Resource allocation model; Self-organisation; System level simulation; Transmit power; Cells; Cellular neural networks; Frequency division multiple access; Mobile telecommunication systems; Network architecture; Resource allocation; Wave interference; Computer simulation
"Dhananjay A., Tierney M., Li J., Subramanian L.",4,WiRE: A new rural connectivity paradigm,2011,9,"New York University, United States",NYU,1,USA,1,24,18,"Many rural areas in developing regions remain largely disconnected from the rest of the world due to low purchasing power and the exorbitant cost of existing connectivity solutions. Wireless Rural Extensions (WiRE) is a lowpower rural wireless network architecture that provides inexpensive, self-sustainable, and high-bandwidth connectivity. WiRE relies on a high-bandwidth directional wireless backbone with local distribution networks to provide focused IP coverage. WiRE also provides cellular connectivity using OpenBTS-based GSM microcells. It supports a naming and addressing framework that inter-operates with traditional telecom networks and enables a wide range of mobile services on a common IP framework. The entire WiRE network can be built by integrating a range of off-the-shelf components and existing open source tools.",Design; Economics; Reliability,Cellular connectivity; Developing regions; High bandwidth; Local distribution networks; Low Power; Micro cell; Mobile service; New rural; Off-the-shelf components; Open source tools; Purchasing power; Rural wireless; Self-sustainable; Telecom networks; Wireless backbone; Bandwidth; Design; Economics; Network architecture; Reliability; Rural areas; Wire
"Curtis A.R., Mogul J.C., Tourrilhes J., Yalagandula P., Sharma P., Banerjee S.",6,DevoFlow: Scaling flow management for high-performance networks,2011,717,"University of Waterloo, Canada; HP Labs, Palo Alto, United States",HP Labs;University of Waterloo,2,Canada;USA,2,5,5,"OpenFlow is a great concept, but its original design imposes excessive overheads. It can simplify network and traffic management in enterprise and data center environments, because it enables ow-level control over Ethernet switching and provides global visibility of the ows in the network. However, such fine-grained control and visibility comes with costs: the switch-implementation costs of involving the switch's control-plane too often and the distributed-system costs of involving the OpenFlow controller too frequently, both on ow setups and especially for statistics-gathering. In this paper, we analyze these overheads, and show that OpenFlow's current design cannot meet the needs of high-performance networks. We design and evaluate DevoFlow, a modification of the OpenFlow model which gently breaks the coupling between control and global visibility, in a way that maintains a useful amount of visibility without imposing unnecessary costs. We evaluate DevoFlow through simulations, and find that it can load-balance data center traffic as well as fine-grained solutions, without as much overhead: DevoFlow uses 10-53 times fewer ow table entries at an average switch, and uses 10-42 times fewer control messages. Copyright 2011 ACM.",Data center; Flow-based networking,Control messages; Data centers; Ethernet switching; Fine-grained control; Flow management; Flow-based networking; Global visibility; High performance networks; Load-balance; Original design; Traffic management; Costs; Design; Network management; Visibility; Information management
"Hong S., Katti S.",2,DOF: A local wireless information plane,2011,42,"Stanford University, United States",Stanford University,1,USA,1,3,1,"The ability to detect what unlicensed radios are operating in a neigh-borhood, their spectrum occupancies and the spatial directions their signals are traversing is a fundamental primitive needed by many applications, ranging from smart radios to coexistence to network management to security. In this paper we present DOF, a detector that in a single framework accurately estimates all three parameters. DOF builds on the insight that in most wireless protocols, there are hidden repeating patterns in the signals that can be used to construct unique signatures, and accurately estimate signal types and their spectral and spatial parameters. We show via experimental evaluation in an indoor testbed that DOF is robust and accurate, it achieves greater than 85% accuracy even when the SNRs of the detected signals are as low as 0 dB, and even when there are multiple interfering signals present. To demonstrate the benefits of DOF, we design and implement a preliminary prototype of a smart radio that operates on top of DOF, and show experimentally that it provides a 80% increase in throughput over Jello, the best known prior implementation, while causing less than 10% performance drop for co-existing WiFi and Zigbee radios. Copyright 2011 ACM.",Algorithms; Design; Performance,Co-existing; Experimental evaluation; Interfering signals; Performance; Spatial direction; Spatial parameters; Three parameters; Wireless protocol; Zig-Bee; Algorithms; Design; Network management; Network security; Information management
"Krifa A., Mendonca M., Rais R.N.B., Barakat C., Turletti T., Obraczka K.",6,Efficient content dissemination in heterogeneous networks prone to episodic connectivity,2011,2,"Plante Project-Team, INRIA Sophia Antipolis, France; University of California, Santa Cruz, CA, United States",INRIA;University of California Santa Cruz,2,France;USA,2,51,43,"Ubiquity of portable computing devices coupled with wide availability of wireless communication present new impor- tant opportunities for applications involving media-rich content dissemination. However, as access networks become increasingly more heterogeneous, seamless data delivery across internets consisting of a variety of network technology becomes a real challenge. In this demonstration, we showcase a system that enables content dissemination over heterogeneous internets consisting of wired, infrastructure-based and infrastructure-less wireless networks that may be prone to intermittent connectivity. Using an efficient, yet flexible buffer management scheme, we are able to address application-specific performance requirements such as average delay, delivery probability, energy efficiency, etc. Our system uses the Message Delivery in Heterogeneous, Disruption-prone Networks (MeDeHa) [2]) framework to deliver messages across a heterogeneous internet coupled with History-Based Scheduling and Drop (HBSD) buffer management [1] as a way to optimize resources provided by opportunistic networks. MeDeHa, which is described in detail in [2], provides seamless data delivery over interconnecting networks of different types, i.e., infrastructure-based and infrastructure-less networks. MeDeHa's comprehensive approach to bridging infrastructure-based and infrastructureless networks also copes with intermittent connectivity. For this demonstration, we showcase a ""complete stack"" solution featuring, from to top to bottom, the DTN2 ""bundle"" layer, HBSD as an ""external router"" to DTN2, and MeDeHa, which handles message delivery. We have implemented, on a Linux-based testbed, (i) the MeDeHa framework, (ii) the HBSD [3] external router for the DTN2 [4] architecture.",Design; Experimentation,Access network; Average delay; Buffer management; Content dissemination; Data delivery; Experimentation; Infrastructure-less wireless networks; Infrastructureless networks; Intermittent connectivity; Message delivery; Network technologies; Opportunistic networks; Performance requirements; Portable computing devices; System use; Wireless communications; Computer architecture; Computer operating systems; Design; Energy efficiency; Heterogeneous networks; Scheduling; Telephone systems; Ubiquitous computing; Wireless networks; Wireless telecommunication systems; Internet
"Li T., Sun Z., Jia C., Su Q., Lee M.",5,Using NetMagic to observe fine-grained per-flow latency measurements,2011,12,"School of Computer, National University of Defense Technology, Changsha, Hunan, China; School of Electrical and Computer Engineering, Purdue University, West Lafayette, United States",National University of Defense Technology;Purdue University,2,China;USA,2,30,20,"We introduce NetMagic [1] to demonstrate the efficacy of RLI architecture [2] for the fine-grained per-flow latency measurements. In this demo, the main function of RLI is implemented in NetMagic, which is the key component of our experimental network comprising several computers and switches. We are going to show how NetMagic can provide rapid implementation and evaluation of RLI architecture that is difficult with commercial switch or router platforms. In the demo, the estimated fine-grained per-flow latency by RLI is monitored and dynamically presented. Further, the true latency with a resolution of 8ns is also provided by NetMagic for the evaluation. The efficacy of RLI architecture can be observed in a real-time fashion by the difference between estimated latencies and true ones.",Measurement; NetMagic Platform; Per-Flow Latency; RLI Architecture,Key component; NetMagic Platform; Per-Flow Latency; Computer architecture; Measurements; Network architecture
"Giotsas V., Zhou S.",2,Detecting and assessing the hybrid IPv4/IPv6 as relationships,2011,8,"University College London, United Kingdom",University College London,1,UK,1,4,2,"The business relationships between the Autonomous Systems (ASes) play a central role in the BGP routing. The existing relationship inference algorithms are profoundly based on the valley-free rule and generalize their inference heuristics for both the IPv4 and IPv6 planes, introducing unavoidable inference artifacts. To discover and analyze the Typeof-Relationship (ToR) properties of the IPv6 topology we mine the BGP Communities attribute which provides an unexploited wealth of reliable relationship information. We obtain the actual relationships for 72% of the IPv6 AS links that are visible in the RouteViews and RIPE RIS repositories. Our results show that as many as 13% of AS links that serve both IPv4 and IPv6 traifc have difierent relationships depending on the IP version. Such relationships are characterized as hybrid. We observe that links with hybrid relationships are present in a large number of IPv6 AS paths. Furthermore, an unusually large portion of IPv6 AS paths violate the valley-free rule, indicating that the global reachability in the IPv6 Internet requires the relaxation of the valley-free rule. Our work highlights the importance of correctly inferring the AS relationships and the need to appreciate the distinct characteristics of IPv6 routing policies.",AS relationship; Autonomous Systems; BGP; Inference algorithms; Inter-domain routing; Internet; IPv6; Topology,AS relationships; Autonomous systems; BGP; Inference algorithm; Interdomain Routing; IPv6; Algorithms; Inference engines; Internet; Landforms; Telecommunication networks; Topology; Internet protocols
"Lin K.C.-J., Gollakota S., Katabi D.",3,Random access heterogeneous MIMO networks,2011,107,"Academia Sinica, Taiwan; MIT, United States",MIT,1,Taiwan;USA,2,5,3,"This paper presents the design and implementation of 802.11n+, a fully distributed random access protocol for MIMO networks. 802.11n+ allows nodes that differ in the number of antennas to contend not just for time, but also for the degrees of freedom provided by multiple antennas. We show that even when the medium is already occupied by some nodes, nodes with more antennas can transmit concurrently without harming the ongoing transmissions. Furthermore, such nodes can contend for the medium in a fully distributed way. Our testbed evaluation shows that even for a small network with three competing node pairs, the resulting system about doubles the average network throughput. It also maintains the random access nature of today's 802.11n networks. Copyright 2011 ACM.",Interference alignment; Interference nulling; MIMO,802.11n; Interference alignment; Multiple antenna; Network throughput; Node pairs; Random access; Random access protocol; Small networks; Interference suppression; MIMO systems; Antennas
Baden R.,1,LoKI: Location-based PKI for social networks,2011,1,"University of Maryland, United States",University of Maryland College Park,1,USA,1,6,5,"Decentralized online social networks (OSNs) typically rely on the existence of a public key infrastructure (PKI), but certificate authorities (CAs) cannot scalably identify all of the members of an OSN. Our system, LoKI, uses the ubiquity of mobile devices to exchange secrets during real-world meetings that can be used for the purposes of identification in-band, allowing each user to easily discover the keys of many one-hop relationships in the OSN. We measure the frequency of such real-world meetings among OSN users with data sets crawled from Facebook, Twitter, and Foursquare. We quantify the resources consumed on the mobile devices in terms of storage and battery based on traces that reveal the number of mobile devices expected to be seen under normal activity. Lastly, we describe a rendezvous service that enables background peer-to-peer (P2P) communication on non-rooted Android phones, which we believe to be a practical and necessary service for many mobile peer-to-peer systems.",Location; Mobility; Online social networks; Public key infrastructure,Certificate authority; Data sets; Facebook; In-band; Location based; Online social networks; Peer-to-peer communications; Peer-to-Peer system; Public key infrastructure; Social Networks; Carrier mobility; Cellular telephone systems; Location; Mobile devices; Peer to peer networks; Public key cryptography; Social networking (online)
"Vanbever L., Vissicchio S., Pelsser C., Francois P., Bonaventure O.",5,Seamless network-wide IGP migrations,2011,47,"UniversitŽ Catholique de Louvain, Belgium; Roma Tre University, Italy; Internet Initiative Japan, Japan",Roma Tre University;Universite Catholique de Louvain,2,Belgium;Italy;Japan,3,33,23,"Network-wide migrations of a running network, such as the replacement of a routing protocol or the modification of its configuration, can improve the performance, scalability, manageability, and security of the entire network. However, such migrations are an important source of concerns for network operators as the reconfiguration campaign can lead to long and service-affecting outages. In this paper, we propose a methodology which addresses the problem of seamlessly modifying the configuration of commonly used link-state Interior Gateway Protocols (IGP). We illustrate the benefits of our methodology by considering several migration scenarios, including the addition or the removal of routing hierarchy in an existing IGP and the replacement of one IGP with another. We prove that a strict operational ordering can guarantee that the migration will not create IP transit service outages. Although finding a safe ordering is NP-complete, we describe techniques which efficiently find such an ordering and evaluate them using both real-world and inferred ISP topologies. Finally, we describe the implementation of a provisioning system which automatically performs the migration by pushing the configurations on the routers in the appropriate order, while monitoring the entire migration process.",Configuration; Design guidelines; Interior Gateway Protocol (IGP); Migration; Summarization,Configuration; Design guidelines; Interior Gateway Protocol (IGP); Migration; Summarization; Internet protocols; Internet service providers; Network protocols; Network security; Routers; Gateways (computer networks)
"Canini M., Jovanovi_ V., Venzano D., Novakovi_ D., Kosti_ D.",5,Online testing of federated and heterogeneous distributed systems,2011,5,"School of Computer and Communication Sciences, EPFL, Switzerland","EPFL, Switzerland",1,Switzerland,1,7,4,"DiCE is a system for online testing of federated and heterogeneous distributed systems. We have built a prototype of DiCE and integrated it with an open-source BGP router. DiCE quickly detects three important classes of faults, resulting from configuration mistakes, policy conflicts and programming errors. The goal of this demo is to showcase our DiCE prototype while it executes an experiment that involves exploring BGP system behavior in a topology with 27 BGP routers and Internet-like conditions (Figure 1).",Fault detection; Federated and heterogeneous distributed systems; Online testing,Heterogeneous distributed systems; On-line testing; Open-source; Policy conflict; Programming errors; System behaviors; Fault detection; Routers; Online systems
"Ren Y., Zhou W., Wang A., Jia L., Gurney A.J.T., Loo B.T., Rexfordz J.",7,FSR: Formal analysis and implementation toolkit for safe inter-domain routing,2011,6,"University of Pennsylvania, United States; Carnegie-Mellon University, United States; Princeton University, United States",Carnegie Mellon University;Princeton University;University of Pennsylvania,3,USA,1,45,39,"We present the demonstration of a comprehensive toolkit for analyzing and implementing routing policies, ranging from high-level guidelines to specific router configurations. Our Formally Safe Routing (FSR) toolkit performs all of these functions from the same algebraic representation of routing policy. We show that routing algebra has a very natural translation to both integer constraints (to perform safety analysis using SMT solvers) and declarative programs (to generate distributed implementations). Our demonstration with realistic topologies and policies shows how FSR can detect problems in an AS's iBGP configuration, prove sufficient conditions for BGP safety, and empirically evaluate convergence time.",Design; Experimentation; Languages,Algebraic representations; Convergence time; Declarative programs; Distributed implementation; Experimentation; Formal analysis; Integer constraints; Interdomain Routing; Router configuration; Routing policies; Safety analysis; Sufficient conditions; Algebra; Design; Query languages; Program translators
"Akhshabi S., Dovrolis C.",2,The evolution of layered protocol stacks leads to an hourglass-shaped architecture,2011,40,"College of Computing, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,4,3,"The Internet protocol stack has a layered architecture that resembles an hourglass. The lower and higher layers tend to see frequent innovations, while the protocols at the waist of the hourglass appear to be ""ossified"". We propose EvoArch, an abstract model for studying protocol stacks and their evolution. EvoArch is based on a few principles about layered network architectures and their evolution in a competitive environment where protocols acquire value based on their higher layer applications and compete with other protocols at the same layer. EvoArch produces an hourglass structure that is similar to the Internet architecture from general initial conditions and in a robust manner. It also suggests a plausible explanation why some protocols, such as TCP or IP, managed to survive much longer than most other protocols at the same layers. Furthermore, it suggests ways to design more competitive new protocols and more evolvable future Internet architectures. Copyright 2011 ACM.",Evolution; Evolutionary kernels; Future internet; Internet architecture; Layering; Network science,Evolution; Evolutionary kernels; Future internet; Internet architecture; Layering; Network science; Internet; Network layers; Telecommunication networks; Transmission control protocol; Network architecture
"Gollakota S., Hassanieh H., Ransford B., Katabi D., Fu K.",5,They can hear your heartbeats: Non-invasive security for implantable medical devices,2011,188,"Massachusetts Institute of Technology, United States; University of Massachusetts, Amherst, United States",MIT;University of Massachusetts Amherst,2,USA,1,9,6,"Wireless communication has become an intrinsic part of modern implantable medical devices (IMDs). Recent work, however, has demonstrated that wireless connectivity can be exploited to compromise the confidentiality of IMDs' transmitted data or to send unauthorized commands to IMDs-even commands that cause the device to deliver an electric shock to the patient. The key challenge in addressing these attacks stems from the difficulty of modifying or replacing already-implanted IMDs. Thus, in this paper, we explore the feasibility of protecting an implantable device from such attacks without modifying the device itself. We present a physicallayer solution that delegates the security of an IMD to a personal base station called the shield. The shield uses a novel radio design that can act as a jammer-cum-receiver. This design allows it to jam the IMD's messages, preventing others from decoding them while being able to decode them itself. It also allows the shield to jam unauthorized commands-even those that try to alter the shield's own transmissions. We implement our design in a software radio and evaluate it with commercial IMDs. We find that it effectively provides confidentiality for private data and protects the IMD from unauthorized commands. Copyright 2011 ACM.",Full-duplex; Implanted medical devices; Wireless,Electric shock; Full-duplex; Implantable devices; Implantable medical devices; Implanted medical devices; Non-invasive; Private data; Radio design; Software Radio; Wireless communications; Wireless connectivities; Biomedical engineering; Design; Electric accidents; Implants (surgical); Radio; Wireless telecommunication systems; Equipment
"Mehendale H., Paranjpe A., Vempala S.",3,LifeNet: A flexible ad hoc networking solution for transient environments,2011,12,"College of Computing, Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech,1,USA,1,20,16,"We demonstrate a new ad hoc routing method that can handle transience such as node-mobility, obstructions and node failures. It has controlled management overhead, and is platform-independent (our demo includes phones, routers, and laptops running different operating systems). It achieves reliability and exibility at the expense of throughput. It is ideal for scenarios where the reliability of connectivity is crit- ical and bandwidth requirements are low. For e.g., disaster relief operations and sensor networks. Along with applica- tions, we exhibit measurements to illustrate the advantages of our approach in dealing with transience.",MANETs; Minimum infrastructure; Reliable routing,Ad hoc routing; Ad-hoc networking; Bandwidth requirement; Disaster relief operations; MANETs; Minimum infrastructure; Node failure; Reliable routing; Transient environment; Disaster prevention; Laptop computers; Sensor networks
"Salvadori E., Corin R.D., Gerola M., Broglio A., De Pellegrini F.",5,Demonstrating generalized virtual topologies in an OpenFlow network,2011,13,"CREATE-NET, Via alla Cascata 56/D Povo, 38123 Trento, Italy","CREATE-NET, Italy",1,Italy,1,58,41,"Welcome to the 2011 ACM SIGCOMM Conference in Toronto, Canada. It has been our pleasure to oversee the tremendous efforts volunteered by our technical program committee and other individuals in shaping this year's technical program. We hope that you will find the papers selected for the technical program stimulating and thought-provoking, and that you enjoy the conference! SIGCOMM 2011 received 223 submissions, and we accepted 32 papers, for an acceptance ratio of 14%. This represents a modest drop over the number of submissions from previous years. We received submissions from authors in at least 36 countries, and the final program reflects the significant geographical diversity across submissions, with authors representing 12 different countries and 44 distinct institutions. The SIGCOMM 2011 TPC comprised 50 members from academia and industry, reflecting the diversity of our community. The TPC members' research interests span the wide range of topics present in this year's submissions and accepted papers. The members of the TPC wrote at least three first-round reviews for all 223 submissions, as well as three or more second-round reviews for the top 101 papers. Thus, we had at least 6 reviews for each of the 70 papers that we discussed in the TPC meeting. Most second-round papers received significant online discussion between PC members prior to the TPC meeting, and in some cases we solicited additional reviews from external topic experts. In total, the submissions received over 1000 written reviews. Reviewing was double-blind, and was subject to a strict conflict-of-interest policy. PC members with potential conflicts of interest were excluded from all discussions of the relevant papers. Both of the TPC co-chairs were authors of submissions; these reviews were handled entirely outside of the online review system, so as to guarantee reviewer anonymity. Almost all of the TPC members attended the TPC meeting in Boston in person, for 1.5 days of energetic discussion. Those who were not able to attend in person participated via a telephone conference. We strove, as TPC chairs, to ensure that all 70 papers received full and fair discussion, and we encouraged the TPC to consider prioritizing ""appropriately risky"" papers over otherwise comparable ""correct but boring"" papers when there was a choice. Each of the 32 accepted papers was shepherded by a member of the TPC, to help the authors improve their final versions. Copyright 2011 ACM.",Network Virtualization; OpenFlow,"Acceptance ratio; Network virtualization; Online discussions; OpenFlow; Potential conflict; Previous year; Technical programs; Toronto , Canada; Virtual topologies; Paper"
"Lehn M., Leng C., Rehner R., Triebel T., Buchmann A.",5,An online gaming testbed for Peer-to-Peer architectures,2011,8,"Databases and Distributed Systems, Technische UniversitŠt Darmstadt, Germany; Praktische Informatik IV, UniversitŠt Mannheim, Germany",TU Darmstadt;UniversitŠt Mannheim,2,Germany,1,6,4,"In this demo we present a testbed environment for Peerto-Peer (P2P) game architectures. It is based on Planet PI4, an online multiplayer game whose gameplay provides a standard workload for a set of gaming-specific network interfaces. Its pluggable architecture allows for the evaluation and comparison of existing and new P2P networking approaches. Planet PI4 can run on a real network for prototypical evaluation as well as in a discrete-event simulator providing a reproducible environment.",Experimentation; Measurement; Performance,Discrete-event simulators; Experimentation; Game architecture; Gameplay; On-line gaming; Online multiplayer games; P2P networking; Peer to peer; Peer-to-peer architectures; Performance; Pluggable architecture; Real networks; Distributed computer systems; Measurements; Testbeds; Network architecture
"Sun Z., Purohit A., De Wagter P., Brinster I., Hamm C., Zhang P.",6,PANDAA: A physical arrangement detection technique for networked devices through ambient-sound awareness,2011,5,"Department of Electrical and Computer Engineering, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA, United States",Carnegie Mellon University,1,USA,1,4,3,"This demo presents PANDAA, a zero-configuration automatic spatial localization technique for networked devices based on ambient sound sensing. We will demonstrate that after initial placement of the devices, ambient sounds, such as human speech, music, footsteps, finger snaps, hand claps, or coughs and sneezes, can be used to autonomously resolve the spatial relative arrangement of devices, such as mobile phones, using trigonometric bounds and successive approximation.",Arrangement detection; Localization; Networked devices,Detection technique; Human speech; Localization; Networked devices; Spatial localization; Successive approximations; Approximation theory; Global system for mobile communications
"Mortier R., Bedwell B., Glover K., Lodge T., Rodden T., Rotsos C., Moore A.W., Koliousis A., Sventek J.",9,Supporting novel home network management interfaces with openflow and NOX,2011,10,"University of Nottingham, United Kingdom; University of Cambridge, United Kingdom; University of Glasgow, United Kingdom",University of Cambridge;University of Glasgow;University of Nottingham,3,UK,1,10,10,"The Homework project1 has examined redesign of existing home network infrastructures to better support the needs and requirements of actual home users. Integrating results from several ethnographic studies, we have designed and built a home networking platform providing detailed per- ow measurement and management capabilities supporting several novel management interfaces. This demo specifically shows these new visualization and control interfaces (¤1), and describes the broader benefits of taking an integrated view of the networking infrastructure, realised through our router's augmented measurement and control APIs (¤2). Aspects of this work have been published: the Homework Database in Internet Management (IM) 2011 [3] and im- plications of the ethnographic results are to appear at the SIGCOMM W-MUST workshop 2011 [2]. Separate, more detailed expositions of the interface elements and system performance and implications are currently under submis- sion at other venues. A partial code release is already available2 and we anticipate fuller public beta release by Q4 2011.",DHCP; Home networks; Network management; NOX; OpenFlow,Control interfaces; DHCP; Ethnographic study; Home network management; Home Networking; Home networks; Home users; Interface elements; Management interfaces; Measurement and control; Networking infrastructure; NOX; OpenFlow; Carrier communication; Personal communication systems; Visualization; Network management
"Gudipati A., Katti S.",2,Strider: Automatic rate adaptation and collision handling,2011,101,"Stanford University, United States",Stanford University,1,USA,1,4,4,"This paper presents the design, implementation and evaluation of Strider, a system that automatically achieves almost the optimal rate adaptation without incurring any overhead. The key component in Strider is a novel code that has two important properties: it is rate-less and collision-resilient. First, in time-varying wireless channels, Strider's rate-less code allows a sender to effectively achieve almost the optimal bitrate, without knowing how the channel state varies. Second, Strider's collision-resilient code allows a receiver to decode both packets from collisions, and achieves the same throughput as the collision-free scheduler. We show via theoretical analysis that Strider achieves Shannon capacity for Gaussian channels, and our empirical evaluation shows that Strider outperforms SoftRate, a state of the art rate adaptation technique by 70% in mobile scenarios and by upto 2:8_ in contention scenarios. Copyright 2011 ACM.",Algorithms; Design; Performance,Bit rates; Channel state; Collision handling; Empirical evaluations; Gaussian channels; Key component; Mobile scenarios; Optimal rate; Performance; Rate adaptation; Shannon capacity; State of the art; Time-varying wireless channel; Algorithms; Design; Optimization; Telecommunication; Optimal systems
"Wilhelm M., Martinovic I., Schmitt J.B., Lenders V.",4,WiFire: A firewall for wireless networks,2011,18,"Disco Labs, TU Kaiserslautern, Germany; EECS, UC Berkeley, United States; Armasuisse, Switzerland",TU Kaiserslautern;University of California Berkeley,2,Germany;Switzerland;USA,3,3,3,"Firewalls are extremely effective at enforcing security policies in wired networks. Perhaps surprisingly, firewalls are entirely nonexistent in the wireless domain. Yet, the need to selectively control and block radio communication is particularly high in a broadcast environment since any node may receive and send packets. In this demo, we present WiFire, a system that brings the firewall concept to wireless networks. First, WiFire detects and analyzes packets during their transmission, checking their content against a set of rules. It then relies on reactive jamming techniques to selectively block undesired communication. We show the feasibility and performance of WiFire, which is implemented on the USRP2 software-defined radio platform, in several scenarios with IEEE 802.15.4 radios. WiFire is able to classify and effectively block undesired communication without interfering with desired communication.",Design; Experimentation; Security,Broadcast environments; Experimentation; IEEE 802.15.4; Jamming technique; Security; Security policy; Set of rules; Software-defined radios; Wired networks; Broadcasting; Communication; Computer viruses; Design; Standards; Radio communication
"Chen L.-W., Sharma P., Tseng Y.-C.",3,Eco-Sign: A load-based traffic light control system for environmental protection with vehicular communications,2011,4,"Department of Computer Science, National Chiao-Tung University, Hsin-Chu, Taiwan",National Chiao-Tung University,1,Taiwan,1,35,25,"The Eco-Sign system is a traffic light control system for minimizing greenhouse gases emitted by idling vehicles at intersections. Eco-Sign provides the following features: (i) it can notify vehicles to turn on/off their engines based on expected waiting time for green lights at intersections, (ii) it can dynamically adjust traffic light timing to minimize the number of vehicles stopping at an intersection based on vehicle arrival and departure rates, and (iii) it is a fully distributed system in the sense that each intersection can learn its local traffic condition and optimize its traffic sign setting to prevent congestions and thus traffic jams. Eco-Sign thus demonstrates a new traffic light control system for environmental protection.",Dynamic traffic light control; Environmental protection; Ignition control; Vehicular communications,Distributed systems; Dynamic traffic; Green light; Ignition control; Number of vehicles; Traffic conditions; Traffic jams; Traffic light; Traffic light control systems; Vehicular communications; Waiting-time; Control systems; Emergency traffic control; Environmental protection; Greenhouse gases; Ignition; Traffic signs; Vehicles; Traffic congestion
"Liao Q., Shi L., He Y., Li R., Su Z., Striegel A., Liu Y.",7,Visualizing anomalies in sensor networks,2011,4,"University of Notre Dame, United States; IBM Research, China; Hong Kong University of Science and Technology, Hong Kong; Xi'an Jiao Tong University, China; Tsinghua University, Hong Kong",Hong Kong University of Science and Technology;IBM;Tsinghua University;University of Notre Dame; Xian JiaoTong University,5,China;Hong Kong;USA,3,3,3,"Diagnosing a large-scale sensor network is a crucial but challenging task due to the spatiotemporally dynamic network behaviors of sensor nodes. In this demo, we present Sensor Anomaly Visualization Engine (SAVE), an integrated system that tackles the sensor network diagnosis problem using both visualization and anomaly detection analytics to guide the user quickly and accurately diagnose sensor network failures. Temporal expansion model, correlation graphs and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a real-world large-scale wireless sensor network deployment (GreenOrbs), we demonstrate that SAVE is able to help better locate the problem and further identify the root cause of major sensor network failures.",Anomaly detection and analysis; Diagnosing; Visualization; Wireless sensor networks,Anomaly detection; Diagnose sensors; Diagnosing; Dynamic network; Dynamic projection; Integrated systems; Large scale sensor network; Large-scale wireless sensor networks; Network diagnosis; Network failure; Root cause; Sensor data; Visualization engine; Wireless sensor; Data visualization; Flow visualization; Topology; Visualization; Sensor nodes
"Sharafat A.R., Das S., Parulkar G., McKeown N.",4,MPLS-TE and MPLS VPNs with OpenFlow,2011,57,"Department of Electrical Engineering, Stanford University, Stanford, CA 94305, United States",Stanford University,1,USA,1,8,5,"We demonstrate MPLS Traffic Engineering (MPLS-TE) and MPLS-based Virtual Private Networks (MPLS VPNs) using OpenFlow [1] and NOX [6]. The demonstration is the outcome of an engineering experiment to answer the following questions: How hard is it to implement a complex control plane on top of a network controller such as NOX? Does the global vantage point in NOX make the implementation easier than the traditional method of implementing it on every switch, embedded in the data plane? We implemented every major feature of MPLS-TE and MPLSVPN in just 2,000 lines of code, compared to much larger lines of code in the more traditional approach, such as Quagga-MPLS. Because NOX maintains a consistent, up-to-date topology map, the MPLS control plane features are quite simple to implement. And its simplicity makes it easy to extend: We have easily added several new features; something a network operator could do to customize their network to meet their customers' needs. The demo consists of two parts: MPLS-TE services and then MPLS VPN driven by a GUI.",MPLS; MPLS-TE; OpenFlow; Traffic Engineering; VPN,MPLS; MPLS-TE; OpenFlow; Traffic Engineering; VPN; Telecommunication networks; Highway engineering
"Kim H., Sundaresan S., Chetty M., Feamster N., Edwards W.K.",5,Communicating with caps: Managing usage caps in home networks,2011,18,"Georgia Tech., United States",Georgia Tech,1,USA,1,2,2,"As Internet service providers increasingly implement and impose ""usage caps"", consumers need better ways to help them understand and control how devices in the home use up the available network resources or available capacity. Towards this goal, we will demonstrate a system that allows users to monitor and manage their usage caps. The system uses the BISMark firmware running on network gateways to collect usage statistics and report them to a logically centralized controller, which displays usage information. The controller allows users to specify policies about how different people, devices, and applications should consume the usage cap; it implements and enforces these policies via a secure OpenFlow control channel to each gateway device. The demonstration will show various use cases, such as limiting the usage of a particular application, visualizing usage statistics, and allowing users within a single household to ""trade"" caps with one another.",Home network; OpenFlow; Usage cap,Available capacity; Control channels; Gateway devices; Home networks; Home use; Network resource; OpenFlow; System use; Usage cap; Usage statistics; Carrier communication; Controllers; Display devices; Firmware; Internet service providers; Personal communication systems; Gateways (computer networks)
"Zohar E., Cidon I., Mokryn O.",3,The power of prediction: Cloud bandwidth and cost reduction,2011,36,"Technion, Israel Institute of Technology, Israel; Tel Aviv Academic College, Israel; HPI Research School, Israel",HPI Research School;Technion - Israel Institute of Technology;Tel Aviv Academic College,3,Israel,1,7,4,"In this paper we present PACK (Predictive ACKs), a novel end-toend Traffic Redundancy Elimination (TRE) system, designed for cloud computing customers. Cloud-based TRE needs to apply a judicious use of cloud resources so that the bandwidth cost reduction combined with the additional cost of TRE computation and storage would be optimized. PACK's main advantage is its capability of offloading the cloud-server TRE effort to end-clients, thus minimizing the processing costs induced by the TRE algorithm. Unlike previous solutions, PACK does not require the server to continuously maintain clients' status. This makes PACK very suitable for pervasive computation environments that combine client mobility and server migration to maintain cloud elasticity. PACK is based on a novel TRE technique, which allows the client to use newly received chunks to identify previously received chunk chains, which in turn can be used as reliable predictors to future transmitted chunks. We present a fully functional PACK implementation, transparent to all TCP-based applications and network devices. Finally, we analyze PACK benefits for cloud users, using traffic traces from various sources. Copyright 2011 ACM.",Caching; Cloud computing; Network optimization; Traffic redundancy elimination,Additional costs; Caching; Network devices; Network optimization; Processing costs; Redundancy elimination; Server migration; Traffic traces; Bandwidth; Cost reduction; Elasticity; Optimization; Redundancy; Cloud computing
"May M., Diot C., Le Guyadec P., Picconi F., Roussel J., Soule A.",6,Service hosting gateways - A platform for distributed service deployment in end user homes,2011,3,"Technicolor, Paris Research Lab., 1 Rue Jeanne d'Arc, 92443 Issy-les-Moulineaux, France","Thomson,France",1,France,1,6,5,"The success of broadband residential Internet access is changing the way home users consume digital content and services. Currently, each home service requires the installation of a separate physical box (for instance, the NetFlix box or IPTV set-top-boxes). Instead, we argue for deploying a single box in the home that is powerful and flexible enough to host a variety of home services. In addition, this box is managed by the Internet Service provider and is able to provide service guarantees. We call such a box a servicehosting gateway (SHG), as it combines the functionalities of the home gateway managed by the network service provider with the capability of hosting services. Isolation between such services is ensured by virtualization. We demonstrate a prototype of our (SHG). It is based on the hardware platform that will be used for future home gateways. We illustrate the features of the SHG with multiple use cases ranging from simple service deployment scenarios to complex media distribution services and home automation features.",Experimentation,Complex media; Digital contents; Distributed service; End users; Experimentation; Hardware platform; Home automation; Home gateway; Home services; Home users; Internet access; Multiple use-cases; Network service providers; Service deployment; Service guarantees; Service hosting; Set top box; Virtualizations; Internet service providers; IPTV; Telecommunication networks; Telecommunication services; Gateways (computer networks)
"Konte M., Feamster N.",2,Wide-area routing dynamics of malicious networks,2011,1,"Georgia Tech, United States",Georgia Tech,1,USA,1,25,12,"This paper studies the routing dynamics of malicious networks. We characterize the routing behavior of malicious networks on both short and long timescales. We find that malicious networks more consistently advertise prefixes with short durations and long interarrival times; over longer timescales, we find that malicious ASes connect with more upstream providers than legitimate ASes, and they also change upstream providers more frequently.",BGP; Hostexploit; Malicious networks; Routing dynamics; Security,BGP; Hostexploit; Inter-arrival time; Routing dynamics; Security; Short durations; Time-scales; Wide area; Dynamics; Network routing
"Rahman R., Vink— T., Hales D., Pouwelse J., Sips H.",5,Design Space Analysis for modeling incentives in distributed systems,2011,25,"Delft University of Technology, Delft, Netherlands; Open University, Milton Keynes, United Kingdom",TU Delft;Open University,2,Netherlands;UK,2,8,5,"Distributed systems without a central authority, such as peer-to-peer (P2P) systems, employ incentives to encourage nodes to follow the prescribed protocol. Game-theoretic analysis is often used to evaluate incentives in such systems. However, most game-theoretic analyses of distributed systems do not adequately model the repeated interactions of nodes inherent in such systems. We present a game-theoretic analysis of a popular P2P protocol, Bit-Torrent, that models the repeated interactions in such protocols. We also note that an analytical approach for modeling incentives is often infeasible given the complicated nature of most deployed protocols. In order to comprehensively model incentives in complex protocols, we propose a simulation-based method, which we call Design Space Analysis (DSA). DSA provides a tractable analysis of competing protocol variants within a detailed design space. We apply DSA to P2P file swarming systems. With extensive simulations we analyze a wide-range of protocol variants and gain insights into their robustness and performance. To validate these results and to demonstrate the efficacy of DSA, we modify an instrumented BitTorrent client and evaluate protocols discovered using DSA. We show that they yield higher system performance and robustness relative to the reference implementation. Copyright 2011 ACM.",Design space analysis; Game theory; Incentive systems; Robustness,Analytical approach; BitTorrent; Complex protocols; Design spaces; Detailed design; Distributed systems; Extensive simulations; Gain insight; Incentive systems; P2P protocols; Peer-to-Peer system; Reference implementation; Simulation-based method; Tractable analysis; Computer simulation; Design; Distributed computer systems; Game theory; Robustness (control systems); Peer to peer networks
"Saucez D., Bonaventure O.",2,Performance based traffic control with IDIPS,2011,1,"UniversitŽ Catholique de Louvaint, ICTEAM, 2 Place Sainte-Barbe, B-1348 Louvain-la-Neuve, Belgium",Universite Catholique de Louvain,1,Belgium,1,5,4,"Nowadays Internet is ubiquitous resulting in an increasing path diversity and content duplication. However, while content can be retrieved from many different places, the paths to those places are not equivalent. Indeed, some paths offer better bandwidth while others are less expensive or more stable. In addition, a new range of applications is sensitive to the performance of the paths that carry their traffic. To support this evolution of the Internet, we propose ISPDriven Informed Path Selection (IDIPS). Any ISP can easily deploy IDIPS to help its customers to select the paths that best meet their requirements in order to reach their content. IDIPS helps in this selection through pro-active measurements and ISP-defined policies. IDIPS is scalable and can support thousands of clients. IDIPS is also flexible and can thus be used by the ISP to optimize its routing decisions to take the performance of its inter-domain links into account.",Route control; Traffic engineering; XORP,Increasing paths; Inter-domain; Path selection; Performance based; Route control; Routing decisions; Traffic engineering; XORP; Telecommunication networks; Internet service providers
"Laoutaris N., Sirivianos M., Yang X., Rodriguez P.",4,Inter-datacenter bulk transfers with NetStitcher,2011,139,"Telefonica Research, Barcelona, Spain",Telefonica Research,1,Spain,1,32,29,"Large datacenter operators with sites at multiple locations dimension their key resources according to the peak demand of the geographic area that each site covers. The demand of specific areas follows strong diurnal patterns with high peak to valley ratios that result in poor average utilization across a day. In this paper, we show how to rescue unutilized bandwidth across multiple datacenters and backbone networks and use it for non-real-time applications, such as backups, propagation of bulky updates, and migration of data. Achieving the above is non-trivial since leftover band-width appears at different times, for different durations, and at different places in the world. To this end, we have designed, implemented, and validated NetStitcher, a system that employs a network of storage nodes to stitch together unutilized bandwidth, whenever and wherever it exists. It gathers information about leftover resources, uses a store-and-forward algorithm to schedule data transfers, and adapts to resource fluctuations. We have compared NetStitcher with other bulk transfer mechanisms using both a testbed and a live deployment on a real CDN. Our testbed evaluation shows that Net-Stitcher outperforms all other mechanisms and can rescue up to five times additional datacenter bandwidth thus making it a valuable tool for datacenter providers. Our live CDN deployment demonstrates that our solution can perform large data transfers at a substantially lower cost than naive end-to-end or store-and-forward schemes. Copyright 2011 ACM.",Bulk transfers; Inter-datacenter traffic; Store-and-forward,Back-bone network; Bulk transfer; Data centers; Diurnal pattern; Geographic areas; Lower cost; Non-trivial; Peak demand; Peak-to-valley ratios; Specific areas; Storage nodes; Store and forward; Data transfer; Scheduling algorithms; Testbeds; Bandwidth
"Chen M.-H., Yang C.-Y., Chang C.-Y., Hsu M.-Y., Lee K.-H., Chou C.-F.",6,Towards energy-efficient streaming system for mobile hotspots,2011,8,"National Taiwan University, Taiwan",National Taiwan University,1,Taiwan,1,8,6,"Modern mobile devices have become an important part of our daily life but the performance of multimedia applications still suffers from the constrained energy supply and commu- nication bandwidth of the mobile devices. In this work, we develop an energy-efficient streaming system for mobile hotspots to achieve better Quality-of-Experience. Our main idea is (a) to avoid redundant 3G transmissions as well as reduce the usage of 3G links for those low residual-energy users, and (b) to enable nearby mobile users cooperatively to share the downloaded data via short-range interfaces. The experiment results shows our scheme can improve the system lifetime by 27%, and provide better throughput as well as lower loss rate than conversional 3G systems do.",Composite networks; Cooperative networks; Energy efficiency; Mobile hotspots; Streaming; Wireless networks,3G links; 3G systems; Constrained energy; Cooperative networks; Daily lives; Energy efficient; Loss rates; Mobile hotspots; Mobile users; Multimedia applications; Acoustic streaming; Global system for mobile communications; Mobile devices; Wireless networks; Wireless sensor networks; Energy efficiency
"Shah Newaz S.H., Choi J.K., Cuevas A., Lee G.M., Crespi N.",5,A novel approach for making energy efficient PON,2011,0,"Dept. of Electrical Engineering (EE), Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Dept. of Wireless Networks and Multimedia Services, Institut Telecom, Telecom SudParis, Evry, France",KAIST,1,France;South Korea,2,37,7,"Nowadays Passive Optical Network (PON) requires that Optical Network Units (ONUs) wake up periodically to check if the Optical Line Terminal (OLT) has any message directed to them.This implies that ONUs change from sleeping mode in which theyjust consume 1 W to active mode in which the consumption goes up to 10 W. In many cases, the OLT does not have any packets for the ONU and it goes to sleep again, what supposes a waste of energy. In this paper, we propose a novel Hybrid ONU that relies on a low-cost and low-energy technology, IEEE 802.15.4, to wake up those ONUs that are going to receive a packet. Our first estimations demonstrates that our solution would save around 25000$ per year and OLT.",Converged; Energy saving; PON; Sleep mode,Active mode; Converged; Energy efficient; IEEE 802.15.4; Low energies; Optical line terminals; Optical network units; Passive optical network; PON; SLEEP mode; Energy conservation; Energy conversion; Energy efficiency; Fiber optic networks; Sleep research; Standards; Wakes; Passive networks
"Sundaresan S., De Donato W., Feamster N., Teixeira R., Crawford S., Pescap A.",6,Broadband Internet performance: A view from the gateway,2011,186,"Georgia Tech., Atlanta, United States; University of Napoli Federico II, Napoli, Italy; CNRS, UPMC Sorbonne Univ., Paris, France; SamKnows, London, United Kingdom",Georgia Tech;University of Napoli Federico II,2,France;Italy;UK;USA,4,3,2,"We present the first study of network access link performance measured directly from home gateway devices. Policymakers, ISPs, and users are increasingly interested in studying the performance of Internet access links. Because of many confounding factors in a home network or on end hosts, however, thoroughly understanding access network performance requires deploying measurement infrastructure in users' homes as gateway devices. In conjunction with the Federal Communication Commission's study of broadband Internet access in the United States, we study the throughput and latency of network access links using longitudinal measurements from nearly 4,000 gateway devices across 8 ISPs from a deployment of over 4,200 devices. We study the performance users achieve and how various factors ranging from the user's choice of modem to the ISP's traffic shaping policies can affect performance. Our study yields many important findings about the characteristics of existing access networks. Our findings also provide insights into the ways that access network performance should be measured and presented to users, which can help inform ongoing broader efforts to benchmark the performance of access networks. Copyright 2011 ACM.",Access networks; Benchmarking; BISMark; Broadband networks,Access network; BISMark; Broadband Internet; Broadband internet access; Federal Communication Commission; Gateway devices; Home gateway; Home networks; Internet access; Network access; Policy makers; Traffic-shaping; Benchmarking; Broadband networks; Internet service providers; Network performance; Personal communication systems; Telecommunication networks; Wireless telecommunication systems; Gateways (computer networks)
"Erickson D., Heller B., Yang S., Chu J., Ellithorpe J., McKeown N., Parulkar G., Rosenblum M., Whyte S., Stuart S.",10,Optimizing a virtualized data center,2011,10,"Stanford University, United States; Google, United States",Google;Stanford University,2,USA,1,3,3,"Many data centers extensively use virtual machines (VMs), which provide the flexibility to move workload among physi- cal servers. VMs can be placed to maximize application per- formance, power efficiency, or even fault tolerance. However, VMs are typically repositioned without considering network topology, congestion, or traffic routes. In this demo, we show a system, Virtue, which enables the comparison of different algorithms for VM placement and network routing at the scale of an entire data center. Our goal is to understand how placement and routing affect over- all application performance by varying the types and mix of workloads, network topologies, and compute resources; these parameters will be available for demo attendees to explore.",Data center network; OpenFlow; Virtualization; Virtue,Application performance; Compute resources; Data centers; Network topology; OpenFlow; Placement and routing; Power efficiency; Traffic routes; Virtual machines; Virtualizations; Virtue; Electric network topology; Fault tolerance; Satellite communication systems; Topology; Network routing
"Shvartzshnaider Y., Ott M.",2,Poster: Towards a fully distributed n-tuple store,2011,1,"NICTA, University of Sydney, Sydney, Australia",NICTA;University of Sydney,2,Australia,1,36,25,"We present our work towards building a novel distributed ntuple store by extending the Kademlia DHT [1] algorithm to support n dimensional keys as well as an multi get operator, where some of the dimensions of the ""query"" key can be left unspecified.",Distributed pattern matching; Kademlia,Distributed patterns; Kademlia; Pattern matching
Chasaki D.,1,"""roto-rooting"" your router: Solution against new potential DoS attacks on modern routers",2011,0,"Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA, United States",University of Massachusetts Amherst,1,USA,1,9,9,"Our work presents the first practical example of an entirely new class of network attacks - attacks that target the network infrastructure. Modern routers use general purpose programmable processors, and the software used for packet processing on these systems is potentially vulnerable to remote exploits. We describe a specific attack that can launch a devastating denial-of-service attack by sending just a single packet. We also show that there are effective defense techniques, based on processor monitoring, that can help in detecting and avoiding such attacks.",Design; Performance; Security,Defense techniques; Denial of service attacks; DoS attacks; General purpose; Network attack; Network infrastructure; Packet processing; Performance; Programmable processors; Security; Design; Routers; Computer crime
"Li Q., Zhou W., Caesar M., Godfrey B.",4,ASAP: A low-latency transport layer,2011,3,"Dept. of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, United States",UIUC,1,USA,1,3,3,"For interactive networked applications like web browsing, every round-trip time (RTT) matters. We introduce ASAP, a new naming and transport protocol that reduces latency by shortcutting DNS requests and eliminating TCP's three-way handshake, while ensuring the key security property of verifiable provenance of client requests. ASAP eliminates between one and two RTTs, cutting the delay of small requests by up to two-thirds.",DNS; Latency; TCP,Client request; DNS; Latency; Low-latency; Networked applications; Round-trip-time; Security properties; TCP; Three-way handshake; Transport layers; Transport protocols; Web browsing; User interfaces; Transmission control protocol
"Rizzo L., Landi M.",2,Netmap: Memory mapped access to network devices,2011,13,"Universitˆ di Pisa, Italy",Universitˆ di Pisa,1,Italy,1,3,3,"Recent papers have shown that wire-speed packet processing is feasible in software even at 10 Gbit/s, but the result has been achieved taking direct control of the network controllers to cut down OS and device driver overheads. In this paper we show how to achieve similar performance in safer conditions on standard operating systems. As in some other proposals, our framework, called netmap, maps packet buffers into the process' memory space; but unlike other proposals, any operation that may affect the state of the hardware is filtered by the OS. This protects the system from crashes induced by misbehaving programs, and simplifies the use of the API. Our tests show that netmap takes less than 90 clock cycles to move one packet between the wire and the application, almost one order of magnitude less than using the standard OS path. One core at 1.33 GHz can send or receive packets at wire speed on 10 Gbit/s links (14.88 Mpps), with very good scalability in the number of cores and clock speed. At least three factors contribute to this performance: A i) no overhead for encapsulation and metadata management; ii) no per-packet system calls and data copying; iii) much simpler device driver operation, because buffers have a plain and simple format that requires no run-time decisions.",Operating systems; Software packet processing,10-Gbit/s; Clock cycles; Clock speed; Data copying; Device Driver; Direct control; Memory space; Metadata management; Network devices; Packet buffers; Packet processing; Runtimes; System calls; Computer operating systems; Metadata; Packet networks; Wire
"Wang Z., Qian Z., Xu Q., Mao Z.M., Zhang M.",5,An untold story of middleboxes in cellular networks,2011,113,"University of Michigan, United States; Microsoft Research, United States",Microsoft;University of Michigan at Ann Arbor,2,USA,1,6,3,"The use of cellular data networks is increasingly popular as network coverage becomes more ubiquitous and many diverse usercontributed mobile applications become available. The growing cellular traffic demand means that cellular network carriers are facing greater challenges to provide users with good network performance and energy efficiency, while protecting networks from potential attacks. To better utilize their limited network resources while securing the network and protecting client devices the carriers have already deployed various network policies that influence traffic behavior. Today, these policies are mostly opaque, though they directly impact application designs and may even introduce network vulnerabilities. We present NetPiculet, the first tool that unveils carriers' NAT and firewall policies by conducting intelligent measurement. By running NetPiculet on the major U.S. cellular providers as well as deploying it as a smartphone application in the wild covering more than 100 cellular ISPs, we identified the key NAT and firewall policies which have direct implications on performance, energy, and security. For example, NAT boxes and firewalls set timeouts for idle TCP connections, which sometimes cause significant energy waste on mobile devices. Although most carriers today deploy sophisticated firewalls, they are still vulnerable to various attacks such as battery draining and denial of service. These findings can inform developers in optimizing the interaction between mobile applications and cellular networks and also guide carriers in improving their network configurations. Copyright 2011 ACM.",Cellular data network; Firewall; Middlebox; NAT; TCP performance,Cellular data networks; Firewall; Middleboxes; NAT; TCP performance; Energy conversion; Energy efficiency; Internet service providers; Mobile devices; Network performance; Cellular neural networks
"Wilson C., Ballani H., Karagiannis T., Rowstron A.",4,Better never than late: Meeting deadlines in datacenter networks,2011,367,"Microsoft Research, Cambridge, United Kingdom",Microsoft,1,UK,1,4,3,"The soft real-time nature of large scale web applications in today's datacenters, combined with their distributed work-flow, leads to deadlines being associated with the datacenter application traffic. A network flow is useful, and contributes to application throughput and operator revenue if, and only if, it completes within its deadline. Today's transport protocols (TCP included), given their Internet origins, are agnostic to such flow deadlines. Instead, they strive to share network resources fairly. We show that this can hurt application performance. Motivated by these observations, and other (previously known) deficiencies of TCP in the datacenter environment, this paper presents the design and implementation of D3, a deadline-aware control protocol that is customized for the datacenter environment. D3 uses explicit rate control to apportion bandwidth according to flow deadlines. Evaluation from a 19-node, two-tier datacenter testbed shows that D3, even without any deadline information, easily outperforms TCP in terms of short flow latency and burst tolerance. Further, by utilizing deadline information, D3 effectively doubles the peak load that the datacenter network can support. Copyright 2011 ACM.",Datacenter; Deadline; Online services; Rate control; SLA,Datacenter; Deadline; On-line service; Rate controls; SLA; User interfaces; Transmission control protocol
"Peterson R.S., Wong B., Sirer E.G.",3,A Content Propagation Metric for efficient content distribution,2011,10,"Cornell University and United Networks, L.L.C., Dept. of Computer Science, Ithaca, NY, United States",Cornell University,1,USA,1,36,27,"Efficient content distribution in large networks comprising datacenters, end hosts, and distributed in-network caches is a difficult problem. Existing systems rely on mechanisms and metrics that fail to effectively utilize all available sources of bandwidth in the network. This paper presents a novel metric, called the Content Propagation Metric (CPM), for quantitatively evaluating the marginal benefit of available bandwidth to competing consumers, enabling efficient utilization of the bandwidth resource. The metric is simple to implement, imposes only a modest overhead, and can be retrofitted easily into existing content distribution systems. We have designed and implemented a high-performance content distribution system, called V-Formation, based on the CPM. The CPM guides V-Formation toward a global allocation of bandwidth that maximizes the aggregate download bandwidth of consumers. Results from a PlanetLab deployment and extensive simulations show that V-Formation achieves high aggregate bandwidth and that the CPM enables hosts to converge quickly on a stable allocation of resources in a wide range of deployment scenarios. Copyright 2011 ACM.",Content distribution; Hybrid; Peer-to-peer,Available bandwidth; Bandwidth resource; Content distribution; Content distribution systems; Data centers; Deployment scenarios; Existing systems; Extensive simulations; Hybrid; Large networks; Marginal benefit; Peer to peer; PlanetLab; Electrostatic discharge; Local area networks; Bandwidth
"Ballani H., Costa P., Karagiannis T., Rowstron A.",4,Towards predictable datacenter networks,2011,471,"Microsoft Research, Cambridge, United Kingdom; Imperial College, London, United Kingdom",Imperial College London;Microsoft,2,UK,1,26,23,"The shared nature of the network in today's multi-tenant datacenters implies that network performance for tenants can vary significantly. This applies to both production datacenters and cloud environments. Network performance variability hurts application performance which makes tenant costs unpredictable and causes provider revenue loss. Motivated by these factors, this paper makes the case for extending the tenant-provider interface to explicitly account for the network. We argue this can be achieved by providing tenants with a virtual network connecting their compute instances. To this effect, the key contribution of this paper is the design of virtual network abstractions that capture the trade-off between the performance guarantees offered to tenants, their costs and the provider revenue. To illustrate the feasibility of virtual networks, we develop Oktopus, a system that implements the proposed abstractions. Using realistic, large-scale simulations and an Oktopus deployment on a 25-node two-tier testbed, we demonstrate that the use of virtual networks yields significantly better and more predictable tenant performance. Further, using a simple pricing model, we find that the our abstractions can reduce tenant costs by up to 74% while maintaining provider revenue neutrality. Copyright 2011 ACM.",Allocation; Bandwidth; Datacenter; Virtual network,Allocation; Application performance; Data centers; Datacenter; Large scale simulations; Multi tenants; Performance guarantees; Performance variability; Pricing models; Virtual networks; Abstracting; Bandwidth; Commerce; Costs; Economics; Network performance; Computer simulation
"Puype B., Papadimitriou D., Das G., Colle D., Pickavet M., Demeester P.",6,OSPF failure reconvergence through SRG inference and prediction of link state advertisements,2011,0,"Dept. of Information Technology (IBCN), Ghent University, IBBT, Ghent, Belgium; Alcatel-Lucent Bell, Antwerp, Belgium",Bell Labs;Ghent University,2,Belgium,1,39,24,"We demonstrate machine learning augmented Open Shortest Path First (OSPF) routing which infers Shared Risk Groups (SRG) from link failure history. For an initial link failure matching an SRG, it predicts subsequent link state advertisements corresponding with that SRG, improving convergence and recovery times during multiple network failures.",Cognitive routing; Machine learning; Network recovery; OSPF; Shared risk group,Cognitive routing; Link failures; Link State Advertisement; Multiple networks; Open shortest path first; OSPF; Reconvergence; Recovery time; Shared risk group; Shared risk groups; Computer system recovery; Learning systems; Telecommunication networks; Internet protocols
"Rabl T., Stegmaier F., Dšller M., Vang T.T.",4,A protocol for disaster data evacuation,2011,1,"Department of Distributed Information Systems, University of Passau Passau, Germany",University of Passau,1,Germany,1,38,37,"Data is the basis of the modern information society. However, recent natural catastrophes have shown that it is not possible to definitively secure a data storage location. Even if the storage location is not destroyed itself the access may quickly become impossible, due to the breakdown of connections or power supply. However, this rarely happens without any warning. While oods have hours or days of warning time, tsunamis usually leave only minutes for reaction and for earthquakes there are only seconds. In such situations, timely evacuation of important data is the key challenge. Consequently, the focus lies on minimizing the time to move away all data from the storage location whereas the actual time to arrival remains less (but still) important. This demonstration presents the dynamic fast send protocol (DFSP), a new bulk data transfer protocol. It employs striping to dynamic intermediate nodes in order to minimize sending time and to utilize the sender's resources to a high extent.",Reliability; Security,Bulk data transfer; Data storage; Information society; Intermediate node; Power supply; Security; Storage location; Warning time; Reliability; Data transfer
"Van Der Linden S., Detal G., Bonaventure O.",3,Revisiting next-hop selection in multipath networks,2011,1,"ICTEAM Institute, UniversitŽ Catholique de Louvain, Louvain-la-Neuve, Belgium",ICTEAM Institute;Universite Catholique de Louvain,2,Belgium,1,6,3,"Multipath routing strategies such as Equal-Cost MultiPath (ECMP) are widely used in IP and data-center networks. Most current methods to balance packets over the multiple next hops toward the destination base their decision on a hash computed over selected fields of the packet headers. Because of the non-invertible nature of hash functions, it is hard to determine the values of those fields so as to make the packet follow a specific path in the network. However, several applications might benefit from being able to choose such a path. Therefore, we propose a novel next-hop selection method based on an invertible function. By encoding the selection of successive routers into common fields of packet headers, the proposed method enables end hosts to force their packets to follow a specific path.",Load balancing; Multipath; Path selection,Multi path routing; Multi-path; Next-hop; Next-hop selection; Packet header; Path selection; Resource allocation; Hash functions
"Wu F.-J., Chu F.-I., Tseng Y.-C.",3,Cyber-physical handshake,2011,13,"Department of Computer Science, National Chiao Tung University, Hsin-Chu, Taiwan",National Chiao-Tung University,1,Taiwan,1,2,2,"While sensor-enabled devices have greatly enriched human interactions in our daily life, discovering the essential knowledge behind sensing data is a critical issue to connect the cyber world and the physical world. This motivates us to design an innovative sensor-aided social network system, termed cyber-physical handshake. It allows two users to naturally exchange personal information with each other after detecting and authenticating the handshaking patterns between them. This work describes our design of detection and authentication mechanisms to achieve this purpose and our prototype system to facilitate handshake social behavior.",Cyber-physical system; Participatory sensing; Pervasive computing; Social network; Wireless sensor network,Authentication mechanisms; Critical issues; Cyber-physical systems; Daily lives; Human interactions; Participatory sensing; Personal information; Physical world; Prototype system; Sensing data; Social behavior; Social network systems; Social Networks; Wireless sensor; Embedded systems; Ubiquitous computing
"Son S., Kang A.R., Kim H.-C., Kwon T.T., Park J., Kim H.K.",6,Multi-relational social networks in a large-scale MMORPG,2011,4,"Seoul National University, South Korea; Korea University, South Korea; Kyunghee University, South Korea",Korea University;Kyunghee University;Seoul National University,3,South Korea,1,4,3,"We analyze multi-relational social interaction networks in a large-scale commercial Massively Multiplayer Online Role- Playing Game (MMORPG). Our work is based on data from AION, currently the world's second most-played MMORPG with 3.4 million subscribers as of mid 2010, created and serviced by NCSoft, Inc. We construct and characterize six distinct interactivity networks (Friend, Private Messaging, Party invitation, Trade, Mail, and Shop), each representing diverse player interaction types.",Massively multiplayer online game; Quantitative social science; Social network analysis,Interactivity; Massively multi-player online games; Massively multiplayer; Social interactions; Social Network Analysis; Social Networks; Internet; Social sciences; Social networking (online)
"Cunha I., Teixeira R., Veitch D., Diot C.",4,Predicting and tracking Internet path changes,2011,22,"Technicolor, Brazil; UPMC Sorbonne UniversitŽs, France; CNRS, France; Dept. of Electrical and Electronic Eng., University of Melbourne, Australia",University of Melbourne;UPMC Sorbonne UniversitŽ,2,Australia;Brazil;France,3,8,4,"This paper investigates to what extent it is possible to use trace-route-style probing for accurately tracking Internet path changes. When the number of paths is large, the usual traceroute based approach misses many path changes because it probes all paths equally. Based on empirical observations, we argue that monitors can optimize probing according to the likelihood of path changes. We design a simple predictor of path changes using a nearest-neighbor model. Although predicting path changes is not very accurate, we show that it can be used to improve probe targeting. Our path tracking method, called DTRACK, detects up to two times more path changes than traditional probing, with lower detection delay, as well as providing complete load-balancer information. Copyright 2011 ACM.",Path changes; Prediction; Topology mapping; Tracking,Internet paths; Nearest-neighbors; Path changes; Path tracking; Topology mapping; Traceroute; Internet; Probes; Surface discharges; Telecommunication networks; Forecasting
"Chowdhury M., Zaharia M., Ma J., Jordan M.I., Stoica I.",5,Managing data transfers in computer clusters with orchestra,2011,310,"University of California, Berkeley, United States",University of California Berkeley,1,USA,1,5,4,"Cluster computing applications like MapReduce and Dryad transfer massive amounts of data between their computation stages. These transfers can have a significant impact on job performance, accounting for more than 50% of job completion times. Despite this impact, there has been relatively little work on optimizing the performance of these data transfers. In this paper, we propose a global management architecture and a set of algorithms that improve the transfer times of common communication patterns, such as broadcast and shuffle, and allow one to prioritize a transfer over other transfers belonging to the same application or to different ones. Using a prototype implementation, we show that our solution improves broadcast completion times by up to 4.5_ compared to the status quo in Hadoop. We also show that transfer-level scheduling can reduce the completion time of high-priority transfers by 1.7_. Copyright 2011 ACM.",Data transfer; Data-intensive applications; Datacenter networks,Communication pattern; Completion time; Computer clusters; Computing applications; Data-intensive application; Global management; Job completion; Job performance; Map-reduce; Prototype implementations; Significant impacts; Transfer time; Cluster computing; Data transfer
"Gill P., Jain N., Nagappan N.",3,"Understanding network failures in data centers: Measurement, analysis, and implications",2011,340,"University of Toronto, Canada; Microsoft Research, United States",Microsoft;University of Toronto,2,Canada;USA,2,34,29,"We present the first large-scale analysis of failures in a data center network. Through our analysis, we seek to answer several fundamental questions: which devices/links are most unreliable, what causes failures, how do failures impact network traffic and how effective is network redundancy? We answer these questions using multiple data sources commonly collected by network operators. The key findings of our study are that (1) data center networks show high reliability, (2) commodity switches such as ToRs and AggS are highly reliable, (3) load balancers dominate in terms of failure occurrences with many short-lived software related faults, (4) failures have potential to cause loss of many small packets such as keep alive messages and ACKs, and (5) network redundancy is only 40% effective in reducing the median impact of failure. Copyright 2011 ACM.",Data centers; Network reliability,Data centers; High reliability; Keep-alive; Large-scale analysis; Load balancer; Multiple data sources; Network failure; Network operator; Network redundancy; Network reliability; Network traffic; Reliability analysis; Satellite communication systems; Software reliability; Redundancy
"Kristiansen S., Plagemann T., Goebel V.",3,Towards scalable and realistic node models for network simulators,2011,4,"Department of Informatics, University of Oslo, GaustadallŽen 23 D, N-0373, Oslo, Norway",University of Oslo,1,Norway,1,45,33,"Network simulators typically do not include node models. Our studies show that in networks such as mobile networks, the impact of nodes on performance can be significant. Existing techniques to simulate nodes' are not scalable for network simulations, and require a too large modelling effort to be feasible for network research. In this paper, we propose to capture flexible perprotocol performance profiles from real, running systems using instrumentation and traffic benchmarking techniques. By using the obtained profiles as input into an extended scheduler simulator, the behaviour of the node can be accurately reproduced. Since the processing overhead is represented statistically, we preserve scalability and a low modelling overhead.",Experimentation; Measurement; Performance,Benchmarking techniques; Experimentation; Network simulation; Network simulators; Node model; Performance; Performance profile; Processing overhead; Running systems; Measurements; Simulators
"Mudigonda J., Stiekes B., Yalagandula P., Mogul J., Pouffary Y.",5,NetLord: A scalable multi-tenant network architecture for virtualized datacenters,2011,93,"HP Labs, Palo Alto, CA, United States; HP, United States",HP Labs,1,USA,1,28,26,"Providers of ""Infrastructure-as-a-Service"" need datacenter networks that support multi-tenancy, scale, and ease of operation, at low cost. Most existing network architectures cannot meet all of these needs simultaneously. In this paper we present NetLord, a novel multi-tenant network architecture. NetLord provides tenants with simple and flexible network abstractions, by fully and efficiently virtualizing the address space at both L2 and L3. NetLord can exploit inexpensive commodity equipment to scale the network to several thousands of tenants and millions of virtual machines. NetLord requires only a small amount of offline, one-time configuration. We implemented NetLord on a testbed, and demonstrated its scalability, while achieving order-of-magnitude goodput improvements over previous approaches. Copyright 2011 ACM.",Datacenter network; Multi-pathing; Multi-tenant; Network virtualization; Scalable ethernet,Address space; Data centers; Flexible networks; Good put; Low costs; Multi tenants; Multi-pathing; Network virtualization; Offline; Virtual machines; Network architecture
"Halperin D., Kandula S., Padhye J., Bahl P., Wetherall D.",5,Augmenting data center networks with multi-gigabit wireless links,2011,197,"Microsoft Research, United States; University of Washington, United States",Microsoft;University of Washington at Seattle,2,USA,1,4,4,"The 60 GHz wireless technology that is now emerging has the potential to provide dense and extremely fast connectivity at low cost. In this paper, we explore its use to relieve hotspots in oversubscribed data center (DC) networks. By experimenting with prototype equipment, we show that the DC environment is well suited to a deployment of 60 GHz links contrary to concerns about interference and link reliability. Using directional antennas, many wireless links can run concurrently at multi-Gbps rates on top-of-rack (ToR) switches. The wired DC network can be used to sidestep several common wireless problems. By analyzing production traces of DC traffic for four real applications, we show that adding a small amount of network capacity in the form of wireless flyways to the wired DC network can improve performance. However, to be of significant value, we find that one hop indirect routing is needed. Informed by our 60 GHz experiments and DC traffic analysis, we present a design that uses DC traffic levels to select and adds flyways to the wired DC network. Trace-driven evaluations show that network-limited DC applications with predictable traffic workloads running on a 1:2 oversubscribed network can be sped up by 45% in 95% of the cases, with just one wireless device per ToR switch. With two devices, in 40% of the cases, the performance is identical to that of a non-oversubscribed network. Copyright 2011 ACM.",Design; Experimentation; Measurement; Performance,Data centers; DC networks; Directional Antenna; Experimentation; Hotspots; Link reliability; Low costs; Multi-Gbps; Network Capacity; Performance; Real applications; Traffic analysis; Traffic levels; Wireless devices; Wireless link; Wireless technologies; Design; Directive antennas; Experiments; Measurements; Wireless telecommunication systems; DC power transmission
"Wang P., Gao Z., Xu X., Zhou Y., Zhu H., Zhu K.Q.",6,Automatic inference of movements from contact histories,2011,6,"Shanghai Jiao Tong University, Shanghai, China",Shanghai JiaoTong University,1,China,1,28,14,"This paper introduces a new security problem in which individuals movement traces (in terms of accurate routes) can be inferred from just a series of mutual contact records and the map of the area in which they roam around. Such contact records may be obtained through the bluetooth communication on mobile phones. We present an approach that solve the trace inference problem in reasonable time, and analyze some properties of the inference algorithm.",Contacts; Inference; Location privacy; Traces,Automatic inference; Inference; Inference algorithm; Inference problem; Location privacy; Security problems; Traces; Contacts (fluid mechanics); Trace analysis; Inference engines
"Woo K., Kwon H., Kim H.-C., Kim C.-K., Kim H.K.",5,What can free money tell us on the virtual black market?,2011,9,"Seoul National University, South Korea; Korea University, South Korea",Korea University;Seoul National University,2,South Korea,1,33,25,"""Real money trading"" or ""Gold farming"" refers to a set of illicit practices for gathering and distributing virtual goods in online games for real money. Unlike previous work, we use network-wide economic interactions among in-game characters as a lens to monitor, detect and identify gold farming networks. Our work is based on a set of real in-game trade activity logs collected for one month in year 2010 from the world's second largest MMORPG called AION (with 3.4 million subscribers). This is the first work that empirically (i) shows that ""free money network"" is a promising measure/approximation for detecting and characterizing gold farming networks, and (ii) measures the size of the free money net and in-game virtual economy in a large-scale MMORPG in terms of the cash flow.",Gold farming; Online game security; Real money trading,Black market; Cash flow; Economic interactions; On-line games; Real money trading; Virtual goods; Gold; Internet; Commerce
"Leng C., Lehn M., Rehner R., Buchmann A.",4,Designing a testbed for large-scale distributed systems,2011,0,"Databases and Distributed Systems, TU Darmstadt, Germany",TU Darmstadt,1,Germany,1,5,5,"Different evaluation methods for distributed systems like prototyping, simulation and emulation have different tradeoffs. We present a testbed for Internet applications that supports real-network prototypes and multiple simulators with unchanged application code. To ensure maximum portability between runtimes, a compact but flexible system interface is defined.",Design; Experimentation; Performance,Application codes; Distributed systems; Evaluation Method; Experimentation; Flexible system; Internet application; Large-scale distributed system; Performance; Runtimes; Design; Testbeds
"Chen Z., Chen Y., Ding C., Deng B., Li X.",5,Pomelo: Accurate and decentralized shortest-path distance estimation in social graphs,2011,6,"Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Computer Science, Duke University, Durham, United States; Institute of Computer Science, University of Goettingen, Goettingen, Germany",Duke University;Tsinghua University;University of Goettingen,3,China;Germany;USA,3,6,5,"Computing the shortest-path distances between nodes is a key problem in analyzing social graphs. Traditional methods like breadth-first search (BFS) do not scale well with graph size. Recently, a Graph Coordinate System, called Orion, has been proposed to estimate shortest-path distances in a scalable way. Orion uses a landmark-based approach, which does not take account of the shortest-path distances between non-landmark nodes in coordinate calculation. Such biased input for the coordinate system cannot characterize the graph structure well. In this paper, we propose Pomelo, which calculates the graph coordinates in a decentralized manner. Every node in Pomelo computes its shortest-path distances to both nearby neighbors and some random distant neighbors. By introducing the novel partial BFS, the com- putational overhead of Pomelo is tunable. Our experimental results from different representative social graphs show that Pomelo greatly outperforms Orion in estimation accuracy while maintaining the same computational overhead.",Graph Coordinate System; Online social network,Breadth-first search; Co-ordinate system; Computational overheads; Distance estimation; Graph sizes; Graph structures; Online social networks; Shortest-path; Social graphs; Estimation; Graph theory
"Valancius V., Lumezanu C., Feamster N., Johari R., Vazirani V.V.",5,How many tiers? Pricing in the internet transit market,2011,85,"Georgia Tech., United States; Stanford University, United States",Georgia Tech;Stanford University,2,USA,1,11,10,"ISPs are increasingly selling ""tiered"" contracts, which offer Internet connectivity to wholesale customers in bundles, at rates based on the cost of the links that the traffic in the bundle is traversing. Although providers have already begun to implement and deploy tiered pricing contracts, little is known about how to structure them. Although contracts that sell connectivity on finer granularities improve market efficiency, they are also more costly for ISPs to implement and more difficult for customers to understand. Our goal is to analyze whether current tiered pricing practices in the wholesale transit market yield optimal profits for ISPs and whether better bundling strategies might exist. In the process, we offer two contributions: (1) we develop a novel way of mapping traffic and topology data to a demand and cost model; and (2) we fit this model on three large real-world networks: an European transit ISP, a content distribution network, and an academic research network, and run counterfactuals to evaluate the effects of different bundling strategies. Our results show that the common ISP practice of structuring tiered contracts according to the cost of carrying the traffic flows (e.g., offering a discount for traffic that is local) can be suboptimal and that dividing contracts based on both traffic demand and the cost of carrying it into only three or four tiers yields near-optimal profit for the ISP. Copyright 2011 ACM.",Algorithms; Design; Economic,Academic research; Bundling strategies; Content distribution networks; Cost models; Counterfactuals; Internet connectivity; Market efficiency; Pricing contracts; Pricing practices; Real-world networks; Traffic demands; Traffic flow; Transit markets; Wholesale customers; Algorithms; Commerce; Costs; Design; Economics; Optimization; Profitability; Sales; Telecommunication networks; Topology; Internet service providers
"Werle C., Bless R., Papadimitriou P., Houidi I., Louati W., Zeghlache D., Mathy L.",7,Building virtual networks across multiple domains,2011,11,"Karlsruhe Institute of Technology, Germany; Leibniz University of Hannover, Germany; Institut Telecom, Telecom SudParis, France; Lancaster University, United Kingdom",Karlsruhe Institute of Technology;Lancaster University;Leibniz University of Hannover,3,France;Germany;UK,3,6,5,"This paper presents a platform for virtual network (VN) provisioning across multiple domains. The platform decomposes VN provisioning into multiple steps to address the implications of limited information disclosure on resource discovery and allocation. A new VN embedding algorithm with simultaneous node and link mapping allows to assign resources within each domain. For inter-domain virtual link setup, we design and realize a signaling protocol that also integrates resource reservations for providing virtual links with Quality-of-Service guarantees. Experimental results show that small VNs can be provisioned within a few seconds.",Network virtualization; Platform design; Quality-of-Service; Resource provisioning,Embedding algorithms; Inter-domain; Limited information; Multiple domains; Network virtualization; Platform design; Quality-of-service guarantee; Resource discovery; Resource provisioning; Resource reservations; Signaling protocol; Virtual Link; Virtual networks; Quality of service
"Dixit A., Prakash P., Kompella R.R.",3,On the efficacy of fine-grained traffic splitting protocols in data center networks,2011,11,"Department of Computer Science, Purdue University, United States",Purdue University,1,USA,1,31,23,"Multi-rooted tree topologies are commonly used to construct high-bandwidth data center network fabrics. In these networks, switches typically rely on equal-cost multipath (ECMP) routing techniques to split traffic across multiple paths, such that packets within a flow traverse the same end-to-end path. Unfortunately, since ECMP splits traffic based on flow-granularity, it can cause load imbalance across paths resulting in poor utilization of network resources. More finegrained traffic splitting techniques are typically not preferred because they can cause packet reordering that can, according to conventional wisdom, lead to severe TCP throughput degradation. In this work, we revisit this fact in the context of regular data center topologies such as fat-tree architectures. We argue that packet-level traffic splitting, where packets of a flow are sprayed through all available paths, would lead to a better load-balanced network, which in turn leads to significantly more balanced queues and much higher throughput compared to ECMP.",Data centers; Traffic splitting,All available paths; Data centers; End-to-end path; High bandwidth; Load imbalance; Load-balanced; Multi-path; Multiple-path; Network fabric; Network resource; Packet reordering; Routing techniques; TCP throughput; Traffic splitting; Tree topology; Plant extracts; Satellite communication systems; Topology; Transmission control protocol; Trees (mathematics)
"Shieh A., GŸn Sirer E., Schneider F.B.",3,NetQuery: A knowledge plane for reasoning about network properties,2011,11,"Department of Computer Science, Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,8,5,"This paper presents the design and implementation of NetQuery, a knowledge plane for federated networks such as the Internet. In such networks, not all administrative domains will generate information that an application can trust and many administrative domains may have restrictive policies on disclosing network information. Thus, both the trustworthiness and accessibility of network information pose obstacles to effective reasoning. NetQuery employs trustworthy computing techniques to facilitate reasoning about the trustworthiness of information contained in the knowledge plane while preserving confidentiality guarantees for operator data. By characterizing information disclosure between operators, NetQuery enables remote verification of advertised claims and contractual stipulations; this enables new applications because network guarantees can span administrative boundaries. We have implemented NetQuery, built several NetQuery-enabled devices, and deployed applications for cloud datacenters, enterprise networks, and the Internet. Simulations, testbed experiments, and a deployment on a departmental network indicate NetQuery can support hundreds of thousands of operations per second and can thus scale to large ISPs. Copyright 2011 ACM.",Design; Management,Data centers; Enterprise networks; Information disclosure; Knowledge plane; Network information; Network properties; New applications; Trustworthy computing; Computer simulation; Design; Internet service providers; Management; Telecommunication networks; Information management
"Gill P., Schapira M., Goldberg S.",3,Let the market drive deployment: A strategy for transitioning to BGP security,2011,60,"University of Toronto, Canada; Princeton University, United States; Boston University, United States",Boston University;Princeton University;University of Toronto,3,Canada;USA,2,6,4,"With a cryptographic root-of-trust for Internet routing (RPKI [17]) on the horizon, we can finally start planning the deployment of one of the secure interdomain routing protocols proposed over a decade ago (Secure BGP [22], secure origin BGP [37]). However, if experience with IPv6 is any indicator, this will be no easy task. Security concerns alone seem unlikely to provide sufficient local incentive to drive the deployment process forward. Worse yet, the security benefits provided by the S*BGP protocols do not even kick in until a large number of ASes have deployed them. Instead, we appeal to ISPs' interest in increasing revenue-generating traffic. We propose a strategy that governments and industry groups can use to harness ISPs' local business objectives and drive global S*BGP deployment. We evaluate our deployment strategy using theoretical analysis and large-scale simulations on empirical data. Our results give evidence that the market dynamics created by our proposal can transition the majority of the Internet to S*BGP. Copyright 2011 ACM.",Economics; Security,Deployment process; Deployment strategy; Empirical data; Industry groups; Interdomain Routing; Internet routing; Large scale simulations; Local business; Market dynamics; Security; Economics; Internet protocols; Telecommunication networks; Internet service providers
"Goma E., Canini M., Toledo A.L., Laoutaris N., Kosti_ D., Rodriguez P., Stanojevi_ R., Valent’n P.Y.",8,Insomnia in the access: Or how to curb access network related energy consumption,2011,48,"Telefonica Research, Spain; EPFL, Switzerland; Institute IMDEA Networks, Spain",IMDEA Networks;Telefonica Research,2,Spain;Switzerland,2,58,54,"Access networks include modems, home gateways, and DSL Access Multiplexers (DSLAMs), and are responsible for 70-80% of total network-based energy consumption. In this paper, we take an in-depth look at the problem of greening access networks, identify root problems, and propose practical solutions for their user-and ISP-parts. On the user side, the combination of continuous light traffic and lack of alternative paths condemns gateways to being powered most of the time despite having Sleep-on-Idle (SoI) capabilities. To address this, we introduce Broadband Hitch-Hiking (BH2), that takes advantage of the overlap of wireless networks to aggregate user traffic in as few gateways as possible. In current urban settings BH2 can power off 65-90% of gateways. Powering off gateways permits the remaining ones to synchronize at higher speeds due to reduced crosstalk from having fewer active lines. Our tests reveal speedup up to 25%. On the ISP side, we propose introducing simple inexpensive switches at the distribution frame for batching active lines to a subset of cards letting the remaining ones sleep. Overall, our results show an 80% energy savings margin in access networks. The combination of BH2 and switching gets close to this margin, saving 66% on average. Copyright 2011 ACM.",Broadband access networks; Energy,Access network; Alternative path; Broad-band access networks; Continuous light; DSL access multiplexers; Energy; Home gateway; Network-based; Practical solutions; Reduced cross-talk; Root problems; Urban settings; User traffics; Broadband networks; Energy utilization; Modems; Gateways (computer networks)
"Soroush H., Gilbert P., Banerjee N., Levine B., Corner M., Cox L.",6,Spider: Improving mobile networking with concurrent Wi-Fi connections,2011,18,"University of Massachusetts, United States; Duke University, United States; University of Arkansas, United States",Duke University;University of Arkansas;University of Massachusetts Amherst,3,USA,1,39,32,"We investigate attempting concurrent connections to multiple Wi-Fi access points (APs) from highly mobile clients. Previous multi-AP solutions are limited to stationary wireless clients and do not take into account a myriad of mobile factors. We show that connection duration, AP response times, channel scheduling, available and offered bandwidth, node speed, and dhcp joins all affect performance. Building on these results, we present a system, Spider, that establishes and maintains concurrent connections to 802.11 APs in a mobile environment. While Spider can manage multiple channels, we demonstrate that it achieves maximum throughput when using multiple APs on a single channel.",Concurrent Wi-Fi; Mobile networks,Access points; Channel scheduling; Maximum through-put; Mobile client; Mobile environments; Mobile networking; Multiple channels; Single channels; Wi-Fi connections; Wireless client; Wireless networks; Wi-Fi
"Ahmadzadeh S.A., Agnew G.B.",2,Covert channels in multiple access protocols,2011,1,"University of Waterloo, Canada",University of Waterloo,1,Canada,1,47,44,"In this paper, the use of structural behavior of communication protocols in designing new covert channels is investigated. In this way, a new covert transmitter is designed based on a modified CSMA protocol that enables the transmitter to embed a covert message in its overt traffic. The proposed scheme provides high covert rate without compromising the stealthiness of the channel.",Algorithms; Design; Security,Covert channels; Multiple access protocols; Security; Structural behaviors; Algorithms; Design; Transmitters; Carrier sense multiple access
"Zhu N., Rao L., Liu X., Liu J., Guan H.",5,Taming power peaks in MapReduce clusters,2011,12,"Dept. of Computer Science, Shanghai Jiaotong University, Shanghai, China; School of Computer Science, McGill University, Montreal, Canada; Microsoft Research, Microsoft Corp., Redmond, United States",McGill University;Microsoft;Shanghai Jiaotong University,3,Canada;China;USA,3,4,4,"Along with the surging service demands on the cloud, the energy cost of Internet Data Centers (IDCs) is dramatically increasing. Energy management for IDCs is becoming ever more important. A large portion of applications running on data centers are data-intensive applications. MapReduce (and Hadoop) has been one of the mostly deployed frameworks for data-intensive applications. Both academia and industry have been greatly concerned with the problem of how to reduce the energy consumption of IDCs. However the critical power peak problem for MapReduce clusters has been overlooked, which is a new challenge brought by the usage of MapReduce. We elaborate the power peak problem and investigate the cause of the problem in details. Then we design an adaptive approach to regulate power peaks.",Algorithms; Design; Performance,Adaptive approach; Critical power; Data centers; Data-intensive application; Energy cost; Internet data centers; Map-reduce; Performance; Service demand; Algorithms; Design; Energy utilization
"Gollakota S., Adib F., Katabi D., Seshan S.",4,Clearing the RF smog: Making 802.11 robust to cross-technology interference,2011,106,"Massachusetts Institute of Technology, United States; Carnegie Mellon University, United States",Carnegie Mellon University;MIT,2,USA,1,6,5,"Recent studies show that high-power cross-technology interference is becoming a major problem in today's 802.11 networks. Devices like baby monitors and cordless phones can cause a wireless LAN to lose connectivity. The existing approach for dealing with such high-power interferers makes the 802.11 network switch to a different channel; yet the ISM band is becoming increasingly crowded with diverse technologies, and hence many 802.11 access points may not find an interference-free channel. This paper presents TIMO, a MIMO design that enables 802.11n to communicate in the presence of high-power cross-technology interference. Unlike existing MIMO designs, however, which require all concurrent transmissions to belong to the same technology, TIMO can exploit MIMO capabilities to decode in the presence of a signal from a different technology, hence enabling diverse technologies to share the same frequency band. We implement a prototype of TIMO in GNURadio-USRP2 and show that it enables 802.11n to communicate in the presence of interference from baby monitors, cordless phones, and microwave ovens, transforming scenarios with a complete loss of connectivity to operational networks. Copyright 2011 ACM.",Cognitive MIMO; Cross-technology interference,802.11 networks; 802.11n; Access points; Baby-monitor; Concurrent transmission; Cordless phones; High-power; ISM bands; Operational network; Cordless telephones; Frequency bands; Switching circuits; Telephone sets; Technology
"Dobrian F., Awan A., Joseph D., Ganjam A., Zhan J., Sekar V., Stoica I., Zhang H.",8,Understanding the impact of video quality on user engagement,2011,357,"Conviva, United States; Intel Labs, United States; Conviva, UC Berkeley, United States; Conviva, CMU, United States",University of California Berkeley,1,USA,1,4,3,"As the distribution of the video over the Internet becomes mainstream and its consumption moves from the computer to the TV screen, user expectation for high quality is constantly increasing. In this context, it is crucial for content providers to understand if and how video quality affects user engagement and how to best invest their resources to optimize video quality. This paper is a first step towards addressing these questions. We use a unique dataset that spans different content types, including short video on demand (VoD), long VoD, and live content from popular video content providers. Using client-side instrumentation, we measure quality metrics such as the join time, buffering ratio, average bitrate, rendering quality, and rate of buffering events. We quantify user engagement both at a per-video (or view) level and a per-user (or viewer) level. In particular, we find that the percentage of time spent in buffering (buffering ratio) has the largest impact on the user engagement across all types of content. However, the magnitude of this impact depends on the content type, with live content being the most impacted. For example, a 1% increase in buffering ratio can reduce user engagement by more than three minutes for a 90-minute live video event. We also see that the average bitrate plays a significantly more important role in the case of live content than VoD content. Copyright 2011 ACM.",Engagement; Measurement; Video quality,Bit rates; Content providers; Data sets; Engagement; High quality; Live video; Quality metrics; Rendering quality; Time spent; User engagement; User expectations; Video contents; Video over the Internet; Video quality; Content based retrieval; Measurements; Video on demand
"Mishra A., Venkitasubramaniam P.",2,Dummy rate analysis of buffer constrained chaum mix,2011,0,"Lehigh University, PA 18015, United States",Lehigh University,1,USA,1,40,30,"Welcome to the 2011 ACM SIGCOMM Conference in Toronto, Canada. It has been our pleasure to oversee the tremendous efforts volunteered by our technical program committee and other individuals in shaping this year's technical program. We hope that you will find the papers selected for the technical program stimulating and thought-provoking, and that you enjoy the conference! SIGCOMM 2011 received 223 submissions, and we accepted 32 papers, for an acceptance ratio of 14%. This represents a modest drop over the number of submissions from previous years. We received submissions from authors in at least 36 countries, and the final program reflects the significant geographical diversity across submissions, with authors representing 12 different countries and 44 distinct institutions. The SIGCOMM 2011 TPC comprised 50 members from academia and industry, reflecting the diversity of our community. The TPC members' research interests span the wide range of topics present in this year's submissions and accepted papers. The members of the TPC wrote at least three first-round reviews for all 223 submissions, as well as three or more second-round reviews for the top 101 papers. Thus, we had at least 6 reviews for each of the 70 papers that we discussed in the TPC meeting. Most second-round papers received significant online discussion between PC members prior to the TPC meeting, and in some cases we solicited additional reviews from external topic experts. In total, the submissions received over 1000 written reviews. Reviewing was double-blind, and was subject to a strict conflict-of-interest policy. PC members with potential conflicts of interest were excluded from all discussions of the relevant papers. Both of the TPC co-chairs were authors of submissions; these reviews were handled entirely outside of the online review system, so as to guarantee reviewer anonymity. Almost all of the TPC members attended the TPC meeting in Boston in person, for 1.5 days of energetic discussion. Those who were not able to attend in person participated via a telephone conference. We strove, as TPC chairs, to ensure that all 70 papers received full and fair discussion, and we encouraged the TPC to consider prioritizing ""appropriately risky"" papers over otherwise comparable ""correct but boring"" papers when there was a choice. Each of the 32 accepted papers was shepherded by a member of the TPC, to help the authors improve their final versions. Copyright 2011 ACM.",Buffer constraint; Chaum Mix; Dummy rate,"Acceptance ratio; Buffer constraints; Chaum Mix; Dummy rate; Online discussions; Potential conflict; Previous year; Rate analysis; Technical programs; Toronto , Canada; Paper"
"Rojas E., Naous J., Iba–ez G., Rivera D., Carral J.A., Arco J.M.",6,Implementing ARP-Path low latency bridges in NetFPGA,2011,6,"University of Alcala, Campus Externo, Alcal‡ de Henares 28805, Spain; Stanford University, Stanford, CA 94305, United States",Stanford University;University of Alcala,2,Spain;USA,2,38,26,"The demo is focused on the implementation of ARP-Path (a.k.a. FastPath) bridges, a recently proposed concept for low latency bridges. ARP-Path Bridges rely on the race between broadcast ARP Request packets, to discover the minimum latency path to the destination host. Several implementations (in Omnet++, Linux, OpenFlow, NetFPGA) have shown that ARP-Path exhibits loop-freedom, does not block links, is fully transparent to hosts and neither needs a spanning tree protocol to prevent loops nor a link state protocol to obtain low latency paths. This demo compares our hardware implementation on NetFPGA to bridges running STP, showing that ARP-Path finds lower latency paths than STP.",Ethernet; NetFPGA; Routing bridges; Shortest Path Bridges; Spanning Tree,Hardware implementations; Link state protocols; Loop freedom; Low latency; NetFPGA; OMNET++; Shortest path; Spanning tree; Spanning tree protocols; Computer operating systems; Ethernet; Hardware; Parallel architectures; Plant extracts; Wireless sensor networks; Internet protocols
"Raiciu C., Barre S., Pluntke C., Greenhalgh A., Wischik D., Handley M.",6,Improving datacenter performance and robustness with multipath TCP,2011,374,"University College London, United Kingdom; Universite Catholique de Louvain, Belgium; Universitatea Politehnica Bucuresti, Romania",Universitatea Politehnica Bucuresti;Universite Catholique de Louvain;University College London,3,Belgium;Romania;UK,3,3,1,"The latest large-scale data centers offer higher aggregate bandwidth and robustness by creating multiple paths in the core of the network. To utilize this bandwidth requires different flows take different paths, which poses a challenge. In short, a single-path transport seems ill-suited to such networks. We propose using Multipath TCP as a replacement for TCP in such data centers, as it can effectively and seamlessly use available bandwidth, giving improved throughput and better fairness on many topologies. We investigate what causes these benefits, teasing apart the contribution of each of the mechanisms used by MPTCP. UsingMPTCP lets us rethink data center networks, with a different mindset as to the relationship between transport protocols, routing and topology. MPTCP enables topologies that single path TCP cannot utilize. As a proof-of-concept, we present a dual-homed variant of the FatTree topology. With MPTCP, this outperforms FatTree for a wide range of workloads, but costs the same. In existing data centers, MPTCP is readily deployable leveraging widely deployed technologies such as ECMP.We have run MPTCP on Amazon EC2 and found that it outperforms TCP by a factor of three when there is path diversity. But the biggest benefits will come when data centers are designed for multipath transports. Copyright 2011 ACM.",Algorithms; Design; Performance,Amazon ec2; Available bandwidth; Data centers; Multipath TCP; Multipath transport; Multiple-path; Path diversity; Performance; Proof of concept; Single path; Transport protocols; Algorithms; Design; Satellite communication systems; Topology; Transmission control protocol; Bandwidth
"Kothari N., Mahajan R., Millstein T., Govindan R., Musuvathi M.",5,Finding protocol manipulation attacks,2011,28,"USC, United States; Microsoft Research, United States; UCLA, United States",Microsoft,1,USA,1,6,4,"We develop a method to help discover manipulation attacks in protocol implementations. In these attacks, adversaries induce honest nodes to exhibit undesirable behaviors by misrepresenting their intent or network conditions. Our method is based on a novel combination of static analysis with symbolic execution and dynamic analysis with concrete execution. The former finds code paths that are likely vulnerable, and the latter emulates adversarial actions that lead to effective attacks. Our method is precise (i.e., no false positives) and we show that it scales to complex protocol implementations. We apply it to four diverse protocols, including TCP, the 802.11 MAC, ECN, and SCTP, and show that it is able to find all manipulation attacks that have been previously reported for these protocols. We also find a previously unreported attack for SCTP. This attack is a variant of a TCP attack but must be mounted differently in SCTP because of subtle semantic differences between the two protocols. Copyright 2011 ACM.",Reliability; Security,802.11 MAC; Complex protocols; False positive; OR-networks; Protocol implementation; Security; Semantic difference; Symbolic execution; Dynamic analysis; Reliability; Semantics; Static analysis; Transmission control protocol
"Mai H., Khurshid A., Agarwal R., Caesar M., Godfrey P.B., King S.T.",6,Debugging the data plane with Anteater,2011,193,"University of Illinois, Urbana-Champaign, United States",UIUC,1,USA,1,14,14,"Diagnosing problems in networks is a time-consuming and error-prone process. Existing tools to assist operators primarily focus on analyzing control plane configuration. Configuration analysis is limited in that it cannot find bugs in router software, and is harder to generalize across protocols since it must model complex configuration languages and dynamic protocol behavior. This paper studies an alternate approach: diagnosing problems through static analysis of the data plane. This approach can catch bugs that are invisible at the level of configuration files, and simplifies unified analysis of a network across many protocols and implementations. We present Anteater, a tool for checking invariants in the data plane. Anteater translates high-level network invariants into instances of boolean satisfiability problems (SAT), checks them against network state using a SAT solver, and reports counterexamples if violations have been found. Applied to a large university network, Anteater revealed 23 bugs, including forwarding loops and stale ACL rules, with only five false positives. Nine of these faults are being fixed by campus network operators. Copyright 2011 ACM.",Boolean satisfiability; Data plane analysis; Network troubleshooting,Boolean satisfiability; Boolean satisfiability problems; Campus network; Configuration analysis; Configuration files; Control planes; Data planes; Error-prone process; False positive; Model complexes; Network invariants; Network state; Network troubleshooting; Protocol behavior; Router software; SAT solvers; Unified analysis; Program debugging; Static analysis; Formal logic
"Li A., Zong X., Kandula S., Yang X., Zhang M.",5,CloudProphet: Towards application performance prediction in cloud,2011,53,"Duke University, Durham, NC, United States; Microsoft Research, Redmond, WA, United States",Duke University;Microsoft,2,USA,1,31,25,"Choosing the best-performing cloud for one's application is a critical problem for potential cloud customers. We propose Cloud- Prophet, a trace-and-replay tool to predict a legacy application's performance if migrated to a cloud infrastructure. CloudProphet traces the workload of the application when running locally, and replays the same workload in the cloud for prediction. We discuss two key technical challenges in designing CloudProphet, and some preliminary results using a prototype implementation.",Cloud computing; Performance; Prediction,Application performance; Critical problems; Legacy applications; Performance; Prototype implementations; Technical challenges; Forecasting; Cloud computing
"Benson T., Akella A., Shaikh A.",3,Demystifying configuration challenges and trade-offs in network-based ISP services,2011,27,"University of Wisconsin, Madison, Madison, WI, United States; AT and T Labs - Research, Florham Park, NJ, United States",AT and T Labs;University of Wisconsin-Madison,2,USA,1,44,37,"ISPs are increasingly offering a variety of network-based services such as VPN, VPLS, VoIP, Virtual-Wire and DDoS protection. Although both enterprise and residential networks are rapidly adopting these services, there is little systematic work on the design challenges and trade-offs ISPs face in providing them. The goal of our paper is to understand the complexity underlying the layer-3 design of services and to highlight potential factors that hinder their introduction, evolution and management. Using daily snapshots of configuration and device metadata collected from a tier-1 ISP, we examine the logical dependencies and special cases in device configurations for five different network-based services. We find: (1) the design of the core data-plane is usually service-agnostic and simple, but the control-planes for different services become more complex as services evolve; (2) more crucially, the configuration at the service edge inevitably becomes more complex over time, potentially hindering key management issues such as service upgrades and troubleshooting; and (3) there are key service-specific issues that also contribute significantly to the overall design complexity. Thus, the high prevalent complexity could impede the adoption and growth of network-based services. We show initial evidence that some of the complexity can be mitigated systematically. Copyright 2011 ACM.",Configuration analysis; Network modeling; Network services,Configuration analysis; Data-plane; Design challenges; Device configurations; Different services; Key management; Logical dependencies; Network modeling; Network services; Network-based; Network-based services; Overall design; Residential networks; Design; Internet telephony; Metadata; Internet service providers
"Eppstein D., Goodrich M.T., Uyeda F., Varghese G.",4,What's the difference? Efficient set reconciliation without prior context,2011,54,"U.C. Irvine, United States; U.C. San Diego, United States; Yahoo Research, United States",Yahoo Research,1,USA,1,6,3,"We describe a synopsis structure, the Difference Digest, that allows two nodes to compute the elements belonging to the set difference in a single round with communication overhead proportional to the size of the difference times the logarithm of the keyspace. While set reconciliation can be done efficiently using logs, logs require overhead for every update and scale poorly when multiple users are to be reconciled. By contrast, our abstraction assumes no prior context and is useful in networking and distributed systems applications such as trading blocks in a peer-to-peer network, and synchronizing link-state databases after a partition. Our basic set-reconciliation method has a similarity with the peeling algorithm used in Tornado codes [6], which is not surprising, as there is an intimate connection between set difference and coding. Beyond set reconciliation, an essential component in our Difference Digest is a new estimator for the size of the set difference that outperforms min-wise sketches [3] for small set differences. Our experiments show that the Difference Digest is more efficient than prior approaches such as Approximate Reconciliation Trees [5] and Characteristic Polynomial Interpolation [17]. We use Difference Digests to implement a generic KeyDiff service in Linux that runs over TCP and returns the sets of keys that differ between machines. Copyright 2011 ACM.",Algorithms; Design; Experimentation,Characteristic polynomials; Communication overheads; Distributed systems; Efficient sets; Essential component; Experimentation; Multiple user; Peeling algorithm; Peer to peer; Tornado codes; Algorithms; Computer operating systems; Design; Distributed computer systems; Distributed database systems; Experiments; Peer to peer networks
"S‡nchez M.A., Otto J.S., Bischof Z.S., Bustamante F.E.",4,Dasu - ISP characterization from the edge: A BitTorrent Implementation,2011,2,"Northwestern University, United States",Northwestern University,1,USA,1,26,24,"Evaluating and characterizing access ISPs is critical to consumers shopping for alternative services and governments surveying the availability of broadband services to their citizens. We present Dasu, a service for crowdsourcing ISP characterization to the edge of the network. Dasu is implemented as an extension to a popular BitTorrent client [5] and has been available since July 2010. While the prototype uses BitTorrent as its host application, its design is agnostic to the particular host application. The demo showcases our current implementation using both a prerecorded execution trace and a live run.",Broadband access networks; Characterization; ISP,BitTorrent; Broad-band access networks; Broadband service; Crowdsourcing; Execution trace; ISP; Broadband networks; Characterization; Internet service providers
"Carzaniga A., Papalini M., Wolf A.L.",3,Content-based publish/subscribe networking and information-centric networking,2011,44,"University of Lugano, Lugano, Switzerland; Imperial College London, London, United Kingdom",Imperial College London;University of Lugano,2,Switzerland;UK,2,21,10,"On-line information comes in different forms and is accessed in different ways and for different purposes. For example, a recording of Beethoven's Ninth Symphony differs from a storm warning from the local weather service. Beethoven's Ninth is a large media file with perpetual validity that is typically accessed on demand by users. By contrast, a storm warning is a small ephemeral message typically pushed by the weather service to all users in a specific geographic area. We argue that both should and would be well supported by an information-centric network. More specifically we argue three points. First, modern applications, reflecting the nature of human communications, use and transmit large and long-lived files as well as small ephemeral messages. Second, accessing those two types of information involves significantly different operations within the network. Third, despite their differences, both types of information would benefit from an addressing scheme based on content rather than on more or less flat identifiers, which means that both should be integrated to some extent within a unified content-based routing infrastructure. © 2011 ACM.",content-based networking; content-centric networking; information-centric networking; named-data networking; publish/subscribe,Content-based networking; content-centric networking; information-centric networking; named-data networking; Publish/subscribe; Storms; Weather information services
"Mok R.K.P., Chan E.W.W., Luo X., Chang R.K.C.",4,Inferring the QoE of HTTP video streaming from user-viewing activities,2011,80,"Department of Computing, Hong Kong Polytechnic University, Hunghom, Kowloon, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,5,4,"HTTP video streaming, employed by most of the video-sharing websites, allows users to control the video playback using, for example, pausing and switching the bit rate. These user-viewing activities can be used to mitigate the temporal structure impairments of the video quality. On the other hand, other activities, such as mouse movement, do not help reduce the impairment level. In this paper, we have performed subjective experiments to analyze user-viewing activities and correlate them with network path performance and user quality of experience. The results show that network measurement alone may miss important information about user dissatisfaction with the video quality. Moreover, video impairments can trigger user-viewing activities, notably pausing and reducing the screen size. By including the pause events into the prediction model, we can increase its explanatory power. © 2011 ACM.",http video streaming; qoe; user-viewing activities,Bit rates; Explanatory power; Mouse movements; Network measurement; Network paths; Prediction model; qoe; Quality of experiences; Screen sizes; Subjective experiments; Temporal structures; user-viewing activities; Video impairments; Video Playback; Video quality; Acoustic streaming; Mammals; Mathematical models; Quality of service; Video streaming; Videotex; HTTP
"Bapat T., Sengupta N., Ghai S.K., Arya V., Shrinivasan Y.B., Seetharam D.",6,User-sensitive scheduling of home appliances,2011,48,"Dept. of CSA, Indian Institute of Science, Bangalore, India; IBM Research India, Bangalore, India",IBM;Indian Institute of Science,2,India,1,11,9,"Demand response (DR) programs encourage end-use customers to alter their power consumption in response to DR events such as change in real-time electricity prices. Facilitating household participation in DR programs is essential as the residential sector accounts for a sizable portion of the total energy consumed. However, manually tracking energy prices and deciding on how to schedule home appliances can be a challenge for residential consumers who are accustomed to fixed price electricity taris. In this work, we present Yupik, a system that helps users respond to real-time electricity prices while being sensitive to their context and lifestyle. Yupik combines sensing, analytics, and optimization to generate appliance usage schedules that may be used by households to minimize their energy bill as well as potential lifestyle disruptions. Yupik uses jPlugs, appliance level energy metering devices, to continuously monitor the power usage by various home appliances. The consumption patterns as well as data from external sources are analyzed using data mining algorithms to infer user's preferred usage profile. Using the preferred profile as a reference, Yupik's optimization engine generates multiple usage plans that attempt to minimize energy and inconvenience costs. Some of Yupik's capabilities are demonstrated with the help of preliminary data collected from a home that was instrumented with jPlugs to monitor the power usage of a few devices. © 2011 ACM.",demand response; energy consumption scheduling; home automation; smart grids,Consumption patterns; Data mining algorithm; Demand response; Demand response programs; Electricity prices; End-uses; Energy bills; Energy prices; External sources; Fixed prices; Home automation; Metering devices; Optimization engine; Power usage; Preliminary data; Residential consumers; Residential sectors; smart grids; Total energy; Computer networks; Costs; Data mining; Domestic appliances; Electric utilities; Electricity; Energy utilization; Optimization; Smart power grids
"Doyle J., O'Mahony D., Shorten R.",3,Server selection for carbon emission control,2011,17,"CTVR, Trinity College Dublin, Dublin, Ireland; Department of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland; Hamilton Institute, NUIM, Maynooth, Ireland",Hamilton Institute;Trinity College Dublin,2,Ireland,1,24,15,Cloud owners are allowing their users to specify the level of resources being used in the different geographical locations that make up the cloud. The carbon emissions caused by powering these resources can vary greatly between different geographical regions. The traffic for a given service can come from anywhere on the planet and the further the request has to travel the greater the negative effect on quality of service (QoS). It is desirable to route traffic to the resources which cause the lowest carbon emissions but this can affect the QoS. A framework that characterizes this trade-off between carbon emissions and QoS is established in this paper. An algorithm that attempts to minimize the total cost of the trade-off described is presented. A traffic generator is used to generate load for a server to establish functions which detail the carbon emissions and QoS of a service. We use these functions to simulate the performance of the algorithm in minimizing the total cost. Our results imply that carbon emissions can be reduced with little effect on the QoS under static traffic conditions and favourable energy supply conditions. © 2011 ACM.,carbon emission; relative price function; subgradient method,Carbon emissions; Energy supplies; Geographical locations; Relative prices; Route traffic; Server selection; Static traffic; Subgradient methods; Total costs; Traffic generators; Algorithms; Computer networks; Emission control; Geographical regions; Quality of service; Carbon
"Jin Y., Duffield N., Gerber A., Haffner P., Hsu W.-L., Jacobson G., Sen S., Venkataraman S., Zhang Z.-L.",9,Large-scale app-based reporting of customer problems in cellular networks: Potential and limitations,2011,3,"AT and T Labs. - Research, Florham Park, NJ, United States; Computer Science Dept., University of Minnesota, Minneapolis, MN, United States",AT and T Labs;University of Minnesota,2,USA,1,16,13,"In this paper, we study the Location-based Reporting Tool (LRT), a smartphone application for collecting large-scale feedback from mobile customers. Using one-year data collected from one of the largest cellular networks in the US, we compare LRT feedback to the traditional customer feedback channel - customer care tickets. Our analysis shows that, due to the light-weight design, LRT encourages customers to report more problems from anywhere and at any time. In addition, we find LRT users access network services more intensively than other mobile users, and hence are more likely to experience and are more sensitive to network problems. All these render LRT feedback a valuable information source for early detection of emerging network problems. © 2011 ACM.",app-based reporting tool; cellular network; troubleshooting,Cellular network; Customer care; Customer feedback; Customer problems; Early detection; Information sources; Lightweight design; Location based; Mobile customer; Mobile users; Network problems; Reporting tools; Smart phones; Users access; Cellular neural networks; Customer satisfaction; Diagnosis; Feedback; Global system for mobile communications; Sales
"Audzevich Y., Watts P., Kilmurray S., Moore A.W.",4,Efficient photonic coding: A considered revision,2011,5,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom; Department of Electronic and Electrical Engineering, UCL, London, United Kingdom",University of Cambridge,1,UK,1,17,15,"In this paper we reconsider the energy consumption of traditional DC-balanced physical line coding schemes applied to optical communication. We demonstrate that not only does an implementation of the popular 8B10B coding scheme have higher power consumption than the optical power requirement, but actually has higher power consumption when transmitting idle sequences than for real data packets. Furthermore, we show that simple codes retain the DC balance performance of 8B10B and hence do not increase the optical power requirement. We propose the use of a coding scheme that permits a default-off transmission system through the addition of a preamble. By analysis of trace data taken from a network covering a 24 hour period, we show that the power saving is up to 93%. The proposed approach not only enables energy proportional links but is fully compatible with future low power optical switched networks. © 2011 ACM.",energy-efficiency; physical line coding,Balance performance; Coding scheme; Data packet; Fully compatible; Low Power; Optical power requirement; physical line coding; Power savings; Switched networks; Trace data; Transmission systems; Computer networks; Energy utilization; Optical communication; Switching circuits; Trace analysis; DC power transmission
"Han S., Li T., Qian C., Leith D., Mok A.K., Lam S.S.",6,HartFi: An energy-efficient localization system,2011,6,"University of Texas, Austin, TX, United States; Hamilton Institute, National Univ. of Ireland Maynooth, Kildare, Ireland",Hamilton Institute;University of Texas at Austin,2,Ireland;USA,2,14,14,"Location-based applications (LBAs) are emerging to be the killer applications on mobile devices. To know the whereabouts of devices, various interfaces (ie, GPS, WiFi or cellular) can be used to sense their locations. Ideally, localization should be done all the time. However, keeping any of these interfaces running continuously would drain a device's battery rapidly. In this paper, we present a radical design of a collaborative localization system called HF, which enhances existing devices with a low-power 802.15.4-based WH interface. A salient feature of this added interface is that its energy consumption is up to two orders of magnitude less than that of a standard WiFi interface; yet it provides a comparable range of coverage. In the HF system, therefore, WH interfaces are used whenever and wherever it is feasible to share location information that has been obtained using GPS WiFi cellular interfaces. We have designed a mechanism to avoid location error accumulation in HF, which raises its localization accuracy to a level comparable to that of WiFi localization. We are implementing a HartFi system at the moment and current results are promising. © 2011 ACM.",location based services; wi-fi; wirelesshart,Cellular interfaces; Energy efficient; Hf systems; Killer-application; Localization accuracy; Localization system; Location errors; Location information; Location-based applications; Location-Based Services; Low Power; Orders of magnitude; Salient features; WirelessHART; Computer networks; Energy utilization; Mobile devices; Mobile telecommunication systems; Wi-Fi; Energy efficiency
"Miller J.S., Mondal A., Potharaju R., Dinda P.A., Kuzmanovic A.",5,Understanding end-user perception of network problems,2011,8,"Northwestern University, Evanston, IL, United States",Northwestern University,1,USA,1,25,19,"It is widely assumed that certain network characteristics cause end-user irritation with network performance. These assumptions then drive the selection of quality of service parameters or the goals of adaptive systems. We have developed a methodology and toolchain, SoylentLogger, that employs user studies to empirically investigate such assumptions. SoylentLogger collects client-centric network measurement data that is labeled by the end-user as being associated with irritation at perceived network performance (or not). The data collection and labeling occurs in real-time as the user normally uses the network. We conducted a study that tracked 32 ordinary users over a period of 3 weeks and then used that data to test common assumptions about network sources of user irritation. © 2011 ACM.",empathic systems; network performance; user studies,Data collection; End users; Network characteristics; Network measurement; Network problems; Quality of Service parameters; User study; Adaptive systems; Network performance
"Ghodsi A., Koponen T., Rajahalme J., Sarolahti P., Shenker S.",5,Naming in content-oriented architectures,2011,129,"UC Berkeley, Berkeley, CA, United States; Nicira Networks, Palo Alto, CA, United States; Nokia Siemens Networks, Espoo, Finland; Aalto University, Espoo, Finland; UC Berkeley, ICSI, Berkeley, CA, United States",Aalto University;Nicira Networks;University of California Berkeley,3,Finland;USA,2,19,10,"There have been several recent proposals for content-oriented network architectures whose underlying mechanisms are surprisingly similar in spirit, but which differ in many details. In this paper we step back from the mechanistic details and focus only on the area where the these approaches have a fundamental difference: naming. In particular, some designs adopt a hierarchical, human-readable names, whereas others use self-certifying names. When discussing a network architecture, three of the most important requirements are security, scalability, and flexibility. In this paper we examine the two different naming approaches in terms of these three basic goals. © 2011 ACM.",content; naming; scalability; security,content; Human-readable; naming; security; Underlying mechanism; Scalability; Network architecture
"Kreibich C., Weaver N., Maier G., Nechaev B., Paxson V.",5,Experiences from Netalyzr with engaging users in end-system measurement,2011,4,"International Computer Science Institute, Berkeley, CA, United States; HIIT, Aalto University, Helsinki, Finland; UC Berkeley, Berkeley, CA, United States",Aalto University;University of California Berkeley,2,Finland;USA,2,11,9,"Netalyzr is a widely used network diagnostic and debugging tool that has collected 259,000 measurement sessions to date. To use Netalyzr, users visit its website, download an applet that proceeds to conduct a suite of tests and measurements, and obtain a summary report detailing the findings. Along with the measurement data, for each session, we record the HTTP referrer that brought the user to the Netalyzr page, the level of trust the user bestowed upon the applet, and any feedback that the user voluntarily left via a form that we include at the bottom of the report page. These data sources illuminate how Netalyzr's users employ the tool, and can provide insights as to how other measurement tools or user surveys involving end-host measurement could effectively involve users. We find that even with little prompting, users leave explicit comments 3% of the time and answer one or more survey questions in 17% of the sessions, reaching up to 44% og sessions during bursts of activity. We also find that significant usage of the tool comes from four types of need: (i) to aid in troubleshooting performance for an on-line game, often via measurement sessions conducted when requested by more sophisticated users in a help forum; (ii) curiosity, often exacerbated by blog postings and other mentions on high-profile websites; (iii) repeat visitors who arrive via a search engine that they used to locate Netalyzr's website; and (iv) IPv6 deployment tests conducted or organized by specialists. © 2011 ACM.",edge-network monitoring; netalyzr; network troubleshooting; user feedback,Blog postings; Data source; Debugging tools; Measurement data; Measurement tools; netalyzr; Network diagnostics; network troubleshooting; On-line games; User feedback; User surveys; Fruits; Program debugging; Program diagnostics; Search engines; Surveys; Measurements
"Arianfar S., Koponen T., Raghavan B., Shenker S.",4,On preserving privacy in content-oriented networks,2011,51,"Aalto University, Helsinki, Finland; Nicira Networks, Palo Alto, CA, United States; ICSI, Berkeley, CA, United States; ICSI/UC Berkeley, Berkeley, CA, United States",Aalto University;Nicira Networks;University of California Berkeley,3,Finland;USA,2,14,12,"The recent literature has hailed the benefits of content-oriented network architectures. However, such designs pose a threat to privacy by revealing a user's content requests. In this paper, we study how to ameliorate privacy in such designs. We present an approach that does not require any special infrastructure or shared secrets between the publishers and consumers of content. In lieu of any informational asymmetry, the approach leverages computational asymmetry by forcing the adversary to perform sizable computations to reconstruct each request. This approach does not provide ideal privacy, but makes it hard for an adversary to effectively monitor the content requests of a large number of users. © 2011 ACM.",content-oriented networking; privacy,content-oriented networking; Informational asymmetry; Shared secrets; Data privacy; Network architecture
"Bjurefors F., Gunningberg P., Rohner C., Tavakoli S.",4,Congestion avoidance in a data-centric opportunistic network,2011,22,"Uppsala University, Uppsala, Sweden",Uppsala University,1,Sweden,1,6,3,"In order to achieve data delivery in an opportunistic network, data is replicated when it is transmitted to nodes within communication reach and that are likely to be able to forward it closer to the destination. This replication and the unpredictable contact times due to mobility necessitate buffer management strategies to avoid buffer overflow on nodes. In this paper, we investigate buffer management strategies based on local forwarding statistics and relevance of the data for other nodes. The results obtained on our emulation platform for opportunistic networks show that strategies with a high data refresh rate achieve the most efficient delivery and generate the smallest overhead on our community and mobility scenarios. © 2011 ACM.",congestion avoidance; data-centric; delay tolerant networks; haggle; opportunistic networks,Congestion avoidance; Data centric; Delay Tolerant Networks; haggle; Opportunistic networks
"Ardakanian O., Keshav S., Rosenberg C.",3,Markovian models for home electricity consumption,2011,57,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; Dept. of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",University of Waterloo,1,Canada,1,33,14,"Modelling home energy consumption is necessary for studying demand-response, transformer sizing, and distribution network simulation. Using an existing classification, we propose parsimonious Markovian reference models of home load for each class. We derive models for on-peak periods, off-peak periods, and mid-peak periods. These models are derived using traces based on fine-grained measurements of electricity consumption in 20 homes over four months. We validate the representativeness of our models in a specific application. © 2011 ACM.",electrical grid; load modelling; markov chain,Distribution network; Electrical grids; Electricity-consumption; Load modelling; Markov Chain; Markovian; Markovian model; Off-peak periods; Reference models; Computer networks; Energy utilization; Markov processes; Computer simulation
"Raghavan B., Ma J.",2,Networking in the long emergency,2011,18,"ICSI, Berkeley, CA, United States; UC Berkeley, Berkeley, CA, United States",University of California Berkeley,1,USA,1,13,13,"We explore responses to a scenario in which the severity of a permanent energy crisis fundamentally limits our ability to maintain the current-day Internet architecture. In this paper, we review why this scenario - whose vague outline is known to many but whose consequences are generally understood only by the scientists who study it - is likely, and articulate the specific impacts that it would have on network infrastructure and networking research. In light of this, we propose a concrete research agenda to address the networking needs of an energy-deprived society. © 2011 ACM.",energy; internet architecture; resource limits,Concrete research; energy; Energy crisis; internet architecture; Network infrastructure; resource limits; Energy policy; Internet; Telecommunication networks; Network architecture
"Sun P., Yu M., Freedman M.J., Rexford J.",4,Identifying performance bottlenecks in CDNs through TCP-level monitoring,2011,15,"Dept. of Computer Science, Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,13,7,"Content distribution networks (CDNs) need to make decisions, such as server selection and routing, to improve performance for their clients. The performance may be limited by various factors such as packet loss in the network, a small receive buffer at the client, or constrained server CPU and disk resources. Conventional measurement techniques are not effective for distinguishing these performance problems: application-layer logs are too coarse-grained, while network-level traces are too expensive to collect all the time. We argue that passively monitoring the transport-level statistics in the server's network stack is a better approach. This paper presents a tool for monitoring and analyzing TCP statistics, and an analysis of a CoralCDN node in PlanetLab for six weeks. Our analysis shows that more than 10% of connections are server-limited at least 40% of the time, and many connections are limited by the congestion window despite no packet loss. Still, we see that clients in 377 Autonomous Systems (ASes) experience persistent packet loss. By separating network congestion from other performance problems, our analysis provides a much more accurate view of the performance of the network paths than what is possible with server logs alone. © 2011 ACM.",content distribution network; performance bottleneck; tcp,Autonomous systems; Coarse-grained; Congestion window; Content distribution networks; Conventional measurements; Network congestions; Network paths; Network stack; Performance bottlenecks; Performance problems; PlanetLab; Server logs; Server selection; tcp; Packet loss; Traffic congestion; Monitoring
"Detti A., Blefari Melazzi N., Salsano S., Pomposini M.",4,CONET: A content centric inter-networking architecture,2011,95,"Department of Electronic Engineering, University of Rome Tor Vergata, Via del Politecnico 1, Rome, Italy",University of Rome Tor Vergata,1,Italy,1,39,34,"CONET is a content-centric inter-network that provides users with a network access to remote named-resources, rather than to remote hosts. Named-resources can be either data (named-data) or service-access-points (named-sap), identified by a network-identifier (a name). CONET interconnects CONET Sub Systems, which can be layer-2 networks, layer-3 networks or couples of nodes connected by a point-to-point link. CONET supports the already proposed ""clean-slate"" and ""overlay"" deployment approaches. In addition, CONET supports a novel ""integration"" approach, which extends the IP layer with a new header option that makes IP itself content-aware. CONET limits the size of name-based routing tables by including only a subset of all named-resources; missing entries are looked up in a name-system and then cached. CONET does not maintain states in network nodes, to deliver contents. © 2011 ACM.",content-centric networking; in-network caching; internet architecture; ip option; route caching; route-by-name,content-centric networking; in-network caching; internet architecture; IP option; Route caching; route-by-name; Internet protocols; Network architecture; Network layers
"Irwin D., Sharma N., Shenoy P.",3,Towards continuous policy-driven demand response in data centers,2011,13,"University of Massachusetts, Amherst, MA, United States",University of Massachusetts Amherst,1,USA,1,18,15,"Demand response (DR) is a technique for balancing electricity supply and demand by regulating power consumption instead of generation. DR is a key technology for emerging smart electric grids that aim to increase grid efficiency, while incorporating significant amounts of clean renewable energy sources. In today's grid, DR is a rare event that only occurs when actual peak demands exceed the expected peak. In contrast, smart electric grids incentivize consumers to engage in continuous policy-driven DR to 1) optimize power consumption for time-of-use pricing and 2) deal with power variations from non-dispatchable renewable energy sources. While data centers are well-positioned to exploit DR, applications must cope with significant, frequent, and unpredictable changes in available power by regulating their energy footprint. The problem is challenging since data centers often use distributed storage systems that co-locate computation and storage, and serve as a foundation for a variety of stateful distributed applications. As a result, existing approaches that deactivate servers as power decreases do not translate well to DR, since important application-level state may become completely unavailable. In this paper, we propose a DR-compatible storage system that uses staggered node blinking patterns combined with a balanced data layout and popularity-based replication to optimize I/O throughput, data availability, and energy-efficiency as power varies. Initial simulation results show the promise of our approach, which increases I/O throughput by at least 25% compared to an activation approach when adjusting to real-world wind and price fluctuations. © 2011 ACM.",blink; power; renewable energy; storage,blink; Blinking pattern; Data availability; Data centers; Data layouts; Demand response; Distributed applications; Distributed storage system; Electric grids; Electricity supply; Grid efficiency; Key technologies; Peak demand; Policy driven; power; Power variations; Price fluctuation; Rare event; Regulating power; Renewable energies; Renewable energy source; Storage systems; Time-of-use pricing; Unpredictable changes; Computer networks; Distributed computer systems; Economics; Energy efficiency; Energy policy; Energy storage; Natural resources; Optimization; Renewable energy resources; Smart power grids
"Shanbhag S., Schwan N., Rimac I., Varvello M.",4,SoCCeR: Services over content-centric routing,2011,69,"University of Massachusetts, Amherst, MA, United States; Bell Labs., Alcatel-Lucent, Stuttgart, Germany; Bell Labs., Alcatel-Lucent, Holmdel, NJ, United States",Bell Labs;University of Massachusetts Amherst,2,Germany;USA,2,18,9,"Content-Centric Networking (CCN) and Service-Centric Networking(SCN) are two novel paradigms that seek to change the way content and services are perceived. CCN is centered around content distribution, while SCN focuses on dynamic customization of in-network services. We present SoCCeR - Services over Content-Centric Routing. SoCCeR extends CCN with integrated support for service routing decisions leveraging ant-colony optimization. SoCCeR adds a control layer on top of CCN for the manipulation of the underlying Forwarding Information Base (FIB). Without affecting content request and retrieval functionality of CCN, SoCCeR adds SCN functionality to CCN. Illustrating the interaction of SoCCeR with the routing layer, our simulation results show that SoCCeR routes service requests selectively to service instances with lighter loads and is highly responsive to network and service state changes. © 2011 ACM.",ant colony optimization; content-centric; service routing; service-centric; services,Ant-colony optimization; content-centric; Service routing; service-centric; services; Optimization; Computer simulation
"Perino D., Varvello M.",2,A reality check for content centric networking,2011,238,"Bell Labs., Alcatel-Lucent, Villarceaux, France; Bell Labs., Alcatel-Lucent, Holmdel, NJ, United States",Bell Labs,1,France;USA,2,29,24,"Content-Centric Networking (CCN) is a novel networking paradigm centered around content distribution rather than host-to-host connectivity. This change from host-centric to content-centric has several attractive advantages, such as network load reduction, low dissemination latency, and energy efficiency. However, it is unclear whether today's technology is ready for the CCN (r)evolution. The major contribution of this paper is a systematic evaluation of the suitability of existing software and hardware components in today's routers for the support of CCN. Our main conclusion is that a CCN deployment is feasible at a Content Distribution Network (CDN) and ISP scale, whereas today's technology is not yet ready to support an Internet scale deployment. © 2011 ACM.",ccn; router,ccn; Content centric; Content distribution; Content distribution networks; Hardware components; Network load; Systematic evaluation; Internet service providers; Routers; Energy efficiency
"DiBenedetto S., Papadopoulos C., Massey D.",3,Routing policies in named data networking,2011,42,"Computer Science Dept., Colorado State University, Fort Collins, CO, United States",Colorado State University,1,USA,1,16,9,"Modern inter-domain routing with BGP is based on policies rather than finding shortest paths. Network operators devise and implement policies affecting route selection and export independently of others. These policies are realized by tuning a variety of parameters, or knobs, present in BGP. Similarly, NDN, a information-centric future Internet architecture, will utilize a policy-based routing protocol such as BGP. However, NDN allows a finer granularity of policies (content names rather than hosts) and more traffic engineering opportunities. This work explores what routing policies could look like in an NDN Internet. We describe the knobs available to network operators and their possible settings. Furthermore, we explore the economic incentives present in an NDN Internet and reason how they might drive operators to set their policies. © 2011 ACM.",information-centric networking; inter-domain policy,Data networking; Economic incentive; Future internet architecture; information-centric networking; Inter-domain policies; Interdomain Routing; Network operator; Policy-based routing; Route Selection; Routing policies; Shortest path; Traffic Engineering; Internet; Knobs; Network architecture; Telecommunication networks; Internet protocols
"Brundell P., Crabtree A., Mortier R., Rodden T., Tennent P., Tolmie P.",6,The network from above and below,2011,8,"School of Computer Science, University of Nottingham, Nottingham NG8 1BB, United Kingdom",University of Nottingham,1,UK,1,19,13,"Recently, the HCI community has taken a strong interest in problems associated with networking. Many of those problems have also been the focus of much recent networking research, e.g., traffic identification, network management, access control. In this paper we consider these two quite different viewpoints of the problems specifically associated with home networking. Focusing on traffic identification as a core capability required by much recent HCI work, we explore the mismatch between the approaches the two communities have taken, and suggest some resulting challenges and directions for future work. © 2011 ACM.",application identification; ethnographic fieldwork; home networks,Application identification; ethnographic fieldwork; Home Networking; Home networks; Traffic identification; Access control; Personal communication systems; Network management
"Bischof Z.S., Otto J.S., S‡nchez M.A., Rula J.P., Choffnes D.R., Bustamante F.E.",6,Crowdsourcing ISP characterization to the network edge,2011,39,"Northwestern University, Evanston, IL, United States; University of Washington, Seattle, WA, United States",Northwestern University;University of Washington at Seattle,2,USA,1,10,6,"Evaluating and characterizing Internet Service Providers (ISPs) is critical to subscribers shopping for alternative ISPs, companies providing reliable Internet services, and governments surveying the coverage of broadband services to its citizens. Ideally, ISP characterization should be done at scale, continuously, and from end users. While there has been significant progress toward this end, current approaches exhibit apparently unavoidable tradeoffs between coverage, continuous monitoring and capturing user-perceived performance. In this paper, we argue that network-intensive applications running on end systems avoid these tradeoffs, thereby offering an ideal platform for ISP characterization. Based on data collected from 500,000 peer-to-peer BitTorrent users across 3,150 networks, together with the reported results from the U.K. Ofcom/SamKnows studies, we show the feasibility of this approach to characterize the service that subscribers can expect from a particular ISP. We discuss remaining research challenges and design requirements for a solution that enables efficient and accurate ISP characterization at an Internet scale. © 2011 ACM.",broadband access networks; characterization; isp,BitTorrent; Broad-band access networks; Broadband service; Continuous monitoring; Crowdsourcing; Design requirements; End systems; End users; Internet services; isp; Network edges; Network-intensive applications; Peer to peer; Research challenges; Broadband networks; Characterization; Distributed computer systems; Internet service providers; Web services; Peer to peer networks
"Joumblatt D., Teixeira R., Chandrashekar J., Taft N.",4,Performance of networked applications: The challenges in capturing the user's perception,2011,3,"CNRS, UPMC Sorbonne Universites, Paris, France; Technicolor, Palo Alto, CA, United States",UPMC Sorbonne UniversitŽs,1,France;USA,2,18,11,"There is much interest recently in doing automated performance diagnosis on user laptops or desktops. One interesting aspect of performance diagnosis that has received little attention is the user perspective on performance. To conduct research on both end-host performance diagnosis and user perception of network and application performance, we designed an end-host data collection tool, called HostView. HostView not only collects network, application and machine level data, but also gathers feedback directly from users. User feedback is obtained via two mechanisms, a system-triggered questionnaire and a user-triggered feedback form, that for example asks users to rate the performance of their network and applications. In this paper, we describe our experience with the first deployment of HostView. Using data from 40 users, we illustrate the diversity of our users, articulate the challenges in this line of research, and report on initial findings in correlating user data to system-level data. © 2011 ACM.",end-host measurement; network performance diagnosis; user experience,Application performance; Data collection tools; Feedback forms; Machine level; network performance diagnosis; Networked applications; Performance diagnosis; System levels; User data; User experience; User feedback; User perceptions; Network performance; Laptop computers
"Wac K., Ickin S., Hong J.-H., Janowski L., Fiedler M., Dey A.K.",6,Studying the experience of mobile applications used in different contexts of daily life,2011,23,"Institute of Services Science, University of Geneva, Switzerland; School of Computing, Blekinge Tekniska Hogskola, Sweden; Human Computer Interaction, Carnegie Mellon University, Pennysylvenia, PA, United States; Department of Telecommunication, AGH University, Poland",AGH University;Carnegie Mellon University;University of Genoa,3,Poland;Sweden;Switzerland;USA,4,22,19,"Mobile applications and services increasingly assist us in our daily life situations, fulfilling our needs for information, communication, entertainment or leisure. However, user acceptance of a mobile application depends on at least two conditions; the application's perceived Quality of Experience (QoE) and the appropriateness of the application to the user's situation and context. Yet, there is generally a weak understanding of a mobile user's QoE and the factors influencing it. The mobile user's experience is related to the Quality of Service (QoS) provided by the underlying service and network infrastructures, which provides a starting point for our work. We present ""work-in- progress"" results from an ongoing study of Android phone users. In this study, we aim to derive and improve understanding of their QoE in different situations and daily life environments. In particular, we evaluate the user's qualitative QoE for a set of widely used mobile applications in the users' natural environments and different contexts, and we analyze this experience and its relation to the underlying quantitative QoS. In our approach we collect both QoE and QoS measures through a combination of user, application and network input from mobile phones. We present initial data acquired in the study and derived from that, a set of preliminary implications for mobile applications design. © 2011 ACM.",mobile application; network performance; quality of experience; quality of service; subjective experience,Daily lives; Daily-life situations; Mobile applications; Mobile applications and services; Mobile users; Natural environments; Network infrastructure; Network inputs; Perceived quality; QoS measure; quality of experience; subjective experience; User acceptance; Global system for mobile communications; Network performance; Quality of service; Telephone sets; Telephone circuits
"Carofiglio G., Gallo M., Muscariello L.",3,Bandwidth and storage sharing performance in information centric networking,2011,144,"Bell Labs., Alcatel-Lucent, Paris, France; Orange Labs., France Telecom, Paris, France",Bell Labs,1,France,1,19,18,"Internet usage has dramatically evolved towards content dissemination and retrieval, whilst the underlying infrastructure remains tied up to hosts interconnection. Information centric networking (ICN) proposals have recently emerged to rethink Internet foundations and design a natively content-centric network environment. Important features of such networks are the availability of built-in network storage and of receiver-driven chunk-level transport, whose interaction significantly impacts overall system and user performance. In the paper, we provide an analytical characterization of statistical bandwidth and storage sharing, under fairly general assumption on total demand, topology, content popularity and limited network resources. A closed-form expression for average content delivery time is derived and its accuracy confirmed by event-driven simulations. Finally, we present some applications of our model, leveraging on explicit formulae for the optimal dimensioning and localization of storage resources. © 2011 ACM.",information-centric networking,Analytical characterization; Closed-form expression; Content delivery; Content dissemination; Event-driven simulations; Explicit formula; information-centric networking; Internet usage; Network environments; Network resource; Network storage; Statistical bandwidths; Storage resources; Storage sharing; User performance; Internet; Telecommunication networks; Bandwidth
"Schatz R., Egger S.",2,Vienna surfing - Assessing mobile broadband quality in the field,2011,21,"Telecommunications Research, Center Vienna - FTW, Donau City Strasse 1, 1220 Vienna, Austria","FTW,Austria",1,Austria,1,27,26,"This paper presents our findings from a mobile broadband QoE field trial conducted in the city of Vienna, Austria. Using their own laptops in everyday contexts, participants regularly assessed the quality of their mobile broadband connection (tasks: web surfing, file downloads) which in the background was manipulated via traffic shaping throughout a period of three weeks. We discuss our study setup and observations of field trial participant behavior (rating patterns, times, contexts, etc.) as well as the results and lessons learned from correlating end user QoE ratings with measurements performed at client and network level. In addition, we compare our results with those from similar lab experiments, showing that the two evaluation contexts (lab, field) cannot be used interchangeably due to deviant QoE rating behavior of participants. © 2011 ACM.",acceptability; lab and field trials; quality of experience; quality of service; web qoe,"acceptability; End users; Field trial; Mobile broadband; Network level; quality of experience; Rating pattern; Traffic-shaping; Vienna , Austria; web qoe; Web surfing; Laptop computers; User interfaces; Quality of service"
"Wang X.S., Choffnes D., Gage Kelley P., Greenstein B., Wetherall D.",5,Measuring and predicting web login safety,2011,1,"University of Washington, Seattle, WA, United States; Carnegie Mellon University, Pittsburgh, PA, United States; Google, Seattle, WA, United States",Carnegie Mellon University;Google;University of Washington at Seattle,3,USA,1,14,7,"Users increasingly entrust websites with their personal and sensitive information. Sites commonly protect this information using user-supplied credentials (i.e., logins). We conducted a measurement study of top websites and surprisingly found that they transmit these credentials in the clear, thus leaving them vulnerable to eavesdropping. To make matters worse, users are often unaware of this threat because sites and browsers reflect little information about how logins are handled. As a first step towards solving this problem, we develop techniques for measuring logins on browsers to predict how logins would be handled before they are submitted. We demonstrate that achieving this goal requires instrumentation at the application layer and inside browsers. Specifically, network traces are not sufficient for determining login safety in general due to application-layer encryption; similarly, application-layer traces are insufficient because login submission logic may be generated in the browser at runtime. Based on a measurement study using login pages gathered from popular sites in addition to those visited by users through normal Web browsing, we found such predictions to be quite challenging due to a lack of any standard formats for Web logins. However, by applying a carefully chosen set of rules when measuring logins, we almost always correctly predict how logins will be handled. © 2011 ACM.",encryption; https; personal information; web logins,Application layers; https; Log-in page; Measurement study; Personal information; Runtimes; Sensitive informations; Set of rules; Standard format; Web browsing; web logins; Cryptography; Forecasting; User interfaces; HTTP
"Zhu Z., Wang S., Yang X., Jacobson V., Zhang L.",5,ACT: Audio conference tool over named data networking,2011,57,"UCLA, Los Angeles, CA, United States; Tsinghua University, Beijing, China; PARC, Palo Alto, CA, United States",Tsinghua University,1,China;USA,2,24,20,"In this paper we present the design of an audio conference tool, which is one of our efforts to explore application de- signs on top of Named Data Networking. Instead of rely- ing on centralized services as current implementations do, ACT takes a named data approach to discover ongoing conferences as well as speakers in each conference, and to fetch voice data from individual speakers. The resulting design is completely distributed and robust against component failures. We discuss design alternatives and tradeoffs, scalability and security considerations, as well as remaining issues for future work. © 2011 ACM.",audio conferencing; decentralized; named data networking,Audio conferences; Audio conferencing; Component failures; Data networking; decentralized; Design alternatives; Security considerations; Voice data; Design
"D'Ambrosio M., Dannewitz C., Karl H., Vercellone V.",4,MDHT: A hierarchical name resolution service for information-centric networks,2011,76,"Telecom Italia, Torino, Italy; University of Paderborn, Paderborn, Germany",University of Paderborn,1,Germany;Italy,2,18,8,"Information-centric network architectures are an increasingly important approach for future Internet architectures. Several approaches are based on a non-hierarchical identifier (ID) namespace that requires some kind of global Name Resolution Service (NRS) to translate the object IDs into network addresses. Building a world-wide NRS for such a namespace with 1015 expected IDs is challenging because of requirements such as low latency, efficient network utilization, and anycast routing. In this paper, we present an NRS called Multi-level Distributed Hash Table (MDHT). It provides name-based anycast routing, can support constant hop resolution, and fulfills the afore mentioned requirements. A scalability assessment shows that our system can scale to the Internet level, managing 1015 objects with today's storage technology and 1/10th of today's DNS nodes. The evaluation indicates that a non-hierarchical namespace can be adopted on a global scale, opening up several design alternatives for information-centric network architectures. © 2011 ACM.",flat namespace; hierarchical dht; information-centric; name resolution; name-based routing,hierarchical dht; information-centric; Name resolution; name-based routing; Namespaces; Internet; Telecommunication networks; Network architecture
"PervilŠ M., Kangasharju J.",2,Cold air containment,2011,10,"Department of Computer Science, University of Helsinki, Helsinki, Finland; Helsinki Institute for Information Technology, University of Helsinki, Helsinki, Finland",Helsinki Institute for Information Technology;University of Helsinki,2,Finland,1,18,8,"This article describes two benchmark studies involving the cooling technique known as cold aisle containment (CAC). One test case studies a 26U server rack operating on unconditioned outside air only in a carefully controlled setup. The other examines a server room with a power draw of over 80 kW during normal operation. In both cases we measure how incorporating CAC changes the air flow, electricity consumption, operating temperatures, and cooling requirements. Our results show how the air flow separation affects the temperatures in the server room and verify that using CAC can reduce CRAC power by roughly a fifth. © 2011 ACM.",cooling; empirical system reliability; sustainable computing,Air flow; Benchmark study; Cold air; Cooling technique; Electricity-consumption; empirical system reliability; Normal operations; Operating temperature; Power draw; sustainable computing; Test case; Air; Computer networks; Cooling
"Tsilopoulos C., Xylomenos G.",2,Supporting diverse traffic types in information centric networks,2011,46,"Mobile Multimedia Laboratory, Athens University of Economics and Business, Patision 76, Athens, 10434, Greece",Athens University of Economics and Business,1,Greece,1,17,12,"In this paper we focus on the issue of transferring diverse kinds of information through information-centric networks (ICNs). We argue that the one request per packet mode of operation suggested in the early development of ICN applications is not a good fit for some types of traffic, such as media streams and real-time notifications. To efficiently deliver all kinds of information, we argue that an ICN should not only identify information by its name, it should also be aware of the nature of its traffic. We classify information traffic types based on two characteristics: a) reliable vs. unreliable transfer and b) real-time vs. on-demand delivery. The combination of these two characteristics leads to three broad categories: a) channels, b) on-demand documents and c) real-time documents. To handle all traffic types, we propose two extensions to the CCN architecture: Persistent Interests and Reliable Notifications. We describe how these additions, together with a careful selection of information names, can efficiently support these three categories of information traffic types. © 2011 ACM.",information traffic types; information-centric networks; network layer design,Information traffic; information-centric networks; Media streams; Packet mode; Network layers
"Defrance S., Gendrot R., Le Roux J., Straub G., Tapie T.",5,Home networking as a distributed file system view,2011,3,"Technicolor R and D France, 1, Avenue de Belle Fontaine, 35576 Cesson-SŽvignŽ, France","Technicolor, France",1,France,1,9,8,"Devices forming a Home Network have different capabilities and interfaces, discouraging users to organize their large digital content libraries. To help users, we propose to organize the Home Network according to a gateway-centric architecture, where the content access unification is realized at the file system level and where no additional software installation on devices is required. Solutions for realizing this unification individually exist for the various devices making up the Home Network (UPnP/DLNA devices, personal computers, cloud storage systems, etc). Unifying the content access at the file system level offers a powerful lever for many legacy applications, as far as these applications can access all shared data in the Home Network. Users can thus continue to use their PC's file manager or favorite media player to browse or display shared content. An indexing application, running on the gateway, possibly managed by the ISP and accessible from any device via a simple web interface, enables more powerful content retrieval and user experience. Such application may be enriched to offer additional services like content format adaptation, duplication detection or automatic backup. Lastly we describe how this gateway-centric architecture can be leveraged by cloud applications such as distributed storage systems. Copyright 2011 ACM.",Backup; Cloud; Content Sharing; Distributed; Home network; Indexation; Storage; Virtual file system,Backup; Content Sharing; Distributed; File systems; Home networks; Indexation; Carrier communication; Computer architecture; Data storage equipment; Digital devices; Digital libraries; Network architecture; Personal communication systems; Personal computers; User interfaces; Gateways (computer networks)
"Lakshminarayanan K., Seshan S., Steenkiste P.",3,Understanding 802.11 performance in heterogeneous environments,2011,12,"Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,15,10,"The availability of unlicensed spectrum coupled with the increasing popularity of wireless communication has given rise to a diverse range of wireless technologies that compete for spectrum. In particular, 802.11 devices face a host of problems such as interference with other 802.11 devices (hidden terminals) as well as with technologies like Bluetooth and ZigBee. Understanding how the medium is utilized and inferring the cause of interference, based on observations from a single wireless node, is hard. Past work has used monitoring infrastructures to detect interference between 802.11 nodes in enterprise networks. In this paper, we try to answer the question: ""how can we enable users to reason about wireless performance variations without requiring elaborate instrumentation and infrastructure support?"". We propose WiMed, a tool that uses only local measurements from commodity 802.11 NICs (at the node being diagnosed) to construct a time map of how the medium is utilized. We have implemented a WiMed prototype using the MadWifi driver for Atheros NICs. Early results show that WiMed is useful and can characterize non-802.11 interference better than existing systems. Copyright 2011 ACM.",802.11; Bluetooth; Diagnosis; Heterogeneous environments; Interference; Monitoring; Performance; Wireless networks,802.11; Atheros; Diverse range; Enterprise networks; Existing systems; Heterogeneous environments; Hidden terminal; Local measurement; MADWIFI; Performance; Performance variations; Unlicensed spectrum; Wireless communications; Wireless nodes; Wireless technologies; Zig-Bee; Bluetooth; Personal communication systems; Wireless telecommunication systems; Monitoring
"Cui H., Biersack E.",2,Trouble shooting interactive Web sessions in a home environment,2011,10,"Eurecom Sophia, Antipolis, France",EURECOM,1,France,1,19,8,"Home clients can use their access to the Internet for different purposes such as file sharing via P2P applications, gaming, or Web browsing; the last one is the focus of this work. When browsing the Web, the time elapsed between the click on a URL and the rendering of the Web page, referred to as page load time, is the key performance metric. When the page load time is higher than a few seconds, the user experience suffers significantly. We have developed a three-tier system that (i) captures in the browser the events necessary to measure the page load time (ii) captures at the network access all incoming and outgoing packets, and (iii) correlates the measurements made at different machines. The capture at packet level allows us to compute the contribution of the various steps that affect the page load time such as DNS resolution, server response time, data transfer time. Correlating the observations made at different machines that share a major part of the network elements can help identifying the root causes for high page load times. We will present the architecture of our system and some examples that illustrate its use. Copyright 2011 ACM.",Performance evaluation; Troubleshooting; Web browsing,File Sharing; Home environment; Network access; Network element; P2P applications; Packet level; Performance evaluation; Performance metrices; Root cause; Three-tier systems; User experience; Web browsing; Web page; Web sessions; Computer architecture; Data transfer; Personal communication systems; User interfaces; Electronic document exchange
"Sundaresan S., Feamster N., Teixeira R., Tang A., Edwards W.K., Grinter R.E., Chetty M., De Donato W.",8,Helping users shop for ISPs with internet nutrition labels,2011,13,"CNRS, UPMC Sorbonne Univ., Paris, France; University of Napoli Federico II, Napoli, Italy; Georgia Tech., Atlanta, United States",Georgia Tech;University of Napoli Federico II,2,France;Italy;USA,3,19,18,"When purchasing home broadband access from Internet service providers (ISPs), users must decide which service plans are most appropriate for their needs. Today, ISPs advertise their available service plans using only generic upload and download speeds. Unfortunately, these metrics do not always accurately reflect the varying performance that home users will experience for a wide range of applications. In this paper, we propose that each ISP service plan carry a ""nutrition label"" that conveys more comprehensive information about network metrics along many dimensions, including various aspects of throughput, latency, loss rate, and jitter. We first justify why these metrics should form the basis of a network nutrition label. Then, we demonstrate that current plans that are superficially similar with respect to advertised download rates may have different performance according to the label metrics. We close with a discussion of the challenges involved in presenting a nutrition label to users in a way that is both accurate and easy to understand. Copyright 2011 ACM.",Access networks; Benchmarking; BISMark; Broadband networks,Access network; BISMark; Broadband access; Comprehensive information; Home users; Loss rates; Network metrics; Service plan; Jitter; Nutrition; Personal communication systems; Telecommunication networks; Internet service providers
"Song H.H., Ge Z., Mahimkar A., Wang J., Yates J., Zhang Y.",6,Analyzing IPTV set-top box crashes,2011,2,"University of Texas at Austin, Austin, TX, United States; AT and T Labs - Research, Florham Park, NJ, United States",AT and T Labs;University of Texas at Austin,2,USA,1,15,10,"Recent advances in residential broadband access technologies have led to a wave of commercial IPTV deployments. As IPTV services are rolled out at scale, it is essential for IPTV systems to maintain ultra-high reliability and performance. A major issue that disrupts IPTV service is the crash of the set-top box (STB) software. The STB directly resides inside the consumer's home network and provides the essential interface to both the user and the network to deliver rich content that goes well beyond traditional TV. To understand the potential causes of STB crashes, we perform an indepth statistical analysis focused on the relationships between STB crashes, video stream content, and user activities. Our initial results suggest that (i) impaired video streams may cause STB crashes, and (ii) continuous STB usage may gradually degrade the STB health over time. Copyright 2011 ACM.",Analysis; Crash; Home networks; IPTV; Set-top box; Video,Analysis; Crash; Home networks; Set top box; Video; Carrier communication; Personal communication systems; Television broadcasting; Video streaming; IPTV
"Banerjee N., Rollins S., Moran K.",3,Automating energy management in green homes,2011,26,"University of Arkansas, Fayetteville, AR, United States; University of San Francisco, San Francisco, CA, United States",University of Arkansas;University of San Francisco,2,USA,1,22,13,"Homes powered fully or partially by renewable sources such as solar are becoming more widely adopted, however energy management strategies in these environments are lacking. This paper presents the first results of a study that explores home automation techniques for achieving better utilization of energy generated by renewable technologies. First, using a network of off-the-shelf sensing devices, we observe that energy generation and consumption in an off-grid home is both variable and predictable. Moreover, we find that reactive energy management techniques are insufficient to prevent critical battery situations. We then present a recommendation based system for helping users to achieve better utilization of resources. Our study demonstrates the feasibility of three recommendation components: an early warning system that allows users of renewable technologies to make more conservative decisions when energy harvested is predicted to be low; a task rescheduling system that advises users when high-power appliances such as clothes dryers should be run to optimize overall energy utilization; and an energy conservation system that identifies sources of energy waste and recommends more conservative usage. Copyright 2011 ACM.",Human factors,Early Warning System; Energy conservation systems; Energy generations; Energy management strategies; High-power; Home automation; Management techniques; Off-grids; Renewable sources; Renewable technology; Sensing devices; Sources of energy; Energy harvesting; Energy utilization; Human engineering; Personal communication systems; Sensors; Solar energy; Energy conversion
"Li Y., Papagiannaki D., Sheth A.",3,Uplink traffic control in home 802.11 wireless networks,2011,5,"Carnegie Mellon University, United States; Telefonica Research, Spain; Technicolor Research, Spain","Carnegie Mellon University;Technicolor, France;Telefonica Research",3,Spain;USA,2,21,16,"IEEE 802.11 wireless networks become increasing more complex and interesting inside homes. A number of home automation, home security, and entertainment products rely on wireless technologies for easy deployment without the need for wiring. Moreover, a number of such applications are fundamentally changing the traffic mix of a home wireless network, resulting in uplink traffic that is not only triggered by the users but that could potentially be nearly continuous in nature, such as wireless home security products, where each individual camera is likely to stream large amounts of data in high traffic areas. Given the diversity of traffic sources and their importance to the user, wireless home APs today can ship with Wireless Multimedia (WMM) support that prioritizes VoIP and video traffic for better user experience. In this paper, however, we note that the type and importance of applications to a home user may be much more diverse than 4 traffic classes could accommodate. In response, we survey the landscape of possible solution in particular when it comes to pacing traffic sources inside the network. We discuss the tradeoffs that such a design space exposes and test the performance of several solutions using ns3 simulations. Finally, we note that instead of a strict prioritization of traffic streams, a simple mechanism by which the user can pace traffic to provision more resource to the traffic of importance may be sufficient. Copyright 2011 ACM.",IEEE 802.11; Uplink Traffic Control; WMM,802.11 wireless networks; Design spaces; High traffic areas; Home automation; Home security; Home users; IEEE 802.11 wireless networks; IEEE 802.11s; Large amounts of data; Possible solutions; Prioritization; Traffic class; Traffic mix; Traffic sources; Traffic streams; Uplink Traffic Control; User experience; Video traffic; Wireless multimedia; Wireless technologies; WMM; Internet telephony; Personal communication systems; Standards; Wireless telecommunication systems; Wireless networks
"Dong C., Dulay N.",2,Argumentation-based fault diagnosis for home networks,2011,8,"Department of Computing, Imperial College London, United Kingdom",Imperial College London,1,UK,1,17,6,"Home networks are a fast growing market but managing them is a difficult task, and diagnosing faults is even more challenging. Current fault management tools provide comprehensive information about the network and the devices but it is left to the user to interpret and reason about the data and experiment in order to find the cause of a problem. Home users may not have motivation or time to learn the required skills. Furthermore current tools adopt a closed approach which hardcodes a knowledge base, making them hard to update and extend. This paper proposes an open fault management framework for home networks, whose goal is to simplify network troubleshooting for non-expert users. The framework is based on assumption-based argumentation that is an AI technique for knowledge representation and reasoning. With the underlying argumentation theory, we can easily capture and model the diagnosis procedures of network administrators. The framework is rule-based and extensible, allowing new rules to be added into the knowledge base and diagnostic strategies to be updated on the fly.The framework can also utilise external knowledge and make distributed diagnosis. Copyright 2011 ACM.",Argumentation; Fault diagnosis; Home networks,AI techniques; Argumentation; Argumentation theory; Comprehensive information; Diagnosis procedure; Diagnostic strategy; Distributed diagnosis; External knowledge; Fault management; Growing markets; Home networks; Home users; Knowledge base; Knowledge representation and reasoning; Network administrator; Network troubleshooting; Open faults; Rule based; Electric fault currents; Information management; Knowledge based systems; Knowledge representation; Personal communication systems; Network management
"Jiang J., Casetti C.",2,Socially-aware gateway-based content sharing and backup,2011,1,"Dipartimento di Elettronica, Politecnico di Torino, Italy",Politecnico di Torino,1,Italy,1,3,3,"The amount of data that home users generate, store, and share with their friends via a multitude of devices has grown significantly in the past few years. In our paper, we assume that every household is equipped with a home gateway that stores and manages the data collected by the home users. To accelerate the content sharing and backup for such users, we propose an efficient backup scheme that hinges upon gateway interactions exploiting the users' social networking information. We formulate this problem as a Budgeted Maximum Coverage (BMC) problem and we numerically compute the optimal content backup solution under a synthetic social network scenario. Then, we compare it with two different content placement strategies for gateways with various quota sizes, in a realistic synthetic social network. Copyright 2011 ACM.",Content backup; Home gateway; Socially-aware,Content backup; Content Sharing; Home gateway; Home users; Maximum coverage; Optimal content; Placement strategy; Social Networks; Socially-aware; Personal communication systems; Gateways (computer networks)
"Yiakoumis Y., Yap K.-K., Katti S., Parulkar G., McKeown N.",5,Slicing home networks,2011,78,"Stanford University, United States",Stanford University,1,USA,1,19,13,"Despite the popularity of home networks, they face a number of systemic problems: (i) Broadband networks are expensive to deploy; and it is not clear how the cost can be shared by several service providers; (ii) Home networks are getting harder to manage as we connect more devices, use new applications, and rely on them for entertainment, communication and work-it is common for home networks to be poorly managed, insecure or just plain broken; and (iii) It is not clear how home networks will steadily improve, after they have been deployed, to provide steadily better service to home users. In this paper we propose slicing home networks as a way to overcome these problems. As a mechanism, slicing allows multiple service providers to share a common infrastructure; and supports many policies and business models for cost sharing. We propose four requirements for slicing home networks: bandwidth and traffic isolation between slices, independent control of each slice, and the ability to modify and improve the behavior of a slice. We explore how these requirements allow cost-sharing, out-sourced management of home networks, and the ability to customize a slice to provide higher-quality service. Finally, we describe an initial prototype that we are deploying in homes. Copyright 2011 ACM.",Home networks; Network slic-ing; OpenFlow; Software-defined networks,Business models; Cost sharing; Home networks; Home users; Independent control; Multiple services; New applications; OpenFlow; Service provider; Software-defined networks; Traffic isolation; Cost effectiveness; Personal communication systems; Network management
"Piamrat K., Fontaine P.",2,Coordinated architecture for wireless home networks,2011,5,"Technicolor, 1, avenue de Belle Fontaine, 35576 Cesson-SŽvignŽ, France","Technicolor, France",1,France,1,11,9,"Today's services in home networks are no longer limited to basic applications such as email or file transfer but also include multimedia delivery for supporting home entertainment. In addition, wireless network is wide spreading in home as users become mobile and now expect to run their applications in wireless environment the same way they do over wired network. As a consequence, entertainment services should be guaranteed in home wireless networks as well. Ensuring quality of service raises new challenges as open wireless conditions result in instability and vulnerability to all types of interference and disturbance. Especially, IPTV application requires not only throughput but also stability on a wide coverage area and with low packet loss. Therefore, good reception level needs to be guaranteed in the whole house in order to use the highest modulation, and interferences need to be controlled when several transmitters share the same channel. In this paper, we present a new architecture for future home networks, in which multiple access points can be easily deployed on the same channel with coordination established to provide reliable transmission of several IPTV applications in the house. The mechanism is built on top of the DCF and has two main advantages: fully compatible with 802.11 standard and applicable to downlink and uplink streams. For our case study, we use NS-3 to evaluate performances of the Coordinated-APs compared to Single-AP and Distributed-APs approaches, in realistic home environment. The obtained results demonstrate better channel utilization and collision reduction that guarantee four IPTV streams in the coordinated approach. Behaviors at lower layers are presented in order to provide a better understanding of resource utilization. Moreover, discussions about feasibility of the solution in real world scenario are also provided. Copyright 2011 ACM.",Coordination function; Home networks; IPTV application; Quality of service; Wireless networks,Basic application; Channel utilization; Coordination functions; Coverage area; Entertainment services; File transfers; Fully compatible; Home entertainment; Home environment; Home networks; Multimedia delivery; Multiple access points; Real-world scenario; Reliable transmission; Resource utilizations; Wired networks; Wireless environment; Wireless home network; IPTV; Multimedia services; Personal communication systems; Quality control; Quality of service; Telecommunication networks; Wireless networks; Network architecture
"Bauer S., Clark D., Lehr W.",3,Powerboost,2011,8,"MIT, 32 Vassar St, G-814 Cambridge MA 02139, United States",MIT,1,USA,1,20,17,"This paper examines a feature present in some cable broadband networks that can enable, for multiple megabytes of data, higher data rates than what can be sustained over the long term. Commonly referred to as ""Powerboost,"" this feature represents a strategy for sharing unused link capacity among users of cable broadband networks. We explain how Powerboost works under current implementations, consider how it may impact the experiences of broadband users, and examine the challenges that Powerboost poses for the design of performance metrics that may be used to evaluate the service quality of broadband ISPs. We present sample measurement data for a Powerboost enabled broadband connection and discuss how such measurements might be reported in the current large scale broadband measurement study led by the FCC. Copyright 2011 ACM.",Applications; Broadband access; Token bucket,Broadband access; Broadband connection; Broadband measurements; Broadband users; Data rates; Link capacities; Measurement data; Performance metrics; Service Quality; Token bucket; Cables; Internet service providers; Personal communication systems; Broadband networks
"Mondal M., Viswanath B., Clement A., Druschel P., Gummadi K.P., Mislove A., Post A.",7,Limiting large-scale crawls of social networking sites,2011,9,"MPI-SWS, Germany; Northeastern University, United States",Northeastern University,1,Germany;USA,2,19,16,"Online social networking sites (OSNs) like Facebook and Orkut contain personal data of millions of users. Many OSNs view this data as a valuable asset that is at the core of their business model. Both OSN users and OSNs have strong incentives to restrict large scale crawls of this data. OSN users want to protect their privacy and OSNs their business interest. Traditional defenses against crawlers involve rate- limiting browsing activity per user account. These defense schemes, however, are vulnerable to Sybil attacks, where a crawler creates a large number of fake user accounts. In this paper, we propose Genie, a system that can be deployed by OSN operators to defend against Sybil crawlers. Genie is based on a simple yet powerful insight: the social network itself can be leveraged to defend against Sybil crawlers. We first present Genie's design and then discuss how Genie can limit crawlers while allowing browsing of user profiles by normal users.",Network-based Sybil defense; Social networks; Sybil attacks,Computer crime; Testbeds; Business models; Facebook; Network-based; Social networking sites; Social Networks; Sybil attack; User profile; Social networking (online)
Ciuffoletti A.,1,Monitoring a virtual network infrastructure: An IaaS perspective,2010,2,"Department of Computer Science, University of Pisa, Italy; ERCIM CoreGRIDWorking Group, Italy",University of Pisa,1,Italy,1,19,12,"Infrastructure as a Service (IaaS) providers keep extending with new features the computing infrastructures they offer on a pay per use basis. In this paper we explore reasons and opportunities to include networking within such features, meeting the demand of users that need composite computing architectures similar to Grids. The introduction of networking capabilities within IaaSs would further increase the potential of this technology, and also foster an evolution of Grids towards a confluence, thus incorporating the experiences matured in this environment. Network monitoring emerges as a relevant feature of such virtual architectures, which must exhibit the distinguishing properties of the IaaS paradigm: scalability, dynamic configuration, accounting. Monitoring tools developed with the same purpose in Grids provide useful insights on problems and solutions.",GRID applications; Network-enabled IaaS,Computing architecture; Computing infrastructures; Dynamic configuration; Grid applications; Monitoring tools; Network Monitoring; Network-enabled IaaS; Pay-per-use; Virtual architecture; Virtual networks; Network architecture
Allman M.,1,On building special-purpose social networks for emergency communication,2010,0,"International Computer Science Institute, Berkeley, CA, United States",University of California Berkeley,1,USA,1,4,0,"In this paper we propose a system that will allow people to communicate their status with friends and family when they find themselves caught up in a large disaster (e.g., sending ""I'm fine"" in the immediate aftermath of an earthquake). Since communication between a disaster zone and the non-affected world is often highly constrained we design the system around lightweight triggers such that people can communicate status with only crude infrastructure (or even sneaker-nets). In this paper we provide the high level system design, discuss the security aspects of the system and study the overall feasibility of a purpose-built social networking system for communication during an emergency.",Emergency communication; Social networks,Disaster zones; Emergency communication; High-level systems; Social Networks; Social networking (online); Communication
"Ganichev I., Dai B., Godfrey P.B., Shenker S.",4,YAMR: Yet another multipath routing protocol,2010,6,"Computer Science Division, Univ. of California, Berkeley, CA, United States; School of Computer, National University of Defense Technology, China; Dept. of Computer Science, Univ. of Illinois, Urbana-Champaign, IL, United States; UCB, ICSI, United States",National University of Defense Technology,1,China;USA,2,13,11,"Multipath routing is a promising technique to increase the Internet's reliability and to give users greater control over the service they receive. However, past proposals choose paths which are not guaranteed to have high diversity. In this paper, we propose yet another multipath routing scheme (YAMR) for the interdomain case. YAMR provably constructs a set of paths that is resilient to any one inter-domain link failure, thus achieving high reliability in a systematic way. Further, even though YAMR maintains more paths than BGP, it actually requires significantly less control traffic, thus alleviating instead of worsening one of the Internet's scalability problems. This reduction in churn is achieved by a novel hiding technique that automatically localizes failures leaving the greater part of the Internet completely oblivious.",Internet; Reliability; Routing protocols,Control traffic; High reliability; Inter-domain; Link failures; Multi path routing; Multi-path routing schemes; Multipath routing protocols; Scalability problems; Reliability; Routing protocols; Internet
Devlic A.,1,SIP-based context distribution: Does aggregation pay off?,2010,3,"Appear Networks, Royal Institute of Technology (KTH), Kista, Sweden",KTH Royal Institute of Technology,1,Sweden,1,13,7,"Context-aware applications need quickly access to current context information, in order to adapt their behavior before this context changes. To achieve this, the context distribution mechanism has to timely discover context sources that can provide a particular context type, then acquire and distribute context information from these sources to the applications that requested this type of information. This paper reviews the state-of-the-art context distribution mechanisms according to identified requirements, then introduces a resource list-based subscription/notification mechanism for context sharing. This SIP-based mechanism enables subscriptions to a resource list containing URIs of multiple context sources that can provide the same context type and delivery of aggregated notifications containing context updates from each of these sources. Aggregation of context is thought to be important as it reduces the network traffic between entities involved in context distribution. However, it introduces an additional delay due to waiting for context updates and their aggregation. To investigate if this aggregation actually pays off, we measured and compared the time needed by an application to receive context updates after subscribing to a particular resource list (using RLS) versus after subscribing to each of the individual context sources (using SIMPLE) for different numbers of context sources. Our results show that RLS aggregation outperforms the SIMPLE presence mechanism with 3 or more context sources, regardless of their context updates size. Database performance was identified as a major bottleneck during aggregation, hence we used in-memory tables & prepared statements, leading to up to 57% database time improvement, resulting in a reduction of the aggregation time by up to 34%. With this reduction and an increase in context size, we pushed the aggregation payoff threshold closer to 2 context sources.",Aggregation; Context distribution; RLS; SIMPLE; XCAP,Context aware applications; Context distribution; Context information; Context sharing; Database performance; Multiple contexts; Network traffic; Prepared statement; RLS; SIMPLE; XCAP; Agglomeration; Semantics; Internet protocols
"Maeder A., Zein N.",2,OFDMA in the field: Current and future challenges,2010,1,"NEC Network Laboratories Europe, United Kingdom",NEC,1,UK,1,16,14,"OFDMA will be the predominant technology for the air interface of broadband mobile wireless systems for the next decades. In recent years, OFDMA-based networks based on IEEE 802.16, and increasingly also on 3GPP LTE are rolled out for commercial use. This article gives an overview of the main challenges for the deployment and operation of state-of-the-art OFDMA networks, along with an outlook into future developments for 4G and beyond 4G networks.",Deployment; LTE; Network operation; OFDMA; Radio resource management; Survey; WiMAX,Deployment; LTE; Network operations; OFDMA; Radio resource management; Mobile telecommunication systems; Surveys; Wimax; Frequency division multiple access
"Cascarano N., Rolando P., Risso F., Sisto R.",4,iNFAnt: NFA pattern matching on GPGPU devices,2010,21,"Politecnico di Torino, Turin, Italy",Politecnico di Torino,1,Italy,1,21,19,"This paper presents iNFAnt, a parallel engine for regular expression pattern matching. In contrast with traditional approaches, iNFAnt adopts non-deterministic automata, allowing the compilation of very large and complex rule sets that are otherwise hard to treat. iNFAnt is explicitly designed and developed to run on graphical processing units that provide large amounts of concurrent threads; this parallelism is exploited to handle the non-determinism of the model and to process multiple packets at once, thus achieving high performance levels.",CUDA; GPGPU; NFA; Pattern matching; Regular expression,Concurrent threads; CUDA; GPGPU; Graphical processing unit (GPUs); NFA; Non-determinism; Nondeterministic automata; Parallel engines; Performance level; Regular expression pattern matching; Regular expressions; Rule set; Program processors; Pattern matching
"Rutkowski A., Kadobayashi Y., Furey I., Rajnovic D., Martin R., Takahashi T.",6,CYBEX - The cybersecurity information exchange framework (X.1500),2010,9,"Yaana Technologies, United States; NAIST, Japan; DHS, United States; FIRST, United States; MITRE, United States; NICT, Japan",Yaana Technologies,1,Japan;USA,2,20,20,"The cybersecurity information exchange framework, known as CYBEX, is currently undergoing its first iteration of standardization efforts within ITU-T. The framework describes how cybersecurity information is exchanged between cybersecurity entities on a global scale and how the exchange is assured. The worldwide implementation of the framework will eventually minimize the disparate availability of cybersecurity information. This paper provides a specification overview, use cases, and the current status of CYBEX.",Cybersecurity; CYBEX; Information exchange; Security,Current status; Cyber security; CYBEX; Global scale; Information exchange framework; Information exchanges; Security
Krishnamurthy B.,1,I know what you will do next summer,2010,9,"AT and T Labs-Research, United States",AT and T Labs,1,USA,1,8,8,This is a brief journey across the Internet privacy landscape. After trying to convince you about the importance of the problem I will try to present questions of interest and how you might be able to apply your expertise to them.,Anonymization; Identity; Online social networks; Privacy,Anonymization; Identity; Internet privacy; Online social networks; Data privacy
"Gyarmati L., Trinh T.A.",2,Scafida: A scale-free network inspired data center architecture,2010,12,"Network Economics Group, Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Hungary",Budapest University of Technology and Economics,1,Hungary,1,14,14,"Data centers have a crucial role in current Internet architecture supporting content-centric networking. State-of-the-art data centers have different architectures like fat-tree [16, 10], DCell [12], or BCube [11]. However, their architectures share a common property: symmetry. Due to their symmetric nature, a tricky point with these architectures is that they are hard to be extended in small quantities. Contrary to state-of-the-art data center architectures, we propose an asymmetric data center topology generation method called Scafida inspired by scale-free networks; these data centers have not only small diameters and high fault tolerance, inherited by scale-free networks, but can also be scaled in smaller and less homogenous increments. We extend the original scale-free network generation algorithm of Barab‡si and Albert [5] to meet the physical constraints of switches and routers. Despite the fact that our method artificially limits the node degrees in the network, our data center architectures keep the preferable properties of scale-free networks. Based on extensive simulations we present preliminary results that are promising regarding the error tolerance, scalability, and flexibility of the architecture.",Data center; Scale-free network,Common property; Data center architecture; Data centers; Error tolerance; Extensive simulations; Internet architecture; Node degree; Physical constraints; Scale free networks; Topology generation; Computer simulation; Fault tolerance; Network architecture
"Claffy K., Aben E., Auge J., Beverly R., Bustamante F., Donnet B., Friedman T., Fomenkov M., Haga P., Luckie M., Shavitt Y.",11,The 2nd Workshop on Active Internet Measurements (AIMS-2) report,2010,0,"CAIDA, France; RIPE NCC, France; UPMC Paris Universitas, France; Naval Postgraduate School, United States; Northwestern University, United States; Universite Catholique de Louvin, FNRS, France; Eotvos Lorand University, Hungary; University of Waikato, New Zealand; Tel Aviv University, Israel",Eotvos Lorand University;Naval Postgraduate School;Northwestern University;Tel Aviv University;UPMC Sorbonne UniversitŽs;Universite Catholique de Louvain;University of Waikato,7,France;Hungary;Israel;New Zealand;USA,5,21,20,"On February 8-10, 2010, CAIDA hosted the second Workshop on Active Internet Measurements (AIMS-2) as part of our series of Internet Statistics and Metrics Analysis (ISMA) workshops. The goals of this workshop were to further our understanding of the potential and limitations of active measurement research and infrastructure in the wide-area Internet, and to promote cooperative solutions and coordinated strategies to addressing future data needs of the network and security research communities. The three-day workshop included presentations, group discussion and analysis, and focused interaction between participating researchers, operators, and policymakers from all over the world. This report describes the motivation and findings of the workshop, and reviews progress on recommendations developed at the 1st Active Internet MeasurementsWorkshop in 2009 [18]. Slides from the workshop presentations are available at [9].",Active measurement; Codes of ethics; Codes of good practice; Management techniques; Measurement techniques; Validation,Active measurement; Codes of ethics; Good practices; Management techniques; Measurement techniques; Validation; Research; Internet
"Sherry J., Katz-Bassett E., Pimenova M., Madhyastha H.V., Anderson T., Krishnamurthy A.",6,Resolving IP aliases with prespecified timestamps,2010,31,"University of Washington, United States; University of California, San Diego, United States",University of California San Diego;University of Washington at Seattle,2,USA,1,18,14,"Operators and researchers want accurate router-level views of the Internet for purposes including troubleshooting and modeling. However, tools such as traceroute return IP addresses. Because routers may have dozens of IP addresses, or aliases, multiple measurements may return different addresses, obscuring whether they represent the same machine. While many techniques exist to address this issue by identifying some IP aliases, these techniques, even in combination, find only a subset of alias pairs. To improve this state, we design and evaluate a new alias resolution technique using the IP prespecified timestamp option. This option allows a sender to request timestamp values from multiple IP addresses in the same probe. By careful arrangement of these IP addresses, we show that we can infer aliases in many cases. In this paper, we conduct a measurement study of how many routers support IP timestamps, demonstrating that enough honor the option to base our technique on it. Using our technique, and compared to the most accurate alias information available, we find that 94.7% of the aliases identified by our technique are true positives. Further, we show that our IP timestamp-based technique complements existing alias resolution techniques, providing significant gains by discovering previously unidentifiable aliases. Copyright 2010 ACM.",Alias resolution; IP options; IP timestamp,Alias resolution; IP addresss; IP options; Measurement study; Multiple measurements; Resolution techniques; Time stamps; Time-stamp; Timestamp option; Traceroute; Troubleshooting; True positive; Internet; Routers; Internet protocols
"Schatzmann D., MŸhlbauer W., Spyropoulos T., Dimitropoulos X.",4,Digging into HTTPS: Flow-based classification of webmail traffic,2010,31,"ETH Zurich, Switzerland",ETH Zurich,1,Switzerland,1,31,26,"Recently, webmail interfaces, e.g., Horde, Outlook Web Access, and webmail platforms such as GMail, Yahoo!, and Hotmail have seen a tremendous boost in popularity. Given the importance of e-mail for personal and business use alike, and its exposure to imminent threats, there exists the need for a comprehensive view of the Internet mail system, including webmail traffic. In this paper we propose a novel, passive approach to identify webmail traffic solely based on network-level data in order to obtain a comprehensive view of the mail system. Key to our approach is that we leverage correlations across protocols and time to introduce novel features for HTTPS webmail classification: First, webmail servers tend to reside close to legacy IMAP and POP mail servers, which are easy to identify. Second, the usage of webmail services results in distinct patterns on sessions' duration and on the diurnal/weekly traffic usage profile. Third, traffic flows to webmail platforms exhibit inherent periodicities since AJAX-based clients periodically check for new messages. We use these features to build a simple classifier and detect webmail traffic on real-world NetFlow traces from a medium-sized backbone network. We believe that the major contribution of this paper - exploring a set of new features that could classify applications that run over HTTPS ports solely based on NetFlow data - will stimulate more general advance in the field of traffic classification. Copyright 2010 ACM.",Flow-level data; HTTPS traffic; Traffic classification; Webmail,Back-bone network; Flow-level; Hotmail; HTTPS traffic; Imminent threats; Internet mail; Mail servers; NetFlow data; NetFlows; Outlook web access; Real-world; Traffic classification; Traffic flow; Webmail; Internet; Internet protocols; Telecommunication traffic; Traffic surveys; HTTP
Luckie M.,1,Scamper: A scalable and extensible packet prober for active measurement of the Internet,2010,52,"Department of Computer Science, University of Waikato, Hamilton, New Zealand",University of Waikato,1,New Zealand,1,26,22,"Large scale active measurement of the Internet requires appropriate software support. The better tools that we have for executing consistent and systematic measurements, the more confidence we can have in the results. This paper presents scamper, a powerful open-source packet-prober for active measurement of the Internet designed to stand alone from coordination mechanisms. We built scamper and populated it with specific measurement techniques, making design decisions aimed at allowing Internet researchers to focus on scientific experiments rather than building accurate instrumentation. Copyright 2010 ACM.",Active measurement; Software; Tools,Active measurement; Coordination mechanisms; Design decisions; Measurement techniques; Open-source; Software; Software support; Stand -alone; Internet; Measurements
"Dhamdhere A., Breslau L., Duffield N., Ee C., Gerber A., Lund C., Sen S.",7,FlowRoute: Inferring forwarding table updates using passive flow-level measurements,2010,2,"CAIDA, University of California, San Diego, CA, United States; AT and T Labs-Research, Florham Park, NJ, United States",AT and T Labs;University of California San Diego,2,USA,1,31,26,"The reconvergence of routing protocols in response to changes in network topology can impact application performance. While improvements in protocol specification and implementation have significantly reduced reconvergence times, increasingly performance-sensitive applications continue to raise the bar for these protocols. As such, monitoring the performance of routing protocols remains a critical activity for network operators. We design FlowRoute, a tool based on passive data plane measurements that we use in conjunction with control plane monitors for offline debugging and analysis of forwarding table dynamics. We discuss practical constraints that affect FlowRoute, and show how they can be addressed in real deployment scenarios. As an application of FlowRoute, we study forwarding table updates by backbone routers at a tier-1 ISP. We detect interesting behavior such as delayed forwarding table updates and routing loops due to buggy routers - confirmed by network operators - that are not detectable using traditional control plane monitors. Copyright 2010 ACM.",Measurement; Netflow; Routing update,Application performance; Control planes; Critical activities; Data planes; Deployment scenarios; Forwarding table update; Forwarding tables; NetFlows; Network operator; Network topology; Offline; Protocol specifications; Reconvergence; Routing loops; Routing update; Sensitive application; Electric network topology; Internet; Internet service providers; Routers; Routing protocols; Internet protocols
"Wustrow E., Karir M., Bailey M., Jahanian F., Huston G.",5,Internet background radiation revisited,2010,77,"Networking Research and Development, Merit Network Inc., Ann Arbor, MI 48104, United States; Department of EECS, University of Michigan, Ann Arbor, MI 48109, United States; Asia Pacific Network, Information Centre, Brisbane, QLD 4064, Australia",Merit Network Inc.;University of Michigan at Ann Arbor,2,Australia;USA,2,33,18,"The monitoring of packets destined for routeable, yet unused, Internet addresses has proved to be a useful technique for measuring a variety of specific Internet phenomenon (e.g., worms, DDoS). In 2004, Pang et al. stepped beyond these targeted uses and provided one of the first generic characterizations of this non-productive traffic, demonstrating both its significant size and diversity. However, the six years that followed this study have seen tremendous changes in both the types of malicious activity on the Internet and the quantity and quality of unused address space. In this paper, we revisit the state of Internet ""background radiation"" through the lens of two unique data-sets: a five-year collection from a single unused /8 network block, and week-long collections from three recently allocated /8 network blocks. Through the longitudinal study of the long-lived block, comparisons between blocks, and extensive case studies of traffic in these blocks, we characterize the current state of background radiation specifically highlighting those features that remain invariant from previous measurements and those which exhibit significant differences. Of particular interest in this work is the exploration of address space pollution, in which significant non uniform behavior is observed. However, unlike previous observations of differences between unused blocks, we show that increasingly these differences are the result of environmental factors (e.g., misconfiguration, location), rather than algorithmic factors. Where feasible, we offer suggestions for clean up of these polluted blocks and identify those blocks whose allocations should be withheld. Copyright 2010 ACM.",Darknet; Internet background traffic; Network pollution,Address space; Background radiation; Clean up; Darknet; Data sets; Environmental factors; Internet background radiation; Longitudinal study; Malicious activities; Misconfigurations; Network pollution; Through the lens; Internet; Pollution; Radiation; Computer crime
"Quan L., Heidemann J.",2,On the characteristics and reasons of long-lived Internet flows,2010,14,"USC, Information Sciences Institute, 4676 Admiralty Way, Marina del Ray, CA 90292, United States",University of Southern California,1,USA,1,23,15,"Prior studies of Internet traffic have considered traffic at different resolutions and time scales: packets and flows for hours or days, aggregate packet statistics for days or weeks, and hourly trends for months. However, little is known about the long-term behavior of individual flows. In this paper, we study individual flows (as defined by the 5-tuple of protocol, source and destination IP address and port) over days and weeks. While the vast majority of flows are short, and most bytes are in short flows, we find that about 20% of the overall bytes are carried in flows that last longer than 10 minutes, and flows lasting 100 minutes or longer make up 2% of traffic. We show that long-lived flows are qualitatively different from short flows: they are generally slower, less bursty, and are due to different applications and protocols. We investigate the causes of short- and long-lived flows, and show that the traffic mix varies significantly depending on duration time scale, with computer-to-computer traffic more and more dominating in larger time scales. Copyright 2010 ACM.",Computer-to-computer communication; Long duration flow,Computer-to-computer communication; Duration time; Internet flows; Internet traffic; IP addresss; Long duration; Long-lived flow; Long-term behavior; Time-scales; Traffic mix; Internet; Time measurement; Internet protocols
"Rasti A.H., Magharei N., Rejaie R., Willinger W.",4,Eyeball ASes: From geography to connectivity,2010,15,"University of Oregon, United States; AT and T Labs-Research, United States",AT and T Labs;University of Oregon,2,USA,1,31,29,"This paper presents a new approach to determine the geographical footprint of individual Autonomous Systems that directly provide service to end-users, i.e.,eyeball ASes. The key idea is to leverage the geo-location of end-users associated with an eyeball AS to identify its geographical footprint. We leverage the kernel density estimation method to estimate the density of users across individual eyeball ASes. This method enables us to cope with the potential error associated with the location of individual end-users while controlling the level of aggregation among data points to capture a geo-footprint at the desired resolution. We use the resulting geo-footprint of individual eyeball ASes to identify their likely Point-of-Presence (PoP) locations. To demonstrate our proposed technique, we use the inferred geo-locations of 48 million users from three popular P2P applications and assess the geo- and PoP-level footprints of 1233 eyeball ASes. The validation of the identified PoP locations by our technique against online information and prior results by a commonly-used technique based on traceroute shows a very high accuracy. Leveraging the acquired PoP locations, we examine the implications of geofootprint of eyeball ASes on their connectivity to the rest of the Internet. In particular, we present a case study that reveals a much more complex picture of AS-level connectivity as compared to what the more traditional but geographyagnostic BGP- or traceroute-based approaches depict. Copyright 2010 ACM.",AS geography; Autonomous system (AS); Eyeball AS; Point-of-Presence (PoP),AS geography; Autonomous system (AS); Autonomous systems; Complex pictures; Data points; End-users; Eyeball AS; Geolocations; Kernel Density Estimation; New approaches; On-line information; P2P applications; Point of presence; Potential errors; Traceroute; Internet
"Leonard D., Loguinov D.",2,Demystifying service discovery: Implementing an Internet-wide scanner,2010,38,"Department of Computer Science and Engineering, Texas A and M University, College Station, TX 77843, United States",Texas A and M University,1,USA,1,24,12,"This paper develops a high-performance, Internet-wide service discovery tool, which we call IRLscanner, whose main design objectives have been to maximize politeness at remote networks, allow scanning rates that achieve coverage of the Internet in minutes/hours (rather than weeks/months), and significantly reduce administrator complaints. Using IRLscanner and 24-hour scans, we perform 21 Internet-wide experiments using 6 different protocols (i.e., DNS, HTTP, SMTP, EPMAP, ICMP and UDP ECHO), demonstrate the usefulness of ACK scans in detecting live hosts behind stateless firewalls, and undertake the first Internet-wide OS fingerprinting. In addition, we analyze the feedback generated (e.g., complaints, IDS alarms) and suggest novel approaches for reducing the amount of blowback during similar studies, which should enable researchers to collect valuable experimental data in the future with significantly fewer hurdles. Copyright 2010 ACM.",Horizontal scanning; Service discovery,Blowback; Design objectives; Different protocols; Experimental data; Horizontal scanning; Remote networks; Scanning rate; Service discovery; HTTP; Internet; Scanning; Internet protocols
"Cai X., Heidemann J., Krishnamurthy B., Willinger W.",4,Towards an AS-to-organization map,2010,15,"USC, ISI, Marina del Rey, CA, United States; AT and T Labs. Research, Florham Park, NJ, United States",AT and T Labs,1,USA,1,22,16,"An understanding of Internet topology is central to answer various questions ranging from network resilience to peer selection or data center location. While much of prior work has examined AS-level connectivity, meaningful and relevant results from such an abstract view of Internet topology have been limited. For one, semantically, AS relationships capture business relationships and not physical connectivity. Additionally, many organizations often use multiple ASes, either to implement different routing policies, or as legacies from mergers and acquisitions. In this paper, we move beyond the traditional AS graph view of the Internet to define the problem of AS-to-organization mapping. We describe our initial steps at automating the capture of the rich semantics inherent in the AS-level ecosystem where routing and connectivity intersect with organizations. We discuss preliminary methods that identify multi-AS organizations from WHOIS data and illustrate the challenges posed by the quality of the available data and the complexity of real- world organizational relationships. Copyright 2010 ACM.",Autonomous system (AS); Clustering; Mapping; Organization; Regional internet registry (RIR); WHOIS,Autonomous systems; Clustering; Organization; Regional internet registry (RIR); WHOIS; Ecology; Internet; Mapping; Semantics; Societies and institutions; Topology; Peer to peer networks
"Jiang J., Wilson C., Wang X., Huang P., Sha W., Dai Y., Zhao B.Y.",7,Understanding latent interactions in online social networks,2010,117,"Peking University, Beijing, China; U. C. Santa Barbara, Santa Barbara, CA, United States",Peking University;University of California Santa Barbara,2,China;USA,2,59,37,"Popular online social networks (OSNs) like Facebook and Twitter are changing the way users communicate and interact with the Internet. A deep understanding of user interactions in OSNs can provide important insights into questions of human social behavior, and into the design of social platforms and applications. However, recent studies have shown that a majority of user interactions on OSNs are latent interactions, passive actions such as profile browsing that cannot be observed by traditional measurement techniques. In this paper, we seek a deeper understanding of both visible and latent user interactions in OSNs. For quantifiable data on latent user interactions, we perform a detailed measurement study on Renren, the largest OSN in China with more than 150 million users to date. All friendship links in Renren are public, allowing us to exhaustively crawl a connected graph component of 42 million users and 1.66 billion social links in 2009. Renren also keeps detailed visitor logs for each user profile, and counters for each photo and diary/blog entry. We capture detailed histories of profile visits over a period of 90 days for more than 61,000 users in the Peking University Renren network, and use statistics of profile visits to study issues of user profile popularity, reciprocity of profile visits, and the impact of content updates on user popularity. We find that latent interactions are much more prevalent and frequent than visible events, non-reciprocal in nature, and that profile popularity are uncorrelated with the frequency of content updates. Finally, we construct latent interaction graphs as models of user browsing behavior, and compare their structural properties against those of both visible interaction graphs and social graphs. Copyright 2010 ACM.",Latent interactions; Online social networks,Browsing behavior; Connected graph; Facebook; Interaction graphs; Latent interactions; Measurement study; Online social networks; Peking University; Social behavior; Social graphs; Traditional measurement techniques; Use statistics; User interaction; User profile; Behavioral research; Internet; Online systems; Social networking (online)
"Adhikari V.K., Jain S., Zhang Z.-L.",3,YouTube traffic dynamics and its interplay with a tier-1 ISP: An ISP perspective,2010,63,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, United States",University of Minnesota,1,USA,1,29,24,"In this paper we conduct an extensive and in-depth study of traffic exchanged between YouTube data centers and its users, as seen from the perspective of a tier-1 ISP in Spring 2008 after YouTube was acquired by Google but before Google did any major restructuring of YouTube. Using flow-level data collected at multiple PoPs of the ISP, we first infer where the YouTube data centers are located and where they are connected to the ISP.We then deduce the load balancing strategy used by YouTube to service user requests, and investigate how load balancing strategies and routing policies affect the traffic dynamics across YouTube and the tier-1 ISP. Copyright 2010 ACM.",Proportional load balancing; Unseen traffic estimation; YouTube,Data centers; Flow-level; In-depth study; Load balancing strategy; Load-Balancing; Routing policies; Traffic dynamics; Traffic estimation; YouTube; Internet; Parallel architectures; Internet service providers
"Gao H., Hu J., Wilson C., Li Z., Chen Y., Zhao B.Y.",6,Detecting and characterizing social spam campaigns,2010,236,"Northwestern University, Evanston, IL, United States; Huazhong Univ. of Sci. and Tech, Northwestern University, United States; U. C. Santa Barbara, Santa Barbara, CA, United States",Northwestern University;University of California Santa Barbara,2,USA,1,30,25,"Online social networks (OSNs) are popular collaboration and communication tools for millions of users and their friends. Unfortunately, in the wrong hands, they are also effective tools for executing spam campaigns and spreading malware. Intuitively, a user is more likely to respond to a message from a Facebook friend than from a stranger, thus making social spam a more effective distribution mechanism than traditional email. In fact, existing evidence shows malicious entities are already attempting to compromise OSN account credentials to support these ""high-return"" spam campaigns. In this paper, we present an initial study to quantify and characterize spam campaigns launched using accounts on online social networks. We study a large anonymized dataset of asynchronous ""wall"" messages between Facebook users. We analyze all wall messages received by roughly 3.5 million Facebook users (more than 187 million messages in all), and use a set of automated techniques to detect and characterize coordinated spam campaigns. Our system detected roughly 200,000 malicious wall posts with embedded URLs, originating from more than 57,000 user accounts. We find that more than 70% of all malicious wall posts advertise phishing sites. We also study the characteristics of malicious accounts, and see that more than 97% are compromised accounts, rather than ""fake"" accounts created solely for the purpose of spamming. Finally, we observe that, when adjusted to the local time of the sender, spamming dominates actual wall post activity in the early morning hours, when normal users are asleep. Copyright 2010 ACM.",Online social networks; Spam; Spam Campaigns,Automated techniques; Communication tools; Data sets; Effective distribution; Effective tool; Facebook; Local time; Malicious entity; Malwares; Online social networks; Phishing; Spam; Spam Campaigns; Computer crime; Internet; Online systems; Spamming; Walls (structural partitions); Social networking (online)
"Luckie M., Stasiewicz B.",2,Measuring Path MTU Discovery behaviour,2010,12,"Department of Computer Science, University of Waikato, Hamilton, New Zealand",University of Waikato,1,New Zealand,1,16,15,"Path MTU Discovery (PMTUD) is widely believed to be unreliable because of firewalls that discard ICMP ""Packet Too Big""messages. This paper measures PMTUD behaviour for 50,000 popular websites and finds the failure rate in IPv4 is much less than previous studies. We measure the overall failure rate between 5% and 18%, depending on the MTU of the constraining link. We explore methods webserver operators are using to reduce their dependence on PMTUD, and find 11% limit themselves to sending packets no larger than 1380 bytes. We identify a number of common behaviours that seem to be software bugs rather than filtering by firewalls. If these are corrected PMTUD failures could be reduced by 63%. We further find the IPv6 failure rate is less than the IPv4 rate even with more scope for failure in IPv6. Copyright 2010 ACM.",IPv4; IPv6; Middleboxes; Path MTU discovery; TCP,IPv4; IPv6; Middleboxes; Path MTU discovery; TCP; Computer system firewalls; Internet; Program debugging; Websites; Internet protocols
"Gerber A., Pang J., Spatscheck O., Venkataraman S.",4,Speed testing without speed tests: Estimating achievable download speed from passive measurements,2010,31,"AT and T Labs. - Research, 180 Park Ave., Florham Park, NJ, United States",AT and T Labs,1,USA,1,44,32,"How fast is the network? The speed at which real users can download content at different locations and at different times is an important metric for service providers. Knowledge of this speed helps determine where to provision more capacity and helps detect network problems. However, most network-level estimates of these speeds today are obtained using active ""speed tests"" that place substantial load on the network and are not necessarily representative of actual user experiences due to limited vantage points. These problems are exacerbated in wireless networks where the physical locations of users play an important role in performance. To redress these problems, this paper presents a new technique to estimate achievable download speed using only flow records collected passively. Estimating achievable speed passively is non-trivial because the measured throughput of real flows is often not comparable to the achievable steady-state TCP rate. This can be because, for example, flows are small and never exit TCP slow start or are rate-limited by the content-provider. Our technique addresses these issues by constructing a Throughput Index, a list of flow types that accurately estimate achievable speed. We show that our technique estimates achievable speed more accurately than other techniques in a large 3G wireless network. Copyright 2010 ACM.",3G; Measurement; Passive; Throughput; UMTS; Wireless,3G; 3G wireless networks; Flow type; Network problems; Non-trivial; Passive; Passive measurements; Physical locations; Real flow; Service provider; Slow start; Speed test; UMTS; User experience; Wireless; Estimation; Internet; Speed; Throughput; Wireless networks
"Falaki H., Lymberopoulos D., Mahajan R., Kandula S., Estrin D.",5,A first look at traffic on smartphones,2010,253,"CENS, UCLA, United States; Microsoft Research, United States",Microsoft,1,USA,1,24,7,"Using data from 43 users across two platforms, we present a detailed look at smartphone traffic. We find that browsing contributes over half of the traffic, while each of email, media, and maps contribute roughly 10%. We also find that the overhead of lower layer protocols is high because of small transfer sizes. For half of the transfers that use transport-level security, header bytes correspond to 40% of the total. We show that while packet loss is the main factor that limits the throughput of smartphone traffic, larger send buffers at Internet servers can improve the throughput of a quarter of the transfers. Finally, by studying the interaction between smartphone traffic and the radio power management policy, we find that the power consumption of the radio can be reduced by 35% with minimal impact on the performance of packet exchanges. Copyright 2010 ACM.",Power management; Smartphone traffic,First look; Internet servers; Layer protocols; Packet exchange; Power Consumption; Power managements; Smart phones; Electric power utilization; Energy management; Internet; Internet protocols; Signal encoding
"Lumezanu C., Guo K., Spring N., Bhattacharjee B.",4,The effect of packet loss on redundancy elimination in cellular wireless networks,2010,15,"Georgia Tech, United States; Alcatel-Lucent Bell Laboratories, United States; University of Maryland, United States",Bell Labs;Georgia Tech;University of Maryland College Park,3,USA,1,16,13,"Network-level redundancy elimination (RE) algorithms reduce traffic volume on bandwidth-constrained network paths by avoiding the transmission of repeated byte sequences. Previous work shows that RE can suppress the transmission of 20-50% bytes when deployed at ISP access links or between routers. In this paper, we focus on the challenges of deploying RE in cellular networks. The potential benefit is substantial, since cellular networks have a growing subscriber base and network links, including wired backhaul, are often oversubscribed. Using three large traces captured at two North American and one European wireless network providers, we show that RE can reduce the bandwidth consumption of the majority of mobile users by at least 10%. However, cellular links have much higher packet loss rates than their wired counterparts, which makes applying RE much more difficult. Our experiments also show that the loss of only a few packets can disrupt RE and eliminate the bandwidth savings. We propose informed marking, a lightweight scheme that detects lost packets and prevents RE algorithms from using them for future encodings. We implement RE with informed marking and deploy it in a real-world cellular network. Our results show that with informed marking, more than 60% of the bandwidth savings of RE are preserved, even when packet loss rates are high. Copyright 2010 ACM.",Cellular networks; Loss; Redundancy elimination,Access links; Bandwidth consumption; Bandwidth savings; Bandwidth-constrained; Cellular links; Cellular network; Cellular wireless networks; Encodings; Mobile users; Network links; Network paths; Network provider; North American; Packet loss rates; Potential benefits; Real-world; Redundancy elimination; Traffic volumes; Algorithms; Bandwidth; Cellular neural networks; Global system for mobile communications; Internet; Internet service providers; Packet loss; Quality assurance; Redundancy; Wireless networks
"Freedmanxz D.A., Marianx T., Leey J.H., Birmanx K., Weatherspoonx H., Xuy C.",6,Exact temporal characterization of 10 Gbps optical wide-area network,2010,5,"Department of Computer Science, Cornell University, Ithaca, NY, United States; Department of Physics, Cornell University, Ithaca, NY, United States; Department of Applied and Engineering Physics, Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,23,20,"We design and implement a novel class of highly precise network instrumentation and apply this tool to perform the first exact packet-timing measurements of a wide-area network ever undertaken, capturing 10 Gigabit Ethernet packets in ight on optical fiber. Through principled design, we improve timing precision by two to six orders of magnitude over existing techniques. Our observations contest several common assumptions about behavior of wide-area networks and the relationship between their input and output traffic ows. Further, we identify and characterize emergent packet chains as a mechanism to explain previously observed anomalous packet loss on receiver endpoints of such networks. Copyright 2010 ACM.",10 Gbps; Ethernet; Optical network; Wide-area network,10 Gbps; 10-Gigabit Ethernet; Input and outputs; Network instrumentation; Optical networks; Orders of magnitude; Timing measurement; Ethernet; Fiber optic networks; Internet; Optical fibers; Wide area networks
"Deshpande P., Hou X., Das S.R.",3,Performance comparison of 3G and metro-scale wifi for vehicular network access,2010,69,"Computer Science Department, Stony Brook University, Stony Brook, NY 11794, United States",Stony Brook University,1,USA,1,20,8,"We perform a head-to-head comparison of the performance characteristics of a 3G network operated by a nation-wide provider and a metro-scale wifi network operated by a commercial ISP, from the perspective of vehicular network access. Our experience shows that over a wide geographic region and under vehicular mobility, these networks exhibit very different throughput and coverage characteristics. Wifi has frequent disconnections even in a commercially operated, metro-scale deployment; but when connected, indeed delivers high throughouts even in a mobile scenario. The 3G network offers similar or lower throughputs in general, but provides excellent coverage and less throughput variability. The two network characteristics are often complementary. It is conceivable that these properties can be judiciously exploited for a hybrid network design where 3G data can be offloaded to wifi for better performance and to reduce 3G network congestion and to lower costs. Copyright 2010 ACM.",3G; Vehicular internet access; Wifi,3G; 3G Networks; Frequent disconnection; Geographic regions; Hybrid network; Lower cost; Mobile scenarios; Network characteristics; Performance characteristics; Performance comparison; Vehicular internet access; Vehicular networks; Wi Fi networks; Internet; Internet service providers; Throughput; Ad hoc networks
"Kone V., Yang L., Yang X., Zhao B.Y., Zheng H.",5,On the feasibility of effective opportunistic spectrum access,2010,28,"U. C. Santa Barbara, Santa Barbara, CA, United States; Intel Labs., Hillsboro, OR, United States",University of California Santa Barbara,1,USA,1,22,13,"Dynamic spectrum access networks are designed to allow today's bandwidth hungry ""secondary devices"" to share spectrum allocated to legacy devices, or ""primary users."" The success of this wireless communication model relies on the availability of unused spectrum, and the ability of secondary devices to utilize spectrum without disrupting transmissions of primary users. While recent measurement studies have shown that there is sufficient underutilized spectrum available, little is known about whether secondary devices can efficiently make use of available spectrum while minimizing disruptions to primary users. In this paper, we present the first comprehensive study on the presence of ""usable"" spectrum in opportunistic spectrum access systems, and whether sufficient spectrum can be extracted by secondary devices to support traditional networking applications. We use for our study fine-grain usage traces of a wide spectrum range (20MHz-6GHz) taken at 4 locations in Germany, the Netherlands, and Santa Barbara, California. Our study shows that on average, 54% of spectrum is never used and 26% is only partially used. Surprisingly, in this 26% of partially used spectrum, secondary devices can utilize very little spectrum using conservative access policies to minimize interference with primary users. Even assuming an optimal access scheme and extensive statistical knowledge of primary user access patterns, a user can only extract between 20-30% of the total available spectrum. To provide better spectrum availability, we propose frequency bundling, where secondary devices build reliable channels by combining multiple unreliable frequencies into virtual frequency bundles. Analyzing our traces, we find that there is little correlation of spectrum availability across channels, and that bundling random channels together can provide sustained periods of reliable transmission with only short interruptions. Copyright 2010 ACM.",Channel bundling; Measurement; Opportunistic spectrum access,Access policies; Access schemes; California; Channel bundling; Comprehensive studies; Dynamic spectrum access networks; Germany; Measurement study; Netherlands; Networking applications; Opportunistic spectrum access; Random channel; Reliable transmission; Santa Barbara; Short interruptions; Spectrum availability; Statistical knowledge; User access patterns; Wide spectrum; Wireless communications; Bandwidth; Equipment; Information theory; Internet; Optimization; Wireless telecommunication systems; Spectroscopy
"Beverly R., Berger A., Xie G.G.",3,Primitives for active Internet topology mapping: Toward high-frequency characterization,2010,18,"Naval Postgraduate School, United States; MIT CSAIL, Akamai, United States",MIT;Naval Postgraduate School,2,USA,1,28,23,"Current large-scale topology mapping systems require multiple days to characterize the Internet due to the large amount of probing traffic they incur. The accuracy of maps from existing systems is unknown, yet empirical evidence suggests that additional fine-grained probing exposes hidden links and temporal dynamics. Through longitudinal analysis of data from the Archipelago and iPlane systems, in conjunction with our own active probing, we examine how to shorten Internet topology mapping cycle time. In particular, this work develops discriminatory primitives that maximize topological fidelity while being efficient. We propose and evaluate adaptive probing techniques that leverage external knowledge (e.g., common subnetting structures) and data from prior cycle(s) to guide the selection of probed destinations and the assignment of destinations to vantage points. Our Interface Set Cover (ISC) algorithm generalizes previous dynamic probing work. Crucially, ISC runs across probing cycles to minimize probing while detecting load balancing and reacting to topological changes. To maximize the information gain of each trace, our Subnet Centric Probing technique selects destinations more likely to expose their network's internal structure. Finally, the Vantage Point Spreading algorithm uses network knowledge to increase path diversity to destination ingress points. Copyright 2010 ACM.",Adaptive probing; Internet topology; Network topology,Active probing; Adaptive probing; Cycle time; Empirical evidence; Existing systems; External knowledge; High-frequency characterization; Information gain; Internal structure; Internet topologies; Internet topology; Large-scale topology; Load-Balancing; Longitudinal analysis; Network topology; Path diversity; Probing techniques; Set cover; Temporal dynamics; Topological changes; Algorithms; Electric network topology; Knowledge management; Mapping; Internet
"Qiu T., Feng J., Ge Z., Wang J., Xu J., Yates J.",6,Listen to me if you can: Tracking user experience of mobile network on social media,2010,24,"Georgia Tech, Atlanta, GA, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;Georgia Tech,2,USA,1,28,24,"Social media sites such as Twitter continue to grow at a fast pace. People of all generations use social media to exchange messages and share experiences of their life in a timely fashion. Most of these sites make their data available. An intriguing question is can we exploit this real-time and massive data-flow to improve business in a measurable way. In this paper, we are particularly interested in tweets (Twitter messages) that are relevant to mobile network performance. We compare tweets with a more traditional source of user experience, i.e., customer care tickets, and correlate both of them with a list of major network incidents. From our study, we have the following observations. First, Twitter users and users who call customer service tend to report different types of performance issues. Second, we observe that tweets typically appear more rapidly in response to network problems than customer tickets. They also appear to respond to a wider range of network issues. Third, significant spikes in the number of tweets appear to indicate short term performance impairments which are not reported in our current list of major network incidents. These observations together indicate that Twitter is an attractive, complementary source for monitoring service performance and its impact on user experience. Copyright 2010 ACM.",Social media; Twitter; User experience,Customer care; Customer services; Intriguing questions; Massive data; Mobile networks; Monitoring services; Network incidents; Network problems; Performance issues; Short term; Social media; Twitter; User experience; Customer satisfaction; Internet; Network performance; Sales; Social networking (online); Wireless networks
"Chan E.W.W., Luo X., Li W., Fok W.W.T., Chang R.K.C.",5,Measurement of loss pairs in network paths,2010,5,"Department of Computing, Hong Kong Polytechnic University, Hong Kong; College of Computing, Georgia Institute of Technology, United States",Georgia Tech;Hong Kong Polytechnic University,2,Hong Kong;USA,2,24,21,"Loss-pair measurement was proposed a decade ago for discovering network path properties, such as a router's buffer size. A packet pair is regarded as a loss pair if exactly one packet is lost. Therefore, the residual packet's delay can be used to infer the lost packet's delay. Despite this unique advantage shared by no other methods, no loss-pair measurement in actual networks has ever been reported. In this paper, we further develop the loss-pair measurement and make the following contributions. First, we characterize the residual packet's delay by including other important factors (such as the impact of the first packet in the pair) which were ignored before. Second, we employ a novel TCP-based probing method to measure from a single endpoint all four possible loss pairs for a round-trip network path. Third, we conducted loss-pair measurement for 88 round-trip paths continuously for almost three weeks. Being the first set of loss-pair measurement, we obtained a number of original results, such as prevalence of loss pairs, distribution of different types of loss pairs, and effect of route change on the paths' congestion state. Copyright 2010 ACM.",Delay; Loss pair; Non-cooperative; Packet pair,Buffer sizes; Delay; Measurement of loss; Network paths; Non-cooperative; Packet pairs; Route changes; Internet; Measurements
"Braun L., Didebulidze A., Kammenhuber N., Carle G.",4,Comparing and improving current packet capturing solutions based on commodity hardware,2010,44,"Technische UniversitŠt MŸnchen, Institute for Informatics, Department for Network Architectures and Services, Germany",TU Munich,1,Germany,1,23,23,"Capturing network traffic with commodity hardware has become a feasible task: Advances in hardware as well as software have boosted off-the-shelf hardware to performance levels that some years ago were the domain of expensive specialpurpose hardware. However, the capturing hardware still needs to be driven by a well-performing software stack in order to minimise or avoid packet loss. Improving the capturing stack of Linux and FreeBSD has been an extensively covered research topic in the past years. Although the majority of the proposed enhancements have been backed by evaluations, these have mostly been conducted on different hardware platforms and software versions, which renders a comparative assessment of the various approaches difficult, if not impossible. This paper summarises and evaluates the performance of current packet capturing solutions based on commodity hardware. We identify bottlenecks and pitfalls within the capturing stack of FreeBSD and Linux, and give explanations for the observed effects. Based on our experiments, we provide guidelines for users on how to configure their capturing systems for optimal performance and we also give hints on debugging bad performance. Furthermore, we propose improvements to the operating system's capturing processes that reduce packet loss, and evaluate their impact on capturing performance. Copyright 2010 ACM.",Measurement; Performance,Capturing system; Commodity hardware; Comparative assessment; FreeBSD; Hardware platform; Network traffic; Off-the-shelf hardwares; Operating systems; Optimal performance; Packet capturing; Performance; Performance level; Research topics; Software stacks; Software versions; Computer operating systems; Internet; Packet loss; Program debugging; Rating; Hardware
"Benson T., Akella A., Maltz D.A.",3,Network traffic characteristics of data centers in the wild,2010,952,"University of Wisconsin-Madison, United States; Microsoft Research-Redmond, United States",Microsoft;;University of Wisconsin-Madison,3,USA,1,53,36,"Although there is tremendous interest in designing improved networks for data centers, very little is known about the network-level traffic characteristics of current data centers. In this paper, we conduct an empirical study of the network traffic in 10 data centers belonging to three different types of organizations, including university, enterprise, and cloud data centers. Our definition of cloud data centers includes not only data centers employed by large online service providers offering Internet-facing applications, but also data centers used to host data-intensive (mapreduce style) applications. We collect and analyze SNMP statistics, topology, and packet-level traces. We examine the range of applications deployed in these data centers and their placement, the flow-level and packetlevel transmission properties of these applications, and their impact on network utilization, link utilization, congestion, and packet drops. We describe the implications of the observed traffic patterns for data center internal traffic engineering as well as for recentlyproposed architectures for data center networks. Copyright 2010 ACM.",Characterization; Data center traffic,Cloud data; Current data; Data centers; Empirical studies; Flow-level; Link utilization; Map-reduce; Net work utilization; Network traffic; On-line service; Packet drops; Traffic characteristics; Traffic Engineering; Traffic pattern; Transmission property; Internet; Telecommunication traffic; Satellite communication systems
"Zhou R., Khemmarat S., Gao L.",3,The impact of YouTube recommendation system on video views,2010,100,"College of Computer Science and Technology, Harbin Engineering University, Harbin, China; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, United States",Harbin Engineering University;University of Massachusetts Amherst,2,China;USA,2,20,13,"Hosting a collection of millions of videos, YouTube offers several features to help users discover the videos of their interest. For example, YouTube provides video search, related video recommendation and front page highlight. The understanding of how these features drive video views is useful for creating a strategy to drive video popularity. In this paper, we perform a measurement study on data sets crawled from YouTube and find that the related video recommendation, which recommends the videos that are related to the video a user is watching, is one of the most important view sources of videos. Despite the fact that the YouTube video search is the number one source of views in aggregation, the related video recommendation is the main source of views for the majority of the videos on YouTube. Furthermore, our results reveal that there is a strong correlation between the view count of a video and the average view count of its top referrer videos. This implies that a video has a higher chance to become popular when it is placed on the related video recommendation lists of popular videos. We also find that the click through rate from a video to its related videos is high and the position of a video in a related video list plays a critical role in the click through rate. Finally, our evaluation of the impact of the related video recommendation system on the diversity of video views indicates that the current recommendation system helps to increase the diversity of video views in aggregation. Copyright 2010 ACM.",Recommendation system; Video sharing site; View diversity; View sources; YouTube,Recommendation systems; Video sharing; View diversity; View sources; YouTube; Internet
"HŠtšnen S., Nyrhinen A., Eggert L., Strowes S., Sarolahti P., Kojo M.",6,An experimental study of home gateway characteristics,2010,26,"University of Helsinki, Finland; Nokia Research Center, United States; University of Glasgow, United Kingdom; HIIT, Aalto University, Finland",Aalto University;Nokia;University of Glasgow;University of Helsinki,4,Finland;UK;USA,3,29,22,"Many residential and small business users connect to the Internet via home gateways, such as DSL and cable modems. The characteristics of these devices heavily influence the quality and performance of the Internet service that these users receive. Anecdotal evidence suggests that an extremely diverse set of behaviors exists in the deployed base, forcing application developers to design for the lowest common denominator. This paper experimentally analyzes some characteristics of a substantial number of different home gateways: binding timeouts, queuing delays, throughput, protocol support and others. Copyright 2010 ACM.",Behavior; Characteristics; Home gateways; Measurements,Anecdotal evidences; Application developers; Behavior; Cable modems; Characteristics; Common denominators; Experimental studies; Home gateway; Internet services; Queuing delay; Small business; Internet; Internet protocols; Modems; Gateways (computer networks)
"Eriksson B., Barford P., Bowden R., Duffield N., Sommers J., Roughan M.",6,BasisDetect: A model-based network event detection framework,2010,14,"UW-Madison, Nemean Networks, United States; University of Adelaide, Australia; AT and T Research, United States; Colgate University, United States",AT and T Labs;Colgate University;University of Adelaide,3,Australia;USA,2,12,12,"The ability to detect unexpected events in large networks can be a significant benefit to daily network operations. A great deal of work has been done over the past decade to develop effective anomaly detection tools, but they remain virtually unused in live network operations due to an unacceptably high false alarm rate. In this paper, we seek to improve the ability to accurately detect unexpected network events through the use of BasisDetect, a flexible but precise modeling framework. Using a small dataset with labeled anomalies, the BasisDetect framework allows us to define large classes of anomalies and detect them in different types of network data, both from single sources and from multiple, potentially diverse sources. Network anomaly signal characteristics are learned via a novel basis pursuit based methodology. We demonstrate the feasibility of our Basis-Detect framework method and compare it to previous detection methods using a combination of synthetic and realworld data. In comparison with previous anomaly detection methods, our BasisDetect methodology results show a 50% reduction in the number of false alarms in a single node dataset, and over 65% reduction in false alarms for synthetic network-wide data. Copyright 2010 ACM.",Anomaly detection,Anomaly detection; Anomaly detection methods; Basis Pursuits; Data sets; Detection methods; False alarm rate; False alarms; Large class; Large networks; Live networks; Model-based; Network anomalies; Network data; Network events; Network operations; Number of false alarms; Precise modeling; Real world data; Signal characteristic; Single source; Synthetic networks; Unexpected events; Errors; Internet; Alarm systems
"Mohaisen A., Yun A., Kim Y.",3,Measuring the mixing time of social graphs,2010,93,"University of Minnesota, Minneapolis, MN 55455, United States",University of Minnesota,1,USA,1,30,23,"Social networks provide interesting algorithmic properties that can be used to bootstrap the security of distributed systems. For example, it is widely believed that social networks are fast mixing, and many recently proposed designs of such systems make crucial use of this property. However, whether real-world social networks are really fast mixing is not verified before, and this could potentially affect the performance of such systems based on the fast mixing property. To address this problem, we measure the mixing time of several social graphs, the time that it takes a random walk on the graph to approach the stationary distribution of that graph, using two techniques. First, we use the second largest eigenvalue modulus which bounds the mixing time. Second, we sample initial distributions and compute the random walk length required to achieve probability distributions close to the stationary distribution. Our findings show that the mixing time of social graphs is much larger than anticipated, and being used in literature, and this implies that either the current security systems based on fast mixing have weaker utility guarantees or have to be less efficient, with less security guarantees, in order to compensate for the slower mixing. Copyright 2010 ACM.",Measurement; Mixing time; Social networks; Sybil defenses,Algorithmic properties; Distributed systems; Mixing property; Mixing time; Random Walk; Real-world; Second largest eigenvalue modulus; Social graphs; Social Networks; Stationary distribution; Sybil defenses; Eigenvalues and eigenfunctions; Internet; Network security; Probability distributions; Random processes; Social networking (online); Mixing
"Kreibich C., Weaver N., Nechaev B., Paxson V.",4,Netalyzr: Illuminating the edge network,2010,172,"ICSI, UC Berkeley, 1947 Center Street, Berkeley, CA 94704, United States; HIIT, Aalto University, PO Box 19800, 00076 Aalto, Finland",Aalto University;University of California Berkeley,2,Finland;USA,2,24,18,"In this paper we present Netalyzr, a network measurement and debugging service that evaluates the functionality provided by people's Internet connectivity. The design aims to prove both comprehensive in terms of the properties we measure and easy to employ and understand for users with little technical background. We structure Netalyzr as a signed Java applet (which users access via their Web browser) that communicates with a suite of measurementspecific servers. Traffic between the two then probes for a diverse set of network properties, including outbound port filtering, hidden in-network HTTP caches, DNS manipulations, NAT behavior, path MTU issues, ipv6 support, and access-modem buffer capacity. In addition to reporting results to the user, Netalyzr also forms the foundation for an extensive measurement of edge-network properties. To this end, along with describing Netalyzr's architecture and system implementation, we present a detailed study of 130,000 measurement sessions that the service has recorded since we made it publicly available in June 2009. Copyright 2010 ACM.",Network measurement; Network neutrality; Network performance; Network troubleshooting,Buffer capacity; EDGE Networks; Internet connectivity; Java Applet; Network measurement; Network neutrality; Network properties; Network troubleshooting; System implementation; Technical background; Users access; Computer architecture; HTTP; Internet; Internet protocols; Network performance; Servers; Measurements
"Tozal M.E., Sarac K.",2,Tracenet: An Internet topology data collector,2010,20,"Department of Computer Science, University of Texas at Dallas, Richardson, TX 75080, United States",University of Texas at Dallas,1,USA,1,32,29,"This paper presents a network layer Internet topology collection tool called tracenet. Comparedto traceroute, tracenet can collect a more complete topology information on an end-to-end path. That is, while traceroute returns a list of IP addresses each representing a router on a path, tracenet attempts to return all the IP addresses assigned to the interfaces on each visited subnetwork on the path. Consequently, the collected information (1) includes more IP addresses belonging to the traced path; (2) represents""being on the same LAN""relationship among the collected IP addresses; and (3) annotates the discovered subnets with their observed subnet masks. Our experiments on Internet2, GEANT, and four major ISP networks demonstrate promising results on the utility of tracenet for future topology measurement studies. Copyright 2010 ACM.",Internet; Network; Subnet; Topology; Traceroute,Data collectors; End-to-end path; Internet topologies; Internet2; IP addresss; Measurement study; Network; Sub-network; Subnet; Subnet masks; Subnets; Topology information; Traceroute; Internet; Internet service providers; Network layers; Topology; Internet protocols
"Carter K.M., Lippmann R.P., Boyer S.W.",3,Temporally oblivious anomaly detection on large networks using functional peers,2010,2,"MIT Lincoln Laboratory, Lexington, MA, United States",MIT,1,USA,1,28,21,"Previous methods of network anomaly detection have focused on defining a temporal model of what is ""normal,"" and flagging the ""abnormal"" activity that does not fit into this pre-trained construct. When monitoring traffic to and from IP addresses on a large network, this problem can become computationally complex, and potentially intractable, as a state model must be maintained for each address. In this paper, we present a method of detecting anomalous network activity without providing any historical context. By exploiting the size of the network along with the minimal overhead of NetFlow data, we are able to model groups of hosts performing similar functions to discover anomalous behavior. As a collection, these anomalies can be further described with a few high-level characterizations and we provide a means for creating and labeling these categories. We demonstrate our method on a very large-scale network consisting of 30 million unique addresses, focusing specifically on traffic related to web servers. Copyright 2010 ACM.",Anomaly detection; Machine learning; Network security,Anomalous behavior; Anomaly detection; IP addresss; Large networks; Large-scale network; Machine-learning; Model groups; NetFlow data; Network activities; Network anomaly detection; State models; Temporal models; Traffic-related; Web servers; Internet; Internet protocols; Learning systems; Network security
"Poese I., Frank B., Ager B., Smaragdakis G., Feldmann A.",5,Improving content delivery using Provider-aided Distance Information,2010,54,"T-Labs., TU Berlin, Germany",TU Berlin,1,Germany,1,22,16,"Content delivery systems constitute a major portion of today's Internet traffic. While they are a good source of revenue for Internet Service Providers (ISPs), the huge volume of content delivery traffic also poses a significant burden and traffic engineering challenge for the ISP. The difficulty is due to the immense volume of transfers, while the traffic engineering challenge stems from the fact that most content delivery systems themselves utilize a distributed infrastructure. They perform their own traffic flow optimization and realize this using the DNS system. While content delivery systems may, to some extent, consider the user's performance within their optimization criteria, they currently have no incentive to consider any of the ISP's constraints. As a consequence, the ISP has ""lost control"" over a major part of its traffic. To overcome this impairment, we propose a solution where the ISP offers a Provider-aided Distance Information System (PaDIS). PaDIS uses information available only to the ISP to rank any client-host pair based on distance information, such as delay bandwidth or number of hops. In this paper we show that the applicability of the system is significant. More than 70% of the HTTP traffic of a major European ISP can be accessed via multiple different locations. Moreover, we show that deploying PaDIS is not only beneficial to ISPs, but also to users. Experiments with different content providers show that improvements in download times of up to a factor of four are possible. Furthermore, we describe a high performance implementation of PaDIS and show how it can be deployed within an ISP. Copyright 2010 ACM.",Content Distribution; DNS Redirection; Host Diversity; Residential Traces; Server Selection,Content distribution; DNS Redirection; Host Diversity; Residential Traces; Server Selection; HTTP; Internet; Internet protocols; Optimization; Servers; Traffic surveys; Internet service providers
"Qian F., Wang Z., Gerber A., Mao Z.M., Sen S., Spatscheck O.",6,Characterizing radio resource allocation for 3G networks,2010,176,"University of Michigan, United States; AT and T Labs. Research, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,23,19,"3G cellular data networks have recently witnessed explosive growth. In this work, we focus on UMTS, one of the most popular 3G mobile communication technologies. Our work is the first to accurately infer, for any UMTS network, the state machine (both transitions and timer values) that guides the radio resource allocation policy through a light-weight probing scheme. We systematically characterize the impact of operational state machine settings by analyzing traces collected from a commercial UMTS network, and pinpoint the inefficiencies caused by the interplay between smartphone applications and the state machine behavior. Besides basic characterizations, we explore the optimal state machine settings in terms of several critical timer values evaluated using real network traces. Our findings suggest that the fundamental limitation of the current state machine design is its static nature of treating all traffic according to the same inactivity timers, making it difficult to balance tradeoffs among radio resource usage efficiency, network management overhead, device radio energy consumption, and performance. To the best of our knowledge, our work is the first empirical study that employs real cellular traces to investigate the optimality of UMTS state machine configurations. Our analysis also demonstrates that traffic patterns impose significant impact on radio resource and energy consumption. In particular, We propose a simple improvement that reduces YouTube streaming energy by 80% by leveraging an existing feature called fast dormancy supported by the 3GPP specifications. Copyright 2010 ACM.",3G Networks; Inactivity timers; Multimedia streaming; RRC state machine; Smartphones; Tail effects; UMTS,3G Networks; Inactivity timers; Multimedia streaming; Smart-phones; State machine; Tail effects; UMTS; Contour followers; Energy efficiency; Energy utilization; Internet; Machine design; Media streaming; Mobile telecommunication systems; Network management; Radio; Resource allocation; Wireless networks
"Ghita D., Argyraki K., Thiran P.",3,Network tomography on correlated links,2010,14,"School of Computer and Communication Sciences, ƒcole Polytechnique FŽdŽrale de Lausanne (EPFL), Switzerland","EPFL, Switzerland",1,Switzerland,1,36,11,"Network tomography establishes linear relationships between the characteristics of individual links and those of end-toend paths. It has been proved that these relationships can be used to infer the characteristics of links from end-to-end measurements, provided that links are not correlated, i.e., the status of one link is independent from the status of other links. In this paper, we consider the problem of identifying link characteristics from end-to-end measurements when links are ""correlated,"" i.e., the status of one link may depend on the status of other links. There are several practical scenarios in which this can happen; for instance, if we know the network topology at the IP-link or at the domain-link level, then links from the same local-area network or the same administrative domain are potentially correlated, since they may be sharing physical links, network equipment, even management processes. We formally prove that, under certain well defined conditions, network tomography works when links are correlated, in particular, it is possible to identify the probability that each link is congested from end-to-end measurements. We also present a practical algorithm that computes these probabilities. We evaluate our algorithm through extensive simulations and show that it is accurate in a variety of realistic congestion scenarios. Copyright 2010 ACM.",Link correlation; Network performance tomography,Administrative domains; Correlated link; End-to-end measurement; Extensive simulations; Linear relationships; Link correlation; Management process; Network equipment; Network tomography; Network topology; Practical algorithms; Algorithms; Electric network topology; Internet; Internet protocols; Network management; Network performance; Probability; Tomography; Local area networks
"Qiu T., Ge Z., Pei D., Wang J., Xu J.",5,What happened in my network? Mining network events from router syslogs,2010,29,"Georgia Tech, Atlanta, GA, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;Georgia Tech,2,USA,1,33,26,"Router syslogs are messages that a router logs to describe a wide range of events observed by it. They are considered one of the most valuable data sources for monitoring network health and for troubleshooting network faults and performance anomalies. However, router syslog messages are essentially free-form text with only a minimal structure, and their formats vary among different vendors and router OSes. Furthermore, since router syslogs are aimed for tracking and debugging router software/hardware problems, they are often too low-level from network service management perspectives. Due to their sheer volume (e.g., millions per day in a large ISP network), detailed router syslog messages are typically examined only when required by an on-going troubleshooting investigation or when given a narrow time range and a specific router under suspicion. Automated systems based on router syslogs on the other hand tend to focus on a subset of the mission critical messages (e.g., relating to network fault) to avoid dealing with the full diversity and complexity of syslog messages. In this project, we design a SyslogDigest system that can automatically transform and compress such low-level minimally-structured syslog messages into meaningful and prioritized high-level network events, using powerful data mining techniques tailored to our problem domain. These events are three orders of magnitude fewer in number and have much better usability than raw syslog messages. We demonstrate that they provide critical input to network troubleshooting, and network health monitoring and visualization. Copyright 2010 ACM.",Data mining; Syslog; Troubleshooting,Automated systems; Critical inputs; Data mining techniques; Data source; Full diversity; Health monitoring; Mining network; Mission critical; Monitoring network; Network events; Network faults; Network services; Network troubleshooting; Performance anomaly; Problem domain; Software/hardware; Syslog; Syslog messages; Syslogs; Three orders of magnitude; Time range; Troubleshooting; Troubleshooting networks; Automation; Data mining; Internet; Internet service providers; Metadata; Monitoring; Routers; Visualization; Network management
"Sekar V., Reiter M.K., Zhang H.",3,Revisiting the case for a minimalist approach for network flow monitoring,2010,23,"Carnegie Mellon University, Pittsburgh, PA, United States; UNC Chapel Hill, Chapel Hill, NC, United States",Carnegie Mellon University,1,USA,1,10,5,"Network management applications require accurate estimates of a wide range of flow-level traffic metrics. Given the inadequacy of current packet-sampling-based solutions, several application-specific monitoring algorithms have emerged. While these provide better accuracy for the specific applications they target, they increase router complexity and require vendors to commit to hardware primitives without knowing how useful they will be to meet the needs of future applications. In this paper, we show using trace-driven evaluations that such complexity and early commitment may not be necessary. We revisit the case for a ""minimalist"" approach in which a small number of simple yet generic router primitives collect flow-level data from which different traffic metrics can be estimated. We demonstrate the feasibility and promise of such a minimalist approach using flow sampling and sample-and-hold as sampling primitives and configuring these in a network-wide coordinated fashion using cSamp. We show that this proposal yields better accuracy across a collection of application-level metrics than dividing the same memory resources across metric-specific algorithms. Moreover, because a minimalist approach enables late binding to what applicationlevel metrics are important, it better insulates router implementations and deployments from changing monitoring needs. Copyright 2010 ACM.",Anomaly detection; Data streaming; Sampling; Traffic monitoring,Anomaly detection; Application-Specific; Data streaming; Flow sampling; Flow-level; Future applications; Management applications; Memory resources; Monitoring algorithms; Network flows; Sample-and-hold; Sampling-based; Traffic monitoring; Algorithms; Data reduction; Internet; Network management; Monitoring
"LaCurts K., Balakrishnan H.",2,Measurement and analysis of real-world 802.11 mesh networks,2010,32,"MIT Computer Science and Artificial Intelligence Lab., Cambridge, MA, United States",MIT,1,USA,1,21,17,"Despite many years of work in wireless mesh networks built using 802.11 radios, the performance and behavior of these networks in the wild is not well-understood. This lack of understanding is due in part to the lack of access to data from a wide range of these networks; most researchers have access to only one or two testbeds at any time. In recent years, however, 802.11 mesh networks networks have been deployed commercially and have real users who use the networks in a wide range of conditions. This paper analyzes data collected from 1407 access points in 110 different commercially deployed Meraki [28] wireless mesh networks, constituting perhaps the largest study of real-world 802.11 networks to date. After analyzing a 24-hour snapshot of data collected from these networks, we answer questions from a variety of active research topics, such as the accuracy of SNR-based bit rate adaptation, the impact of opportunistic routing, and the prevalence of hidden terminals. The size and diversity of our data set allows us to analyze claims previously only made in small-scale studies. In particular, we find that the SNR of a link is a good indicator of the optimal bit rate for that link, but that one could not make an SNR-to-bit rate look-up table that was accurate for an entire network. We also find that an ideal opportunistic routing protocol provides little to no benefit on most paths, and that ""hidden triples""-network topologies that can lead to hidden terminals-are more common than suggested in previous work, and increase in proportion as the bit rate increases. Copyright 2010 ACM.",802.11; Bit rate adaptation; Hidden terminals; Measurement; Mesh; Opportunistic routing; Wireless,802.11; Bit rate adaptation; Hidden terminal; Mesh; Opportunistic routing; Wireless; Electric network topology; Internet; Internet protocols; Table lookup; Wireless local area networks (WLAN); Wireless mesh networks (WMN); MESH networking
"Stanojevic R., Laoutaris N., Rodriguez P.",3,On economic heavy hitters: Shapley value analysis of 95th-percentile pricing,2010,42,"Research Telefonica, United States",Telefonica Research,1,USA,1,46,38,"Cost control for the Internet access providers (AP) influences not only the nominal speeds offered to the customers, but also other, more controversial, policies related to traffic shaping and discrimination. Given that the cost for the AP is determined by the peak-hour traffic (e.g. through the 95th-percentile), the individual user contribution towards the aggregate cost is not a linear function of its byte usage. In this paper we propose a metric for evaluating the contribution each individual user has on the peak demand, that is based on Shapley value, a well known game-theoretic concept. Given the computational complexity of calculating the Shapley value, we use a Monte Carlo method for approximating it with reasonable accuracy. We employ our methodology to study a dataset that logs per-subscriber temporal usage patterns over one month period for 10K broadband subscribers of a European AP and report observed results. Copyright 2010 ACM.",Heavy-hitters Network economics Net-neutrality Shapley value Monte-Carlo method,Aggregate costs; Broadband subscribers; Cost controls; Data sets; Heavy-hitter; Internet access providers; Linear functions; Peak demand; Reasonable accuracy; Shapley value; Traffic-shaping; Usage patterns; Computational complexity; Costs; Economics; Internet; Monte Carlo methods; Game theory
"Kalafut A.J., Gupta M., Cole C.A., Chen L., Myers N.E.",5,An empirical study of orphan DNS servers in the Internet,2010,6,"School of Computing and Information Systems, Grand Valley State University, Allendale, MI, United States; School of Informatics and Computing, Indiana University, Bloomington, IN, United States",Grand Valley State University;Indiana University,2,India;USA,2,39,30,"An orphan DNS server is a DNS server which has an address record in the DNS, even though the domain in which it resides has no DNS records itself and hence does not exist. For example, the DNS server ns.foo.com would be an orphan DNS server if it had an address record, but the domain foo.com did not exist. In this paper, we undertake the first systematic study of the prevalence of orphan DNS servers in the Internet. We also examine who is using them and what they are used for. We find that certain top-level domains (TLDs) account for a disproportionate number of orphans. We also find that some orphans are used for malicious activities and as placeholders for records from deleted domains, while others likely only exist due to simple configuration errors. Our study points to the need for better scrutiny of orphan DNS servers so they cannot be misused. Copyright 2010 ACM.",DNS; Top level domains,DNS; DNS server; Empirical studies; Malicious activities; Placeholders; Systematic study; Top level domains; Internet; Internet protocols; Servers
"Yadav S., Reddy A.K.K., Reddy A.L.N., Ranjan S.",4,Detecting algorithmically generated malicious domain names,2010,166,"Department of Electrical and Computer Engineering, Texas A and M University, College Station, TX 77843, United States; Narus Inc., Sunnyvale, CA 94085, United States",Narus Inc.;Texas A and M University,2,USA,1,23,21,"Recent Botnets such as Conficker, Kraken and Torpig have used DNS based ""domain fluxing"" for command-and-control, where each Bot queries for existence of a series of domain names and the owner has to register only one such domain name. In this paper, we develop a methodology to detect such ""domain fluxes"" in DNS traffic by looking for patterns inherent to domain names that are generated algorithmically, in contrast to those generated by humans. In particular, we look at distribution of alphanumeric characters as well as bigrams in all domains that are mapped to the same set of IP-addresses. We present and compare the performance of several distance metrics, including KL-distance, Edit distance and Jaccard measure. We train by using a good data set of domains obtained via a crawl of domains mapped to all IPv4 address space and modeling bad data sets based on behaviors seen so far and expected. We also apply our methodology to packet traces collected at a Tier-1 ISP and show we can automatically detect domain fluxing as used by Conficker botnet with minimal false positives. Copyright 2010 ACM.",Components; Domain flux; Domain names; Edit distance; Entropy; IP Fast Flux; Jaccard Index; Malicious,Components; Domain flux; Domain names; Edit distance; Fast flux; Jaccard index; Malicious; Entropy; Internet; Internet service providers; Internet protocols
"MŽrindol P., Donnet B., Bonaventure O., Pansiot J.-J.",4,On the impact of layer-2 on node degree distribution,2010,10,"UniversitŽ Catholique de Louvain, ICTEAM, Louvain-la-Neuve, Belgium; LSIIT, UniversitŽ de Strasbourg, Strasbourg, France",Universite Catholique de Louvain;UniversitŽ de Strasbourg,2,Belgium;France,2,25,4,"The Internet topology data collected through traceroute exploration has been extensively studied in the past. In particular, a remarkable property of the Internet, the power-law shape of node degree distribution, drew the attention of the research community. Several studies have since questioned this property. In this paper, based on a large dataset collected using mrinfo, we show that the node degree distribution is strongly impacted by the presence of layer-2 (L2) networks, such as switches. L2 devices interconnect a large number of routers, themselves being also involved in multiple L2 interconnections. Such a situation induces nodes with very high degree when analyzing the layer-3 (L3) graph with traceroute probing. Considering the physical design of a network, our analysis provides a lower bound on the bias generated by using only an L3 view. We also provide a model that can be a first step towards L2 aware topology generation. Copyright 2010 ACM.",Degree distribution; Layer-2; Mrinfo; Network topology,Data sets; Degree distributions; Internet topologies; Layer-2; Lower bounds; Mrinfo; Network topology; Node degree distribution; Physical design; Power-law; Research communities; Topology generation; Traceroute; Electric network topology; Internet
"Ager B., MŸhlbauer W., Smaragdakis G., Uhlig S.",4,Comparing DNS resolvers in the wild,2010,59,"T-Labs., TU Berlin, Germany; ETH Zurich, Switzerland",ETH Zurich;TU Berlin,2,Germany;Switzerland,2,34,26,"The Domain Name System (DNS) is a fundamental building block of the Internet. Today, the performance of more and more applications depend not only on the responsiveness of DNS, but also the exact answer returned by the queried DNS resolver, e. g., for Content Distribution Networks (CDN). In this paper, we compare local DNS resolvers against GoogleDNS and OpenDNS for a large set of vantage points. Our end-host measurements inside 50 commercial ISPs reveal that two aspects have a significant impact on responsiveness: (1) the latency to the DNS resolver, (2) the content of the DNS cache when the query is issued. We also observe significant diversity, even at the AS-level, among the answers provided by the studied DNS resolvers. We attribute this diversity to the location-awareness of CDNs as well as to the location of DNS resolvers that breaks the assumption made by CDNs about the vicinity of the end-user and its DNS resolver. Our findings pinpoint limitations within the DNS deployment of some ISPs, as well as the way third-party DNS resolvers bias DNS replies. Copyright 2010 ACM.",DNS resolvers; Measurement; Performance analysis,Content distribution networks; DNS resolvers; Domain name system; End users; Fundamental building blocks; Location awareness; Performance analysis; Significant impacts; Distributed parameter networks; Internet; Internet service providers; Internet protocols
"Guha S., Cheng B., Francis P.",3,Challenges in measuring online advertising systems,2010,63,"Microsoft Research India, Bangalore, India; Max Planck Institute for Software Systems, Kaiserslautern-Saarbruecken, Germany","Max Planck Institute,Germany;Microsoft",2,Germany;India,2,44,34,"Online advertising supports many Internet services, such as search, email, and social networks. At the same time, there are widespread concerns about the privacy loss associated with user targeting. Yet, very little is publicly known about how ad networks operate, especially with regard to how they use user information to target users. This paper takes a first principled look at measurement methodologies for ad networks. It proposes new metrics that are robust to the high levels of noise inherent in ad distribution, identifies measurement pitfalls and artifacts, and provides mitigation strategies. It also presents an analysis of how three different classes of advertising - search, contextual, and social networks, use user profile information today. Copyright 2010 ACM.",Advertising; Behavioral Targeting; Churn; Contextual; Facebook; Google; Rivacy; Similarity,Advertising; Behavioral Targeting; Churn; Contextual; Facebook; Google; Rivacy; Similarity; Information use; Internet; Online systems; Social networking (online)
"Fan X., Heidemann J.",2,Selecting representative IP addresses for Internet topology studies,2010,11,"USC, Information Sciences Institute, 4676 Admiralty Way, Marina del Ray, CA 90292, United States",University of Southern California,1,USA,1,17,7,"An Internet hitlist is a set of addresses that cover and can represent the the Internet as a whole. Hitlists have long been used in studies of Internet topology, reachability, and performance, serving as the destinations of traceroute or performance probes. Most early topology studies used manually generated lists of prominent addresses, but evolution and growth of the Internet make human maintenance untenable. Random selection scales to today's address space, but most random addresses fail to respond. In this paper we present what we believe is the first automatic generation of hitlists informed censuses of Internet addresses. We formalize the desirable characteristics of a hitlist: responsiveness, each representative responds to pings; completeness, they cover all the allocated IPv4 address space; and stability, list evolution is minimized when possible. We quantify the accuracy of our automatic hitlists, showing that only one-third of the Internet allows informed selection of representatives. Of informed representatives, 50-60% are likely to respond three months later, and we show that causes for non-responses are likely due to dynamic addressing (so no stable representative exists) or firewalls. In spite of these limitations, we show that the use of informed hitlists can add 1.7 million edge links (a 5% growth) to traceroute-based Internet topology studies Our hitlists are available free-of-charge and are in use by several other research projects. Copyright 2010 ACM.",Internet topology; IP Hitlist; Topology representatives,Address space; Automatic Generation; Dynamic addressing; Internet topologies; IP addresss; IP Hitlist; Random selection; Reachability; Traceroute; Internet; Topology; Internet protocols
"Li A., Yang X., Kandula S., Zhang M.",4,CloudCmp: Comparing public cloud providers,2010,505,"Duke University, United States; Microsoft Research, United States",Duke University;Microsoft,2,USA,1,9,8,"While many public cloud providers offer pay-as-you-go computing, their varying approaches to infrastructure, virtualization, and software services lead to a problem of plenty. To help customers pick a cloud that fits their needs, we develop CloudCmp, a systematic comparator of the performance and cost of cloud providers. CloudCmp measures the elastic computing, persistent storage, and networking services offered by a cloud along metrics that directly reflect their impact on the performance of customer applications. CloudCmp strives to ensure fairness, representativeness, and compliance of these measurements while limiting measurement cost. Applying CloudCmp to four cloud providers that together account for most of the cloud customers today, we find that their offered services vary widely in performance and costs, underscoring the need for thoughtful provider selection. From case studies on three representative cloud applications, we show that CloudCmp can guide customers in selecting the best-performing provider for their applications. Copyright 2010 ACM.",Cloud computing; Comparison; Cost; Performace,Cloud computing; Cloud providers; Comparison; Measurement costs; Networking services; Pay-as-you-go; Performace; Persistent storage; Software services; Virtualizations; Costs; Customer satisfaction; Internet; Sales; Distributed computer systems
"Ribeiro B., Towsley D.",2,Estimating and sampling graphs with multidimensional random walks,2010,149,"Computer Science Department, University of Massachusetts at Amherst, Amherst, MA 01002, United States",University of Massachusetts Amherst,1,USA,1,34,30,"Estimating characteristics of large graphs via sampling is a vital part of the study of complex networks. Current sampling methods such as (independent) random vertex and random walks are useful but have drawbacks. Random vertex sampling may require too many resources (time, bandwidth, or money). Random walks, which normally require fewer resources per sample, can suffer from large estimation errors in the presence of disconnected or loosely connected graphs. In this work we propose a new m-dimensional random walk that uses m dependent random walkers. We show that the proposed sampling method, which we call Frontier sampling, exhibits all of the nice sampling properties of a regular random walk. At the same time, our simulations over large real world graphs show that, in the presence of disconnected or loosely connected components, Frontier sampling exhibits lower estimation errors than regular random walks. We also show that Frontier sampling is more suitable than random vertex sampling to sample the tail of the degree distribution of the graph. Copyright 2010 ACM.",Assortativity; Estimates; Frontier sampling; Global clustering coefficient; MCMC; Power laws; Random walks,Assortativity; Estimates; Frontier sampling; Global clustering; MCMC; Power law; Random Walk; Estimation; Graph theory; Graphic methods; Internet; Random processes; Random errors
"Fusco F., Luca D.",2,High speed network traffic analysis with commodity multi-core systems,2010,96,"IBM Research - Zurich, ETH Zurich, Switzerland; Ntop, United States",ETH Zurich;IBM,2,Switzerland;USA,2,37,18,"Multi-core systems are the current dominant trend in computer processors. However, kernel network layers often do not fully exploit multi-core architectures. This is due to issues such as legacy code, resource competition of the RXqueues in network interfaces, as well as unnecessary memory copies between the OS layers. The result is that packet capture, the core operation in every network monitoring application, may even experience performance penalties when adapted to multi-core architectures. This work presents common pitfalls of network monitoring applications when used with multi-core systems, and presents solutions to these issues. We describe the design and implementation of a novel multi-core aware packet capture kernel module that enables monitoring applications to scale with the number of cores. We showcase that we can achieve high packet capture performance on modern commodity hardware. Copyright 2010 ACM.",Linux kernel; Multi-core systems; Network packet capture,Commodity hardware; Computer processors; High speed network traffic; Kernel modules; Legacy code; Linux kernel; Monitoring applications; Multi-core aware; Multi-core systems; Multicore architectures; Network interface; Network Monitoring; Network packet capture; Packet capture; Performance penalties; Computer operating systems; HIgh speed networks; Internet; Monitoring; Network architecture; Network layers; Microprocessor chips
"Anwer M.B., Nayak A., Feamster N., Liu L.",4,Network I/O fairness in virtual machines,2010,17,"School of Computer Science, Georgia Tech., United States",Georgia Tech,1,USA,1,38,30,"We present a mechanism for achieving network I/O fairness in virtual machines, by applying flexible rate limiting mechanisms directly to virtual network interfaces. Conventional approaches achieve this fairness by implementing rate limiting either in the virtual machine monitor or hypervisor, which generates considerable CPU interrupt and instruction overhead for forwarding packets. In contrast, our design pushes per-VM rate limiting as close as possible to the physical hardware themselves, effectively implementing per-virtual interface rate limiting in hardware. We show that this design reduces CPU overhead (both interrupts and instructions) by an order of magnitude. Our design can be applied either to virtual servers for cloud-based services, or to virtual routers. © 2010 ACM.",NetFPGA; network virtualization; xen,Conventional approach; Hypervisor; NetFPGA; Network virtualization; Order of magnitude; Rate limiting; Virtual interfaces; Virtual machine monitors; Virtual machines; Virtual network interfaces; Virtual servers; xen; Computer hardware; Computer simulation; Design; Network architecture
"Lischka J., Karl H.",2,RiaS: Overlay topology creation on a PlanetLab infrastructure,2010,1,"Paderborn Center for Parallel Computing, Paderborn University, 33102 Paderborn, Germany",Paderborn University,1,Germany,1,26,20,"The PlanetLab testbed was originally built to develop new technologies for distributed storage, network mapping, peer-to-peer systems, distributed hash tables and query processing in a live-traffic environment. This allowed researchers to construct their own overlay network topologies on top of IP without any need for direct Layer2 access. While this structure is easy to use for many purposes, it does not lend itself directly to experiments with new routing protocols, which need a finer-grained control of where packets flow. Enabling such tests of new protocols and architectures on the PlanetLab infrastructure is the objective of this paper. To this end, a researcher must be able to build Layer2 topologies upon the PlanetLab infrastructure and to have routing and forwarding protocols execute in such a defined infrastructure. Currently this is impossible due to the nature of PlanetLab's network virtualization. This paper describes RiaS, a tool to create customized network topologies inside of PlanetLab slices. This enables researchers to evaluate and test new routing protocols on PlanetLab. We analyze the existing shortcomings of PlanetLab, identify the prerequisites to enable routing experiments, and propose our Routing-in-a-Slice (RiaS) system to overcome this impasse. © 2010 ACM.",experimentation; network testbeds; overlay networks; routing,Distributed Hash Table; Distributed storage; experimentation; Network mapping; Network testbeds; Network topology; Network virtualization; New protocol; New technologies; Overlay network topology; Overlay topologies; Peer-to-Peer system; PlanetLab; routing; Traffic environment; Distributed computer systems; Electric network topology; Experiments; Internet protocols; Network architecture; Overlay networks; Routing protocols; Test facilities; Testbeds; Peer to peer networks
"Yeow W.-L., Westphal C., Kozat U.",3,Designing and embedding reliable virtual infrastructures,2010,65,"DoCoMo USA Labs., 3240 Hillview Ave, Palo Alto, CA 94304, United States",DoCoMo USA Labs,1,USA,1,24,18,"In a virtualized infrastructure where physical resources are shared, a single physical server failure will terminate several virtual servers and crippling the virtual infrastructures which contained those virtual servers. In the worst case, more failures may cascade from overloading the remaining servers. To guarantee some level of reliability, each virtual infrastructure, at instantiation, should be augmented with backup virtual nodes and links that have sufficient capacities. This ensures that, when physical failures occur, sufficient computing resources are available and the virtual network topology is preserved. However, in doing so, the utilization of the physical infrastructure may be greatly reduced. This can be circumvented if backup resources are pooled and shared across multiple virtual infrastructures, and intelligently embedded in the physical infrastructure. These techniques can reduce the physical footprint of virtual backups while guaranteeing reliability. © 2010 ACM.",infrastructure virtualization,Backup resources; Computing resource; Physical resources; Virtual infrastructures; Virtual network topology; Virtual node; Virtual servers; Virtualizations; Worst case; Electric network topology; Network architecture; Servers
"Bienkowski M., Feldmann A., Jurca D., Kellerer W., Schaffrath G., Schmid S., Widmer J.",7,Competitive analysis for service migration in VNets,2010,33,"Institute of Computer Science, University of Wroc_aw, Poland; T-Labs., TU Berlin, Berlin, Germany; DOCOMO Labs. Europe, Munich, Germany",TU Berlin;University of Wroclaw,2,Germany;Poland,2,19,10,"Network virtualization promises a high flexibility by decoupling services from the underlying substrate network and allowing the virtual network to adapt to the needs of the service, e.g., by migrating servers or/and parts of the network. We study a system (e.g., a gaming application) where network virtualization is used to support thin client applications for mobile devices to improve their QoS. To deal with the dynamics of both the mobile clients as well as the ability to migrate services closer to the client location we advocate, in this paper, the use of competitive analysis. After identifying the parameters that characterize the cost-benefit tradeoff for this kind of application we propose an online migration strategy. The strength of the strategy is that it is robust with regards to any arbitrary request access pattern. In particular, it is close to the optimal offline algorithm that knows the access pattern in advance. In this paper we present both an optimal offline algorithm based on dynamic programming techniques to find the best migration paths for a given request sequence, and a O(_ log n)-competitive migration strategy MIG where _ is the ratio between maximal and minimal link capacity in the substrate network for a simplified model. This is almost optimal for small _, as we also show that there are networks where no online algorithm can achieve a ratio below ½(log n/log log n). In contrast, the optimal solution without migration can only achieve a competitive ratio that is linear in the network diameter. Our simulations indicate that the competitive ratio of MIG is robust to the network size, and that the ratio is small if the request dynamics are limited and the requests are correlated. © 2010 ACM.",competitive analysis; network virtualization; online algorithms,Access patterns; Competitive analysis; Competitive ratio; Cost-benefit tradeoffs; High flexibility; Link capacities; Migration path; Migration strategy; Mobile client; Network diameter; Network size; Network virtualization; Off-line algorithm; ON dynamics; On-line algorithms; Optimal solutions; Service migration; Simplified models; Substrate networks; Thin clients; Virtual networks; Algorithms; Computer simulation; Dynamic programming; Mobile devices; Optimization; Network architecture
"Houidi I., Louati W., Zeghlache D., Papadimitriou P., Mathy L.",5,Adaptive virtual network provisioning,2010,79,"Institut Telecom., Telecom. SudParis, Evry, France; Computing Dept., Lancaster University, Lancaster, United Kingdom",Lancaster University,1,France;UK,2,24,19,"In the future, virtual networks will be allocated, maintained and managed much like clouds offering flexibility, extensibility and elasticity with resources acquired for a limited time and even on a lease basis. Adaptive provisioning is required to maintain virtual network topologies, comply with established contracts, expand initial allocations on demand, release resources no longer useful, optimize resource utilization and respond to anomalies, faults and evolving demands. In this paper, we elaborate on adaptive virtual resource provisioning to maintain virtual networks, allocated initially on demand, in response to a virtual network creation request. We propose a distributed fault-tolerant embedding algorithm, which relies on substrate node agents to cope with failures and severe performance degradation. This algorithm coupled with dynamic resource binding is integrated and evaluated within a medium-scale experimental infrastructure. © 2010 ACM.",fault-tolerant embedding; network virtualization; virtual network provisioning,Adaptive virtual networks; Fault-tolerant embedding; Network virtualization; Node agents; Performance degradation; Resource binding; Resource utilizations; Virtual network topology; Virtual networks; Virtual resource; Electric network topology; Fault tolerant computer systems; Network architecture
"Yin D., Unnikrishnan D., Liao Y., Gao L., Tessier R.",5,Customizing virtual networks with partial FPGA reconfiguration,2010,12,"Dept. of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA 01003, United States; Northwestern Polytechnical University, Xi'an, Shanxi, China",Northwestern Polytechnical University;University of Massachusetts Amherst,2,China;USA,2,27,25,"Recent FPGA-based implementations of network virtualization represent a significant step forward in network performance and scalability. Although these systems have been shown to provide orders of magnitude higher performance than solutions using software-based routers, straightforward reconfiguration of hardware-based virtual networks over time is a challenge. In this paper, we present the implementation of a reconfigurable network virtualization substrate that combines several partially-reconfigurable hardware virtual routers with software virtual routers. The update of hardware-based virtual networks in our system is supported via real-time partial FPGA reconfiguration. Hardware virtual networks can be dynamically reconfigured in a fraction of a second without affecting other virtual networks operating in the same FPGA. A heuristic has been developed to allocate virtual networks with diverse bandwidth requirements and network characteristics on this heterogeneous virtualization substrate. Experimental results show that the reconfigurable virtual routers can forward packets at line rate. Partial reconfiguration allows for 20x faster hardware reconfiguration than a previous approach which migrated hardware virtual networks to software. © 2010 ACM.",FPGA; network virtualization; partial reconfiguration,Bandwidth requirement; Forward packets; FPGA; FPGA-based implementation; Line rate; Network characteristics; Network virtualization; Orders of magnitude; Partial reconfiguration; Re-configurable; Reconfigurable network; Software-based router; Virtual networks; Virtualizations; Hardware; Network performance; Reconfigurable hardware; Routers; Network architecture
"Luo Y., Murray E., Ficarra T.L.",3,Accelerated virtual switching with programmable NICs for scalable data center networking,2010,10,"Dept. of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, MA, United States",University of Massachusetts Lowell,1,USA,1,26,18,"Recently virtual switches in data center hosts have been employed to interconnect virtual machines (VMs) within data center networks. Such a virtual network layer, however, faces performance challenges when the number of VMs and the line rates scale up. Motivated by the performance and programmability of intelligent network interface cards (NICs), we propose to offload the virtual switching onto such programmable NICs (PNICs) to achieve scalable VM networking. We describe the design and advantages of a novel PNIC-oriented data center network architecture. We then present a prototype of a PNIC based virtual switch that supports virtual NICs, OpenFlow switching, clock synchronization and flow monitoring. We finally introduce an efficient packet buffering mechanism enabled by such PNICs and OpenFlow-capable top-of-rack switches for reducing the congestion on network fabric. © 2010 ACM.",data centers; packet buffering; programmable network interface card; virtual switch,Clock Synchronization; Data centers; Flow monitoring; Intelligent network interface; Line rate; Network fabric; Packet buffering; Programmability; Programmable network interface cards; Scale-up; Virtual machines; Virtual networks; virtual switch; Interfaces (computer); Network architecture; Programmed control systems; Satellite communication systems; Switching circuits; Network layers
"Bhanage G., Seskar I., Mahindra R., Raychaudhuri D.",4,Virtual basestation: Architecture for an open shared WiMAX framework,2010,59,"WINLAB, Rutgers University, 671 US1 South, North Brunswick, NJ 08902, United States; NEC Labs. America, 4 Independence Way, Princeton, NJ 08540, United States",Rutgers University,1,USA,1,20,18,"This paper presents the architecture and performance evaluation of a virtualized wide-area ""4G"" cellular wireless network. Specifically, it addresses the challenges of virtualization of resources in a cellular base station to enable shared use by multiple independent slice users (experimenters or mobile virtual network operators), each with possibly distinct flow types and network layer protocols. The proposed virtual basestation architecture is based on an external substrate which uses a layer-2 switched datapath, and an arbitrated control path to the WiMAX basestation. The framework implements virtualization of base station's radio resources to achieve isolation between multiple virtual networks. An algorithm for weighted fair sharing among multiple slices based on an airtime fairness metric has been implemented for the first release. Preliminary experimental results from the virtual basestation prototype are given, demonstrating mobile network performance, isolation across slices with different flow types, and custom flow scheduling capabilities. © 2010 ACM.",802.16e; GENI; mobile WiMAX; MVNO; network virtualization; testbeds; virtual basestation,802.16e; GENI; Mobile WiMAX; MVNO; Network virtualization; Base stations; Computer network performance evaluation; Mathematical operators; Mobile telecommunication systems; Network architecture; Network layers; Network performance; Network protocols; Telecommunication networks; Test facilities; Testbeds; Wimax; Wireless networks
"Chowdhury M., Samuel F., Boutaba R.",3,PolyViNE: Policy-based virtual network embedding across multiple domains,2010,114,"Computer Science Division, University of California, Berkeley, CA, United States; Cheriton School of Computer Science, University of Waterloo, ON, Canada",University of California Berkeley;University of Waterloo,2,Canada;USA,2,25,23,"Intra-domain virtual network embedding is a well studied problem in the network virtualization literature. For most practical purposes, however, virtual networks (VNs) must be provisioned across heterogeneous administrative domains managed by multiple infrastructure providers (InPs). In this paper we present PolyViNE, a policy-based inter-domain VN embedding framework that embeds end-to-end VNs in a decentralized manner. PolyViNE introduces a distributed protocol that coordinates the VN embedding process across participating InPs and ensures competitive prices for service providers (SPs), i.e., VN owners. We also present a location aware VN request forwarding mechanism - based on a hierarchical addressing scheme (COST) and a location awareness protocol (LAP) - to allow faster embedding and outline scalability and performance characteristics of PolyViNE using quantitative and qualitative evaluations. © 2010 ACM.",decentralized embedding; inter-domain virtual network embedding; network virtualization; policy-based resource allocation,Addressing scheme; Administrative domains; Competitive prices; decentralized embedding; Distributed protocols; Embedding process; Inter-domain; Intra-domain; Location awareness; Location-aware; Multiple domains; Network virtualization; Performance characteristics; policy-based resource allocation; Qualitative evaluations; Service provider; Virtual networks; Resource allocation; Wireless sensor networks; Network architecture
"Yap K.-K., Sherwood R., Kobayashi M., Huang T.-Y., Chan M., Handigol N., McKeown N., Parulkar G.",8,Blueprint for introducing innovation into wireless mobile networks,2010,115,"Stanford University, United States; Deutsche Telekom. Inc., R and D Lab., United States; NEC, United States",Deutsche Telekom;Stanford University,2,USA,1,16,6,"In the past couple of years we've seen quite a change in the wireless industry: Handsets have become mobile computers running user-contributed applications on (potentially) open operating systems. It seems we are on a path towards a more open ecosystem; one that has been previously closed and proprietary. The biggest winners are the users, who will have more choice among competing, innovative ideas. The same cannot be said for the wireless network infrastructure, which remains closed and (mostly) proprietary, and where innovation is bogged down by a glacial standards process. Yet as users, we are surrounded by abundant wireless capacity and multiple wireless networks (WiFi and cellular), with most of the capacity off-limits to us. It seems industry has little incentive to change, preferring to hold onto control as long as possible, keeping an inefficient and closed system in place. This paper is a ""call to arms"" to the research community to help move the network forward on a path to greater openness. We envision a world in which users can move freely between any wireless infrastructure, while providing payment to infrastructure owners, encouraging continued investment. We think the best path to get there is to separate the network service from the underlying physical infrastructure, and allow rapid innovation of network services, contributed by researchers, network operators, equipment vendors and third party developers. We propose to build and deploy an open - but backward compatible - wireless network infrastructure that can be easily deployed on college campuses worldwide. Through virtualization, we allow researchers to experiment with new network services directly in their production network. © 2010 ACM.",flowvisor; mobile networks; mobility; openflow; software-defined networks; wireless,flowvisor; Mobile networks; mobility; openflow; software-defined networks; wireless; Computer operating systems; Ecology; Investments; Network architecture; Research; Wi-Fi; Wireless networks
"DiCioccio L., Teixeira R., Rosenberg C.",3,Impact of home networks on end-to-end performance: Controlled experiments,2010,19,"Technicolor, UPMC Paris Universitas, France; CNRS, UPMC Paris Universitas, France; University of Waterloo, Canada",UPMC Sorbonne UniversitŽs;University of Waterloo,2,Canada;France,2,21,21,"This paper performs controlled experiments to analyze the performance of home networks. We show that the home network has a significant impact on end-to-end performance. For example, watching TV can double the time to download a file; and deploying a wireless network significantly increases round-trip times. Despite its impact on end-to-end performance, most existing diagnosis tools ignore the home network when identifying the cause of performance problems. To make matters worse, our results show that simple techniques that directly probe the home gateway cannot reliably identify that the home network is the cause of performance degradation. We are currently designing a technique based on packet bursts to identify performance problems caused by the home network. Our results for Ethernet based home networks are encouraging. © 2010 ACM.",home networks; monitoring; performance evaluation; troubleshooting,Controlled experiment; Diagnosis tools; End-to-end performance; Home gateway; Home networks; Performance degradation; Performance evaluation; Performance problems; Round-trip time; Significant impacts; Troubleshooting; Carrier communication; Experiments; Personal communication systems; Gateways (computer networks)
"Calvert K.L., Edwards W.K., Feamster N., Grinter R.E., Deng Y., Zhou X.",6,Instrumenting home networks,2010,17,"Lab. for Advanced Networking, University of Kentucky, Lexington, KY, United States; College of Computing, Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech;University of Kentucky,2,USA,1,15,6,"In managing and troubleshooting home networks, one of the challenges is in knowing what is actually happening. Availability of a record of events that occurred on the home network before trouble appeared would go a long way toward addressing that challenge. In this position/work-in-progress paper, we consider requirements for a general-purpose logging facility for home networks. Such a facility, if properly designed, would potentially have other uses. We describe several such uses and discuss requirements to be considered in the design of a logging platform that would be widely supported and accepted. We also report on our initial experience deploying such a facility. © 2010 ACM.",home network management; home network troubleshooting,Home network management; home network troubleshooting; Home networks; Troubleshooting; Carrier communication; Personal communication systems; Network management
"An X., Prasad V., Niemegeers I.",3,Exploring the suitability of 60 GHz radio for building in-home networks,2010,0,"Faculty of EEMCS, Delft University of Technology, Netherlands",TU Delft,1,Netherlands,1,10,6,"60 GHz radio technology is highly promising since it can offer multi-Gbps data rate for short range wireless communication. Hence it is able to support in-home wireless multimedia applications such as high-definition video streaming, ultra high speed content downloads, etc. Hitherto, the main research efforts have been on 60 GHz physical layer design and channel model investigations. However, the unique properties of 60 GHz radio, viz, the use of directional antennas and link blockage problem impose new challenges for the higher layer protocol design. We explore the suitability of 60 GHz radio technology for in-home networks. In this paper we provide a comprehensive overview regarding medium access control related protocol design issues. Moreover, we also identify a number of directions which are helpful to develop the future architecture as well as technology to realize the grand vision of 60 GHz home networks. © 2010 ACM.",60GHz radio; in-home network; medium access control; performance analysis,60-GHz radio; Channel model; Data rates; Directional Antenna; High-definition videos; Higher-layer protocols; Home networks; in-home network; Medium access; Multi-Gbps; Performance analysis; Physical layers; Protocol design; Research efforts; Short-range wireless communications; Ultra high speed; Wireless multimedia applications; Carrier communication; Design; Directive antennas; Network protocols; Personal communication systems; Security systems; Videotex; Wireless telecommunication systems; Medium access control
"Yang J., Edwards W.K.",2,A study on network management tools of householders,2010,15,"HCI Group, LG Advanced Research Institute, United States; GVU Center, School of Interactive Computing, Georgia Tech., United States",GVU Center;Georgia Tech;LG Advanced Research Institute,3,USA,1,19,18,"In this paper, we report on the tools that users currently rely on for their home network management, the usability problems with those tools, and some desirable features for a tool for householders. The data was collected from 25 home network users in Atlanta, USA. The results of this study provide initial clues on the practices of home network management of householders, as well as design implications for future kinds of home network management tools. © 2010 ACM.",home network; management tools; usability problems,Atlanta; Design implications; Home network management; Home networks; management tools; Network management tools; Usability problems; Carrier communication; Management; Personal communication systems; Network management
"Chhabra P., Laoutaris N., Rodriguez P., Sundaram R.",4,Home is where the (fast) internet is: Flat-rate compatible incentives for reducing peak load,2010,3,"Telefonica Research, Barcelona, Spain; Northeastern University, Boston, MA, United States",Northeastern University;Telefonica Research,2,Spain;USA,2,18,12,"Internet traffic to homes is surging, driven by the demand for rich content and the proliferation of home networks. This creates a huge problem for ISPs since residential customers expect the certainty of a fixed bill while ISPs do not want to upgrade backhaul equipment frequently in the absence of extra revenue streams. We consider simple variants on existing flat-rate schemes that will enable homes to self-select a portion of their peak hours traffic and move it to non-peak hours to benefit from offered incentives. We present a well-defined formulation of the problem and characterize its computational complexity. We show that a simple fractional algorithm achieves the optimal traffic reallocation and is realizable with small modifications to existing infrastructure. The fractional model also captures the reality that homes may be willing to move a fraction of their delay-tolerant traffic in response to appropriate incentives. Using trace-driven simulations based on well-accepted utility models and actual backbone traffic from a large ISP, we demonstrate that our incentive scheme can substantially lower peak congestion while still satisfying the increased demand of home networks. © 2010 ACM.",delay tolerance; flat-rate compatible; incentives; user greediness,delay tolerance; Delay tolerant; flat-rate compatible; Fractional model; Home networks; Incentive schemes; incentives; Internet traffic; Peak load; Rate-compatible; Residential customers; Revenue streams; Trace driven simulation; user greediness; Utility model; Computational complexity; Computer simulation; Internet; Internet service providers; Personal communication systems; Traffic congestion
"Erman J., Gerber A., Sen S.",3,HTTP in the home: It is not just about PCs,2010,2,"AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs,1,USA,1,12,9,"HTTP (Hypertext Transport Protocol) was originally primarily used for human-initiated client-server communications launched from web browsers, traditional computers and laptops. However, today it has become the protocol of choice for a bewildering range of applications from a wide array of emerging devices like smart TVs and gaming consoles. This paper presents an initial study characterizing the non-traditional sources of HTTP traffic such as consumer devices and automated updates in the overall HTTP traffic for residential Internet users. Among our findings, 13% of all HTTP traffic in terms of bytes is due to non-traditional sources, with 5% being from consumer devices such as WiFi enabled smartphones and 8% generated from automated software updates and background processes. Our findings show that 11% of all HTTP requests are caused by communications with advertising servers from as many as 190 countries worldwide, suggesting the widespread prevalence of such activities. Overall, our findings start to answer questions about what is the state of traffic generated in these smart homes. © 2010 ACM.",consumer devices; home networks; traffic classification,Client-server communication; Consumer devices; Gaming consoles; home networks; HTTP traffic; Internet users; Non-traditional; Smart homes; Smart-phones; Software updates; Traditional computers; Traffic classification; Transport protocols; Hypertext systems; Internet protocols; Laptop computers; Personal communication systems; Servers; Telecommunication traffic; Web browsers; World Wide Web; HTTP
"Mamatas L., Psaras I., Pavlou G.",3,Incentives and algorithms for broadband access sharing,2010,12,"Dept. of Electronic and Electrical Engineering, University College London, Torrington Place, WC1E 7JE, London, United Kingdom",University College London,1,UK,1,16,12,"The unprecedented growth of the mobile (Smart)phone industry that comes together with the corresponding application development market has made apparent that mobile networking through 3G links is just about to reach an unbreakable limit, in terms of network capacity. The networking research community has recently started considering alternative connectivity approaches to support and boost the performance of mobile networking. In particular, researchers have identified a big amount of ""power"", hidden at the edges of the network, which remains there unexploited and is no other than the WiFi technology deployed in home-networks. We explore incentives and algorithms for Broadband Access Sharing to support nomadic users and show that ubiquitous connectivity in densely populated areas is already possible, since the infrastructure is already there, waiting to be used. © 2010 ACM.",broadband access sharing; load-balancing; UPN incentives; UPNs; user-provided networks,Broadband access; load-balancing; UPN incentives; UPNs; user-provided networks; Personal communication systems; Wi-Fi; Wireless networks
"Anand A., Gember A., Akella A., Sekar V.",4,Tracking semantic relationships for effective data management in home networks,2010,3,"University of Wisconsin, Madison, Madison, WI, United States; Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University;University of Wisconsin-Madison,2,USA,1,9,7,"The amount of data that home users generate, store, and peruse has grown significantly in the past few years. Increasingly, organizing this huge amount of data - in order to make it easy to browse, query and access - is becoming challenging. Many recent proposals have emphasized the importance of data management in home networks and proposed mechanisms for managing replicas across devices to increase availability. Essentially, they capture the relationship ""is copy of"" between files across devices. However, files can be semantically related. Users are often interested in finding data that has such semantic relationships; tracking these relationships helps users to effectively search based on content or human-understandable context, organize data and manage the limited storage while ensuring availability of information. However, inferring semantic relationships just based on user-defined tags and file names can be challenging, since users may not follow any standard or unique naming conventions. We argue that such semantic relationships should be derived on the basis of content itself, and propose to leverage recent developments in multimedia processing literature, with minimal user involvement. The decentralized, heterogeneous and dynamic operational environment of home networks present interesting systems and network challenges. In this paper, we have highlighted several candidate designs and system-optimizations that can help build an effective semantic-aware data management for home networks. As ongoing work, we are working on a prototype implementation of a decentralized data management system. © 2010 ACM.",content fingerprinting; data management; home networks; retrieval,Content fingerprinting; data management; Data management system; Home networks; Home users; Limited storage; Multimedia processing; Operational environments; Prototype implementations; retrieval; Search-based; Semantic relationships; User involvement; Digital watermarking; Information management; Personal communication systems; Security of data; Network management
"MŸller A., Kinkelin H., Ghai S.K., Carle G.",4,A secure service infrastructure for interconnecting future home networks based on DPWS and XACML,2010,9,"Network Architectures and Services, Technische UniversitŠt MŸnchen, Germany; Delhi College of Engineering, India; TUM, Germany",Delhi College of Engineering;TU Munich,2,Germany;India,2,14,12,"Home networks differ from most other networks since they are usually administrated by inexperienced users. Today, protocols such as Universal Plug and Play (UPnP) support zero-configuration networking and are used for data-sharing and entertainment. However, security mechanisms are neglected and are not integrated into current UPnP devices. This becomes even more of an issue when we think of future interconnected home networks where many users and devices will interact. A possible successor of UPnP, the Devices Profile for Web Services (DPWS), is built upon the standard Web-Services(WS) stack and thus also provides WS-Security. However, the configuration of fine-grained access rights for DPWS actions (e.g. for browsing through a media collection) is not defined. This paper describes how to use DPWS and the security framework XACML as a basis for a secure service infrastructure for future home networks. Templates for policies can be auto-generated and a trust model based on X.509 certificates is used for identifying devices and for the interconnection of multiple home networks. © 2010 ACM.",DPWS; home networking; plug and play; security; trust; XACML,DPWS; home networking; Plug and play; security; trust; XACML; Internet protocols; Web services; Personal communication systems
Feamster N.,1,Outsourcing home network security,2010,47,"School of Computer Science, Georgia Tech., United States",Georgia Tech,1,USA,1,27,14,"The growth of home and small enterprise networks brings with it a large number of devices and networks that are either managed poorly or not at all. Hosts on these networks may become compromised and become sources of spam, denial-of-service traffic, or the site of a scam or phishing attack site. Although a typical user now knows how to apply software updates and run anti-virus software, these techniques still require user vigilance, and they offer no recourse when a machine ultimately becomes compromised. Rather than having individual networks managed independently, we propose to outsource the management and operation of these networks to a third party that has both operations expertise and a broader view of network activity. Our approach harnesses two trends: (1) the advent of programmable network switches, which offer flexibility and the possibility for remote management; and (2) the increasing application of distributed network monitoring and inference algorithms to network security problems (an appealing technique because of its ability to reveal coordinated behavior that may represent an attack). © 2010 ACM.",home networking; network security; programmable networking,Antivirus softwares; Coordinated behavior; Denial of Service; Distributed networks; Home Networking; Individual network; Inference algorithm; Network activities; Network security problems; Outsource; Phishing attacks; Programmable network; programmable networking; Remote management; Small enterprise; Software updates; Third parties; Carrier communication; Inference engines; Personal communication systems; Network security
"Farrington N., Porter G., Radhakrishnan S., Bazzaz H.H., Subramanya V., Fainman Y., Papen G., Vahdat A.",8,Helios: A hybrid electrical/optical switch architecture for modular data centers,2010,443,"University of California, San Diego, CA, United States",University of California San Diego,1,USA,1,11,11,"The basic building block of ever larger data centers has shifted from a rack to a modular container with hundreds or even thousands of servers. Delivering scalable bandwidth among such containers is a challenge. A number of recent efforts promise full bisection bandwidth between all servers, though with significant cost, complexity, and power consumption. We present Helios, a hybrid electrical/optical switch architecture that can deliver significant reductions in the number of switching elements, cabling, cost, and power consumption relative to recently proposed data center network architectures. We explore architectural trade offs and challenges associated with realizing these benefits through the evaluation of a fully functional Helios prototype. © 2010 ACM.",data center networks; optical networks,Basic building block; Bisection bandwidth; Data centers; Modular data; Optical networks; Power Consumption; Switch architectures; Switching elements; Trade off; Fiber optic networks; Satellite communication systems; Network architecture
"Kwak H., Choi Y., Eom Y.-H., Jeong H., Moon S.",5,Mining communities in networks: A solution for consistency and its evaluation,2009,41,"Computer Science Dept., KAIST, South Korea; Samsung Advanced Institute of Technology, South Korea; Department of Physics, KAIST, South Korea",KAIST;Samsung Advanced Institute of Technology,2,South Korea,1,62,49,"Online social networks pose significant challenges to computer scientists, physicists, and sociologists alike, for their massive size, fast evolution, and uncharted potential for social computing. One particular problem that has interested us is community identification. Many algorithms based on various metrics have been proposed for identifying communities in networks [18, 24], but a few algorithms scale to very large networks. Three recent community identification algorithms, namely CNM [16],Wakita [59], and Louvain [10], stand out for their scalability to a few millions of nodes. All of them use modularity as the metric of optimization. However, all three algorithms produce inconsistent communities every time the input ordering of nodes to the algorithms changes. We propose two quantitative metrics to represent the level of consistency across multiple runs of an algorithm: pairwise membership probability and consistency. Based on these two metrics, we propose a solution that improves the consistency without compromising the modularity. We demonstrate that our solution to use pairwise membership probabilities as link weights generates consistent communities within six or fewer cycles for most networks. However, our iterative, pairwise membership reinforcing approach does not deliver convergence for Flickr, Orkut, and Cyworld networks as well for the rest of the networks. Our approach is empirically driven and is yet to be shown to produce consistent output analytically. We leave further investigation into the topological structure and its impact on the consistency as future work. In order to evaluate the quality of clustering, we have looked at 3 of the 48 communities identified in the AS graph. Surprisingly, they all have either hierarchical, geographical, or topological interpretations to their groupings. Our preliminary evaluation of the quality of communities is promising. We plan to conduct more thorough evaluation of the communities and study network structures and their evolutions using our approach. Copyright 2009 ACM.",AS graph; CNM; Community; Consistent community identification; Louvain; Modularity; Social networks; Wakita,AS graph; CNM; Community; Community identification; Louvain; Modularity; Social Networks; Wakita; Algorithms; Computer aided network analysis; Iterative methods; Online systems; Social networking (online); Social sciences computing; Topology; Quality control
"Bush R., Maennel O., Roughan M., Uhlig S.",4,Internet optometry: Assessing the broken glasses in internet reachability,2009,50,"IIJ, Tokyo, Japan; Loughborough University, United Kingdom; University of Adelaide, Australia; TU Berlin/T-Labs, Berlin, Germany",Loughborough University;TU Berlin;University of Adelaide,3,Australia;Germany;Japan;UK,4,44,37,"Reachability is thought of as the most basic service provided by today's Internet. Unfortunately, this does not imply that the community has a deep understanding of it. Researchers and operators rely on two views of reachability: control/routing- and data-plane measurements, but both types of measurements suffer from biases and limitations. In this paper, we illustrate some of these biases, and show how to design controlled experiments which allow us to ""see"" through the limitations of previous measurement techniques. For example, we discover the extent of default routing and its impact on reachability. This explains some of the previous unexpected results from studies that compared control- and data-plane measurements. However, not all limitations of visibility given by routing and probing tools can be compensated for by methodological improvements. We will show in this paper, that some of the limitations can be carefully addressed when designing an experiment, e.g. not seeing the reverse path taken by a probe can be partly compensated for by our methodology, called dual probing. However, compensating for other biases through more measurements may not always be possible. Therefore, calibration of expectations and checks of assumptions are critical when conducting measurements that aim at making conclusions about topological properties of the Internet. Copyright 2009 ACM.",Control-plane; Data-plane; Default-routing; Limitation of data; Reachability; Routing,Control-plane; Data-plane; Default-routing; Limitation of data; Reachability; Routing; Experiments; Topology; Internet
"Portoles-Comeras M., Cabellos-Aparicio A., Banchs A., Mangues-Bafalluy J., Domingo-Pascual J.",5,Impact of transient CSMA/CA access delays on active bandwidth measurements,2009,8,"Centre Tecnologic DeTelecomunicacions de Catalunya, Castelldefels (Barcelona), Spain; Departament d'Arquitectura de Computadors, Universitat Politecnica de Catalunya, Barcelona, Spain; Universidad Carlos III de Madrid, Leganes, Spain",Universidad Carlos III de Madrid;Universitat Politecnica de Catalunya,2,Spain,1,32,29,"WLAN devices based on CSMA/CA access schemes have become a fundamental component of network deployments. In such wireless scenarios, traditional networking applications, tools, and protocols, with their built-in measurement techniques, are usually run unchanged. However, their actual interaction with the dynamics of underlying wireless systems is not yet fully understood. A relevant example of such built-in techniques is bandwidth measurement. When considering WLAN environments, various preliminary studies have shown that the application of results obtained in wired setups is not straightforward. Indeed, the contention for medium sharing among multiple users inherent to CSMA/CA access schemes has remarkable consequences on the behavior of and results obtained by bandwidth measurement techniques. In this paper, we focus on evaluating the effect of CSMA/CA-based contention on active bandwidth measurement techniques. As a result, it presents the rate response curve in steady state of a system with both FIFO and CSMA/CA-based contending cross-traffic. We also find out that the distribution of access delay shows a transient regime before reaching a stationary state. The duration of such transient regime is characterized and bounded. We also show how dispersion-based measurements that use a short number of probing packets are biased measurements of the achievable throughput, the origin of this bias lying on the transient detected in the access delay of probing packets. Overall, the results presented in this paper have several consequences that are expected to influence the design of bandwidth measurement tools as well as to better understand the results obtained with them in CSMA/CA links. Copyright 2009 ACM.",Achievable throughput; Bandwidth measurements; CSMA/CA; Wireless,Achievable throughputs; Bandwidth measurements; CSMA/CA; Fundamental component; Measurement techniques; Network deployment; Networking applications; Preliminary studies; Bandwidth; Radio; Carrier sense multiple access
"Lumezanu C., Baden R., Spring N., Bhattacharjee B.",4,Triangle inequality variations in the internet,2009,41,"Department of Computer Science, University of Maryland, College Park, MD 20742, United States",University of Maryland College Park,1,USA,1,18,16,"Triangle inequality violations (TIVs) are important for latency sensitive distributed applications. On one hand, they can expose opportunities to improve network routing by finding shorter paths between nodes. On the other hand, TIVs can frustrate network embedding or positioning systems that treat the Internet as a metric space where the triangle inequality holds. Even though triangle inequality violations are both significant and curious, their study has been limited to aggregate data sets that combine measurements taken over long periods of time. The limitations of these data sets open crucial questions in the design of systems that exploit (or avoid) TIVs: are TIVs stable or transient? Or are they illusions caused by aggregating measurements taken at different times? We collect latency matrices at varying sizes and time granularities and study dynamic properties of triangle inequality violations in the Internet. We show that TIVs are not results of measurement error and that their number varies with time. We examine how latency aggregates of data measured over longer periods of time preserve TIVs. Using medians to compute violations eliminates most of the TIVs that appear sporadically during the measurement but it misses many of the ones that are present for more than five hours. Copyright 2009 ACM.",Latency; TIV; Triangle inequality violation; Variation,Distributed applications; Latency; Positioning system; TIV; Triangle inequality; Triangle inequality violation (TIVs); Triangle inequality violations; Variation; Internet; Aggregates
"Zhu Y., Rexford J., Sen S., Shaikh A.",4,Impact of prefix-match changes on IP reachability,2009,5,"Princeton University, United States; AT and T Labs-Research, United States",AT and T Labs;Princeton University,2,USA,1,20,17,"Although most studies of Internet routing treat each IP address block (or prefix) independently, the relationship between prefixes is important because routers ultimately forward packets based on the""longest-matching prefix."" In fact, the most-specific prefix for a given destination address may change over time, as BGP routes are announced and withdrawn. Even if the most-specific route is withdrawn, routers may still be able to deliver packets to the destination using a less-specific route. In this paper, we analyze BGP update messages and Netflow traffic traces from a large ISP to characterize both the changes to the longest-matching prefix over time and the resulting effects on end-to-end reachability of the destination hosts. To drive our analysis, we design and implement an efficient online algorithm for tracking changes in the longest-matching prefix for each IP address. We analyze the BGP message traces to identify the reasons for prefix-match changes, including failures, route flapping, sub-prefix hijacking, and load-balancing policies. Our preliminary analysis of the Netflow data suggests that the relationship between BGP updates and IP reachability is sometimes counterintuitive. Copyright 2009 ACM.",BGP; IP reachability; Longest-matching prefix,BGP; Design and implements; Internet routing; Longest-matching prefix; On-line algorithms; Preliminary analysis; Reachability; Update messages; Digital storage; Internet service providers; Internet protocols
"Pietrzyk M., Costeux J.-L., Urvoy-Keller G., En-Najjary T.",4,Challenging statistical classification for operational usage: The ADSL case,2009,41,"Orange Labs, France; Eurecom, France",Eurecom,1,France,1,27,22,"Accurate identification of network traffic according to application type is a key issue for most companies, including ISPs. For example, some companies might want to ban p2p traffic from their network while some ISPs might want to offer additional services based on the application. To classify applications on the fly, most companies rely on deep packet inspection (DPI) solutions. While DPI tools can be accurate, they require constant updates of their signatures database. Recently, several statistical traffic classification methods have been proposed. In this paper, we investigate the use of these methods for an ADSL provider managing many Points of Presence (PoPs). We demonstrate that statistical methods can offer performance similar to the ones of DPI tools when the classifier is trained for a specific site. It can also complement existing DPI techniques to mine traffic that the DPI solution failed to identify. However, we also demonstrate that, even if a statistical classifier is very accurate on one site, the resulting model cannot be applied directly to other locations. We show that this problem stems from the statistical classifier learning site specific information. Copyright 2009 ACM.",Machine learning; Traffic classification,Deep packet inspection (DPI); Network traffic; Operational usage; Points of presences; Site-specific information; Statistical classification; Statistical classifier; Traffic classification; Classification (of information); Industry; Internet service providers; Learning systems; Telecommunication traffic
"Balakrishnan M., Mohomed I., Ramasubramanian V.",3,Where's that phone?: Geolocating IP addresses on 3G networks,2009,53,"Microsoft Research Silicon Valley, Mountain View, CA 94043, United States",Microsoft,1,USA,1,13,6,"Cell phones connected to high-speed 3G networks constitute an increasingly important class of clients on the Internet. From the viewpoint of the servers they connect to, such devices are virtually indistinguishable from conventional end- hosts. In this study, we examine the IP addresses seen by Internet servers for cell phone clients and make two observations. First, individual cell phones can expose different IP addresses to servers within time spans of a few minutes, rendering IP-based user identification and blocking inadequate. Second, cell phone IP addresses do not embed geographical information at reasonable fidelity, reducing the effectiveness of commercial geolocation tools used by websites for fraud detection, server selection and content customization. In addition to these two observations, we show that application- level latencies between cell phones and Internet servers can differ greatly depending on the location of the cell phone, but do not vary much at a given location over short time spans; as a result, they provide fine-grained location information that IPs do not. Copyright 2009 ACM.",3G networks; Geolocation; Smartphones,3G Networks; Content customization; Geographical information; Geolocations; Individual cells; Location information; Server selection; User identification; 3G mobile communication systems; Cellular telephones; Internet; Mobile phones; Smartphones; Telecommunication equipment; Internet protocols
"Rubinstein B.I.P., Nelson B., Huang L., Joseph A.D., Lau S.-H., Rao S., Taft N., Tygar J.D.",8,Antidote: Understanding and defending against poisoning of anomaly detectors,2009,94,"Computer Science Division, University of California, Berkeley, United States; Intel Labs Berkeley, United States",University of California Berkeley,1,USA,1,33,31,"Statistical machine learning techniques have recently garnered increased popularity as a means to improve network design and security. For intrusion detection, such methods build a model for normal behavior from training data and detect attacks as deviations from that model. This process invites adversaries to manipulate the training data so that the learned model fails to detect subsequent attacks. We evaluate poisoning techniques and develop a defense, in the context of a particular anomaly detector-namely the PCA-subspace method for detecting anomalies in backbone networks. For three poisoning schemes, we show how attackers can substantially increase their chance of successfully evading detection by only adding moderate amounts of poisoned data. Moreover such poisoning throws off the balance between false positives and false negatives thereby dramatically reducing the efficacy of the detector. To combat these poisoning activities, we propose an antidote based on techniques from robust statistics and present a new robust PCA-based detector. Poisoning has little effect on the robust model, whereas it significantly distorts the model produced by the original PCA method. Our technique substantially reduces the effectiveness of poisoning for a variety of scenarios and indeed maintains a significantly better balance between false positives and false negatives than the original method when under attack. Copyright 2009 ACM.",Adversarial learning; Network traffic analysis; Principal components analysis; Robust statistics,Adversarial learning; Anomaly detector; Back-bone network; False negatives; Network traffic analysis; Principal components analysis; Robust statistics; Statistical machine learning; Intrusion detection; Learning systems; Principal component analysis; Detectors
"Nazir A., Raza S., Gupta D., Chuah C.-N., Krishnamurthy B.",5,Network level footprints of facebook applications,2009,40,"University of California, Davis CA, United States; AT and T Labs-Research NJ, United States",AT and T Labs;University of California Davis,2,USA,1,15,14,"With over half a billion users, Online Social Networks (OSNs) are the major new applications on the Internet. Little information is available on the network impact of OSNs, although there is every expectation that the volume and diversity of traffic due to OSNs is set to explode. In this paper, we examine the specific role played by a key component of OSNs: the extremely popular and widespread set of third-party applications on some of the most popular OSNs. With over 81,000 third-party applications on Facebook alone, their impact is hard to predict and even harder to study. We have developed and launched a number of Facebook applications, all of which are among the most popular applications on Facebook in active use by several million users monthly. Through our applications, we are able to gather, analyze, correlate, and report their workload characteristics and performance from the perspective of the application servers. Coupled with PlanetLab experiments, where active probes are sent through Facebook to access a set of diverse applications, we are able to study how Facebook forwarding/ processing of requests/responses impacts the overall delay performance perceived by end-users. These insights help provide guidelines for OSNs and application developers. We have also made the data studied here publicly available to the research community. This is the first and only known study of popular thirdparty applications on OSNs at this depth. Copyright 2009 ACM.",Applications; Delays; Facebook; Online social networks; Platform; Social games,Delays; Facebook; On-line social networks; Platform; Social games; Applications; Online systems; Social networking (online)
"Augustin B., Krishnamurthy B., Willinger W.",3,IXPs: Mapped?,2009,96,"UniversitŽ Pierre et Marie Curie, Paris, France; AT and T Labs-Research, Florham Park, United States",AT and T Labs;University Pierre and Marie Curie,2,France;USA,2,40,35,"Internet exchange points (IXPs) are an important ingredient of the Internet AS-level ecosystem-a logical fabric of the Internet made up of about 30,000 ASes and their mutual business relationships whose primary purpose is to control and manage the flow of traffic. Despite the IXPs' critical role in this fabric, little is known about them in terms of their peering matrices (i.e., who peers with whom at which IXP) and corresponding traffic matrices (i.e., how much traffic do the different ASes that peer at an IXP exchange with one another). In this paper, we report on an Internet-wide traceroute study that was specifically designed to shed light on the unknown IXP-specific peering matrices and involves targeted traceroutes from publicly available and geographically dispersed vantage points. Based on our method, we were able to discover and validate the existence of about 44K IXP-specific peering links-nearly 18K more links than were previously known. In the process, we also classified all known IXPs depending on the type of information required to detect them. Moreover, in view of the currently used inferred AS-level maps of the Internet that are known to miss a significant portion of the actual AS relationships of the peer-to-peer type, our study provides a new method for augmenting these maps with IXP-related peering links in a systematic and informed manner. Copyright 2009 ACM.",IXP; Peering; Traceroute,AS relationships; Business relationships; Internet as levels; Internet exchange points; IXP; Peering; Traceroute; Traffic matrices; Measurements; Internet
"Yilek S., Rescorla E., Shacham H., Enright B., Savage S.",5,When private keys are public: Results from the 2008 debian openssl vulnerability,2009,67,"UC, San Diego, United States; RTFM, Inc., United States",University of California San Diego,1,USA,1,20,19,"We report on the aftermath of the discovery of a severe vulnerability in the Debian Linux version of OpenSSL. Systems afiected by the bug generated predictable random numbers, most importantly public/private keypairs. To study user response to this vulnerability, we collected a novel dataset of daily remote scans of over 50,000 SSL/TLS-enabled Web servers, of which 751 displayed vulnerable certificates. We report three primary results. First, as expected from previous work, we find an extremely slow rate of fixing, with 30% of the hosts vulnerable when we began our survey on day 4 after disclosure still vulnerable almost six months later. However, unlike conventional vulnerabilities, which typically show a short, fast fixing phase, we observe a much atter curve with fixing extending six months after the announcement. Second, we identify some predictive factors for the rate of upgrading. Third, we find that certificate authorities continued to issue certificates to servers with weak keys long after the vulnerability was disclosed. Copyright 2009 ACM.",Attacks; Debian; Entropy; Openssl; Prng; Survey,Attacks; Certificate authority; Debian; Open SSL; Predictive factors; Private key; Prng; Random Numbers; Computer operating systems; Entropy; Random number generation; Surveys; Curve fitting
"Antoniades D., Markatos E.P., Dovrolis C.",3,One-click hosting services: A file-sharing hideout,2009,42,"FORTH-ICS, Heraklion, Greece; GATECH, Atlanta, United States",Georgia Tech,1,Greece;USA,2,28,26,"File sharing using peer-to-peer (p2p) systems is a major Internet application and the leading source of network traffic today. However, the dominance of p2p systems for file sharing has been recently challenged by an increasing number of services, such as Rapid- Share and MegaUpload, which offer users the ability to share files through centralized servers, without relying on an underlying p2p infrastructure. These services, referred to as One-Click Hosting (OCH), have the potential to offer users better performance and availability than p2p systems. If they succeed, OCH services may become the leading platform for file sharing and eventually replace p2p systems for this purpose. In this paper, we present the first, to our knowledge, detailed study of OCH traffic and services focusing on the most popular such service: RapidShare. Through a combination of passive and active measurements, we attempt to understand their service architecture, usage patterns, and content characteristics. We also compare RapidShare with BitTorrent in terms of userperceived throughput and content availability, and we explore the characteristics of some popular RapidShare indexing sites. Copyright 2009 ACM.",Bittorrent; File sharing; One click hosting; Peer-to-peer; Rapid- share,Bit torrents; File Sharing; One-Click Hosting; Peer to peer; Rapid- share; Online systems; Peer to peer networks; Distributed computer systems
"Qian F., Gerber A., Mao Z.M., Sen S., Spatscheck O., Willinger W.",6,TCP revisited: A fresh look at TCP in the wild,2009,38,"University of Michigan, United States; AT and T Labs Research, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,36,22,"Since the last in-depth studies of measured TCP traffic some 6- 8 years ago, the Internet has experienced significant changes, including the rapid deployment of backbone links with 1-2 orders of magnitude more capacity, the emergence of bandwidth-intensive streaming applications, and the massive penetration of new TCP variants. These and other changes beg the question whether the characteristics of measured TCP traffic in today's Internet reflect these changes or have largely remained the same. To answer this question, we collected and analyzed packet traces from a number of Internet backbone and access links, focused on the ""heavy-hitter"" flows responsible for the majority of traffic. Next we analyzed their within-flow packet dynamics, and observed the following features: (1) in one of our datasets, up to 15.8% of flows have an initial congestion window (ICW) size larger than the upper bound specified by RFC 3390. (2) Among flows that encounter retransmission rates of more than 10%, 5% of them exhibit irregular retransmission behavior where the sender does not slow down its sending rate during retransmissions. (3) TCP flow clocking (i.e., regular spacing between flights of packets) can be caused by both RTT and non-RTT factors such as application or link layer, and 60% of flows studied show no pronounced flow clocking. To arrive at these findings, we developed novel techniques for analyzing unidirectional TCP flows, including a technique for inferring ICW size, a method for detecting irregular retransmissions, and a new approach for accurately extracting flow clocks. Copyright 2009 ACM.",Network measurement; TCP,Congestion window; Internet backbone; Network measurement; Orders of magnitude; Rapid deployments; Retransmission behavior; Streaming applications; TCP; Internet; Clocks
"Tariq M.B., Mansy A., Feamster N., Ammar M.",4,Characterizing VLAN-induced sharing in a campus network,2009,5,"School of Computer Science, Georgia Tech., Atlanta, GA, United States",Georgia Tech,1,USA,1,14,9,"Many enterprise, campus, and data-center networks have complex layer-2 virtual LANs (""VLANs"") below the IP layer. The interaction between layer-2 and IP topologies in these VLANs introduces hidden dependencies between IP level network and the physical infrastructure that has implications for network management tasks such as planning for capacity or reliability, and for fault diagnosis. This paper characterizes the extent and effect of these dependencies in a large campus network. We first present the design and implementation of EtherTrace, a tool that we make publicly available, which infers the layer-2 topology using data passively collected from Ethernet switches. Using this tool, we infer the layer-2 topology for a large campus network and compare it with the IP topology. We find that almost 70% of layer-2 edges are shared by 10 or more IP edges, and a single layer-2 edge may be shared by as many as 34 different IP edges. This sharing of layer-2 edges and switches among IP paths commonly results from trunking multiple VLANs to the same access router, or from colocation of academic departments that share layer-2 infrastructure, but have logically separate IP subnet and routers. We examine how this sharing affects the accuracy and specificity of fault diagnosis. For example, applying network tomography to the IP topology to diagnose failures caused by layer-2 devices results in only 54% accuracy, compared to 100% accuracy when our tomography algorithm takes input across layers. Copyright 2009 ACM.",Network diagnosis; Network virtualization; Vlan; Vlan-induced dependency,Academic department; Design and implementations; Network diagnosis; Network tomography; Network virtualization; Tomography algorithm; Vlan; Vlan-induced dependency; Complex networks; Network management; Topology; Network layers
"Yin H., Liu X., Qiu F., Xia N., Lin C., Zhang H., Sekar V., Min G.",8,Inside the bird's nest: Measurements of large-scale live VoD from the 2008 olympics,2009,43,"Tsinghua University, China; ChinaCache Co., Ltd, China; Huazhong University of Science and Technology, China; Carnegie Mellon University, United States; University of Bradford, United Kingdom",Carnegie Mellon University;Huazhong University of Science and Technology;Tsinghua University;University of Bradford,4,China;UK;USA,3,28,20,"The 2008 Beijing Olympics was an interesting event from a VoD perspective because it involved near real-time video de- livery at massive scales over multiple days of a high-profile event. We present some measurement-driven insights into this event through a unique dataset obtained from China Cache, the largest CDN in China. The dataset is unique in three respects. First, it gives a \white-box"" view into user access patterns which would otherwise be impossible. Second, since the CDN serves different content providers, it allows to compare and contrast the effects of different presentation models on end users. Third, the nature of the con- tent itself is vastly different from traditional VoD systems in terms of the real-time and event-driven nature, which gives rise to unique effects. The dataset allows us to investigate a wide range of interesting issues: (1) how the live nature of the events causes differences in access patterns compared to traditional VoD and User-Generated Content (UGC) systems, (2) how the presentation models affect user behavior, and (3) ¡ash-crowd phenomena. Based on these observations, we discuss implications for future live VoD systems. Copyright 2009 ACM.",Flash crowds; User behavior; Video-on-demand,2008 beijing olympics; Content providers; Flash crowd; Implications for futures; Presentation model; User access patterns; User behaviors; User-generated content; Video on demand; Behavioral research
"Schneider F., Feldmann A., Krishnamurthy B., Willinger W.",4,Understanding online social network usage from a network perspective,2009,153,"TU Berlin / T-Labs, Germany; AT and T Labs - Research, United States",AT and T Labs;TU Berlin,2,Germany;USA,2,42,37,"Online Social Networks (OSNs) have already attracted more than half a billion users. However, our understanding of which OSN features attract and keep the attention of these users is poor. Studies thus far have relied on surveys or interviews of OSN users or focused on static properties, e. g., the friendship graph, gathered via sampled crawls. In this paper, we study how users actually interact with OSNs by extracting clickstreams from passively monitored network traffic. Our characterization of user interactions within the OSN for four different OSNs (Facebook, LinkedIn, Hi5, and StudiVZ) focuses on feature popularity, session characteristics, and the dynamics within OSN sessions. We find, for example, that users commonly spend more than half an hour interacting with the OSNs while the byte contributions per OSN session are relatively small. Copyright 2009 ACM.",Clickstream analysis; Feature popularity; Http; Network measurement; Online social networks; Session characteristics; User interactions,Clickstream analysis; Feature popularity; Network measurement; On-line social networks; Session characteristics; User interaction; HTTP; Online systems; Social networking (online); Surveys
"Afanasyev M., Snoeren A.C.",2,The importance of being overheard: Throughput gains in wireless mesh networks,2009,8,"University of California, San Diego, United States",University of California San Diego,1,USA,1,21,18,"A flurry of recent work has focused on the performance gains that may be achieved by leveraging the broadcast nature of the wireless channel. In particular, researchers have observed that nodes other than the intended recipient of a packet may overhear the transmission in certain settings. Systems have been proposed to leverage this so-called overhearing phenomena by opportunistically adjusting forwarding paths, suppressing similar transmissions, and superimposing packet transmissions using network coding. The effectiveness of such approaches in practice depends greatly on the empirical overhearing rate, which is a function not only of the particular network and its environment, but also upon individual nodes' transmission rates. Most existing opportunistic routing systems use a single, fixed bitrate throughout the network, leaving open significant opportunity for increased performance. We present modrate, a mechanism to jointly optimize rate selection and overhearing opportunities to maximize overall network throughput. We implement modrate in ExOR, an integrated routing and MAC protocol that leverages overhearing to improve bulk-data transfers, and compare its performance in a 48-node wireless mesh network testbed to ExOR, MORE, and traditional routing. While modrate increases the number of profitable overhearing instances in the network, we discover that ExOR extracts far less value from overhearing than might be expected. Instead, the majority of ExOR's performance improvement in many instances is due to its bulk-acknowledgment scheme. Copyright 2009 ACM.",802.11 mesh networks; Overhearing,Integrated routing; Mesh network; Opportunistic routing; Overhearing; Packet transmissions; Performance improvements; Transmission rates; Wireless mesh network testbed; Data transfer; Medium access control; Profitability; Wireless mesh networks (WMN); MESH networking
"Cai K., Blackstock M., Feeley M.J., Krasic C.",4,"Non-intrusive, dynamic interference detection for 802.11 networks",2009,4,"Dept. of Computer Science, University of British Columbia, Vancouver, B.C., Canada",University of British Columbia,1,Canada,1,22,2,"In densely packed 802.11 environments, access-point domains significantly overlap and wireless hosts interfere with each other in complex ways. Knowing which devices interfere is an essential first step to minimizing this interference, improving efficiency and delivering quality connectivity throughout the network. This knowledge, however, is extremely difficult to obtain without either taking a running network offline for measurements or having client hosts monitor and report airspace anomalies, something typically outside the control of network administrators. In this paper we describe a technique we have developed to reveal wireless-network interference relationships by examining the network traffic at wired routers that connects wireless domains to the Internet. This approach, which we call VOID (Vvirless Online Interference Detection), searches for correlated throughput changes that occur when traffic from one node causes a throughput drop at other nodes in its radio range. In one analysis round we identify each node's interference neighbours using a single set of performance data collected from a wired-network router. We have evaluated VOID in Emulab testbeds consisting of tens of nodes as well as a six-node testbed in a live wireless network. The initial results have shown the promise of VOID to accurately correlate interfering devices together and effectively discriminate interfering devices from non-interfering ones. Copyright 2009 ACM.",802.11; Multiple regression; Online interference detection,802.11; 802.11 networks; Control of networks; Improving efficiency; Interference detection; Multiple regressions; Network traffic; Performance data; Air traffic control; Routers; Testbeds; Complex networks
"Houidi Z.B., Meulle M., Teixeira R.",3,Understanding slow BGP routing table transfers,2009,14,"France Telecom R and D Orange Labs, UPMC Paris Universitas, France; France Telecom R and D Orange Labs, France; UPMC Paris Universitas, CNRS, France",France Telecom R and D;UPMC Sorbonne UniversitŽs,2,France,1,14,13,"Researchers and network operators often say that BGP table transfers are slow. Despite this common knowledge, the reasons for slow BGP transfers are not well understood. This paper explains BGP table transfer delays by combining BGP messages collected at a large VPN provider backbone and controlled experiments with routers of three different vendors as well as a software BGP speaker. Our results show that table transfers both in the provider network and in the controlled experiments contain gaps, i.e., periods in which both the sending and receiving routers are idle, but no BGP routes are exchanged. Gaps can represent more than 90% of the table transfer time. Our analysis of a software router and discussions with router vendors indicate that gaps happen because of the timer-driven implementation of sending of BGP updates. Hence, gaps represent an undocumented design choice that gives preference to more controlled router load over faster table transfers. Copyright 2009 ACM.",BGP; Route propagation; Routing convergence,BGP; Common knowledge; Controlled experiment; Network operator; Receiving router; Routing convergence; Routing Table Transfer; Software routers; Experiments; Routers
"Castelluccia C., Kaafar M.A., Manils P., Perito D.",4,Geolocalization of proxied services and its application to fast-flux hidden servers,2009,11,"INRIA Rhone-Alpes, Grenoble, France",INRIA,1,France,1,13,8,"Fast-flux is a redirection technique used by cyber-criminals to hide the actual location of malicious servers. Its purpose is to evade identification and prevent or, at least delay, the shutdown of these illegal servers by law enforcement. This paper proposes a framework to geolocalize fast-flux servers, that is, to determine the physical location of the fast-flux networks roots (mothership servers) based on network measurements. We performed an extensive set of measurements on PlanetLab in order to validate and evaluate the performance of our method in a controlled environment. These experimentations showed that, with our framework, fast-flux servers can be localized with similar mean distance errors than non-hidden servers, i.e. approximately 100 km. In the light of these very promising results, we also applied our scheme to several active fast-flux servers and estimated their geographic locations, providing then statistics on the locations of ""in the wild"" fast-flux services. Copyright 2009 ACM.",Fast-flux; Geolocalization; Hidden servers,Controlled environment; Fast-flux; Geographic location; Geolocalization; ITS applications; Mean distances; Network measurement; Physical locations; Measurements; Crime
"Kandula S., Sengupta S., Greenberg A., Patel P., Chaiken R.",5,The nature of datacenter traffic: Measurements & analysis,2009,554,"Microsoft Research, United States",Microsoft,1,USA,1,36,31,"We explore the nature of traffic in data centers, designed to support the mining of massive data sets. We instrument the servers to collect socket-level logs, with negligible performance impact. In a 1500 server operational cluster, we thus amass roughly a petabyte of measurements over two months, from which we obtain and report detailed views of traffic and congestion conditions and patterns. We further consider whether trafficmatrices in the clustermight be obtained instead via tomographic inference from coarser-grained counter data. Copyright 2009 ACM.",Characterization; Data center traffic; Models; Tomography,Congestion conditions; Data centers; Datacenter; Massive data sets; Performance impact; Tomographic; Characterization; Measurements; Models; Tomography
"Balasubramanian N., Balasubramanian A., Venkataramani A.",3,Energy consumption in mobile phones: A measurement study and implications for network applications,2009,733,"Department of Computer Science, University of Massachusetts Amherst, United States",University of Massachusetts Amherst,1,USA,1,25,22,"In this paper, we present a measurement study of the energy consumption characteristics of three widespread mobile networking technologies: 3G, GSM, and WiFi. We find that 3G and GSM incur a high tail energy overhead because of lingering in high power states after completing a transfer. Based on these measurements, we develop a model for the energy consumed by network activity for each technology. Using this model, we develop TailEnder, a protocol that reduces energy consumption of common mobile applications. For applications that can tolerate a small delay such as e-mail, TailEnder schedules transfers so as to minimize the cumulative energy consumed while meeting user-specified deadlines. We show that the TailEnder scheduling algorithm is within a factor 2_ of the optimal and show that any online algorithm can at best be within a factor 1.62_ of the optimal. For applications like web search that can benefit from prefetching, TailEnder aggressively prefetches several times more data and improves user-specified response times while consuming less energy. We evaluate the benefits of TailEnder for three different case study applications-email, news feeds, and web search-based on real user logs and show significant reduction in energy consumption in each case. Experiments conducted on the mobile phone show that TailEnder can download 60% more news feed updates and download search results for more than 50% of web queries, compared to using the default policy. Copyright 2009 ACM.",Cellular networks; Energy savings; Mobile applications; Power measurement; WiFi,Cellular network; Cumulative energy; Mobile applications; Mobile networking; Network activities; Network applications; On-line algorithms; Reduction in energy consumption; Cellular telephones; Electric power measurement; Electronic mail; Energy conservation; Energy utilization; Global system for mobile communications; Information retrieval; Mobile computing; Mobile phones; Optimization; Websites; Wi-Fi
"Chang H., Jamin S., Wang W.",3,Live streaming performance of the zattoo network,2009,22,"Alcatel-Lucent Bell Labs, Holmdel, NJ 07733, United States; University of Michigan, Ann Arbor, MI 48109, United States; Zattoo Inc., Ann Arbor, MI 48105, United States",Bell Labs;University of Michigan at Ann Arbor;Zattoo Inc.,3,USA,1,30,30,"A number of commercial peer-to-peer systems for live streaming, such as PPLive, Joost, LiveStation, SOPCast, TVants, etc. have been introduced in recent years. The behavior of these popular systems has been extensively studied in several measurement papers. Due to the proprietary nature of these commercial systems, however, these studies have to rely on a ""black-box"" approach, where packet traces are collected from a single or a limited number of measurement points, to infer various properties of traffic on the control and data planes. Although such studies are useful to compare different systems from end-user's perspective, it is difficult to intuitively understand the observed properties without fully reverse-engineering the underlying systems. Our paper presents a large-scale measurement study of Zattoo, one of the largest production live streaming providers in Europe, using data collected by the provider. To highlight, we found that even when the Zattoo system was heavily loaded with as high as 20,000 concurrent users on a single overlay, the median channel join delay remained less than 2 to 5 seconds, and that, for a majority of users, the streamed signal lags over-the-air broadcast signal by no more than 3 seconds. To motivate the measurement study, we also present a description of the Zattoo network architecture. Copyright 2009 ACM.",Live streaming; Network architecture; Peer-to-peer system,Broadcast signals; Commercial systems; Large-scale measurement; Live streaming; Measurement points; Measurement study; Peer-to-Peer system; Underlying systems; Network architecture; Video streaming
"Benson T., Akella A., Maltz D.A.",3,Mining policies from enterprise network configuration,2009,20,"University of Wisconsin, Madison, WI, United States; Microsoft Research, Redmond, WA, United States",Microsoft;University of Wisconsin-Madison,2,USA,1,13,12,"Few studies so far have examined the nature of reachability policies in enterprise networks. A better understanding of reachability policies could both inform future approaches to network design as well as current network configuration mechanisms. In this paper, we introduce the notion of a policy unit, which is an abstract representation of how the policies implemented in a network apply to different network hosts. We develop an approach for reverse-engineering a network's policy units from its router configuration. We apply this approach to the configurations of five productions networks, including three university and two private enterprises. Through our empirical study, we validate that policy units capture useful characteristics of a network's policy. We also obtain insights into the nature of the policies implemented in modern enterprises. For example, we find most hosts in these networks are subject to nearly identical reachability policies at Layer 3. Copyright 2009 ACM.",Configuration management,Abstract representation; Configuration management; Empirical studies; Enterprise networks; Network configuration; Network design; Private enterprise; Router configuration; Measurements; Industry
"Maier G., Feldmann A., Paxson V., Allman M.",4,On dominant characteristics of residential broadband internet traffic,2009,236,"TU-Berlin, T-Labs, Germany; UC Berkeley, ICSI, United States; ICSI, United States",TU Berlin;University of California Berkeley,2,Germany;USA,2,57,47,"While residential broadband Internet access is popular in many parts of the world, only a few studies have examined the characteristics of such traffic. In this paper we describe observations from monitoring the network activity for more than 20,000 residential DSL customers in an urban area. To ensure privacy, all data is immediately anonymized. We augment the anonymized packet traces with information about DSL-level sessions, IP (re-)assignments, and DSL link bandwidth. Our analysis reveals a number of surprises in terms of the mental models we developed from the measurement literature. For example, we find that HTTP-not peer-to-peer-traffic dominates by a significant margin; that more often than not the home user's immediate ISP connectivity contributes more to the round-trip times the user experiences than the WAN portion of the path; and that the DSL lines are frequently not the bottleneck in bulk-transfer performance. Copyright 2009 ACM.",Application mix; Dsl; Http usage; Network measurement; Residential broadband traffic; Tcp performance,Broadband Internet; Broadband internet access; Broadband traffic; Network activities; Network measurement; Round-trip time; TCP performance; User experience; DSL; Housing; Internet service providers; HTTP
"Qiu T., Ge Z., Lee S., Wang J., Xu J., Zhao Q.",6,Modeling user activities in a large IPTV system,2009,69,"Georgia Tech, Atlanta GA, United States; AT and T Labs - Research, Florham Park, NJ, United States",AT and T Labs;Georgia Tech,2,USA,1,22,19,"Internet Protocol Television (IPTV) has emerged as a new delivery method for TV. In contrast with native broadcast in traditional cable and satellite TV system, video streams in IPTV are encoded in IP packets and distributed using IP unicast and multicast. This new architecture has been strategically embraced by ISPs across the globe, recognizing the opportunity for new services and its potential toward a more interactive style of TV watching experience in the future. Since user activities such as channel switches in IPTV impose workload beyond local TV or set-top box (different from broadcast TV systems), it becomes essential to characterize and model the aggregate user activities in an IPTV network to support various system design and performance evaluation functions such as network capacity planning. In this work, we perform an in-depth study on several intrinsic characteristics of IPTV user activities by analyzing the real data collected from an operational nation-wide IPTV system. We further generalize the findings and develop a series of models for capturing both the probability distribution and time-dynamics of user activities. We then combine theses models to design an IPTV user activity workload generation tool called SIMULWATCH, which takes a small number of input parameters and generates synthetic workload traces that mimic a set of real users watching IPTV. We validate all the models and the prototype of SIMULWATCH using the real traces. In particular, we show that SIMULWATCH can estimate the unicast and multicast traffic accurately, proving itself as a useful tool in driving the performance study in IPTV systems. Copyright 2009 ACM.",IPTV; Modeling; Network measurement; Workload generator,Intrinsic characteristics; Network capacity planning; Network measurement; Performance study; Synthetic workloads; System design and performance; Workload generation; Workload generators; Models; Multicasting; Probability distributions; Television broadcasting; Video streaming; IPTV
"Zhang Y., Mao Z.M., Zhang M.",3,Detecting traffic differentiation in backbone ISPs with NetPolice,2009,40,"University of Michigan, 2260 Hayward Street, Ann Arbor, MI, United States; Microsoft Research, One Microsoft Way, Redmond, WA, United States",Microsoft;University of Michigan at Ann Arbor,2,USA,1,35,24,"Traffic differentiations are known to be found at the edge of the Internet in broadband ISPs and wireless carriers [13, 2]. The ability to detect traffic differentiations is essential for customers to develop effective strategies for improving their application performance. We build a system, called NetPolice, that enables detection of content- and routing-based differentiations in backbone ISPs. NetPolice is easy to deploy since it only relies on loss measurement launched from end hosts. The key challenges in building NetPolice include selecting an appropriate set of probing destinations and ensuring the robustness of detection results to measurement noise. We use NetPolice to study 18 large ISPs spanning 3 major continents over 10 weeks in 2008. Our work provides concrete evidence of traffic differentiations based on application types and neighbor ASes. We identify 4 ISPs that exhibit large degree of differentiation on 4 applications and 10 ISPs that perform previous-AS hop based differentiation, resulting in up to 5% actual loss rate differences. The significance of differences increases with network load. Some ISPs simply differentiate traffic based on port numbers irrespective of packet payload and the differentiation policies may only be partially deployed within their networks. We also find strong correlation between performance differences and Type-of-Service value differences in the traffic. Copyright 2009 ACM.",Internet measurement; Traffic differentiation,Application performance; In-buildings; Internet measurement; Loss measurement; Measurement Noise; Packet payloads; Strong correlation; Wireless carriers; Measurements; Internet service providers
"MŽrindol P., Van Den Schrieck V., Donnet B., Bonaventure O., Pansiot J.-J.",5,Quantifying ASes multiconnectivity using multicast information,2009,18,"UniversitŽ Catholique de Louvain, Louvain-la-Neuve, Belgium; UniversitŽ de Strasbourg, Strasbourg, France",Universite Catholique de Louvain;UniversitŽ de Strasbourg,2,Belgium;France,2,28,23,"Redundant connectivity (or multiconnectivity) between adjacent autonomous systems (ASes) is important for inter-domain traffic engineering and fast recovery in case of failures. However, the redundancy of ASes business relationship links has not been quantitatively studied, mainly due to the difficulty of obtaining relevant data. In this paper, we show that the mrinfo multicast monitoring tool can provide useful data about the Internet topology and such redundant links in particular. Our analysis relies on more than four years of daily queries to about ten thousand routers mapped into more than two hundred ASes. We demonstrate that peering links between ASes are frequently redundant. In particular, our analysis shows that more than half of the studied ASes pairs are connected through multiple physical links. We then refine our analysis by considering the different types of ASes and their business relationships. A particular result of our analysis is that at least 75% of the peer-to-peer relationships between adjacent Tier-1 ASes are redundant, i.e., the con- nections between these ASes involve several physical links. Our analysis is conservative, providing so a lower bound, as some links might not be seen by mrinfo due to ISPs filtering policies. Copyright 2009 ACM.",ASes connectivity; Mrinfo; Multicast; Network topology,ASes connectivity; Business relationships; Mrinfo; Multicast information; Multicast monitoring; Multicasts; Network topology; Peer-to-peer relationships; Electric network topology; Internet service providers; Multicasting
"Kandula S., Mahajan R.",2,Sampling biases in network path measurements and what to do about it,2009,10,"Microsoft Research, United States",Microsoft,1,USA,1,27,25,"We show that currently prevalent practices for network path measurements can produce inaccurate inferences because of sampling biases. The inferred mean path latency can be more than a factor of two off the true mean. We present the Broom toolkit that has three methods to correct for this bias. Broom places no burden on the measurement process itself and can be applied post hoc to any measured data set. Our evaluation finds that two of the methods are particularly effective. One of them estimates missing path samples by embedding the nodes in a low-dimensional coordinate space. For realistic sampling rates, the quality of its estimates for path latency approximates ideal, unbiased sampling. The other method is based on a view of network paths as being composed of source-specific, destination-specific, and shared components. It reduces bias for a wide range of path properties, such as latency, hop count and capacity. Applying Broom to data from a real measurement study leads to substantial changes in the resulting inferences. For some networks, the post-correction estimate is 30% higher than the original. Copyright 2009 ACM.",Coordinate embedding; Networkmeasurement; Path decomposition; Sampling bias,Coordinate embedding; Measurement process; Network path measurement; Networkmeasurement; Path decomposition; Sampling bias; Shared components; Unbiased samplings; Measurements; Estimation
"Grieco L.A., Barakat C.",2,An analysis of packet sampling in the frequency domain,2009,8,"INRIA, Planete Research Group, Sophia Antipolis, France",INRIA;Planete Research Group,2,France,1,17,15,"Packet sampling techniques introduce measurement errors that should be carefully handled in order to correctly characterize the network behavior. In the literature several works have studied the statistical properties of packet sampling and the way it should be inverted to recover the original network measurements. Here we take the new direction of studying the spectral properties of packet sampled traffic. A novel technique to model the impact of packet sampling is proposed based on a theoretical analysis of network traffic in the frequency domain. Moreover, a real-time algorithm is also presented to detect the spectrum portion of the network traffic that can be restored once packet sampling has been applied. Preliminary experimental results are reported to validate the proposed approach. Copyright 2009 ACM.",Aliasing; Measurement; Packet sampling; Variance,Aliasing; Network behaviors; Network measurement; Packet sampling; Real time algorithms; Spectral properties; Statistical properties; Variance; Measurements; Frequency domain analysis
"Brauckhoff D., Dimitropoulos X., Wagner A., Salamatian K.",4,Anomaly extraction in backbone networks using association rules,2009,53,"ETH Zurich, Zurich, Switzerland; Lancaster University Lancaster, United Kingdom",ETH Zurich;Lancaster University,2,Switzerland;UK,2,23,18,"Anomaly extraction is an important problem essential to several applications ranging from root cause analysis, to attack mitigation, and testing anomaly detectors. Anomaly extraction is preceded by an anomaly detection step, which detects anomalous events and may identify a large set of possible associated event flows. The goal of anomaly extraction is to find and summarize the set of flows that are effectively caused by the anomalous event. In this work, we use meta-data provided by several histogram-based detectors to identify suspicious flows and then apply association rule mining to find and summarize the event flows. Using rich traffic data from a backbone network (SWITCH/AS559), we show that we can reduce the classification cost, in terms of items (flows or rules) that need to be classified, by several orders of magnitude. Further, we show that our techniques effectively isolate event flows in all analyzed cases and that on average trigger between 2 and 8.5 false positives, which can be trivially sorted out by an administrator. Copyright 2009 ACM.",Anomaly extraction; Association rules; Histogram cloning,Anomalous events; Anomaly detection; Anomaly detector; Back-bone network; False positive; Orders of magnitude; Root cause analysis; Traffic data; Association rules; Genetic engineering; Graphic methods; Extraction
"Beverly R., Arthur B., Hyun Y., Claffy K.",4,Understanding the efficacy of deployed internet source address validation filtering,2009,68,"MIT CSAIL, United States; CAIDA, United States",MIT,1,USA,1,47,44,"IP source address forgery, or ""spoofing,"" is a long-recognized consequence of the Internet's lack of packet-level authenticity. Despite historical precedent and filtering and tracing efforts, attackers continue to utilize spoofing for anonymity, indirection, and amplification. Using a distributed infrastructure and approximately 12,000 active measurement clients, we collect data on the prevalence and efficacy of current bestpractice source address validation techniques. Of clients able to test their provider's source-address filtering rules, we find 31% able to successfully spoof an arbitrary, routable source address, while 77% of clients otherwise unable to spoof can forge an address within their own /24 subnetwork. We uncover significant differences in filtering depending upon network geographic region, type, and size. Our new tracefilter tool for filter location inference finds 80% of filters implemented a single IP hop from sources, with over 95% of blocked packets observably filtered within the source's autonomous system. Finally, we provide initial longitudinal results on the evolution of spoofing revealing no mitigation improvement over four years of measurement. Our analysis provides an empirical basis for evaluating incentive and coordination issues surrounding existing and future Internet packet authentication strategies. Copyright 2009 ACM.",Filtering; IP spoofing; Source address validation,Active measurement; Autonomous systems; Distributed infrastructure; Filter locations; Internet sources; IP spoofing; Significant differences; Source address; Computer crime; Filtration; Internet; Internet protocols
"Trestian I., Ranjan S., Kuzmanovic A., Nucci A.",4,"Measuring serendipity: Connecting people, locations and interests in a mobile 3G network",2009,116,"Northwestern University, Evanston IL, United States; Narus Inc., Mountain View, CA, United States",Narus Inc.;Northwestern University,2,USA,1,26,20,"Characterizing the relationship that exists between people's application interests and mobility properties is the core question relevant for location-based services, in particular those that facilitate serendipitous discovery of people, businesses and objects. In this paper, we apply rule mining and spectral clustering to study this relationship for a population of over 280,000 users of a 3G mobile network in a large metropolitan area. Our analysis reveals that (i) People's movement patterns are correlated with the applications they access, e.g., stationary users and those who move more often and visit more locations tend to access different applications. (ii) Location affects the applications accessed by users, i.e., at certain locations, users are more likely to evince interest in a particular class of applications than others irrespective of the time of day. (iii) Finally, the number of serendipitous meetings between users of similar cyber interest is larger in regions with higher density of hotspots. Our analysis demonstrates how cellular network providers and location- based services can benefit from knowledge of the inter-play between users and their locations and interests. Copyright 2009 ACM.",Experimentation; Human factors; Measurement,3G mobile network; Cellular network; Experimentation; Metropolitan area; Mobility properties; Movement pattern; Serendipitous discovery; Spectral clustering; Human engineering; Location based services; Measurements; 3G mobile communication systems
"Garg S., Gupta T., Carlsson N., Mahanti A.",4,Evolution of an online social aggregation network: An empirical study,2009,30,"IIT Delhi, New Delhi, India; University of Calgary, Calgary, AB, Canada; National ICT Australia, Alexandria, NSW, Australia",University of Calgary,1,Australia;Canada;India,3,28,24,"Many factors such as the tendency of individuals to develop relationships based on mutual acquaintances, proximity, common interests, or combinations thereof, are known to contribute toward evolution of social networks. In this paper, we analyze an evolving online social aggregator, FriendFeed, which collates content generated by participating individuals on a variety of Web 2.0 services and allows easy dissemination of the aggregated content to other participants of the aggregator. Analyzing data collected between September 2008 and May 2009, we find that although preferential attachment captures the evolution of the network, its influence varies significantly based on how long ago a user joined the service. In particular, preferential attachment does not appear to apply to new entrants of the FriendFeed service. Analysis suggests that proximity bias plays an important role in link formation. We study the influence of common foci and find that individuals have a greater affinity toward those with similar interests. Copyright 2009 ACM.",Evolution; Social aggregation; Social networks; Web 2.0,Empirical studies; Evolution; Preferential attachments; Similar Interests; Social aggregation; Social Networks; Web 2.0; Web 2.0 services; World Wide Web; Social networking (online)
"Cunha ê., Teixeira R., Feamster N., Diot C.",4,Measurement methods for fast and accurate blackhole identification with binary tomography,2009,15,"Thomson, UPMC Paris Universitas, France; CNRS, UPMC Paris Universitas, France; Georgia Tech, United States; Thomson, United States",Georgia Tech;UPMC Sorbonne UniversitŽs,2,France;USA,2,30,29,"Binary tomography-the process of identifying faulty network links through coordinated end-to-end probes-is a promising method for detecting failures that the network does not automatically mask (e.g., network ""blackholes""). Because tomography is sensitive to the quality of the input, however, nŠive end-to-end measurements can introduce inaccuracies. This paper develops two methods for generating inputs to binary tomography algorithms that improve their inference speed and accuracy. Failure confirmation is a perpath probing technique to distinguish packet losses caused by congestion from persistent link or node failures. Aggregation strategies combine path measurements from unsynchronized monitors into a set of consistent observations. When used in conjunction with existing binary tomography algorithms, our methods identify all failures that are longer than two measurement cycles, while inducing relatively few false alarms. In two wide-area networks, our techniques decrease the number of alarms by as much as two orders of magnitude. Compared to the state of the art in binary tomography, our techniques increase the identification rate and avoid hundreds of false alarms. Copyright 2009 ACM.",Diagnosis; Network tomography; Troubleshooting,Aggregation strategy; Binary tomography; End-to-end measurement; Identification rates; Measurement methods; Network tomography; Orders of magnitude; Probing techniques; Algorithms; Diagnosis; Errors; Wide area networks; Inference engines
"Krishnan R., Madhyastha H.V., Srinivasan S., Jain S., Krishnamurthy A., Anderson T., Gao J.",7,Moving beyond end-to-end path information to optimize CDN performance,2009,109,"Google Inc., United States; University of California, San Diego, United States; University of Washington, United States; Stony Brook University, United States",Google;Stony Brook University;University of California San Diego;University of Washington at Seattle,4,USA,1,25,21,"Replicating content across a geographically distributed set of servers and redirecting clients to the closest server in terms of latency has emerged as a common paradigm for improving client performance. In this paper, we analyze latencies measured from servers in Google's content distribution network (CDN) to clients all across the Internet to study the effectiveness of latency-based server selection. Our main result is that redirecting every client to the server with least latency does not suffice to optimize client latencies. First, even though most clients are served by a geographically nearby CDN node, a sizeable fraction of clients experience latencies several tens of milliseconds higher than other clients in the same region. Second, we find that queueing delays often override the benefits of a client interacting with a nearby server. To help the administrators of Google's CDN cope with these problems, we have built a system called WhyHigh. First, WhyHigh measures client latencies across all nodes in the CDN and correlates measurements to identify the prefixes affected by inflated latencies. Second, since clients in several thousand prefixes have poor latencies, WhyHigh prioritizes problems based on the impact that solving them would have, e.g., by identifying either an AS path common to several inflated prefixes or a CDN node where path inflation is widespread. Finally, WhyHigh diagnoses the causes for inflated latencies using active measurements such as traceroutes and pings, in combination with datasets such as BGP paths and flow records. Typical causes discovered include lack of peering, routing misconfigurations, and side-effects of traffic engineering. We have used WhyHigh to diagnose several instances of inflated latencies, and our efforts over the course of a year have significantly helped improve the performance offered to clients by Google's CDN. Copyright 2009 ACM.",Content distribution networks; Latency inflation; Network troubleshooting,Active measurement; Content distribution networks; End-to-end path; Latency inflation; Misconfigurations; Network troubleshooting; Server selection; Traffic Engineering; Measurements; Optimization
"Nechaev B., Paxson V., Allman M., Gurtov A.",4,On calibrating enterprise switch measurements,2009,0,"International Computer Science Institute, University of California, Berkeley, United States; International Computer Science Institute, United States; Helsinki Institute for Information Technology HIIT, Helsinki University of Technology TKK, Finland",Helsinki Institute for Information Technology HIIT;Helsinki University of Technology;University of California Berkeley,3,Finland;USA,2,8,4,"The complexity of modern enterprise networks is ever-increasing, and our understanding of these important networks is not keeping pace. Our insight into intra-subnet traffic (staying within a single LAN) is particularly limited, due to the widespread use of Ethernet switches that preclude ready LAN-wide monitoring. We have recently undertaken an approach to obtaining extensive intra-subnet visibility based on tapping sets of Ethernet switch ports simultaneously. However, doing so leads to a number of measurement calibration issues that require careful consideration to address. First, one must correctly account for redundant copies of packets that appear due to switch flooding, which if not accurately identified can greatly skew subsequent analysis results. We show that a simple, natural rule one might use for doing so in fact introduces systematic errors, but an altered version of the rule performs significantly better. We then employ this revised rule to aid with calibration issues concerning the fidelity of packet timestamps and the amount of measurement loss that our collection apparatus incurred. Additionally, we develop techniques to ""map"" the monitored network in terms of identifying key topological components, such as subnet boundaries, which hosts were directly monitored, and the presence of ""hidden"" switches and hubs. Finally, we present initial analyses demonstrating that the magnitude and diversity of traffic at the subnet level is in fact striking, highlighting the importance of obtaining and correctly calibrating switch-level enterprise traces. Copyright 2009 ACM.",Enterprise networks; Network traces; Switchbased packet capture; Trace calibration,Collection apparatus; Enterprise networks; Ethernet switches; Measurement calibration; Measurement loss; Packet capture; Time stamps; Calibration; Ethernet; Industry; Complex networks
"Song H.H., Cho T.W., Dave V., Zhang Y., Qiu L.",5,Scalable proximity estimation and link prediction in online social networks,2009,87,"University of Texas, Austin, United States",University of Texas at Austin,1,USA,1,56,37,"Proximity measures quantify the closeness or similarity between nodes in a social network and form the basis of a range of applications in social sciences, business, information technology, computer networks, and cyber security. It is challenging to estimate proximity measures in online social networks due to their massive scale (with millions of users) and dynamic nature (with hundreds of thousands of new nodes and millions of edges added daily). To address this challenge, we develop two novel methods to efficiently and accurately approximate a large family of proximity measures. We also propose a novel incremental update algorithm to enable near real-time proximity estimation in highly dynamic social networks. Evaluation based on a large amount of real data collected in five popular online social networks shows that our methods are accurate and can easily scale to networks with millions of nodes. To demonstrate the practical values of our techniques, we consider a significant application of proximity estimation: link prediction, i.e., predicting which new edges will be added in the near future based on past snapshots of a social network. Our results reveal that (i) the effectiveness of different proximity measures for link prediction varies significantly across different online social networks and depends heavily on the fraction of edges contributed by the highest degree nodes, and (ii) combining multiple proximity measures consistently yields the best link prediction accuracy. Copyright 2009 ACM.",Embedding; Link prediction; Matrix factorization; Proximity measure; Sketch; Social network,Embedding; Link prediction; Matrix factorizations; Proximity measure; Sketch; Social Networks; Estimation; Forecasting; Information technology; Online systems; Social networking (online)
"Lakshmanan S., Sundaresan K., Rangarajan S., Sivakumar R.",4,Practical beamforming based on RSSI measurements using off-the-shelf wireless clients,2009,15,"Georgia Institute of Technology, Atlanta, GA, United States; NEC-Laboratories America, Princeton, NJ, United States",Georgia Tech;NEC,2,USA,1,18,14,"WLANs have become an important last-mile technology for providing internet access within homes and enterprises. In such indoor deployments, the wireless channel suffers from significant multipath scattering and fading that degrades performance. Beamforming is a smart antenna technology that adjusts the transmissions at the transmitter to reenforce the signals received through multiple paths at the receiver. However, doing this requires the accurate estimation of the channel coefficients at the receiver and its knowledge at the transmitter which off-the-shelf WiFi clients are incapable of doing. In this work, we develop a novel procedure that uses Received Signal Strength Indicator (RSSI) measurements at the receiver along with an intelligent estimation methodology at the transmitter to achieve beamforming benefits. Using experiments in an indoor office scenario with commercial WiFi clients, we show that the scheme achieves significant performance improvements across diverse scenarios. Copyright 2009 ACM.",Beamforming; Smart antennas; Throughput; Wireless link stability,Accurate estimation; Channel coefficient; Intelligent estimation; Multipath scattering; Performance improvements; Received signal strength indicators; Smart antenna technology; Wireless link; Smart antennas; Throughput; Transmitters; Beamforming
"Benevenuto F., Rodrigues T., Cha M., Almeida V.",4,Characterizing user behavior in online social networks,2009,448,"Computer Science Department, Federal University of Minas Gerais, Brazil; Max Planck Institute for Software Systems (MPI-SWS), Kaiserslautern/SaarbrŸcken, Germany","Federal University of Minas Gerais;Max Planck Institute,Germany",2,Brazil;Germany,2,33,28,"Understanding how users behave when they connect to social networking sites creates opportunities for better interface design, richer studies of social interactions, and improved design of content distribution systems. In this paper, we present a first of a kind analysis of user workloads in on- line social networks. Our study is based on detailed click- stream data, collected over a 12-day period, summarizing HTTP sessions of 37,024 users who accessed four popular social networks: Orkut, MySpace, Hi5, and LinkedIn. The data were collected from a social network aggregator web- site in Brazil, which enables users to connect to multiple social networks with a single authentication. Our analysis of the clickstream data reveals key features of the social net- work workloads, such as how frequently people connect to social networks and for how long, as well as the types and sequences of activities that users conduct on these sites. Ad- ditionally, we crawled the social network topology of Orkut, so that we could analyze user interaction data in light of the social graph. Our data analysis suggests insights into how users interact with friends in Orkut, such as how frequently users visit their friends' or non-immediate friends' pages. In summary, our analysis demonstrates the power of using clickstream data in identifying patterns in social network workloads and social interactions. Our analysis shows that browsing, which cannot be inferred from crawling publicly available data, accounts for 92% of all user activities. Con- sequently, compared to using only crawled data, considering silent interactions like browsing friends' pages increases the measured level of interaction among users. Copyright 2009 ACM.",Browsing; Clickstream; Online social networks; Session; Silent activity; Social network aggregator; User behavior,Browsing; Clickstreams; On-line social networks; Session; Social network aggregators; User behaviors; Behavioral research; Electric network topology; HTTP; Online systems; Social sciences; Social networking (online)
"Anand B., Ananda A.L., Chan M.C., Long L.T., Balan R.K.",5,Game action based power management for multiplayer online game,2009,16,"School of Computing, National University of Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore",National University of Singapore;Singapore Management University,2,Singapore,1,11,10,"Current mobile devices embrace a wide range of functionalities including high speed network support, hardware accelerated 3D graphics, and multimedia capabilities. These capabilities have boosted the interest for enabling multiplayer online games (MOG) support on such devices. However, the lack of similar growth in battery technology limits the usability of these devices for MOGs. In this paper, we present energy conservation techniques for highly interactive MOGs. These are games, such as first-person shooters, where crisp user interaction is paramount to the overall game experience. Hence, conserving energy while preserving crisp user interaction becomes a critical consideration in this domain. We first present three obvious power management approaches and highlight their limitations. We then discuss two application-assisted approaches for power management that manage to save power while preserving the required user experience. Our results demonstrate that these application-assisted approaches are very promising. © 2009 ACM.",Mobile games; Power management; Statistical prediction; Wireless networks,Energy conservation; Energy management; Graphical user interfaces; HIgh speed networks; Social networking (online); User interfaces; Wireless networks; Battery technology; First person shooter; Game experience; Hardware-accelerated; Mobile games; Multi-player online games; Statistical prediction; User interaction; Power management
"Yoneki E., Baltopoulos I., Crowcroft J.",3,D3N: Programming distributed computation in Pocket Switched Networks,2009,3,"University of Cambridge, Computer Laboratory, Cambridge, CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,26,26,"We propose a novel approach to Pocket Switched Networks (PSNs) [8] using a specialised declarative language called 'D3N'. A PSN is a recently devised type of communication based on physical proximity, where people encounter each other and their devices directly communicate within their communication range. D3N allows us to program distributed applications based on reactive behaviour in a distributed set of nodes. We exploit a functional language approach in designing D3N for the clean abstraction given by pure declarative languages, at the same time, taking an advantage of well defined semantics. In this paper, we show a fragment of D3N, describe the node runtime architecture, and illustrate its effectiveness through some examples. © 2009 ACM.",Declarative networking; Delay tolerant networks; Distributed computation; F#; Functional programming,Application programs; Delay tolerant networks; Fluorine; Functional programming; Semantics; Switching networks; Communication range; Declarative Languages; Declarative networkings; Distributed applications; Distributed computations; Functional languages; Pocket switched networks; Runtime architecture; Distributed computer systems
"Van Damme G., Wouters K., Karahan H., Preneel B.",4,Offline NFC payments with electronic vouchers,2009,18,"Dept. Electrical Engineering-ESAT/SCD/IBBT-COSIC, Katholieke Universiteit Leuven, Kasteelpark Arenberg 10, Heverlee-Leuven, 3001, Belgium",KU Leuven,1,Belgium,1,19,6,"In this paper a practical offline payment system based on digital vouchers using Near Field Communication (NFC) in mobile phones is presented. This work was performed within the scope of the IBBT NFC-Voucher project. The goal of the project is to assess the feasibility of such a system, from a technical and security perspective, using tangible NFC devices such as the Nokia 6131 NFC mobile phone. This involved an in-depth technical and security analysis of all actors in the system and a rigorous elaboration of the practical security requirements and assumptions. In the architecture implementing and connecting all the different actors of this voucher payment system, no compromises regarding security were made. At device level all sensitive data is stored in a Secure Element (SE) with limited access for nonauthorised users. The backbone and voucher transfer system uses a classical Public Key Infrastructure (PKI), such that only trusted and registered parties can handle and transfer vouchers. After having implemented this system, we conclude that it is possible to build an off-line payment system for mobile phones without compromising security, but that it remains quite challenging, given the current limitations on speed, available memory and security functionality. © 2009 ACM.",NFC; Nokia; Security; Voucher,Cellular telephone systems; Cellular telephones; Electronic money; Mobile devices; Mobile phones; Mobile security; Public key cryptography; Telephone sets; Current limitation; Nokia; Offline payment systems; Public-key infrastructure; Security; Security requirements; The near field communication (NFC); Voucher; Near field communication
"Jain A., Jaiswal S., Majumder A., Naidu K.V.M., Narlikar G., Shrivastava N., Poosala V.",7,"Mango: Low-cost, scalable delivery of rich content on mobiles",2009,3,"Bell Labs India, Alcatel-Lucent, Bangalore, India",Bell Labs,1,India,1,10,9,"We present mango, a low-cost and highly scalable content-delivery service for mobile phones. The service is targeted at emerging countries such as India where users are highly price sensitive, and there is considerable demand for rich media content. mango is designed as a content ""synch-up"" service. Users install an app on the phone, and through a simple menu select content for download, upload or sharing. Then, in order to actually transfer content to and from their phones, users visit or opportunistically connect with mango hot-spots. The hot-spots are short-range cells (installed in shops, cafes, or as an app in other users' phones) with a back-haul connection and a wireless interface such as Bluetooth to communicate with the phones. Given a large number of such low-cost, shortrange access-points, the mango network delivers content to the very edge of the network, to within a few feet from the user. Such a content delivery architecture is faster, cheaper and can support a much larger number of users than macro-cellular data networks. In this paper we present the mango service architecture, discuss its potential as a substrate for deploying a range of novel applications and present technical challenges for timely, low-cost content-delivery. © 2009 ACM.",CDN; Mobile applications,Costs; Fruits; Network architecture; Telephone sets; Cellular data networks; Content delivery services; Emerging countries; Mobile applications; Novel applications; Service architecture; Technical challenges; Wireless interfaces; Cellular telephone systems
"Agrawal S., Constandache I., Gaonkar S., Choudhury R.R.",4,PhonePoint pen: Using mobile phones to write in air,2009,14,"Dept. of ECE, Duke University, Durham, NC, United States; Dept. of CS, Duke University, Durham, NC, United States; Dept. of CS, UIUC, Urbana-Champaign, IL, United States",Duke University;UIUC,2,USA,1,12,8,"The ability to note down small pieces of information, quickly and ubiquitously, can be useful. This paper proposes a system called PhonePoint Pen that uses the in-built accelerometer in mobile phones to recognize human writing. By holding the phone like a pen, an user should be able to write short messages or even draw simple diagrams in air. The acceleration due to hand gestures can be converted into an image, and sent to the user's Internet email address for future reference. We motivate the utility of such a system through simple use-cases and applications, and present the design and implementation challenges towards a functional prototype. Our early results show that the PhonePoint Pen is feasible if the user is restricted to a few simple constraints. © 2009 ACM.",Accelerometers; Electronic pen; Gestures; Handwriting; Input device; Mobile computing applications; Mobile phones; Sketching; Strokes; Writing in air,Accelerometers; Cellular telephones; Character recognition; Mobile computing; Mobile devices; Mobile phones; Telephone sets; Electronic pen; Gestures; Handwriting; Input devices; Sketching; Strokes; Cellular telephone systems
"Landsiedel O., Kunz G., Gštz S., Wehrle K.",4,A virtual platform for network experimentation,2009,3,"Distributed Systems Group, RWTH Aachen University, Germany",RWTH Aachen University,1,Germany,1,45,32,"Although the diversity of platforms for network experimentation is a boon to the development of protocols and distributed systems, it is challenging to exploit its benefits. Implementing or adapting the systems under test for such heterogeneous environments as network simulators, network emulators, testbeds, and end systems is immensely time and work intensive. In this paper, we present VIPE, a unified virtual platform for network experimentation, that slashes the porting effort. It allows to smoothly evolve a single implementation of a distributed system or protocol from its design up into its deployment by leveraging any form of network experimentation tool available. Copyright 2009 ACM.",Deployment; Network Experimentation; Resource Virtualization; Simulation,Deployment; Distributed systems; Heterogeneous environments; Network experimentations; Network simulators; Resource Virtualization; Simulation; Systems under tests; Internet protocols
"Fortuna C., Mohorcic M.",2,A local knowledge base for service oriented access network selection,2009,0,"Jozef Stefan Institute, Jamova 39, Ljubljana, 1000, Slovenia",Jozef Stefan Institute,1,Slovenia,1,5,0,"Service oriented access in a multi-application, multi-access network environment poses interesting research challenges. One of these challenges refers to cross-layer interoperability among technologies. In this poster, we introduce a knowledge base (KB) which contains local (user terminal specific) knowledge that enables pro-active network selection by translating technology specific parameters to higher-level, more abstract parameters. We implemented a prototype which makes use of semantic technology (namely ResearchCyc) for creating the elements of the KB: the ontology, the concepts, facts and rules. The system implements technologyspecific QoS parameters mapping according to the IEEE 802.21 draft standard recommendation. © 2009 ACM.",Knowledge base; Network selection; Service oriented; Vertical handover,Distributed computer systems; Interoperability; Knowledge based systems; Radio systems; Semantics; Access network selections; Knowledge base; Multiaccess networks; Network selection; Research challenges; Semantic technologies; Service Oriented; Vertical handovers; Quality of service
"Liao Y., Yin D., Gao L.",3,PdP: Parallelizing data plane in virtual network substrate,2009,17,"ECE Department, University of Massachusetts, Amherst, MA  01003, United States; Automation Department, Northwestern Polytech Univ, Xi'an, ShanXi, 710072, China",University of Massachusetts Amherst,1,China;USA,2,22,10,"Network virtualization provides the ability to run multiple concurrent virtual networks over a shared substrate. However, it is challenging to design such a platform to host multiple heterogenous and often highly customized virtual networks. Not only minimal interference among different virtual networks is desired, high speed packet processing is also required. This paper presents PdP, a flexible virtual network platform which can achieve high speed packet processing. A PdP node has a cluster of machines that can perform packet processing in parallel. Each virtual network can be allocated with one or multiple forwarding machines so as to satisfy the packet processing requirement of the virtual network. Furthermore, a virtual network hosted in PdP has the freedom to be fully customized. Both the control plane and the data plane of a virtual network run in virtual machines so as to be isolated from other virtual networks. We have built a proofof-concept prototype of the PdP platform using off-The-shelf commodity hardware and open source software. The performance measurement shows promising results. Copyright 2009 ACM.",Network Virtualization; Parallelization; Virtual Network Platform,Open systems; Software engineering; Virtual reality; Virtualization; Commodity hardware; High-speed packet processing; Network virtualization; Packet processing; Parallelizations; Performance measurements; Proof of concept; Virtual networks; Open source software
"Rantala E., Karppanen A., Granlund S., Sarolahti P.",4,Modeling energy efficiency in wireless internet communication,2009,13,"Nokia Research Center, Helsinki, Finland; Nokia Research Center, Espoo, Finland",Nokia,1,Finland,1,4,4,"For wireless mobile Internet users the length of the battery life is one of the most important performance factors. The energy efficiency of the data transmission over radio is a key component affecting the battery lifetime. This paper investigates WLAN energy consumption in network communication on a Mobile handset. We introduce an energy model that allows analysis and simulation of the energy efficiency of the Internet protocols on a Wireless Network Interface, and have extended the NS-2 simulation platform to allow investigating the energy consumption of the Radio Modem and the Power Amplifier in WLAN 802.11g network interface of a mobile device. We have also validated our model against measurements on real wireless hardware, and show that the simulation results closely match the real world behavior. We claim to present more detailed and accurate model of the WLAN energy consumption than what is done by the past work that allows designing and optimizing future Internet protocols towards more energy efficient behavior. © 2009 ACM.",Energy efficiency; Network simulation; TCP; Wireless networking,Electric batteries; Energy utilization; Internet; Internet protocols; Mobile devices; Power amplifiers; Radio transmission; Wireless local area networks (WLAN); Wireless networks; Accurate modeling; Analysis and simulation; Battery lifetime; Energy efficient; Network simulation; Performance factors; Wireless internet; Wireless networking; Energy efficiency
"Rumble S.M., Stutsman R., Levis P., Mazires D., Zeldovich N.",5,Apprehending joule thieves with Cinder,2009,13,"Stanford University, 353 Serra Mall, Stanford, CA  94305, United States; MIT, 32 Vassar Street, Cambridge, MA  02139, United States",MIT;Stanford University,2,USA,1,13,7,"Energy is the critical limiting resource to mobile computing devices. Correspondingly, an operating system must track, provision, and ration how applications consume energy. The emergence of third-party application stores and marketplaces makes this concern even more pressing. A third-party application must not deny service through excessive, unforeseen energy expenditure, whether accidental or malicious. Previous research has shown promise in tracking energy usage and rationing it to meet device lifetime goals, but such mechanisms and policies are still nascent, especially regarding user interaction. We argue for a new operating system, called Cinder, which builds on top of the HiStar OS. Cinder's energy awareness is based on hierarchical capacitors and task profiles. We introduce and explore these abstractions, paying particular attention to the ways in which policies could be generated and enforced in a dynamic system. © 2009 ACM.",Capacitor; Energy; Hierarchical,Device lifetime; Energy; Energy awareness; Energy expenditure; Hierarchical; Mobile computing devices; Third party application (Apps); User interaction; Capacitors
"Belle S.K., Waldvogel M., Haase O.",3,PathForge:: Faithful anonymization of movement data,2009,0,"Department of Computer and Information Science, University of Konstanz, Konstanz, Germany",University of Konstanz,1,Germany,1,2,2,"For most mobile networks, providers need the current position of their users to provide efficient service. The resulting motion data is not only an invaluable source for analyzing traffic or flow patterns, but also for tracking an individual's whereabouts, even without their knowledge. Today, many carry at least one mobile networked device with them wherever they go, day and night. The resulting motion data can be used to reveal the most intimate details of our lives, making this information extremely privacy sensitive. In this paper, we present PathForge, a lightweight solution, which not only fulfills the provider's efficiency requirement, but continues to allow flow pattern analysis, yet provides full privacy for users when not actively involved in a call. © 2009 ACM.",Algorithms; Design; Security,Algorithms; Design; Mobile telecommunication systems; Anonymization; Efficiency requirements; Flow pattern analysis; Motion data; Movement datum; Networked devices; Security; Flow patterns
"Chen J., Linn B., Subramanian L.",3,SMS-based contextual web search,2009,9,"New York University, United States",NYU,1,USA,1,22,13,"SMS-based web search is different from traditional web search in that the final response to a search query is limited to a very small number of bytes (typically 1-2 SMS messages, 140 bytes each). SMS-based web search is also a non-interactive search problem where the user has to specify a query and obtain a response in one round of search. Enabling search with with such constraints is challenging. Several search engines have developed SMS-based search capabilities in recent years and many of these search engines are limited in their recognized topics (phone, address, location, weather etc.), involve a human in the loop or apply to only specific types of search queries. We describe a simple generic approach to extracting results for both well-known and arbitrary topics. We have implemented our prototype system SMSFind and demonstrate the effectiveness of our approach. While the underlying mechanisms we present are by no means perfect, we show that our system returns appropriate responses for a range of topics not covered by existing systems. © 2009 ACM.",Cell phones; Context; Search; SMS,Data mining; Information retrieval; Mobile phones; Samarium; Search engines; Telephone sets; Cell phone; Context; Generic approach; Human-in-the-loop; Interactive search; Prototype system; Search; Search capabilities; Websites
"Courcoubetis C., Weber R.R.",2,Economic issues in shared infrastructures,2009,8,"Department of Computer Science, Athens University of Economics and Business, Athens, 11362, Greece; Department of Pure Mathematics and, Mathematical Statistics, University of Cambridge, Cambridge, CB2 0WB, United Kingdom",Athens University of Economics and Business;University of Cambridge,2,Greece;UK,2,21,5,"We define some interesting incentive issues that arise in the management of virtual infrastructures. We demonstrate that participants' decisions about the quantities of infrastructure that they will choose to contribute to a virtual organization can be greatly affected by the resource sharing policy that they know will be deployed when the system operates. Unless this policy is well-designed, agents will attempt to free-ride by contributing less resource than is desirable. Our novel contribution is the formulation of models for designing optimal management policies, an analysis that demonstrates the inadequacy of simple sharing policies, and proposals for some better ones. We find an optimal policy in a limit as the number of participants becomes large. We learn that simple policies may be far from optimal and that efficient policy design is not trivial; policy parameters play important role in optimizing the efficiency of virtual facility formation. Copyright 2009 ACM.",Ad-Hoc Grid; Algorithms; Computational Grids; Economic-Based,Algorithms; Ad hoc grid; Computational grids; Optimal management; Optimal policies; Resource sharing; Shared infrastructure; Virtual infrastructures; Virtual organization; Grid computing
"Miwa S., Suzuki M., Hazeyama H., Uda S., Miyachi T., Kadobayashi Y., Shinoda Y.",7,Experiences in emulating 10K AS topology with massive vm multiplexing,2009,8,"NICT, 4-2-1 Nukuikita-machi, Koganei, Tokyo, Japan; NICT, Japan; NAIST, Ikoma, Nara, Takayama, 8916-5, Japan; JAIST, 1-1 Asahidai, Nomi, Ishikawa, Japan; NAIST/NICT, Japan; NICT+/JAIST, Japan",NICTA,1,Japan,1,27,13,"New technologies that will be introduced to the Internet should be practically tested for effectiveness and for side effects. A realistic environment that simulates the Internet is needed to experimentally test such technologies, which will be widely deployed on the Internet. To support experimentation in a realistic, Internet-like environment, we are now trying to construct an Internet on a testbed. We describe our method of constructing an Internet-like environment on the testbed using a virtualization technology and estimation of the inter-AS network on StarBED with Xen and our prototype system. We stably constructed a 10,000-AS network using 150 testbed nodes and estimated its performance and feasibility. Copyright 2009 ACM.",BGP; Internet; Network Emulation; Testbed; Virtualization,Internet; Virtual reality; Virtualization; AS topologies; inter-AS; Network emulation; Prototype system; Realistic environments; Side effect; Virtualization technologies; Testbeds
"C‡ceres R., Cox L., Lim H., Shakimov A., Varshavsky A.",5,Virtual Individual Servers as privacy-preserving proxies for mobile devices,2009,34,"ATandT Labs, Florham Park, NJ, United States; Duke University, Durham, NC, United States",AT and T Labs;Duke University,2,USA,1,23,23,"People increasingly generate content on their mobile devices and upload it to third-party services such as Facebook and Google Latitude for sharing and backup purposes. Although these services are convenient and useful, their use has important privacy implications due to their centralized nature and their acquisitions of rights to user-contributed content. This paper argues that people's interests would be be better served by uploading their data to a machine that they themselves own and control. We term these machines Virtual Individual Servers (VISs) because our preferred instantiation is a virtual machine running in a highly-available utility computing infrastructure. By using VISs, people can better protect their privacy because they retain ownership of their data and remain in control over the software and policies that determine what data is shared with whom. This paper also describes a range of applications of VIS proxies. It then presents our initial implementation and evaluation of one of these applications, a decentralized framework for mobile social services based on VISs. Our experience so far suggests that building such applications on top of the VIS concept is feasible and desirable. © 2009 ACM.",Cloud computing; Location based services; Mobile devices; Online social networks; Privacy; Utility computing; Virtual machines,Cloud computing; Data privacy; Distributed computer systems; Mobile devices; Mobile telecommunication systems; Network security; Social networking (online); Social sciences computing; Telecommunication services; Virtual machine; Facebook; In-control; On-line social networks; Privacy preserving; Running-in; Social service; Third party services; Utility computing; Location based services
"Deboosere L., Vankeirsbilck B., Simoens P., De Turck F., Dhoedt B., Demeester P.",6,Self management of a mobile thin client service,2009,0,"IBBT - Department of Information Technology (INTEC), Ghent University, Gaston Crommenlaan 8, bus 201, Gent, 9050, Belgium",Ghent University,1,Belgium,1,5,3,"Mobile thin client computing is an enabler for the execution of demanding applications from mobile handhelds. In thin client computing, the application is executed on remote servers and the mobile handheld only has to display the graphical updates and send input from the user to the remote execution environment. To guarantee a high user experience in a mobile environment, a Service Management Framework is required to prevent users observing lower Quality of Experience due to changes in the available network, server and client resources. Therefore, the Service Management Framework monitors the environment and the Self Management component intervenes when necessary, e.g. by adapting the thin client protocol settings or moving a user session from one server to another. The design of the Self Management component is presented and the performance is evaluated. © 2009 ACM.",Design; Management; Performance,Design; Management; Quality of service; Client resources; Mobile environments; Mobile thin clients; Performance; Quality of experience (QoE); Remote execution; Service management; Thin-client computing; Environmental management
"Hao F., Lakshman T.V., Mukherjee S., Song H.",4,Enhancing dynamic cloud-based services using network virtualization,2009,50,"Bell Labs, Alcatel-Lucent, France",Bell Labs,1,France,1,22,20,"It is envisaged that services and applications will migrate to a cloud-computing paradigm where thin-clients on userdevices access, over the network, applications hosted in data centers by application service providers. Examples are cloudbased gaming applications and cloud-supported virtual desktops. For good performance and efficiency, it is critical that these services are delivered from locations that are the best for the current (dynamically changing) set of users. To achieve this, we expect that services will be hosted on virtual machines in interconnected data centers and that these virtual machines will migrate dynamically to locations bestsuited for the current user population. A basic network infrastructure need then is the ability to migrate virtual machines across multiple networks without losing service continuity. In this paper, we develop mechanisms to accomplish this using a network-virtualization architecture that relies on a set of distributed forwarding elements with centralized control (borrowing on several recent proposals in a similar vein). We describe a preliminary prototype system, built using Openflow components, that demonstrates the feasibility of this architecture in enabling seamless migration of virtual machines and in enhancing delivery of cloud-based services. Copyright 2009 ACM.",Data Center; Virtualization; VM Migration,Cloud computing; Network architecture; Network security; Population statistics; Virtual machine; Virtual reality; Virtualization; Application service provider; Centralized control; Data centers; Gaming applications; Network infrastructure; Network virtualization; Services and applications; Vm migrations; Distributed computer systems
"Tripathi S., Droux N., Srinivasan T., Belgaied K.",4,Crossbow: From hardware virtualized NICS to virtualized networks,2009,19,"Solaris Kernel Networking, Sun Microsystems, Inc., 17 Network Circle, Menlo Park, CA  94025, United States",Sun Microsystems,1,USA,1,24,19,"This paper describes a new architecture for achieving net-work virtualization using virtual NICs (VNICs) as the build-ing blocks. The VNICs can be associated with dedicated and independent hardware lanes that consist of dedicated NIC and kernel resources. Hardware lanes support dynamic polling, which enables the fair sharing of bandwidth with no performance penalty. VNICs ensure full separation of trafic for virtual machines within the host. A collection of VNICs on one or more physical machines can be connected to create a Virtual Wire by assigning them a common attribute such as a VLAN tag. Copyright 2009 ACM.",Classification; Crossbow; Hypervisor; Networking; Performance; Virtualization; VLAN; VMs; VNICs; vWire; Zones,Classification (of information); Network architecture; Virtual reality; Virtualization; Zoning; Crossbow; Hypervisor; Networking; Performance; VLAN; VNICs; vWire; Hardware
"Lischka J., Karl H.",2,A virtual network mapping algorithm based on subgraph isomorphism detection,2009,377,"Paderborn Center for Parallel Computing, Paderborn University, Paderborn, 33102, Germany",Paderborn University,1,Germany,1,17,9,"Assigning the resources of a virtual network to the compo-nents of a physical network, called Virtual Network Map-ping, plays a central role in network virtualization. Existing approaches use classical heuristics like simulated annealing or attempt a two stage solution by solving the node map-ping in a first stage and doing the link mapping in a second stage. The contribution of this paper is a Virtual Network Map-ping (VNM) algorithm based on subgraph isomorphism de-Tection: it maps nodes and links during the same stage. Our experimental evaluations show that this method results in better mappings and is faster than the two stage approach, especially for large virtual networks with high resource con-sumption which are hard to map. Copyright 2009 ACM.",Network Embedding; Network Vir-Tualization; Resource Allocation; Subgraph Isomorphism Detection; Virtual Network Mapping,Conformal mapping; Distributed computer systems; Resource allocation; Set theory; Simulated annealing; Experimental evaluation; Network embedding; Nodes and links; Physical network; Subgraph isomorphism; Two stage approach; Virtual network mappings; Virtual networks; Mapping
"Carapinha J., JimŽnez J.",2,Network virtualization - A view from the bottom,2009,119,"PT Inova‹o, Rua Eng. Ferreira Pinto Basto, Aveiro, 3810-106, Portugal; Telef—nica I+D, C/ Emilio Vargas, 6, Madrid, 28043, Spain",Telefonica Research,1,Portugal;Spain,2,19,15,"The interest in network virtualization has been growing steadily among the networking community in the last few years. Network virtualization opens up new possibilities for the evolution path to the Future Internet by enabling the deployment of different architectures and protocols over a shared physical infrastructure. The deployment of network virtualization imposes new requirements and raises new issues in relation to how networks are provisioned, managed and controlled today. The starting point for this paper is the network virtualization reference model conceived in the framework of the EU funded 4WARD project. In this paper we look at network virtualization mainly from the perspective of the network infrastructure provider, following the 4WARD network virtualization architecture and evaluate the main issues and challenges to be faced in commercial operator environments. Copyright 2009 ACM.",Network Virtualization; Resource Management,Virtual reality; Virtualization; Commercial operators; Future internet; Issues and challenges; Network infrastructure; Network virtualization; Networking community; Reference modeling; Resource management; Network architecture
"Whitbeck J., Conan V., De Amorim M.D.",3,Tuning message size in opportunistic mobile networks,2009,1,"Thales Communications, UPMC Paris Universitas, France; Thales Communications, France; UPMC Paris Universitas, France",UPMC Sorbonne UniversitŽs,1,France,1,3,3,"We describe a new model for studying intermittently connected mobile networks, based on Markovian random temporal graphs, that captures the influence of message size, maximum tolerated delay and link stability on the delivery ratio. © 2009 ACM.",Delay tolerant networks; Delivery ratio; Message size; Random temporal graphs,Mobile telecommunication systems; Wireless networks; Delivery ratio; Intermittently connected mobile networks; Link stability; Markovian; Message size; Temporal graphs; Delay tolerant networks
"Klepal M., Bylemans I., Weyn M., Wibowo S., Najib W., Widyawan, Hantono B.",7,OLS - Opportunistic localization system for smart phones devices,2009,7,"Cork Institute of Technology, Cork, Ireland; Artesis University, College of Antwerp, Antwerp, Belgium",Artesis University;College of Antwerp;Cork Institute of Technology,3,Belgium;Ireland,2,5,0,"In this paper, we describe the opportunistic localization, which enables localization services that works seamlessly in heterogeneous environments including indoors as oppose to GPS based outdoor-only systems. © 2009 ACM.",Data fusion; Localization; Opportunistic localization; Particle filter; Smart phone; Tracking,Data fusion; Surface discharges; Telephone sets; Heterogeneous environments; Localization; Localization services; Localization system; Opportunistic localization; Particle filter; Smartphones
"Potter R., Nakao A.",2,Mobitopolo: A portable infrastructure to facilitate flexible deployment and migration of distributed applications with virtual topologies,2009,9,"NICT, Tokyo, Japan; University of Tokyo and NICT, Tokyo, Japan",University of Tokyo,1,Japan,1,14,14,"Hosting network services on virtual machines has become appealing for provisioning resources, saving power and enabling migration in case of service disruption, especially in data centers. Network services implemented widely over the Internet may enjoy similar benefits, because general-purpose hosting infrastructures such as PlanetLab and Amazon EC2 are available to host them. However, such infrastructures are piecemeal and heterogeneous in terms of virtualization technologies, which makes it hard to use them all together to their full potential. To ease this challenge, we implemented Mobitopolo, a portable infrastructure service to deploy and migrate distributed network services spanning over hetero-geneous hosting infrastructures while preserving the logical connections between the service components. To the best of our knowledge, Mobitopolo is the first virtualized execution environment to integrate all these attributes into one system. Copyright 2009 ACM.",Internet; Virtualization,Internet; Virtualization; Distributed applications; Distributed networks; Execution environments; Infrastructure services; Logical connections; Service disruptions; Virtual topologies; Virtualization technologies; Virtual reality
"Abdesslem F.B., Phillips A., Henderson T.",3,Less is more: Energy-efficient mobile sensing with SenseLess,2009,74,"School of Computer Science, University of St. Andrews, St.Andrews-Fife, United Kingdom",University of St. Andrews,1,UK,1,4,4,"We present SenseLess, a system that leverages the different energy consumption characteristics of sensors to maximise battery life in mobile-sensing applications. We use the less expensive sensors more often, thereby enabling us to use the more expensive sensors less frequently. In the context of location-aware services, experimental results indicate that for a typical indoor and outdoor walk, compared to a simple GPS-based system, our SenseLess system can reduce energy consumption by more than 58% when determining a user's location, while maintaining the fidelity of the sensed data. This extends the battery life of a typical handheld device from 9 hours to 22 hours. © 2009 ACM.",Experimentation; Management,Electric batteries; Energy efficiency; Energy utilization; Management; Battery life; Energy efficient; Experimentation; Hand held device; Less is mores; Location aware services; Mobile sensing; Reduce energy consumption; Location based services
"Schaffrath G., Werle C., Feldmann A., Bless R., Papadimitriou P., Greenhalgh A., Wundsam A., Kind M., Maennel O., Mathy L.",10,Network virtualization architecture: Proposal and initial prototype,2009,133,"DTLabs / TU-Berlin, Berlin, Germany; University of Karlsruhe, Karlsruhe, Germany; Lancaster University, Lancaster, United Kingdom; University College London, London, United Kingdom",TU Berlin;Lancaster University;University College London;University of Karlsruhe,4,Germany;UK,2,20,13,"The tussle between reliability and functionality of the Internet is firmly biased on the side of reliability. New enabling technologies fail to achieve traction across the majority of ISPs. We believe that the greatest challenge is not in finding solutions and improvements to the Internet's many problems, but in how to actually deploy those solutions and re-balance the tussle between reliability and functionality. Network virtualization provides a promising approach to enable the co-existence of innovation and reliability. We describe a network virtualization architecture as a technology for enabling Internet innovation. This architecture is motivated from both business and technical perspectives and comprises four main players. In order to gain insight about its viability, we also evaluate some of its components based on experimental results from a prototype implementation. Copyright 2009 ACM.",Network architecture; Network virtualization; Socio-Economics,Reliability; Virtual reality; Virtualization; Co-existence; Enabling technologies; Finding solutions; Gain insight; Network virtualization; Prototype implementations; Socio-economics; Network architecture
"Keller E., Lee R.B., Rexford J.",3,Accountability in hosted virtual networks,2009,30,"Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,29,20,"Virtualization enables multiple networks, each customized for a particular purpose, to run concurrently over a shared substrate. One such model for managing these virtual net-works is to create a hosting platform where companies can deploy services by leasing a portion of several physical routers. While lowering the barrier for innovation in the network, this model introduces new security concerns. In this paper we examine the issue of accountability in this setting of hosted virtual networks. That is, how a service provider can know its software is running without modification and that the in-frastructure provider's physical router is forwarding packets as instructed with the quality of service promised. Rather than presenting a single specification of what every router on the Internet must look like, in this paper we examine two possible approaches: one that detects violations by monitor-ing the service and one that prevents violations from occur-ring in the first place. For each, we provide a description of an architecture that can be achieved with technology avail-Able today, the limitations of that architecture, and then propose an extension which overcomes the limitations. Copyright 2009 ACM.",Accountability; Router architecture; Security; Virtualization,Quality of service; Routers; Virtual reality; Virtualization; Accountability; Multiple networks; Router architecture; Security; Service provider; Virtual networks; Network architecture
"Anwer M.B., Feamster N.",2,"Building a fast, virtualized data plane with programmable hardware",2009,37,"School of Computer Science, Georgia Tech, United States",Georgia Tech,1,USA,1,18,14,"Network virtualization allows many networks to share the same underlying physical topology; this technology has offered promise both for experimentation and for hosting multiple networks on a single shared physical infrastructure. Much attention has focused on virtualizing the network control plane, but, ultimately, a limiting factor in the deployment of these virtual networks is data-plane performance: Virtual networks must ultimately forward packets at rates that are comparable to native, hardware-based approaches. Aside from proprietary solutions from vendors, hardware support for virtualized data planes is limited. The advent of open, programmable network hardware promises flexibility, speed, and resource isolation, but, unfortunately, hardware does not naturally lend itself to virtualization. We leverage emerging trends in programmable hardware to design a flexible, hardware-based data plane for virtual networks. We present the design, implementation, and preliminary evaluation of this hardware-based data plane and show how the proposed design can support many virtual networks without compromising performance or isolation. Copyright 2009 ACM.",NetFPGA; Network virtualization,Virtual reality; Virtualization; Hardware-based approach; Multiple networks; NetFPGA; Network control plane; Network virtualization; Programmable hardware; Programmable network; Proprietary solutions; Hardware
"Paik M., Chen J., Subramanian L.",3,Epothecary: Cost-effective drug pedigree tracking and authentication using mobile phones,2009,3,"New York University, United States",NYU,1,USA,1,26,21,"Counterfeit and expired pharmaceuticals are a significant problem in the developing world, constituting up to 80% of stock on pharmacy shelves. This is due both to poor existing controls and to lack of supporting infrastructure on which to build such controls. Existing strategies to fight counterfeiting include holograms, special packaging, and paper invoice tracing, but each of these have been proven ineffectual in the face of increasingly sophisticated counterfeiting rings, which inject fake drugs into the market for profit and/or sell off genuine medications on the black market or in adjacent countries at marked up prices. This paper describes Epothecary, a system which uses built-in functionality in midlevel mobile telephones including cameras, SMS, and optionally GPS to construct a robust system for tracking and verifying the pedigrees of pharmaceutical products at every point in the distribution chain, particularly in the developing world. © 2009 ACM.",Barcode; Counterfeit; Pedigree; SMS; Track & trace,Bar codes; Commerce; Cost effectiveness; Crime; Developing countries; Mobile phones; Samarium; Telephone sets; Cost effective; Counterfeit; Developing world; Distribution chains; Mobile telephones; Pedigree; Pharmaceutical products; Robust systems; Cellular telephone systems
"Cai L., Machiraju S., Chen H.",3,Defending against sensor-sniffing attacks on mobile phones,2009,38,"University of California, Davis, CA, United States; Sprint Applied Research, Burlingame, CA, United States",University of California Davis,1,USA,1,25,23,"Modern mobile phones possess three types of capabilities: computing, communication, and sensing. While these capabilities enable a variety of novel applications, they also raise serious privacy concerns. We explore the vulnerability where attackers snoop on users by sniffing on their mobile phone sensors, such as the microphone, camera, and GPS receiver. We show that current mobile phone platforms inadequately protect their users from this threat. To provide better privacy for mobile phone users, we analyze desirable uses of these sensors and discuss the properties of good privacy protection solutions. Then, we propose a general framework for such solutions and discuss various possible approaches to implement the framework's components. © 2009 ACM.",Microphone; Mobile; Privacy; Sensor; Sniffing,Data privacy; Global positioning system; Microphones; Mobile devices; Mobile phones; Sensors; Telephone sets; Mobile; Mobile phone platforms; Mobile phone sensors; Mobile-phone users; Novel applications; Privacy concerns; Privacy protection; Sniffing; Cellular telephones
"Krifa A., Sbai M.K., Barakat C., Turletti T.",4,A standalone content sharing application for spontaneous communities of mobile handhelds,2009,1,"Plante Project-team, INRIA, France",INRIA,1,France,1,4,0,"This demo illustrates the benefits of BitHoc, a standalone protocol for content sharing among spontaneous communities of mobile handhelds using wireless multi-hop connections. BitHoc is a Trackerless BitTorrent-like application adapted to mobile wireless ad-hoc networks(MANET). The current BitHoc architecture is composed of three principal components: a content sharing service, a membership management service and a content discovery service. The present demo highlights the efficiency of the BitHoc package in dealing with diverse challenges encountered in the MANET environment. Our solution considers the following issues: routing overhead, sharing opportunities and mobility of nodes. In order to validate the feasibility of our application and evaluate its performance, we consider a test-bed composed of PDAs and smartphones equipped withWIFI adapters and Windows Mobile 6 operating system. © 2009 ACM.",Algorithms design experimentation,Ad hoc networks; Windows operating system; Wireless ad hoc networks; Content discoveries; Content sharing services; Design experimentations; Membership management; Mobile wireless ad hoc networks; Principal Components; Routing overheads; Wireless multi-hop; Mobile ad hoc networks
"Kumar A., Chen J., Paik M., Subramanian L.",4,ELMR: Efficient Lightweight Mobile Records,2009,3,"Dept. of Computer Science, New York University, United States",NYU,1,USA,1,7,3,"In this paper we describe Efficient Lightweight Mobile Records (ELMR), a system that provides a practical protocol for accessing and updating database records remotely from low-end mobile devices using the 140-byte SMS channel. © 2009 ACM.",Cell phones; Compression; Healthcare; User interface,Compaction; Health care; mHealth; Mobile phones; Cell phone; Database records; User interfaces
"Bao X., Choudhury R.R.",2,VUPoints: Collaborative sensing and video recording through mobile phones,2009,2,"Department of ECE, Duke University, Durham, NC, United States",Duke University,1,USA,1,10,5,"Mobile phones are becoming a convergent platform for sensing, computation, and communication. This paper envisions VUPoints, a collaborative sensing and video-recording system that takes advantage of this convergence. Ideally, when multiple phones in a social gathering run VUPoints, the output is expected to be a short video-highlights of the occasion, created without human intervention. To achieve this, mobile phones must sense their surroundings and collaboratively detect events that qualify for recording. Short video-clips from different phones can be combined to produce the highlights of the occasion. This paper reports exploratory work towards this longer term project. We present a feasibility study, and show how social events can be sensed through mobile phones and used as triggers for video-recording. While false positives cause inclusion of some uninteresting videos, we believe that further research can significantly improve the efficacy of the system. © 2009 ACM.",Activity recognition; Collaborative ambience sensing; Image processing; Mobile phones; Participatory sensing; Social networks; Video recording; Wearable devices,Cellular telephones; Image processing; Image recording; Mobile devices; Mobile phones; Social networking (online); Telephone sets; Video recording; Activity recognition; Collaborative ambience sensing; Collaborative sensing; Feasibility studies; Human intervention; Participatory Sensing; Social gatherings; Wearable devices; Video signal processing
"Shakimov A., Varshavsky A., Cox L.P., C‡ceres R.",4,"Privacy, cost, and availability tradeoffs in decentralized OSNs",2009,45,"Duke University, Durham, NC, United States; AT and T Labs, Florham Park, NJ, United States",AT and T Labs;Duke University,2,USA,1,21,13,"Online Social Networks (OSNs) have become enormously popular. However, two aspects of many current OSNs have important implications with regards to privacy: Their centralized nature and their acquisition of rights to users' data. Recent work has proposed decentralized OSNs as more privacy-preserving alternatives to the prevailing OSN model. We present three schemes for decentralized OSNs. In all three, each user stores his own personal data in his own machine, which we term a Virtual Individual Server (VIS). VISs self-organize into peer-To-peer overlay networks, one overlay per social group with which the VIS owner wishes to share information. The schemes differ in where VISs and data reside: (a) on a virtualized utility computing infrastructure in the cloud, (b) on desktop machines augmented with socially-informed data replication, and (c) on desktop machines during normal operation, with failover to a standby virtual machine in the cloud when the primary VIS becomes unavailable. We focus on tradeoffs between these schemes in the areas of privacy, cost, and availability. © 2009 ACM.",Cloud Computing; Online Social Networks; Privacy; Replication; Utility Computing; Virtual Machines,Cloud computing; Commerce; Data privacy; Distributed computer systems; Java programming language; Peer to peer networks; Social sciences computing; Decentralized OSNs; On-line social networks; Online social networks (OSNs); Peer-to-peer overlay networks; Privacy preserving; Replication; Utility computing; Virtual machines; Social networking (online)
"Gaito S., Pagani E., Rossi G.P.",3,Opportunistic forwarding in workplaces,2009,25,"Computer Science Dept., Univ. Degli Studi di Milano, v.Comelico 39, Milano, Italy",Univ. Degli Studi di Milano,1,Italy,1,14,12,"So far, the search for Opportunistic Network (ON) applications has focused on urban/rural scenarios where the combined use of mobility and the store-carry-And-forward paradigm helpfully recovers from network partitions and copes with node sparsity. This paper explores the chance of using ONs in workplaces, where the node distribution is denser, thus contributing to reduce the message delivery latency, and where we still find similar needs for informal and unplanned network platforms to support human social relationships and interactions. Both a survey and trace recording experiments have been used to support the analysis of this mobility setting. The ability of recording very short contact times (i.e. lasting few seconds) allowed to interestingly show the slightly different role the social relationships play in dense scenarios and how the large amount of contacts (both short and long), occurring in densily populated spaces, actually contribute to reduce the message-delivery latency and to increase the delivery probability. © 2009 ACM.",Human mobility; Message forwarding; Mobility analysis.; Opportunistic networks,Social aspects; Social networking (online); Delivery probabilities; Human mobility; Message forwarding; Mobility analysis; Network partitions; Opportunistic forwarding; Opportunistic networks; Social relationships; Online systems
"PietilŠinen A.-K., Oliver E., LeBrun J., Varghese G., Diot C.",5,MobiClique: Middleware for mobile social networking,2009,255,"Thomson, United States; University of Waterloo, Canada; University of California, Davis, United States; Univ. of California, San Diego, United States",University of California Davis;University of Waterloo,2,Canada;USA,2,15,10,"We consider a mobile ad hoc network setting where Bluetooth enabled mobile devices communicate directly with other devices as they meet opportunistically. We design and implement a novel mobile social networking middleware named MobiClique. MobiClique forms and exploits ad hoc social networks to disseminate content using a store-carry-forward technique. Our approach distinguishes itself from other mobile social software by removing the need for a central server to conduct exchanges, by leveraging existing social networks to bootstrap the system, and by taking advantage of the social network overlay to disseminate content. We also propose an open API to encourage third-party application development. We discuss the system architecture and three example applications. We show experimentally that MobiClique successfully builds and maintains an ad hoc social network leveraging contact opportunities between friends and people sharing interest(s) for content exchanges. Our experience also provides insight into some of the key challenges and short-comings that researchers face when designing and deploying similar systems. © 2009 ACM.",Bluetooth; Mobile social networks; Opportunistic communications,Application programming interfaces (API); Bluetooth; Middleware; Mobile devices; Mobile telecommunication systems; Social networking (online); Social sciences computing; Bluetooth enabled mobiles; Content exchange; Design and implements; Mobile social networks; Opportunistic communications; Store carry forwards; System architectures; Third party application (Apps); Mobile ad hoc networks
"Motoyama M., Varghese G.",2,CrossTalk: Scalably interconnecting instant messaging networks,2009,7,"University of California, 9500 Gilman Drive, San Diego, CA  92093, United States",University of California San Diego,1,USA,1,18,9,"We consider the problem of interconnecting a simple type of social network: Instant Messaging services. Today, users are members of various IM communities such as AOL, Ya-hoo, and MSN. Users often want to engage in conversations that span multiple IM communities, since their friends may use competing IM clients. While client-side solutions exist in the form of Trillian and Pidgin, they require multiple lo-gins and offer a subset of the features present in official IM clients. We propose a different solution based on translat-ing gateways that only requires a single login and allows users to keep their existing IM clients. We claim that such interconnection empowers users and encourages the devel-opment of third-party applications. We propose using an overlay of bypass gateways that avoids many of the scalabil-ity limitations of standard gateways. We argue that smaller IM networks have the right incentives to use these gateways, and larger networks cannot easily obstruct bypass gateways. Deploying these gateways into a system we call CrossTalk can ultimately aid in protocol standardization. We describe the architecture of bypass gateways and the implementation challenges faced in interconnecting MSN, AOL, Jabber and Yahoo for IM. We briey discuss to extensions to other do-mains such as interconnecting SIP and Skype. © 2009 ACM.",DHT; Instant Messaging; Interconnection; XMPP,Message passing; Reconfigurable hardware; Social networking (online); Instant messaging; Instant messaging networks; Instant messaging service; Interconnection; Larger networks; Simple types; Third party application (Apps); XMPP; Gateways (computer networks)
"Krishnamurthy B., Wills C.E.",2,On the leakage of personally identifiable information via online social networks,2009,183,"ATandT Labs - Research, Florham Park, NJ, United States; Worcester Polytechnic Institute, Worcester, MA, United States",AT and T Labs;Worcester Polytechnic Institute,2,USA,1,14,9,"For purposes of this paper, we define ""Personally identifiable information"" (PII) as information which can be used to distinguish or trace an individual's identity either alone or when combined with other information that is linkable to a specific individual. The popularity of Online Social Networks (OSN) has accelerated the appearance of vast amounts of personal information on the Internet. Our research shows that it is possible for third-parties to link PII, which is leaked via OSNs, with user actions both within OSN sites and elsewhere on non-OSN sites. We refer to this ability to link PII and combine it with other information as ""leakage"". We have identified multiple ways by which such leakage occurs and discuss measures to prevent it. © 2009 ACM.",Online Social Networks; Personally Identifiable Information; Privacy,Computer networks; Data privacy; Information systems; Linkable; nocv1; On-line social networks; Online social networks (OSN); Personal information; Personally identifiable information; Third parties; User action; Social networking (online)
"Torkjazi M., Rejaie R., Willinger W.",3,"Hot today, gone tomorrow: On the migration of myspace users",2009,38,"Department of Computer and Information Science, University of Oregon, Eugene, OR  97403, United States; ATandT Research Labs, 180 Park Ave.-Building 103, Florham Park, NJ  07932, United States",AT and T Labs;University of Oregon,2,USA,1,15,11,"While some empirical studies on Online Social Networks (OSNs) have examined the growth of these systems, little is known about the patterns of decline in user population or user activity (in terms of visiting their OSN account) in large OSNs, mainly because capturing the required information is challenging. In this paper, we examine the evolution of user population and user activity in a popular OSN, namely MySpace. Leveraging more than 360K randomly sampled profiles, we characterize both the pattern of departure and the level of activity among MySpace users. Our main findings can be summarized as follows: (i) A significant fraction of accounts have been deleted and a large fraction of valid accounts have not been visited for more than three months. (ii) One third of public accounts are owned by users who abandon their accounts shortly after creation (i.e., tourists). We leverage this information to estimate the account creation time of other users from their user IDs. (iii) We demonstrate that the growth of allocated user IDs in MySpace was exponential, followed by a sudden and significant slow-down in April 2008 due to an increase in the popularity of Facebook. If such up-and down-Turns are symptomatic of OSNs, they raise the obvious question: What are the main forces that enable some systems to compete and strive in the Internet's OSN eco-system, while others decline and ultimately die out? © 2009 ACM.",Online Social Networks; OSN Eco-system; User Dynamics and Activities,Online systems; Population statistics; Empirical studies; Facebook; Myspace; On-line social networks; Online social networks (OSNs); Public accounts; User activity; User dynamics; Social networking (online)
"Tang J., Musolesi M., Mascolo C., Latora V.",4,Temporal distance metrics for social network analysis,2009,109,"Computer Laboratory, University of Cambridge, United Kingdom; Dipartimento di Fisica, University of Catania, Italy",University of Cambridge;University of Catania,2,Italy;UK,2,15,14,"The analysis of social and technological networks has at-tracted a lot of attention as social networking applications and mobile sensing devices have given us a wealth of real data. Classic studies looked at analysing static or aggre-gated networks, i.e., networks that do not change over time or built as the results of aggregation of information over a certain period of time. Given the soaring collections of measurements related to very large, real network traces, re-searchers are quickly starting to realise that connections are inherently varying over time and exhibit more dimensional-ity than static analysis can capture. In this paper we propose new temporal distance metrics to quantify and compare the speed (delay) of information diffiusion processes taking into account the evolution of a network from a local and global view. We show how these metrics are able to capture the temporal characteristics of time-varying graphs, such as delay, duration and time order of contacts (interactions), compared to the metrics used in the past on static graphs. As a proof of concept we apply these techniques to two classes of time-varying networks, namely connectivity of mobile devices and e-mail exchanges. © 2009 ACM.",Complex Networks; Information Diffusion; Social Networks; Temporal Efficiency; Temporal Graphs; Temporal Metrics,Mobile devices; Social networking (online); Information diffusion; Social networking applications; Technological networks; Temporal characteristics; Temporal distance; Temporal graphs; Temporal Metrics; Time-varying graphs; Complex networks
"Valafar M., Rejaie R., Willinger W.",3,Beyond friendship graphs: A study of user interactions in flickr,2009,39,"Department of Computer and Information Science, University of Oregon, Eugene, OR  97403, United States; AT and T Research Labs, 180 Park Ave.-Building 103, Florham Park, NJ  07932, United States",AT and T Labs;University of Oregon,2,USA,1,5,5,"Most of the existing literature on empirical studies of Online Social Networks (OSNs) have focused on characterizing and modeling the structure of their inferred friendship graphs. However, the friendship graph of an OSN does not demonstrate what fraction of its users actively interact with other users, how these users interact, and how these active users and their interactions evolve over time. In this paper, we characterize indirect fan-owner interactions through photos among users in a large photo-sharing OSN, namely Flickr. Our results show that a very small fraction of users in the main component of the friendship graph is responsible for the vast majority of fan-owner interactions; moreover, these interactions involve only a small fraction of photos in Flickr. We also characterize some of the temporal properties of fan arrival. For example, we show that there is no strong correlation between age and popularity of a photo and that most photos gain a majority of their fans during the first week after their posting. Overall, our findings provide new insights into the fan-owner interactions among Flickr users. © 2009 ACM.",Measurement; Online Social Networks; User Interaction,Measurements; User interfaces; Empirical studies; Friendship graphs; On-line social networks; Online social networks (OSNs); Photo sharing; Strong correlation; Temporal property; User interaction; Social networking (online)
"Uyeda F., Gupta D., Vahdat A., Varghese G.",4,GrassRoots: Socially-driven web sites for the masses,2009,1,"U.C. San Diego, 9500 Gilman Drive, San Diego, CA  92093-0404, United States",University of California San Diego,1,USA,1,19,5,"Large, socially-driven Web 2.0 sites such as Facebook and Youtube have seen significant growth in popularity [5, 10]. However, strong demand also exists for socially-driven web sites specialized to companies and knowledge domains. Unfortunately, existing tools for building such sites only provide low-level functionality to address recurring search and organization patterns. Further, they require expertise at many levels of the software stack. Therefore, we propose GrassRoots, a declarative language for modeling socially-driven websites and a compiler to automatically generate the code at several layers of the software stack. We provide abstractions for modeling data and relationships, search, page composition, and navigation. Most notably, we propose a graph-based data model that allows designers to both filter and rank search results using structural and value-based primitives. In this paper, we describe the GrassRoots language and show how popular sociallydriven websites can be specified using it. We also describe the GR compiler that generates web sites based on Grass-Roots specifications. © 2009 ACM.",Code Generation; Declarative Specification; Web 2.0,Graphic methods; Modeling languages; Program compilers; Social networking (online); Specifications; Code Generation; Declarative Languages; Graph-based; Knowledge domains; Page composition; Software stacks; Strong demand; Web 2.0; Websites
"Anderson J., Diaz C., Bonneau J., Stajano F.",4,Privacy-enabling social networking over untrusted networks,2009,48,"Computer Laboratory, University of Cambridge, United Kingdom; ESAT/COSIC, K.U. Leuven, Belgium",University of Cambridge,1,Belgium;UK,2,22,22,"Current social networks require users to place absolute faith in their operators, and the inability of operators to protect users from malicious agents has led to sensitive private in-formation being made public. We propose an architecture for social networking that protects users' social information from both the operator and other network users. This archi-tecture builds a social network out of smart clients and an untrusted central server in a way that removes the need for faith in network operators and gives users control of their privacy. © 2009 ACM.",Distributed Access Control; Privacy; Social Networks,Access control; Data privacy; Central servers; Distributed access controls; In networks; Malicious agent; Network users; Smart client; Social information; Untrusted network; Social networking (online)
"Heidemann J., Pradkin Y., Govindan R., Papadopoulos C., Bartlett G., Bannister J.",6,Census and survey of the visible Internet,2008,80,"USC/Information Sciences Institute, United States; USC/Computer Science Dept.; Colorado State University, United States; Aerospace Corporation, United States",Colorado State University;University of Southern California,2,USA,1,50,34,"Prior measurement studies of the Internet have explored traffic and topology, but have largely ignored edge hosts. While the number of Internet hosts is very large, and many are hidden behind firewalls or in private address space, there is much to be learned from examining the population of visible hosts, those with public unicast addresses that respond to messages. In this paper we introduce two new approaches to explore the visible Internet. Applying statistical population sampling, we use censuses to walk the entire Internet address space, and surveys to probe frequently a fraction of that space. We then use these tools to evaluate address usage, where we find that only 3.6% of allocated addresses are actually occupied by visible hosts, and that occupancy is unevenly distributed, with a quarter of responsive /24 address blocks (subnets) less than 5% full, and only 9% of blocks more than half full. We show about 34 million addresses are very stable and visible to our probes (about 16% of responsive addresses), and we project from this up to 60 million stable Internet-accessible computers. The remainder of allocated addresses are used intermittently, with a median occupancy of 81 minutes. Finally, we show that many firewalls are visible, measuring significant diversity in the distribution of firewalled block size. To our knowledge, we are the first to take a census of edge hosts in the visible Internet since 1982, to evaluate the accuracy of active probing for address census and survey, and to quantify these aspects of the Internet. Copyright 2008 ACM.",Census; Firewalls; Internet address allocation; IPv4; Survey,Active probing; Address spaces; Block sizes; Census; Firewalls; Internet hosts; IPv4; New approaches; Prior measurements; Sub-nets; Unicast; Computer system firewalls; Internet protocols; Population statistics; Probes; Sampling; Semiconducting intermetallics; Space probes; Surveys; Internet
"Kalafut A.J., Shue C.A., Gupta M.",3,Understanding implications of DNS zone provisioning,2008,13,"Computer Science Department, Indiana University, Bloomington, IN, United States",Indiana University,1,India;USA,2,20,11,"DNS is a critical component of the Internet. This paper takes a comprehensive look at the provisioning of Internet domains and its impact on the availability of various services. To gather data, we sweep 60% of the Internet's domains for zone transfers. 6.6% of them allow us to transfer their complete information. We find that carelessness in handling DNS records can lead to reduced availability of name servers, email, and Web servers. It also undermines anti-spam efforts and the efforts to shut down phishing sites or to contain mal ware infections. Copyright 2008 ACM.",DNS; Domain name system; Zone transfer,Anti-spam; Complete informations; Critical components; DNS; Domain name system; Internet domains; Name servers; Phishing; Shut downs; Web servers; Zone transfer; Internet; Internet protocols; Semiconducting intermetallics; Servers
"Shrivastava V., Rayanchu S., Yoon J., Banerjee S.",4,802.11n under the microscope,2008,83,"Department of Computer Sciences, University of Wisconsin, Madison, WI 53706, United States",University of Wisconsin-Madison,1,USA,1,7,7,"We present an experimental study of IEEE 802.11n (high throughput extension to the 802.11 standard) using commodity wireless hardware. 802.11n introduces a variety of new mechanisms including physical layer diversity techniques, channel bonding and frame aggregation mechanisms. Using measurements from our testbed, we analyze the fundamental characteristics of 802.11n links and quantify the gains of each mechanism under diverse scenarios. We show that the throughput of an 802.11n link can be severely degraded (up to w 85%) in presence of an 802.11g link. Our results also indicate that increased amount of interference due to wider channel bandwidths can lead to throughput degradation. To this end, we characterize the nature of interference due to variable channel widths in 802.11n and show that careful modeling of interference is imperative in such scenarios. Further, as a reappraisal of previous work, we evaluate the effectiveness of MAC level diversity in the presence of physical layer diversity mechanisms introduced by 802.11n. Copyright 2008 ACM.",802.11n; Channel bonding; Frame aggregation; MAC diversity; MIMO; Performance; PHY diversity; Wireless,802.11n; Channel bonding; Frame aggregation; MAC diversity; MIMO; Performance; PHY diversity; Wireless; MIM devices; Multiplexing; Semiconducting intermetallics; Standards; Internet
"Coyle A., Kraetzl M., Maennel O., Roughan M.",4,On the predictive power of shortest-path weight inference,2008,0,"University of Adelaide, SA, Australia; Dept. of Defence, Canberra, Australia; Tech. UniversitŠt Berlin, Deutsche Telekom Labs., Germany",TU Berlin;University of Adelaide,2,Australia;Germany,2,18,18,"Reverse engineering of the Internet is a valuable activity. Apart from providing scientific insight, the resulting datasets are invaluable in providing realistic network scenarios for other researchers. The Rocketfuel project attempted this process, but it is surprising how little effort has been made to validate its results. This paper concentrates on validating a particular inference methodology used to obtain link weights on a network. There is a basic difficulty in assessing the accuracy of such inferences in that a non-unique set of link-weights may produce the same routing, and so simple measurements of accuracy (even where ground truth data are available) do not capture the usefulness of a set of inferred weights. We propose a methodology based on predictive power to assess the quality of the weight inference. We used this to test Rocketfuel's algorithm, and our tests suggest that it is reasonably good particularly on certain topologies, though it has limitations when its underlying assumptions are incorrect. Copyright 2008 ACM.",Inference; Routing; Topology,Data-sets; Ground truth datum; Inference; Link weights; Network scenarios; Predictive power; Routing; Shortest paths; Reengineering; Reverse engineering; Semiconducting intermetallics; Topology; Internet
"Roughan M., Tuke J., Maennel O.",3,"Bigfoot, Sasquatch, the Yeti and other missing links: What we don't know about the AS graph",2008,30,"University of Adelaide, SA, Australia; Tech. UniversitŠt Berlin, Deutsche Telekom Labs., Germany",TU Berlin;University of Adelaide,2,Australia;Germany,2,14,8,"Study of the Internet's high-level structure has for some time intrigued scientists. The AS-graph (showing interconnections between Autonomous Systems) has been measured, studied, modelled and discussed in many papers over the last decade. However, the quality of the measurement data has always been in question. It is by now well known that most measurements of the AS-graph are missing some set of links. Many efforts have been undertaken to correct this, primarily by increasing the set of measurements, but the issue remains: how much is enough? When will we know that we have enough measurements to be sure we can see all (or almost all) of the links. This paper aims to address the problem of estimating how many links are missing from oui- measurements. We use techniques pioneered, in biostatistics and epidemiology for estimating the size of populations (for instance of fish or disease carriers). It is rarely possible to observe entire populations, and so sampling techniques are used. We extend those techniques to the domain of the AS-graph. The key difference between our work and the biological literature is that all links are not the same, and so we build a stratified model and specify an EM algorithm for estimating its parameters. Our estimates suggest that a very significant number of links (many of thousands) are missing from standard route monitor measurements of the AS-graph. Finally, we use the model to derive the number of monitors that would be needed to see a complete AS-graph with high-probability. We estimate that 700 route monitors would see 99.9% of links. Copyright 2008 ACM.",Topology inference,AS graphs; Autonomous systems; E-M algorithms; High-level structures; Measurement datum; Sampling techniques; Stratified models; Topology inference; Internet; Parameter estimation; Semiconducting intermetallics; Measurements
"Nychis G., Sekar V., Andersen D.G., Kim H., Zhang H.",5,An empirical evaluation of entropy-based traffic anomaly detection,2008,188,"Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University,1,USA,1,20,14,"Entropy-based approaches for anomaly detection are appealing since they provide more fine-grained insights than traditional traffic volume analysis. While previous work has demonstrated the benefits of entropy-based anomaly detection, there has been little effort to comprehensively understand the detection power of using entropy-based analysis of multiple traffic distributions in conjunction with each other. We consider two classes of distributions: flow-header features (IP addresses, ports, and flow-sizes), and behavioral features (degree distributions measuring the number of distinct destination/source IPs that each host communicates with). We observe that the timeseries of entropy values of the address and port distributions are strongly correlated with each other and provide very similar anomaly detection capabilities. The behavioral and flow size distributions are less correlated and detect incidents that do not show up as anomalies in the port and address distributions. Further analysis using synthetically generated anomalies also suggests that the port and address distributions have limited utility in detecting scan and bandwidth flood anomalies. Based on our analysis, we discuss important implications for entropy-based anomaly detection. Copyright 2008 ACM.",Anomaly detection; Entropy,Anomaly detection; Behavioral features; Degree distributions; Empirical evaluations; Entropy values; IP address; Time-series; Traffic anomalies; Traffic distributions; Traffic volumes; Internet; Internet protocols; Semiconducting intermetallics; Entropy
"Bender A., Sherwood R., Spring N.",3,Fixing Ally's growing pains with velocity modeling,2008,41,"Dept. of Computer Science, University of Maryland, College Park, MD, United States",University of Maryland College Park,1,USA,1,20,19,"Mapping the router topology is an important component of Internet measurement. Alias resolution, the process of mapping IP addresses to routers, is critical to accurate Internet mapping. Ally, a popular alias resolution tool, was developed to resolve aliases in individual ISPs, but its probabilistic accuracy and need to send O(n2) probes to infer aliases among n IP addresses make it unappealing for large-scale Internet mapping. In this paper, we present RadarGun, a tool that uses IP identifier velocity modeling to improve the accuracy and scalability of the Ally-based resolution technique. We provide analytical bounds on Ally's accuracy and validate our predicted aliases against Ally. Additionally, we show that velocity modeling requires only O(n) probes and thus scales to Internet-sized mapping efforts. Copyright 2008 ACM.",Alias resolution; Ally; IP identifier; Velocity modeling,Alias resolution; Ally; Analytical bounds; Internet mappings; Internet measurements; IP address; IP identifier; Resolution techniques; Velocity modeling; Internet; Internet service providers; Probes; Routers; Semiconducting intermetallics; Velocity; Internet protocols
"Songjie W., Mirkovic J.",2,Correcting congestion-based error in network telescope's observations of worm dynamics,2008,5,"Computer and Information Sciences Dept., University of Delaware, Newark, DE 19716, United States; USC Information Sciences Institute, 4676 Admiralty Way, Marina Del Rey, CA 90292, United States",University of Southern California;University of Delaware,2,USA,1,18,11,"Network telescopes have been invaluable for collecting information about dynamics of large-scale worm events. Yet, a telescope's observation may be incomplete due to scan congestion drops, hardware limitations, filtering and presence of NATs, a worm's non-uniform scanning strategy or its short life. We investigate inaccuracies in telescope observations that arise from worm-induced congestion drops of worm scans and show that they may lead to significant underestimates of the number of infectees and their scanning rate. We propose a method to infer worm-induced congestion drops from telescope's observations and use them to accurately estimate global worm dynamics. We apply our methods to CAIDA telescope's observations of Witty worm's spread, and release corrected statistics of worm dynamics for public use. Copyright 2008 ACM.",Network telescope; Observation error; Worm spread,Congestion-based; In networks; Network telescope; Non-uniform; Observation error; Scanning rates; Scanning strategies; Worm spread; Drops; Dynamics; Internet; Optical instruments; Optical telescopes; Scanning; Semiconducting intermetallics; Telescopes; Computer crime
"Rinc—n D., Roughan M., Willinger W.",3,Towards a meaningful MRA of traffic matrices,2008,15,"Univ. Politcnica de Catalunya, Av. Canal Ol’mpio, 15, Castelldefels 08860 Barcelona, Spain; School of Mathematical Sciences, University of Adelaide, SA 5005, Australia; AT and T Labs. - Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs;University of Adelaide,2,Australia;Spain;USA,3,21,18,"Most research on traffic matrices (TM) has focused on finding models that help with inference, but not with other important tasks such as synthesis of TMs, traffic prediction, or anomaly detection. In this paper we approach the problem of a general model for traffic matrices, and argue that such a model must be sparse, i.e., have a small number of parameters in comparison to the size of the TM. A Multi-Resolution Analysis (MRA) of TMs can provide such a sparse representation. The Diffusion Wavelet (DW) transform is a good choice as a MRA tool here, because it inherently adapts to the structure of the underlying network. The paper describes our construction of the two-dimensional version of the DW transform and shows how to use it for our proposed MRA of TMs. The results obtained with operational networks confirm the sparseness of the DW-based TM analysis approach and its applicability to other TM-related tasks. Copyright 2008 ACM.",Diffusion wavelets; Multi-resolution analysis; Traffic characterization; Traffic matrices,Analysis approaches; Anomaly detections; General models; Operational networks; Sparse representations; Traffic characterization; Traffic matrices; Traffic predictions; Two-dimensional; Underlying networks; Dielectric waveguides; Diffusion; Internet; Semiconducting intermetallics; Signal analysis; Multiresolution analysis
"Luckie M., Hyun Y., Huffaker B.",3,Traceroute probe method and forward IP path inference,2008,45,"Department of Computer Science, University of Waikato, Hamilton, New Zealand; CAIDA, University of California at San Diego, San Diego, CA, United States",University of California San Diego;University of Waikato,2,New Zealand;USA,2,33,15,"Several traceroute probe methods exist, each designed to perform better in a scenario where another fails. This paper examines the effects that the choice of probe method has on the inferred forward IP path by comparing the paths inferred with UDP, ICMP, and TCP-based traceroute methods to (1) a list of routable IP addresses, (2) a list of known routers, and (3) a list of well-known websites. We further compare methods by examining seven months of macroscopic Internet topology data collected by CAIDA's Archipelago infrastructure. We found significant differences in the topology observed using different probe methods. In particular, we found that ICMP-based traceroute methods tend to successfully reach more destinations, as well as collect evidence of a greater number of AS links. UDP-based methods infer the greatest number of IP links, despite reaching the fewest destinations. We hypothesise that some per-fiow load balancers implement different forwarding policies for TCP and UDP, and run a specific experiment to confirm this hypothesis. Copyright 2008 ACM.",Macroscopic internet topology discovery; Traceroute,AS-links; IP address; Ip paths; Load balancers; Macroscopic internet topology discovery; Probe methods; Traceroute; Internet; Probes; Semiconducting intermetallics; Topology; Transmission control protocol; Internet protocols
"Plonka D., Barford P.",2,Context-aware clustering of DNS query traffic,2008,37,"Uiversity of Wisconsin-Madison, United States; University of Wisconsin-Madison, Nemean Networks, United States",University of Wisconsin-Madison,1,USA,1,39,26,"The Domain Name System (DNS) is a, one of the most widely used services in the Internet. In this paper, we consider the question of how DNS traffic monitoring can provide an important and useful perspective on network traffic in an enterprise. We approach this problem by considering three classes of DNS traffic: canonical (i.e., RFC-intended behaviors), overloaded (e.g., black-list services), and unwanted (i.e., queries that will never succeed). We describe a contextaware clustering methodology that is applied to DNS queryresponses to generate the desired aggregates. Our method enables the analysis to be scaled to expose the desired level of detail of each traffic type, and to expose their time varying characteristics. We implement our method in a tool we call TreeTop, which can be used to analyze and visualize DNS traffic in real-time. We demonstrate the capabilities of our methodology and the utility of TreeTop using a set of DNS traces that we collected from our campus network over a period of three months. Our evaluation highlights both the coarse and fine level of detail that can be revealed by our method. Finally, we show preliminary results on how DNS analysis can be coupled with general network traffic monitoring to provide a useful perspective for network management and operations. Copyright 2008 ACM.",Design; Experimentation; Measurement; Performance,Campus networks; Context-aware; Domain name systems; Experimentation; General networks; Level of details; Network traffics; Performance; Time-varying; Traffic monitoring; Internet; Internet protocols; Monitoring; Semiconducting intermetallics; Network management
"Osterweil E., Massey D., Ryan M., Zhang L.",4,Quantifying the operational status of the DNSSEC deployment,2008,29,"UCLA, United States; Colorado State University, United States",Colorado State University,1,USA,1,20,14,"This paper examines the deployment of the DNS Security Extensions (DNSSEC), which adds cryptographic protection to DNS, one of the core components in the Internet infrastructure. We analyze the data collected from the initial DNSSEC deployment which started over 2 years ago, and identify three critical metrics to gauge the deployment: availability, verifiability, and validity. Our results provide the first comprehensive look at DNSSECs deployment and reveal a number of challenges that were not anticipated in the design but have become evident in the deployment. First, obstacles such as middle-boxes (firewalls, NATs, etc.) that exist in today's Internet infrastructure have proven to be problematic and have resulted in unforeseen availability problems. Second, the public-key delegation system of DNSSEC has not evolved as it was hoped and it currently leaves over 97% of DNSSEC zones isolated and unverifiable, unless some external key authentication mechanism is added. Furthermore, our results show that cryptographic verification is not equivalent to validation; a piece of verified data can still contain the wrong value. Finally, our results demonstrate the essential role of monitoring and measurement in the DNSSEC deployment. We believe that the observations and lessons from the DNSSEC deployment can provide insights into measuring future Internet-scale cryptographic systems. Copyright 2008 ACM.",DNSSEC; Internet-scale security; Measurement; Metrics,Core components; Critical metrics; Cryptographic systems; DNSSEC; External keys; Future internets; Internet infrastructures; Metrics; Public keys; Verifiability; Internet; Internet protocols; Semiconducting intermetallics; Intrusion detection
"Ramachandran A., Seetharaman S., Feamster N., Vazirani V.",4,Fast monitoring of traffic subpopulations,2008,38,"School of Computer Science, Georgia Tech., 266 Ferst Drive, Atlanta, GA, United States",Georgia Tech,1,USA,1,45,33,"Network accounting, forensics, security, and performance monitoring applications often need to examine detailed traces from subsets of flows (""subpopulations""), where the application requires flexibility in specifying the subpopulation (e.g., to detect a portscan, the application must observe many packets between a source and a destination with one packet to each port). Unfortunately, the dynamism and volume of network traffic on many high-speed links requires traffic sampling, which adversely affects subpopulation monitoring: because many subpopulations of interest to operators are low-volume flows, conventional sampling schemes (e.g., uniform random sampling) can miss much of the subpopulation's traffic. Today's routers and network devices provide scant support for monitoring specific traffic subpopulations. This paper presents the design, implementation, and evaluation of FlexSample, a traffic monitoring framework that dynamically extracts traffic from subpopulations that operators define using conditions on packet header fields. FlexSample uses a fast, flexible counter array to provide rough estimates of packets' membership in respective subpopulations. Based on these coarse estimates, FlexSample then makes per-packet sampling decisions to sample proportionately from each subpopulation (as specified by a network operator), subject to an overall sampling constraint. We apply FlexSample to extract subpopulations such as port scans and traffic to high-degree nodes and find that it can capture significantly more packets from these subpopulations than conventional approaches. Copyright 2008 ACM.",Counters; Flexsample; Sampling; Traffic statistics; Traffic subpopulations,Conventional approaches; Counter arrays; Counters; Flexsample; High-degree nodes; High-speed links; Network accountings; Network devices; Network operators; Network traffics; Packet header fields; Packet samplings; Performance monitoring; Port scans; Random samplings; Sampling schemes; Traffic monitoring; Traffic samplings; Traffic statistics; Traffic subpopulations; Volume flows; Applications; Forestry; Internet; Monitoring; Routers; Semiconducting intermetallics; Traffic surveys; Sampling
"Han D., Kaminsky M., Agarwala A., Papagiannaki K., Andersen D.G., Seshan S.",6,"Mark-and-sweep: Getting the ""Inside"" scoop on neighborhood networks",2008,12,"Carnegie Mellon University, United States; Intel Research Pittsburgh, United States",Carnegie Mellon University;Intel,2,USA,1,9,8,"Residential Internet connectivity is growing at a phenomenal rate. A number of recent studies have attempted to characterize this connectivity - measuring coverage and performance of last-mile broadband links - from a various vantage points on the Internet, via wireless APs, and even with user cooperation. These studies, however, sacrifice accuracy or require substantial human time. In this work, we present a novel two-pass method to characterize neighborhood networks. We demonstrate that the two pass method dramatically reduces the time spent in active measurement while retaining accuracy. A case study on two neighborhoods in Pittsburgh provide new and accurate insights into broadband connectivity, including throughput, broadband coverage (DSL vs. cable vs. fiber), NAT configurations, DHCP, DNS usage. The results further characterize 802.11 connectivity in the neighborhood. Copyright 2008 ACM.",Access network; Access point; Broadband connection; Measurement tool,Access network; Access point; Active measurements; Broadband connection; Broadband connectivities; Internet connectivities; Mark and sweeps; Measurement tool; Pittsburgh; Time spent; User cooperations; Internet; Semiconducting intermetallics; Servers; Telecommunication systems; Wireless networks; Measurements
"Brik V., Rayanchu S., Saha S., Sen S., Shrivastava V., Baneriee S.",6,A measurement study of a commercial-grade urban WiFi mesh,2008,37,"Department of Computer Sciences, University of Wisconsin, Madison, WI 53706, United States",University of Wisconsin-Madison,1,USA,1,23,20,"We present a measurement study of a large-scale urban WiFi mesh network consisting of more than 250 Mesh Access Points (MAPs), with paying customers that use it for Internet access. Our study, involved collecting multi-modal data, e.g., through continuous gathering of SNMP logs, syslogs, passive traffic capture, and limited active measurements in different parts of the city. Our study is split into four components -planning and deployment of the mesh, success of mesh routing techniques, likely experience of users, and characterization of how the mesh is utilized. During our data collection process that spanned 8 months, the network changed many times due to hardware and software upgrades. Hence to present a consistent view of the network, the core dataset used in this paper comes from a two week excerpt of our dataset. This part of the dataset had more than 1.7 million SNMP log entries (from 224 MAPs) and more than 100 hours of active measurements. The scale of the study allowed us to make many important observations that are critical in planning and using WiFi meshes as an Internet access technology. For example, our study indicates that the last hop 2.4GHz wireless link between the mesh and the client is the major bottleneck in client performance. Further we observe that deploying the mesh access points on utility poles results in performance degradation for indoor clients that receive poor signal from the access points. Copyright 2008 ACM.",Access network; Active measurement; Client experience; Commercial; Measurement; Pathloss; Urban; WiFi mesh; Wireless,Access network; Active measurement; Client experience; Commercial; Pathloss; Urban; WiFi mesh; Wireless; Internet; Internet protocols; Measurements; Modal analysis; Semiconducting intermetallics; Wi-Fi; Wireless networks
"Vishnumurthy V., Francis P.",2,On the difficulty of finding the nearest peer in P2P systems,2008,6,"Department of Computer Science, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,17,17,"Finding the nearest peer, in terms of latency, is an important problem in many Internet applications. In this paper, we argue that existing solutions, which only examine interpeer latencies as part of their operation will find it costly, in certain commonly occurring scenarios, to discover the nearest peer in P2P systems. The difficulty arises out of the way the PoP access networks are laid out in the Internet, where a single PoP (point of presence) belonging to an ISP provides connectivity to numerous client networks. This setup makes a group of peers all appear roughly the same distance from each other, leading to inefficiencies in the existing solutions. In this paper, we use large-scale measurements to show that the problematic topology does occur, use simulations of the Meridian closest-server algorithm to show that the condition does indeed lead to difficulty in finding the exact-closest peer, and propose solutions. Copyright 2008 ACM.",Last-hop; Latency; Nearest peer,Access networks; Internet applications; Large-scale measurements; Last-hop; Latency; Nearest peer; P2p systems; Point of presences; Client server computer systems; Internet service providers; Semiconducting intermetallics; Internet
"Afanasyev M., Chen T., Voelker G.M., Snoeren A.C.",4,Analysis of a mixed-use urban WiFi network: When metropolitan becomes neapolitan,2008,58,"University of California, San Diego, United States; Google Inc.",Google;University of California San Diego,2,USA,1,29,29,"While WiFi was initially designed as a local-area access network, mesh networking technologies have led to increasingly expansive deployments of WiFi networks. In urban environments, the WiFi mesh frequently supplements a number of existing access technologies, including wired broadband networks, 3G cellular, and commercial WiFi hotspots. It is an open question what role city-wide WiFi deployments play in the increasingly diverse access network spectrum.. We study the usage of the Google WiFi network deployed in Mountain View, California, and find that usage naturally falls into three classes, based almost entirely on client device type. Moreover, each of these classes of use has significant geographic locality, following the distribution of residential, commercial, and transportation areas of the city. Finally, we find a diverse set of mobility patterns that map well to the archetypal use cases for traditional access technologies. Copyright 2008 ACM.",Measurement; Performance,3G cellular; Access networks; Access technologies; California; Client devices; Mesh networking technologies; Mobility patterns; Performance; Urban environments; Wi-Fi deployments; Wi-Fi hotspots; Wi-fi networks; WiFi meshes; Internet; Semiconducting intermetallics; Wi-Fi; Local area networks
"Chun H., Ahn Y.-Y., Kwak H., Moon S., Eom Y.-H., Jeong H.",6,Comparison of online social relations in terms of volume vs. interaction: A case study of cyworld,2008,87,"Dept. of Computer Science, KAIST, Daejeon, South Korea; Center for Complex Network Research, Boston, United States; Dept. of Physics, KAIST, Daejeon, South Korea",KAIST,1,South Korea;USA,2,45,32,"Online social networking services are among the most popular Internet services according to Alexa.com and have become a key feature in many Internet services. Users interact through various features of online social networking services: making friend relationships, sharing their photos, and writing comments. These friend relationships are expected to become a key to many other features in web services, such as recommendation engines, security measures, online search, and personalization issues. However, we have very limited knowledge on how much interaction actually takes place over friend relationships declared online. A friend relationship only marks the beginning of online interaction. Does the interaction between users follow the declaration of friend relationship? Does a user interact evenly or lopsidedly with, friends? We venture to answer these questions in this work. We construct a network from comments written in guestbooks. A node represents a user and a directed, edge a comments from a user to another. We call this network an activity network. Previous work on activity networks include phone-call networks [34, 35] and MSN messenger networks [27]. To our best knowledge, this is the first attempt to compare the explicit friend relationship network and implicit activity network. We have analyzed structural characteristics of the activity network and compared them with the friends network. Though the activity network is weighted and directed, its structure is similar to the friend relationship network. We report that the in-degree and out-degree distributions are close to each other and the social interaction through the guestbook is highly reciprocated. When we consider only those links in the activity network that are reciprocated, the degree correlation distribution exhibits much more pronounced assortativity than the friends network and places it close to known social networks. The k-core analysis gives yet another corroborating evidence that the friends network deviates from the known social network and has an unusually large number of highly connected cores. We have delved into the weighted and directed nature of the activity network, and investigated the reciprocity, disparity, and network motifs. We also have observed that peer pressure to stay active online stops building up beyond a certain number of friends. The activity network has shown topological characteristics similar to the friends network, but thanks to its directed and weighted nature, it has allowed us more in-depth analysis of user interaction. Copyright 2008 ACM.",Clustering coefficient; Cyworld; Degree correlation; Degree distribution; Disparity; Friend relationship; Guestbook log; K-core; Network motif; Online social network; Reciprocity,Clustering coefficient; Cyworld; Degree correlation; Degree distribution; Disparity; Friend relationship; Guestbook log; K-core; Network motif; Online social network; Reciprocity; Internet; Large scale systems; Semiconducting intermetallics; Telephone circuits
"Raspall F., Sallent S.",2,Adaptive shared-state sampling,2008,11,"Department of Telematics, Technical University of Catalonia (UPC), Spain",Technical University of Catalonia (UPC),1,Spain,1,17,12,"We present two algorithms to the problem of identifying and measuring heavy-hitters. Our schemes report, with high probability, those flows that exceed a prescribed share of the traffic observed so far; along with an estimate of their sizes. One of the biggest advantages of our schemes is that they entirely rely on sampling. This makes them flexible and lightweight, permits implementing them in cheap DRAM and scale to very high speeds. Despite sampling, our algorithms can provide very accurate results and offer performance guarantees independent of the traffic mix. Most remarkably, the schemes are shown to require memory that is constant regardless of the volume and composition of the traffic observed. Thus, besides computationally light, costeffective and flexible, they are scalable and robust against malicious traffic patterns. We provide theoretical and empirical results on their performance; the latter, with software implementations and real traffic traces. Copyright 2008 ACM.",Frequent items; Heavy-hitters; Sampling; Scalability,Empirical results; Frequent items; Heavy-hitters; High probabilities; Malicious traffics; Performance guarantees; Real traffics; Software implementations; Traffic mixes; Internet; Semiconducting intermetallics; Scalability
"Su A.-J., Kuzmanovic A.",2,Thinning Akamai,2008,15,"Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL 60208, United States",Northwestern University,1,USA,1,29,16,"Global-scale Content Distribution Networks (CDNs), such as Akamai, distribute thousands of servers worldwide providing a highly reliable service to their customers. Not only has reliability been one of the main design goals for such systems -they are engineered to operate under severe and constantly changing number of server failures occurring at all times. Consequently, in addition to being resilient to component or network outages, CDNs are inherently considered resilient to denial-of-service (DoS) attacks as well. In this paper, we focus on Akamai's (audio and video) streaming service and demonstrate that the current system design is highly vulnerable to intentional service degradar tions. We show that (i) the discrepancy among streaming flows' lifetimes and DNS redirection timescales, (ii) the lack of isolation among customers and services, (e.g., video on demand vs. live streaming), (iii) a highly transparent system design, (iv) a strong bias in the stream popularity, and (v) minimal clients' tolerance for low-quality viewing experiences, are all factors that make intentional service degradations highly feasible. We demonstrate that it is possible to impact arbitrary customers' streams in arbitrary network regions: not only by targeting appropriate points at the streaming network's edge, but by effectively provoking resource bottlenecks at a much higher level in Akamai's multicast hierarchy. We provide countermeasures to help avoid such vulnerabilities and discuss how lessons learned from this research could be applied to improve DoS-resiliency of large-scale distributed and networked systems in general. Copyright 2008 ACM.",Akamai; CDN; Denial of service; Streaming,Akamai; Arbitrary networks; Audio and videos; CDN; Content distribution networks; Current systems; Denial of service; Denial-of-Service attacks; Design goals; Lessons learned; Live streaming; Low qualities; Multicast; Networked systems; Or-networks; Service degradations; Streaming; Streaming flows; Streaming networks; Streaming services; System designs; Time-scales; Video-on-demand; Customer satisfaction; Distributed computer systems; Distributed parameter networks; Distribution of goods; Internet; Sales; Semiconducting intermetallics; Servers; Systems analysis; Transmission control protocol; Large scale systems
"Dhamdhere A., Dovrolis C.",2,Ten years in the evolution of the internet ecosystem,2008,86,"School of Computer Science, Georgia Tech., United States",Georgia Tech,1,USA,1,39,32,"Our goal is to understand the evolution of the Autonomous System (AS) ecosystem over the last decade. Instead of focusing on abstract topological properties, we classify ASes into a number of ""species"" depending on their function and business type. Further, we consider the semantics of inter-AS links, in terms of customerprovider versus peering relations. We find that the available historic datasets from Route Views and RIPE are not sufficient to infer the evolution of peering links, and so we restrict our focus to customerprovider links. Our findings highlight some important trends in the evolution of the Internet over the last decade, and hint at what the Internet is heading towards. After an exponential increase phase until 2001, the Internet now grows linearly in terms of both ASes and inter-AS links. The growth is mostly due to enterprise networks and content/access providers at the periphery of the Internet. The average path, length remains almost constant mostly due to the increasing multihoming degree of transit and content/access providers. In recent years, enterprise networks prefer to connect to small transit providers, while content/access providers connect equally to both large and small transit providers. The AS species differ significantly from each other with respect to their rewiring activity; content/access providers are the most active. A few large transit providers act as ""attractors"" or ""repellers"" of customers. For many providers, strong attractiveness precedes strong repulsiveness by 3-9 months. Finally, in terms of regional growth, we find that the AS ecosystem is now larger and more dynamic in Europe than in North America. Copyright 2008 ACM.",Economics; Evolution; Internet topology; Measurement,As species; AS-links; Autonomous systems; Data-sets; Enterprise networks; Evolution; Exponential increase; Internet topology; Multi-homing; Topological properties; Ecosystems; Information theory; Semiconducting intermetallics; Internet
"Guha S., Chandrashekar J., Taft N., Papagiannaki K.",4,How healthy are today's enterprise networks?,2008,20,"Cornell University, United States; Intel Research",Cornell University;Intel,2,USA,1,17,12,"In this paper we take a look at the health of a typical enterprise network via a new metric based on the fraction of useful flows generated by endhosts. Flows considered non-useful are those that explicitly fail or else do not elicit a response from the intended destination. Examining traces collected from a large number of mobile hosts in an enterprise network, we find that about 34% of the flows are not useful. Through our study that combines data analysis and ongoing interactions with our IT department, we learn that these non-useful flows arise from several causes. Our mobile hosts frequently change environments, by either moving in and out of the corporate environment, or by switching the point and means of attachment to the corporate network. We find that many of the failures occur due to the hosts' lack of environment awareness, which results in attempts to discover services that are not present in all environments. Other causes include misconfiguration, unnecessary broadcast traffic, and excessive connection retries. Understanding this ever present noise in endhost communication is important for a variety of reasons including the fact that it complicates anomaly detection design and wastes resources, the latter of which is particularly crucial for wireless and mobile environments. Finally, we discuss possible means to design applications and services that can significantly improve the health of the network. Copyright 2008 ACM.",Enterprise; Environment awareness; Mobility; Network health,Anomaly detections; Broadcast traffics; Corporate environments; Corporate networks; Data analysis; Design applications; Enterprise; Enterprise networks; Environment awareness; Misconfiguration; Mobile environments; Mobile hosts; Mobility; Network health; Health; Internet; Online systems; Semiconducting intermetallics; Wireless networks
"Wang G., Ng T.S.E.",2,Distributed algorithms for stable and secure network coordinates,2008,17,"Dept. of Computer Science, Rice University, Houston, TX 77005, United States",Rice University,1,USA,1,38,38,"Since its inception, the concept of network coordinates has been proposed to solve a wide variety of problems such as overlay optimization, network routing, network localization, and network modeling. However, two practical problems significantly limit the applications of network coordinates today. First, how can network coordinates be stabilized without losing accuracy so that they can be cached by applications? Second, how can network coordinates be secured such that legitimate nodes' coordinates are not impacted by misbehaving nodes? Although these problems have been discussed extensively, solving them in decentralized network coordinates systems remains an open problem. This paper presents new distributed algorithms to solve the coordinates stability and security problems. For the stability problem, we propose an error elimination model that can achieve stability without hurting accuracy. A novel algorithm based on this model is presented. For the security problem, we show that recently proposed statistical detection mechanisms cannot achieve an acceptable level of security against even simple attacks. We propose to address the security problem in two parts. First, we show how the computation of coordinates can be protected by a customized Byzantine fault detection algorithm. Second, we adopt a triangle inequality violation detection algorithm to protect delay measurements. These algorithms can be integrated together to provide stable and secure network coordinates. Copyright 2008 ACM.",Distributed algorithms; Network coordinates; Security; Stability,Byzantine faults; Can networks; Decentralized networks; Delay measurements; Detection algorithms; Distributed algorithms; Error eliminations; Misbehaving nodes; Network coordinates; Network localizations; Network modeling; Novel algorithms; Open problems; Practical problems; Secure networks; Security; Security problems; Stability problems; Statistical detections; Triangle inequalities; Fault detection; Internet; Parallel algorithms; Semiconducting intermetallics; Signal detection; System stability; Network security
"Cha M., Rodriguez P., Crowcroft J., Moon S., Amatriain X.",5,Watching television over an IP network,2008,173,"MPI-SWS, SaarbrŸcken, Germany; Telefonica Research, Barcelona, Spain; University of Cambridge, Cambridge, United Kingdom; KAIST, Daejeon, South Korea",KAIST;Telefonica Research;University of Cambridge,3,Germany;South Korea;Spain;UK,4,45,29,"For half a century, television has been a dominant and pervasive mass media, driving many technological advances. Despite its widespread usage and importance to emerging applications, the ingrained TV viewing habits are not completely understood. This was primarily due to the difficulty of instrumenting monitoring devices at individual homes at a large scale. The recent boom of Internet TV (IPTV) has enabled us to monitor the user behavior and network usage of an entire network. Such analysis can provide a clearer picture of how people watch TV and how the underlying networks and systems can better adapt to future challenges. In this paper, we present the first analysis of IPTV workloads based on network traces from one of the world's largest IPTV systems. Our dataset captures the channel change activities of 250,000 households over a six month period. We characterize the properties of viewing sessions, channel popularity dynamics, geographical locality, and channel switching behaviors. We discuss implications of our findings on networks and systems, including the support needed for fast channel changes. Our data analysis of an operational IPTV system has important implications on not only existing and future IPTV systems, but also the design of the open Internet TV distribution systems such as Joost and BBC's iPlayer that distribute television on the wider Internet. Copyright 2008 ACM.",Channel switching behavior; IPTV; Network measurement,Channel changes; Channel switching behavior; Data analysis; Data sets; Distribution systems; Emerging applications; Future challenges; Geographical localities; Ip networks; IPTV; Iptv systems; Mass medias; Monitoring devices; Network measurement; Network usages; Networks and systems; Technological advances; Underlying networks; User behaviors; Behavioral research; Internet; Internet protocols; Semiconducting intermetallics; Television broadcasting; Television networks
"Nazir A., Raza S., Chuah C.-N.",3,Unveiling facebook: A measurement study of social network based applications,2008,171,"University of California, Davis, Davis, CA, United States",University of California Davis,1,USA,1,31,29,"Online social networking sites such as Facebook and MySpace have become increasingly popular, with close to 500 million users as of August 2008. The introduction of the Facebook Developer Platform and OpenSocial allows thirdparty developers to launch their own applications for the existing massive user base. The viral growth of these social applications can potentially influence how content is produced and consumed in the future Internet. To gain a better understanding, we conducted a largescale measurement study of the usage characteristics of online social network based applications. In particular, we developed and launched three Facebook applications, which have achieved a, combined subscription base of over 8 million users. Using the rich dataset gathered through these applications, we analyze the aggregate workload characteristics (including temporal and geographical distributions) as well as the structure of user interactions. We explore the existence of 'communities', with high degree of interaction within a community and limited interaction outside the community. We find that a small fraction of users account for the majority of activity within the context of our Facebook applications and a small number of applications account for the majority of users on Facebook. Furthermore, user response times for Facebook applications are independent of source/destination user locality. We also investigate distinguishing characteristics of social gaming applications. To the best of our knowledge, this is the first study analyzing user activities on online social applications. Copyright 2008 ACM.",Applications; Characterization; Facebook; Online social networks; Social games,Data sets; Degree of interactions; Facebook; Future internets; Geographical distributions; Large-scale measurements; Measurement studies; Online social networks; Response time; Social games; Social gamings; Social networking sites; User activities; User interactions; Workload characteristics; Game theory; Internet; Semiconducting intermetallics; Applications
"Dischinger M., Mislove A., Haeberlen A., Gummadi K.P.",4,Detecting BitTorrent blocking,2008,45,"MPI-SWS, Germany; Rice University, United States",Rice University,1,Germany;USA,2,9,0,"Recently, it has been reported that certain access ISPs are surreptitiously blocking their customers from uploading data using the popular BitTorrent file-sharing protocol. The reports have sparked an intense and wide-ranging policy debate on network, neutrality and ISP traffic management practices. However, to date, end users lack access to measurement tools that can detect whether their access ISPs are blocking their BitTorrent traffic. And since ISPs do not voluntarily disclose their traffic management policies, no one knows how widely BitTorrent traffic blocking is deployed in the current Internet. In this paper, we address this problem, by designing an easy-to-use tool to detect BitTorrent blocking and by presenting results from a widely used public deployment of the tool. Copyright 2008 ACM.",Bittorrent; Blocking; Network measurement,Bittorrent; Blocking; End users; File-sharing; Measurement tools; Network measurement; Policy debates; Traffic blocking; Traffic managements; Internet; Internet protocols; Internet service providers; Online systems; Semiconducting intermetallics; Measurements
"Ribeiro B., Ye T., Towsley D.",3,A resource-minimalist flow size histogram estimator,2008,14,"Computer Science Department, University of Massachusetts, Amherst, MA 01003, United States; Sprint, Burlingame, CA 94010, United States",University of Massachusetts Amherst,1,USA,1,8,7,"The histogram of network flow sizes is an important yet difficult metric to estimate in network monitoring. It is important because it characterizes traffic compositions and is a, crucial component of anomaly detection methods. It is difficult to estimate because of its high memory and computational requirements. Existing algorithms compute fine grained estimates for each flow size, i.e. 1, 2,... up to the maximum number observed over a finite time interval. Our approach instead relies on the insight that, while many applications require fine grained estimates of small flow sizes, i.e. {1,2,..., k} with a small k, network operators are often only interested in coarse grained estimates of larger flow sizes. Thus, we propose an estimator that outputs a binned histogram of size distributions. Our estimator computes this histogram in O(k 3 + log W) operations, where W is the largest flow size of interest to the network operator, while requiring only a few bits of memory per measured flow. This translates into more than 4 fold memory savings and an exponential speedup in the estimator as compared to previous works, greatly increasing the possibility of performing on line estimation inside a router. Copyright 2008 ACM.",Data stream algorithms; Flow size histogram; Monitoring systems; Sampling methods,Anomaly detection methods; Coarse-grained; Computational requirements; Data stream algorithms; Fine grained; Finite time intervals; Flow size histogram; Histogram estimators; In networks; Memory savings; Monitoring systems; Network flows; Network operators; On-line estimations; Sampling methods; Traffic compositions; Internet; Parameter estimation; Semiconducting intermetallics; Monitoring
"Tune P., Veitch D.",2,Towards optimal sampling for flow size estimation,2008,34,"CUBIN, Dept. of EandE Engineering, University of Melbourne, Australia; ARC Special Research Centre for Ultra-Broadband Information Networks (CUBIN), National ICT Australia (NICTA), Australia",NICTA;University of Melbourne,2,Australia,1,19,10,"The flow size distribution is a useful metric for traffic modeling and management. It is well known however that its estimation based on sampled data is problematic. Previous work has shown that flow sampling (FS) offers enormous statistical benefits over packet sampling, however it suffers from high resource requirements and is not currently used in routers. In this paper we present Dual Sampling, which can to a large extent provide flow-sampling-like statistical performance for packet-sampling-like computational cost. Our work is grounded in a Fisher information based approach recently used to evaluate a number of sampling schemes, excluding however FS, for TCP flows. We show how to revise and extend the approach to include FS as well as DS and others, and how to make rigorous and fair comparisons. We show how DS significantly outperforms other packet based methods, but also prove that DS is inferior to flow sampling. However, since DS is a two-parameter family of methods which includes FS as a special case. DS can be used to approach flow sampling continuously. We then describe a packet sampling based implementation of DS and analyze its key computational costs to show that router implementation is feasible. Our approach offers insights into many issues, including how the notions of 'flow quality' and 'packet gain' can be used to understand the relative performance of methods, and how the problem of optimal sampling can be formulated. Our work is theoretical with some simulation support and a case study on Internet data. Copyright 2008 ACM.",Fisher information; Flow size distribution; Internet measurement; Routers; Sampling,Approach flows; Computational costs; Dual samplings; Fisher information; Flow qualities; Flow size distribution; Flow size estimations; Internet datum; Internet measurement; Optimal samplings; Packet samplings; Packet-based; Relative performance; Resource requirements; Sampled datum; Sampling schemes; Statistical performance; Tcp flows; Traffic modeling; Dielectric relaxation; Fisher information matrix; Internet; Packet networks; Routers; Semiconducting intermetallics; Size distribution; Sampling
"Beheshti N., Ganjali Y., Ghobadi M., McKeown N., Salmon G.",5,Experimental study of router buffer sizing,2008,44,"Department of Electrical Engineering, Stanford University, Stanford, CA, United States; Department of Computer Science, University of Toronto, Toronto, ON, Canada",Stanford University;University of Toronto,2,Canada;USA,2,28,21,"During the past four years, several papers have proposed rules for sizing buffers in Internet core routers. Appenzeller et al. suggest that a link needs a buffer of size O(C/ÃN), where C is the capacity of the link, and N is the number of flows sharing the link. If correct, buffers could be reduced by 99% in a typical backbone router today without loss in throughput. Enachecsu et al., and Raina et al. suggest that buffers can be reduced even further to 20-50 packets if we are willing to sacrifice a, fraction of link capacities, and if there is a large ratio between the speed of core and access links. If correct, this is a five orders of magnitude reduction in buffer sizes. Each proposal is based on theoretical analysis and validated using simulations. Given the potential benefits (and the risk of getting it wrong!) it is worth asking if these results hold in real operational networks. In this paper, we report buffer-sizing experiments performed on real networks - either laboratory networks with commercial routers as well as customized switching and monitoring equipment (UW Madison, Sprint ATL, and University of Toronto), or operational backbone networks (Level 3 Communications backbone network, Internet2, and Stanford). The good news: Subject to the limited scenarios we can create, the buffer sizing results appear to hold. While we are confident that the O(C/ÃN) will hold quite generally for backbone routers, the 20-50 packet rule should be applied with extra caution to ensure that network components satisfy the underlying assumptions. Copyright. 2008 ACM.",NetFPGA; Network test-beds; Router buffer size; TCP,Access links; Back-bone networks; Buffer sizes; Buffer sizings; Commercial routers; Experimental studies; Internet cores; Internet-2; Level 3 communications; Link capacities; Monitoring equipments; NetFPGA; Network test-beds; Operational networks; Orders of magnitudes; Potential benefits; Real networks; Router buffer size; Stanford; TCP; University of toronto; Electric network analysis; Internet; Public works; Risk perception; Semiconducting intermetallics; Test facilities; Transmission control protocol; Routers
"Abrahao B., Kleinberg R.",2,On the Internet delay space dimensionality,2008,22,"Department of Computer Science, Cornell University, Ithaca, NY 14850, United States",Cornell University,1,USA,1,46,30,"We investigate the dimensionality properties of the Internet delay space, i.e., the matrix of measured round-trip latencies between Internet hosts. Previous work on network coordinates has indicated that this matrix can be embedded, with reasonably low distortion, into a 4- to 9-dimensional Euclidean space. The application of Principal Component Analysis (PCA) reveals the same dimensionality values. Our work addresses the question: to what extent is the dimensionality an intrinsic property of the delay space, defined without reference to a host metric such as Euclidean space? Is the intrinsic dimensionality of the Internet delay space approximately equal to the dimension determined using embedding techniques or PCA? If not, what explains the discrepancy? What properties of the network contribute to its overall dimensionality? Using datasets obtained via the King [14] method, we study different measures of dimensionality to establish the following conclusions. First, based on its power-law behavior, the structure of the delay space can be better characterized by fractal measures. Second, the intrinsic dimension is significantly smaller than the value predicted by the previous studies; in fact by our measures it is less than 2. Third, we demonstrate a particular way in which the AS topology is reflected in the delay space; subnetworks composed of hosts which share an upstream Tier-1 autonomous system in common possess lower dimensionality than the combined delay space. Finally, we observe that fractal measures, due to their sensitivity to non-linear structures, display higher precision for measuring the influence of subtle features of the delay space geometry. Copyright 2008 ACM.",Delay space; Dimensionality; Internet structure; Network embedding,Autonomous systems; Data-sets; Delay space; Dimensionality; Embedding techniques; Euclidean spaces; Fractal measures; Internet delays; Internet hosts; Internet structure; Intrinsic dimensions; Intrinsic properties; Low distortions; matrixes; Network coordinates; Network embedding; Non-linear structures; Power-law behaviors; Principal components; Space geometries; Sub-networks; Fractals; Principal component analysis; Semiconducting intermetallics; Internet
"Kanuparthy P., Dovrolis C., Ammar M.",3,"Spectral probing, crosstalk and frequency multiplexing in internet paths",2008,8,"School of Computer Science, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,25,18,"We present an end-to-end active probing methodology that creates frequency-domain signals in IP network paths. The signals are generated by periodic packet trains that cause short-lived queueing delay spikes. Different probers can be multiplexed in the frequency-domain on the same path. Further, a signal that is introduced by a ""prober"" in one path can cause a crosstalk effect, inducing a signal of the same frequency into another path (the ""sampler"") as long as the two paths share one or more bottleneck queues. Applications of the proposed methodology include the detection of shared store-and-forward devices among two or more paths, the creation of covert channels, and the modulation of voice or video periodic packet streams in less noisy frequencies. In this paper we focus on the first application. Our goal is to detect shared bottleneck(s) between a ""sampler"" and one or more ""prober"" paths. We present a spectral probing methodology as well as the corresponding signal processing/detection process. The accuracy of the method has been evaluated with controlled and repeatable simulation experiments, and it has also been tested on some Internet paths. Copyright 2008 ACM.",Active probing; Distributed agents; Fourier transform; Frequency multiplexing; Network management; Signal processing,Active probing; Covert channels; Crosstalk effects; Distributed agents; Frequency domains; Frequency multiplexing; Frequency-domain signals; Internet paths; Ip networks; Packet streams; Packet trains; Queueing delays; Simulation experiments; Store and forwards; Crosstalk; Frequency domain analysis; Internet; Internet protocols; Multiplexing; Network management; Semiconducting intermetallics; Signal processing; Voice/data communication systems; Fourier transforms
"Panchard J., Papadimitratos P., Hubaux J.-P., Rao P.R.S., Sheshshayee M.S., Kumar S.",6,Wireless sensor networking for rain-fed farming decision support,2008,20,"LCA, EPFL, Switzerland; Chennakeshava Trust, Karnataka, India; Univ. of Agriculture Sciences, Bangalore, India","EPFL, Switzerland",1,India;Switzerland,2,20,11,"Wireless sensor networks (WSNs) can be a valuable decision-support tool for farmers. This motivated our deployment of a WSN system to support rain-fed agriculture in India. We defined promising use cases and resolved technical challenges throughout a two-year deployment of our COMMON-Sense Net system, which provided farmers with environment data. However, the direct use of this technology in the field did not foster the expected participation of the population. This made it difficult to develop the intended decision-support system. Based on this experience, we take the following position in this paper: currently, the deployment of WSN technology in developing regions is more likely to be effective if it targets scientists and technical personnel as users, rather than the farmers themselves. We base this claim on the lessons learned from the COMMON-Sense system deployment and the results of an extensive user experiment with agriculture scientists, which we describe in this paper. Copyright 2008 ACM.",Agriculture; Developing countries; User experiment; Wireless sensor network,Decision support tools; Decision supports; Developing regions; Direct use; Environment data; Lessons learned; Net systems; System deployment; Technical challenges; Technical personnel; User experiment; Wireless sensor; Agriculture; Decision support systems; Developing countries; Experiments; Rain; Routing protocols; Sensor networks; Wireless telecommunication systems; Wireless sensor networks
"Nungu A., Pehrson B., Genesis N.",3,Serengeti broadband,2008,8,"TSLab., KTH, Electrum 229, SE-164 40 Kista, Sweden; Computer Studies Dept., DIT, P.O. Box 2958, Dar Es Salaam Tanzania, India","Dar Es Salaam Tanzania,India;KTH Royal Institute of Technology",2,India;Sweden;Tanzania,3,15,15,"This paper presents a broadband island defined by a fibre-optic communication network between Bunda and Serengeti, two rural districts in the Mara region in northern Tanzania. The purpose of the network is to facilitate creation and sharing of information at government institutions. The network is also expected to create jobs and entrepreneurial activities in these under-served areas The network is comprised of an optical fibre backbone and wireless local area networks operating in license-free spectrum as access networks. The fibre is currently terminated at three locations. VLAN-capable Ethernet switches with long range optical transceivers provide backbone transmission as well as fibre access. To minimize costs, routers and servers in the network are all based on standard PC hardware and Free Open Source software. The infrastructure is operated under an Open Access regime, other ways of resource sharing like virtualization at the link; network and application layers are explored. Although the broadband island defined by the fibre has a narrowband VSAT connection to the Internet, the focus on the services provided in the network is local, focusing on e-government, education, healthcare and support to local entrepreneurs. Copyright 2008 ACM.",Broadband communication; Network design; Networks; Rural networks,Access network; Application layers; Broadband communication; e-Government; Entrepreneurial activity; Ethernet switches; Fibre-optic communication; Government institutions; Long range; Narrow bands; Network design; Networks; Open Access; Open Source Software; Optical fibre; Optical transceivers; PC hardware; Resource sharing; Rural networks; Tanzania; Under-served areas; Virtualizations; Communication; Fibers; Government data processing; Light transmission; Local area networks; Open systems; Optical fibers; Optical switches; Wireless telecommunication systems; Wireless local area networks (WLAN)
"Flickenger R., Okay S., Pietrosemoli E., Zennaro M., Fonda C.",5,Very long distance Wi-Fi networks,2008,20,"Hacker Friendly LLC, 410 Broadway Ave E, Seattle, WA 98102, United States; Inveneo, 972 Mission Street, 5th, San Francisco, CA, United States; EsLaRed-ULA, Apartado 514, MŽrida 5101, Venezuela; Abdus Salm ICTP, Strada Costiera 11, 34014 Trieste, Italy","Abdus Salam ICTP,Italy",1,Italy;USA;Venezuela,3,13,12,"802.11 Wi-Fi technology is commonly used for creating wireless networks with a range of about one hundred meters. With careful planning and proper antennas, this same equipment can be used to make point-to-point links of hundreds of kilometers. This paper presents a successful 279 km link made by wireless experts in Venezuela, and a permanent 133 km test network in northern Italy for ongoing research. Copyright 2008 ACM.",Long distance; Low-cost networking; Wi-Fi; Wireless,Long distance; Long distances; Low-cost networking; Northern Italy; Point-to-point link; Test network; Venezuela; Wi Fi networks; Wi-Fi - Technology; Wireless; Wi-Fi; Wireless networks
"Rahman S.U., Hengartner U., Ismail U., Keshav S.",4,Practical security for rural Internet kiosks,2008,4,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo ON N2L 3G1, Canada",University of Waterloo,1,Canada,1,16,16,"Rural Internet kiosks typically provide weak security guarantees and therefore cannot support secure web access or transaction-oriented applications such as banking and bill payment. We present a practical, unobtrusive and easy-to-use security architecture for rural Internet kiosks that uses a combination of physical and cryptographic mechanisms to protect user data and kiosk infrastructure. Our contributions include (a) a detailed threat analysis of rural Internet kiosks, (b) a security architecture for rural Internet kiosks that does not require any specialized hardware features in kiosks, and (c) an application-independent and backward-compatible security API for securely sending and receiving data between kiosks and the Internet that can operate over disconnection-tolerant links. Copyright 2008 ACM.",Design; Measurement; Security,Bill payment; Security; Security API; Security Architecture; Specialized hardware; Threat analysis; User data; Web access; Application programming interfaces (API); Internet; Security of data
"Honicky R.J., Brewer E.A., Paulos E., White R.M.",4,N-SMARTS: Networked suite of mobile atmospheric real-time sensors,2008,87,"Dept. of Computer Science, UC Berkeley, Intel Research, Berkeley, CA, United States; Intel Research, Berkeley, CA, United States; Department of Electrical Engineering, UC Berkele, Berkeley, CA, United States",Intel;University of California Berkeley;University of California Berkeley,3,USA,1,8,5,"By attaching sensors to GPS-enabled cell phones, we can gather the raw data necessary to begin understand how urban air pollution impacts both individuals and communities. In this paper we introduce a hardware and software platform for exploring algorithms and data gathered from pollution sensors integrated into cell phones, and discuss our main research agenda going forward. Copyright 2008 ACM.",Mobile phones; Sensing,Cell phone; GPS-enabled cell phones; Hardware and software; Pollution sensors; Real time sensors; Research agenda; Sensing; Urban air pollution; Air quality; Cell membranes; Mobile devices; Mobile phones; Sensors; Telephone; Telephone sets; Wireless networks
"Sharma A., Subramanian L., Brewer E.A.",3,Secure rural supply chain management using low cost paper watermarking,2008,6,"Department of Computer Science, New York University, New York 10012, United States; Department of Computer Science, University of California, Berkeley, CA 94720, United States",NYU;University of California Berkeley,2,USA,1,23,17,"Supply chain systems in rural developing regions are extremely fragile and are vulnerable to a wide range of security threats including theft, fraud and counterfeit goods. In this paper, we propose the design of a secure, low cost supply chain management system that leverages cheap cellphones and a low-cost paper watermarking system that can authenticate and verify the integrity of goods in a supply chain. Unlike many sophisticated solutions which have deployment problems due to the harsh ground realities in rural regions, our system is easy to use, deploy and does not require significant changes to the existing operational model. In addition, our system relies only on paper and cellphones, both of which are ubiquitously used in rural developing regions. Copyright 2008 ACM.",Paper authentication; Paper speckle; Supply chain,Cell phone; Deployment problems; Developing regions; Low costs; Operational model; Rural regions; Security threats; Supply chain systems; Watermarking systems; Authentication; Chains; Speckle; Supply chains; Telephone; Telephone sets; Watermarking; Supply chain management; Paper; Supply Chain Management; Telephones
"Patra R., Surana S., Nedevschi S., Brewer E.",4,Optimal scheduling and power control for TDMA based point to multipoint wireless networks,2008,7,"Department of Electrical Engineering and Computer Science, University of California, Berkeley, United States",University of California Berkeley,1,USA,1,13,7,"In TDMA-based point-to-multipoint rural wireless deployments, co-located base station radios and sector antennas are used to increase base station capacity. To achieve maximum capacity with limited availability of non-overlapping wireless channels, we need to operate as many radios as possible from different sectors on the same channel. However, operating co-located radios on the same channel can result in substantial interference especially with the current practice of operating all radios at maximum power. We investigate techniques that increase network throughput by eliminating this interference. To this end we formulate an LP optimization problem that maximizes throughput by computing optimal transmit schedules, optimal allocation of clients to base station radios, and optimal radio power levels. Our results suggest that there is a large gap between currently-used and optimal strategies, creating opportunities for simple, practical algorithms to address these issues. Our techniques are equally applicable to both WiFi based networks as well as other point-to-multipoint technologies such as WiMax. Copyright 2008 ACM.",Point-to-multipoint; Power control; Rural wireless,Co-located; Current practices; Maximum power; Network throughput; Optimal allocation; Optimal scheduling; Optimal strategies; Optimization problems; Point-to-multipoint; Power levels; Practical algorithms; Rural wireless; Sector antennas; Wireless channel; Base stations; Optimization; Power control; Time division multiple access; Wimax; Wireless networks
"Natarajan P., Amer P.D., Stewart R.",3,Multistreamed web transport for developing regions,2008,21,"Protocol Engineering Lab., CIS Dept., University of Delaware, United States; Internet Technologies Division, Cisco Systems",Internet Technologies Division;University of Delaware,2,USA,1,20,5,"A multistreamed web transport has the potential to reduce head-of-line (HOL) blocking, and improve response times in high latency Internet browsing environments, typical of developing regions. In our position paper [13], we proposed a design for HTTP over the multistreamed Stream Control Transmission Protocol (SCTP), and implemented the design for non-pipelined (HTTP 1.0) transactions in the Apache web server and Firefox web browser. We have since adapted Apache and Firefox to handle HTTP 1.1 persistent, pipelined transfers over SCTP streams. Initial emulation results over high latency paths reveal that HTTP over SCTP streams benefits from faster page downloads, and achieves visually perceivable improvements to pipelined objects' response times. Movies comparing page downloads of HTTP/TCP vs. HTTP/SCTP streams can be found on the author's website [12]. The promising results have motivated us to propose a low cost, easily realizable, gateway-based HTTP over SCTP deployment solution to enhance users' browsing experience in developing regions. Copyright 2008 ACM.",Developing regions; Head-of-line blocking; SCTP; Transport layer multistreaming; Web response time,Developing regions; Head-of-line blocking; SCTP; Transport layer multistreaming; Web response time; Gateways (computer networks); Hypertext systems; Internet protocols; Packet networks; Response time (computer systems); Transmission control protocol; Web browsers; World Wide Web; HTTP
"Buyukkaya E., Abdallah M.",2,Efficient triangulation for P2P networked virtual environments,2008,7,"LIP6, University of Paris 6, France",University of Paris 6,1,France,1,17,13,"Peer-to-peer (P2P) architectures have recently become a popular design choice for building scalable Networked Virtual Environments (NVEs). In P2P-based NVEs, system and data management is distributed among all participating users. Towards this end, a Delaunay triangulation can be used to provide connectivity between the different NVE users depending on their positions in the virtual world. However, a Delaunay triangulation clearly suffers from a high maintenance cost as it is subject to high connection change rate due to continuous users' movement. In this paper, we propose a new variant to the Delaunay triangulation algorithm that provides network connectivity to support P2P NVEs while dramatically decreasing maintenance overhead by reducing the number of connection changes due to users' insertion and movement. Performance evaluations show that our solution drastically reduces overlay maintenance cost in highly dynamic NVEs. Copyright 2008 ACM.",Delaunay triangulation; Networked virtual environments; Peer-to-peer systems,Data management; Delaunay triangulation; Maintenance cost; Maintenance overhead; Network connectivity; Networked virtual environments; P2P-based; Peer-to-peer architectures; Peer-to-peer systems; Performance evaluation; Virtual worlds; Game theory; Maintenance; Triangulation; Virtual reality; Client server computer systems
"Chen K.-T., Pao H.-K.K., Chang H.-C.",3,Game bot identification based on manifold learning,2008,30,"Institute of Information Science, Academia Sinica, Taiwan; Dept. of Computer Science And Information Engineering, National Taiwan Univ. of Science and Technology, Taiwan",National Taiwan University of Science and Technology,1,Taiwan,1,29,22,"In recent years, online gaming has become one of the most popular Internet activities, but cheating activity, such as the use of game bots, has increased as a consequence. Generally, the gaming community disapproves of the use of game bots, as bot users obtain unreasonable rewards without corresponding efforts. However, bots are hard to detect because they are designed to simulate human game playing behavior and they follow game rules exactly. Existing detection approaches either disrupt players' gaming experiences, or they assume game bots are run as standalone clients or assigned a specific goal, such as aim bots in FPS games. In this paper, we propose a manifold learning approach for detecting game bots. It is a general technique that can be applied to any game in which avatars' movement is controlled by the players directly. Through real-life data traces, we show that the trajectories of human players and those of game bots are very different. In addition, although game bots may endeavor to simulate players' decisions, certain human behavior patterns are difficult to mimic because they are AI-hard. Taking Quake 2 as a case study, we evaluate our scheme's performance based on real-life traces. The results show that the scheme can achieve a detection accuracy of 98% or higher on a trace of 700 seconds. Copyright 2008 ACM.",Cheating; Classification; Isomap; KNN; Online Games; SVM; Tra jectory,Cheating; Classification; Isomap; KNN; Online Games; SVM; Behavioral research; Distributed computer systems; Support vector machines; Game theory
"Shirali-Shahreza M., Shirali-Shahreza S.",2,A captcha system for nintendo DS,2008,1,"Computer Science Department, Sharif University of Technology, Tehran, Iran",Sharif University of Technology,1,Iran,1,4,4,"In some websites, it is necessary to distinguish between human users and computer programs which is known as CAPTCHA (Completely Automated Public Turing test to tell Computers and Human Apart). CAPTCHA methods are mainly based on the weaknesses of OCR systems while using them are undesirable to human users and cannot be used in some devices such as devices without keyboard. Nintendo DS is a popular handheld game console which was released in 2004. Nowadays, facilities such as the Internet connection are added in new game consoles and they are not merely used for playing games. Nintendo DS is also capable of connecting to the Internet by using the Nintendo DS Browser. But Nintendo DS Browser has some limitations such as no support for Adobe Flash. Therefore we cannot use the available CAPTCHA methods on the Nintendo DS. In this paper a new CAPTCHA system based on Online Collage CAPTCHA is designed for Nintendo DS Game console. This project has been implemented by PHP scripting language. Copyright 2008 ACM.",Captcha (Completely Automated Public Turing test to tell Computers and Human Apart); Game consoles; Nintendo DS,Captcha (Completely Automated Public Turing test to tell Computers and Human Apart); CAPTCHAs; Computer program; Game consoles; Handhelds; Human users; Internet connection; Nintendo DS; PHP scripting language; System-based; Turing tests; Automation; Game theory; Internet; Optical character recognition; Dielectric relaxation
"Goodman J., Verbrugge C.",2,A peer auditing scheme for cheat elimination in MMOGs,2008,17,"McGill University, School of Computer Science, MontrŽal, QC, Canada",McGill University,1,Canada,1,28,23,"Although much of the research into massively multiplayer online games (MMOGs) focuses on scalability concerns, other issues such as the existence of cheating have an equally large practical impact on game success. Cheat prevention itself is usually addressed through the use of proprietary, ad-hoc or manual methods, combined with a strong centralized authority as found in a straightforward client/server network model. To improve scalability, however, the use of more extensible, yet less secure, peer-to-peer (P2P) models has become an attractive game design option. Here we present the IRS hybrid game model that efficiently incorporates a centralized authority into a P2P setting for purposes of controlling and eliminating game cheaters. Analysis of our design shows that with any reasonable parametrization malicious clients are purged extremely quickly and with minimal impact on non-cheating clients, while still ensuring continued benefit and scalability from distributed computations. Cheating has a serious impact on the viability of multiplayer games, and our results illustrate the possibility of a system in which scalability and security coexist. Copyright 2008 ACM.",Cheating; Computer games; Network Model; Peer auditing; Peer to peer; Trust model,Cheating; Computer games; Network Model; Peer auditing; Peer to peer; Trust model; Computer networks; Game theory; Interactive computer graphics; Scalability; Distributed computer systems
Krause S.,1,A case for mutual notification: A survey of P2P protocols for massively multiplayer online games,2008,13,"Institut fŸr Telematik, UniversitŠt Karlsruhe (TH), Germany",University of Karlsruhe,1,Germany,1,19,15,"Massively Multiplayer Online Games and Virtual Worlds are among the most popular applications on the Internet. As player numbers increase, the limits of the currently dominant client/server architecture are becoming obvious. To overcome those limits, the research community has developed protocols for these applications based on peer-to-peer technologies. However, no consensus has been found yet on how the potential of peer-to-peer can be optimally used for these applications. In this paper, we compare and evaluate three classes of proposed architectures that within themselves share common design principles. One representative protocol of each class is examined in greater detail. The performance of these protocols is then evaluated in different scenarios in a series of simulations. We show, that the architecture with the best performance in message delay is the one relying on mutual notification for detecting new neighbors and on direct connections to all neighbors for exchanging event messages. Furthermore, this architecture is still competitive regarding the required bandwidth. Copyright 2008 ACM.",Mmog; Mutual Notification; P2P; Simulation,Client/server architecture; Design Principles; Massively multi-player online games; Message delay; Mmog; Mutual Notification; P2P; P2P protocols; Peer to peer; Peer-to-peer technologies; Proposed architectures; Research communities; Simulation; Virtual worlds; Distributed computer systems; Game theory; Interactive computer graphics; Internet protocols
"Russell G., Donaldson A.F., Sheppard P.",3,Tackling online game development problems with a novel network scripting language,2008,4,"Codeplay Software Ltd., 45 York Place, Edinburgh, United Kingdom; ITI Techmedia, Glasgow, United Kingdom",Codeplay Software,1,UK,1,15,10,"We describe a novel scripting language for writing bandwidth-efficient online game logic. The language facilitates the development of deterministic, concurrent, distributed games, with assurances of consistency maintenance between clients and server. Our approach allows for increased simulation accuracy when compared to dead reckoning, and removes the need to write code to repair distributed state inconsistencies, or to explicitly transfer data over a network. Copyright 2008 ACM.",Computer games; Concurrency; Distributed games,Computer games; Concurrency; Consistency maintenance; Dead reckoning; Distributed games; Distributed state; On-line games; Scripting languages; Simulation accuracy; Computer simulation; Linguistics; Game theory
"Hildebrandt T., BergstrŠser S., Rensing C., Steinmetz R.",4,Dynamic voice communication support for multiplayer online games,2008,3,"Multimedia Communications Lab., TU Darmstadt, Germany",TU Darmstadt,1,Germany,1,6,4,"Voice communication has become an important part of interaction between players in many Multiplayer Online Games (MOGs). Successful team play depends on fast perception of and adaptation to the opponent's actions. Current voice communication tools utilize a single chat room for all team members. However several tactical situations require communication within sub groups which would interfere with other important group communication. There is a need to provide parallel dynamic communication to support current MOG scenarios demanding hierarchical grouping, increasing group sizes and handling of tactical as well as rapidly changing situations. We have developed a concept to support dynamic voice communication and implemented a tool to support communication in different game situations. Our solution supports template based pre-planning, adaptation to different game situations in real time and is easily pluggable on existing voice communication tools.",Context awareness; Networked gaming; Voice communication,Chat rooms; Context awareness; Dynamic communication; Group communications; Group size; Hierarchical groupings; Multi-player online games; Networked gaming; Pre-planning; Real time; Sub-groups; Team members; Template-based; Voice communication; Distributed computer systems; Game theory; Communication
"Prasetya K., Wu Z.D.",2,Performance analysis of game world partitioning methods for multiplayer mobile gaming,2008,11,"School of Information Technology, Bond University, Gold Coast, QLD, Australia",Bond University,1,Australia,1,9,8,"Fast development and increasing trend in multiplayer mobile gaming have created a new challenge to offer better gaming experience to mobile user. With current problems in mobile network revolving around instability of its connection, one way to minimize the impact is to reduce the amount of required state update. Game world partition has been used in multiplayer online game to provide better network management and reduce the number of network traffic by filtering the receiver for state update. In this paper, we define the metric for performance analysis specifically for game world partition. Furthermore, we propose our method where its design consideration is to keep game mechanics simple but also efficient in network resource usage for mobile gaming. We call it Brickworks with Internal Partitions (BIP). In order to compare current methods with ours, we used a simulator which takes random player movement pattern as the input and generate results based on metrics explained in this paper. Our simulation shows better result for BIP compared to other traditional partition method and based on our analysis, it will not consume much of computing resources because of its simple mechanism. Copyright 2008 ACM.",Game world partition; Mobile gaming; Networking,Computing resource; Design considerations; Game world partition; In-network; Internal partitions; Mobile gaming; Mobile networks; Mobile users; Movement pattern; Multi-player online games; Multiplayers; Network traffic; Networking; Partition methods; Partitioning methods; Performance analysis; Brickmaking; Game theory; Global system for mobile communications; Internet; Network management; Partitions (building); Wireless networks
"Suznjevic M., Matijasevic M., Dobrijevic O.",3,Action specific massive multiplayer online role playing games traffic analysis: Case study of world of warcraft,2008,15,"University of Zagreb, FER nska 3, Zagreb, Croatia",University of Zagreb,1,Croatia,1,8,7,"In Massive Multiplayer Online Role Playing Games (MMORPGs) players can perform various actions in the virtual world. We try to answer the question how is generated network traffic, and to what extent, dependent of the action that player performs and overall context/situation in the virtual world. We have divided action types in four major categories: questing, trading, raiding, and player versus player (PvP) combat. We have carried out action-specific measurements of the network traffic for the World of Warcraft (WoW) game and gathered 1.28 GB of data on which the analysis was performed. The traffic analysis included network bandwidth usage, packet payload size, percentage of data packets in the total traffic, packet rate, and packet interarrival and interdeparture times. While the category of PvP combat has highest overall demands on the client side traffic, raiding imposes highest demands on the server side. Trading showed lowest demands on the both sides in almost all categories of the analysis. Copyright 2008 ACM.",Mmorpg; Network performance measurement,Data packet; Massive multiplayer online role playing games; Mmorpg; Mmorpgs; Network bandwidth; Network performance measurement; Network traffic; Packet payloads; Packet rate; Traffic analysis; Virtual worlds; Internet; Network performance; Systems engineering; Virtual reality; Game theory
"Saroiu S., Wolman A.",2,SpySaver: Using incentives to address spyware,2008,3,"University of Toronto, Canada; Microsoft Research",Microsoft;University of Toronto,2,Canada,1,28,25,"Despite the many solutions proposed by industry and the research community to address spyware, this problem continues to grow. Many of today's anti-spyware approaches are inspired by techniques used against related security problems, such as worms, DoS attacks, computer viruses, and spam. Although these techniques have been retrofitted to address spyware, they remain ineffective because they rely on the compromised host to detect and remove spyware. Once a host is compromised, attackers often find simple ways to escape spyware detection and removal. This paper presents SpySaver - a novel anti-spyware approach that reduces the incentive to deploy spyware. Our approach does not prevent spyware installations, nor does it recover from them. Instead, SpySaver decreases the value of the information spyware collects by creating counterfeit information. Our goal is to generate enough counterfeit information to devalue the information gathered by spyware to the point that we eliminate the incentive to collect it in the first place. In this paper, we present our approach and an initial design of a tool that produces realistic counterfeit information about the browsing patterns of Web users. © 2008 ACM.",Spyware,Anti-spyware; Browsing patterns; DoS attacks; Initial designs; Research communities; Security problems; Spyware; Spyware detections; Techniques used; Web users; Technical presentations; Computer viruses
"Krishnamurthy B., Gill P., Arlitt M.",3,A few chirps about Twitter,2008,436,"AT and T Labs - Research, United States; University of Calgary, Canada; HP Labs, University of Calgary, Canada",AT and T Labs;HP Labs;University of Calgary,3,Canada;USA,2,21,9,"Web 2.0 has brought about several new applications that have enabled arbitrary subsets of users to communicate with each other on a social basis. Such communication increasingly happens not just on Facebook and MySpace but on several smaller network applications such as Twitter and Dodgeball. We present a detailed characterization of Twitter, an application that allows users to send short messages. We gathered three datasets (covering nearly 100,000 users) including constrained crawls of the Twitter network using two different methodologies, and a sampled collection from the publicly available timeline. We identify distinct classes of Twitter users and their behaviors, geographic growth patterns and current size of the network, and compare crawl results obtained under rate limiting constraints. Copyright 2008 ACM.",Measurement; Online social networks,Arbitrary subsets; Data sets; Facebook; Geographic growth; Network applications; New applications; Online social networks; Rate limiting; Short message; Web 2.0; Computer networks
"Klein M., Moreno G.A., Parkes D.C., Plakosh D., Seuken S., Wallnau K.",6,Handling interdependent values in an auction mechanism for bandwidth allocation in tactical data networks,2008,7,"Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA 15213, United States; Harvard School of Engineering and Applied Sciences, Cambridge, MA 02138, United States",Carnegie Mellon University,1,USA,1,15,12,"We consider a tactical data network with limited bandwidth, in which each agent is tracking objects and may have value for receiving data from other agents. The agents are self-interested and would prefer to receive data than share data. Each agent has private information about the quality of its data and can misreport this quality and degrade or otherwise decline to share its data. The problem is one of interdependent value mechanism design because the value to one agent for the broadcast of data on an object depends on the quality of the data, which is privately known to the sender. A recent two-stage mechanism due to Mezzetti (2004) can be modified to our setting. Our mechanism achieves efficient bandwidth allocation and provides incentive compatibility by conditioning payments on the realized value for data shared between agents. © 2008 ACM.",Interdependent values; Mechanism design; Sensor networks,Auction mechanisms; Band-width allocations; Efficient bandwidths; Incentive compatibilities; Interdependent values; Its datum; Limited bandwidths; Mechanism design; Private informations; Tactical data networks; Tracking objects; Two stages; Agents; Bandwidth; Sensor networks; Technical presentations; Telecommunication systems; Machine design
"Radosavac S., Kempf J., Kozat U.C.",3,Using insurance to increase internet security,2008,5,"DoCoMo Communications Laboratories USA, Inc., Palo Alto, CA 94304, United States",DoCoMo USA Labs,1,USA,1,4,2,"Managing security risks in the Internet has so far mostly involved methods to reduce the risks and the severity of the damages. Those methods reduce but do not eliminate risk, and the question remains on how to handle the residual risk. Current schemes applied by Internet Service Providers (ISPs) penalize the users, who suffer from the consequences. In this paper, we take a new approach to the problem of Internet security and advocate managing the residual risk by buying insurance against it and consequently re-arranging the incentive chain. We first analyze the current state of the Internet and investigate if it is possible to alleviate the existing problems by introducing insurance schemes. By performing detailed analysis we define an insurance policy that can survive in a competitive market. Following that, we analyze the impact of insurance-based ISPs on the rest of the network and attempt to answer whether using insurance can increase the overall security of the system and provide incentive to other ISPs to implement such policies. © 2008 ACM.",Correlated risk; Ddos; Economy; Incentive; Insurance; Risk transfer; Security,Correlated risk; Ddos; Economy; Incentive; Risk transfer; Security; Economics; Internet; Internet service providers; Technical presentations; Insurance
"Laskowski P., Johnson B., Chuang J.",3,"User-directed routing: From theory, towards practice",2008,1,"School of Information, United States; Logic and the Methodology of Science, UC Berkeley, United States",University of California Berkeley,1,USA,1,32,29,"User-directed routing technologies - that is, systems in which users choose their own routes through a communications network - have generated considerable interest in recent years. Despite their numerous theoretical advantages, ISPs have so far resisted these technologies, even as users have learned to capture some routing power through overlay networks. This study responds to this disconnect between theory and practice by asking how user-directed routing would affect three prominent objectives of network operators: maintaining control over the network, earning profits, and keeping inner details of the network secret. Contrary to the modern theme in routing proposals, we argue that user-directed routing is not fundamentally incompatible with ISP-control, as long as a flexible pricing system is in place. Instead - and under surprisingly general assumptions - an ISP can use prices on the open market to induce any feasible traffic pattern. Moreover, we argue that the market-based approach maximizes welfare for any given traffic pattern. In general, our model does not guarantee whether an ISP will earn more money under user-directed routing. Nevertheless, we provide some intuition to suggest why a typical ISP may expect higher profits. Finally, we suggest that giving routing power to users conflicts with an ISP's desire for secrecy. At the same time, widespread adoption of user-directed routing, perhaps promoted through regulation, may facilitate a transparent and civil industry, to the benefit of many ISPs. © 2008 ACM.",Control; Market-based routing; Pricing; Traffic engineering; Transparency; User-directed routing,Communications networks; Market-based approaches; Market-based routing; Network operators; Open markets; Pricing; Pricing systems; Theory and practices; Traffic engineering; Traffic patterns; User-directed routing; Costs; Economics; Highway engineering; Marketing; Overlay networks; Technical presentations; Transparency; Internet service providers
"Mazloumian A., Manshaei M.H., FŽlegyh‡zi M., Hubaux J.-P.",4,Optimal pricing strategy for wireless social community networks,2008,8,"Laboratory for Computer Communications and Applications, EPFL, Lausanne, Switzerland; EECS, University of California, Berkeley, United States","EPFL, Switzerland;University of California Berkeley",2,Switzerland;USA,2,9,3,"Wireless social community operators rely on subscribers who constitute a community of users. The pricing strategy of the provided wireless access is an open problem for this new generation of wireless access providers. In this paper, using both analytical and simulation approaches, we study the problem comprised of modeling user subscription and mobility behavior and of coverage evolution with the objective of finding optimal subscription fees. We compute optimal prices with both static and semi-dynamic pricing. Coping with an incomplete knowledge about users, we calculate the best static price and prove that optimal fair pricing is the optimal semi-dynamic pricing. Moreover, we have developed a simulator to verify optimal prices of social community operators with complete and incomplete knowledge. Our results show that the optimal fair pricing strategy significantly improves the cumulative payoff of social community operators. © 2008 ACM.",Pricing; Wireless internet service providers; Wireless social community,Dynamic pricing; Fair pricing; Incomplete knowledge; Mobility behaviors; Open problems; Pricing; Pricing strategies; Simulation approaches; User subscriptions; Wireless access; Wireless internet service providers; Wireless social community; Costs; Economics; Internet; Internet service providers; Optimization; Technical presentations; World Wide Web; Wireless networks
"Lelarge M., Bolot J.",2,A local mean field analysis of security investments in networks,2008,37,"INRIA-ENS, Paris, France; Sprint, CA, United States",INRIA,1,France;USA,2,16,16,"Getting agents in the Internet, and in networks in general, to invest in and deploy security features and protocols is a challenge, in particular because of economic reasons arising from the presence of network externalities. Our goal in this paper is to model and investigate the impact of such externalities on security investments in a network. Specifically, we study a network of interconnected agents subject to epidemic risks such as viruses and worms where agents can decide whether or not to invest some amount to deploy security solutions. We consider both cases when the security solutions are strong (they perfectly protect the agents deploying them) and when they are weak. We make three contributions in the paper. First, we introduce a general model which combines an epidemic propagation model with an economic model for agents which captures network effects and externalities. Second, borrowing ideas and techniques used in statistical physics, we introduce a Local Mean Field (LMF) model, which extends the standard mean-field approximation to take into account the correlation structure on local neighborhoods. Third, we solve the LMF model in a network with externalities, and we derive analytic solutions for sparse random graphs of agents, for which we obtain asymptotic results. We find known phenomena such as free riders and tipping points. We also observe counter-intuitive phenomena, such as increasing the quality of the security technology can result in a decreased adoption of that technology in the network. In general, we find that both situations with strong and weak protection exhibit externalities and that the equilibrium is not socially optimal - therefore there is a market failure. Insurance is one mechanism to address this market failure. In related work, we have shown that insurance is a very effective mechanism [3,4], and argue that using insurance would increase the security in a network such as the Internet. © 2008 ACM.",Economics; Epidemics; Free-rider problem; Game theory; Price of anarchy; Security; Tipping,Epidemics; Free-rider problem; Price of anarchy; Security; Tipping; Economics; Epidemiology; Game theory; Graph theory; Internet; Internet protocols; Investments; Network security; Technical presentations; Computer viruses
"Levin D., Baden R., Lumezanu C., Spring N., Bhattacharjee B.",5,Motivating participation in internet routing overlays,2008,1,"Department of Computer Science, University of Maryland, College Park, MD 20742, United States",University of Maryland College Park,1,USA,1,15,10,"PeerWise is an Internet routing overlay that reduces end-to-end latencies by allowing peers to forward through a relay instead of connecting directly to their destinations. Fundamental to PeerWise is the notion of peering agreements between two peers, wherein they agree to forward for one another. In this paper, we consider the problem of motivating users to establish and maintain peerings in a completely decentralized, scalable manner. We show that routing overlays present unique challenges and goals. For instance, since participants can always ""fall back"" on standard Internet routing, we must encourage users to stay in the system and maintain long-lived peering agreements. To address these challenges, we propose two mechanisms: First, we use Service Level Agreements (SLAs) to expressively negotiate peers' demands and the recourses they will take when SLAs are violated. Second, we propose a mechanism to address SLA violations that differs from the standard notion of punishment via service degradation. Our simulation results demonstrate that our mechanism causes peers to avoid SLA violators in favor of long-lived peerings. Lastly, we discuss potential, emergent behaviors in a selfish routing overlay. © 2008 ACM.",Incentives; Internet routing overlays; Service-level agreements,Emergent behaviors; End-to-end latencies; Incentives; Internet routing overlays; Selfish routing; Service degradations; Service-level agreements; Simulation results; Motivation; Ocean currents; Quality of service; Technical presentations; Internet
"Bicz—k G., Kardos S., Trinh T.A.",3,Pricing internet access for disloyal users: A game-theoretic analysis,2008,6,"High Speed Networks Lab., Dept. of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Hungary",Budapest University of Technology and Economics,1,Hungary,1,20,9,"In this paper we investigate the impact of customer loyalty on the price competition between local Internet Service Providers who sell Internet access to end-users. The main contribution of this paper is threefold. First, we develop a repeated game, and show how cooperation between ISPs resulting in higher profits can be enforced through a threat strategy in the presence of customer loyalty. Second, we investigate the case of a differentiated customer population by introducing dual reservation values, and show how it leads to new, pure strategy Nash equilibra for a wide range of demand functions. Third, we develop two novel models for customer loyalty, along with a simulation tool that is capable of demonstrating the impact of the novel models. We argue that our findings can bring us closer to the understanding of economic interactions among ISPs and, at the same time, can motivate researchers to incorporate a finer-grained user behavior model involving customer loyalty in their investigations of such interactions. © 2008 ACM.",Game theory; Internet access; Loyalty; Pricing,Customer loyalties; Demand functions; Economic interactions; End-users; Internet access; Internet services; Loyalty; Price competitions; Pricing; Repeated games; Simulation tools; Theoretic analysis; User behaviors; Behavioral research; Competition; Costs; Customer satisfaction; Economics; Functions; Internet; Internet service providers; Sales; Technical presentations; Game theory
"Zhao B.Q., Lui J.C.S., Chiu D.-M.",3,Mathematical modeling of incentive policies in p2p systems,2008,9,"Dept. of Computer Science and Engineering, Chinese University of HK, Shatin, NT, Hong Kong; Dept. of Information Engineering, Chinese University of HK, Shatin, NT, Hong Kong",Chinese University of Hong Kong,1,Hong Kong,1,10,9,"In order to stimulate cooperation among nodes in P2P systems, some form of incentive mechanism is necessary so as to encourage service contribution. Hence, designing and evaluating the stability, robustness and performance of incentive policies is extremely critical. In this paper, we propose a general mathematical framework to evaluate the stability and evolution of a family of shared history based incentive policies. To illustrate the utility of the framework, we present two incentive policies and show why one incentive policy can lead to a total system collapse while the other is stable and operates at the optimal point. One can use this mathematical framework to design and analyze various incentive policies and verify whether they match the design objectives of the underlying P2P systems. Copyright 2008 ACM.",Incentive; Learning; Peer-to-peer; Reciprocative; Stability; Strategy,Incentive; Learning; Peer-to-peer; Reciprocative; Strategy; Client server computer systems; Computer systems; Technical presentations; System stability
"Krishnamurthy B., Wills C.E.",2,Characterizing privacy in online social networks,2008,165,"AT and T Labs - Research, Florham Park, NJ, United States; Worcester Polytechnic Institute, Worcester, MA, United States",AT and T Labs;Worcester Polytechnic Institute,2,USA,1,17,17,"Online social networks (OSNs) with half a billion users have dramatically raised concerns on privacy leakage. Users, often willingly, share personal identifying information about themselves, but do not have a clear idea of who accesses their private information or what portion of it really needs to be accessed. In this study we examine popular OSNs from a viewpoint of characterizing potential privacy leakage. Our study identifies what bits of information are currently being shared, how widely, and what users can do to prevent such sharing. We also examine the role of third-party sites that track OSN users and compare with privacy leakage on popular traditional Web sites. Our long term goal is to identify the narrow set of private information that users really need to share to accomplish specific interactions on OSNs. Copyright 2008 ACM.",Online social networks; Privacy,Long-term goals; Online social networks; Privacy; Private information; Social Networks; Specific interaction; Information dissemination; Computer networks
"Gjoka M., Sirivianos M., Markopoulou A., Yang X.",4,Poking facebook: Characterization of OSN applications,2008,68,"University of California, Irvine, United States",University of California Irvine,1,USA,1,12,9,"Facebook is one of the most popular Internet sites today. A key feature that arguably contributed to Facebook's unprecedented success is its application platform, which enables the development of third-party social-networking applications. Understanding how these applications are installed and used is important for the function and utility of web-based online social networks, e.g. to better engineer them and/or to design advertising campaigns. In this paper, we characterize the popularity and user reach of Facebook applications. We analyze application usage data gathered over a period of six months from Facebook and Adonomics - a Facebook analytics service. We also crawl publicly accessible Facebook user profiles and obtain per-user application installation statistics, for approximately 300K users and 13.6K applications. Our findings include that (i) the popularity of Facebook applications has a highly skewed distribution; (ii) although the total number of application installations increases with time, the average user activity decreases; and (iii) users with more applications installed are more likely to install new applications. Copyright 2008 ACM.",Applications; Characterization; Facebook; Online social networks,Advertising campaign; Application platforms; Facebook; Key feature; Networking applications; New applications; Online social networks; Skewed distribution; Social Networks; Usage data; User activity; User profile; Installation
"Jin Y., Sen S., GuŽrin R., Hosanagar K., Zhang Z.-L.",5,Dynamics of competition between incumbent and emerging network technologies,2008,37,"ESE, University of Pennsylvania, United States; Wharton, U. Pennsylvania, United States; CSE, U. Minnesota, United States",University of Pennsylvania,1,USA,1,8,2,"The Internet is by all accounts an incredible success, but in spite or maybe because of this success, its deficiencies have come under increasing scrutiny and triggered calls for new architectures to succeed it. Those architectures will, however, face a formidable incumbent in the Internet, and their ability to ultimately replace it is likely to depend equally on technical superiority as on economic factors. The goal of this paper is to start developing models that can help provide a quantitative understanding of a competition between the Internet and a new system, and show what factors affect it most strongly. A model for the adoption of competing network technologies by individual users is formulated and solved. It accounts for both the intrinsic value of each technology and the positive externalities derived from their respective numbers of adopters. Using this model, different configurations are explored and possible outcomes characterized. More importantly, configurations are identified where small differences in the attributes of either technology can lead to vastly different results. The paper provides initial results that can help identify parameters that significantly affect the likelihood of success of new network technologies. © 2008 ACM.",Network externality; Technology adoption; Technology diffusion; User heterogeneity,Economic factors; Network externality; Network technologies; New systems; Technology adoption; Technology diffusion; User heterogeneity; Competition; Economics; Internet; Technical presentations; Technology
"Guha S., Tang K., Francis P.",3,NOYB: Privacy in online social networks,2008,169,"Cornell University, Ithaca, United States",Cornell University,1,USA,1,20,16,"Increasingly, Internet users trade privacy for service. Face-book, Google, and others mine personal information to target advertising. This paper presents a preliminary and partial answer to the general question ""Can users retain their privacy while still benefiting from these web services?"". We propose NOYB, a novel approach that provides privacy while preserving some of the functionality provided by online services. We apply our approach to the Facebook online social networking website. Through a proof-of-concept implementation we demonstrate that NOYB is practical and incrementally deployable, requires no changes to or cooperation from an existing online service, and indeed can be non-trivial for the online service to detect. Copyright 2008 ACM.",Cloud computing; NOYB; Privacy,Cloud computing; Facebook; Internet users; Non-trivial; NOYB; On-line service; Personal information; Privacy; Proof of concept; Social networking; Social Networks; Computer science; Electronic commerce; Mining; World Wide Web
"Tootoonchiar A., Gollu K.K., Saroiu S., Ganjali Y., Wolman A.",5,Lockr: Social access control for web 2.0,2008,53,"Department of Computer Science, University of Toronto, Toronto, ON M5S 2E4, Canada; Microsoft Research, Redmond, WA 98052, United States",Microsoft;University of Toronto,2,Canada;USA,2,9,6,"Sharing personal content online is surprisingly hard despite the recent emergence of a huge number of content sharing systems and sites. These systems suffer from several drawbacks: they each have a different way of providing access control which cannot be used with other systems; moving to a new system is a lengthy process and requires registration and invitation of all one's friends to the new system; and the rules for access control are complicated and become more so as our networks of online friends grow. In this paper, we present Lockr - an access control scheme based on social relationships that makes sharing personal content easy. Lockr separates social networking information from the content sharing mechanisms, thereby eliminating the need for users to maintain many site-specific copies of their social networks. We describe Lockr's design, security properties, and limitations. We also present how we integrated Lockr with two popular systems for sharing content online - BitTorrent and Flickr. Copyright 2008 ACM.",Access control; BitTorrent; Lockr; Online social networks; Web,Access control schemes; BitTorrent; Content Sharing; Content-sharing system; Lockr; New system; Online social networks; Personal Content; Security properties; Site-specific; Social networking; Social Networks; Social relationships; Web; Web 2.0; Computer networks; Online systems; Security systems; Access control
"Mislove A., Koppula H.S., Gummadi K.P., Druschel P., Bhattacharjee B.",5,Growth of the Flickr social network,2008,231,"MPI-SWS, Campus E1 4, Saarbrucken, Germany; IIT Kharagpur, Kharagpur, India; MPI-SWS, Campus E1 4, SaarbrŸcken, Germany; Computer Science Department, University of Maryland, College Park, MD, United States",University of Maryland College Park,1,Germany;India;USA,3,22,17,"Online social networking sites like MySpace, Orkut, and Flickr are among the most popular sites on the Web and continue to experience dramatic growth in their user population. The popularity of these sites offers a unique opportunity to study the dynamics of social networks at scale. Having a proper understanding of how online social networks grow can provide insights into the network structure, allow predictions of future growth, and enable simulation of systems on networks of arbitrary size. However, to date, most empirical studies have focused on static network snapshots rather than growth dynamics. In this paper, we collect and examine detailed growth data from the Flickr online social network, focusing on the ways in which new links are formed. Our study makes two contributions. First, we collect detailed data covering three months of growth, encompassing 950,143 new users and over 9.7 million new links, and we make this data available to the research community. Second, we use a first-principles approach to investigate the link formation process. In short, we find that links tend to be created by users who already have many links, that users tend to respond to incoming links by creating links back to the source, and that users link to other users who are already close in the network. Copyright 2008 ACM.",Growth; Measurement; Social networks,Close-in; Empirical studies; First-principles approaches; Formation process; Growth; Growth data; Growth dynamics; Network structures; Research communities; Social networking sites; Social networks; Static networks; Computer simulation; Online systems; Computer networks
"Cha M., Mislove A., Adams B., Gummadi K.P.",4,Characterizing social cascades in Flickr,2008,98,"MPI-SWS, Campus E1 4, SaarbrŸcken, Germany","Max Planck Institute,Germany",1,Germany,1,16,10,"Online social networking sites like MySpace and Flickr have become a popular way to share and disseminate content. Their massive popularity has led to the viral marketing of content, products, and political campaigns on the sites themselves. Despite the excitement, the precise mechanisms by which information is exchanged over these networks are not well understood. In this paper, we investigate social cascades, or how information disseminates through social links in online social networks. Using real traces of 1,000 popular photos and a social network collected from Flickr, and a theoretical framework borrowed from epidemiology, we show that social cascades are an important factor in the dissemination of content. Our work provides an important first step in understanding how information disseminates in social networks. Copyright 2008 ACM.",Cascades; Epidemiology; Information dissemination; Social networks,Cascades; Political campaign; Real trace; Social networking sites; Social networks; Theoretical framework; Viral marketing; Epidemiology; Information dissemination; Computer networks
"Yardi S., Feamster N., Bruckman A.",3,Photo-based authentication using social networks,2008,19,"School of Computer Science; School of Interactive Computing, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,9,8,"We present Lineup, a system that uses the social network graph in Facebook and auxiliary information (e.g., ""tagged"" user photos) to build a photo-based Web site authentication framework. Lineup's underlying mechanism leverages the concept of CAPTCHAs, programs that are designed to distinguish bots from human users. Lineup extends this functionality to help a Web site ascertain a user's identity or membership in a certain group (e.g., an interest group, invitees to a certain event) in order to infer some level of trust. Lineup works by presenting a user with photographs and asking the user to identify subjects in the photo whom a user with the appropriate identity or group membership should know. We present the design and implementation for Lineup, describe a preliminary prototype implementation, and discuss Lineup's security properties, including possible guarantees and threats. Copyright 2008 ACM.",Social networks; Trust,Auxiliary information; CAPTCHAs; Facebook; Group memberships; Human users; Prototype implementations; Security properties; Social networks; Trust; Underlying mechanism; Authentication; Photography; Software prototyping; World Wide Web; Computer networks
"Lerman K., Galstyan A.",2,Analysis of social voting patterns on Digg,2008,57,"University of Southern California, Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA, United States",University of Southern California,1,USA,1,24,20,"The social Web is transforming the way information is created and distributed. Blog authoring tools enable users to publish content, while sites such as Digg and Del.icio.us are used to distribute content to a wider audience. With content fast becoming a commodity, interest in using social networks to promote and find content has grown, both on the side of content producers (viral marketing) and consumers (recommendation). Here we study the role of social networks in promoting content on Digg, a social news aggregator that allows users to submit links to and vote on news stories. Digg's goal is to feature the most interesting stories on its front page, and it aggregates opinions of its many users to identify them. Like other social networking sites, Digg allows users to designate other users as ""friends"" and see what stories they found interesting. We studied the spread of interest in news stories submitted to Digg in June 2006. Our results suggest that pattern of the spread of interest in a story on the network is indicative of how popular the story will become. Stories that spread mainly outside of the submitter's neighborhood go on to be very popular, while stories that spread mainly through submitter's social neighborhood prove not to be very popular. This effect is visible already in the early stages of voting, and one can make a prediction about the potential audience of a story simply by analyzing where the initial votes come from. Copyright 2008 ACM.",Information sharing and forwarding; Recommendation/collaborative filtering systems,Authoring tool; Content producers; Front pages; Information sharing and forwarding; News aggregators; Recommendation/collaborative filtering systems; Social networking sites; Social Networks; Viral marketing; Information dissemination; Information retrieval; Computer networks
"Ramachandran A., Feamster N.",2,Authenticated out-of-band communication over social links,2008,12,"School of Computer Science, Georgia Tech., United States",Georgia Tech,1,USA,1,15,14,"Many existing host-based applications rely on their own authentication mechanisms and peer discovery services. Although social networking sites already provide mechanisms for users both to discover other users (e.g., by logging on to the social network Web site) and to communicate securely with each other (e.g., using instant messages within the social networking site), today's applications have no way to exploit the relationships and trust that are inherent in these networks. This paper proposes Authenticatr, a framework that allows applications to use the authentication and peer discovery mechanisms inherent in social networking sites to bootstrap their own authenticated communication channels. We describe motivating applications, detail the interface that Authenticatr exposes to applications, and discuss practical considerations and security threats. Copyright 2008 ACM.",Authentication; Security; Social networks,Authenticated communication; Authentication mechanisms; Host-based; Instant messages; Out-of-band; Security; Security threats; Social networking sites; Social networks; Authentication; Communication; World Wide Web; Computer networks
"Belenkiy M., Chase M., Erway C.C., Jannotti J., KŸpŸ A., Lysyanskaya A.",6,Incentivizing outsourced computation,2008,38,"Microsoft Corporation, United States; Brown University, United States",Brown University;Microsoft,2,USA,1,17,9,"We describe different strategies a central authority, the boss, can use to distribute computation to untrusted contractors. Our problem is inspired by volunteer distributed computing projects such as SETI@home, which outsource computation to large numbers of participants. For many tasks, verifying a task's output requires as much work as computing it again; additionally, some tasks may produce certain outputs with greater probability than others. A selfish contractor may try to exploit these factors, by submitting potentially incorrect results and claiming a reward. Further, malicious contractors may respond incorrectly, to cause direct harm or to create additional overhead for result-checking. We consider the scenario where there is a credit system whereby users can be rewarded for good work and fined for cheating. We show how to set rewards and fines that incentivize proper behavior from rational contractors, and mitigate the damage caused by malicious contractors. We analyze two strategies: random double-checking by the boss, and hiring multiple contractors to perform the same job. We also present a bounty mechanism when multiple contractors are employed; the key insight is to give a reward to a contractor who catches another worker cheating. Furthermore, if we can assume that at least a small fraction h of the contractors are honest (1% - 10%), then we can provide graceful degradation for the accuracy of the system and the work the boss has to perform. This is much better than the Byzantine approach, which typically assumes h > 60%. © 2008 ACM.",Currency; Distributed computation; Incentives; Outsourcing,Credit systems; Currency; Distributed computation; Distributed Computing; Graceful degradations; Incentives; Multiple contractors; Outsource; Distributed computer systems; Economics; Outsourcing; Technical presentations; Contractors
"Jiang L., Anantharam V., Walrand J.",3,Efficiency of selfish investments in network security,2008,16,"Department of Electrical Engineering and Computer Scienceat Berkeley, University of California, Berkeley, CA 94720, United States",University of California Berkeley,1,USA,1,8,7,"Internet security does not only depend on the security-related investments of individual users, but also on how these users affect each other. In a non-cooperative environment, each user chooses a level of investment to minimize its own security risk plus the cost of investment. Not surprisingly, this selfish behavior often results in undesirable security degradation of the overall system. In this paper, we first characterize the price of anarchy (POA) of network security under two models: an ""Effective-investment"" model, and a ""Bad-traffic"" model. We give insight on how the POA depends on the network topology, individual users' cost functions, and their mutual influence. We also introduce the concept of ""weighted POA"" to bound the region of all feasible payoffs. In a repeated game, on the other hand, users have more incentive to cooperate for their long term interests. We consider the socially best outcome that can be supported by the repeated game, and give a ratio between this outcome and the social optimum. Although the paper focuses on Internet security, many results are generally applicable to games with positive externalities. © 2008 ACM.",Game theory; Internet security; Positive externality; Price of anarchy,Cost of investments; Internet security; Long terms; Network topologies; Non cooperatives; Positive externality; Price of anarchy; Repeated games; Security risks; Social optimums; Cost functions; Costs; Economics; Electric network topology; Internet; Investments; Mobile telecommunication systems; Network security; Technical presentations; Game theory
"Shavitt Y., Singer Y.",2,Trading potatoes in distributed multi-tier routing systems,2008,4,"School of Electrical Engineering, Tel Aviv University, Israel; Computer Science Division, UC Berkeley, Berkeley, CA 94720, United States",Tel Aviv University;University of California Berkeley,2,Israel;USA,2,9,8,"The The Internet is an example of a distributed system where the task of routing is performed in a multi-tier fashion: interdomain paths between autonomously-managed networks are sub ject to a global agreement (BGP), and the choice of intradomain paths is left to the discretion of each such network. When forwarding packets, Autonomous Systems (ASes) frequently choose the shortest path in their network to the next-hop AS in the BGP path, a strategy known as hot potato routing. As a result, paths in the Internet are suboptimal from a global perspective. In this paper we explore complementary deviations from hot-potato routing in a manner which benefits both ASes. We show that even for a pair of ASes obtaining such path trading solutions is NP-complete, and give pseudo-polynomial algorithms to find them. We use PoP-level maps of ASes obtained from measurements of real AS topologies in the Internet to show that, in comparison to hot-potato routing, path trading can substantially reduce the cost of intradomain routing. © 2008 ACM.",Bargaining; Hot-potato routing; Ospf,Autonomous systems; Bargaining; Distributed systems; Global perspectives; Hot-potato routing; Inter domains; Intra domains; Intra-domain routing; Managed networks; Multi tiers; NP-complete; Ospf; Pseudo-polynomial algorithms; Routing systems; Shortest paths; Grid computing; Internet; Internet protocols; Technical presentations
"Jiang W., Zhang-Shen R., Rexford J., Chiang M.",4,Cooperative content distribution and traffic engineering,2008,10,"Department of Computer Science, Princeton University, United States; Department of Electrical Engineering, Princeton University, United States",Princeton University,1,USA,1,19,12,"Traditionally, Internet Service Providers (ISPs) make profit by providing Internet connectivity, while content providers (CPs) play the more lucrative role of delivering content to users. As network connectivity is increasingly a commodity, ISPs have a strong incentive to offer content to their subscribers by deploying their own content distribution infrastructure. Providing content services in a provider network presents new opportunities for coordination between server selection (to match servers with subscribers) and traffic engineering (to select efficient routes for the traffic). In this work, we utilize a mathematical framework to show that separating server selection and traffic engineering leads to a sub-optimal equilibrium, even when the CP is given accurate and timely information about network conditions. Leveraging ideas from cooperative game theory, we propose that the system implements a Nash bargaining solution that significantly improves the fairness and efficiency of the joint system. This study is another step toward a systematic understanding of the interactions between those who generate and distribute content and those who provide and operate networks. © 2008 ACM.",Content distribution; Interaction; Nash bargaining; Traffic-engineering,Co-operative game theories; Content distribution; Content providers; Content services; Interaction; Internet connectivities; Internet services; Joint systems; Mathematical frameworks; Nash bargaining; Nash bargaining solutions; Network conditions; Network connectivities; New opportunities; Server selections; Traffic engineerings; Traffic-engineering; Game theory; Internet; Internet service providers; Servers; Technical presentations; Engineering
"Yan X., Van Roy B.",2,Reputation markets,2008,4,"Electrical Engineering, Stanford University, United States; Management Science and Engineering, Electrical Engineering, Stanford University, United States",Stanford University,1,USA,1,9,6,"A reputation system should incentivize users to obtain and reveal estimates of content quality. It should also aggregate these estimates to establish content reputation in a way that counters strategic manipulation. Mechanisms have been proposed in recent literature that offer financial incentives to induce these desirable outcomes. In this paper, to systematically study what we believe to be fundamental characteristics of these mechanisms, we view them as information markets designed to assess content quality, and refer to them as reputation markets. Specifically, we develop a rational expectations equilibrium model to study how incentives created by reputation markets should influence community behavior and the accuracy of assessments. Our analysis suggests that reputation markets offer a number of desirable features: - As the quality of information improves or the cost of information acquisition decreases, reputation assessments become increasingly robust to manipulation. - If users can pay to acquire information, errors in reputation assessments do not depend on uncertainty in the manipulator's intent. - Reputation distortion incurs cost to the manipulator, resulting in cash transfers to other users. - Pseudonyms do not help a manipulator distort reputations. © 2008 ACM.",Information market; Online ratings; Rational expectations equilibrium; Reputation market; Strategic manipulation,Information market; Online ratings; Rational expectations equilibrium; Reputation market; Strategic manipulation; Cost benefit analysis; Manipulators; Personnel; Technical presentations; Marketing
"Swamynathan G., Wilson C., Boe B., Almeroth K., Zhao B.Y.",5,Do social networks improve e-commerce? A study on social marketplaces,2008,83,"Department of Computer Science, University of California at Santa Barbara, Santa Barbara, CA, United States",University of California Santa Barbara,1,USA,1,18,16,"Social networks have made a significant impact on how today's Internet users communicate, search for and share data. Numerous proposals have been made to improve existing distributed systems by leveraging the inherent trust built into social links. Many believe that augmenting online marketplaces with social networking should improve trust between transaction partners and improve user satisfaction. In this paper, we perform a detailed study of Overstock Auctions, a novel auction site that integrates social links into user profiles. Using data on connections between roughly 399,000 Overstock users, we evaluate the impact of social connections on business transactions. Our results show that while the majority of users do not engage in social networking, those who transact with friends of friends generally obtain significantly benefits in the form of higher user satisfaction. Copyright 2008 ACM.",E-Commerce; Social networks; Trust,Auction sites; Business transaction; Distributed systems; E-Commerce; Internet users; Online marketplaces; Significant impacts; Social connection; Social networking; Social networks; Trust; User profile; User satisfaction; Human computer interaction; Electronic commerce
"Ma R.T.B., Chiu D.-M., Lui J.C.S., Misra V., Rubenstein D.",5,Interconnecting eyeballs to content: A shapley value perspective on isp peering and settlement,2008,34,"Dept. of Electrical Engineering, Columbia University, New York, NY, United States; Dept. of Information Engineering, Chinese University of HK, Shatin, NT, Hong Kong; Dept. of Computer Science and Engineering, Chinese University of HK, Shatin, NT, Hong Kong; Dept. of Computer Science, Columbia University, New York, NY, United States",Chinese University of Hong Kong;Columbia University,2,Hong Kong;USA,2,10,8,"Internet service providers (ISPs) must interconnect to provide global Internet connectivity to users. The payment structure of these interconnections are often negotiated and maintained via bilateral agreements. Current differences of opinion in the appropriate revenue model in the Internet has on occasion caused ISPs to de-peer from one another, hindering network connectivity and availability. Our previous work demonstrates that the Shapley value has several desirable properties, and that if applied as the revenue model, selfish ISPs would yield globally optimal routing and interconnecting decisions. In this paper, we focus our investigation of Shapley value in networks with two basic classes of ISP: content and eyeball. In particular, we analyze the revenue distribution between ISPs with elastic and inelastic customer demands, and calculate the bilateral payments between ISPs that implement the Shapley revenue. Our results illustrate how ISP revenues are influenced by different demand models. In particular, the marginal revenue lost by de-peering for an eyeball ISP with inelastic demand is inversely proportional to the square of its degree of connectivity to content ISPs. In practice, these results provide a guideline for ISPs, even in peering relationships, to negotiate bilateral payments and for regulatory institutions to design pricing regulations. © 2008 ACM.",Bilateral agreements; Content isp; Eyeball isp; Paid-peering; Shapley value,Bilateral agreements; Content isp; Eyeball isp; Paid-peering; Shapley value; Economics; Internet; Laws and legislation; Technical presentations; Internet service providers
"Dhamdhere A., Dovrolis C.",2,"Can ISPs be profitable without violating ""network neutrality""?",2008,8,"Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,18,18,"At the core of the network neutrality debate we find that ISPs, in particular the last-mile Access Providers (APs), are trying to find new ways to be profitable, despite the fact that their transit traffic has been dramatically increasing, while they continue to charge their customers a flat monthly price. In this paper, we consider a simple model of an AP that serves its users traffic from a number of Content Providers (CPs). The AP can communicate with the CPs through a Transit Provider (TP) or through settlement-free peering. We examine the profitability of the AP under a ""baseline"" model that is based on current practice, considering the heavy tailed variability in per-user traffic and in the popularity of different CPs. Further, we consider other strategies, such as usage-based pricing for heavy hitters, selective peering with popular CPs, and content caching. Our results indicate that an AP can be profitable without the risk of losing users and without violating ""network neutrality"", through selective peering with CPs and/or content caching. © 2008 ACM.",Isp peering; Isp pricing; Network neutrality,Content providers; Heavy hitters; Heavy-tailed; Isp peering; Isp pricing; Network neutrality; On currents; Simple models; User traffics; Costs; Economics; Internet service providers; Technical presentations; Internet
"Mtibaa A., Chaintreau A., LeBrun J., Oliver E., Pietilainen A.-K., Diot C.",6,Are you moved by your social network application?,2008,54,"Thomson, 46 quai A. Le Gallo, 92648 Boulogne Cedex, France","Thomson,France",1,France,1,9,9,"This paper studies a Bluetooth-based mobile social network application deployed among a group of 28 participants collected during a computer communication conference. We compare the social graph containing friends, as defined by participants, to the contact graph, that is the temporal network created by opportunistic contacts as owners of devices move and come into communication range. Our contribution is twofold: first, we prove that most properties of nodes, links, and paths correlate among the social and contact graphs. Second, we describe how the structure of the social graph helps build forwarding paths in the contact graph, allowing two nodes to communicate over time using opportunistic contacts and intermediate nodes. Efficient paths can be built using only pairs of nodes that are socially close (i.e. connected through a few pairs of friends). Our results indicate that opportunistic forwarding complies with the requirement of social network application. Copyright 2008 ACM.",Cen-trality; Delay-tolerant network; Mobile network; Online social network; Pocket-switched networks; Temporal networks,Cen-trality; Delay-tolerant network; Mobile network; Online social network; Pocket-switched networks; Temporal networks; Bluetooth; Cellular telephone systems; Communication; Internet; Switching circuits; Wireless networks
"Chaintreau A., Fraigniaud P., Lebhar E.",3,Opportunistic spatial gossip over mobile social networks,2008,32,"CNRS, Universite Paris Diderot, France",Universite Paris Diderot,1,France,1,15,13,"This paper investigates how the principles underlying online social network services could be used to take advantage of node mobility in an opportunistic manner. As an example, we show how to take advantage of opportunistic contacts between mobile phones that run an online social network service. Our model includes static nodes, and mobile nodes which follow random walks. As in an online network service, we assume that each node can only communicate with a small subset of others nodes (called its mates) in addition to its geographical neighbors. Here we prove that, in such context, a simple connection scheme enables to execute sophisticated tasks (e.g., routing) and mechanisms (e.g., spatial gossip), while using only opportunistic communication and communication between mates. In other words, our results show that future online social networks can exploit mobility as long as they forget connections appropriately. Copyright 2008 ACM.",Delay-tolerant network; Network navigability; Online social networks; Pocket-switched networks; Spatial gossip,Delay-tolerant network; Network navigability; Online social networks; Pocket-switched networks; Spatial gossip; Communication; Switching circuits; Telecommunication equipment; Wireless networks
"La C.-A., Michiardi P.",2,Characterizing user mobility in Second Life,2008,27,"Eurecom, 2229, Route des Cretes, 06560 Sophia Antipolis, France",Eurecom,1,France,1,17,12,"In this work we present a measurement study of user mobility in Second Life. We first discuss different techniques to collect user traces and then focus on results obtained using a crawler that we built. Tempted by the question whether our methodology could provide similar results to those obtained in real-world experiments, we study the statistical distribution of user contacts and show that user mobility in Second Life presents similar traits to those of real humans. We further push our analysis to radio networks that emerge from user interaction and show that they are highly clustered. Lastly, we focus on the spatial properties of user movements and observe that users in Second Life revolve around several points of interest traveling in general short distances. Using maximum likelihood estimation, we show that our empirical data best fit to power-law with cutoff distributions, indicating that contact time distributions in a virtual environment has very similar characteristics to those observed in real-world experiments. Copyright 2008 ACM.",Contact times; Radio networks; Spatial distribution,Best fit; Contact time distributions; Contact times; Empirical data; Measurement study; Points of interest; Power-law; Radio networks; Real world experiment; Second Life; Short distances; Spatial distribution; Spatial properties; Statistical distribution; User interaction; User mobility; User movement; User trace; Virtual environments; Experiments; Maximum likelihood estimation; Radio; Size distribution; Virtual reality; Computer networks
Yang X.,1,"Auction, but don't block",2008,1,"Department of Computer Science, University of California, Irvine, United States",University of California Irvine,1,USA,1,23,18,"This paper argues that ISP's recent actions to block certain applications (e.g. BitTorrent) and attempts to differentiate traffic could be a signal of bandwidth scarcity. Bandwidth-intensive applications such as VoD could have driven the traffic demand to the capacity limit of their networks. This paper proposes to let ISPs auction their bandwidth, instead of blocking or degrading applications. A user places a bid in a packet header based on how much he values the communication. When congestion occurs, ISPs allocate bandwidth to those users that value their packets the most, and charge them the Vickrey auction price. We outline a design that addresses the technical challenges to support this auction and analyze its feasibility. Our analysis suggests that the design have reasonable overhead and could be feasible with modern hardware. © 2008 ACM.",Auction; Internet; Net-neutrality,Auction; Bandwidth-intensive applications; Bittorrent; Capacity limits; Net-neutrality; Packet headers; Technical challenges; Traffic demands; Vickrey auctions; Applications; Bandwidth; Internet; Internet service providers; Technical presentations; Telecommunication systems; Commerce
"Argyraki K., Baset S., Chun B.-G., Fall K., Iannaccone G., Knies A.",6,Can software routers scale?,2008,45,"EPFL, Switzerland; Columbia University, United States; ICSI; Intel Research","Columbia University;EPFL, Switzerland;Intel",3,Switzerland;USA,2,24,18,"Software routers can lead us from a network of special-purpose hardware routers to one of general-purpose extensible infrastructure - if, that is, they can scale to high speeds. We identify the challenges in achieving this scalability and propose a solution: a cluster-based router architecture that uses an interconnect of commodity server platforms to build software routers that are both incrementally scalable and fully programmable. Copyright 2008 ACM.",Packet processing; Routers,Cluster-based; Hardware routers; Packet processing; Router architectures; Server platforms; Software routers; Packet networks; Technical presentations; Routers
"Keller E., Green E.",2,Virtualizing the data plane through source code merging,2008,9,"Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,19,16,"Virtualization is a key technology that enables multiple research groups to test new protocols simultaneously on the same physical network and also allows service providers to incrementally add new services. In this paper we focus on virtualization of the data plane, allowing for customized packet handling in each virtual network. Much work has been done on virtualization technology. However, this has been focused on the user application experience or on a fixed networking stack. Rather than running custom data planes in user space or running separate guest operating systems, both of which come at a performance hit, we propose running a single kernel-level custom data-plane by synthesizing the configuration of the per-virtual-network data planes. In this paper we present this idea using Click, where packet processing is specified as an interconnection of fixed networking tasks. We then demonstrate the idea using an unvirtualized Linux kernel as the target platform, showing how we provided isolation between the customized data plane. Copyright 2008 ACM.",Architecture; Routing; Virtual router; Virtualization,Data planes; Key technologies; Linux kernels; Multiple researches; Network datum; New protocols; New services; Operating systems; Packet processing; Physical networks; Routing; Service providers; Single kernels; Source codes; Virtual networks; Virtual router; Virtualization; Technical presentations; Telecommunication networks; Routers
"Liu C., Mao Y., Oprea M., Basu P., Loo B.T.",5,A declarative perspective on adaptive manet routing,2008,15,"University of Pennsylvania, United States; BBN Technologies, United States",BBN Technologies;University of Pennsylvania,2,USA,1,16,10,"In this paper, we present a declarative perspective on adaptable extensible MANET protocols. Our work builds upon declarative networking, a recent innovation for building extensible network architectures using declarative languages. We make the following contributions. First, we demonstrate that traditional MANET protocols, ranging from proactive, reactive, to epidemic can be expressed in a compact fashion as declarative networks, and we validate experimentally the use of declarative techniques to implement traditional MANETs emulated on a testbed cluster. Second, we show that the declarative framework enables policy-driven adaptation, in which a generic set of declarative rule-based policies are used to make runtime decisions on the choice of MANET protocols. Third, we present some initial ideas on fine-grained protocol composition and adaptation, where a typical MANET protocol can be composed and adapted from simpler components. Copyright 2008 ACM.",Declarative queries; Extensible routing; Programmable manets; Routing languages,Declarative languages; Declarative queries; Extensible routing; Manet routing; Policy-driven; Programmable manets; Protocol compositions; Routing languages; Rule-based; Run-time; Test beds; Access control; Linguistics; Routers; Technical presentations; Ad hoc networks
"Caesar M., Rexford J.",2,Building bug-tolerant routers with virtualization,2008,12,"Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,37,25,"Implementation bugs are a highly critical problem in wide-area networks. The software running on core routers is subject to vulnerabilities, coding mistakes, and misconfiguration. Unfortunately, these problems are often found after deployment in live networks, where they lead to outages, make networks prone to attack, and involve a challenging process to localize and debug. In this work, we propose a bug-tolerant router that runs multiple diverse copies of router software in parallel, such that each copy is unlikely to fail at the same time as the others. Diversity is achieved by varying the ordering and timing of routing messages, running different routing protocols, running code written by different implementers, etc. Because each copy is different, each copy will likely have a different output during an error, and hence a simple voting procedure is then used to decide which copy's output will drive packet forwarding and control-plane communication with other routers. In this paper we motivate our design, describe some design decisions and tradeoffs, and then conclude with a description of our ongoing work in building a prototype of this architecture. Copyright 2008 ACM.",Internet routing; Protocols,Core routers; Critical problems; Design decisions; In buildings; Internet routing; Live networks; Misconfiguration; Packet forwarding; Protocols; Router softwares; Routing messages; Virtualization; Internet; Internet protocols; Routing protocols; Technical presentations; Wide area networks; Routers
"Shimonishi H., Yoshikawa T., Iwata A.",3,Off-the-path flow handling mechanism forhigh-speed and programmable traffic management,2008,1,"System Platforms Research Laboratories, NEC Corporation, 1753 Shimonumabe, Nakahara, Kawasaki, Kanagawa 211-8666, Japan",NEC,1,Japan,1,17,4,"In this paper, we propose a high-speed and programmable traffic management mechanism to enable easy and timely innovations. A control framework introduced by 4D, Tesseract, or OpenFlow, separates control functions from the switch nodes to a control server so that a variety of network control policies can be implemented outside of the switches. Within this framework, we propose a mechanism to enable flexible flow-based traffic management so that a variety of innovative traffic management schemes can be realized. Per-flow traffic management, however, requires packet-by-packet state updates, which can spoil this control framework. The proposed mechanism consists of a control server that monitors traffic conditions using sampled packets sent from the switches and calculates per-flow packet discarding rate, and switches that discard incoming packets according to the discarding rate. Packet sampling and discarding do not require packet-by-packet state handling at the switches and thus allows controls from a control server. We also propose a mechanism to compress the discarding information using a time series of bloom filters, so that frequent control updates are allowed. We tested the mechanism with per-flow WFQ emulation and the simulation results showed very good per-flow fairness. Furthermore, we found that the flow table is compressed 600 times smaller and that the processing cost at the server and the switches is small enough for use with 10 Gbps links. Copyright 2008 ACM.",Bloom filter; High-speed; Network virtualization; Per-flow; Programmable; Qos; Scalable; Traffic management,Bloom filter; High-speed; Network virtualization; Per-flow; Programmable; Qos; Scalable; Traffic management; Blooms (metal); Management; Routers; Speed; Switches; Technical presentations; Time series; Flow simulation
"Naous J., Gibb G., Bolouki S., McKeown N.",4,NetFPGA: Reusable router architecture for experimental research,2008,86,"Stanford University, CA, United States",Stanford University,1,USA,1,14,9,"Our goal is to enable fast prototyping of networking hardware (e.g. modified Ethernet switches and IP routers) for teaching and research. To this end, we built and made available the NetFPGA platform. Starting from open-source reference designs, students and researchers create their designs in Verilog, and then download them to the NetFPGA board where they can process packets at line-rate for 4-ports of 1GE. The board is becoming widely used for teaching and research, and so it has become important to make it easy to re-use modules and designs. We have created a standard interface between modules, making it easier to plug modules together in pipelines, and to create new re-usable designs. In this paper we describe our modular design, and how we have used it to build several systems, including our IP router reference design and some extensions to it. Copyright 2008 ACM.",Modular design; Netfpga; Reuse,Ethernet switches; Experimental researches; Fast prototyping; Ip routers; Modular design; Netfpga; Open sources; Process packets; Re-usable designs; Reference designs; Reuse; Router architectures; Standard interfaces; Verilog; Internet protocols; Pipelines; Routers; Teaching; Technical presentations; Design
"Bolla R., Bruschi R.",2,Pc-based software routers: High performance and application service support,2008,50,"DIST, University of Genoa, Via all'Opera Pia 13, 16139, Genoa, Italy",University of Genoa,1,Italy,1,12,9,"Despite high potential and flexibility in developing new functionalities and mechanisms, as well as the availability of well-established networking SW, common criticism of Software Routers, based on COTS HW elements and open-source SW, is mainly focused on performance, especially for issues concerning the data plane. In this respect, our contribution is aimed at evaluation of architectural bottlenecks limiting the scalability of Software Router performance, and identification of SW and HW enhancements needed to overcome these limitations. Starting from these considerations, we propose a feasible Software Router HW/SW solution able to boost data plane performance while maintaining the flexibility level typical of a SW approach. Copyright 2008 ACM.",Linux networking; Multi-layer support; Open router,Application services; Data planes; High potentials; Linux networking; Multi-layer support; Open router; Open sources; Pc-based softwares; Software routers; Technical presentations; Routers
"Greenberg A., Lahiri P., Maltz D.A., Patel P., Sengupta S.",5,Towards a next generation data center architecture: Scalability and commoditization,2008,130,"Microsoft, Redmond, WA, United States",Microsoft,1,USA,1,18,17,"Applications hosted in today's data centers suffer from internal fragmentation of resources, rigidity, and bandwidth constraints imposed by the architecture of the network connecting the data center's servers. Conventional architectures statically map web services to Ethernet VLANs, each constrained in size to a few hundred servers owing to control plane overheads. The IP routers used to span traffic across VLANs and the load balancers used to spray requests within a VLAN across servers are realized via expensive customized hardware and proprietary software. Bisection bandwidth is low, severly constraining distributed computation Further, the conventional architecture concentrates traffic in a few pieces of hardware that must be frequently upgraded and replaced to keep pace with demand - an approach that directly contradicts the prevailing philosophy in the rest of the data center, which is to scale out (adding more cheap components) rather than scale up (adding more power and complexity to a small number of expensive components). Commodity switching hardware is now becoming available with programmable control interfaces and with very high port speeds at very low port cost, making this the right time to redesign the data center networking infrastructure. In this paper, we describe monsoon, a new network architecture, which scales and commoditizes data center networking monsoon realizes a simple mesh-like architecture using programmable commodity layer-2 switches and servers. In order to scale to 100,000 servers or more,monsoon makes modifications to the control plane (e.g., source routing) and to the data plane (e.g., hot-spot free multipath routing via Valiant Load Balancing). It disaggregates the function of load balancing into a group of regular servers, with the result that load balancing server hardware can be distributed amongst racks in the data center leading to greater agility and less fragmentation. The architecture creates a huge, flexible switching domain, supporting any server/any service and unfragmented server capacity at low cost. Copyright 2008 ACM.",Commoditization; Data center network,Bandwidth constraints; Bisection bandwidths; Commoditization; Control interfaces; Control planes; Data center architectures; Data center network; Data planes; Distributed computations; Flexible switching; Hot spots; Ip routers; Load balancers; Load-balancing; Low costs; Multi-path routing; Networking infrastructures; Proprietary softwares; Scale-Up; Server capacities; Source-routing; Valiant load-balancing; Architecture; Philosophical aspects; Routers; Satellite communication systems; Technical presentations; Servers
"Egi N., Greenhalgh A., Handley M., Hoerdt M., Huici F., Mathy L.",6,Fairness issues in software virtual routers,2008,32,"Computing Dept., Lancaster University, Lancaster, United Kingdom; Dept. of Computer Science, University College London, London, United Kingdom; NEC Europe Ltd., Heidelberg, Germany",Lancaster University;University College London,2,Germany;UK,2,10,8,In this paper we investigate the building of a virtual router platform that ensures isolation and fairness between concurrent virtual routers. Recent developments in commodity x86 hardware enable us to take advantage of the flexibility and wealth of resources available to a software router in order to build a virtual router platform. Using commodity x86 hardware we show that it is viable to run highly experimental and untrusted router systems along side a production router on the same hardware platform without sacrificing performance. We investigate the extent to which we can isolate a virtual router running experimental code from other virtual routers. Copyright 2008 ACM.,Commodity hardware; Routers; Virtualization,Commodity hardware; Hardware platforms; Software routers; Virtualization; Hardware; Technical presentations; Routers
"Sharma A., Belding E.M.",2,FreeMAC: Framework for multi-channel mac development on 802.11 hardware,2008,47,"Department of Computer Science, University of California, Santa Barbara, CA 93106, United States",University of California Santa Barbara,1,USA,1,16,13,"Exponential growth in the number of wireless devices that operate in the limited unlicensed frequency spectrum necessitates the next generation of radio devices to be reconfigurable and sensitive to changes in network conditions and spectrum availability. Most modern wireless devices offer increased software programmability and control over radio communication parameters. Since a large portion of the MAC protocol is implemented in software, with the firmware providing a set of functional primitives, it is possible to design and implement alternate MAC protocols in real testbeds equipped with commodity 802.11 devices. This paper describes FreeMAC, a reconfigurable MAC protocol development framework that enables the design and implementation of a general class of multi-channel MAC protocols on a typical Linux system. FreeMAC provides support for frequent channel switching and fine control over the timing of packet transmissions. We also propose a mechanism to reduce the latency in the scheduling of periodic operations of a software MAC protocol that have strict timing requirements. Results from our six node testbed indicate that using our approach, the scheduling latency of slot transitions in a TDMA-style MAC can be improved by up to an order of magnitude, with minimal overhead. FreeMAC also exports a number of radio configuration parameters as API functions to enable cross layer interactions among wireless networking protocols. As a proof of concept, we implement a simple multi-channel TDMA MAC on our testbed to demonstrate the utility of FreeMAC as a development framework. Copyright 2008 ACM.",Mac; Medium access; Multi channel; Tdma; Wireless networks,Api functions; Channel switching; Communication parameters; Cross-layer interactions; Exponential growths; Frequency spectrums; General class; In networks; Linux systems; Mac; Mac protocols; Medium access; Multi channel; Multi-channel MAC protocols; Multi-channel macs; Order of magnitudes; Packet transmissions; Periodic operations; Programmability; Proof of concepts; Radio configurations; Re-configurable; Tdma; Timing requirements; Wireless devices; Wireless-networking protocols; Concurrency control; Firmware; International trade; Radio; Radio communication; Routers; Scheduling; Technical presentations; Test facilities; Testbeds; Time division multiple access; Time measurement; Wireless telecommunication systems; Wireless networks
"Bouabene G., Jelger C., Tschudin C.",3,Virtual network stacks,2008,6,"Computer Science Department, University of Basel, Switzerland",University of Basel,1,Switzerland,1,13,6,"In this paper, we get inspiration from peer to peer file sharing networks to provide a new way of inter-networking. In our proposal, nodes having access to multiple network types can share their networking resources with other peers residing in networks with different protocols and (potentially) different addressing schemes. Such neighbor nodes will form a peer to peer overlay backbone; the purpose of it being to offer to applications and protocols access to remote network stacks that their running hosts do not implement or have no direct access to. This creates RPC-like access to foreign network stacks well in line with a federation approach that avoids introducing a global overlay for integrating heterogeneous networks. Copyright 2008 ACM.",Autonomic network architecture; Distributed network stacks; Inter-networking; Network sharing; Virtual network stacks,Autonomic network architecture; Distributed network stacks; Inter-networking; Network sharing; Virtual network stacks; Heterogeneous networks; Overlay networks; Routers; Technical presentations; Network architecture
"Yu M., Thottan M., Li L.",3,Latency equalization: A programmable routing service primitive,2008,3,"Princeton University, United States; Bell Labs, Alcatel-Lucent, United States",Bell Labs;Princeton University,2,USA,1,19,16,"Today the Internet is the primary medium for deploying new real time services such as gaming and distributed online live music concerts. Different network services have different expectations from the routing infrastructure. Some network services require conventional routing paths optimized for low latency or low congestion. However, real-time interactive services such as online gaming and distributed live music performance require more than just low latency. They require Latency EQualization (LEQ) among participating users. Although LEQ could be performed by the client or the server, end-system techniques for estimating network conditions are often inaccurate. Instead, we argue that the network should provide a LEQ service. We propose a LEQ routing architecture that can leverage programmable hub nodes. By deploying a few flexible, well-placed programmable nodes to redirect traffic, we can flexibly support both latency equalized and low latency routing services simultaneously. For LEQ routing, programmable hub nodes provide services such as application packet identification, application level packet processing and latency equalized routing paths. Extensive simulation studies on provider network topologies show that using just a few programmable nodes we can achieve an 80% improvement in LEQ over the conventional architecture that uses shortest path routing. Copyright 2008 ACM.",Latency equalization; Online interactive applications; Optimization; Programmable routing,Application levels; Conventional routing; Extensive simulations; Interactive services; Latency equalization; Low latencies; Music performance; Network conditions; Network services; Network topologies; On-line gamings; Online interactive applications; Packet identifications; Packet processing; Programmable nodes; Programmable routing; Real-time services; Routing architectures; Routing infrastructures; Routing paths; Routing services; Shortest-path routing; Applications; Electric network topology; Routers; Technical presentations; Wireless sensor networks
"Wang H., Yang Y.R., Liu P.H., Wang J., Gerber A., Greenberg A.",6,Reliability as an interdomain service,2007,10,"Yale University, United States; AT and T Labs - Research, United States; Microsoft Research",AT and T Labs;Microsoft;Yale University,3,USA,1,43,33,"Reliability is a critical requirement of the Internet. The availability and resilience of the Internet under failures can have significant global effects. However, in the current Internet routing architecture, achieving the high level of reliability demanded by many mission critical activities can be costly. In this paper, we first propose a novel solution framework called reliability as an interdomain service (REIN) that can be incrementally deployed in the Internet and may improve the redundancy of IP networks at low cost. We then present robust algorithms to efficiently utilize network redundancy to improve reliability. We use real IP network topologies and traffic traces to demonstrate the effectiveness of our framework and algorithms. Copyright 2007 ACM.",Fast rerouting; Reliability; Traffic engineering,Fast rerouting; Internet routing; Traffic engineering; Algorithms; Computer system recovery; Internet protocols; Network routing; Robust control; Telecommunication traffic; Web services
"Koponen T., Chawla M., Chun B.-G., Ermolinskiy A., Kim K.H., Shenker S., Stoica I.",7,A data-oriented (and beyond) network architecture,2007,782,"International Computer Science Institute (ICSI), United States; Helsinki Institute for Information Technology (HIIT), Finland; UC Berkeley, Computer Science Division, United States",Helsinki Institute for Information Technology;University of California Berkeley,2,Finland;USA,2,43,35,"The Internet has evolved greatly from its original incarnation. For instance, the vast majority of current Internet usage is data retrieval and service access, whereas the architecture was designed around host-to-host applications such as telnet and ftp. Moreover, the original Internet was a purely transparent carrier of packets, but now the various network stakeholders use middleboxes to improve security and accelerate applications. To adapt to these changes, we propose the Data-Oriented Network Architecture (DONA), which involves a clean-slate redesign of Internet naming and name resolution. Copyright 2007 ACM.",data; Internet architecture; middleboxes; name resolution; Naming,Data-Oriented Network Architecture (DONA); Internet architecture; Network stakeholders; Data processing; Packet networks; Security of data; Web services; Network architecture
"MŸhlbauer W., Uhlig S., Fu B., Meulle M., Maennel O.",5,In search for an appropriate granularity to model routing policies,2007,36,"TU Berlin, T-Labs, Germany; Delft University of Technology, Netherlands; France Telecom R and D, France; University of Adelaide, Australia",TU Delft;France Telecom R and D;TU Berlin;University of Adelaide,4,Australia;France;Germany;Netherlands,4,27,21,"Routing policies are typically partitioned into a few classes that capture the most common practices in use today [1]. Unfortunately, it is known that the reality of routing policies [2] and peering relationships is far more complex than those few classes [1,3]. We take the next step of searching for the appropriate granularity at which policies should be modeled. For this purpose, we study how and where to configure per-prefix policies in an AS-level model of the Internet, such that the selected paths in the model are consistent with those observed in BGP data from multiple vantage points. By comparing business relationships with per-prefix filters, we investigate the role and limitations of business relationships as a model for policies. We observe that popular locations for filtering correspond to valleys where no path should be propagated according to inferred business relationships. This result reinforces the validity of the valley-free property used for business relationships inference. However, given the sometimes large path diversity ASs have, business relationships do not contain enough information to decide which path will be chosen as the best. To model how individual ASs choose their best paths, we introduce a new abstraction: next-hop atoms. Next-hop atoms capture the different sets of neighboring ASs an AS uses for its best routes. We show that a large fraction of next-hop atoms correspond to per-neighbor path choices. A non-negligible fraction of path choices, however, correspond to hot-potato routing and tie-breaking within the BGP decision process, very detailed aspects of Internet routing. Copyright 2007 ACM.",BGP; Inter-domain routing; Routing policies,Inter-domain routing; Peer to peer; Prefix filters; Computational complexity; Distributed computer systems; Electronic commerce; Information analysis; Network routing; Web services; Search engines
Ford B.,1,Structured streams: A new transport abstraction,2007,35,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,56,27,"Internet applications currently have a choice between stream and datagram transport abstractions. Datagrams efficiently support small transactions and streams are suited for long-running conversations, but neither abstraction adequately supports applications like HTTP that exhibit a mixture of transaction sizes, or applications like FTP and SIP that use multiple transport instances. Structured Stream Transport (SST) enhances the traditional stream abstraction with a hierarchical hereditary structure, allowing applications to create lightweight child streams from any existing stream. Unlike TCP streams, these lightweight streams incur neither 3-way handshaking delays on startup nor TIME-WAIT periods on close. Each stream offers independent data transfer and flow control, allowing different transactions to proceed in parallel without head-of-line blocking, but all streams share one congestion control context. SST supports both reliable and best-effort delivery in a way that semantically unifies datagrams with streams and solves the classic ""large datagram"" problem, where a datagram's loss probability increases exponentially with fragment count. Finally, an application can prioritize its streams relative to each other and adjust priorities dynamically through out-of-band signaling. A user-space prototype shows that SST is TCP-friendly to within 2%, and performs comparably to a user-space TCP and to within 10% of kernel TCP on a WiFi network. Copyright 2007 ACM.",Best effort; Datagram; Fairness; Mobility; Multimedia; Reliable; SST; Stream; TCP; Transport protocols; Web transport,Datagrams; Structured Stream Transport (SST); Structured streams; Transport abstraction; Congestion control (communication); Data structures; Hierarchical systems; HTTP; Multimedia services; Problem solving; User interfaces; Web services; Transmission control protocol
"Cheng Y.-C., Afanasyev M., Verkaik P., Benkš P., Chiang J., Snoeren A.C., Savage S., Voelker G.M.",8,Automating cross-layer diagnosis of enterprise wireless networks,2007,53,"Department of Computer Science and Engineering, University of California, San Diego, United States; Traffic Analysis and Network Performance Laboratory(TrafficLab), Ericsson Research, Budapest, Hungary",Ericsson Research;University of California San Diego,2,Hungary;USA,2,23,23,"Modern enterprise networks are of sufficient complexity that even simple faults can be difficult to diagnose - let alone transient outages or service degradations. Nowhere is this problem more apparent than in the 802.11-based wireless access networks now ubiquitous in the enterprise. In addition to the myriad complexities of the wired network, wireless networks face the additional challenges of shared spectrum, user mobility and authentication management. Not surprisingly, few organizations have the expertise, data or tools to decompose the underlying problems and interactions responsible for transient outages or performance degradations. In this paper, we present a set of modeling techniques for automatically characterizing the source of such problems. In particular, we focus on data transfer delays unique to 802.11 networks - media access dynamics and mobility management latency. Through a combination of measurement, inference and modeling we reconstruct sources of delay - from the physical layer to the transport - layer as well as the interactions among them. We demonstrate our approach using comprehensive traces of wireless activity in the UCSD Computer Science building. Copyright 2007 ACM.",802.11; Measurement; Modeling; Wireless networks,Authentication; Computational complexity; Electronic commerce; Multimedia services; Problem solving; Ubiquitous computing; Enterprise networks; Media access dynamics; Wired network; Wireless networks
"Huang C., Li J., Ross K.W.",3,Can internet video-on-demand be profitable?,2007,313,"Microsoft Research, Redmond, WA 98052, United States; Polytechnic University, Brooklyn, NY 11201, United States",Microsoft;NYU,2,USA,1,22,16,"Video-on-demand in the Internet has become an immensely popular service in recent years. But due to its high bandwidth requirements and popularity, it is also a costly service to provide. We consider the design and potential benefits of peer-assisted video-on-demand, in which participating peers assist the server in delivering VoD content. The assistance is done in such a way that it provides the same user quality experience as pure client-server distribution. We focus on the single-video approach, whereby a peer only redistributes a video that it is currently watching. Using a nine-month trace from a client-server VoD deployment for MSN Video, we assess what the 95 percentile server bandwidth costs would have been if a peer-assisted employment had been instead used. We show that peer-assistance can dramatically reduce server bandwidth costs, particularly if peers prefetch content when there is spare upload capacity in the system. We consider the impact of peer-assisted VoD on the cross-traffic among ISPs. Although this traffic is significant, if care is taken to localize the P2P traffic within the ISPs, we can eliminate the ISP cross traffic while still achieving important reductions in server bandwidth. We also develop a simple analytical model which captures many of the critical features of peer-assisted VoD, including its operational modes. Copyright 2007 ACM.",ISP-friendly; Peer-to-peer; Video-on-demand,Operational modes; Peer-to-peer; Server bandwidth; Bandwidth; Distributed computer systems; Servers; Telecommunication traffic; Web services; Video on demand
"Bhandarkar S., Reddy A.L.N., Zhang Y., Loguinov D.",4,Emulating AQM from end hosts,2007,23,"Texas A and M University, College Station, TX 77843, United States; Motorola Inc., Austin, TX, United States",Motorola;Texas A and M University,2,USA,1,32,20,"In this paper, we show that end-host based congestion prediction is more accurate than previously characterized. However, it may not be possible to entirely eliminate the uncertainties in congestion prediction. To address these uncertainties, we propose Probabilistic Early Response TCP (PERT). PERT emulates the behavior of AQM/ECN, in the congestion response function of end-hosts. We present fluid-flow analysis of PERT/RED and PERT/PI, versions of PERT that emulate router-based RED and PI controllers. Our analysis shows that PERT/RED has better stability behavior than router-based RED. We also present results from ns-2 simulations to show the practical feasibility of PERT. The scheme presented here is general and can be used for emulating other AQM algorithms. Copyright 2007 ACM.",Algorithms; Design; Experimentation; Measurement; Performance; Theory,Congestion prediction; Experimentation; Algorithms; Computer simulation; Data transfer; Routers; Transmission control protocol; Congestion control (communication)
"Jamieson K., Balakrishnan H.",2,PPR: partial packet recovery for wireless networks,2007,166,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,35,17,"Bit errors occur in wireless communication when interference or noise overcomes the coded and modulated transmission. Current wireless protocols may use forward error correction (FEC) to correct some small number of bit errors, but generally retransmit the whole packet if the FEC is insufficient. We observe that current wireless mesh network protocols retransmit a number of packets and that most of these retransmissions end up sending bits that have already been received multiple times, wasting network capacity. To overcome this inefficiency, we develop, implement, and evaluate a partial packet recovery (PPR) system. PPR incorporates two new ideas: (1) SoftPHY, an expanded physical layer (PHY) interface that provides PHY-independent hints to higher layers about the PHY's confidence in each bit it decodes, and (2) a postamble scheme to recover data even when a packet preamble is corrupted and not decodable at the receiver. Finally, we present PP-ARQ, an asynchronous link-layer ARQ protocol built on PPR that allows a receiver to compactly encode a request for retransmission of only those bits in a packet that are likely in error. Our experimental results from a 31-node Zigbee (802.15.4) testbed that includes Telos motes with 2.4 GHz Chipcon radios and GNU Radio nodes implementing the 802.15.4 standard show that PP-ARQ increases end-to-end capacity by a factor of 2x under moderate load. Copyright 2007 ACM.",802.11; ARQ; Llayering; Synchronization; Wireless; Zigbee,Bit errors; Packet recovery; Wireless mesh network protocols; Error correction; Network protocols; Signal interference; Spurious signal noise; Synchronization; Telecommunication systems; Wireless networks; Packet networks
"Sommers J., Barford P., Duffield N., Ron A.",4,Accurate and efficient SLA compliance monitoring,2007,50,"University of Wisconsin-Madison, United States; AT and T Labs-Research, United States",AT and T Labs;;University of Wisconsin-Madison,3,USA,1,42,33,"Service level agreements (SLAs) define performance guarantees made by service providers, e.g, in terms of packet loss, delay, delay variation, and network availability. In this paper, we describe a new active measurement methodology to accurately monitor whether measured network path characteristics are in compliance with performance targets specified in SLAs. Specifically, (1) we describe a new methodology for estimating packet loss rate that significantly improves accuracy over existing approaches; (2) we introduce a new methodology for measuring mean delay along a path that improves accuracy over existing methodologies, and propose a method for obtaining confidence intervals on quantiles of the empirical delay distribution without making any assumption about the true distribution of delay; (3) we introduce a new methodology for measuring delay variation that is more robust than prior techniques; and (4) we extend existing work in network performance tomography to infer lower bounds on the quantiles of a distribution of performance measures along an unmeasured path given measurements from a subset of paths. We unify active measurements for these metrics in a discrete time-based tool called SLAM. The unified probe stream from SLAM consumes lower overall bandwidth than if individual streams are used to measure path properties. We demonstrate the accuracy and convergence properties of SLAM in a controlled laboratory environment using a range of background traffic scenarios and in one- and two-hop settings, and examine its accuracy improvements over existing standard techniques. Copyright 2007 ACM.",Active measurement; Network congestion; Network delay; Network jitter; Packet loss; Service-level agreements; SLAM,Active measurement; Delay variation; Network congestion; Service level agreements (SLA); Computer aided software engineering; Computer networks; Convergence of numerical methods; Robust control; Telecommunication traffic; Web services; Packet loss
"Gummadi R., Wetherall D., Greenstein B., Seshan S.",4,Understanding and mitigating the impact of RF interference on 802.11 networks,2007,136,"USC; Intel Research; University of Washington, United States; CMU",Intel;University of Washington at Seattle,2,USA,1,30,7,"We study the impact on 802.11 networks of RF interference from devices such as Zigbee and cordless phones that increasingly crowd the 2.4GHz ISM band, and from devices such as wireless camera jammers and non-compliant 802.11 devices that seek to disrupt 802.11 operation. Our experiments show that commodity 802.11 equipment is surprisingly vulnerable to certain patterns of weak or narrow-band interference. This enables us to disrupt a link with an interfering signal whose power is 1000 times weaker than the victim's 802.11 signals, or to shut down a multiple AP, multiple channel managed network at a location with a single radio interferer. We identify several factors that lead to these vulnerabilities, ranging from MAC layer driver implementation strategies to PHY layer radio frequency implementation strategies. Our results further show that these factors are not overcome by simply changing 802.11 operational parameters (such as CCA threshold, rate and packet size) with the exception of frequency shifts. This leads us to explore rapid channel hopping as a strategy to withstand RF interference. We prototype a channel hopping design using PRISM NICs, and find that it can sustain throughput at levels of RF interference well above that needed to disrupt unmodified links, and at a reasonable cost in terms of switching overheads. Copyright 2007 ACM.",802.11; Channel hopping; Jamming; RF interference; SINR,Channel hopping; Radio frequency implementation strategies; Radio interferers; Wireless cameras; Cordless telephones; Data transfer; Jamming; Natural frequencies; Packet networks; Radio interference
"Casado M., Freedman M.J., Pettit J., Luo J., Mckeown N., Shenker S.",6,Ethane: Taking control of the enterprise,2007,366,"Stanford University, United States; UC Berkeley, ICSI, United States",Stanford University;University of California Berkeley,2,USA,1,25,15,"This paper presents Ethane, a new network architecture for the enterprise. Ethane allows managers to define a single network-wide fine-grain policy, and then enforces it directly. Ethane couples extremely simple flow-based Ethernet switches with a centralized controller that manages the admittance and routing of flows. While radical, this design is backwards-compatible with existing hosts and switches. We have implemented Ethane in both hardware and software, supporting both wired and wireless hosts. Our operational Ethane network has supported over 300 hosts for the past four months in a large university network, and this deployment experience has significantly affected Ethane's design. Copyright 2007 ACM.",Architecture; Management; Network; Security,Ethane network; Fine-grain policy; Wireless hosts; Computer software; Control systems; Ethernet; Network architecture; Network routing; Security of data; Switching systems; Industrial economics
"Mudigonda J., Vin H.M., Keckler S.W.",3,Reconciling performance and programmability in networking systems,2007,8,"Department of Computer Sciences, University of Texas, Austin, TX 78712, United States",University of Texas at Austin,1,USA,1,38,19,"Challenges in addressing the memory bottleneck have made it difficult to design a packet processing platform that simultaneously achieves both ease-of-programming and high performance. Today's commercial processors support two architectural mechanisms - namely, hardware multithreading and caching - to overcome the memory bottleneck. The configurations of these mechanisms (e.g., cache capacity, number of threads per processor core) are fixed at processor-design time. The relative effectiveness of these mechanisms, however, varies significantly with application, traffic, and system characteristics. Thus, programmers often struggle to achieve high performance from a processor that is not well-suited to a particular deployment. To address this challenge, we first make a case for, and then develop a malleable processor architecture that facilitates the dynamic reconfiguration of cache capacity and number of threads to best-suit the needs of each deployment. We then present an algorithm that can determine the optimal thread-cache balance at run-time. The combination of these two allows us to simultaneously achieve the goals of ease-of-programming and high performance. We demonstrate that our processor outperforms a processor similar to Intel's IXP2800 - a state-of-the-art commercial Network Processor - in about 89% of the deployments we consider. Further, in about 30% of the deployments our platform improves the throughput by as much as 300%. Copyright 2007 ACM.",Data cache; Memory bottleneck; Multithreading; Packet processing; Processor architectures; Reconfigurable architectures; Routers,Computer hardware; Computer networks; Data processing; Packet networks; Program processors; Routers; Memory bottleneck; Packet processing; Processor architectures; System characteristics; Computer systems programming
"Parno B., Wendlandt D., Shi E., Perrig A., Maggs B., Hu Y.-C.",6,Portcullis: Protecting connection setup from denial-of-capability attacks,2007,84,"Carnegie Mellon University, United States; Carnegie Mellon University, Akamai Technologies, United States; Carnegie Mellon University, Urbana-Champaign, United States",Akamai Technologies;Carnegie Mellon University,2,USA,1,32,26,"Systems using capabilities to provide preferential service to selected flows have been proposed as a defense against large-scale network denial-of-service attacks. While these systems offer strong protection for established network flows, the Denial-of-Capability (DoC) attack, which prevents new capability-setup packets from reaching the destination, limits the value of these systems. Portcullis mitigates DoC attacks by allocating scarce link bandwidth for connection establishment packets based on per-computation fairness. We prove that a legitimate sender can establish a capability with high probability regardless of an attacker's resources or strategy and that no system can improve on our guarantee. We simulate full and partial deployments of Portcullis on an Internet-scale topology to confirm our theoretical results and demonstrate the substantial benefits of using per-computation fairness. Copyright 2007 ACM.",Network capability; Per-computation fairness,Network capability; Percomputation fairness; Computational methods; Internet; Large scale systems; Network management; Network security
"Terpstra W.W., Kangasharju J., Leng C., Buchmann A.P.",4,"Bubblestorm: Resilient, probabilistic, and exhaustive peer-to-peer search",2007,91,"Technische Universitat Darmstadt, Germany; University of Helsinki, Finland",TU Darmstadt;University of Helsinki,2,Finland;Germany,2,21,19,"Peer-to-peer systems promise inexpensive scalability, adaptability, and robustness. Thus, they are an attractive platform for file sharing, distributed wikis, and search engines. These applications often store weakly structured data, requiring sophisticated search algorithms. To simplify the search problem, most scalable algorithms introduce structure to the network. However, churn or violent disruption may break this structure, compromising search guarantees. This paper proposes a simple probabilistic search system, BubbleStorm, built on random multigraphs. Our primary contribution is a flexible and reliable strategy for performing exhaustive search. BubbleStorm also exploits the heterogeneous bandwidth of peers. However, we sacrifice some of this bandwidth for high parallelism and low latency. The provided search guarantees are tunable, with success probability adjustable well into the realm of reliable systems. For validation, we simulate a network with one million low-end peers and show BubbleStorm handles up to 90% simultaneous peer departure and 50% simultaneous crash. Copyright 2007 ACM.",Exhaustive search; Peer-to-peer; Resilience; Simulation,Exhaustive search; Peer-to-peer; Scalable algorithms; Algorithms; Computer simulation; Probabilistic logics; Problem solving; Robustness (control systems); Search engines; Distributed computer systems
"Bonfiglio D., Mellia M., Meo M., Rossi D., Tofanelli P.",5,Revealing skype traffic: When randomness plays with you,2007,173,"Politecnico di Torino, Dipartimento di Elettronica, Italy; ENST TŽlŽcom Paris, Informatique et RŽseaux, France; Motorola Inc., Torino, Italy",Motorola;Politecnico di Torino,2,France;Italy,2,17,12,"Skype is a very popular VoIP software which has recently attracted the attention of the research community and network operators. Following a closed source and proprietary design, Skype protocols and algorithms are unknown. Moreover, strong encryption mechanisms are adopted by Skype, making it very difficult to even glimpse its presence from a traffic aggregate. In this paper, we propose a framework based on two complementary techniques to reveal Skypetraffic in real time. The first approach, based on Pearson'sChi-Square test and agnostic to VoIP-related trafficcharacteristics, is used to detect Skype's fingerprint from the packet framing structure, exploiting the randomness introduced at the bit level by the encryption process. Conversely, the second approach is based on a stochastic characterization of Skype traffic in terms of packet arrival rate and packet length, which are used as features of a decision process based on Naive Bayesian Classifiers.In order to assess the effectiveness of the above techniques, we develop an off-line cross-checking heuristic based on deep-packet inspection and flow correlation, which is interesting per se. This heuristic allows us to quantify the amount of false negatives and false positives gathered by means of the two proposed approaches: results obtained from measurements in different networks show that the technique is very effective in identifying Skype traffic. While both Bayesian classifier and packet inspection techniques are commonly used, the idea of leveraging on randomness to reveal traffic is novel. We adopt this to identify Skype traffic, but the same methodology can be applied to other classification problems as well. Copyright 2007 ACM.",Deep packet inspection; Nadie;ive Bayesian classification; Passive measurement; Pearson chi-square test; Traffic identification,Bayesian classification; Passive measurement; Skype protocols; Traffic identification; Algorithms; Computer software; Cryptography; Internet protocols; Packet networks; Telecommunication traffic
"Zheng C., Ji L., Pei D., Wang J., Francis P.",5,A light-weight distributed scheme for detecting ip prefix hijacks in real-time,2007,88,"AT and T Labs - Research, Florham Park, NJ, United States; Dept. of Computer Science, Cornell University, Ithaca, NY, United States",AT and T Labs;Cornell University,2,USA,1,36,26,"As more and more Internet IP prefix hijacking incidents are being reported, the value of hijacking detection services has become evident. Most of the current hijacking detection approaches monitor IP prefixes on the control plane and detect inconsistencies in route advertisements and route qualities. We propose a different approach that utilizes information collected mostly from the data plane. Our method is motivated by two key observations: when a prefix is not hijacked, 1) the hop count of the path from a source to this prefix is generally stable; and 2) the path from a source to this prefix is almost always a super-path of the path from the same source to a reference point along the previous path, as long as the reference point is topologically close to the prefix. By carefully selecting multiple vantage points and monitoring from these vantage points for any departure from these two observations, our method is able to detect prefix hijacking with high accuracy in a light-weight, distributed, and real-time fashion. Through simulations constructed based on real Internet measurement traces, we demonstrate that our scheme is accurate with both false positive and false negative ratios below 0.5%. Copyright 2007 ACM.",BGP; Detection; Hijacking; Interception; Routing,Hijacking detection services; Interception; Prefix hijacking; Data acquisition; Data transfer; Distributed computer systems; Real time systems; Routing protocols; Internet protocols
"Elmeleegy K., Cox A.L., Ng T.S.E.",3,Etherfuse: An ethernet watchdog,2007,6,"Department of Computer Science, Rice University, United States",Rice University,1,USA,1,22,13,"Ethernet is pervasive. This is due in part to its ease of use. Equipment can be added to an Ethernet network with little or no manual configuration. Furthermore, Ethernet is self-healing in the event of equipment failure or removal. However, there are scenarios where a local event can lead to network-wide packet loss and duplication due to slow or faulty reconfiguration of the spanning tree. Moreover, in some cases the packet loss and duplication may persist indefinitely. To address these problems, we introduce the EtherFuse, a new device that can be inserted into an existing Ethernet to speed the reconfiguration of the spanning tree and suppress packet duplication. EtherFuse is backward compatible and requires no change to the existing hardware, software, or protocols. We describe a prototype EtherFuse implementation and experimentally demonstrate its effectiveness. Specifically, we characterize how quickly it responds to network failures, its ability to reduce packet loss and duplication, and its benefits on the end-to-end performance of common applications. Copyright 2007 ACM.",Count to infinity; Ethernet; Forwarding loop; Network watchdog; Reliability,Forwarding loop; Network failures; Network watchdog; Spanning tree; Computer hardware; Computer software; Computer system recovery; Network protocols; Packet loss; Problem solving; Ethernet
"Xie Y., Yu F., Achan K., Gillum E., Goldszmidt M., Wobber T.",6,How dynamic are IP addresses?,2007,91,"Microsoft Research, Silicon Valley, United States; Microsoft Research",Microsoft,1,USA,1,32,22,"This paper introduces a novel algorithm, UDmap, to identify dynamically assigned IP addresses and analyze their dynamics pattern. UDmap is fully automatic, and relies only on application-level server logs. We applied UDmap to a month-long Hotmail user-login trace and identified a significant number of dynamic IP addresses - more than 102 million. This suggests that the fraction of IP addresses that are dynamic is by no means negligible. Using this information in combination with a three-month Hotmail email server log, we were able to establish that 95.6% of mail servers setup on the dynamic IP addresses in our trace sent out solely spam emails. Moreover, these mail servers sent out a large amount of spam - amounting to 42.2% of all spam emails received by Hotmail. These results highlight the importance of being able to accurately identify dynamic IP addresses for spam filtering. We expect similar benefits to arise for phishing site identification and botnet detection. To our knowledge, this is the first successful attempt to automatically identify and understand IP address dynamics. Copyright 2007 ACM.",DHCP; Dynamic IP addresses; Entropy; IP volatility; Spam detection,Site identification; Spam detection; Data transfer; Intrusion detection; Servers; Spamming; User interfaces; Internet protocols
"Balasubramanian A., Levine B., Venkataramani A.",3,DTN routing as a resource allocation problem,2007,552,"Dept. of Computer Science, University of Massachusetts Amherst, Amherst, MA, United States",University of Massachusetts Amherst,1,USA,1,37,31,"Many DTN routing protocols use a variety of mechanisms, including discovering the meeting probabilities among nodes, packet replication, and network coding. The primary focus of these mechanisms is to increase the likelihood of finding a path with limited information, so these approaches have only an incidental effect on such routing metrics as maximum or average delivery latency. In this paper, we present RAPID, an intentional DTN routing protocol that can optimize a specific routing metric such as worst-case delivery latency or the fraction of packets that are delivered within a deadline. The key insight is to treat DTN routing as a resource allocation problem that translates the routing metric into per-packet utilities which determine how packets should be replicated in the system. We evaluate RAPID rigorously through a prototype of RAPID deployed over a vehicular DTN testbed of 40 buses and simulations based on real traces. To our knowledge, this is the first paper to report on a routing protocol deployed on a real DTN at this scale. Our results suggest that RAPID significantly outperforms existing routing protocols for several metrics. We also show empirically that for small loads RAPID is within 10% of the optimal performance. Copyright 2007 ACM.",Deployment; DTN; Mobility; Routing; Utility,Computer simulation; Encoding (symbols); Optimization; Packet networks; Problem solving; Resource allocation; Network coding; Packet replication; Routing metrics; Routing protocols
"Bahl P., Chandra R., Greenberg A., Kandula S., Maltz D.A., Zhang M.",6,Towards highly reliable enterprise network services via inference of multi-level dependencies,2007,178,Microsoft Research,Microsoft,1,USA,1,21,14,"Localizing the sources of performance problems in large enterprise networks is extremely challenging. Dependencies are numerous, complex and inherently multi-level, spanning hardware and software components across the network and the computing infrastructure. To exploit these dependencies for fast, accurate problem localization, we introduce an Inference Graph model, which is well-adapted to user-perceptible problems rooted in conditions giving rise to both partial service degradation and hard faults. Further, we introduce the Sherlock system to discover Inference Graphs in the operational enterprise, infer critical attributes, and then leverage the result to automatically detect and localize problems. To illuminate strengths and limitations of the approach, we provide results from a prototype deployment in a large enterprise network, as well as from testbed emulations and simulations. In particular, we find that taking into account multi-level structure leads to a 30% improvement in fault localization, as compared to two-level approaches. Copyright 2007 ACM.",Dependencies; Fault localization; Network and service management; Probabilistic inference,Computation theory; Computer hardware; Computer software; Graph theory; Industrial economics; Problem solving; Fault localization; Inference Graph model; Probabilistic inference; Sherlock system; Computer networks
"Kaafar M.A., Mathy L., Barakat C., Salamatian K., Turletti T., Dabbous W.",6,Securing internet coordinate embedding systems,2007,39,"INRIA Sophia Antipolis, France; Lancaster University, United Kingdom; LIP6, France; EPFL, Switzerland","EPFL, Switzerland;INRIA;Lancaster University",3,France;Switzerland;UK,3,23,14,"This paper addresses the issue of the security of Internet Coordinate Systems,by proposing a general method for malicious behavior detection during coordinate computations. We first show that the dynamics of a node, in a coordinate system without abnormal or malicious behavior, can be modeled by a Linear State Space model and tracked by a Kalman filter. Then we show, that the obtained model can be generalized in the sense that the parameters of a filtercalibrated at a node can be used effectively to model and predict the dynamic behavior at another node, as long as the two nodes are not too far apart in the network. This leads to the proposal of a Surveyor infrastructure: Surveyor nodes are trusted, honest nodes that use each other exclusively to position themselves in the coordinate space, and are therefore immune to malicious behavior in the system.During their own coordinate embedding, other nodes can thenuse the filter parameters of a nearby Surveyor as a representation of normal, clean system behavior to detect and filter out abnormal or malicious activity. A combination of simulations and PlanetLab experiments are used to demonstrate the validity, generality, and effectiveness of the proposed approach for two representative coordinate embedding systems, namely Vivaldi and NPS. Copyright 2007 ACM.",Internet Coordinates-embedding systems; Kalman filter; Malicious behavior detection; Network positioning systems; Security,Computation theory; Computer simulation; Embedded systems; Kalman filters; Web services; Malicious behavior; Network positioning systems; PlanetLab experiments; Security of data
"Katti S., Gollakota S., Katabi D.",3,Embracing wireless interference: analog network coding,2007,794,"MIT CSAIL, United States",MIT,1,USA,1,35,27,"Traditionally, interference is considered harmful. Wireless networks strive to avoid scheduling multiple transmissions at the same time in order to prevent interference. This paper adopts the opposite approach; it encourages strategically picked senders to interfere. Instead of forwarding packets, routers forward the interfering signals. The destination leverages network-level information to cancel the interference and recover the signal destined to it. The result is analog network coding because it mixes signals not bits. So, what if wireless routers forward signals instead of packets? Theoretically, such an approach doubles the capacity of the canonical 2-way relay network. Surprisingly, it is also practical. We implement our design using software radios and show that it achieves significantly higher throughput than both traditional wireless routing and prior work on wireless network coding. Copyright 2007 ACM.",Cooperative transmission; Network coding; Wireless networks,Cooperative transmission; Network coding; Relay networks; Wireless interference; Data transfer; Encoding (symbols); Radio interference; Routers; Routing protocols; Wireless telecommunication systems; Wireless networks
"Douceur J.R., Moscibroda T.",2,Lottery trees: Motivational deployment of networked systems,2007,25,"Microsoft Research, Redmond, WA 98052, United States",Microsoft,1,USA,1,36,28,"We address a critical deployment issue for network systems, namely motivating people to install and run a distributed service. This work is aimed primarily at peer-to-peer systems, in which the decision and effort to install a service falls to individuals rather than to a central planner. This problem is relevant for bootstrapping systems that rely on the network effect, wherein the benefits are not felt until deployment reaches a significant scale, and also for deploying asymmetric systems, wherein the set of contributors is different than the set of beneficiaries. Our solution is the lottery tree (lottree), a mechanism that probabilistically encourages both participation in the system and also solicitation of new participants. We define the lottree mechanism and normally state seven properties that encourage contribution, solicitation, and fair play. We then present the Pachira lottree scheme, which satisfies five of these seven properties, and we prove this to be a maximal satisfiable subset. Using simulation, we determine optimal parameters for the Pachira lottree scheme, and we determine how to configure a lottree system for achieving various deployment scales based on expected installation effort. We also present extensive sensitivity analyses, which bolster the generality of our conclusions. Copyright 2007 ACM.",bootstrapping; Deployment; Desiderata; Impossibility results; Incentive systems; Lotteries; Networked systems; Prospect theory,Bootstrapping systems; Incentive systems; Networked systems; Prospect theory; Decision making; Parameter estimation; Problem solving; Set theory; Trees (mathematics); Web services; Distributed computer systems
"Chachulski S., Jennings M., Katti S., Katabi D.",4,Trading structure for randomness in wireless opportunistic routing,2007,764,"MIT CSAIL, United States",MIT,1,USA,1,36,33,"Opportunistic routing is a recent technique that achieves high throughput in the face of lossy wireless links. The current opportunistic routing protocol, ExOR, ties the MAC with routing, imposing a strict schedule on routers' access to the medium. Although the scheduler delivers opportunistic gains, it misses some of the inherent features of the 802.11 MAC. For example, it prevents spatial reuse and thus may underutilize the wireless medium. It also eliminates the layering abstraction, making the protocol less amenable to extensions to alternate traffic types such as multicast. This paper presents MORE, a MAC-independent opportunistic routing protocol. MORE randomly mixes packets before forwarding them. This randomness ensures that routers that hear the same transmission do not forward the same packets. Thus, MORE needs no special scheduler to coordinate routers and can run directly on top of 802.11. Experimental results from a 20-node wireless testbed show that MORE's median unicast throughput is 22% higher than ExOR, and the gains rise to 45% over ExOR when there is a chance of spatial reuse. For multicast, MORE's gains increase with the number of destinations, and are 35-200% greater than ExOR. Copyright 2007 ACM.",Network coding; Wireless networks,Network coding; Opportunistic routing; Wireless links; Access control; Feature extraction; Packet networks; Routing protocols; Telecommunication links; Telecommunication traffic; Wireless networks
"Lakshminarayanan K., Caesar M., Rangan M., Anderson T., Shenker S., Stoica I.",6,Achieving convergence-free routing using failure-carrying packets,2007,77,"University of California, Berkeley, United States; University of Washington, United States",University of California Berkeley;University of Washington at Seattle,2,USA,1,35,30,"Current distributed routing paradigms (such as link-state, distance-vector, and path-vector) involve a convergence process consisting of an iterative exploration of intermediate routes triggered by certain events such as link failures. The convergence process increases router load, introduces outages and transient loops, and slows reaction to failures. We propose a new routing paradigm where the goal is not to reduce the convergence times but rather to eliminate the convergence process completely. To this end, we propose a technique called Failure-Carrying Packets (FCP) that allows data packets to autonomously discover a working path without requiring completely up-to-date state in routers. Our simulations, performed using real-world failure traces and Rocketfuel topologies, show that: (a) the overhead of FCP is very low, (b) unlike traditional link-state routing (such as OSPF), FCP can provide both low loss-rate as well as low control overhead, (c) compared to prior work in backup path pre-computations, FCP provides better routing guarantees under failures despite maintaining lesser state at the routers. Copyright 2007 ACM.",Convergence; Internet routing; Protocols,Failure-Carrying Packets (FCP); Internet routing; Link failures; Computer simulation; Computer system recovery; Convergence of numerical methods; Packet networks; Routers; Telecommunication links; Network routing
"Ballani H., Francis P., Zhang X.",3,A study of prefix hijacking and interception in the internet,2007,92,"Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,53,44,"There have been many incidents of prefix hijacking in the Internet. The hijacking AS can blackhole the hijacked traffic. Alternatively, it can transparently intercept the hijacked traffic by forwarding it onto the owner. This paper presents a study of such prefix hijacking and interception with the following contributions: (1). We present a methodology for prefix interception, (2). We estimate the fraction of traffic to any prefix that can be hijacked and intercepted in the Internet today, (3). The interception methodology is implemented and used to intercept real traffic to our prefix, (4). We conduct a detailed study to detect ongoing prefix interception. We find that: Our hijacking estimates are in line with the impact of past hijacking incidents and show that ASes higher up in the routing hierarchy can hijack a significant amount of traffic to any prefix, including popular prefixes. A less apparent result is that the same holds for prefix interception too. Further, our implementation shows that intercepting traffic to a prefix in the Internet is almost as simple as hijacking it. Finally, while we fail to detect ongoing prefix interception, the detection exercise highlights some of the challenges posed by the prefix interception problem. Copyright 2007 ACM.",BGP; Hijacking; Interception; Routing,Internet Hijacking; Prefix hijacking; Real traffic; Real time systems; Routing protocols; Telecommunication traffic; Web services; Security of data
"Guha S., Francis P.",2,An end-middle-end approach to connection establishment,2007,39,"Cornell University, Ithaca, United States",Cornell University,1,USA,1,64,48,"The current model for flow establishment in the Internet: DNS Names, IP addresses, and transport ports, is inadequate. Not all of the problem is due to the small IPv4 address space and resulting NAT boxes. Even where global addresses exist, firewalls cannot glean enough information about a flow from packet headers, and so often err, typically by being over-conservative: disallowing flows that might otherwise be allowed. This paper presents a novel architecture, protocol design, and implementation, for flow establishment in the Internet. The architecture, called NUTSS, takes into account the combined policies of endpoints and network providers. While NUTSS borrows liberally from other proposals (URI-like naming, signaling to manage ephemeral IPv4 or IPv6 data flows), NUTSS is unique in that it couples overlay signaling with data-path signaling. NUTSS requires no changes to existing protocol stacks, and combined with recent NAT traversal techniques, works with IPv4 and existing NAT/firewalls. This paper describes NUTSS and shows how it satisfies a wide range of ""end-middle-end""network requirements, including access control, middlebox steering, multi-homing, mobility, and protocol negotiation. Copyright 2007 ACM.",End-middle-end; NUTSS; Off-path; On-path; Signaling,End-middle-end approach; Packet headers; Protocol design; Computer system firewalls; Distributed computer systems; Internet protocols; Network architecture; Packet networks; Problem solving; Web services
"Ee C.T., Ramachandran V., Chun B.-G., Lakshminarayanan K., Shenker S.",5,Resolving inter-domain policy disputes,2007,19,"Department of Computer Science, University of California, Berkeley, Berkeley, CA 94720, United States; Department of Computer Science, Colgate University, Hamilton, NY 13346, United States; Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai 600036, India; International Computer Science Institute (ICSI), University of California, Berkeley, Berkeley, CA 94704, United States",Colgate University;IIT Madras;University of California Berkeley,3,India;USA,2,17,12,"The Border Gateway Protocol (BGP) allows each autonomous system (AS) to select routes to destinations based on semantically rich and locally determined policies. This autonomously exercised policy freedom can cause instability, where unresolvable policy-based disputes in the network result in interdomain route oscillations. Several recent works have established that such instabilities can only be eliminated by enforcing a globally accepted preference ordering on routes (such as shortest path). To resolve this conflict between policy autonomy and system stability, we propose a distributed mechanism that enforces a preference ordering only when disputes resulting in oscillations exist. This preserves policy freedom when possible, and imposes stability when required. Copyright 2007 ACM.",BGP; Convergence; Inter-domain routing; Policy disputes,Autonomous system (AS); Border Gateway Protocol (BGP); Inter-domain routing; Autonomous agents; Convergence of numerical methods; Network routing; Semantic Web; Gateways (computer networks)
"Raghavan B., Vishwanath K., Ramabhadran S., Yocum K., Snoeren A.C.",5,Cloud control with distributed rate limiting,2007,100,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,41,23,"Today's cloud-based services integrate globally distributed resources into seamless computing platforms. Provisioning and accounting for the resource usage of these Internet-scale applications presents a challenging technical problem. This paper presents the design and implementation of distributed rate limiters, which work together to enforce a global rate limit across traffic aggregates at multiple sites, enabling the coordinated policing of a cloud-based service's network traffic. Our abstraction not only enforces a global limit, but also ensures that congestion-responsive transport-layer flows behave as if they traversed a single, shared limiter. We present two designs - one general purpose, and one optimized for TCP - that allow service operators to explicitly trade off between communication costs and system accuracy, efficiency, and scalability. Both designs are capable of rate limiting thousands of flows with negligible overhead (less than 3% in the tested configuration). We demonstrate that our TCP-centric design is scalable to hundreds of nodes while robust to both loss and communication delay, making it practical for deployment in nationwide service providers. Copyright 2007 ACM.",CDN; Rate limiting; Token bucket,Communication delay; Computing platforms; Distributed rate limiting; Token bucket; Congestion control (communication); Data transfer; Internet; Transmission control protocol; Information services
"Mahadevan P., Hubble C., Krioukov D., Huffaker B., Vahdat A.",5,Orbis: Rescaling degree correlations to generate annotated internet topologies,2007,43,"UC San Diego, United States; CAIDA, United States",University of California San Diego,1,USA,1,34,22,"Researchers involved in designing network services and protocols rely on results from simulation and emulation environments to understand their application performance and scalability. To better understand the behavior of these applications and predict their performance when deployed on the actual Internet, the generated topologies must closely match real network characteristics, not just in terms of graph structure (node interconnectivity) but also with respect to various node and link annotations. Relevant annotations include link latencies, AS membership and whether a router is a peering or internal router. Finally, it should be possible to rescale a given topology to a variety of sizes while still maintaining its essential characteristics. In this paper, we propose techniques to generate annotated, Internet router graphs of different sizes based on existing observations of Internet characteristics. We find that our generated graphs match a variety of graph properties of observed topologies for a range of target graph sizes. While the best available data of Internet topology currently remains imperfect, the quality of our generated topologies will improve with the fidelity of available measurement techniques or next generation architectures that make Internet structure more transparent. Copyright 2007 ACM.",Degree correlations; Network topology,Degree correlations; Graph properties; Internet topology; Network services; Correlation methods; Graph theory; Information services; Network management; Internet
"Ballani H., Francis P.",2,CONMan: A step towards network manageability,2007,58,"Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,51,33,"Networks are hard to manage and in spite of all the so called holistic management packages, things are getting worse. We argue that the difficulty of network management can partly be attributed to a fundamental flaw in the existing architecture: protocols expose all their internal details and hence, the complexity of the ever-evolving data plane encumbers the management plane. Guided by this observation, in this paper we explore an alternative approach and propose Complexity Oblivious Network Management (CONMan), a network architecture in which the management interface of data-plane protocols includes minimal protocol-specific information. This restricts the operational complexity of protocols to their implementation and allows the management plane to achieve high level policies in a structured fashion. We built the CONMan interface of a few protocols and a management tool that can achieve high-level configuration goals based on this interface. Our preliminary experience with applying this tool to real world VPN configuration indicates the architecture's potential to alleviate the difficulty of configuration management.Copyright 2007 ACM.",Abstraction; Configuration; Management,Complexity Oblivious Network Management (CONMan); Management tools; Operational complexity; Computational complexity; Computer aided software engineering; Data processing; Internet protocols; Network architecture; Real time systems; Network management
"Turner J.S., Crowley P., Dehart J., Freestone A., Heller B., Kuhns F., Kumar S., Lockwood J., Lu J., Wilson M., Wiseman C., Zar D.",12,"Supercharging planetlab: A high performance, multi-application, overlay network platform",2007,92,"Washington University, United States",University of Washington at Seattle,1,USA,1,23,10,"In recent years, overlay networks have become an important vehicle for delivering Internet applications. Overlay network nodes are typically implemented using general purpose servers or clusters. We investigate the performance benefits of more integrated architectures, combining general-purpose servers with high performance Network Processor (NP) subsystems. We focus on PlanetLab as our experimental context and report on the design and evaluation of an experimental PlanetLab platform capable of much higher levels of performance than typical system configurations. To make it easier for users to port applications, the system supports a fast path/slow path application structure that facilitates the mapping of the most performance-critical parts of an application onto an NP subsystem, while allowing the more complex control and exception-handling to be implemented within the programmer-friendly environment provided by conventional servers. We report on implementations of two sample applications, an IPv4 router, and a forwarding application for the Internet Indirection Infrastructure. We demonstrate an 80x improvement in packet processing rates and comparable reductions in latency. Copyright 2007 ACM.",Global Environment for Network Innovation (GENI); Network processors; Overlay networks; PlanetLab,Global Environment for Network Innovation (GENI); Integrated architectures; Network Processor (NP); Overlay networks; PlanetLab; Cluster analysis; Control systems; Internet protocols; Program processors; Servers; Web services; Computer applications
"Karsten M., Keshav S., Prasad S., Beg M.",4,An axiomatic basis for communication,2007,17,"David R. Cheriton School of Computer Science, University of Waterloo, Canada; Department of Computer Science and Engineering, IIT Delhi, India",University of Waterloo,1,Canada;India,2,25,14,"The de facto service architecture of today's communication networks, in particular the Internet, is heterogeneous, complex, ad hoc, and not particularly well understood. With layering as the only means for functional abstraction, and even this violated by middle-boxes, the diversity of current technologies can barely be expressed, let alone analyzed. As a first step to remedying this problem, we present an axiomatic formulation of fundamental forwarding mechanisms in communication networks. This formulation allows us to express precisely and abstractly the concepts of naming and addressing and to specify a consistent set of control patterns and operational primitives, from which a variety of communication services can be composed. Importantly, this framework can be used to (1) formally analyze network protocols based on structural properties, and also to (2) derive working prototype implementations of these protocols. The prototype is implemented as a universal forwarding engine, a general framework and runtime environment based on the Click router. Copyright 2007 ACM.",Addressing; Concepts; Definitions; Naming; Protocols; Routing,Axiomatic formulation; Communication services; Runtime environment; Ad hoc networks; Computational complexity; Internet protocols; Network routing; Problem solving; Software prototyping; Web services; Telecommunication networks
"Yuan L., Chuah C.-N., Mohapatra P.",3,ProgME: towards programmable network measurement,2007,43,"University of California, Davis, United States",University of California Davis,1,USA,1,38,26,"Traffic measurements provide critical input for a wide range of network management applications, including traffic engineering, accounting, and security analysis. Existing measurement tools collect traffic statistics based on some pre-determined, inflexible concept of ""flows"". They do not have sufficient built-in intelligence to understand the application requirements or adapt to the traffic conditions. Consequently, they have limited scalability with respect to the number of flows and the heterogeneity of monitoring applications. We present ProgME, a Programmable MEasurement architecture based on a novel concept of flowset - arbitrary set of flows defined according to application requirements and/or traffic conditions. Through a simple flowset composition language, ProgME can incorporate application requirements, adapt itself to circumvent the challenges on scalability posed by the large number of flows, and achieve a better application-perceived accuracy. ProgME can analyze and adapt to traffic statistics in real-time. Using sequential hypothesis test, ProgME can achieve fast and scalable heavy hitter identification. Copyright 2007 ACM.",Flowset; Flowset composition language; Multi-resolution tiling; Programmable measurement; Traffic measurement,Flowset composition language; Programmable measurement; Traffic engineering; Traffic measurement; Computer aided software engineering; Computer programming languages; Intelligent systems; Real time systems; Telecommunication traffic; Computer networks
"Oliveira R.V., Zhang B., Zhang L.",3,Observing the evolution of internet as topology,2007,92,"University of California, Los Angeles, CA, United States; University of Arizona, Tucson, AZ, United States",University of Arizona;University of California Los Angeles,2,USA,1,34,25,"Characterizing the evolution of Internet topology is important to our understanding of the Internet architecture and its interplay with technical, economic and social forces. A major challenge in obtaining empirical data on topology evolution is to identify real topology changes from the observed topology changes, since the latter can be due to either topology changes or transient routing dynamics. In this paper, we formulate the topology liveness problem and propose a solution based on the analysis of BGP data. We find that the impact of transient routing dynamics on topology observation decreases exponentially over time, and that the real topology dynamics consist of a constant-rate birth process and a constant-rate death process. Our model enables us to infer real topology changes from observation data with a given confidence level. We demonstrate the usefulness of the model by applying it to three applications: providing more accurate views of the topology, evaluating theoretical evolution models, and empirically characterizing the trends of topology evolution. We find that customer networks and provider networks have distinct evolution trends, which can provide an important input to the design of future Internet routing architecture. Copyright 2007 ACM.",Internet topology; Topology evolution,Internet routing architecture; Routing dynamics; Topology evolution; Data acquisition; Mathematical models; Routing protocols; Topology; User interfaces; Internet protocols
"Mislove A., Marcon M., Gummadi K.P., Druschel P., Bhattacharjee B.",5,Measurement and analysis of online social networks,2007,1616,"MPI for Software Systems, Campus E1 4, SaarbrŸcken 66123, Germany; Computer Science Department, University of Maryland, College Park, MD 20742, United States",University of Maryland College Park,1,Germany;USA,2,55,38,"Online social networking sites like Orkut, YouTube, and Flickr are among the most popular sites on the Internet. Users of these sites form a social network, which provides a powerful means of sharing, organizing, and finding content and contacts. The popularity of these sites provides an opportunity to study the characteristics of online social network graphs at large scale. Understanding these graphs is important, both to improve current systems and to design new applications of online social networks. This paper presents a large-scale measurement study and analysis of the structure of multiple online social networks. We examine data gathered from four popular online social networks: Flickr, YouTube, LiveJournal, and Orkut. We crawled the publicly accessible user links on each site, obtaining a large portion of each social network's graph. Our data, set contains over 11.3 million users and 328 million links. We believe that this is the first study to examine multiple online social networks at scale. Our results confirm the power-law, small-world, and scale-free properties of online social networks. We observe that the indegree of user nodes tends to match the outdegree; that the networks contain a densely connected core of high-degree nodes; and that this core links small groups of strongly clustered, low-degree nodes at the fringes of the network. Finally, we discuss the implications of these structural properties for the design of social network based systems. Copyright 2007 ACM.",Analysis; Measurement; Social networks,(PL) properties; Current systems; Degree nodes; High-degree nodes; internet measurements; Large scale measurement; Large scales; Measurement and analysis; new applications; Outdegree; Power laws; Scale free properties; small groups; Small worlds; Social networking; Social networks; User nodes; YouTube; Graph theory; Internet; Measurements; Semiconducting intermetallics; Structural properties; Telecommunication networks; Online systems
"Zhang Y., Zhang Z., Mao Z.M., Hu Y.C., Maggs B.M.",5,On the impact of route monitor selection,2007,25,Univ. of Michigan; Purdue Univ.; Carnegie Mellon and Akamai Tech.,Carnegie Mellon University;Purdue University;University of Michigan at Ann Arbor,3,USA,1,23,20,"Several route monitoring systems have been set up to help understand the Internet routing system. They operate by gathering realtime BGP updates from different networks. Many studies have relied on such data sources by assuming reasonably good coverage and thus representative visibility into the Internet routing system. However, different deployment strategies of route monitors directly impact the accuracy and generality of conclusions. Our work is the first to critically examine the visibility constraints imposed by the deployment of route monitors on various applications. We study the difference due to diverse deployment schemes on three important classes of applications: (1) discovery of relatively stable Internet properties such as the AS topology and prefix to origin AS mappings, (2) discovery of dynamic routing behavior such as IP prefix hijack attacks and routing instability, and (3) inference of important network properties such as AS relationships and AS-level paths. We study several simple schemes of route monitor selection and provide insights on improving monitor placement. Copyright 2007 ACM.",BGP; Internet measurement,(PL) properties; (SPM) classes; Data sourcing; dynamic routing; internet measurements; Internet routing; Monitor (CO); Network properties; Real time; Route monitoring; Routing instability; Internet; Monitoring; Optical properties; Semiconducting intermetallics; Terminology; Visibility; Internet protocols
"Allman M., Paxson V., Terrell J.",3,A brief history of scanning,2007,63,"ICSI, Berkeley, CA, United States; ICSI and LBNL, Berkeley, CA, United States; UNC-Chapel Hill, Chapel Hill, NC, United States",University of North Carolina at Chapel Hill;University of California Berkeley,2,USA,1,12,10,"Incessant scanning of hosts by attackers looking for vulnerable servers has become a fact of Internet life. In this paper we present an initial study of the scanning activity observed at one site over the past 12.5 years. We study the onset of scanning in the late 1990s and its evolution in terms of characteristics such as the number of scanners, targets and probing patterns. While our study is preliminary in many ways, it provides the first longitudinal examination of a now ubiquitous Internet phenomenon. Copyright 2007 ACM.",Longitudinal; Malicious activity; Scanning,Internet; Semiconducting intermetallics; Ubiquitous computing; Evolution (CO); internet measurements; Scanning
"Soule A., Ringberg H., Silveira F., Diot C.",4,Challenging the supremacy of traffic matrices in anomaly detection,2007,7,Thomson; Princeton University,Princeton University,1,USA,1,12,9,"Multiple network-wide anomaly detection techniques proposed in the literature define an anomaly as a statistical outlier in aggregated network traffic. The most popular way to aggregate the traffic is as a Traffic Matrix, where the traffic is divided according to its ingress and egress points in the network. However, the reasons for choosing traffic matrices instead of any other formalism have not been studied yet. In this paper we compare three network-driven traffic aggregation formalisms: ingress routers, input links and origin-destination pairs (i.e. traffic matrices). Each formalism is computed on data collected from two research back-bones. Then, a network-wide anomaly detection method is applied to each formalism. All anomalies are manually labeled, as a true or false positive. Our results show that the traffic aggregation level has a significant impact on the number of anomalies detected and on the false positive rate. We show that aggregating by OD pairs is indeed the most appropriate choice for the data sets and the detection method we consider. We correlate our observations with time series statistics in order to explain how aggregation impacts anomaly detection. Copyright 2007 ACM.",Anomaly detection; Traffic aggregation,Administrative data processing; Financial data processing; Internet; Semiconducting intermetallics; Signal detection; Statistical methods; Statistics; Telecommunication traffic; Time series analysis; Turbulent flow; Anomaly detections; Applied (CO); Data collected; Data sets; Detection methods; False positive (FP); False positive rate (FPR); In order; ingress routers; internet measurements; Network traffics; O-D pairs; Origin-destination (O-D) pairs; Time-series statistics; Traffic aggregation; Traffic matrices; Matrix algebra
"Erramilli V., Chaintreau A., Crovella M., Diot C.",4,Diversity of forwarding paths in pocket switched networks,2007,95,"Dept. of Computer Science, Boston University, Boston, United States; Thomson Paris, Paris, France",Boston University,1,France;USA,2,20,16,"Forwarding in Delay Tolerant Networks(DTNs) is a challenging problem. We focus on the specific issue of forwarding in an environment where mobile devices are carried by people in a restricted physical space (a conference) and contact patterns are not predictable. We show for the first time a path explosion phenomenon between most pairs of nodes. This means that, once the first path reaches the destination, the number of subsequent paths grows rapidly with time, so there usually exist many near-optimal paths. We study the path explosion phenomenon both analytically and empirically. Our results highlight the importance of unequal contact rates across nodes for understanding the performance of forwarding algorithms. We also find that a variety of well-known forwarding algorithms show surprisingly similar performance in our setting and we interpret this fact in light of the path explosion phenomenon. Copyright 2007 ACM.",DTN; Forwarding; Path diversity; Pocket switched networks,Internet; Mobile devices; Semiconducting intermetallics; Switching circuits; Telecommunication equipment; Challenging problem; contact patterns; Delay Tolerant Networks; Forwarding algorithms; internet measurements; Optimal paths; Physical space; Switched networks; Explosions
"Augustin B., Friedman T., Teixeira R.",3,Measuring load-balanced paths in the internet,2007,61,"Laboratoire d'Informatique de Paris 6 (LIP6), UniversitŽ Pierre et Marie Curie, CNRS",University Pierre and Marie Curie,1,France,1,29,19,"Tools to measure internet properties usually assume the existence of just one single path from a source to a destination. However, load-balancing capabilities, which create multiple active paths between two end-hosts, are available in most contemporary routers. This paper proposes a methodology to identify load-balancing routers and characterize load-balanced paths. We enhance our traceroute-like tool, called Paris traceroute, to find all paths between a pair of hosts, and use it from 15 sources to over 68 thousand destinations. Our results show that the traditional concept of a single network path between hosts no longer holds. For instance, 39% of the source-destination pairs in our traces traverse a load balancer. Furthermore, this fraction increases to 70% if we consider the paths between a source and a destination network. Copyright 2007 ACM.",Load balancing; Multipath; Path diversity; Traceroute,(PL) properties; Destination network; internet measurements; load balancers; Load Balancing; Load-balanced; network paths; Single path; Source destination (SD) pairs; trace route; Balancing; Internet; Mobile telecommunication systems; Semiconducting intermetallics; Loads (forces)
"Sommers J., Barford P.",2,An active measurement system for shared environments,2007,22,Colgate University; University of Wisconsin-Madison,Colgate University;;University of Wisconsin-Madison,3,USA,1,45,29,"Testbeds composed of end hosts deployed across the Internet enable researchers to simultaneously conduct a wide variety of experiments. Active measurement studies of Internet path properties that require precisely crafted probe streams can be problematic in these environments. The reason is that load on the host systems from concurrently executing experiments (as is typical in PlanetLab) can significantly alter probe stream timings. In this paper we measure and characterize how packet streams from our local PlanetLab nodes are affected by experimental concurrency. We find that the effects can be extreme. We then set up a simple PlanetLab deployment in a laboratory testbed to evaluate these effects in a controlled fashion. We find that even relatively low load levels can cause serious problems in probe streams. Based on these results, we develop a novel system called MAD that can operate as a Linux kernel module or as a stand-alone daemon to support real-time scheduling of probe streams. MAD coordinates probe packet emission for all active measurement experiments on a node. We demonstrate the capabilities of MAD, showing that it performs effectively even under very high levels of multiplexing and host system load. Copyright 2007 ACM.",Active measurement; MAD,Active measurements; Host system; internet measurements; Internet paths; linux kernel; Low load; packet streams; Planetlab nodes; Real time scheduling; Test beds; Test-beds; Experiments; Internet; Loads (forces); Mobile telecommunication systems; Photoacoustic effect; Rivers; Semiconducting intermetallics; Telecommunication; Measurements
"Shrivastava V., Agrawal D., Mishra A., Banerjee S., Nadeem T.",5,Understanding the limitations of transmit power control for indoor WLANs,2007,38,"University of Wisconsin, Madison, United States; Siemens Research, Princeton, NJ, United States",Siemens Research;University of Wisconsin-Madison,2,USA,1,22,6,"A wide range of transmit power control (TPC) algorithms have been proposed in recent literature to reduce interference and increase capacity in 802.11 wireless networks. However, few of them have made it to practice. In many cases this gap is attributed to lack of suitable hardware support in wireless cards to implement these algorithms. In particular, many research efforts have indicated that wireless card vendors need to support power control mechanisms in a finegrained manner - both in the number of possible power levels and the time granularity at which the controls can be applied. In this paper we claim that even if fine-grained power control mechanisms were to be made available by wireless card vendors, algorithms would not be able to properly leverage such degrees of control in typical indoor environments. We prove this claim through rigorous empirical analysis and then build a tunable empirical model (Model-TPC) that can determine the granularity of power control that is actually useful. To illustrate the importance of our solution, we conclude by demonstrating the impact of choice of power control granularity on Internet applications where wireless clients interact with servers on the Internet. We observe that the number of feasible power was found to be between 2-4 for most indoor environments. We believe that the results from this study can serve as the right set of assumptions to build practically realizable TPC algorithms in the future. Copyright 2007 ACM.",EEE 802.11; Fine-grained; Indoor WLAN; Kullback-leibler; Limitations; RSSI modeling; Transmit power control,Beamforming; Communication channels (information theory); Information services; Internet; Local area networks; Mechanisms; Modal analysis; Power control; Semiconducting intermetallics; Telecommunication systems; Wireless local area networks (WLAN); (Semi-)empirical models; 802.11 wireless networks; Applied (CO); control mechanisms; Empirical analyses; Fine grained power; Hardware supports; Indoor environments; internet applications; internet measurements; power leveling; Research efforts; Transmit power control (TPC); Wide-range; Wireless cards; wireless clients; Concurrency control
"John W., Tafvelln S.",2,Analysis of internet backbone traffic and header anomalies observed,2007,85,Chalmers University of Technology,Chalmers University of Technology,1,USA,1,15,13,"The dominating Internet protocols, IP and TCP, allow some flexibility in implementation, including a variety of optional features. To support research and further development of these protocols, it is crucial to know about current deployment of protocol specific features and accompanying anomalies. This work is intended to reflect the current characteristics of Internet backbone traffic and point out misbehaviors and potential problems. On 20 consecutive days in April 2006 bidirectional traffic was collected on an OC-192 back-bone link. The analysis of the data provides a comprehensive summary about current protocol usage including comparisons to prior studies. Furthermore, header misbehaviors and anomalies were found within almost every aspect analyzed and are discussed in detail. These observations are important information for designers of network protocols, network application and network attack detection systems. 1 Copyright 2007 ACM.",Header anomalies; Internet measurement; Traffic analysis,Consecutive days; current characteristics; Internet backbone; internet measurements; Network applications; network attacks; p otential problems; protocol usage; specific features; Administrative data processing; Cold heading; Computer crime; Financial data processing; Internet; Network protocols; Semiconducting intermetallics; Sensors; Internet protocols
"Zhao H., Spatscheck O., Lall A., Wang J., Ogihara M., Xu J.",6,A data streaming algorithm for estimating entropies of OD flows,2007,27,Georgia Inst. of Technology; AT and T Labs - Research; University of Rochester,AT and T Labs;University of Rochester,2,USA,1,29,24,"Entropy has recently gained considerable significance as an important metric for network measurement. Previous research has shown its utility in clustering traffic and detecting traffic anomalies. While measuring the entropy of the traffic observed at a single point has already been studied, an interesting open problem is to measure the entropy of the traffic between every origin-destination pair. In this paper, we propose the first solution to this challenging problem. Our sketch builds upon and extends the Lp sketch of Indyk with significant additional innovations. We present calculations showing that our data streaming algorithm is feasible for high link speeds using commodity CPU/memory at a reasonable cost. Our algorithm is shown to be very accurate in practice via simulations, using traffic traces collected at a tier-1 ISP backbone link. Copyright 2007 ACM.",Data streaming; Entropy estimation; Network measurement; Stable distributions; Traffic matrix,Challenging problem; Datastream (CO); internet measurements; Network measurements; O D flows; open problems; Origin-destination (OD); Single point; Traffic anomalies; Administrative data processing; Data reduction; Financial data processing; Internet; Semiconducting intermetallics; Entropy
"Allman M., Paxson V.",2,Issues and etiquette concerning use of shared measurement data,2007,38,"ICSI, Berkeley, CA, United States; ICSI and LBNL, Berkeley, CA, United States",University of California Berkeley,1,USA,1,18,13,"In this note we discuss issues surrounding how to provide and use network measurement data made available for sharing among researchers. While previous work has focused on the technical details of enabling sharing via traffic anonymization, we focus on higher-level aspects of the process such as potential harm to the provider (e.g., by de-anonymizing a shared dataset) or interactions to strengthen subsequent research (e.g., helping to establish ground truth). We believe the community would benefi t from a dialog regarding expectations and responsibilities of data providers, and the etiquette involved with using others' measurement data. To this end, we provide a set of guidelines that aim to aid the process of sharing measurement data. We present these not as specific rules, but rather a framework under which providers and users can better attain a mutual understanding about how to treat particular datasets. Copyright 2007 ACM.",Anonymization; Data sharing,"Electric measuring instruments; Internet; Semiconducting intermetallics; Wireless telecommunication systems; (e ,3e) process; Anonymization; Data sets; Data-sets; ground truth; internet measurements; Measurement data; Mutual understanding; Network measurements; Potential harm; technical details; Measurements"
"Mao Y., Tao S., Jamjoom H., Smith J.M.",4,NetworkMD: Topology inference and failure diagnosis in the last mile,2007,8,University of Pennsylvania; IBM T. J. Watson Research,IBM;University of Pennsylvania,2,USA,1,23,18,"Health monitoring, automated failure localization and diagnosis have all become critical to service providers of large distribution networks (e.g., digital cable and fiber-to-thehome), due to the increases in scale and complexity of their offered services. Existing automated failure diagnosis solutions typically assume complete knowledge of network topology, which in practice is rarely available. The solution presented in this paper - Network Management and Diagnosis (NetworkMD) - is an automated failure diagnosis system that can infer failure groups based on historical failure data, and optionally geographical information. The inferred failure groups mirror missing topologies, and can be used to localize failures, diagnose root causes of problems, and detect misconfiguration in known topologies. NetworkMD uses an unsupervised learning algorithm based on non-negative matrix factorization (NMF) to infer failure groups. Using cable network as the primary example, we demonstrate the effectiveness of NetworkMD in both simulated settings and real environment using data collected from a commercial network serving hundreds of thousands of customers via thousands of intermediate network devices. Copyright 2007 ACM.",Failure diagnosis; Network topology inference,(algorithmic) complexity; cable networks; Data collected; distribution networks; Failure data; failure diagnosis; Geographical information; Health-monitoring; internet measurements; last mile; Misconfiguration; network devices; network topologies; Non-negative matrix factorization (DNMF); Real environments; Root causes; Service provider (SP); Topology inference; Administrative data processing; Automation; Blind source separation; Cables; Distributed parameter networks; Distribution of goods; Electric network topology; Factorization; Fiber optics; Health; Information management; Internet; Learning algorithms; Learning systems; Management information systems; Matrix algebra; Semiconducting intermetallics; Solutions; Topology; Wire rope; Network management
"Baccelli F., Machiraju S., Veitch D., Bolot J.",4,On optimal probing for delay and loss measurement,2007,40,"INRlA-ENS, Ecole Normale SupŽrieure, France; Sprint, CA, United States; Dept. of E and E Engineering, University of Melbourne, Australia; ARC Snecial Research Centre on Ultra-Broadband Information Networks",University of Melbourne,1,Australia;France;USA,3,22,13,"Packet delay and loss are two fundamental measures of performance. Using active probing to measure delay and loss typically involves sending Poisson probes, on the basis of the PASTA property (Poisson Arrivals See Time Averages), which ensures that Poisson probing yields unbiased estimates. Recent work, however, has questioned the utility of PASTA for probing and shown that, for delay measurements, i) a wide variety of processes other than Poisson can be used to probe with zero bias and ii) Poisson probing does not necessarily minimize the variance of delay estimates. In this paper, we determine optimal probing processes that minimize the mean-square error of measurement estimates for both delay and loss. Our contributions are twofold. First, we show that a family of probing processes, specifically Gamma renewal probing processes, has optimal properties in terms of bias and variance. The optimality result is general, and only assumes that the target process we seek to optimally measure via probing, such as a loss or delay process, has a convex auto-covariance function. Second, we use empirical datasets to demonstrate the applicability of our results in practice, specifically to show that the convexity condition holds true and that Gamma probing is indeed superior to Poisson probing. Together, these results lead to explicit guidelines on designing the best probe streams for both delay and loss estimation. Copyright 2007 ACM.",Active probing; Auto-covariance; Convexity; PASTA; Variance,"Computational geometry; Error analysis; Estimation; Internet; Lead; Measurements; Mobile telecommunication systems; Poisson distribution; Poisson equation; Semiconducting intermetallics; (e ,3e) process; (I ,J) conditions; active probing; Auto covariances; Bias and variance; Delay measurements; Empirical datasets; General (CO); internet measurements; Loss estimation; loss measurements; Mean square error (MSE); Measures of Performance (MoP); Optimal properties; optimality; Packet delays; Poisson; Property (S); Time averaging; Unbiased estimates; Zero bias; Industrial management"
"Nguyen H.X., Thiran P.",2,Network loss inference with second order statistics of end-to-end flows,2007,52,"School of Computer and Communication Sciences, EPFL, CH-1015 Lausanne, Switzerland","EPFL, Switzerland",1,Switzerland,1,36,24,"We address the problem of calculating link loss rates from end-to-end measurements. Contrary to existing works that use only the average end-to-end loss rates or strict temporal correlations between probes, we exploit second-order moments of end-to-end flows. We first prove that the variances of link loss rates can be uniquely calculated from the covariances of the measured end-to-end loss rates in any realistic topology. After calculating the link variances, we remove the un-congested links with small variances from the first-order moment equations to obtain a full rank linear system of equations, from which we can calculate precisely the loss rates of the remaining congested links. This operation is possible because losses due to congestion occur in bursts and hence the loss rates of congested links have high variances. On the contrary, most links on the Internet are un-congested, and hence the averages and variances of their loss rates are virtually zero. Our proposed solution uses only regular unicast probes and thus is applicable in today's Internet. It is accurate and scalable, as shown in our simulations and experiments on PlanetLab. Copyright 2007 ACM.",Identifiability; Inference; Network tomography,Internet; Linear equations; Linear systems; Semiconducting intermetallics; (+ mod 2N) operation; Congested links; End to end (ETE); End-to-end measurements; first orders; internet measurements; Linear system of equations; link loss; loss rates; Moment equations; network losses; Second order statistics (SOS); Second-order moments (SOM); Temporal correlation (TC); unicast; Statistics
"Hummel B., Kosub S.",2,Acyclic type-of-relationship problems on the internet: An experimental analysis,2007,7,"FakultŠt fŸr Informatik, Technische UniversitŠt MŸnchen",TU Munich,1,Germany,1,23,13,"An experimental study of the feasibility and accuracy of the acyclicity approach introduced in [14] for the inference of business relationships among autonomous systems (ASes) is provided. We investigate the maximum acyclic type-of-relationship problem: on a given set of AS paths, find a maximum-cardinality subset which allows an acyclic and valley-free orientation. Inapproximability and NP-hardness results for this problem are presented and a heuristic is designed. The heuristic is experimentally compared to most of the state-of-the-art algorithms on a reliable data set. It turns out that the proposed heuristic produces the least number of misclassified customer-to-provider relationships among the tested algorithms. Moreover, it is flexible in handling pre-knowledge in the sense that already a small amount of correct relationships is enough to produce a high-quality relationship classification. Furthermore, the reliable data set is used to validate the acyclicity assumptions. The findings demonstrate that acyclicity notions should be an integral part of models of AS relationships. Copyright 2007 ACM.",Algorithms; AS relationships; Inter-domain routing,(1 1 1) orientation; Acyclicity; Autonomous System (AS); Business relationships; Cardinality; Data sets; Experimental analysis; Experimental studies; High quality (HQ); Inapproximability; Integral part; internet measurements; NP hardness; State-of-the-art algorithms; Heuristic methods; Heuristic programming; Internet; Nuclear propulsion; Semiconducting intermetallics; Heuristic algorithms
"Iliofotou M., Mitzenmacher M., Pappu P., Singh S., Faloutsos M., Varghese G.",6,Network monitoring using traffic dispersion graphs (TDGs),2007,83,"UC Riverside; Harvard University; Rinera Networks; Cisco Systems, Inc.; UC San Diego",Harvard University;Inc.;University of California Riverside;University of California San Diego,4,USA,1,13,13,"Monitoring network traffic and detecting unwanted applications has become a challenging problem, since many applications obfuscate their traffic using unregistered port numbers or payload encryption. Apart from some notable exceptions, most traffic monitoring tools use two types of approaches: (a) keeping traffic statistics such as packet sizes and interarrivals, flow counts, byte volumes, etc., or (b) analyzing packet content. In this paper, we propose the use of Traffic Dispersion Graphs (TDGs) as a way to monitor, analyze, and visualize network traffic. TDGs model the social behavior of hosts (""who talks to whom""), where the edges can be defined to represent different interactions (e.g. the exchange of a certain number or type of packets). With the introduction of TDGs, we are able to harness a wealth of tools and graph modeling techniques from a diverse set of disciplines. Copyright 2007 ACM.",Behavioral approach; Hosts' connection graphs; Network monitoring; Network traffic visualization,Challenging problem; graph modeling; internet measurements; Monitor (CO); Monitoring networks; Network Monitoring; Network traffics; Payload encryption; Port numbers; Social behaviors; traffic monitoring; traffic statistics; Two types; Cryptography; Dispersion (waves); Exchange interactions; Graph theory; Internet; Semiconducting intermetallics; Traffic surveys; Monitoring
"Cohen E., Duffield N., Kaplan H., Lund C., Thorup M.",5,Algorithms and estimators for accurate summarization of internet traffic,2007,15,"AT and T Labs-Research, 180 Park Avenue, Florham Park, NJ 07932, United States; School of Computer Science, Tel Aviv University, Tel Aviv, Israel",AT and T Labs;Tel Aviv University,2,Israel;USA,2,17,15,"Statistical summaries of traffic in IP networks are at the heart of network operation and are used to recover information on arbitrary subpopulations of flows. It is therefore of great importance to collect the most accurate and informative summaries given the router's resource constraints. Cisco's sampled NetFlow, based on aggregating a sampled packet stream into flows, is the most widely deployed such system. We observe two sources of inefficiency in current methods. Firstly, a single parameter (the sampling rate) is used to control utilization of both memory and processing/access speed, which means that it has to be set according to the bottleneck resource. Secondly, the unbiased estimators are applicable to summaries that in effect are collected through uneven use of resources during the measurement period (information from the earlier part of the measurement period is either not collected at all and fewer counter are utilized or discarded when performing a sampling rate adaptation). We develop algorithms that collect more informative summaries through an even and more efficient use of available resources. The heart of our approach is a novel derivation of unbiased estimators that use these more informative counts. We show how to efficiently compute these estimators and prove analytically that they are superior (have smaller variance on all packet streams and subpopulations) to previous approaches. Simulations on Pareto distributions and IP flow data show that the new summaries provide significantly more accurate estimates. We provide an implementation design that can be efficiently deployed at routers. Copyright 2007 ACM.",Data streams; IP flows; NetFlow; Network management; Sketches; Subpopulation queries,Estimation; Internet; Measurements; Phase matching; Routers; Semiconducting intermetallics; Implementation design; internet measurements; internet traffic; IP flow; ip networks; net flows; Network operations; packet streams; pareto distributions; resource constraints; Sampled packet stream; Sampling rate (SR); single parameter; Statistical summaries; Two sources; Unbiased estimators; Internet protocols
"Falkner J., Piatek M., John J.P., Krishnamurthy A., Anderson T.",5,Profiling a million user DHT,2007,77,University of Washington,University of Washington at Seattle,1,USA,1,11,11,"Distributed hash tables (DHTs) provide scalable, key-based lookup of objects in dynamic network environments. Although DHTs have been studied extensively from an analytical perspective, only recently have wide deployments enabled empirical examination. This paper reports measurements of the Azureus BitTorrent client's DHT, which is in active use by more than 1 million nodes on a daily basis. The Azureus DHT operates on untrusted, unreliable end-hosts, offering a glimpse into the implementation challenges associated with making structured overlays work in practice. Our measurements provide characterizations of churn, overhead, and performance in this environment. We leverage these measurements to drive the design of a modified DHT lookup algorithm that reduces median DHT lookup time by an order of magnitude for a nominal increase in overhead. Copyright 2007 ACM.",Measurement; Performance,"(p ,p ,t) measurements; BitTorrent (BT); Distributed hash tables (DHTs); dynamic networks; Empirical examination; internet measurements; Lookup algorithms; Lookup time; Order-of magnitudes; Internet; Measurements; Semiconducting intermetallics; Industrial management"
"Raghavendra R., Beldingt E.M., Papagiannaki K., Almeroth K.C.",4,Understanding handoffs in large IEEE 802.11 wireless networks,2007,13,"Department of Computer Science, University of California, Santa Barbara, United States; Intel Research, Pittsburgh, United States",Intel;University of California Santa Barbara,2,USA,1,13,12,"As the utility of wireless technology grows, wireless networks are being deployed in more widely varying conditions. The monitoring of these networks continues to reveal key implementation deficiencies that need to be corrected in order to improve protocol operation and end-to-end performance. Using data we collected from the 67th Internet Engineering Task Force (IETF) meeting held in November 2006, we show that under conditions of high medium utilization and packet loss, handoffs can be incorrectly initiated. Using the notion of persistence and prevalence for the association of a client to an Access Point (AP), we show that although the clients were predominantly static, the handoff rate is surprisingly high. Through the analysis of the data set, we show that unnecessary handoff events not only increase the amount of management traffic in the network, but also severely impact client performance. Copyright 2007 ACM.",Congestion; Handoff; IEEE 802.11; Wireless networks,"(I ,J) conditions; End-to-end performances; IEEE 802.11 wireless networks; In order; internet measurements; Protocol operation; Wireless technologies; Internet; Internet protocols; Semiconducting intermetallics; Standards; Telecommunication systems; Wireless networks"
"Eriksson B., Barford P., Crovella M., Nowak R.",4,Learning network structure from passive measurements,2007,13,UW-Madison; Boston University,Boston University,1,USA,1,21,18,"The ability to discover network organization, whether in the form of explicit topology reconstruction or as embeddings that approximate topological distance, is a valuable tool. To date, network discovery has been based on active measurements. However, it is feasible to envision passive discovery of network topology and distance, simply by monitoring packet traffic. Unfortunately, the lack of explicit control over the choices of which endpoints are measured means that passive network discovery must deal with the problem of missing information. We consider one such example, namely reconstructing embeddings and some network structure information from unwanted network traffic captured at a set of honeypots. We develop a number of algorithms for reconstruction of missing measurements. Our algorithms use insights derived from the known topology of the Internet as well as local imputation techniques from approximation theory. We characterize the degree to which missing information can be reconstructed and show that a limited but useful amount of reconstruction is possible, allowing the recovery of network embeddings and some topological relationships from passively collected data. Copyright 2007 ACM.",Embedding; Imputation; Inference; Measurement; Topology,"(e ,2e) theory; Active measurements; Embeddings; Honeypots; Imputation techniques; internet measurements; learning networks; Missing information; Missing measurements; Network discovery; network organizations; Network structures; network topologies; Network traffics; packet traffics; Passive measurements; Topological distance; Topological relationships; Topology reconstruction; Electric network topology; Internet; Learning systems; Measurements; Passive networks; Repair; Restoration; Semiconducting intermetallics; Topology; Approximation algorithms"
"Chandalia G., Rish I.",2,Blind source separation approach to performance diagnosis and dependency discovery,2007,5,"IBM T.J. Watson Research, Hawthorne, NY 10532, United States",IBM,1,USA,1,16,14,"We consider the problem of diagnosing performance problems in distributed system and networks given end-to-end performance measurements provided by test transactions, or probes. Common techniques for problem diagnosis such as, for example, codebook and network tomography usually assume a known dependency (e.g., routing) matrix that describes how each probe depends on the systems components. However, collecting full information about routing and/or probe dependencies on all systems components can be very costly, if not impossible, in large-scale, dynamic networks and distributed systems. We propose an approach to problem diagnosis and dependency discovery from end-to-end performance measurements in cases when the dependency/routing information is unknown or partially known. Our method is based on Blind Source Separation (BSS) approach that aims at reconstructing unobserved input signals and the mixing-weights matrix from the observed mixtures of signals. Particularly, we apply sparse non-negative matrix factorization techniques that appear particularly fitted to the problem of recovering network bottlenecks and dependency (routing) matrix, and show promising experimental results on several realistic network topologies. Copyright 2007 ACM.",Blind source separation; End-to-end probes; Matrix factorization; Network tomography; Sparse optimization,Apartment houses; Diagnostic radiography; Electric network topology; Factorization; Industrial management; Internet; Isomers; Matrix algebra; Measurements; Medical imaging; Mixing; Semiconducting intermetallics; Separation; Signal analysis; Tomography; Blind source separation (BSS); Code books; distributed systems; Distributed Systems; dynamic networks; End-to-end performances; Experimental results; Full information; input signals; internet measurements; Network tomography; network topologies; Performance diagnosis; Source separation; Sparse non-negative matrix factorization (SNMF); Blind source separation
"Wei W., Gu Y., Suh K., Kurose J., Wang B., Towsley D.",6,Passive online rogue access point detection using sequential hypothesis testing with TCP ACK-pairs,2007,45,"United Technologies Research Center; University of Massachusetts, Amherst, United States; Illinois State University; University of Connecticut",Illinois State University;United Technologies Research Center;University of Connecticut;University of Massachusetts Amherst,4,USA,1,27,12,"Rogue (unauthorized) wireless access points pose serious security threats to local networks. In this paper, we propose two online algorithms to detect rogue access points using sequential hypothesis tests applied to packet-header data collected passively at a monitoring point. One algorithm requires training sets, while the other does not. Both algorithms extend our earlier TCP ACK-pair technique to differentiate wired and wireless LAN TCP traffic, and exploit the fundamental properties of the 802.11 CSMA/CA MAC protocol and the half duplex nature of wireless channels. Our algorithms make prompt decisions as TCP ACK-pairs are observed, and only incur minimum computation and storage overhead. We have built a system for online rogue-accesspoint detection using these algorithms and deployed it at a university gateway router. Extensive experiments in various scenarios have demonstrated the excellent performance of our approach: the algorithm that requires training provides rapid detection and is extremely accurate (the detection is mostly within 10 seconds, with very low false positive and false negative ratios); the algorithm that does not require training detects 60%-76% of the wireless hosts without any false positives; both algorithms are light-weight (with computation and storage overhead well within the capability of commodity equipment). Copyright 2007 ACM.",Rogue access point detection; Sequential hypothesis testing; TCP ACK-pairs,Access point (AP); Adaptive (TCP) traffic; Applied (CO); CSMA/CA; Excellent performance; False negatives; False positive (FP); Fundamental properties; Half-duplex; Header data; Hypothesis testing; internet measurements; light weighting; local networks; Mac protocols; Monitoring points; On line algorithms; Rapid detection; Security threats; storage overhead; Training sets; Wireless access points (WAP); wireless channels; Wireless hosts; Wireless LAN (WLAN); Algorithms; Boolean functions; Diffractive optical elements; Electronic commerce; Frequency allocation; Gateways (computer networks); Internet; Internet protocols; Local area networks; Semiconducting intermetallics; Storage (materials); Transmission control protocol; Well equipment; Wireless local area networks (WLAN); Routing algorithms
"Coates M., Pointurier Y., Rabbat M.",3,Compressed network monitoring for IP and all-optical networks,2007,39,"Department of Electrical and Computer Engineering, McGill University, Montreal, QC H3A-2A7, Canada",McGill University,1,Canada,1,23,18,"We address the problem of efficient end-to-end network monitoring of path metrics in communication networks. Our goal is to minimize the number of measurements or monitors required to maintain an acceptable estimation accuracy. We present a framework based on diffusion wavelets and nonlinear estimation. Our procedure involves the development of a diffusion wavelet basis that is adapted to the monitoring problem. This basis exploits spatial and temporal correlations in the measured phenomena to provide a, compressible representation of the path metrics. The framework employs nonlinear estimation techniques using l1 minimization to generate estimates for the unmeasured paths. We describe heuristic approaches for the selection of the paths that should be monitored, or equivalently, where hardware monitors should be located. We demonstrate how our estimation framework can improve the efficiency of end-to-end delay estimation in IP networks and reduce the number of hardware monitors required to track bit-error rates in all-optical networks (networks with no electrical regenerators). Copyright 2007 ACM.",Compressed sensing; Diffusion wavelets; Network monitoring,"Communication; Estimation; Fiber optic networks; Internet; Mobile telecommunication systems; Monitoring; Optical communication; Semiconducting intermetallics; Semiconductor doping; Wireless telecommunication systems; (p ,p ,t) measurements; All optical network (AON); Communication networks; End to end network; Estimation accuracies; internet measurements; Network Monitoring; Non-linear estimation; path metrics; Spatial and temporal correlations; wavelet basis; Internet protocols"
"Gunes M.H., Sarac K.",2,Inferring subnets in router-level topology collection studies,2007,18,"Department of Computer Science, University of Texas, Dallas, United States",University of Texas at Austin,1,USA,1,23,20,"Internet measurement studies require availability of representative topology maps. Depending on the map resolution (e.g., autonomous system level or router level), the procedure of collecting and processing an Internet topology map involves different tasks. In this paper, we present a new task, i.e., subnet inference, to advance the current state of the art in topology collection studies. Utilizing a technique to infer the subnet relations among the routers in the resulting topology map, we identify IP addresses that are connected over the same connection medium. We believe that the successful inclusion of subnet relations among the routers will yield topology maps that are closer, at the network layer, to the sampled segments of the Internet in router level topology measurement studies. Copyright 2007 ACM.",Router-level map; Subnet inference; Topology discovery,Autonomous System (AS); Current state; internet measurements; Internet protocol (IP) addresses; Internet topologies; network layers; Sub-nets; Topology map; Data storage equipment; Internet; Internet protocols; Maps; Measurements; Optical projectors; Routers; Semiconducting intermetallics; Topology
"Gill P., Arlitt M., Li Z., Mahanti A.",4,YouTube traffic characterization: A view from the edge,2007,554,"Department of Computer Science, University of Calgary, Canada; Enterprise Systems and Software Lab., HP Labs., Palo Alto, United States; Department of Computer Science and Engineering, Indian Institute of Technology, Delhi, India",HP Labs;IIT Madras;University of Calgary,3,Canada;India;USA,3,44,24,"This paper presents a traffic characterization study of the popular video sharing service, YouTube. Over a three month period we observed almost 25 million transactions between users on an edge network and YouTube, including more than 600,000 video downloads. We also monitored the globally popular videos over this period of time. In the paper we examine usage patterns, file properties, popularity and referencing characteristics, and transfer behaviors of YouTube, and compare them to traditional Web and media streaming workload characteristics. We conclude the paper with a discussion of the implications of the observed characteristics. For example, we find that as with the traditional Web, caching could improve the end user experience, reduce network bandwidth consumption, and reduce the load on YouTube's core server infrastructure. Unlike traditional Web caching, Web 2.0 provides additional metadata that should be exploited to improve the effectiveness of strategies like caching. Copyright 2007 ACM.",Characterization; Multimedia; Web 2.0; YouTube,Metadata; Semiconducting intermetallics; (PL) properties; End user experience; internet measurements; Media streaming; Network bandwidths; Server infrastructure; Traffic characterization; Usage patterns; Video sharing; Web 2.0; Web Caching; workload characteristics; YouTube; Internet
"Steiner M., En-Najjary T., Biersack E.W.",3,A global view of KAD,2007,125,"Institut Eurecom, Sophia-Antipolis, France",EURECOM,1,France,1,16,9,"Distributed hash tables (DHTs) have been actively studied in literature and many different proposals have been made on how to organize peers in a DHT. However, very few DHTs have been implemented in real systems and deployed on a large scale. One exception is KAD, a DHT based on KademHa, which is part of eDonkey2000, a peer-to-peer file sharing system with several million simultaneous users. We have been crawling KAD continuously for about six months and obtained information about the total number of peers online and their geographical distribution. Peers are identified by the so called KAD ID, which was up to now assumed to remain the same across sessions. However, we observed that this is not the case: There is a large number of peers, in particular in China, that change their KAD ID, sometimes as frequently as after each session. This change of KAD IDs makes it difficult to characterize end-user availability or membership turnover. Copyright 2007 ACM.",Distributed hash table; Lookup; Peer-to-peer,Distributed computer systems; Internet; Distributed hash tables (DHTs); End users; Geographical distributions; Global views; internet measurements; Large scales; Peer-to-Peer (P2P) file sharing; Real systems; Semiconducting intermetallics
"Mahajan R., Zahorjan J., Zill B.",3,Understanding WiFi-based connectivity from moving vehicles,2007,60,Microsoft Research; University of Washington,Microsoft;University of Washington at Seattle,2,USA,1,16,12,"Using measurements from VanLAN, a modest-size testbed that we have deployed, we analyze the fundamental characteristics of WiFi-based connectivity between basestations and vehicles in urban settings. Our results uncover a more complex picture than previous work which was conducted in more benign settings. The interval between a vehicle coming into and going out of range of a basestation is often marred by intermittent periods of very poor connectivity. These ""gray periods"" are hard to reliably predict because their arrival is not signaled by metrics such as signal strength, loss rate, speed or distance from the basestation. At the same time, they also do not consistently occur at the same spot. Our analysis suggests that gray periods are not caused by the motion of the vehicle per se but by the variability in the urban radio environment combined with the vehicle traversing locations that are poorly covered by the basestation. We also find that knowledge of past connectivity can be used to identify regions where gray periods are more likely to occur as well as regions where the vehicle is likely to experience good connectivity. Copyright 2007 ACM.",Measurement; Vehicular networks; WiFi,"Base stations; Internet; Semiconducting intermetallics; Signaling; (p ,p ,t) measurements; Base Station (BS); Base stations (BS); Fundamental characteristics; internet measurements; loss rates; Metrics (CO); Moving vehicles; Radio environments; Signal strengths; Test beds; Urban settings; Vehicles"
"Cha M., Kwak H., Rodriguez P., Ahnt Y.-Y., Moon S.",5,"I tube, you tube, everybody tubes: Analyzing the world's largest user generated content video system",2007,955,"Telefonica Research, Barcelona, Spain; KAIST, Daejeon, South Korea",KAIST;Telefonica Research,2,South Korea;Spain,2,40,25,"User Generated Content (UGC) is re-shaping the way people watch video and TV, with millions of video producers and consumers. In particular, UGC sites are creating new viewing patterns and social interactions, empowering users to be more creative, and developing new business opportunities. To better understand the impact of UGC systems, we have analyzed YouTube, the world's largest UGC VoD system. Based on a large amount of data collected, we provide an in-depth study of YouTube and other similar UGC systems. In particular, we study the popularity life-cycle of videos, the intrinsic statistical properties of requests and their relationship with video age, and the level of content aliasing or of illegal content in the system. We also provide insights on the potential for more efficient UGC VoD systems (e.g. utilizing P2P techniques or making better use of caching). Finally, we discuss the opportunities to leverage the latent demand for niche videos that a,re not reached today due to information filtering effects or other system scarcity distortions. Overall, we believe that the results presented in this paper are crucial in understanding UGC systems and can provide valuable information to ISPs, site administrators, and content owners with major commercial and technical implications. Copyright 2007 ACM.",Caching; Content aliasing; Long tail; P2P; Popularity analysis; Power-law; User generated content; VoD,Filtration; Internet; Internet service providers; Life cycle; Rhenium; Semiconducting intermetallics; aliasing; business opportunities; Creative (CO); Data collected; Distributed video-on-demand (VoD) systems; In depth studies; information filtering; internet measurements; Life Cycle (LC); Peer-to-peer (P2P) techniques; Social interactions; Statistical properties; Technical implications; User generated contents; Valuable informations; viewing patterns; YouTube; Tubes (components)
"Dischinger M., Gummadi K.P., Haeberlen A., Saroiu S.",4,Characterizing residential broadband networks,2007,192,"MPI for Software Systems; MPI for Software Systems, Rice University; University of Toronto",Rice University;University of Toronto,2,USA;Canada,2,52,44,"A large and rapidly growing proportion of users connect to the Internet via residential broadband networks such as Digital Subscriber Lines (DSL) and cable. Residential networks are often the bottleneck in the last mile of today's Internet. Their characteristics critically affect Internet applications, including voice-over-IP, online games, and peer-to-peer content sharing/delivery systems. However, to date, few studies have investigated commercial broadband deployments, and rigorous measurement data that characterize these networks at scale are lacking. In this paper, we present the first large-scale measurement study of major cable and DSL providers in North America and Europe. We describe and evaluate the measurement tools we developed for this purpose. Our study characterizes several properties of broadband networks, including link capacities, packet round-trip times and jitter, packet loss rates, queue lengths, and queue drop policies. Our analysis reveals important ways in which residential networks differ from how the Internet is conventionally thought to operate. We also discuss the implications of our findings for many emerging protocols and systems, including delay-based congestion control (e.g., PCP) and network coordinate systems (e.g., Vivaldi). Copyright 2007 ACM.",Broadband access networks; Cable; DSL; Network measurement,(PL) properties; Congestion control; Digital subscriber lines (xDSL); internet applications; internet measurements; Large scale measurement; last mile; link capacities; Measurement data; Measurement tools; network coordinates; North America; On-line games; Packet loss rate (PLR); Peer-to-peer (p2p); Queue lengths; Residential networks; Round trip times (RTTs); Vivaldi; Voice-over-IP (VoIP); Broadband networks; Cables; Control systems; Delay control systems; DSL; Information services; Internet; Internet telephony; Jitter; Measurements; Modems; Online systems; Semiconducting intermetallics; Telecommunication equipment; Telecommunication lines; Telecommunication systems; Telephone lines; Traffic congestion; Voice/data communication systems; Wire rope; Internet protocols
"Lee H.K., Malkin T., Nahum E.",3,Cryptographic strength of SSL/TLS servers: Current and recent practices,2007,31,"Department of Computer Science, Columbia University, New York, NY, United States; Network Server System, Software Dept., IBM T.J. Watson Research Ctr., Hawthorne, NY, United States",Columbia University;IBM,2,USA,1,47,25,"The Secure Socket Layer (SSL) and its variant, Transport Layer Security (TLS), are used toward ensuring server security. In this paper, we characterize the cryptographic strength of public servers running SSL/TLS. We present a tool developed for this purpose, the Probing SSL Security Tool (PSST), and evaluate over 19,000 servers. We expose the great diversity in the levels of cryptographic strength that is supported on the Internet. Some of our discouraging results show that most sites still support the insecure SSL 2.0, weak export-level grades of encryption ciphers, or weak RSA key strengths. We also observe encouraging behavior such as sensible default choices by servers when presented with multiple options, the quick adoption of AES (more than half the servers support strong key AES as their default choice), and the use of strong RSA key sizes of 1024 bits and above. Comparing results of running our tool over the last two years points to a positive trend that is moving in the right direction, though perhaps not as quickly as it should. Copyright 2007 ACM.",Network security; Servers; SSL,internet measurements; Key sizes; Secure Socket Layer (SSL); Security tools; server security; SSL/TLS; Strength (IGC: D5/D6); Transport layer security (TLS); Cryptography; Internet; Semiconducting intermetallics; Servers; Tools; Public key cryptography
"Collins M.P., Shimeall T.J., Faber S., Janies J., Weaver R., De Shon M., Kadane J.B.",7,Using uncleanliness to predict future botnet addresses,2007,72,"CERT Network Situational Awareness Group, 5000 Forbes Avenue, Pittsburgh, PA 15213, United States; Department of Statistics, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, United States",Carnegie Mellon University,1,USA,1,25,24,"The increased use of botnets as an attack tool and the awareness attackers have of blocking lists leads to the question of whether we can effectively predict future bot locations. To that end, we introduce a network quality that we term uncleanliness: an indicator of the propensity for hosts in a network to be compromised by outside parties. We hypothesize that unclean networks will demonstrate two properties: spatial and temporal uncleanliness. Spatial uncleanliness is the tendency for compromised hosts to cluster within unclean networks. Temporal uncleanliness is the tendency for unclean networks to contain compromised hosts for extended periods. We test for these properties by collating data from multiple indicators (spamming, phishing, scanning and botnet IRC log monitoring). We demonstrate evidence for both spatial and temporal uncleanliness. We further show evidence for cross-relationship between the various datasets, showing that botnet activity predicts spamming and scanning, while phishing activity appears to be unrelated to the other indicators.",Blacklists; Botnets; Reputation management,(PL) properties; Botnets; Data-sets; internet measurements; phishing; Internet; Semiconducting intermetallics; Spamming; Scanning
Niculescu D.,1,Interference map for 802.11 networks,2007,58,"NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States",NEC,1,USA,1,19,18,"The interference map of an 802.11 network is a collection of data structures that can help heuristics for routing, channel assignment and call admission in dense wireless networks. The map can be obtained from detailed measurements, which are time consuming and require network down time. We explore methods and models to produce the interference map with a reduced number of measurements, by identifying interference properties that help to extrapolate complex measurements from simple measurements. Actual interference in an 802.11 a testbed is shown to follow certain regularities - it is linear with respect to packet rate of the source, packet rate of the interferer, and shows independence among interferers. When multiple cards are available, they behave differently, and even different channels of the same card have different performance. We find that while current methods of gathering the interference map may be appropriate for characterizing interference in one card networks, they are unscalable for multiple card networks when considering: 802.1.1 characteristics (card and channel asymmetries, time variation), required downtime, and complexity of the measurement procedure. Copyright 2007 ACM.",802.1.1; Interference; Measurement; Model,"Data structures; File organization; Heuristic programming; Internet; Maps; Mobile telecommunication systems; Semiconducting intermetallics; Telecommunication systems; (algorithmic) complexity; (p ,p ,t) measurements; (PL) properties; 802.11 networks; 802.11a; call admission; channel assignments; Complex measurements; Dense wireless networks; Down time; Independence (personality); Interference map; internet measurements; packet rate; Test beds; Time consuming; Time variations; Measurements"
"Schnitter S., Hartleb F., Homeffer M.",3,Quality-of-service class specific traffic matrices in IP/MPLS networks,2007,4,"Deutsche Telekom, T-Systems, D-64295 Darmstadt, Germany; Deutsche Telekom, T-Com, Hammer Str. 216-226, D-48165 MŸnster, Germany",Deutsche Telekom,1,Germany,1,15,9,"In this paper we consider the problem of determining traffic matrices for end-to-end demands in an IP/MPLS network that supports multiple quality of service (QoS) classes. More precisely, we want to determine the set of traffic matrices Tl for each QoS class i separately. Tl contains average bandwidth levels for QoS class i for every pair of routers within the network. We propose a new method for obtaining QoS class specific traffic matrices that combines estimation and measurement methods: We take advantage of the fact that the total traffic matrix can be measured precisely in MPLS networks using either the LDP or RSVP-TE protocol. These measurements can then be used in a mathematical model to improve estimation methods - known as network tomography - that estimate QoS class specific traffic matrices from QoS class specific link utilizations. In addition to the mathematical model, we present results of the proposed method from its application in Deutsche Telekom's global IP/MPLS backbone network and we show that the estimation accuracy (mean relative error) is improved by a factor of 2.5 compared to results from network tomogravity. We investigate the structure of the estimated traffic matrices for the different QoS classes and motivate in this paper why QoS class specific traffic matrices will be essential for efficient network planning and network engineering in the future. Copyright 2007 ACM.",LDP; MPLS; QoS; Traffic matrices,(SPM) classes; End to end (ETE); internet measurements; IP/MPLS; IP/MPLS networks; Quality of service (QoS); Traffic matrices; Internet; Matrix algebra; Semiconducting intermetallics; Quality of service
"Khadilkar M., Feamster N., Sanders M., Clark R.",4,Usage-based DHCP lease time optimization,2007,17,"College of Computing, Georgia Tech",Georgia Tech,1,USA,1,5,3,"The Dynamic Host Configuration Protocol (DHCP) is used to dynamically allocate address space to hosts on a local area network. Despite its widespread usage, few studies exist on DHCP usage patterns, and even less is known about the importance of setting the lease time (the time that a client retains ownership over some IP address) to an appropriate value. Lease time can greatly affect the tradeoff between address space utilization and the number of both renewal messages and client session expirations. In this paper, using a DHCP trace for 5 weekdays from the Georgia Tech campus network, we present the largest known study of DHCP utilization. We also explore how various strategies for setting lease times can dramatically reduce the number of renewals and expirations without prohibitively increasing address space utilization. Copyright 2007 ACM.",DHCP; Network management; Optimization; Usage,Address space; Campus network; Dynamic Host Configuration Protocol (DHCP); Georgia (CO); internet measurements; IP addresses; time optimization; Usage patterns; Internet; Local area networks; Semiconducting intermetallics; Internet protocols
"Shue C.A., Kalafut A.J., Gupta M.",3,The web is smaller than it seems,2007,10,"Computer Science Department, Indiana University, Bloomington, United States",Indiana University,1,India;USA,2,17,9,"The Web has grown beyond anybody's imagination. While significant research has been devoted to understanding aspects of the Web from the perspective of the documents that comprise it, we have little data on the relationship among servers that comprise the Web. In this paper, we explore the extent to which Web servers are co-located with other Web servers in the Internet. In terms of the location of servers, we find that the Web is surprisingly smaller than it seems. Our work has important implications for the availability of Web servers in case of DoS attacks and blocklisting. Copyright 2007 ACM.",Block lists; DoS attacks; Server co-location; World wide web,DOS attacks; internet measurements; Web servers; Computer crime; Internet; Semiconducting intermetallics; Web services; World Wide Web
"Bartlett G., Heidemann J., Papadopoulos C.",3,Understanding passive and active service discovery,2007,31,"USC, Information Sciences Institute, Marina del Rey, CA, United States; Colorado State University, Fort Collins, CO, United States",Colorado State University;University of Southern California,2,USA,1,19,13,"Increasingly, network operators do not directly operate computers on their network, yet are responsible for assessing network vulnerabilities to ensure compliance with policies about information disclosure, and tracking services that affect provisioning. Thus, with decentralized network management, service discovery becomes an important part of maintaining and protecting computer networks. We explore two approaches to service discovery: active probing and passive monitoring. Active probing finds all services currently on the network, except services temporarily unavailable or hidden by firewalls; however, it is often too invasive, especially if used across administrative boundaries. Passive monitoring can find transient services, but misses services that are idle. We compare the accuracy of passive and active approaches to service discovery and show that they are complimentary, highlighting the need for multiple active scans coupled with long-duration passive monitoring. We find passive monitoring is well suited for quickly finding popular services, finding servers responsible for 99% of incoming connections within minutes. Active scanning is better suited to rapidly finding all servers, which is important for vulnerability detection-one scan finds 98% of services in two hours, missing only a handful. External scans are an unexpected ally to passive monitoring, speeding service discovery by the equivalent of 9-15 days of additional observation. Finally, we show how the use of static or dynamic addresses changes the effectiveness of service discovery, both due to address reuse and VPN effects. Copyright 2007 ACM.",Active measurement; Network reconnaissance; Passive monitoring; Service discovery; Situational awareness,active probing; Active scanning; Active service; Decentralized network management; Incoming connections; Information disclosures; internet measurements; network operators; Network vulnerabilities; passive monitoring; service discovery; Tracking services; Vulnerability detection; Administrative data processing; Internet; Ketones; Management information systems; Monitoring; Network management; Scanning; Semiconducting intermetallics; Computer networks
"Wang G., Zhang B., Ng T.S.E.",3,Towards network triangle inequality violation aware distributed systems,2007,77,"Dept. of Computer Science, Rice University, Houston, TX 77005, United States",Rice University,1,USA,1,39,33,"Many distributed systems rely on neighbor selection mechanisms to create overlay structures that have good network performance. These neighbor selection mechanisms often assume the triangle inequality holds for Internet delays. However, the reality is that the triangle inequality is violated by Internet delays. This phenomenon creates a strange environment that confuses neighbor selection mechanisms. This paper investigates the properties of triangle inequality violation (TIV) in Internet delays, the impacts of TIV on representative neighbor selection mechanisms, specifically Vivaldi and Meridian, and avenues to reduce these impacts. We propose a TIV alert mechanism that can inform neighbor selection mechanisms to avoid the pitfalls caused by TIVs and improve their effectiveness. Copyright 2007 ACM.",Analysis; Distributed system; Internet delay space; Neighbor selection; Triangle inequality violations,Internet; Semiconducting intermetallics; Systems engineering; Telecommunication; Triangulation; (PL) properties; Distributed Systems; internet measurements; Meridian (CO); Network performances; Overlay structures; Selection mechanisms; Triangle inequalities; Vivaldi; Mechanisms
"Das S.M., Pucha H., Papagiannaki K., Hu Y.C.",4,Studying wireless routing link metric dynamics,2007,47,"School of ECE, Purdue University; Intel Research, Pittsburgh, United States",Intel;Purdue University,2,USA,1,8,6,"Multi-hop wireless mesh networks are increasingly being deployed for last-mile Internet access. Typically, network algorithms such as routing, channel assignment and topology control for such networks rely heavily on metrics that intend to capture link, ""quality"" across the network. However, the underlying dynamics of the proposed link metrics themselves have not yet been studied in detail. In this paper, we study the dynamics of the most popular link metrics in real network deployments. Using two wireless mesh testbeds, we measure a number of link metrics across different hardware platforms and network environments. The collected measurements allow us to study the stability and sensitivity of the different metrics to various conditions. Our study provides several insights and future research directions on how network algorithms need to adapt to link dynamics as well as how popular and widely used link metrics can be improved. Copyright 2007 ACM.",Link metrics; Link variation; Wireless networks,"(I ,J) conditions; (p ,p ,t) measurements; channel assignments; future research directions; Hardware platforms; internet access; internet measurements; Link dynamics; Metrics (CO); Multi hop wireless mesh networks; network algorithms; Network environments; Real networks; Test-beds; Topology control (TC); Underlying dynamics; Wireless meshes; Wireless routing; Ad hoc networks; Dynamics; Internet; Local area networks; Mobile telecommunication systems; Public works; Routing algorithms; Semiconducting intermetallics; Telecommunication networks; Topology; Wireless local area networks (WLAN); Wireless telecommunication systems; Wireless networks"
"Ohm P., Sicker D., Grunwald D.",3,Legal issues surrounding monitoring during network research (invited paper),2007,56,"School of Law, University of Colorado, Boulder, United States; Dept. of Computer Science, University of Colorado, Boulder, United States",University of Colorado Boulder,1,USA,1,20,13,"This work was motivated by a discussion that two of the coauthors (computer science professors) had with the other coauthor (a law professor and a former computer crime Trial Attorney at the U.S. Department of Justice), in which it was pointed out that some of the network measurements that the computer scientists were thinking of making might potentially violate Federal laws. Several Federal laws prohibit or restrict network monitoring and the sharing of records of network activity. These laws are designed to protect online privacy. They apply both to private parties and government agents, although the details vary depending on who is doing the monitoring. The most important thing to note is that none of these laws contain any specific exceptions or safe harbors for scientific or academic research. The laws are complex, but they follow a basic pattern. First, certain types of network monitoring and data access are prohibited. People who violate the prohibitions may be sued by the people whose privacy they invade and potentially prosecuted and convicted of federal crimes (i.e., misdemeanor and felony convictions). In this paper, we will examine these laws and consider what they might mean for the network measurement community. Although we focus on U.S. Federal Law, we also highlight general trends and approaches in state and international laws that impact network researchers. We will examine the steps commonly taken in prior research in network measurement to respect user privacy, and we will compare those approaches to the evolving legal rules. We will also consider whether legislative reform is needed, describe steps that researchers might take when pursuing such work in light of the legal rules, and propose future technical and policy-related steps the community can take to focus more attention on user privacy. Copyright 2007 ACM.",Law; Legal; Monitoring; Privacy; Wiretap,"(R ,s ,S) policy; Academic researches; Computer scientists; Data accessing; Department of Justice (DOJ); Federal (CO); Federal laws; General trends; International (CO); internet measurements; legal issues; Legal rules; network activities; Network measurements; Network Monitoring; Online privacy; user privacy; Computer crime; Computer science; Internet; Law enforcement; Measurements; Monitoring; Research; Semiconducting intermetallics; Stabilizers (agents); Laws and legislation"
"Varvello M., Biersack E., Diot C.",3,Dynamic clustering in delaunay-based P2P networked virtual environments,2007,23,"Eurecom, Thomson, France; Eurecom, Sophia-Antipolis, France; Thomson, Paris, France",Eurecom,1,France,1,15,11,"Classical client/server approaches for Networked Virtual Environments (NVEs) require considerable server resources to support a large number of players. On the opposite peer-to-peer (p2p) architectures achieve the required scalability at much lower cost. The feasibility of a p2p approach to NVEs depends heavily on the fact that a given user is interested only in a small part of the virtual world. For this reason, the Delaunay network is an appealing solution, which organizes peers according to their position within the NVE. However, in a NVE players typically tend to aggregate around some attractive points. As the cost of maintenance of the Delaunay network increases with player density and velocity, some peers may see a considerable volume of maintenance traffic. To address this issue, we propose a dynamic clustering algorithm: each peer in the network monitors his cost of maintenance and triggers the creation of a cluster as soon as the volume of traffic generated exceeds a given threshold. Members of a cluster then expand their coordinates to increase their reciprocal distances. In this way, decreasing the concentration of players we achieve a diminution of the maintenance cost. To evaluate our clustering scheme we simulate a simple NVE and run an experiment in Second Life. The results we obtained show that our solution is effective in keeping the amount of maintenance traffic below a chosen threshold.",Clustering; Delaunay triangulation; NVE; P2P; Second Life,Client/server; Clustering scheme; Concentration of; Cost of maintenance; Delaunay; Delaunay networks; Delaunay triangulation; Dynamic clustering; Dynamic clustering algorithm; Lower cost; Maintenance cost; Network monitors; Networked virtual environments; Peer-to-peer architectures; Second Life; Server resources; Virtual worlds; Clustering algorithms; Costs; Maintenance of way; Triangulation; Virtual reality; Peer to peer networks
"Levanti K., Kim H.S., Wong T.",3,Intent-based analysis of network-wide routing policy configuration,2007,0,"ECE Department, Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,5,5,"Routing policy configuration is a very important aspect of network operations because it affects the network's profit, performance and security. Network operators implement lowlevel routing policies according to their high-level objectives. In this paper, we propose a set of techniques for analyzing networkwide routing policies. First, we interpret the routing policies relevant to a single neighbor. Then, we classify all neighbors into groups which express common intent. Classification is done by generating and comparing update patterns. We validate our approach by experimenting with the router configuration files of a Tier-1 ISP. Our techniques classify neighbors according to their type (customer/peer/transit), highlight neighbors which deviate from the norm and reveal possible mistakes. Consequently, our network-wide analysis seems to be promising for automating the translation of routing policy configuration into initial intent. Copyright 2007 INM'07.",BGP; Router configuration; Routing policies,Network operations; Network operator; Router configuration; Routing policies; Update patterns; Internet; Internet service providers; Profitability; Routers
"BergstrŠsser S., Hildebrandt T., Lehmann L., Rensing C., Steinmetz R.",5,Virtual context based services for support of interaction in virtual worlds,2007,6,"Multimedia Communications Lab. (KOM), Technische UniversitŠt, Darmstadt, Germany",TU Munich,1,Germany,1,16,15,"A wide variety of virtual worlds exists today. They embed the user into a virtual reality allowing interaction with the virtual environment and, in case of multiplayer worlds, other users. Our goal is to support these interactions. Therefore we are using virtual parameters to describe the user's virtual context and provide additional services depending on this context. These services can either be included into the virtual world or can be realized using a community portal. In this paper we will introduce the concept of virtual context based services and its fundamentals like the classification of interaction in virtual worlds, a generic interaction model and an extended model including additional services.",Context-based service; MMORPG; Online games; User-support,Context-based; Extended model; Interaction model; MMORPG; Multiplayers; On-line games; Virtual contexts; Virtual environments; Virtual worlds; Virtual reality; Interactive computer graphics
"But J., Nguyen T., Stewart L., Williams N., Armitage G.",5,Performance analysis of the ANGEL system for automated control of game traffic prioritisation,2007,7,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,23,21,The Automated Network Games Enhancement Layer (ANGEL) [6] is a novel architecture for meeting Quality of Service (QoS) requirements of real-time network game traffic across consumer broadband links. ANGEL utilises detection of game traffic in the ISP network via the use of Machine Learning techniques and then uses this information to inform network routers - in particular the home access modem where bandwidth is limited - of these flows such that the traffic may be prioritised. In this paper we present the performance characteristics of the fully built ANGEL system. In particular we show that ANGEL is able to detect game traffic with better than 96% accuracy and effect prioritisation within a second of game flow detection. We also demonstrate the processing performance of key ANGEL components under typical hardware scenarios.,Machine learning; Online gaming; Quality-of-service; Traffic classification,Automated control; Enhancement Layers; Flow detection; Machine learning techniques; Machine-learning; Network game; Network routers; Novel architecture; On-line gaming; Performance analysis; Performance characteristics; Processing performance; Real-time network game; Internet service providers; Learning algorithms; Learning systems; Online systems; Quality of service; Telecommunication traffic; Routers
"Chen X., Mao Z.M., Van Der Merwe J.",3,Towards automated network management: Network operations using dynamic views,2007,11,"University of Michigan, United States; AT and T Labs.Research, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,11,10,"We analyze data from a Tier-1 ISP that reflect the dynamic operational tasks performed in the ISP network to build a holistic view of configuration management operations. We observe that in addition to commands that lead to persistent configuration changes, virtually all management tasks also involve status-checking commands that do not change the configuration, but allow the operator to verify some router specific state. Based on this observation we model configuration modifications using automatically generated deter- ministic finite automata (DFA), where a state represents the configured behavior of an interface and an edge indicates the operations performed on the interface either to fulfill a specific task or to check the status of the router. The DFA model captures common configuration tasks derived by our analysis and their ordering and dependency. We argue that composing DFAs is a (small) step towards enabling opera-tors to reason about the operational state of the network, as well as enabling tools for automated network management. Copyright 2007 INM'07.",DFA; Network management automation; TACACS,Automatically generated; Configuration management; DFA; Enabling tools; Holistic view; Management tasks; Model configuration; Network operations; Operational state; Operational tasks; Specific state; Specific tasks; Automata theory; Automation; Internet; Internet service providers; Management
"Le F., Xie G.G.",2,On guidelines for safe route redistributions,2007,9,"Carnegie Mellon University, United States; Naval Postgraduate School, United States",Carnegie Mellon University;Naval Postgraduate School,2,USA,1,11,10,"Route redistribution (RR) is becoming a critical tool in enterprise network operations. Like BGP, RR is prone to configuration errors, which may result in severe instabilities such as permanent routing loops and oscillations. In response, router vendors have put forth a set of recommendations on how to configure RR. However, the proposed guidelines are mainly derived from anecdotal experience and based on a limited range of parameters. Having not been subjected to systematic validation, their general effectiveness for preventing routing instabilities is largely unknown. This paper shows that the vendor recommendations do not completely eliminate routing instabilities and have severe limitations in terms of domain backup. It then presents a set of new guidelines with provable properties assuring safety, robustness, reachability, and domain backup. Configurations based on these guidelines allow routing domains of a network to safely exchange information and back up each other, thus increasing the robustness of the network against failures. Copyright 2007 INM'07.",Route oscillations; Route redistribution; Router configuration; Routing loop,Back up; Enterprise networks; Provable properties; Reachability; Router configuration; Routing instability; Routing loops; Internet; Routers
"Ishibashi Y., Hashimoto Y., Ikedo T., Sugawara S.",4,Adaptive _-causality control with adaptive dead-reckoning in networked games,2007,14,"Department of Computer Science and Engineering, Graduate School of Engineering, Nagoya Institute of Technology, Nagoya 466-8555, Japan",Nagoya Institute of Technology,1,Japan,1,12,9,"This paper proposes an adaptive _-causality control scheme with adaptive dead-reckoning to preserve the consistency among players and the causality for networked games. The proposed scheme carries out adaptive _-causality control and adaptive dead-reckoning together. By simulation, we make a performance comparison among nine schemes including the scheme for a networked racing game. We also investigate the influence of the maximum value of _ of the scheme on the interactivity by subjective assessment. As a result, we illustrate that the scheme is superior to the other schemes in terms of the consistency among players. Also, we show that if the maximum value of _ is less than about 100 ms, the influence of the value on the interactivity is small.",Causality control; Consistency; Networked racing game; Simulation; Subjective assessment,Control schemes; Dead reckoning; Game simulation; Interactivity; Maximum values; Networked games; Networked racing game; Performance comparison; Subjective assessments
"Wang J., Nelakuditi S.",2,IP fast reroute with failure inferencing,2007,30,"Department of Computer Science and Engineering, University of South Carolina, United States",University of South Carolina,1,USA,1,15,14,"Five nines availability is being expected from IP networks due to the growing popularity of IP telephony and the increasing usage of the Internet for mission-critical applications. This necessitates enhancing the resiliency of IP networks against transient failures that are observed to happen relatively frequently even in well-managed networks. Towards that end, we proposed failure inferencing based fast rerouting (FIFR) approach that exploits the existence of a forwarding table per line-card, for lookup efficiency in current routers, to provide fast rerouting similar to MPLS, while adhering to the destination-based forwarding paradigm. Earlier, we have shown that FIFR can deal with either single link or single node failures in a network consisting of pointto-point links with symmetric link weights. In this paper, we generalize FIFR to handle both link and node failures in networks with asymmetric link weights and multi-access links too. Furthermore, we apply FIFR for protecting against inter-AS failures also. With these extensions, we argue that FIFR elevates the resiliency of any IP network with minimal changes to the forwarding and routing planes. Categories and Subject Descriptors: C.2.2 [Network Protocols]: Routing Protocols General Terms: Algorithms. Copyright 2007 INM'07.",Failure protection; Fast rerouting,Asymmetric links; Descriptors; Failure protection; Fast reroute; Fast rerouting; Forwarding tables; In-network; IP networks; IP telephony; Lookups; Managed networks; Mission critical applications; Multiaccess; Node failure; Point-to-point link; Single link; Single node failure; Symmetric links; Internet; Internet telephony; Routers; Table lookup; Telephone systems; Internet protocols
"Jiang H., Moore A.W., Ge Z., Jin S., Wang J.",5,Lightweight application classification for network management,2007,39,"EECS Department, Case Western Reserve Univ., Cleveland, OH 44106, United States; Computer Laboratory, University of Cambridge, United Kingdom; Adverplex Inc., 100 Quannapowitt Parkway, Wakefield, MA 01880, United States; AT and T Labs Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs;Adverplex Inc.;University of Cambridge,3,UK;USA,2,14,13,"Traffic application classification is an essential step in the network management process to provide high availability of network services. However, network management has seen limited use of traffic classification because of the significant overheads of existing techniques. In this context we explore the feasibility and performance of lightweight traffic classification based on NetFlow records. In our experiments, the NetFlow records are created from packettrace data and pre-tagged based upon packet content. This provides us with NetFlow records that are tagged with a high accuracy for ground-truth. Our experiments show that NetFlow records can be usefully employed for application classification. We demonstrate that our machine learning technique is able to provide an identification accuracy (Å 91%) that, while a little lower than that based upon previous packet-based machine learning work (> 95%), is significantly higher than the commonly used port-based approach (50 - 70%). Trade-offs such as the complexity of feature selection and packet sampling are also studied. We conclude that a lightweight mechanism of classification can provide application information with a considerably high accuracy, and can be a useful practice towards more effective network management. Copyright 2007 INM'07.",Flow classification; Internet traffic; Traffic identification,Feature selection; Flow classification; High availability; Identification accuracy; Internet traffic; Lightweight application; Machine learning techniques; Machine-learning; NetFlows; Network services; Packet contents; Packet sampling; Packet-based; Traffic classification; Traffic identification; Feature extraction; Flow patterns; Internet; Learning algorithms; Learning systems; Management; Telecommunication traffic
"Cricenti A., Branch P.",2,"ARMA(1,1) modeling of Quake4 Server to client game traffic",2007,13,"Centre for Advanced Internet Architecture, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,17,14,"Modeling traffic generated by Internet based multiplayer computer games has attracted a great deal of attention in the past few years. In part this has been driven by a need to simulate correctly the network impact of highly interactive online game genres such as the first person shooter (FPS). Packet size distributions and autocorrelation models are important elements in the creation of realistic traffic generators for network simulators such as ns-2 and OMNET++. In this paper we show that ARMA(1,1) models capture the time series behaviour of Quake4 game traffic well. We also show that the random component of the ARMA models (the innovations) have distributions that appear to change little as the number of players increases.",First person shooter; Online games; Simulation; Teletraffic analysis; Traffic engineering; Traffic modeling; UDP,First person shooter; On-line games; Teletraffic analysis; Traffic Engineering; Traffic modeling; Time series; Internet protocols
"Turner A., Kim H.S., Wong T.",3,Automatic discovery of relationships across multiple network layers,2007,3,"ECE Department, Carnegie Mellon University, Pittsburgh, PA 15213, United States",Carnegie Mellon University,1,USA,1,13,6,"As networks become increasingly large and complex the relationships and dependencies between network elements also grow in complexity and size. If an e-mail server goes off-line for ten minutes but never goes off-line again, it might not be a serious problem, and can be forgotten about. But if the e-mail server repeatedly goes off-line, the cause of the problem must be found. The difficulty for network operators is discovering what causes the problem - we address this issue and formalize a method to make event logs more useful to network operators. In this paper we describe how network events can be correlated across multiple network layers, and utilize the temporal and spatial aspects of the event data to more accurately correlate network events than using the event descriptions alone. Our results show that by statistically analyzing Syslog data, a relationship graph can be automatically generated that shows relationships between network elements. We then go on to discuss how such a relationship graph, in combination with event correlation, can help operators more accurately discover the root cause of problems, and identify hidden relationships and dependencies within their networks. Copyright 2007 INM'07.",Network management; Probability; Root cause analysis; Sequential pattern mining; Syslog,Automatic discovery; Automatically generated; E-mail servers; Event correlation; Event description; Multiple networks; Network element; Network operator; Relationship graphs; Root cause; Root cause analysis; Sequential-pattern mining; Spatial aspect; Electronic mail; Internet; Network layers; Problem solving; Security of data
"Kvalbein A., Lysne O.",2,How can multi-topology routing be used for intradomain traffic engineering?,2007,13,"Simula Research Laboratory, Oslo, Norway",Simula Research,1,Norway,1,25,20,"Multi-Topology routing allows each router in a network to maintain several valid routes to each destination. This increases the possibilities to spread traffic towards a destination over multiple paths with connectionless routing protocols like OSPF or IS-IS. In this paper, we report early ideas on how this can be utilized as a Traffic Engineering tool. We look at both offline and online approaches, and argue that a Multi-Topology based solution has advantages over previous solutions in both paradigms. Copyright 2007 INM'07.",Intradomain; Multi-topology routing; Traffic engineering,Connectionless routing; Intra-domain; Intra-domain traffic; Multi-topology routing; Multiple-path; Offline; Traffic Engineering; Internet; Internet protocols; Routers; Topology
"Kharrazi M., Sen S., Spatscheck O.",3,Towards real-time performance monitoring for encrypted traffic,2007,1,"AT and T Labs-Research, Florham Park, NJ, 07932, United States",AT and T Labs,1,USA,1,16,13,"IP networks are increasingly carrying mission-critical applications with robust end-to-end network performance and reliability requirements. Network performance monitoring forms an essential component of critical IP network management functions such as troubleshooting, anomaly detection, and Service-Level-Agreement (SLA) compliance monitoring. However, privacy and security considerations are fueling the use of IP-level encryption techniques such as IPsec, which obscure important transport layer features that existing performance measurement techniques need. New techniques are therefore needed for monitoring performance of encrypted traffic. Towards this goal, in this paper we present a new technique for monitoring round-trip times (RTT) for IP-level encrypted communications. Our approach involves using network-level features like packet size and inter-packet timing to infer specific timing events, and aggregating measurements across short time intervals and related connections to derive final RTT estimates for network paths of interest. Extensive evaluations using traces from an enterprise and a broadband access network, demonstrate that the resulting RTT estimates are quite accurate. Copyright 2007 INM'07.",Encrypted traffic; IPsec traffic; Performance monitoring; Traffic analysis,Anomaly detection; Broad-band access networks; Compliance monitoring; Encrypted communication; Encrypted traffic; Encryption technique; End-to-end network; Essential component; IP networks; Management functions; Mission critical applications; Monitoring performance; Network paths; Packet size; Performance measurements; Privacy and security; Real time performance; Round-trip time; Service level agreements; Short time intervals; Traffic analysis; Traffic performance; Transport layers; Troubleshooting; Cryptography; Internet; Internet protocols; Network performance; Network security; Time measurement; Monitoring
"Sardouk A., Senouci S.M., Achir N., Boussetta K.",4,Assessment of MANET broadcast schemes in the application context of multiplayer video games,2007,2,"Orange Labs., CORE/M2I, 2, Avenue Pierre Marzin, 22307 Lannion, France; L2TI, Institut Galilee, University Paris 13, 99 Avenue J-B Clement, 93430 Villetaneuse, France",University Paris 13,1,France,1,11,8,"Taking into consideration the popularity of multiplayer games and the tremendous success of wireless networks, we strongly believe that future game engines will benefit from the integration of MANET (Mobile Ad hoc NETworks) technology [1]. Indeed, in addition to the social interests of playing with close located persons, MANET technology will allow players, like a group of kids in a playground, to easily improvise a LAN multiplayer party without any need for an existing wireless network infrastructure. In order to make such scenario a common based reality, several issues still have to be addressed. Among which is the MANET's broadcast problem. In fact, broadcast is a fundamental network service for multiplayer LAN mode. But up to now, the most used scheme for broadcasting in MANET relies on flooding. Unfortunately, this simple scheme leads to high redundancy and collisions. In the context of a multiplayer party supported by mobile terminals, this broadcast storm problem [10], could result into a dramatic reduction of the network energy-based lifetime and to a high variability of the transmission delay. The latter one is know to be a crucial QoS parameter which can significantly affect the game play. In this paper, we evaluate the performance of different MANET broadcast schemes in the context of multiplayer video games. We analyze the capacity of simple flooding, distance based, probability based and self pruning broadcast schemes to satisfy the QoS constraints required by multiplayer games like FPS. Assessment simulations are conducted for both Client/Server and P2P network game architectures.",Ad hoc networks; Broadcast; Multiplayer video games,Application contexts; Broadcast problem; Broadcast scheme; Broadcast storm problem; Client/server; Distance-based; Game Engine; High redundancy; High variability; Mobile terminal; Multiplayer games; Multiplayer video games; Multiplayers; Network services; P2P network; QoS constraints; QoS parameters; Self-pruning; Transmission delays; Video game; Access control; Broadcasting; Computer simulation; Distributed computer systems; Mobile ad hoc networks; Network architecture; Peer to peer networks; Wireless local area networks (WLAN); Ad hoc networks
"Jafarisiavoshani M., Fragouli C., Diggavi S., Gkantsidis C.",4,Bottleneck discovery and overlay management in network coded peer-to-peer systems,2007,23,"EPFL, Switzerland; Microsoft Research, United Kingdom","EPFL, Switzerland;Microsoft",2,Switzerland;UK,2,11,9,"The performance of peer-to-peer (P2P) networks depends critically on the good connectivity of the overlay topology. In this paper we study P2P networks for content distribution (such as Avalanche) that use randomized network coding techniques. The basic idea of such systems is that peers randomly combine and exchange linear combinations of the source packets. A header appended to each packet specifies the linear combination that the packet carries. In this paper we show that the linear combinations a node receives from its neighbors reveal structural information about the network. We propose algorithms to utilize this observation for topology management to avoid bottlenecks and clustering in network-coded P2P systems. Our approach is decentralized, inherently adapts to the network topology, and reduces substantially the number of topology rewirings that are necessary to maintain a well connected overlay; moreover, it is integrated in the normal content distribution. This work demonstrates another advantage of using network coding and complements previous work that showed network coding achieves high network-resource utilization. Copyright 2007 INM'07.",Network algorithms; Network coding; Peer-to-peer networks; Topology management,Basic idea; Content distribution; In-network; Linear combinations; Network algorithms; Network coding; Network topology; Overlay topologies; P2P network; P2P system; Peer-to-Peer system; Resource utilizations; Structural information; Topology management; Ad hoc networks; Clustering algorithms; Distributed computer systems; Electric network topology; Information theory; Internet; Management; Normal distribution; Peer to peer networks
"Lusch A.C., Fleury A.V., Chandra S.",3,Do nintendo handhelds play nice? An analysis of its wireless behavior,2007,0,"University of Notre Dame, Notre Dame, IN 46556, United States",University of Notre Dame,1,USA,1,13,13,"Nintendo DS handheld game units are popular. They are capable of wireless game play using IEEE 802.11 networks. In this paper, we investigated the local Nintendo wireless game traffic and the effect of this game traffic on other wireless users. We analyzed the wireless traffic generated by up to six players for a number of different games. Our analysis showed that the local wireless traffic differed significantly from wide-area wireless traffic for the same games and hardware. The bit rates used made the small game packets appear large to higher speed networks that shared the wireless channel. Also, Nintendo used a point coordination function (PCF) to arbitrate channel access for local games. Ideally, the contention free slots provided by PCF can provide better quality of service for the game traffic. However, this added extra overhead for the coordination traffic, about 98% of polls for Pictochat produced no game data. Also, this PCF coordination packets were unaware of the coexistence of distributed coordination function (DCF) traffic from typical wireless access points; catastrophically interfering with the wireless traffic of other wireless LAN users.",Distributed coordination function (DCF); IEEE 802.11 wireless; Nintendo DS; Point coordination function (PCF),Bit rates; Channel access; Contention-free; Distributed coordination functions; Handhelds; IEEE 802.11 networks; IEEE 802.11s; Nintendo; Nintendo DS; Point coordination functions; Wide area; Wireless access points; Wireless channel; Wireless games; Wireless LAN; Wireless traffic; Wireless users; Quality of service; Standards; Wireless local area networks (WLAN)
"Backhaus H., Krause S.",2,Voronoi-based adaptive scalable transfer revisited: Gain and loss of a Voronoi-based peer-to-peer approach for MMOG,2007,15,"Institute of Telematics, University of Karlsruhe (TH), Karlsruhe, Germany",University of Karlsruhe,1,Germany,1,12,7,"We present and evaluate an implementation of VAST (Voronoi-based Adaptive Scalable Transfer) as proposed by Shun-Yun Hu and Guan-Ming Liao in Scalable Peer-to-Peer Networked Virtual Environment [4]. VAST is a fully-distributed peer-to-peer protocol, designed to handle event messages in MMOGs (Massively Multiplayer Online Games) and virtual worlds. VAST relies on voronoi diagrams and AOI (Areas Of Interest) for neighbor discovery. Benefits and problems of using voronoi diagrams in peer-to-peer-based MMOGs and virtual worlds are discussed, by looking at bandwidth usage, scalability and consistency of VAST and comparing it to other approaches. We point out certain issues regarding VASTs consistency and propose some changes to VASTs architecture aiming at enhancing its consistency. Finally we have a look at future extensions like group management and adaptive areas of interest per peer, in order to reduce bandwidth requirements and further increase VASTs consistency.",Massively multiplayer online games; Neighbor discovery; Peer-to-peer; Scalability; Virtual worlds; Voronoi diagram,Massively multi-player online games; Neighbor discovery; Peer to peer; Virtual worlds; Voronoi diagrams; Computational geometry; Interactive computer graphics; Scalability; Virtual reality; Distributed computer systems
"Ramamurthy P., Sekar V., Akella A., Krishnamurthy B., Shaikh A.",5,Using mini-flash crowds to infer resource constraints in remote web servers,2007,3,"University of Wisconsin-Madison, United States; Carnegie Mellon University, United States; AT and T Labs.Research, United States; IBM Research, United States",AT and T Labs;Carnegie Mellon University;IBM;;University of Wisconsin-Madison,5,USA,1,12,7,"Unexpected surges in request traffic (e.g., flash crowds) can exercise server-side resources such as access bandwidth, CPU, and disks in unanticipated ways. Administrators today do not have the requisite tools to fully understand the effect that flash crowds can have on server-side resources. As a result, most Web-servers today rely on significant over-provisioning, strict admission control, or alternatively use potentially expensive solutions like CDNs to provide high availability under load. A more fine-grained understanding of the performance of servers under emulated but controlled flash crowd like conditions can guide administrators to make more efficient provisioning and resource management decisions. We present the initial design of Mini-Flash Crowds (MFC). a light-weight wide-area profiling service that reveals resource bottlenecks in aWeb-server infrastructure, including access bandwidth, processing resources, and back-end data management. The MFC approach is based on a set of controlled measurements in which an increasing number of distributed clients make synchronized requests to exercise specific resources of a remote server. Using a number of wide-area experiments and controlled lab tests, we show that our approach can faithfully track the impact of request loads on different server resources. Our approach is non-intrusive and thus we can use it to actively probe numerous live Web servers. We present the results from a preliminary measurement study of resource provisioning on public Web servers. Copyright 2007 INM'07.",Flash crowds; Web performance,Admission Control; Data management; Flash crowd; High availability; Initial design; Light weight; Measurement study; Non-intrusive; Processing resources; Remote servers; Resource Constraint; Resource management; Resource provisioning; Server infrastructure; Server resources; Web performance; Web servers; Wide area; Access control; Internet; Web services; Servers
"Que Y.P., Safaei F., Boustead P.",3,An immersive voice over IP service to wireless gaming: User study and impact of virtual world mobility,2007,3,"Smart Internet CRC, Telecommunications and Information Technology Research Institute, University of Wollongong, Australia",University of Wollongong,1,Australia,1,17,12,"The current generation of VoIP services offer only single channel (mono) party-mix of voices. Thus when added to a network game engine, mono VoIP service can not really contribute to the gamers' sense of virtual world immersion. As a future development, the Immersive VoIP service delivers to each gamer an Auditory Scene, mixing the live voices of surrounding gamers which are all directionally placed and distance attenuated according to the appropriate virtual world positions. In previous work, we have proposed the Wireless Immersive Communication Environment (WICE) which is special type of Immersive VoIP service tailored to the scarce resources of wireless gaming clients. Also in previous work, we have already addressed the processing scalability of WICE with the conjecture of distance-governed relaxation of acceptable angular errors which allows multiple gamers to share the voice localised along the same direction. In this work, we verify the conjecture of acceptable angular errors in a series of subjective listening tests. An important test finding is the apparent user sensitivity to angular shifts in voice localisation when such auditory movements correspond to little or no visual movements. This finding suggests that the re-establishment of Auditory Scenes across time can not be memoryless in the face of gamer mobility in the virtual world. A mechanism has thus been developed to address this issue and analytic results are obtained on the impact of virtual world mobility on the required execution frequency of such mechanism.",Auditory scene creation; Immersive voice over IP service; Voice processing reduction; Wireless Immersive Communication Environment (WICE),Immersive; Voice over IP services; Voice processing reduction; Wireless Immersive Communication Environment (WICE); Errors; Internet telephony; Patient rehabilitation; Telecommunication services; Telecommunication systems; Virtual reality; Voice/data communication systems
"Trejos L.M., Kamada M., Yonekura T., Reaz M.B.I.",4,Wildlife net-gamekeepers using sensor network,2007,0,"Ibaraki University, 4-12-1, Nakanarusawa, Hitachi, ibaraki 316-8511, Japan; Department of Electrical and Computer Engineering, International Islamic University Malaysia, Jalan Gombak, 53100 Kuala Lumpur, Malaysia",Ibaraki University;International Islamic University Malaysia,2,Japan;Malaysia,2,7,2,"Wildlife lies in vast and wide areas where human gamekeepers work as protectors. The task of recognizing poachers in protected areas is tedious, tiring, and requires huge manpower and computational overhead. A fully automated system cannot accurately identify every such poacher. This paper proposes a conceptual system based on sensor network, which will provide amusement for cyberspace gamekeepers while protecting the wildlife. For this, the sensory data from the park is mapped to a game-like virtual environment. Cyberspace gamekeepers will access the system and play the game. While playing, they will help to conserve the wildlife in national parks by pattern recognition of intruders in the game. The sensor network in the proposed system will use microphone, accelerometers and wireless transmission system.",Game modification; Nature conservation; Network monitoring; Pattern recognition,Automated systems; Computational overheads; Conceptual systems; Cyberspaces; National parks; Nature conservation; Network Monitoring; Protected areas; Sensory data; Virtual environments; Wide area; Wireless transmission systems; Animals; Automation; Computers; Parks; Pattern recognition; Sensor networks; Virtual reality; Conservation
"Khan A.M., Chabridon S., Beugnard A.",3,Synchronization medium: A consistency maintenance component for mobile multiplayer games,2007,7,"GET INT, CNRS UMR SAMOVAR, 9 rue Charles Fourier, 91011 Evry Cedex, France; ENST Bretagne, Computer Science Department, CS83818, F-29238 Brest Cedex 3, France","CNRS UMR SAMOVAR, France",1,France,1,17,11,"In multiplayer games, where many players take part in a game while communicating through a network, the players may have an inconsistent view of the game world because of the communication delays across the network. This problem of inconsistency is even more crucial when playing on a mobile phone via a 3G network where the communication delays can be of several seconds. Consistency maintenance algorithms must be used to have a uniform view of the game world. These algorithms are very complex and hard to program. In this paper, we discuss different consistency maintenance algorithms from the point of view of mobile devices and present an approach where the consistency concern is handled separately by a distributed component called synchronization medium, which is responsible for communication as well as consistency maintenance. The game logic components interact with the synchronization medium to communicate between them and synchronize their data. We argue that this separation of concerns reduces the burden on the game developer. Moreover, a medium offers a generic interface and is designed to be easily reused for different game applications. Finally, using a medium, different consistency maintenance approaches can be tested and compared easily for experimentation.",Communication abstraction; Data synchronization; Latency hiding; Medium; Multiplayer mobile games,Communication abstraction; Data synchronization; Latency hiding; Mobile games; Multiplayers; Abstracting; Algorithms; Communication; Maintenance; Mobile devices; Synchronization
"Wang Y., Avramopoulos I., Rexford J.",3,Morpheus: Making routing programmable,2007,4,"Princeton University, United States",Princeton University,1,USA,1,7,7,"This paper presents Morpheus, a modular, open routing platform that supports flexible control of routing policies of a network. With Morpheus, network operators can re- alize many useful policies that are infeasible today through composition of multiple policy modules and programming the route-selection algorithms. Morpheus can be readily de- ployed without requiring changes in other domains. Copyright 2007 INM'07.",Flexibility; Modularity; Programmability,Flexible control; Network operator; Programmability; Routing policies; Selection algorithm; Mathematical operators; Internet
"Triebel T., Guthier B., Effelsberg W.",3,Skype4Games,2007,3,"Praktische Informatik IV, University of Mannheim, Germany",University of Mannheim,1,Germany,1,18,12,"We propose to take advantage of the distributed multi-user Skype system for the implementation of an interactive online game. Skype combines efficient multi-peer support with the ability to get around firewalls and network address translation; in addition, speech is available to all game participants for free. We discuss the network requirements of interactive multi-player games, in particular concerning end-to-end delay and distributed state maintenance. We then introduce the multi-user support available in Skype and conclude that it should suffice for a game implementation. We explain how our multi-player game based on the Irrlicht graphics engine was implemented over Skype, and we present very promising results of an early performance evaluation.",Distributed interactive applications; Peer-to-peer; Skype,Distributed interactive applications; Distributed state; End to end delay; Graphics engine; Multi-user; Multiplayer games; Network address translations; Network requirements; On-line games; Peer support; Peer to peer; Performance evaluation; Distributed computer systems; Interactive devices; Peer to peer networks
"Glinka F., Plo§ A., MŸller-Lden J., Gorlatch S.",4,RTF: A real-time framework for developing scalable multiplayer online games,2007,33,"University of MŸnster, Germany",University of MŸnster,1,Germany,1,9,8,"This paper presents a middleware system called RTF (Real-Time Framework) which aims at supporting the development of modern real-time online games. The RTF automatically distributes the game state among participating servers, and supports parallel state update computations, as well as efficient communication and synchronization between game servers and clients. The game developers access the RTF via a comfortable interface that offers a considerably higher level of abstraction than the time-consuming and error-prone programming in C++ with socket-based communication. We describe the structure of the RTF system and its current proof-of-concept implementation which supports the multi-server parallelization concepts of zoning, instancing and replication for real-time online games. The novel feature of the RTF is the combination of these three concepts which allows the developer to create large, seamless virtual worlds and to migrate zones between servers.",Design; Massively multiplayer online games; Middleware; Performance; Scalability,Error prones; Game servers; Level of abstraction; Massively multi-player online games; Middleware performance; Middleware system; Multi-player online games; Multi-server; On-line games; Parallelizations; Proof of concept; Virtual worlds; Interactive computer graphics; Middleware; Scalability; Servers
"Zhan C., Li W., Safaei F., Ogunbona P.",4,Emotional states control for on-line game avatars,2007,2,"University of Wollongong, Wollongong, NSW 2522, Australia",University of Wollongong,1,Australia,1,15,9,"Although detailed animation has already been achieved in a number of Multi-player On-line Games (MOGs), players have to use text commands to control emotional states of avatars. Some systems have been proposed to implement a real-time automatic system facial expression recognition of players. Such systems can then be used to control avatars emotional states by driving the MOG's ""animation engine"" instead of text commands. Some of the challenges of such systems is the ability to detect and recognize facial components from low spatial resolution face images. In this paper a system based on an improved face detection method of Viola and Jones is proposed to serve the MOGs better. In addition a robust coarse-to-fine facial landmark localization method is proposed. The proposed system is evaluated by testing it on a database different from the training database and achieved 83% recognition rate for 4 emotional state expressions. The system is able to operate over a wider range of distance from user to camera.",Avatar control; Facial expression recognition; Multiplayer on-line game,Animation engine; Automatic systems; Coarse-to-fine; Emotional state; Face detection methods; Face images; Facial components; Facial expression recognition; Facial landmark; Multiplayers; On-line games; Recognition rates; Spatial resolution; System-based; Training database; Animation; Gesture recognition; Real time systems; Face recognition
"Webb S.D., Soh S., Lau W.",3,Enhanced mirrored servers for network games,2007,23,"Curtin University of Technology, Department of Computing, Perth, WA, Australia",Curtin University of Technology,1,Australia,1,18,8,"The Mirrored Server (MS) architecture uses multiple mirrored servers across multiple locations to alleviate the bandwidth bottleneck in the Client/Server (C/S) architecture. Each mirror receives and multicasts player updates to the others, simulates the game, and disseminates the new game state to players. However, keeping the game state consistent between mirrors in the presence of network delay, and maintaining game responsiveness requires each server in MS to simulate the game multiple times for each game update, and additional times in the event of costly rollbacks. In this paper we propose the Enhanced Mirrored Server (EMS) architecture. Like in the Peer-to-Peer architecture, EMS allows peers to exchange updates directly, resulting in a higher tolerance to delay at the mirrors. We propose using bucket synchronization in the mirrors so that each server in EMS simulates the game only once for each update and does not require rollbacks. The server dissenates updates to clients only in the event of inconsistency, and thus its outgoing bandwidth is lower than in MS. Our EMS uses cryptographic techniques to provide security equivalent to C/S, and prevents the timestamp cheat possible in MS. Our analytical analysis and simulations show the advantages of EMS over MS.",Architecture; Cheating; Client/server; Mirrored servers; MMOG; Peer-to-peer,Analytical analysis; Bandwidth bottlenecks; Cheating; Client/server; Cryptographic techniques; Mirrored servers; Multicasts; Network delays; Network game; Peer to peer; Peer-to-peer architectures; Time-stamp; Distributed computer systems; Mirrors; Servers
"Ramakrishnan K.K., Shenoy P., Van Der Merwe J.",3,Live data center migration acrossWANs: A robust cooperative context aware approach,2007,40,"AT and T Labs-Research, United States; University of Massachusetts, United States",AT and T Labs;University of Massachusetts Amherst,2,USA,1,23,17,"A significant concern for Internet-based service providers is the continued operation and availability of services in the face of outages, whether planned or unplanned. In this paper we advocate a cooperative, context-aware approach to data center migration across WANs to deal with outages in a non-disruptive manner. We specifically seek to achieve high availability of data center services in the face of both planned and unanticipated outages of data center facilities. We make use of server virtualization technologies to enable the replication and migration of server functions. We propose new network functions to enable server migration and replication across wide area networks (e.g., the Internet), and finally show the utility of intelligent and dynamic storage replication technology to ensure applications have access to data in the face of outages with very tight recovery point objectives. Copyright 2007 INM'07.",Data center migration; Storage; Virtual server,Context-Aware; Data center services; Data centers; Dynamic storage; High availability; Internet-based services; Network functions; Recovery point objectives; Replication technology; Server function; Server migration; Virtual servers; Virtualizations; Outages; Technology transfer; Wide area networks; Internet
"Mogaki S., Kamada M., Yonekura T., Okamoto S., Ohtaki Y., Reaz M.B.I.",6,Time-stamp service makes real-time gaming cheat-free,2007,24,"Ibaraki University, 4-12-1, Nakanarusawa, Hitachi, Ibaraki 316-8511, Japan; Seikei University, Musashino, Tokyo 180-8633, Japan; Department of Electrical and Computer Engineering, International Islamic University Malaysia, Jalan Gombak, 53100 Kuala Lumpur, Malaysia",Ibaraki University;International Islamic University Malaysia;Seikei University,3,Japan;Malaysia,2,5,3,"Assuming time-stamp servers that we can trust exist everywhere in the Internet, we propose a cheat-proof protocol for real-time gaming that has the minimum latency. The assumptions are: 1) Time-stamp servers are available near each player that issue serially numbered time stamps. 2) There is no communication break down between the player and the nearest time-stamp server. By this protocol, each player sends its own action to the other player and also sends its hash to the nearest time-stamp server. The time-stamp server sends back to the player the signed hash with time and a serial number involved. The signature is an undeniable evidence of the action. The actions are checked if they are compatible with the hashes and the signed hashes are checked if they have the correct time and if the serial numbers are contiguous. This verification can be done as a batch after the game is finished. The latency in this protocol is only the packet traveling time from a player to another.",Cheat-proofing; Real-time network gaming; Time-stamp service,Break down; Cheat-proof; Cheat-proofing; Real-time network gaming; Serial number; Time stamps; Time-stamp; Traveling time; Internet protocols; Servers; Crack initiation
"Chen K.-T., Hong L.-W.",2,User identification based on game-play activity patterns,2007,31,"Academia Sinica, Taiwan","Academia Sinica, Taiwan",1,Taiwan,1,18,15,"Account hijacking is considered one of the most serious security problems in online games. A hijacker normally takes away valuable virtual items from the stolen accounts, and trades those items for real money. Even though account hijacking is not uncommon, there is currently no general solutions to determine whether an account has been hijacked. The game company is not aware of a hijack unless it is reported by the victim. However, it is usually too late - -usually a hijacker already took away anything valuable when a user finds that his/her account has been stolen. In this paper, we propose a new biometric for human identification based on users' game-play activities. Our main summary are two-fold: 1) we show that the idle time distribution is a representative feature of game players; 2) we propose the RET scheme, which is based on the KullbackLeibler divergence between idle time distributions, for user identification. Our evaluations shows that the RET scheme achieves higher than 90% accuracy with a 20-minute detection time given a 200-minute history size.",Account hijacking; Biometrical signatures; Kullback-Leibler divergence; Online games; User behavior,Activity patterns; Detection time; Game players; General solutions; Human identification; Idle time distribution; Kullback Leibler divergence; On-line games; Security problems; User behaviors; User identification; Behavioral research; Biometrics; Network security
"Schluessler T., Goglin S., Johnson E.",3,Is a bot at the controls? Detecting input data attacks,2007,26,"Intel Corporation, 2111 NE 25th Ave, Hillsboro, OR 97123, United States",Intel,1,USA,1,27,17,"The use of programmatically generated input data in place of human-generated input data poses problems for many computer applications in use today. Mouse clicks and keyboard strokes can automatically be generated to cheat in online games, or to perpetrate click fraud. The ability to discern whether input data was computationally generated instead of created by a human input device is therefore of paramount importance to these types of applications. This paper describes a method for detecting input data that was computationally modified or fabricated. This includes detecting data that was not directly generated by a physical human input device such as a keyboard or mouse. A prototype of this system was built on existing hardware and was shown to be effective at detecting attacks on a real application. This detection method is capable of addressing the majority of input-based attacks currently in use. When used in conjunction with a trusted peripheral, it offers a robust mechanism for ensuring a computer is not at the controls.",Cheat detection; Cheating; Online games; Security,Cheat detection; Click fraud; Detecting attacks; Detection methods; Input datas; Input devices; Mouse clicks; On-line games; Real applications; Computer peripheral equipment; Input output programs; Knobs; Typewriter keyboards; Computer applications
"Hui P., Yoneki E., Chan S.Y., Crowcroft J.",4,Distributed community detection in delay tolerant networks,2007,258,"University of Cambridge, Computer Laboratory, Cambridge CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,26,25,"Community is an important attribute of Pocket Switched Networks (PSN), because mobile devices are carried by people who tend to belong to communities. We analysed community structure from mobility traces and used for forwarding algorithms [12], which shows significant impact of community. Here, we propose and evaluate three novel distributed community detection approaches with great potential to detect both static and temporal communities. We find that with suitable configuration of the threshold values, the distributed community detection can approximate their corresponding centralised methods up to 90% accuracy. © 2007 ACM.",Delay tolerant networks; Distributed community detection; Network measurement; Social networks,Block codes; Internet; Mobile devices; Technical presentations; Telecommunication equipment; Wireless networks; Community structures; Delay tolerant networks; Distributed community detection; Forwarding algorithms; Network measurement; Significant impacts; Social networks; Switching circuits
"Gupta G.K., Raghavan S.V.",2,A framework for evolutionary networking,2007,0,"Network Systems Laboratory, Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai 600 036, India",IIT Madras,1,India,1,19,11,"In Computer-Communication Networks, addressing and routing have been fundamental issues that have challenged researchers - resulting in myriads of addressing and routing protocols. In recent times, self-configuration of nodes has become a necessity due to large number of networked devices and pervasive use of networks. Emergence of autonomic networks based on wireless mesh or ad hoc approach underline the need for self-configuration. Besides, success in sensor technology resulting in proliferation of wireless sensor networks is rapidly pushing the frontiers of self-configuration in large scale. The solutions reported hitherto in literature, has an interesting Addressing, Routing and Mobility (A.R.M.) issues have been tackled separately. In this work, we propose Protocol for Evolutionary Addressing (PEA) Framework, pronounced as ""P"", which solves the problem of addressing and routing in unison - thereby eliminating the need for separate routing algorithm. In PEA Framework, nodes assume addresses and self-configure the forwarding tables to reflect the changes in the network topology. Besides, PEA Framework enables self-configuration of nodes in a network so that the network naturally evolves (or readjusts) as it grows (or changes). We describe the framework, protocol, and evolution of network in addition to analyzing the time and message complexity of the protocol. © 2007 ACM.",Addressing; Next-gen network architecture; Self-configuration,Acoustoelectric effects; Ad hoc networks; Electric network topology; Internet; Internet protocols; Network architecture; Piezoelectric devices; Routing algorithms; Routing protocols; Sensors; Technical presentations; Wireless ad hoc networks; Wireless telecommunication systems; Ad hoc approaches; Addressing; Autonomic networks; Forwarding tables; Message complexity; Network topologies; Networked devices; Next-gen network architecture; Self-configuration; Sensor technologies; Wireless meshes; Wireless sensors; Wireless sensor networks
"Quoitin B., Iannone L., De Launois C., Bonaventure O.",4,Evaluating the benefits of the locator/identifier separation,2007,97,"UniversitŽ Catholique de Louvain (UCL), Belgium",Universite Catholique de Louvain,1,Belgium,1,28,22,"Since recent years, it has been recognized that the existing routing architecture of today's Internet is facing scalability problems. Single numbering space, multi-homing, and traffic engineering, are making routing tables of the default free zone to grow very rapidly. Recently, in order to solve this issue, it has been proposed to review the Internet addressing architecture by separating the end-systems identifiers' space and the routing locators' space. In this paper we review the most recent Locator/ID separation proposal and explore the benefits that such an architecture may bring. In particular, we evaluate the improvements that can be achieved in terms of routing tables' size reduction and traffic engineering. © 2007 ACM.",Addressing; Locator ID separation; Routing; Traffic engineering,International trade; Internet; Separation; Telecommunication networks; Addressing; End-systems; Locator ID separation; Multi-homing; Routing; Routing architectures; Routing tables; Scalability problems; Size reductions; Traffic engineering; Technical presentations
"Matos A., Sargento S., Aguiar R.",3,Embedding identity in mobile environments,2007,4,"Instituto de Telecomunica›es, Universidade de Aveiro, Campus Universit‡crio de Santiago, 3800-193 Aveiro, Portugal",Campus Universit‡crio de Santiago;Universidade de Aveiro,2,Portugal,1,15,13,"Recent trends bring Identity concepts into the application layer, although usually focusing in web environments. While this enables new solutions, interactions and paradigms at the application layer, the lower layers are neglected, and considered irrelevant for identity purposes. However, making Identity information available to the OSI stack enables enhanced protocols, which better integrate with A4C mechanisms, and provide better cross-layer integration. We present a solution to integrate identity information into all layers of the OSI stack, and enhance it with resolution mechanisms, enabling full fledged use of Identity by lower layers, such as transport and network. In particular, a new mobility paradigm can be created through an identity-dependent design. © 2007 ACM.",Identity management; Mobility management; Next generation networks,Internet; Internet protocols; Network layers; Security of data; Technical presentations; Wireless networks; Application layers; Cross layers; Identity informations; Identity management; Mobile environments; Mobility management; New solutions; Next generation networks; Recent trends; Web environments; Network management
"Rousseau F., Grunenberger Y., Untz V., Schiller E., Starzetz P., Theoleyre F., Heusse M., Alphand O., Duda A.",9,An architecture for seamless mobility in spontaneous wireless mesh networks,2007,1,"LIG - Grenoble Informatics Laboratory, Grenoble, France","Grenoble Informatics Laboratory,France",1,France,1,17,14,"In this paper, we consider spontaneous wireless mesh networks that can provide wide coverage connectivity to mobile nodes. Our mobility scheme builds upon separation between a persistent node identifier and its current address. When joining the mesh, a mobile node associates with a mesh router that updates a location service managed in the mesh as a distributed hash table. Mobility implies changing addresses while a node moves in the mesh. To keep the rate of location updates and correspondent node notifications low, the address of the new mesh router with which the mobile node is associated needs to be topologically close to the previous one. Thus, such a mobility scheme requires an addressing space with specific properties. We achieve this by defining an algorithm for constructing a pseudo-geographical addressing space: a few nodes know their exact locations and others estimate their relative positions to form a topologically consistent addressing space. Such an addressing space also enables scalable and low overhead routing in the wireless mesh - -we propose a trajectory based long distance ballistic geographical routing. © 2007 ACM.",Coordinate addressing space; Geographical routing,Internet; Internet protocols; Location; Mobile computing; Technical presentations; Wireless local area networks (WLAN); Wireless telecommunication systems; Coordinate addressing space; Correspondent nodes; Distributed hash tables; Geographical routing; Location services; Location updates; Long distances; Low overheads; Mesh routers; Mobile nodes; Mobility schemes; Node identifiers; Relative positions; Seamless mobilities; Trajectory-based; Wireless meshes; Wireless networks
"Atkinson R., Bhatti S., Hailes S.",3,Mobility as an integrated service through the use of naming,2007,7,"Extreme Networks, Santa Clara, CA 95051, United States; University of St. Andrews, School of Computer Science, St Andrews KY16 9SX, United Kingdom; University College London, Dept. of Computer Science, London WC1E 6BT, United Kingdom",University College London;University of St. Andrews,2,UK;USA,2,14,11,"As Mobile IP is deployed, so the requirements for its deployment evolve, reflecting the actual use of IP networks today. This includes the ability to use Mobile IP with IPsec, NATs and multi-homed networks. Furthermore, new requirements arise as people start to use IP in scenarios where the whole network is mobile (e.g. military networks), and where edge-networks may not be IP-enabled (e.g. sensor networks), but there is a requirement to interoperate across an IP network. In all these cases, rather than engineering retro-fits, creating an increasingly complex network landscape with possible unforeseen feature interactions and dependencies, we would prefer an integrated architectural solution. We present, from our ongoing work, a solution that would seem to meet all these needs, through a modified use of naming and addressing. Our proposal is incrementally deployable and existing core network routers & routing protocols need not change. © 2007 ACM.",Addressing; Identifier; Locator; Mobility; Naming; Routing,Internet; Internet protocols; Routing protocols; Sensor networks; Technical presentations; Telecommunication networks; Wireless networks; Addressing; Identifier; Locator; Mobility; Naming; Routing; Routers
"PitkŠnen M.J., Ott J.",2,Redundancy and distributed caching in mobile DTNs,2007,33,"Helsinki Institute of Physics, Technology Programme; Helsinki University of Technology, Networking Laboratory",Helsinki Institute of Physics;Helsinki University of Technology,2,Finland,1,33,29,"Delay tolerant networking (DTN) allows endpoints to exchange information in networks where end-to-end path may not exist at any given time. In this opportunistic model, routing and forwarding functionality in intermediate nodes enables data transfer following the store, carry, and forward paradigm. Thereby, even in sparsely populated settings, node-to-node contacts can be exploited for communications where network infrastructure does not exist or is not viable to use. Beyond plain message forwarding, the increasing amount of storage in modern devices enables nodes to hold messages for an extended period of time. This feature can then be utilized to create an opportunistic cooperative storage. Having established how to leverage DTN routing nodes for distributed content retrieval, caching, and storage in previous work, in this paper, we investigate applying redundancy schemes to improve message delivery and content retrieval. © 2007 ACM.",Application; Bundle; Caching; Delay tolerant; DTN; Mobile Ad-hoc networking; Storage,Application; Bundle; Caching; Delay tolerant; DTN; Mobile Ad-hoc networking; Storage; Ad hoc networks; Block codes; Data transfer; Internet; Quality assurance; Redundancy; Reliability; Technical presentations; Wireless networks
"Ohba Y., Das S., Dutta A.",3,Kerberized handover keying: A media-independent handover key management architecture,2007,16,"Toshiba America Research, Inc., P.O. Box 429, Piscataway, NJ 08854-4151, United States; Telcordia Technologies Inc., One Telcordia Drive, Piscataway, NJ 08854, United States",Inc.;Telcordia Technologies Inc.;Toshiba America Research,3,USA,1,18,18,"This paper proposes a media-independent handover key management architecture that uses Kerberos for secure key distribution among a server, an authenticator, and a mobile node. With the proposed architecture, signaling for key distribution is based on re-keying and is decoupled from re-authentication that requires EAP (Extensible Authentication Protocol) and AAA (Authentication, Authorization and Accounting) signaling similar to initial network access authentication. In this framework, the mobile node is able to obtain master session keys required for dynamically establishing the security associations with a set of authenticators without communicating with them before handover. By separating re-key operation from re-authentication, the proposed architecture is more optimized for proactive mode of operation. It is also optimized for reactive mode of operation by reversing the key distribution roles between the mobile node and the target access node. This paper discusses how the proposed architecture is applicable to the existing link-layer technologies including IEEE 802.11 and 802.16 and across multiple AAA domains. This paper also describes how Kerberos is bootstrapped from initial access authentication using an EAP method. © 2007 ACM.",Handover; Kerberos; Key distribution; Network access authentication; Signaling,Access control; Architecture; Authentication; Internet; Internet protocols; Mobile computing; Network architecture; Optical communication; Signaling; Standards; Technical presentations; Wireless networks; Access nodes; Handover; Ieee 802.11; Kerberos; Key distribution; Key managements; Key operations; Mobile nodes; Mode of operations; Network access authentication; Proposed architectures; Re-keying; Secure key distributions; Security associations; Session keys; Public key cryptography
"Khurri A., Vorobyeva E., Gurtov A.",3,Performance of host identity protocol on lightweight hardware,2007,18,"Helsinki Institute for Information Technology, Finland",Helsinki Institute for Information Technology,1,Finland,1,11,11,"The Host Identity Protocol (HIP) is being standardized by the IETF as a new solution for host mobility and multihoming in the Internet. HIP uses self-certifying public-private key pairs in combination with IPsec to authenticate hosts and protect user data. While there are three open-source HIP implementations, no experience is available with running HIP on lightweight hardware such as a PDA or a mobile phone. Limited computational power and battery lifetime of lightweight devices raises concerns if HIP can be used there at all. This paper presents performance measurements of HIP over WLAN on Nokia 770 Internet Tablet. It also provides comprehensive analysis of the results and makes suggestions on HIP suitability for lightweight clients. © 2007 ACM.",Diffie-Hellman key exchange; Encryption; HIP; Internet tablet; Mobility; PDA; Public key signature,Cryptography; Hand held computers; Internet; Personal digital assistants; Technical presentations; Telecommunication equipment; Telecommunication networks; Wireless local area networks (WLAN); Wireless telecommunication systems; Diffie-Hellman key exchange; Encryption; HIP; Internet tablet; Mobility; PDA; Public key signature; Internet protocols
"Gkantsidis C., Miller J., Rodriguez P.",3,Comprehensive view of a live network coding P2P system,2006,104,"Microsoft Research, 7 J J Thomson Avenue, Cambridge, CB3 0FB, United Kingdom",Microsoft,1,UK,1,32,28,"In this paper we present the first implementation of a P2P content distribution system that uses Network Coding. Using results from live trials with several hundred nodes, we provide a detailed performance analysis of such P2P system. In contrast to prior work, which mainly relies on monitoring P2P systems at particular locations, we are able to provide performance results from a variety of novel angles by monitoring all components in the P2P distribution.In particular, we show that Network Coding is practical in a P2P setting since it incurs little overhead, both in terms of CPU processing and IO activity, and it results in smooth, fast downloads, and efficient server utilization. We also study the importance of topology construction algorithms in real scenarios and study the effect of peers behind NATs and firewalls, showing that the system is surprisingly robust to large number of unreachable peers. Finally, we present performance results related to verifying network encoded blocks on-the-fly using special security primitives called Secure-Random- Checksums. Copyright 2006 ACM.",Content distribution; NAT issues; Network coding; Peer-to-peer; Secure random chesksums,Content based retrieval; Distributed computer systems; Random processes; Real time systems; Servers; Tracking (position); Content distribution systems; NAT issues; Network coding; Secure random chesksums; Network security
"Pang R., Paxson V., Sommer R., Peterson L.",4,Binpac: A yacc for writing application protocol parsers,2006,75,"Google, Inc., New York, NY, United States; International Computer Science Institute, Lawrence Berkeley National Laboratory, Berkeley, CA, United States; International Computer Science Institute, Berkeley, CA, United States; Princeton University, Princeton, NJ, United States",Google;University of California Berkeley;Princeton University,3,USA,1,46,23,"A key step in the semantic analysis of network traffic is to parse the traffic stream according to the high-level protocols it contains. This process transforms raw bytes into structured, typed, and semantically meaningful data fields that provide a high-level representation of the traffic. However, constructing protocol parsers by hand is a tedious and error-prone affair due to the complexity and sheer number of application protocols.This paper presents binpac, a declarative language and compiler designed to simplify the task of constructing robust and efficient semantic analyzers for complex network protocols. We discuss the design of the binpac language and a range of issues in generating efficient parsers from high-level specifications. We have used binpac to build several protocol parsers for the ""Bro"" network intrusion detection system, replacing some of its existing analyzers (handcrafted in C++), and supplementing its operation with analyzers for new protocols. We can then use Bro's powerful scripting language to express application-level analysis of network traffic in high-level terms that are both concise and expressive. binpac is now part of the open-source Bro distribution. Copyright 2006 ACM.",Parser generator; Protocol,Computational complexity; High level languages; Network protocols; Semantics; Specifications; Telecommunication traffic; Complex network protocols; Network traffic; Parser generators; Semantic analysis; Automata theory
"Katz-Bassett E., John J.P., Krishnamurthy A., Wetherall D., Anderson T., Chawathe Y.",6,Towards IP geolocation using delay and topology measurements,2006,156,"Dept. of Computer Science, Univ. of Washington, Seattle, United States; Univ. of Washington, Intel Research, United States; Google Inc.",Google;Intel,2,USA,1,29,16,"We present Topology-based Geolocation (TBG), a novel approach to estimating the geographic location of arbitrary Internet hosts. We motivate our work by showing that 1) existing approaches, based on end-to-end delay measurements from a set of landmarks, fail to outperform much simpler techniques, and 2) the error of these approaches is strongly determined by the distance to the nearest landmark, even when triangulation is used to combine estimates from different landmarks. Our approach improves on these earlier techniques by leveraging network topology, along with measurements of network delay, to constrain host position. We convert topology and delay data into a set of constraints, then solve for router and host locations simultaneously. This approach improves the consistency of location estimates, reducing the error substantially for structured networks in our experiments on Abilene and Sprint. For networks with insufficient structural constraints, our techniques integrate external hints that are validated using measurements before being trusted. Together, these techniques lower the median estimation error for our university-based dataset to 67 km vs. 228 km for the best previous approach. Copyright 2006 ACM.",Delay measurements; Geolocation; Network topology; Route measurements,Delay measurements; Network topology; Route measurements; Topology-based Geolocation (TBG); Constrained optimization; Data reduction; Delay circuits; Geographical regions; Parameter estimation; Internet protocols
"Ramaswamy R., Kencl L., Iannaccone G.",3,Approximate fingerprinting to accelerate pattern matching,2006,11,"University of Massachusetts, United States; Intel Research, Cambridge, United Kingdom",Intel;University of Massachusetts Amherst,2,UK;USA,2,21,16,"Pattern matching and analysis over network data streams is increasingly becoming an essential primitive of network monitoring systems. It is a fundamental part of most intrusion detection systems, worm detecting algorithms and many other anomaly detection mechanisms. It is a processing-intensive task, usually requiring to search for a large number of patterns simultaneously.We propose the technique of ""approximate fingerprinting"" to reduce the memory demands and significantly accelerate the pattern matching process. The method computes fingerprints of prefixes of the patterns and matches them against the input stream. It acts as a generic preprocessor to a standard pattern matching engine by ""clearing"" a large fraction of the input that would not match any of the patterns. The main contribution is the ""approximate"" characteristic of the fingerprint, which allows to slide the fingerprinting window through the packet at a faster rate, while maintaining a small memory footprint and low number of false positives. An improvement over a Bloom filter solution, a fingerprint can indicate which patterns are the candidate matches. We validate our technique by presenting the performance gain for the popular Snort intrusion detection system with the preprocessor in place. Copyright 2006 ACM.",Deep packet inspection; Fingerprint; Intrusion detection; Pattern matching,Deep packet inspection; Network monitoring systems; Small memory footprints; Worm detecting algorithms; Algorithms; Network security; Packet networks; Pattern matching; Storage allocation (computer); Intrusion detection
"Li X., Bian F., Crovella M., Diot C., Govindan R., Iannaccone G., Lakhina A.",7,Detection and identification of network anomalies using sketch subspaces,2006,120,"Computer Science Department, University of Southern California, Los Angeles, CA 90089, United States; Computer Science Department, Boston University, Boston, MA 02215, United States; Thomson Paris Research Lab., 46 Quai A. Le Gallo, 92648 Boulogne Cedex, France; Intel Research, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom","Boston University;Intel;Thomson,France;University of Southern California",4,France;UK;USA,3,12,10,"Network anomaly detection using dimensionality reduction techniques has received much recent attention in the literature. For example, previous work has aggregated netflow records into origin-destination (OD) flows, yielding a much smaller set of dimensions which can then be mined to uncover anomalies. However, this approach can only identify which OD flow is anomalous, not the particular IP flow(s) responsible for the anomaly. In this paper we show how one can use random aggregations of IP flows (i.e., sketches) to enable more precise identification of the underlying causes of anomalies. We show how to combine traffic sketches with a subspace method to (1) detect anomalies with high accuracy and (2) identify the IP flows(s) that are responsible for the anomaly. Our method has detection rates comparable to previous methods and detects many more anomalies than prior work, taking us a step closer towards a robust on-line system for anomaly detection and identification. Copyright 2006 ACM.",Anomaly detection; Defeat; Sketch; Subspace method,Identification (control systems); Internet protocols; Network security; Online systems; Robust control; Detection rates; Network anomalies; Origin-destination (OD) flows; Error detection
"Haeberlen A., Dischinger M., Gummadi K.P., Saroiu S.",4,Monarch: A tool to emulate transport protocol flowsover the internet at large,2006,11,"MPI for Software Systems, Rice University, Germany; MPI for Software Systems, Germany; University of Toronto, Canada",Rice University;University of Toronto,2,Canada;Germany,2,49,35,"This paper proposes Monarch, a novel tool that accurately emulates transport protocol flows from an end host controlled by its user to any other Internet host that responds to simple TCP, UDP, or ICMP packet probes. Since many Internet hosts and routers respond to such probes, Monarch can evaluate transport protocols, such as TCP Reno, TCP Vegas, and TCP Nice, over a large and diverse set of Internet paths. Current approaches to evaluating these protocols need control over both end hosts of an Internet path. Consequently, they are limited to a small number of paths between nodes in testbeds like PlanetLab, RON or NIMI. Monarch's ability to evaluate transport protocols with minimal support from the destination host enables many new measurement studies. We show the feasibility of using Monarch for three example studies: (a) understanding transport protocol behavior over network paths that are less explored by the research community, such as paths to cable and DSL hosts, (b) investigating the relative performance of different transport protocol designs, such as TCP Vegas and TCP Reno, and (c) testing protocol implementations under a wide range of experimental conditions. Copyright 2006 ACM.",Emulation; Network measurement; Transport protocols,Internet path; Network measurements; Transport protocol flows; Computer aided design; Internet; Motion planning; Optimization; User interfaces; Network protocols
"Sherwood R., Spring N.",2,Touring the internet in a TCP sidecar,2006,36,"Department of Computer Science, University of Maryland, College Park, United States",University of Maryland College Park,1,USA,1,33,28,"An accurate router-level topology of the Internet would benefit many research areas, including network diagnosis, inter-domain traffic engineering, and overlay construction. We present TCP Sidecar and Passenger, two elements of a system for router-level Internet topology discovery. Sidecar transparently injects measurement probes into non-measurement TCP streams, while Passenger combines TTL-limited probes with the often-ignored IP record route option. The combined approach mitigates problems associated with traceroute-based topology discovery, including abuse reports, spurious edge inference from multi-path routing, unresolved IP aliases, long network timeouts, and link discovery behind NATs and firewalls. We believe that we are the first mapping project to measure MPLS use with ICMP extensions and record route behavior when the TTL is not decremented. We are able to discover NATs when monitoring TCP connections that tunnel through them. In this paper, we present preliminary results for TCP Sidecar and Passenger on PlanetLab. Our experiments inject measurement probes into traffic generated both from the CoDeeN Web proxy project and from a custom web crawler to 166,745 web sites. Copyright 2006 ACM.",Network topology discovery; Passenger; Record route; Sidecar,Network topology discovery; Record route; Traffic engineering; Computer system firewalls; Multipath propagation; Routers; Telecommunication traffic; Topology; Transmission control protocol; Internet
"Shin S., Jung J., Balakrishnan H.",3,Malware prevalence in the KaZaA file-sharing network,2006,35,"ETRI, Daejeon, South Korea; Mazu Networks, Cambridge, MA, United States; MIT CSAIL, Cambridge, MA, United States",MIT,1,South Korea;USA,2,30,12,"In recent years, more than 200 viruses have been reported to use a peer-to-peer (P2P) file-sharing network as a propagation vector. Disguised as files that are frequently exchanged over P2P networks, these malicious programs infect the user's host if downloaded and opened, leaving their copies in the user's sharing folder for further propagation. Using a light-weight crawler built for the KaZaA file-sharing network, we study the prevalence of malware in this popular P2P network, the malware's propagation behavior in the P2P network environment and the characteristics of infected hosts. We gathered information about more than 500,000 files returned by the KaZaA network in response to 24 common query strings. With 364 signatures of known malicious programs, we found that over 15% of the crawled files were infected by 52 different viruses. Many of the malicious programs that we find active in the KaZaA P2P network open a backdoor through which an attacker can remotely control the compromised machine, send spam, or steal a user's confidential information. The assertion that these hosts were used to send spam was supported by the fact that over 70% of infected hosts were listed on DNS-based spam black-lists. Our measurement method is efficient: it enables us to investigate more than 30,000 files in an hour, identifying infected hosts without directly accessing their file system. Copyright 2006 ACM.",KaZaA; Peer-to-peer; Virus prevalence,Access control; Data acquisition; Distributed computer systems; File organization; Remote control; Spamming; File sharing networks; Peer-to-peer networks; Virus prevalence; Computer viruses
"Zerfos P., Meng X., Wong S.H.Y., Samanta V., Lu S.",5,A study of the short message service of a nationwide cellular network,2006,44,"Deutsche Telekom Laboratories, Berlin, Germany; UCLA Computer Science Dept., Los Angeles, CA 90095, United States",Deutsche Telekom,1,Germany;USA,2,21,18,"In recent years, cellular networks have experienced an astronomical increase in the use of Short Message Service (SMS), making it a popular communication means for inter-personal as well as content provider-to-person usage. Yet little is known about the traffic and message user behavior in real SMS systems. In this paper, we present a measurement study of SMS based on traces collected from a nationwide cellular carrier during a three-week period. We characterize message traffic at both the message level and the conversation thread level. We also examine the ""store-and-forward"" mechanism of SMS and present initial measurements on how messages are actually delivered. Copyright 2006 ACM.",Network measurements; Short message service; Traffic characterization,Content based retrieval; Electronic data interchange; Information dissemination; Real time systems; Telecommunication services; Telecommunication traffic; Content providers; Network measurements; Short Message Service (SMS); Traffic characterization; Message passing
"Augustin B., Cuvellier X., Orgogozo B., Viger F., Friedman T., Latapy M., Magnien C., Teixeira R.",8,Avoiding traceroute anomalies with Paris traceroute,2006,203,"UniversitŽ Pierre et Marie Curie - CNRS, Laboratoire LIP6, France; UniversitŽ Denis Diderot - CNRS, Laboratoire LIAFA, France; Ecole Polytechnique - CNRS, Laboratoire CREA, France",UniversitŽ Denis Diderot - CNRS;University Pierre and Marie Curie,2,France,1,16,9,"Traceroute is widely used, from the diagnosis of network problems to the assemblage of internet maps. However, there are a few serious problems with this tool, in particular due to the presence of load balancing routers in the network. This paper describes a number of anomalies that arise in nearly all traceroute-based measurements. We categorize them as ""loops"", ""cycles"", and ""diamonds"". We provide a new publicly-available traceroute, called Paris traceroute, which controls packet header contents to obtain a more precise picture of the actual routes that packets follow. This new tool allows us to find conclusive explanations for some of the anomalies, and to suggest possible causes for others. Copyright 2006 ACM.",Load balancing; Traceroute,Internet maps; Network routers; Traceroute; Traceroute-based measurements; Conformal mapping; Internet; Packet networks; Resource allocation; Routers; Network security
"Ballani H., Francis P., Ratnasamy S.",3,A measurement-based deployment proposal for IP anycast,2006,19,"Cornell University, Ithaca, NY, United States; Intel Research, Berkeley, CA, United States",Cornell University;Intel,2,USA,1,50,44,"Despite its growing use in critical infrastructure services, the performance of IP(v4) Anycast and its interaction with IP routing practices is not well understood. In this paper, we present the results of a detailed measurement study of IP Anycast. Our study uses a two-pronged approach. First, using a variant of known latency estimation techniques, we measure the performance of current commercially operational IP Anycast deployments from a large number (>20,000) of vantage points. Second, we deploy our own small-scale anycast service that allows us to perform controlled tests under different deployment and failure scenarios. To the best of our knowledge, our study represents the first large-scale evaluation of existing anycast services and the first evaluation of the behavior of IP Anycast under failure.We find that: (1) IP Anycast, if deployed in an ad-hoc manner, does not offer good latency-based proximity, (2) IP Anycast, if deployed in an ad-hoc manner, does not provide fast failover to clients, (3) IP Anycast typically offers good affinity to all clients with the exception of those that explicitly load balance traffic across multiple providers, (4) IP Anycast, by itself, is not effective in balancing client load across multiple sites. We thus propose and evaluate practical means by which anycast deployments can achieve good proximity, fast failover and control over the distribution of client load. Overall, our results suggest that an IP Anycast service, if deployed carefully, can offer good proximity, load balance, and failover behavior. Copyright 2006 ACM.",Affinity; BGP; Failover; IP anycast; Load distribution; Proximity,Ad hoc networks; Client server computer systems; Interactive computer systems; Quality of service; Routing algorithms; Telecommunication services; Anycast services; Client loads; Infrastructure services; Internet protocols
"Pucha H., Hu Y.C., Mao Z.M.",3,On the impact of research network based testbeds on wide-area experiments,2006,14,"School of ECE, Purdue University, West Lafayette, IN, United States; Dept. of EECS, University of Michigan, Ann Arbor, MI, United States",Purdue University;University of Michigan at Ann Arbor,2,USA,1,35,21,"An important stage of wide-area systems and networking research is to prototype a system to understand its performance when deployed in the real Internet. A key requirement of prototyping is that results obtained from the prototype experiments be representative of the behavior if the system were deployed over nodes connected to commercial ISPs. Recently, distributed testbeds such as PlanetLab and RON have become increasingly popular for performing wide-area experimentation. However, such testbeds typically consist of a significant fraction of nodes with connectivity to research and education networks which potentially hinder their usability in prototyping systems.In this paper, we investigate the impact of testbeds with connectivity to research and education networks on the applications and network services so that such testbeds can be leveraged for evaluation and prototyping. Specifically, we investigate when the representativeness of wide-area experiments deployed on such testbeds is affected by studying the routing paths that applications use over such testbeds. We then investigate how the representativeness of wide-area experiments is affected by studying the performance properties of such paths. We further measure the impact of using such testbeds on application performance via application case studies. Finally, we propose a technique that uses the currently available testbeds but reduces their bias by exposing applications evaluated to network conditions more reflective of the conditions in the commercial Internet. Copyright 2006 ACM.",Network characteristics; Testbeds,Network characteristics; Prototype experiments; Research networks; Wide-area systems; Distributed computer systems; Internet; Motion planning; Network management; Software prototyping; Wide area networks
"Raspall F., Sallent S., Yufera J.",3,Shared-state sampling,2006,22,"Dept. of Telematics, Technical University of Catalonia (UPC), Spain",Technical University of Catalonia (UPC),1,Spain,1,44,34,"We present an algorithm, Shared-State Sampling (S 3), for the problem of detecting large flows in high-speed networks. While devised with different principles in mind, (S 3) turns out to be a generalization of two existing algorithms tackling the same problem: Sample-and-Hold and Multistage Filters. S 3 is found to outperform its predecessors, with the advantage of smoothly adapting to the memory technology available, to the extent of allowing a partial implementation in DRAM. (S 3) exhibits mild tradeoffs between the different metrics of interest, which greatly benefits the scalability of the approach. The problem of detecting frequent items in streams appears in other areas. We also compare our algorithm with proposals appearing in the context of databases and regarded superior to the aforementioned. Our analysis and experimental results show that, among those evaluated, (S 3) is the most attractive and scalable solution to the problem in the context of high-speed network measurements. Copyright 2006 ACM.",Per-flow measurements; Scalability,Memory technology; Scalable solutions; Shared-state sampling; Algorithms; Dynamic random access storage; Flow measurement; Sampling; Scalability; Signal filtering and prediction; HIgh speed networks
"Kreibich C., Crowcroft J.",2,Efficient sequence alignment of network traffic,2006,8,"University of Cambridge, Computer Laboratory, United Kingdom",University of Cambridge,1,UK,1,13,9,"String comparison algorithms, inspired by methods used in bioinformatics, have recently gained popularity in network applications. In this paper we demonstrate the need for careful selection of alignment models if such algorithms are to yield the desired results when applied to network traffic. We introduce a novel variant of the Jacobson-Vo algorithm employing a flexible gap-minimising alignment model suitable for network traffic, and find that our software implementation outperforms the commonly used Smith-Waterman approach by a factor of 33 on average and up to 58.5 in the best case on a wide range of network protocols. Copyright 2006 ACM.",Sequence alignment; Sequence analysis; Traffic monitoring,Jacobson-Vo algorithms; Sequence alignment; Sequence analysis; Traffic monitoring; Algorithms; Bioinformatics; Information use; Mathematical models; Optimization; Telecommunication traffic
"Ma J., Levchenko K., Kreibich C., Savage S., Voelker G.M.",5,Unexpected means of protocol inference,2006,125,"Dept. of Computer Science and Engineering, University of California, San Diego, United States; University of Cambridge, Computer Laboratory, United Kingdom",University of California San Diego;University of Cambridge,2,UK;USA,2,23,18,"Network managers are inevitably called upon to associate network traffic with particular applications. Indeed, this operation is critical for a wide range of management functions ranging from debugging and security to analytics and policy support. Traditionally, managers have relied on application adherence to a well established global port mapping: Web traffic on port 80, mail traffic on port 25 and so on. However, a range of factors - including firewall port blocking, tunneling, dynamic port allocation, and a bloom of new distributed applications - has weakened the value of this approach. We analyze three alternative mechanisms using statistical and structural content models for automatically identifying traffic that uses the same application-layer protocol, relying solely on flow content. In this manner, known applications may be identified regardless of port number, while traffic from one unknown application will be identified as distinct from another. We evaluate each mechanism's classification performance using real-world traffic traces from multiple sites. Copyright 2006 ACM.",Application signatures; Network data mining; Protocol analysis; Relative entropy; Sequence analysis; Statistical content modeling; Traffic classification,Classification (of information); Data mining; Sequential machines; Statistical methods; Telecommunication traffic; Application signatures; Network data mining; Protocol analysis; Relative entropy; Sequence analysis; Statistical content modeling; Traffic classification; Network protocols
"Ribeiro B., Towsley D., Ye T., Bolot J.",4,Fisher information of sampled packets: An application to flow size estimation,2006,40,"Department of Computer Science, University of Massachusetts at Amherst, 140 Governors Drive, Amherst, MA 01003-9264, United States; Sprint ATL, One Adrian Court, Burlingame, CA 94010, United States",University of Massachusetts Amherst,1,USA,1,23,11,"Packet sampling is widely used in network monitoring. Sampled packet streams are often used to determine flow-level statistics of network traffic. To date there is conflicting evidence on the quality of the resulting estimates. In this paper we take a systematic approach, using the Fisher information metric and the CramŽr-Rao bound, to understand the contributions that different types of information within sampled packets have on the quality of flow-level estimates. We provide concrete evidence that, without protocol information and with packet sampling rate p = 0.005, any accurate unbiased estimator needs approximately 10 16 sampled flows. The required number of sampled flows drops to roughly 10 4 with the use of TCP sequence numbers. Furthermore, additional SYN flag information significantly reduces the estimation error of short flows. We present a Maximum Likelihood Estimator (MLE) that relies on all of this information and show that it is efficient, even when applied to a small sample set. We validate our results using Tier-1 Internet backbone traces and evaluate the benefits of sampling from multiple monitors. Our results show that combining estimates from several monitors is 50% less accurate than an estimate based on all samples. Copyright 2006 ACM.",Efficient estimator; Fisher information; Flow size distribution; Maximum likelihood estimation; Packet sampling; Probabilistic sampling,Efficient estimators; Flow size distribution; Packet sampling; Probabilistic sampling; Cramer-Rao bounds; Fisher information matrix; Internet; Maximum likelihood estimation; Probabilistic logics; Telecommunication traffic; Packet networks
"Pei D., Van Der Merwe J.",2,BGP convergence in virtual private networks,2006,11,"AT and T Labs. - Research, 180 Park Ave, Florham Park, NJ, United States",AT and T Labs,1,USA,1,14,12,"Multi-protocol label switching (MPLS) virtual private networks (VPNs) have had significant and growing commercial deployments. In this paper we present the first systematic study of BGP convergence in MPLS VPNs using data collected from a large tier-1 ISP. We combine several data sources to produce a methodology to accurately estimate routing convergence delays. We discovered an iBGP version of BGP path exploration, and show that the route invisibility problem occurs frequently and is one of the most significant contributing factors to BGP convergence delay in the VPNs we studied. We therefore propose and evaluate several configuration changes that can be employed to greatly improve the routing convergence time and minimize the connectivity disruption in the face of network changes. Copyright 2006 ACM.",BGP; MPLS VPN; Routing convergence,Convergence delay; Data collection; Data sources; Virtual private networks (VPN); Convergence of numerical methods; Data acquisition; Delay control systems; Optimization; Telecommunication networks; Virtual reality; Network protocols
"Zhang B., Ng T.S.E., Nandi A., Riedi R., Druschel P., Wang G.",6,"Measurement based analysis, modeling, and synthesis of the internet delay space",2006,78,"Rice University, United States; Max Planck Institute for Software Systems, Germany","Max Planck Institute,Germany;Rice University",2,Germany;USA,2,49,34,"Understanding the characteristics of the Internet delay space (i.e., the all-pairs set of static round-trip propagation delays among edge networks in the Internet) is important for the design of global-scale distributed systems. For instance, algorithms used in overlay networks are often sensitive to violations of the triangle inequality and to the growth properties within the Internet delay space. Since designers of distributed systems often rely on simulation and emulation to study design alternatives, they need a realistic model of the Internet delay space.Our analysis shows that existing models do not adequately capture important properties of the Internet delay space. In this paper, we analyze measured delays among thousands of Internet edge networks and identify key properties that are important for distributed system design. Furthermore, we derive a simple model of the Internet delay space based on our analytical findings. This model preserves the relevant metrics far better than existing models, allows for a compact representation, and can be used to synthesize delay data for simulations and emulations at a scale where direct measurement and storage are impractical. Copyright 2006 ACM.",Analysis; Distributed system; Internet delay space; Measurement; Modeling; Simulation; Synthesis,Computer aided design; Computer simulation; Delay control systems; Distributed computer systems; Mathematical models; Static analysis; Delay data; Design alternatives; Internet delay spaces; Internet
"Oliveira R., Zhang B., Pei D., Izhak-Ratzin R., Zhang L.",5,Quantifying path exploration in the internet,2006,40,"Computer Science Department, University of California, Los Angeles, United States; Computer Science Department, University of Arizona, United States; ATT Labs. Research, United States",AT and T Labs;University of Arizona;University of California Los Angeles,3,USA,1,30,24,"A number of previous measurement studies [10, 12, 17] have shown the existence of path exploration and slow convergence in the global Internet routing system, and a number of protocol enhancements have been proposed to remedy the problem [21, 15, 4, 20, 5]. However all the previous measurements were conducted over a small number of testing pre-fixes. There has been no systematic study to quantify the pervasiveness of BGP slow convergence in the operational Internet, nor there is any known effort to deploy any of the proposed solutions. In this paper we present our measurement results from identifying BGP slow convergence events across the entire global routing table. Our data shows that the severity of path exploration and slow convergence varies depending on where prefixes are originated and where the observations are made in the Internet routing hierarchy. In general, routers in tier-1 ISPs observe less path exploration, hence shorter convergence delays than routers in edge ASes, and prefixes originatd from tier-1 ISPs also experience less path exploration than those originated from edge ASes. Our data also shows that the convergence time of route fail-over events is similar to that of new route announcements, and significantly shorter than that of route failures, which confirms our earlier analytical results [19]. In addition, we also developed a usage-time based path preference inference method which can be used by future studies of BGP dynamics. Copyright 2006 ACM.",BGP; Path exploration; Routing convergence; Slow convergence,Internet routing systems; Operational Internet; Path exploration; Routing convergence; Convergence of numerical methods; Delay circuits; Failure analysis; Motion planning; Routing protocols; User interfaces; Internet
"Kammenhuber N., Luxenburger J., Feldmann A., Weikum G.",4,Web search clickstreams,2006,28,"Technische UniversitŠt MŸnchen, Germany; Max-Planck Institute of Informatics, Germany; Deutsche Telekom Laboratories, Germany","Deutsche Telekom;Max Planck Institute,Germany;TU Munich",3,Germany,1,18,13,"Search engines are a vital part of the Web and thus the Internet infrastructure. Therefore understanding the behavior of users searching the Web gives insights into trends, and enables enhancements of future search capabilities. Possible data sources for studying Web search behavior are either server-side logs or client-side logs. Unfortunately, current server-side logs are hard to obtain as they are considered proprietary by the search engine operators. Therefore we in this paper present a methodology for extracting client-side logs from the traffic exchanged between a large user group and the Internet. The added benefit of our methodology is that we do not only extract the search terms, the query sequences, and search results of each individual user but also the full clickstream, i.e., the result pages users view and the subsequently visited hyperlinked pages. We propose a finite-state Markov model that captures the user web searching and browsing behavior and allows us to deduce users' prevalent search patterns. To our knowledge, this is the first such detailed client-side analysis of clickstreams. Copyright 2006 ACM.",Clickstream; HTTP traces; Markov model; Web search,Finite automata; Hidden Markov models; Internet; Servers; Telecommunication links; User interfaces; Finite-state Markov models; Hyperlinked pages; Search patterns; Web search; Search engines
"Sundaresan K., Papagiannaki K.",2,The need for cross-layer information in access point selection algorithms,2006,39,"Georgia Tech., United States; Intel Research Cambridge, United Kingdom",Georgia Tech;Intel,2,UK;USA,2,8,7,"The low price of commodity wireless LAN cards and access points (APs) has resulted in the rich proliferation of high density WLANs in enterprise, academic environments, and public spaces. In such environments wireless clients have a variety of affiliation options that ultimately determine the quality of service they receive from the network. The state of the art mechanism behind such a decision typically relies on received signal strength, associating clients to that access point (AP) in their neighborhood that features the strongest signal. More intelligent algorithms have been further proposed in the literature. In this work we take a step back and look into the fundamental metrics that determine end user throughput in 802.11 wireless networks. We identify three such metrics pertaining to wireless channel quality, AP capacity in the presence of interference, and client contention. We modify the low level software functionality (firmware and microcode) of a commercial wireless adaptor to measure the necessary quantities. We then test, in a real testbed, the ability of each metric to capture end user throughput through a range of diverse network conditions. Our experimental results indicate that user affiliation decisions should be based on metrics that do not only reflect physical layer performance, or network occupancy, but also concretely capture MAC layer behavior. Based on the acquired insight, we propose a new metric that is shown to be highly accurate across all tested network scenarios. Copyright 2006 ACM.",Access point selection; Cross-layer; IEEE 802.11,Access point selection; Intelligent algorithms; Wireless adaptors; Wireless clients; Algorithms; Channel capacity; Enterprise resource planning; Information analysis; Intelligent agents; Wireless local area networks (WLAN); Access control
"Madhyastha H.V., Anderson T., Krishnamurthy A., Spring N., Venkataramani A.",5,A structural approach to latency prediction,2006,52,"University of Washington, United States; University of Maryland, United States; University of Massachusetts Amherst, United States",University of Maryland College Park;University of Massachusetts Amherst;University of Washington at Seattle,3,USA,1,21,17,"Several models have been recently proposed for predicting the latency of end to end Internet paths. These models treat the Internet as a black-box, ignoring its internal structure. While these models are simple, they can often fail systematically; for example, the most widely used models use metric embeddings that predict no benefit to detour routes even though half of all Internet routes can benefit from detours.In this paper, we adopt a structural approach that predicts path latency based on measurements of the Internet's routing topology, PoP connectivity, and routing policy. We find that our approach outperforms Vivaldi, the most widely used black-box model. Furthermore, unlike metric embeddings, our approach successfully predicts 65% of detour routes in the Internet. The number of measurements used in our approach is comparable with that required by black box techniques, but using traceroutes instead of pings. Copyright 2006 ACM.",Internet topology; Latency prediction; Route measurements,Internet paths; Internet topology; Latency prediction; Route measurements; Codes (symbols); Distributed computer systems; Embedded systems; Mathematical models; Motion planning; Routing algorithms; Internet
"Guo L., Tan E., Chen S., Xiao Z., Spatscheck O., Zhang X.",6,Delving into internet streaming media delivery: A quality and resource utilization perspective,2006,49,"Department of Computer Science and Engineering, Ohio State University, Columbus, OH 43210, United States; Department of Computer Science, George Mason University, Fairfax, VA 22030, United States; IBM T. J. Watson Research Center, 19 Skyline Drive, Hawthorne, NY 10532, United States; AT and T Labs.-Research, 180 Park Ave., Florham Park, NJ 07932, United States",AT and T Labs;George Mason University;IBM;Ohio State University,4,USA,1,33,17,"Modern Internet streaming services have utilized various techniques to improve the quality of streaming media delivery. Despite the characterization of media access patterns and user behaviors in many measurement studies, few studies have focused on the streaming techniques themselves, particularly on the quality of streaming experiences they offer end users and on the resources of the media systems that they consume. In order to gain insights into current streaming services techniques and thus provide guidance on designing resource-efficient and high quality streaming media systems, we have collected a large streaming media workload from thousands of broadband home users and business users hosted by a major ISP, and analyzed the most commonly used streaming techniques such as automatic protocol switch, Fast Streaming, MBR encoding and rate adaptation. Our measurement and analysis results show that with these techniques, current streaming systems these techniques tend to over-utilize CPU and bandwidth resources to provide better services to end users, which may not be a desirable and effective is not necessary the best way to improve the quality of streaming media delivery. Motivated by these results, we propose and evaluate a coordination mechanism that effectively takes advantage of both Fast Streaming and rate adaptation to better utilize the server and Internet resources for streaming quality improvement. Copyright 2006 ACM.",Multimedia streaming; Traffic analysis,Bandwidth; Internet; Pattern recognition; Quality of service; Telecommunication traffic; User interfaces; Internet streaming; Multimedia streaming; Streaming media delivery; Traffic analysis; Multimedia systems
"Mai J., Chuah C.-N., Sridharan A., Ye T., Zang H.",5,Is sampled data sufficient for anomaly detection?,2006,122,"University of California, Davis, 2064 Kemper Hall, Davis, CA 956165294, United States; Sprint Advanced Technology Labs., One Adrian Court, Burlingame, CA 94010, United States",University of California Davis,1,USA,1,20,17,"Sampling techniques are widely used for traffic measurements at high link speed to conserve router resources. Traditionally, sampled traffic data is used for network management tasks such as traffic matrix estimations, but recently it has also been used in numerous anomaly detection algorithms, as security analysis becomes increasingly critical for network providers. While the impact of sampling on traffic engineering metrics such as flow size and mean rate is well studied, its impact on anomaly detection remains an open question.This paper presents a comprehensive study on whether existing sampling techniques distort traffic features critical for effective anomaly detection. We sampled packet traces captured from a Tier-1 IP-backbone using four popular methods: random packet sampling, random flow sampling, smart sampling, and sample-and-hold. The sampled data is then used as input to detect two common classes of anomalies: volume anomalies and port scans. Since it is infeasible to enumerate all existing solutions, we study three representative algorithms: a wavelet-based volume anomaly detection and two portscan detection algorithms based on hypotheses testing. Our results show that all the four sampling methods introduce fundamental bias that degrades the performance of the three detection schemes, however the degradation curves are very different. We also identify the traffic features critical for anomaly detection and analyze how they are affected by sampling. Our work demonstrates the need for better measurement techniques, since anomaly detection operates on a drastically different information region, which is often overlooked by existing traffic accounting methods that target heavy-hitters. Copyright 2006 ACM.",Anomaly detection; Portscan; Sampling; Volume anomaly,Anomaly detection; Hypotheses testing; Traffic accounting methods; Traffic features; Algorithms; Data reduction; Internet protocols; Network management; Sampling; Telecommunication links; Network security
"Abu Rajab M., Zarfoss J., Monrose F., Terzis A.",4,A multifaceted approach to understanding the botnet phenomenon,2006,333,"Department of Computer Science, Johns Hopkins University, Baltimore, MD, United States",Johns Hopkins University,1,USA,1,24,15,"The academic community has long acknowledged the existence of malicious botnets, however to date, very little is known about the behavior of these distributed computing platforms. To the best of our knowledge, botnet behavior has never been methodically studied, botnet prevalence on the Internet is mostly a mystery, and the botnet life cycle has yet to be modeled. Uncertainty abounds. In this paper, we attempt to clear the fog surrounding botnets by constructing a multifaceted and distributed measurement infrastructure. Throughout a period of more than three months, we used this infrastructure to track 192 unique IRC botnets of size ranging from a few hundred to several thousand infected end-hosts. Our results show that botnets represent a major contributor to unwanted Internet traffic - 27% of all malicious connection attempts observed from our distributed darknet can be directly attributed to botnet-related spreading activity. Furthermore, we discovered evidence of botnet infections in 11% of the 800,000 DNS domains we examined, indicating a high diversity among botnet victims. Taken as a whole, these results not only highlight the prominence of botnets, but also provide deep insights that may facilitate further research to curtail this phenomenon. Copyright 2006 ACM.",Botnets; Computer security; Malware; Network security,Distributed computer systems; Information technology; Mathematical models; Tracking (position); Uncertainty analysis; Botnet phenomenon; Botnet-related spreading activity; Distributed computing platforms; Malware; Network security
"Brauckhoff D., Tellenbach B., Wagner A., May M., Lakhina A.",5,Impact of packet sampling on anomaly detection metrics,2006,148,"Department of Information Technology and Electrical Engineering, Swiss Federal Institute of Technology (ETH), Zurich, Switzerland; Department of Computer Science, Boston University, Boston, MA, United States",Boston University;ETH Zurich,2,Switzerland;USA,2,21,19,"Packet sampling methods such as Cisco's NetFlow are widely employed by large networks to reduce the amount of traffic data measured. A key problem with packet sampling is that it is inherently a lossy process, discarding (potentially useful) information. In this paper, we empirically evaluate the impact of sampling on anomaly detection metrics. Starting with unsampled flow records collected during the Blaster worm outbreak, we reconstruct the underlying packet trace and simulate packet sampling at increasing rates. We then use our knowledge of the Blaster anomaly to build a baseline of normal traffic (without Blaster), against which we can measure the anomaly size at various sampling rates. This approach allows us to evaluate the impact of packet sampling on anomaly detection without being restricted to (or biased by) a particular anomaly detection method.We find that packet sampling does not disturb the anomaly size when measured in volume metrics such as the number of bytes and number of packets, but grossly biases the number of flows. However, we find that recently proposed entropy-based summarizations of packet and flow counts are affected less by sampling, and expose the Blaster worm outbreak even at higher sampling rates. Our findings suggest that entropy summarizations are more resilient to sampling than volume metrics. Thus, while not perfect, sampling still preserves sufficient distributional structure, which when harnessed by tools like entropy, can expose hard-to-detect scanning anomalies. Copyright 2006 ACM.",Anomaly detection; Network traffic analysis; Sampling,Anomaly detection; Network traffic analysis; Packet sampling; Traffic data; Data reduction; Data structures; Packet networks; Sampling; Telecommunication traffic; Network security
"Stutzbach D., Rejaie R., Duffield N., Sen S., Willinger W.",5,On unbiased sampling for unstructured peer-to-peer networks,2006,63,"University of Oregon, United States; AT and T Labs - Research, United States",AT and T Labs;University of Oregon,2,USA,1,44,34,"This paper addresses the difficult problem of selecting representative samples of peer properties (eg degree, link bandwidth, number of files shared) in unstructured peer-to-peer systems. Due to the large size and dynamic nature of these systems, measuring the quantities of interest on every peer is often prohibitively expensive, while sampling provides a natural means for estimating system-wide behavior efficiently. However, commonly-used sampling techniques for measuring peer-to-peer systems tend to introduce considerable bias for two reasons. First, the dynamic nature of peers can bias results towards short-lived peers, much as naively sampling flows in a router can lead to bias towards short-lived flows. Second, the heterogeneous nature of the overlay topology can lead to bias towards high-degree peers.We present a detailed examination of the ways that the behavior of peer-to-peer systems can introduce bias and suggest the Metropolized Random Walk with Backtracking (MRWB) as a viable and promising technique for collecting nearly unbiased samples. We conduct an extensive simulation study to demonstrate that the proposed technique works well for a wide variety of common peer-to-peer network conditions. Using the Gnutella network, we empirically show that our implementation of the MRWB technique yields more accurate samples than relying on commonly-used sampling techniques. Furthermore, we provide insights into the causes of the observed differences. The tool we have developed, ion-sampler, selects peer addresses uniformly at random using the MRWB technique. These addresses may then be used as input to another measurement tool to collect data on a particular property. Copyright 2006 ACM.",Peer-to-peer; Sampling,Link bandwidth; Metropolized Random Walk with Backtracking (MRWB); Peer-to-peer systems; Unbiased sampling; Bandwidth; Computer simulation; Metropolitan area networks; Parameter estimation; Problem solving; Random processes; Distributed computer systems
"Kalafut A., Acharya A., Gupta M.",3,A study of malware in peer-to-peer networks,2006,38,"Computer Science Department, Indiana University, Bloomington, Bloomington, IN, United States",Indiana University,1,India;USA,2,21,12,"Peer-to-peer (P2P) networks continue to be popular means of trading content. However, very little protection is in place to make sure that the files exchanged in these networks are not malicious, making them an ideal medium for spreading malware. We instrument two different open source P2P networks, Limewire and OpenFT, to examine the prevalence of malware in P2P networks. Our results from over a month of data show that 68% of all downloadable responses in Limewire containing archives and executables contain malware. The corresponding number for OpenFT is 3%. Also, most infections are from a very small number of distinct malware. In particular, in Limewire, the top three most prevalent malware account for 99% of all the malicious responses. The corresponding number for OpenFT is 75%. We also investigate the sources of malicious responses. To our surprise, 28% of all malicious responses in Limewire come from private address ranges. In OpenFT, the top virus, which accounts of 67% of all the malicious responses, is served by a single host. Further, our study provides a useful insight into filtering malware: filtering downloads based on the most commonly seen sizes of the most popular malware could block a large portion of malicious files with a very low rate of false positives. While current Limewire mechanisms detect only about 6% of malware containing responses, our size based filtering would detect over 99% of them. Copyright 2006 ACM.",Filtering; Limewire; Malware; OpenFT; Peer-to-peer,Content based retrieval; Data reduction; Electronic data interchange; File organization; Signal filtering and prediction; Limewire mechanisms; Malware; Peer-to-peer (P2P) networks; Distributed computer systems
"Ma J., Dunagan J., Wang H.J., Savage S., Voelker G.M.",5,Finding diversity in remote code injection exploits,2006,19,"University of California, San Diego, United States; Microsoft Research",Microsoft;University of California San Diego,2,USA,1,29,23,"Remote code injection exploits inflict a significant societal cost, and an active underground economy has grown up around these continually evolving attacks. We present a methodology for inferring the phylogeny, or evolutionary tree, of such exploits. We have applied this methodology to traffic captured at several vantage points, and we demonstrate that our methodology is robust to the observed polymorphism. Our techniques revealed non-trivial code sharing among different exploit families, and the resulting phylogenies accurately captured the subtle variations among exploits within each family. Thus, we believe our methodology and results are a helpful step to better understanding the evolution of remote code injection exploits on the Internet. Copyright 2006 ACM.",Binary emulation; Bots; Malware classification; Phylogeny; Worms,Binary emulation; Code sharing; Malware classification; Phylogeny; Classification (of information); Codes (symbols); Computer science; Data acquisition; Telecommunication traffic; Security of data
"Krishnamurthy B., Wills C.E.",2,Generating a privacy footprint on the internet,2006,49,"AT and T Labs. - Research, United States; Worcester Polytechnic Institute, United States",AT and T Labs;Worcester Polytechnic Institute,2,USA,1,5,2,"As a follow up to characterizing traffic deemed as unwanted by Web clients such as advertisements, we examine how information related to individual users is aggregated as a result of browsing seemingly unrelated Web sites. We examine the privacy diffusion on the Internet, hidden transactions, and the potential for a few sites to be able to construct a profile of individual users. We define and generate a privacy footprint allowing us to assess and compare the diffusion of privacy information across a wide variety of sites. We examine the effectiveness of existing and new techniques to reduce this diffusion. Our results show that the size of the privacy footprint is a legitimate cause for concern across the sets of sites that we study. Copyright 2006 ACM.",Anonymity; Privacy; Web,Hidden transactions; Privacy footprints; Privacy information; Data privacy; Electronic data interchange; Information management; Telecommunication traffic; User interfaces; Web browsers; Internet
"Kannan J., Jung J., Paxson V., Koksal C.E.",4,Semi-automated discovery of application session structure,2006,44,"UC Berkeley, Berkeley, CA, United States; Mazu Networks, Cambridge, MA, United States; International Computer Science Institute, Lawrence Berkeley National Laboratory, Berkeley, CA, United States; EPFL, Luasanne, Switzerland","EPFL, Switzerland;University of California Berkeley",2,Switzerland;USA,2,42,21,"While the problem of analyzing network traffic at the granularity of individual connections has seen considerable previous work and tool development, understanding traffic at a higher level - the structure of user-initiated sessions comprised of groups of related connections - remains much less explored. Some types of session structure, such as the coupling between an FTP control connection and the data connections it spawns, have prespecified forms, though the specifications do not guarantee how the forms appear in practice. Other types of sessions, such as a user reading email with a browser, only manifest empirically. Still other sessions might exist without us even knowing of their presence, such as a botnet zombie receiving instructions from its master and proceeding in turn to carry them out. We present algorithms rooted in the statistics of Poisson processes that can mine a large corpus of network connection logs to extract the apparent structure of application sessions embedded in the connections. Our methods are semi-automated in that we aim to present an analyst with high-quality information (expressed as regular expressions) reflecting different possible abstractions of an application's session structure. We develop and test our methods using traces from a large Internet site, finding diversity in the number of applications that manifest, their different session structures, and the presence of abnormal behavior. Our work has applications to traffic characterization and monitoring, source models for synthesizing network traffic, and anomaly detection. Copyright 2006 ACM.",Anomaly detection; Application sessions; Traffic analysis,Error detection; Poisson distribution; Problem solving; Specifications; Statistical methods; Telecommunication traffic; Anomaly detection; Application sessions; High-quality information; Traffic analysis; Data structures
"Legout A., Urvoy-Keller G., Michiardi P.",3,Rarest first and choke algorithms are enough,2006,203,"I.N.R.I.A., Sophia Antipolis, France; Institut Eurecom, Sophia Antipolis, France",EURECOM,1,France,1,26,22,"The performance of peer-to-peer file replication comes from its piece and peer selection strategies. Two such strategies have been introduced by the BitTorrent protocol: the rarest first and choke algorithms. Whereas it is commonly admitted that BitTorrent performs well, recent studies have proposed the replacement of the rarest first and choke algorithms in order to improve efficiency and fairness. In this paper, we use results from real experiments to advocate that the replacement of the rarest first and choke algorithms cannot be justified in the context of peer-to-peer file replication in the Internet.We instrumented a BitTorrent client and ran experiments on real torrents with different characteristics. Our experimental evaluation is peer oriented, instead of tracker oriented, which allows us to get detailed information on all exchanged messages and protocol events. We go beyond the mere observation of the good efficiency of both algorithms. We show that the rarest first algorithm guarantees close to ideal diversity of the pieces among peers. In particular, on our experiments, replacing the rarest first algorithm with source or network coding solutions cannot be justified. We also show that the choke algorithm in its latest version fosters reciprocation and is robust to free riders. In particular, the choke algorithm is fair and its replacement with a bit level tit-for-tat solution is not appropriate. Finally, we identify new areas of improvements for efficient peer-to-peer file replication protocols. Copyright 2006 ACM.",BitTorrent; Choke algorithm; Peer-to-peer; Rarest first algorithm,Algorithms; Information dissemination; Information use; Network protocols; Network security; Robust control; Choke algorithms; Peer-to-peer systems; Rarest first algorithms; Client server computer systems
"Erramill V., Crovella M., Taft N.",3,An independent-connection model for traffic matrices,2006,38,"Dept. of Computer Science, Boston University, Boston, MA, United States; Intel Research, Berkeley, CA, United States",Boston University;Intel,2,USA,1,16,13,"A common assumption made in traffic matrix (TM) modeling and estimation is independence of a packet's network ingress and egress. We argue that in real IP networks, this assumption should not and does not hold. The fact that most traffic consists of two-way exchanges of packets means that traffic streams flowing in opposite directions at any point in the network are not independent. In this paper we propose a model for traffic matrices based on independence of connections rather than packets. We argue that the independent-connection (IC) model is more intuitive, and has a more direct connection to underlying network phenomena than the gravity model. To validate the IC model, we show that it fits real data better than the gravity model and that it works well as a prior in the TM estimation problem. We study the model's parameters empirically and identify useful stability properties. This justifies the use of the simpler versions of the model for TM applications. To illustrate the utility of the model we focus on two such applications: synthetic TM generation and TM estimation. To the best of our knowledge this is the first traffic matrix model that incorporates properties of bidirectional traffic. Copyright 2006 ACM.",Gravity; Independent-connection model; Modeling; Traffic matrix,Convergence of numerical methods; Mathematical models; Packet loss; Parameter estimation; Problem solving; Real time systems; Independent-connection models; Traffic matrix (TM) modeling; Traffic matrix model; Traffic streams; Telecommunication traffic
"Stutzbach D., Rejaie R.",2,Understanding churn in peer-to-peer networks,2006,487,"University of Oregon, United States",University of Oregon,1,USA,1,27,27,"The dynamics of peer participation, or churn, are an inherent property of Peer-to-Peer (P2P) systems and critical for design and evaluation. Accurately characterizing churn requires precise and unbiased information about the arrival and departure of peers, which is challenging to acquire. Prior studies show that peer participation is highly dynamic but with conflicting characteristics. Therefore, churn remains poorly understood, despite its significance.In this paper, we identify several common pitfalls that lead to measurement error. We carefully address these difficulties and present a detailed study using three widely-deployed P2P systems: an unstructured file-sharing system (Gnutella), a content-distribution system (BitTorrent), and a Distributed Hash Table (Kad). Our analysis reveals several properties of churn: (i) overall dynamics are surprisingly similar across different systems, (ii) session lengths are not exponential, (iii) a large portion of active peers are highly stable while the remaining peers turn over quickly, and (iv) peer session lengths across consecutive appearances are correlated. In summary, this paper advances our understanding of churn by improving accuracy, comparing different P2P file sharingdistribution systems, and exploring new aspects of churn. Copyright 2006 ACM.",BitTorrent; Churn; Gnutella; Kad; Peer-to-peer; Session length; Uptime,Active peers; Content-distribution system; Peer-to-Peer (P2P) systems; Computer aided design; Content based retrieval; Electronic data interchange; File organization; Information technology; Distributed computer systems
"Aggarwal S., Christofoli J., Mukherjee S., Rangarajan S.",4,Authority assignment in distributed multi-player proxy-based games,2006,3,"Department of Computer Science, Florida State University, Tallahassee, FL, United States; Center for Networking Research, Bell Laboratories, Holmdel, NJ, United States",Bell Labs;Florida State University,2,USA,1,23,18,"We present a proxy-based gaming architecture and authority assignment within this architecture that can lead to better game playing experience in Massively Multi-player Online games. The proposed game architecture consists of distributed game clients that connect to game proxies (referred to as ""communication proxies"") which forward game related messages from the clients to one or more game servers. Unlike proxy-based architectures that have been proposed in the literature where the proxies replicate all of the game state, the communication proxies in the proposed architecture support clients that are in proximity to it in the physical network and maintain information about selected portions of the game space that are relevant only to the clients that they support. Using this architecture, we propose an authority assignment mechanism that divides the authority for deciding the outcome of different actions/events that occur within the game between client and servers on a per action/event basis. We show that such division of authority leads to a smoother game playing experience by implementing this mechanism in a massively multi-player online game called RPGQuest. In addition, we argue that cheat detection techniques can be easily implemented at the communication proxies if they are made aware of the game-play mechanics. Copyright 2006 ACM.",Authority; Communication proxy; Distributed multi-player games; Games; Latency compensation; MMOG,Cheat detection; Distributed multi-player games; Game architecture; Game playing; Game servers; Game space; Massively multi-player online games; Physical network; Proposed architectures; Online systems; Three dimensional computer graphics; Communication
"Seligman M., Fall K., Mundur P.",3,Alternative custodians for congestion control in delay tolerant networks,2006,61,"Laboratory for Telecommunication Sciences, United States; Intel Research; Dept. of CSEE, UMBC, United States",Intel,1,USA,1,14,9,"We approach the problem of handling storage congestion at store-and-forward (DTN) nodes by migrating stored data to neighbors. The proposed solution includes a set of algorithms to determine which messages should be migrated to which neighbors and when. It also includes an extension to the DTN custody transfer mechanism enabling a ""pull"" form of custody transfer where a custodian may request custody of a message from another custodian. This approach allows us to decouple the problem of storage allocation among a relatively proximal group of storage nodes from the overall problem of path selection across a larger network. Doing so admits the possibility of localized routing loops for some messages which has been shown to be desirable for avoiding some head-of-line blocking problems. We select eligible storage neighbors using a function of available storage and incident link characteristics. Using simulation, we evaluate this approach and show how migrating custodian storage in this fashion can improve message completion rate by as much as 48% for some storage-constrained DTN networks. Copyright 2006 ACM.",Delay tolerant network; Routing,Delay tolerant network; Path selection; Storage allocation; Delay tolerant networks (DTN); Messages; Computer simulation; Constraint theory; Data reduction; Network routing; Problem solving; Resource allocation; Algorithms; Data transfer rates; Message passing; Storage allocation (computer); Telecommunication links; Telecommunication networks; Congestion control (communication)
"Che H., Su W., Lagoa C., Xu K., Liu C., Cui Y.",6,"An integrated, distributed traffic control strategy for the future internet",2006,4,"Department of Computer Science and Engineering, University of Texas at Arlington, TX, United States; Department of Electrical Engineering, Pennsylvania State University, PA, United States; Department of Computer Science, Tsinghau University, Beijing, China",Pennsylvania State University;Tsinghua University;University of Texas at Arlington,3,China;USA,2,16,12,"Due to the lack of a general theoretical foundation, today's distributed traffic control mechanisms developed at the networking layer, transport layer, and overlay are largely disintegrated. As a result, traffic control protocols developed at different layers may achieve conflicting design objectives and interact with one another in an unpredictable fashion. In this paper, we propose a novel strategy to tackle this issue. First, we propose a theoretical foundation for distributed traffic control. On the basis of this foundation, we then propose an integrated, multilayer, multi-domain traffic control structure. This structure makes it possible to develop traffic control protocols at different layers, possessing the following nice features: (1) they achieve non-conflicting design objectives; (2) they enable rich service quality features, including Quality-of-Service (QoS), Traffic Engineering (TE), and Fast Failure Recovery (FFR); (3) they lead to highly scalable, globally stable and optimal control; (4) they can deal with network diversities and tussles among administrative domains; (5) they allow effective control of dynamically generated overlay networks. The proposed strategy only makes two assumptions about the Internet architecture, i.e., the ability to support multiple domains and multi-path forwarding. As a result, the proposed strategy can be applied to the existing or any future Internet architectures for which these two assumptions hold. Copyright 2006 ACM.",Distributed traffic control; Fast failure recovery; Quality of service; Traffic engineering,Computer architecture; Internet protocols; Network architecture; Network management; Quality of service; Distributed traffic control; Fast Failure Recovery (FFR); Internet architecture; Traffic control protocols; Traffic Engineering (TE); Congestion control (communication)
"Fletcher R.D.S., Graham T.C.N., Wolfe C.",3,Plug-replaceable consistency maintenance for multiplayer games,2006,3,"School of Computing, Queen's University, Kingston, ON K7L 3N6, Canada",Queens University,1,Canada,1,10,8,"Consistency maintenance of replicated data in multiplayer games is a challenging issue due to the performance constraints of real-time interactive applications. We present an approach which separates game logic from consistency maintenance code through the use of reusable, plug-replaceable concurrency control and consistency maintenance (CCCM) modules. Using plug-replaceable consistency maintenance strategies also permits rapid comparisons of multiple approaches, which facilitates experimentation. We conduct a case study to illustrate how multiple consistency maintenance strategies can be applied without changing the original game code. Copyright 2006 ACM.",Consistency maintenance; Multiplayer game; Workspace model,Consistency maintenance; Interactive applications; Multiplayer game; Multiplayer games; Performance constraints; Replicated data; Concurrency control; Maintenance
"Li Z., Chen Y., Beach A.",3,Towards scalable and robust distributed intrusion alert fusion with good load balancing,2006,45,"Department of Electrical Engineering and Computer Science, Northwestern University, 2145 Sheridan Road, Evanston, IL 60208, United States",Northwestern University,1,USA,1,37,31,"Traffic anomalies and distributed attacks are commonplace in today's networks. Single point detection is often insufficient to determine the causes, patterns and prevalence of such events. Most existing distributed intrusion detection systems (DIDS) rely on centralized fusion, or distributed fusion with unscalable communication mechanisms. In this paper, we propose to build a DIDS based on the emerging decentralized location and routing infrastructure: distributed hash table (DHT). We embed the intrusion symptoms into the DHT dimensions so that alarms related to the same intrusion (thus with similar symptoms) will be routed to the same sensor fusion center (SFC) while evenly distributing unrelated alarms to different SFCs. This is achieved through careful routing key design based on: 1) analysis of essential characteristics of four common types of intrusions: DoS attacks, port scanning, virus/worm infection and botnets; and 2) distribution and stability analysis of the popular port numbers and those of the popular source IP subnets in scans. We further propose several schemes to distribute the alarms more evenly across the SFCs, and improve the resiliency against the failures or attacks. Evaluation based on one month of DShield firewall logs (600 million scan records) collected from over 2200 worldwide providers show that the resulting system, termed Cyber Disease DHT (CDDHT), can effectively fuse related alarms while distributing unrelated ones evenly among the SFCs. It significantly outperforms the traditional hierarchical approach when facing large amounts of diverse intrusion alerts. Copyright 2006 ACM.",Alert fusion; Distributed hash tables; Distributed intrusion detection systems; Load balancing; Scalability,Computer viruses; Cybernetics; Distributed computer systems; Resource allocation; Robust control; Alert fusion; Distributed hash tables; Distributed intrusion detection systems (DIDS); Sensor fusion center (SFC); Intrusion detection
"Nakagawa M., Okamoto S., Kamada M., Yonekura T.",4,Flash movie authoring environment based on state diagram,2006,6,"Department of Computer and Information Sciences, Ibaraki University Hitachi, Japan; Faculty of Science and Technology, Seikei University, Japan",Ibaraki University;Seikei University,2,Japan,1,8,2,A tool for authoring interactive Flash movies is presented. Characters that play in a movie are modeled as object definitions in terms of state-transition diagrams. Each state has a picture and activities. The picture represents appearance of the character in that state. The activities can be selected out of a set of performances such as relocation of the character and generation of other characters. A transition is conditioned in terms of events such as mouse click and collision with other characters. The graphical editor of state-transition diagrams built in this tool is so easy to manipulate that even children can compose interactive Flash animations including video games. Copyright 2006 ACM.,Game authoring; Macromedia flash movies; State diagrams,Authoring environments; Flash animations; Flash movies; Graphical editors; Macromedia Flash; Mouse clicks; State diagram; State-transition diagrams; Video game; Graphic methods; Motion pictures
"Lukac M., Girod L., Estrin D.",3,Disruption tolerant shell,2006,12,"UCLA CENS, 3563 Boelter Hall, Los Angeles, CA 90095, United States; MIT CSAIL, 32 Vassar St., Cambridge, MA 02139, United States",MIT,1,USA,1,12,8,"Wireless network technology is being applied to a wide range of scientific and engineering problems and across a wide dynamic range of spatial scales. When node placement is constrained by the application (e.g, coupled to sensor placement needs), and can not rely on pre-existing infrastructure (e.g., cellular infrastructure or power-lines), such systems may experience erratic link qualities and intermittent node disconnection. These characteristics, combined with unpredictable environmental conditions, make it difficult to rely upon traditional end to end connections for regular high bandwidth data acquisition and for system management and configuration. We have implemented and deployed such a ""challenged network"" system of 50 nodes for use by seismologists along a part of the Mesoamerican Subduction Experiment (MASE) broadband seismic array, stretching 500 KM from Acapulco to Tampico through Mexico city. In addition to supporting Delay Tolerant data transfer of relatively high bandwidth seismic data, our system includes a reliable asynchronous remote shell interface (referred to as Disruption Tolerant Shell, DTS) to accomplish the management on these types of system. We present the implementation of this solution and its evaluation on a 13 node portion of the MASE network. Copyright 2006 ACM.",Ad-hoc networks; Delay tolerant networking; System management; Wireless sensor networks,Delay tolerant networking; Seismic data; System management; Broadband seismic arrays; Disruption Tolerant Shell (DTS); Seismologists; Ad hoc networks; Bandwidth; Constraint theory; Data acquisition; Data transfer; Problem solving; Network architecture; Network management; Wireless sensor networks
"Beverly R., Sollins K., Berger A.",3,SVM learning of IP address structure for latency prediction,2006,17,"MIT CSAIL, United States; MIT/Akamai, United States",MIT,1,USA,1,19,13,"We examine the ability to exploit the hierarchical structure of Internet addresses in order to endow network agents with predictive capabilities. Specifically, we consider Support Vector Machines (SVMs) for prediction of round-trip latency to random network destinations the agent has not previously interacted with. We use kernel functions to transform the structured, yet fragmented and discontinuous, IP address space into a feature space amenable to SVMs. Our SVM approach is accurate, fast, suitable to on-line learning and generalizes well. SVM regression on a large, randomly collected data set of 30,000 Internet latencies yields a mean prediction error of 25ms using only 20% of the samples for training. Our results are promising for equipping end-nodes with intelligence for service selection, user-directed routing, resource scheduling and network inference. Finally, feature selection analysis finds that the eight most significant IP address bits provide surprisingly strong discriminative power. Copyright 2006 ACM.",IP networks; Latency; Machine learning; Prediction; SVM,Feature selection analysis; Kernel functions; Network inference; Resource scheduling; Artificial intelligence; Computer networks; Data acquisition; Resource allocation; Scheduling; Support vector machines; Internet protocols
"Zhang Y., Chen L., Chen G.",3,Globally synchronized dead-reckoning with local lag for continuous distributed multiplayer games,2006,17,"College of Computer Science, Zhejiang University, Hangzhou 310027, China; School of Computer Science and IT, University of Nottingham, Nottingham NG8 1BB, United Kingdom",University of Nottingham;Zhejiang University,2,China;UK,2,15,9,"Dead-Reckoning (DR) is an effective method to maintain consistency for Continuous Distributed Multiplayer Games (CDMG). Since DR can filter most unnecessary state updates and improve the scalability of a system, it is widely used in commercial CDMG. However, DR cannot maintain high consistency, and this constrains its application in highly interactive games. With the help of global synchronization, DR can achieve higher consistency, but it still cannot eliminate before inconsistency. In this paper, a method named Globally Synchronized DR with Local Lag (GS-DR-LL), which combines local lag and Globally Synchronized DR (GS-DR), is presented. Performance evaluation shows that GS-DR-LL can effectively decrease before inconsistency, and the effects increase with the lag. Copyright 2006 ACM.",Consistency; Continuous replicated application; Dead-reckoning; Distributed multi-player games; Local lag,Dead reckoning; Distributed multi-player games; Global synchronization; Interactive games; Performance evaluation; Synchronization
"Chen L.-J., Yu C.-H., Sun T., Chen Y.-C., Chu H.-H.",5,A hybrid routing approach for opportunistic networks,2006,73,"Academia Sinica, Taiwan; National Taiwan University, Taiwan; UCLA, United States",National Taiwan University,1,Taiwan;USA,2,30,22,"With wireless networking technologies extending into the fabrics of our working and operating environments, proper handling of intermittent wireless connectivity and network disruptions is of significance. As the sheer number of potential opportunistic application continues to surge (i.e. wireless sensor networks, underwater sensor networks, pocket switched networks, transportation networks, and etc.), the design for an effective routing scheme that considers and accommodates the various intricate behaviors observed in an opportunistic network is of interest and remained desirable. While previous solutions use either replication or coding techniques to address the challenges in opportunistic networks, the tradeoff of these two techniques only make them ideal under certain network scenarios. In this paper, we propose a hybrid scheme, named H-EC, to deal with a wide variety of opportunistic network cases. H-EC is designed to fully combine the robustness of erasure coding based routing techniques, while preserving the performance advantages of replication techniques. We evaluate H-EC against other similar strategies in terms of delivery ratio and latency, and find that H-EC offers robustness in worst-case delay performance cases while achieving good performance in small delay performance cases. We also discuss the traffic overhead issues associated with H-EC as compared to other schemes, and present several strategies that can potentially alleviate the traffic overhead of H-EC schemes. Copyright 2006 ACM.",Erasure coding; Hybrid approach; Opportunistic networks; Routing,Erasure coding; Hybrid approach; Opportunistic networks; Routing techniques; Traffic overhead; Underwater sensor networks; Robustness (control systems); Telecommunication traffic; Wireless networks; Network management; Packet networks; Signal encoding; Wireless sensor networks; Network routing
"Huang L., Garofalakis M., Hellerstein J., Joseph A., Taft N.",5,Toward sophisticated detection with distributed triggers,2006,20,"UC Berkeley, United States; Intel Research Berkeley, United States",Intel;University of California Berkeley,2,USA,1,18,16,"Recent research has proposed efficient protocols for distributed triggers, which can be used in monitoring infrastructures to maintain system-wide invariants and detect abnormal events with minimal communication overhead. To date, however, this work has been limited to simple thresholds on distributed aggregate functions like sums and counts. In this paper, we present our initial results that show how to use these simple threshold triggers to enable sophisticated anomaly detection in near-real time, with modest communication overheads. We design a distributed protocol to detect ""unusual traffic patterns"" buried in an Origin-Destination network flow matrix that: a) uses a Principal Components Analysis decomposition technique to detect anomalies via a threshold function on residual signals [10]; and b) efficiently tracks this threshold function in near-real time using a simple distributed protocol.In addition, we speculate that such simple thresholding can be a powerful tool for a variety of monitoring tasks beyondthe one presented here, and we propose an agenda to explore additional sophisticated applications. Copyright 2006 ACM.",Anomaly detection; Distributed triggers; PCA,Anomaly detection; Distributed triggers; Network flow matrix; Threshold function; Distribution functions; Network protocols; Principal component analysis; Real time systems; Telecommunication traffic; Intrusion detection
"Chen A., Muntz R.R.",2,Peer clustering: A hybrid approach to distributed virtual environments,2006,16,"University of California, Los Angeles, 3285 Boelter Hall, Los Angeles, CA 90095, United States; University of California, Los Angeles, 3277 Boelter Hall, Los Angeles, CA 90095, United States",University of California Los Angeles,1,USA,1,18,16,"This paper proposes a hybrid architecture for distributed virtual environments, utilizing servers alongside peer-to-peer components. Current research into peer-based systems seeks to alleviate resource constraints, but it largely ignores a number of difficult problems, from bootstrapping and persistence to user authentication and system security (i.e., cheat resistance). This work proposes a hybrid architecture that turns the massive scale of the system from a problem into an asset, while still providing the features essential to a distributed virtual environment. Peers work together to distribute the workload, allowing redundant peer clusters to overcome failures and detect unacceptable behavior. The goal is to reduce cost and significantly increase the size of the concurrent user base while providing equivalent levels of robustness, persistence, and security. Simulations show that the hybrid architecture can handle massive populations. Copyright 2006 ACM.",Hybrid architecture; MMO; Peer-to-peer,Distributed Virtual Environments; Hybrid approach; Hybrid architectures; Peer to peer; Resource Constraint; System security; User authentication; Adaptive filtering; Authentication; Cost reduction; Virtual reality; Distributed computer systems
"Van Der Merwe J., Cepleanu A., D'Souza K., Freeman B., Greenberg A., Knight D., Mcmillan R., Moloney D., Mulligan J., Nguyen H., Nguyen M., Ramarajan A., Saad S., Satterlee M., Spencer T., Toll D., Zelingher S.",17,Dynamic connectivity management with an intelligent route service control point,2006,30,"AT and T Labs, United States",AT and T Labs,1,USA,1,11,10,"Increased use of demanding network applications, as well as the increase of unwanted network traffic in the form of DDoS attacks, are putting new pressures on service providers to meet the expectations of customers in terms of network availability and performance. Providers are expected to deal with potential problems in near real-time fashion. Further, many of these demanding application, such as VoIP and online gaming, are very sensitivity to even small periods of disruption. In this work we therefore specifically focus on dynamic connectivity management, which we broadly define as the ability to dynamically manage how and where traffic flows across a network. Because it is intimately involved with how traffic flows through the network, BGP would be an ideal candidate for many of these management tasks. Unfortunately, BGP is itself a complicated protocol and up to now the prospect of using it to perform routine management tasks has not been considered a feasible approach. In this paper we show how the simplification introduced by a centralized Intelligent Route Service Control Point (IRSCP) that allows route selection to be performed outside the routers and also allows such route selection to be informed by external network intelligence, address this quandary. We present several examples of connectivity management tasks that can benefit from our approach. We describe our trial implementation of the IRSCP and show how our approach raise the level of abstraction, allowing operators to focus on what functions need to be performed, rather than getting bogged down with how to perform them. Copyright 2006 ACM.",BGP; Connectivity management; Route; Routing control,Intelligent Route Service Control Point (IRSCP); Network traffic; Online gaming; Routing control; Animation; Online systems; Telecommunication industry; Telecommunication traffic; Web services; Network management
"Roughan M., Zhang Y.",2,Privacy-preserving performance measurements,2006,7,"School of Mathematical Science, University of Adelaide, SA 5005, Australia; Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712, United States",University of Adelaide;University of Texas at Austin,2,Australia;USA,2,21,10,"Internet performance is an issue of great interest, but it is not trivial to measure. A number of commercial companies try to measure this, as does RIPE, and many individual Internet Service Providers. However, all are hampered in their efforts by a fear of sharing such sensitive information. Customers make decision about ""which provider"" based on such measurements, and so service providers certainly do not want such data to be public (except in the case of the top provider), but at the same time, it is in everyones' interest to have good metrics in order to reduce the risk of large network problems, and to test the effect of proposed network improvements.This paper shows that it is possible to have your cake, and eat it too. Providers (and other interested parties) can make such measurements, and compute Internet-wide metrics securely in the knowledge that their private data is never shared, and so cannot be abused. Copyright 2006 ACM.",Management; Measurement; Network; Performance; Privacy-preserving data-mining; Secure distributed computation,Computer networks; Data mining; Decision making; Information dissemination; Internet service providers; Performance measurements; Privacy-preserving data-mining; Secure distributed computation; Data privacy
"Machiraju S., Veitch D.",2,A Measurement-Friendly Network (MFN) architecture,2006,11,"Sprint Advanced Technology Labs (ATL), Burlingame, CA, United States; Dept. of Electrical and Electronic Engineering, University of Melbourne, Australia",University of Melbourne,1,Australia;USA,2,23,20,"Using active Techniques to measure networks, that is by injecting probe packets, has proved to be quite challenging for properties beyond simple end-to-end delay and loss. Some of the greatest difficulties have resulted from our inability to design techniques robust to multi-hop queueing effects. This difficulty is only compounded by the need to keep measurements non-intrusive, that is to minimally affect ongoing data flows. In this paper, we show that novel network primitives based on hop-dependent priority queueing are very effective in addressing these challenges. By enabling these primitives, network operators can perform a variety of active measurements accurately. Such measurement-friendliness results from many factors including ease of applying fundamentally single-hop methods, better measurement capabilities, and easier clock synchronization. Other advantages of our architecture include ease of deployment, simplicity, low overhead and generality, i.e., no constraints on scheduling policies for data packets. We also discuss the challenges faced, for example, in coping with small but unavoidable inaccuracies and with exposing the primitives to end-users. Copyright 2006 ACM.",Active measurement; Measurement-friendly network; MFN; Priority queueing; Probing,Computational methods; Data flow analysis; Local area networks; Packet networks; Queueing networks; Clock synchronization; Data packets; Network operators; Queueing effects; Network architecture
"Teh J., Cheok A.D.",2,Poultry.Internet and Internet Pajama: Novel systems for remote haptic interaction,2006,3,"Mixed Reality Lab., Interactive and Digital Media Network, National University of Singapore, Singapore 117574, Singapore",National University of Singapore,1,Singapore,1,3,2,"In this paper, we present novel systems supporting remote interactions between humans and also between humans and animals. We developed interfaces which supports non-verbal modes of communication. We introduce the Poultry.Internet system, a remote multi-modal human-pet interaction system. This system allows humans to remotely touch their pet using a system interconnected through the Internet. We also present the Internet Pajama, a wearable suit which allows parents to interact with their child. The aim of the system is to allow parents to hug their child while they are not at home. Copyright 2006 ACM.",Haptic; Intimate computing; Network interaction; Remote interaction,Haptic interactions; Interaction systems; Intimate computing; Multi-modal; Network interaction; Remote interactions; Animals; Communication; Hosiery manufacture; Internet
"Prieto A.G., Stadler R.",2,Adaptive distributed monitoring with accuracy objectives,2006,13,"KTH Royal Institute of Technology, Sweden",KTH Royal Institute of Technology,1,Sweden,1,14,11,"We present A-GAP, a novel protocol for continuous monitoring of network state variables, which aims at achieving a given monitoring accuracy with minimal overhead. Network state variables are computed from device counters using aggregation functions, such as SUM, AVERAGE and MAX. The accuracy objective is expressed as the average estimation error. A-GAP is decentralized and asynchronous to achieve robustness and scalability. It executes on an overlay that interconnects management processes on the devices. On this overlay, the protocol maintains a spanning tree and updates the network state variables through incremental aggregation. It dynamically configures local filters that control whether an update is sent towards the root of the tree. It reduces the overhead by attempting to minimize the maximum processing load over all management processes. We evaluate A-GAP through simulation using an ISP topology and real traces. The results show that we can effectively control the trade-off between accuracy and protocol overhead, that the overhead can be reduced significantly by allowing small errors, and that an accurate estimation of the error distribution can be provided in real-time. Copyright 2006 ACM.",Adaptive systems; Distributed management; Large-scale distributed systems; Real-time monitoring,Distributed management; Error distribution; Estimation errors; Network state variables; Real time monitoring; Adaptive systems; Digital filters; Function evaluation; Interconnection networks; Measurement errors; Network protocols; Optimization; Network management
"Chen K.-T., Lei C.-L.",2,Network game design: Hints and implications of player interaction,2006,20,"Institute of Information Science, Academia Sinica, Taiwan; Department of Electrical Engineering, National Taiwan University, Taiwan",Institute of Information Science;National Taiwan University,2,Taiwan,1,20,13,"While psychologists analyze network game-playing behavior in terms of players' social interaction and experience, understanding user behavior is equally important to network researchers, because how users act determines how well network systems, such as online games, perform. To gain a better understanding of patterns of player interaction and their implications for game design, we analyze a 1, 356-million-packet trace of ShenZhou Online, a mid-sized commercial MMORPG. This work is dedicated to draw out hints and implications of player interaction patterns, which is inferred from network-level traces, for online games. We find that the dispersion of players in a virtual world is heavy-tailed, which implies that static and fixed-size partitioning of game worlds is inadequate. Neighbors and teammates tend to be closer to each other in network topology. This property is an advantage, because message delivery between the hosts of interacting players can be faster than between those of unrelated players. In addition, the property can make game playing fairer, since interacting players tend to have similar latencies to their servers. We also find that participants who have a higher degree of social interaction tend to play much longer, and players who are closer in network topology tend to team up for longer periods. This suggests that game designers could increase the ""stickiness"" of games by encouraging, or even forcing, team playing. Copyright 2006 ACM.",Design recommendations; Internet measurement; MMO-RPG; Online games; Overlay networks; Social interaction,Design recommendations; Internet measurement; MMO-RPG; On-line games; Social interactions; Behavioral research; Design; Electric network topology; Interactive computer graphics; Internet; Overlay networks; Trace analysis; Virtual reality; Online systems
"Ng T.S.E., Yan H.",2,Towards a framework for network control composition,2006,6,"Department of Computer Science, Rice University, United States; Department of Computer Science, Carnegie Mellon University, United States",Carnegie Mellon University;Rice University,2,USA,1,6,5,"IP networks nowadays perform many functions in addition to best-effort datagram forwarding. These functions are typically achieved via an ad hoc combination of distributed protocols, database- and tool-driven router configurations, and manual configurations. In such an ad hoc system, it is difficult to anticipate any potential harmful interactions among the control functions or to provide any behavioral assurances.What kind of a framework will enable the composition of network control functions for sophisticated yet robust network control? Is it possible to have a framework in which each network control function is implemented as an independent application that runs on top of an operating platform, where the operating platform serves as an interface between the applications and the underlying network routers, provides services to facilitate the composition of applications, and ensures that network-wide operational invariants are not violated by the actions of the applications?Using an application example to illustrate, we discuss some challenges that underlie the design of such a potential operating platform. We hope this article will stimulate discussions on more principled approaches for network control composition. Copyright 2006 ACM.",Control; Network management; Robustness,Ad hoc systems; Distributed protocols; Network control functions; Ad hoc networks; Database systems; Interfaces (computer); Network protocols; Network routing; Routers; Network management
"Wang J., Hamadeh L., Kesidis G., Miller D.J.",4,"Polymorphic worm detection and defense: System design, experimental methodology, and data resources",2006,11,"Departments of Ee and CS and E, Penn State University, University Park, PA 16802, United States",Pennsylvania State University,1,USA,1,19,13,"The polymorphic variety of Internet worms presents a formidable challenge to network intrusion detection and methods designed to extract payload signatures for worm containment. Recently, several systems, including Earlybird and Polygraph, have been proposed, based on efficient processing of payloads to extract signatures that are either explicitly indicative of an attack (exploit code strings) or which have unusual statistical character (content prevalence, address dispersion) consistent with worm activity. While these works are seminal, these systems have limitations that affect accuracy of the extracted signatures and/or practicability of the system's deployment. Earlybird's signature extraction is fragile to polymorphism, while Polygraph makes assumptions about data availability and the accuracy of front-end flow classification. This method also possesses high complexity.We propose a new method which, fundamentally, integrates header-based multidimensional flow clustering as front-end processing, with content sifting (signature extraction) performed, separately, solely on each cluster in the (small) subset of identified suspicious clusters. Front-end clustering improves purity of the (separate) signature pools and also reduces complexity. We apply a ""suffix tree"" approach to signature extraction, gleaning both length and frequency information. We demonstrate efficacy of our approach on a (background) trace taken from a /24 in Taiwan, which we salt with worm traffic based on two realistic polymorphic mechanisms that we propose. Since there is a dearth of public data for such testing, we have also made an anonymized version of this trace available, based on randomized headers and fingerprinted payloads. Copyright 2006 ACM.",Intrusion detection system; Network anomaly detection; Polymorphic worms; Worm signature extraction,Intrusion detection system; Network anomaly detection; Polymorphic worms; Worm signature extraction; Clustering algorithms; Computer worms; Data flow analysis; Electronic document identification systems; Internet; Systems analysis; Intrusion detection
"Lee H.-H., Sun C.-H.",2,Load-balancing for peer-to-peer networked virtual environment,2006,5,"Department of Computer Science and Information Engineering, National Taiwan University, #1 Roosevelt Rd. Sec. 4, Taipei, 106, Taiwan",National Taiwan University,1,Taiwan,1,16,14,"The trend of games is online games. Most MMORPGs (Massive Multi-user Online Role Playing Games) we can see today are based on client-server architecture. This causes some disadvantages as follows: the server is very expensive and the failure of the server fails the whole game. Besides, the vendor of a game need to provide several servers to allow more players playing at the same time, but players connect to different servers are in the different virtual environments. This paper provides a peer-to-peer architecture with dynamic status information distribution (DSID) mechanism for MMORPG to address the issues occurred in the client-server architecture. We hope to construct a low-cost and flexible architecture that allows all players to interact to each other in the same virtual environment. Copyright 2006 ACM.",Load-balancing; Networked virtual environment; Peer-to-peer,Client-server architectures; Flexible architectures; Information distributions; Load-Balancing; Mmorpgs; Multi-user; Networked virtual environments; On-line games; Peer to peer; Peer-to-peer architectures; Role-playing game; Virtual environments; Client server computer systems; Virtual reality; Servers
"Cooke E., Myrick A., Rusek D., Jahanian F.",4,Resource-aware multi-format network security data storage,2006,5,"Department of Electrical Engineering and Computer Science, University of Michigan, United States",University of Michigan at Ann Arbor,1,USA,1,10,8,"Internet security systems like intrusion detection and intrusion prevention systems are based on a simple input-output principle: they receive a high-bandwidth stream of input data and produce summaries of suspicious events. This simple model has serious drawbacks, including the inability to attach context to security alerts, a lack of detailed historical information for anomaly detection baselines, and a lack of detailed forensics information. Together these problems highlight a need for fine-grained security data in the shortterm, and coarse-grained security data in the long-term. To address these limitations we propose resource-aware multi-format security data storage. Our approach is to develop an architecture for recording different granularities of security data simultaneously. To explore this idea we present a novel framework for analyzing security data as a spectrum of information and a set of algorithms for collecting and storing multi-format data. We construct a prototype system and deploy it on darknets at academic, Fortune 100 enterprise, and ISP networks. We demonstrate how a hybrid algorithm that provides guarantees on time and space satisfies the short and long-term goals across a four month deployment period and during a series of large-scale denial of service attacks. Copyright 2006 ACM.",Anomaly classification; Anomaly detection; Darknet; Network-wide traffic analysis,Anomaly classification; Anomaly detection; Darknet; Network-wide traffic analysis; Algorithms; Computer crime; Internet; Intrusion detection; Network security; Resource allocation; Data storage equipment
"Shimomura T., Okamoto S., Kamada M., Yonekura T.",4,A game authoring tool based on character definition in terms of state-transition diagrams,2006,1,"Department of Computer and Information Sciences, Ibaraki University Hitachi, Japan; Faculty of Science and Technology, Seikei University, Japan",Ibaraki University;Seikei University,2,Japan,1,12,3,A tool for authoring dynamical animations and video games is presented. The logical behavior of characters such as its internal feeling and icon images representing its appearance is described as finite state machines in terms of the state-transition diagrams. The physical behavior is controlled by plug-in modules that can be optionally incorporated into the main body. An example video game is also presented. Copyright 2006 ACM.,Edutainment; Interactive animations; State-transition diagrams; Video games,Edutainment; Example videos; Finite state machines; Game authoring tool; Icon images; Interactive animations; Logical behavior; Physical behaviors; Plug-ins; State-transition diagrams; Video game; Graphic methods; Educational motion pictures
"Carrig B., Denieffe D., Murphy J.",3,A relative delay minimization scheme for multiplayer gaming in differentiated services networks,2006,1,"Institute of Technology, Carlow, Kilkenny Road, Carlow, Ireland; University College Dublin, Belfield, Dublin 4, Ireland",University College Dublin,1,Ireland,1,8,6,"Multiplayer gaming over the Internet continues to grow in popularity, despite a lack of Quality of Service (QoS) mechanisms. Future QoS-aware networks such as those based on the Differentiated Services (DiffServ) framework will provide an opportunity for gamers to enhance their game-playing experience. An important QoS metric for networked games is a user's delay relative to the delay of other users. In this paper, we propose a Relative Delay Minimization (RDM) algorithm for use in DiffServ environments. Simulation results are described and presented showing that the algorithm can reduce the Relative Delay Variation (RDV) between users in a DiffServ environment. Copyright 2006 ACM.",DiffServ; Network games; QoS; Relative delay,Differentiated services; Differentiated services network; DiffServ; Diffserv networks; Multi-player gaming; Networked games; QoS metric; Relative delay; Simulation result; Optimization; Routers; Quality of service
"Bertelsmeyer C., Koch E., Schirm A.H.",3,A new approach on wearable game design and its evaluation,2006,1,"University Bremen, Am Fallturm 1, 28359 Bremen, Germany",University of Bremen,1,Germany,1,15,4,"As technologies evolve and computer systems shrink to the size of matchboxes, also their field of application shifts in new directions. Our permanent companions, mobile phones, personal digital assistants and laptops, have made their contribution to dislocate our workplace from the little office to anywhere we want to work. A similar trend is happening in the field of video and computer entertainment. Mobile and location based games using wearable computers are the next step to drag us out of our homes, away from TV or computer screens, where we were used to play, and lead us into the new worlds of mixed realities. Since game platforms and interfaces change as well, we also have to redefine the way we create and design this sort of game. This paper displays the approach we chose to find a concept for an innovative wearable game and how to consider the characteristics of today's wearable hardware when developing a game. Moreover it will give an outline of the game, that our approach led us to. Copyright 2006 ACM.",Design principles; Game theory; Mobile games; Pervasive computing; Physical environment games; Ubiquitous computing,Design principles; Mobile games; Pervasive computing; Physical environment games; Physical environments; Design; Laptop computers; Personal digital assistants; Service oriented architecture (SOA); Telecommunication equipment; Ubiquitous computing; Wearable computers; Game theory
"Kulkarni P., Nazeeruddin M., Mcclean S.",3,Building a controlled delay assured forwarding class in differentiated services networks,2006,2,"Faculty of Engineering, University of Ulster, Coleraine, United Kingdom",University of Ulster,1,UK,1,15,13,"Several Active Queue Management (AQM) based solutions have been proposed to enable service differentiation in the DiffServ Assured Forwarding (AF) class(es). Most of these solutions, however, provide throughput guarantees only. This paper proposes a new queue management approach called PAQMAN-DS which provides quantitative controlled delay guarantees to delay sensitive applications in the AF class. The proposed approach is based on predicting the future state of the queue and requires specification of only a single parameter (target delay) per hop. Performance evaluation of PAQMAN-DS through ns-2 simulations reveals that it regulates the delay around the target mark on a per-hop basis, discriminates in favour of IN contract traffic and simultaneously achieves high link utilization. Copyright 2006 ACM.",Assured forwarding; Controlled delay service; DiffServ; PAQMAN,Congestion control (communication); Data transfer; Network management; Parameter estimation; Queueing networks; Active Queue Management (AQM); Differentiated services networks; Web services
"Verkaik P., Spatscheck O., Van Der Merwe J., Snoeren A.C.",4,PRIMED: Community-of-interest-based DDoS mitigation,2006,15,"University of California, San Diego, United States; AT and T Labs-Research, United States",AT and T Labs;University of California San Diego,2,USA,1,25,21,"Most existing distributed denial-of-service (DDoS) mitigation proposals are reactive in nature, i.e., they are deployed to limit the damage caused by attacks after they are detected. In contrast, we present PRIMED, a proactive approach to DDoS mitigation that allows users to specify to their ISP a priori their (dis)interest in receiving traffic from particular network entities. Our solution employs communities of interest (COIs) to capture the collective past behavior of remote network entities and uses them to predict future behavior. Specifically, ISPs construct a network-wide bad COI that contains network entities who exhibited unwanted behavior in the past, and per-customer good COIs containing remote network entities that have previously engaged in legitimate communication with the customer. Our system uses these derived sets together with customer-specific policies to proactively mitigate DDoS attacks using existing router mechanisms. Indeed, preliminary lab testing shows that our approach is deployable on modern edge router platforms without degrading packet forwarding performance. This implies that our approach offers DDoS protection at a truly massive scale, i.e., every customer access link. Simulation results show that our approach improves protection against 91 - 93% of actual DDoS attacks on real customers - -providing complete protection against 38 - 53% of such attacks - -while slightly increasing vulnerability in only 5 - 7% of attacks. Copyright 2006 ACM.",Communities of interest; Denial of service,Communities of interest (COI); Degrading packets; Denial of service (DoS); Router mechanisms; Computer crime; Data privacy; Routers; Software testing; Telecommunication traffic; User interfaces; Telecommunication services
"Lee G.J., Poole L.",2,Diagnosis of TCP overlay connection failures using bayesian networks,2006,14,"Computer Science and AI Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, United States; Department of Computer Science, Princeton University, Princeton, NJ 08544, United States",MIT;Princeton University,2,USA,1,11,10,"When failures occur in Internet overlay connections today, it is difficult for users to determine the root cause of failure. An overlay connection may require TCP connections between a series of overlay nodes to succeed, but accurately determining which of these connections has failed is difficult for users without access to the internal workings of the overlay. Diagnosis using active probing is costly and may be inaccurate if probe packets are filtered or blocked. To address this problem, we develop a passive diagnosis approach that infers the most likely cause of failure using a Bayesian network modeling the conditional probability of TCP failures given the IP addresses of the hosts along the overlay path. We collect TCP failure data for 28.3 million TCP connections using data from the new Planetseer overlay monitoring system and train a Bayesian network for the diagnosis of overlay connection failures. We evaluate the accuracy of diagnosis using this Bayesian network on a set of overlay connections generated from observations of CoDeeN traffic patterns and find that our approach can accurately diagnose failures. Copyright 2006 ACM.",Bayesian networks; Fault diagnosis; Passive diagnosis; Planetseer; TCP overlay path diagnosis,Bayesian networks; Computer simulation; Computer system recovery; Data acquisition; Internet; Telecommunication traffic; Conditional probability; Passive diagnosis; Planetseer; TCP overlay path diagnosis; Transmission control protocol
"Liang D., Boustead P.",2,Using local lag and timewarp to improve performance for real life multi-player online games,2006,3,"Telecommunications and Information Technology Research Institete, University of Wollongong, Australia",University of Wollongong,1,Australia,1,6,6,"When developing distributed server games it is important to consider consistency of decisions made at different servers as well as the response time experienced by the players. This paper examines two approaches that are commonly used to improve the consistency of distributed servers: local lag and timewarp. Local lag can be used to remove inconsistencies, however it can significantly increase the response time experienced by players. Timewarp on the other hand allows inconsistencies to exist, for a short time, before rolling back time and correcting the decisions in the servers. This paper aims to produce a platform to experimentally evaluate the effect of each of these on players. To do this we have developed a distributed version of Quake III that includes both timewarp and rollbacks. In this paper we present the first set of results obtained with this test-bed. These results examine the performance, based upon the score in the game, of computer-controlled players, or ""bots"". We present results on how varying both local-lag, and network lag (with and without timewarp) effect ""bot"" performance. With the results it shows that the combinative use of local lag and timewarp could achieve a similar effect of half reducing the network lag. We plan to use the test-bed to test the effect on real players at a later stage. Copyright 2006 ACM.",Consistency; Local lag; Networked games; Paradox; Quake 3; Timewarp,Distributed servers; Multi-player online games; Network lag; Networked games; Response time; Computer control systems; Earthquakes; Response time (computer systems); Test facilities; Servers
"Lu F., Parkin S., Morgan G.",3,Load balancing for massively multiplayer online games,2006,34,"Newcastle University, School of Computing Science, United Kingdom",Newcastle University,1,UK,1,22,16,"Supporting thousands, possibly hundreds of thousands, of players is a requirement that must be satisfied when delivering server based online gaming as a commercial concern. Such a requirement may be satisfied by utilising the cumulative processing resources afforded by a cluster of servers. Clustering of servers allow great flexibility, as the game provider may add servers to satisfy an increase in processing demands, more players, or remove servers for routine maintenance or upgrading. If care is not taken, the way processing demands are distributed across a cluster of servers may hinder such flexibility and also hinder player interaction within a game. In this paper we present an approach to load balancing that is simple and effective, yet maintains the flexibility of a cluster while promoting player interaction. Copyright 2006 ACM.",Augmented; Design; Experimentation; H.5.1 [information interfaces and presentation]: multimedia information systems - artificial; Measurement; Performance; Virtual realities C.2.4 [distributed systems]: distributed applications,Distributed applications; Distributed systems; Experimentation; H.5.1 [information interfaces and presentation]: Multimedia information systems-artificial; Performance; Information systems; Interactive computer graphics; Parallel architectures; Virtual reality; Servers
Fujinoki H.,1,On the support for heterogeneity in networked virtual environment,2006,2,"Department of Computer Science, Southern Illinois University Edwardsville, Edwardsville, IL 62026-1656, United States",Southern Illinois University,1,USA,1,6,3,"This paper presents our ongoing research activity to design and implement a framework for an networked virtual environment (NVE) that efficiently supports both hardware and software heterogeneity. In the proposed framework, three new techniques, application layer multicast transmission-rate pruning, fairness control for delay-sensitive activities (token-bucket algorithm) and bandwidth compensation by a combination of server-side and client-side dead reckoning, are designed, proposed and integrated in the new framework that supports heterogeneous networks and end systems. Copyright 2006 ACM.",Event synchronization; Heterogeneous networks; Multicast; Networked virtual environments,Application-layer multicast; Dead reckoning; Delay sensitive; End systems; Event synchronization; Fairness control; Hardware and software; Multicasts; Networked virtual environments; Research activities; Heterogeneous networks; Multicasting; Virtual reality
"Mogul J.C., Arlitt M.",2,SC2D: An alternative to trace anonymization,2006,13,"HP Labs, Palo Alto, CA 94304, United States; HP Labs, University of Calgary, Palo Alto, CA 94304, Canada",HP Labs;University of Calgary,2,Canada;USA,2,18,15,"Progress in networking research depends crucially on applying novel analysis tools to real-world traces of network activity. This often conflicts with privacy and security requirements; many raw network traces include information that should never be revealed to others.The traditional resolution of this dilemma uses trace anonymization to remove secret information from traces, theoretically leaving enough information for research purposes while protecting privacy and security. However, trace anonymization can have both technical and non-technical drawbacks.We propose an alternative to trace-to-trace transformation that operates at a different level of abstraction. Since the ultimate goal is to transform raw traces into research results, we say: cut out the middle step. We propose a model for shipping flexible analysis code to the data, rather than vice versa. Our model aims to support independent, expert, prior review of analysis code. We propose a system design using layered abstraction to provide both ease of use, and ease of verification of privacy and security properties. The system would provide pre-approved modules for common analysis functions. We hope our approach could significantly increase the willingness of trace owners to share their data with researchers. We have loosely prototyped this approach in previously published research. Copyright 2006 ACM.",Trace anonymization,Analysis code; Common analysis functions; Layered abstraction; Trace anonymization; Abstracting; Codes (symbols); Computer networks; Data privacy; Data reduction; Systems analysis; Network security
"Lee S., Moon S., Kim J.",3,A network-adaptive transport scheme for haptic-based collaborative virtual environments,2006,9,"Networked Media Lab., Dept. of Info. and Comm., Gwangju Institute of Science and Technology (GIST), South Korea",Gwangju Institute of Science and Technology (GIST),1,South Korea,1,20,14,"In this paper, we design and implement a transport scheme for haptic interactions in CVEs (collaborative virtual environments). When interacting with haptic interfaces in the CVEs, network delay jitter and packet loss over the Internet may seriously degrade the user experience of haptic interactions. The existing transport schemes tailored for networked haptics claim that their schemes could improve the quality of networked haptic interaction. However, what seems to be lacking is that they do not focus on reducing the transmission rate and end-to-end delay of the haptic events. On the contrary, the proposed transport scheme reduces the transmission rate of haptic events by using network-adaptive aggregated packetization and the priority-based filtering. It also compensates the network delay jitter and loss in order to improve the haptic interaction quality by using haptic event error control and priority-based buffering scheme with low processing delay. According to the experimental results, the proposed transport scheme provides shorter playout delay and less transmission rate than those of the existing networked haptic transports. Copyright 2006 ACM.",Adaptive playout; Aggregated packetization; CVEs (collaborative virtual environments); Data filtering; FEC (forward error control); Haptic interactions; Network QoS; Prioritizing,Collaborative virtual environment; Data filtering; Forward error controls; Haptic interactions; Network QoS; Packetization; Adaptive control systems; Delay control systems; Elastic deformation; Jitter; Quality of service; Virtual reality; Haptic interfaces
"But J., Williams N., Zander S., Stewart L., Armitage G.",5,Automated network games enhancement layer - A proposed architecture,2006,4,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,25,24,"In this paper we present the design of the Automated Network Games Enhancement Layer (ANGEL), a novel architecture for meeting Quality of Service (QoS) requirements of real-time network game traffic across consumer broadband links. Consumer access links can become bottlenecks when faced with heterogeneous network traffic (e.g. simultaneous use of online games and peer-to-peer file sharing) and the online gaming experience can be significantly affected by bottleneck queuing. Implementing QoS on these links provides improvement by reducing latency and jitter. In our approach network servers automatically identify traffic that might benefit from QoS and then trigger provisioning of QoS by signaling network elements such as access routers. By placing intelligence within the network, QoS decisions can be transparently made for the game applications without imposing an additional processing cost at the access link router. Our system uniquely uses machine learning methods to perform traffic classification. Copyright 2006 ACM.","1.5 [pattern recognition]: general; C.2 [computer-communication networks]: [network architecture and design, network operations, distributed systems, internetworking]; Management; Performance","C.2 [computer-communication networks]: [network architecture and design, network operations, distributed systems, internetworking]; Computer communication networks; Distributed systems; Internetworking; Network operations; Computer architecture; Design; Distributed computer systems; Heterogeneous networks; Jitter; Learning systems; Mobile telecommunication systems; Network architecture; Pattern recognition systems; Quality of service; Routers; Servers; Signaling; Telecommunication traffic; Peer to peer networks"
"Chambers C., Feng W.-C., Feng W.-C.",3,Towards public server MMOs,2006,4,"Portland State University, United States",Portland State University,1,USA,1,14,10,"While massively multiplayer on-line games (MMOs) are enormously popular, their use of the client-server architecture causes them to suffer from scalability issues and high maintenance costs. In contrast, the public server architecture employed by most first-person shooter (FPS) games scales more easily by relying on user-supplied hosting and user-generated content, but lacks persistence between servers that is required in the MMO genre. This paper examines an architecture that leverages the resources of the public server approach to support a scalable, persistent MMO. Copyright 2006 ACM.",MMO; Online games,Client-server architectures; First person shooter; Maintenance cost; Massively multiplayer; On-line games; Scalability issue; Server architecture; User-generated content; Client server computer systems; Maintenance; Servers
"Breslau L., Chase C., Duffield N., Fenner B., Mao Y., Sen S.",6,VMScope: A virtual multicast VPN performance monitor,2006,4,"AT and T Research, United States; SBC Labs, United States; University of California San Diego, United States",AT and T Labs;University of California San Diego,2,USA,1,10,8,"The growth of one-to-many applications in enterprise networks is fueling the demand for VPNs to support multicast applications. The deployment of such a Multicast VPN service creates the need for appropriate management tools and techniques including performance monitoring, problem isolation and troubleshooting. In this paper we present the MVPN monitoring problem, identify requirements for solutions to the problem, and describe VMScope, a virtual MVPN performance monitor designed to facilitate provider monitoring and debugging of the MVPN service. Copyright 2006 ACM.",Multicast; Multicast VPN; Performance monitoring; Virtual private networks (VPN),Multicast applications; Performance monitoring; Virtual private networks (VPN); Computational methods; Metropolitan area networks; Multicasting; Problem solving; Program debugging; Web services; Network management
"Assiotis M., Tzanov V.",2,A distributed architecture for MMORPG,2006,38,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,9,8,"We present an approach to support Massively Multiplayer Online Role-Playing Games. Our proposed solution begins by splitting the large virtual world into smaller regions, each region handled by a different server. We present techniques and algorithms that (1) reduce the bandwidth requirements for both game servers and clients, (2) address consistency, hotspot, congestion and server failure problems typically found in MMORPG and (3) allow seamless interaction between players residing on areas handled by different servers. By implementing a simple game, Kosmos, we show the applicability of our approach as well as the relative performance benefits of designing new games using our architecture. Copyright 2006 ACM.",Distributed architecture; MMORPG; Multiplayer game,Bandwidth requirement; Distributed architecture; Failure problems; Game servers; Hot spot; Massively multiplayer; Multiplayer games; Relative performance; Role-playing game; Simple games; Virtual worlds; Interactive computer graphics; Virtual reality; Servers
"Boulanger J.-S., Kienzle J., Verbrugge C.",3,Comparing interest management algorithms for massively multiplayer games,2006,55,"School of Computer Science, McGill University, MontrŽal, QC, Canada",McGill University,1,Canada,1,20,12,"Broadcasting all state changes to every player of a massively multiplayer game is not a viable solution. To successfully overcome the challenge of scale, massively multiplayer games have to employ sophisticated interest management techniques that only send relevant state changes to each player. This paper compares the performance of different interest management algorithms based on measurements obtained in a real massively multiplayer game using human and computer-generated player actions. We show that interest management algorithms that take into account obstacles in the world reduce the number of update messages between players by up to a factor of 6, and that some computationally inexpensive tile-based interest management algorithms can approximate ideal visibility-based interest management at very low cost. The experiments also show that measurements obtained with computer-controlled players performing random actions can approximate measurements of games played by real humans, provided that the starting positions of the random players are chosen adequately. As the size of the world and the number of players of massively multiplayer games increases, adaptive interest management techniques such as the ones studied in this paper will become increasingly important. Copyright 2006 ACM.",Computer games; Distributed games; Interest management,Computer game; Interest managements; Low costs; Massively multiplayer games; Player action; Viable solutions; Algorithms; Computer control systems; Computer software; Cost reduction; Industrial management; Distributed computer systems
"Erman J., Arlitt M., Mahanti A.",3,Traffic classification using clustering algorithms,2006,417,"University of Calgary, 2500 University Drive NW, Calgary, Alta., Canada",University of Calgary,1,Canada,1,17,14,"Classification of network traffic using port-based or payload-based analysis is becoming increasingly difficult with many peer-to-peer (P2P) applications using dynamic port numbers, masquerading techniques, and encryption to avoid detection. An alternative approach is to classify traffic by exploiting the distinctive characteristics of applications when they communicate on a network. We pursue this latter approach and demonstrate how cluster analysis can be used to effectively identify groups of traffic that are similar using only transport layer statistics. Our work considers two unsupervised clustering algorithms, namely K-Means and DBSCAN, that have previously not been used for network traffic classification. We evaluate these two algorithms and compare them to the previously used AutoClass algorithm, using empirical Internet traces. The experimental results show that both K-Means and DBSCAN work very well and much more quickly then AutoClass. Our results indicate that although DBSCAN has lower accuracy compared to K-Means and AutoClass, DBSCAN produces better clusters. Copyright 2006 ACM.",Machine learning; Unsupervised clustering,Cluster analysis; Clustering algorithms; Cryptography; Distributed computer systems; Internet; Learning systems; Network traffic classification; Transport layer statistics; Unsupervised clustering; Telecommunication traffic
"Lee D.K., Moon S., Choi T., Jeong T.",4,Forensic analysis of autonomous system reachability,2006,0,"Division of Computer Science, KAIST, South Korea; ETRI, South Korea",KAIST,1,South Korea,1,17,14,"Security incidents have an adverse impact not only on end systems, but also on Internet routing, resulting in many out-of-reach prefixes. Previous work has looked at performance degradation in the data plane in terms of delay and loss. Also it has been reported that the number of routing updates increased significantly, which could be a reflection of increased routing instability in the control domain. In this paper, we perform a detailed forensic analysis of routing instability during known security incidents and present useful metrics in assessing damage in AS reachability. Any change in AS reachability is a direct indication of whether the AS had fallen victim to the security incident or not.We choose the Slammer worm attack in January, 2003, as a security incident for closer examination. For our forensic analysis, we use BGP routing data from RouteViews and RIPE. As a way to quantify AS reachability, we propose the following metrics: the prefix count and the address count. The number of unique prefixes in routing tables during the attack fluctuates greatly, but it does not represent the real scope of damage. We define the address count as the cardinality of the set of IP addresses an AS is responsible for either as an origin or transit AS, and observe how address counts changed over time. These two metrics together draw an accurate picture of how reachability to or through the AS had been affected. Though our analysis was done off-line, our methodology can be applied on-line and used in quick real-time assessment of AS reachability. Copyright 2006 ACM.",Address count; AS reachability; BGP; Prefix count; Security incidents,Address count; AS reachability; Prefix count; Routing instability; Security incidents; Computer worms; Data reduction; Internet protocols; Network routing; Real time systems; Security of data; Systems analysis
"Frei S., May M., Fiedler U., Plattner B.",4,Large-scale vulnerability analysis,2006,78,"Computer Engineering and Networks Laboratory, ETH Zurich, Switzerland",ETH Zurich,1,Switzerland,1,30,11,"The security level of networks and systems is determined by the software vulnerabilities of its elements. Defending against large scale attacks requires a quantitative understanding of the vulnerability lifecycle. Specifically, one has to understand how exploitation and remediation of vulnerabilities, as well as the distribution of information thereof is handled by industry.In this paper, we examine how vulnerabilities are handled in large-scale, analyzing more than 80,000 security advisories published since 1995. Based on this information, we quantify the performance of the security industry as a whole. We discover trends and discuss their implications. We quantify the gap between exploit and patch availability and provide an analytical representation of our data which lays the foundation for further analysis and risk management. Copyright 2006 ACM.",Business risk management; Disclosure date; Exploit; Intrusion detection; Patch; Security dynamics; Security exposure; Vulnerability lifecycle,Computer privacy; Distributed computer systems; Large scale systems; Risk management; Software reliability; Business risk management; Disclosure dates; Security dynamics; Security exposure; Vulnerability lifecycles; Intrusion detection
"Fritsch T., Ritter H., Schiller J.",3,CAN mobile gaming be improved?,2006,7,"Freie UniversitŠt Berlin, Takustrasse 9, D-14195 Berlin, Germany",Freie UniversitŠt Berlin,1,Germany,1,12,9,"The importance of mobile (phone) games is rapidly growing over the last years. One of the current evolutions is getting away from the pure solo content of the current games and creating possibilities to play together. However there are different ways to connect players in a mobile environment. With the growing interest comes the need for more efficient techniques to handle common issues like latency, data distribution and other requirements of multimedia real time applications. Those solutions should also provide viable ideas to other non-gaming related problem fields. This paper will introduce the CAN (Content Addressable Network) technique in the gaming sector. Therefore, we combine the very efficient CAN peer to peer strategy with a real time application (Conquer the tag). We will show how the addressed issues can be solved with our approach. Furthermore we will compare CAN to other P2P architectures like Pastry and Chord. Copyright 2006 ACM.",Advanced protocols and games; CAN; Games on mobile and resource-scarce devices; Mobile gaming; Multiplayer gaming; Peer to peer; Protocols for peer-to-peer networked games,Advanced protocols; Mobile gaming; Multi-player gaming; Networked games; Peer to peer; Peer-to-peer protocols; Distributed computer systems; Network protocols; Wireless networks
"Harrop W., Armitage G.",2,Modifying first person shooter games to perform real time network monitoring and control tasks,2006,3,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,39,34,"This paper describes how a first person shooter (FPS) game engine can be leveraged for monitoring and control of enterprise IP data networks. Network administration can then occur in the following manner: network events (such as port scans or packets hitting a darknet) are translated in real time to various changes in the 3D game world state. Network administrators, logged in as 'players', can then collaboratively detect anomalous network events using the visual and aural cues given by the game. Using the native interaction metaphors from within the game (such as shooting, using or healing) they can then instantiate network administration policy changes (such as network layer firewall rules) directly back onto the running network without the need for interactions with complicated command line interfaces. We explore the possibilities offered by modern 3D game engines to implement this scheme as a server-side 'mod'. Finally, we detail the modifications made to the open source game engine 'Cube' to allow both the visualisation of large amounts of live network data within a virtual environment and support interacting with this data to create network administration events. Copyright 2006 ACM.",3D; Game modification; Greynet; Intrusion detection; Network control; Network monitoring; NIDS; Real-time; Visualization,3D; 3D game engines; Command line interface; Darknet; Data network; Firewall rules; First person shooter games; Greynet; Interaction metaphors; Live networks; Monitoring and control; Network Administration; Network administrator; Network control; Open source game engine; Port scans; Real time; Real time network; Real time visualization; Virtual environments; Visualisation; Intrusion detection; Network layers; Virtual reality; Visualization; Three dimensional
"Keralapura R., Chuah C.-N., Fan Y.",3,Optimal strategy for graceful network upgrade,2006,5,"University of California, Davis, United States",University of California Davis,1,USA,1,10,8,"One of the critical aspects of network management that has not received much attention is network upgrade. This paper addresses the question of ""how to add new nodes and links into an operational network in a graceful manner so that the perceived network performance from the perspective of existing customers does not deteriorate?"". We propose a two-phase framework to find the optimal upgrade strategy: first, deciding what nodes should be added and how they should be connected to existing topology, and second, deciding the ideal sequence to add these new nodes and links. We formulate the first phase as a non-linear optimization problem and the second phase as a multistage dynamic programming problem. Through a numerical example, we show the feasibility of this framework and demonstrate the advantages of our multistage approach in determining an ideal upgrade sequence. The results also highlight the significance of incorporating network performance (for ex, service availability) into the two-phase framework to achieve minimal impact to existing customers. Copyright 2006 ACM.",Graceful network upgrade; Multi-stage network upgrade,Dynamic programming problems; Nonlinear optimization; Optimization problems; Computational methods; Dynamic programming; Network architecture; Optimization; Problem solving; Web services; Network management
"Wang Y., Want C.-Y., Martonosi M., Peh L.-S.",4,Transport layer approaches for improving idle energy in challenged sensor networks,2006,9,"Princeton University, United States; Intel Corporation",Princeton University,1,USA,1,24,21,"Today, the study of energy efficient networking solutions in sensor networks has been focusing on networks with always-on connectivity between communication end-points and short link delays. However, these assumptions are not true for networks with very long propagation delays such as Underwater Sensor Networks (UWSNs) or networks with intermittent connectivity. In such networks, idle energy expenditure, which includes energy spent on node rendezvous and idle waiting, becomes significant, and renders conventional data transport inefficient. In this work, we leverage characteristics that are unique to such networks, i.e., long-delay tolerability and low duty-cycles, to improve idle energy efficiency. To this end, we propose a staged transport protocol, aDapTN, that adopts a store-and-forward transport paradigm with an asynchronous wakeup scheme. We evaluate the idle energy efficiency of our approach through both analysis and simulation. Our results show that aDapTN achieves much better idle energy efficiency than conventional approaches. The increased latency is a function of parameters for node rendezvous, which can be adjusted depending on the application. Copyright 2006 ACM.",Asynchronous wakeup; Challenged sensor networks; DTN; Idle energy; Transport protocol,Asynchronous wakeup; Challenged sensor networks; Idle energy; Transport protocol; Underwater Sensor Networks (UWSN); Duty cycle; Nodes; Computer simulation; Data transfer; Energy efficiency; Parameter estimation; Carrier communication; Electric power utilization; Electromagnetic wave propagation; Telecommunication links; Transmission control protocol; Wireless sensor networks; Sensor networks
"Calvert K.L., Griffioen J.",2,On information hiding and network management,2006,1,"Laboratory for Advanced Networking, University of Kentucky, United States",University of Kentucky,1,USA,1,13,7,"No single administration controls the entire Internet. Instead, competing providers work together to enforce of a wide variety of network management policies, including policies that limit the flow of management information itself. In many cases these policies are designed to keep information about the state of the network from ""leaking"" outside the network. In this position paper, we consider the ramifications of such information-hiding policies for network management. We discuss mechanisms that might be used to enforce such policies, and argue for an open access policy. Copyright 2006 ACM.",Network architecture; Network management; Privacy; Scalability,Network management policies; Open access policies; Data flow analysis; Internet; Network architecture; Network management; Telecommunication industry; Data privacy
"Branch P., Armitage G.",2,Extrapolating server to client IP traffic from empirical measurements of first person shooter games,2006,15,"Centre for Advanced Internet Architectures (CAIA), Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,14,8,"Modelling traffic generated by Internet based multiplayer computer games has attracted a great deal of attention in the past few years. In part this has been driven by a desire to properly simulate the network impact of highly interactive online game genres such as the first person shooter (FPS). Packet size distributions are an important element in the creation of plausible traffic generators for network simulators such as ns-2 and omnet++. In this paper we present a simple technique for creating representative packet size distributions for N-player FPS games based on empirically measured traffic of 2- and 3-player games. We illustrate the likely generality of our approach using data from Half-Life, Half-Life Counterstrike, Half-Life 2, Half-Life 2 Counterstrike, Quake III Arena and Wolfenstein Enemy Territory. Copyright 2006 ACM.",First person shooter; Games; Teletraffic analysis; Traffic engineering,Empirical measurement; First person shooter; First person shooter games; Internet based; IP traffic; Multiplayer computer games; Network simulators; OMNET++; On-line games; Packet size distribution; Teletraffic analysis; Traffic Engineering; Traffic generators; Internet protocols; Packet networks; Size distribution; Radioactivity
"Wattimena A.F., Kooij R.E., Van Vugt J.M., Ahmed O.K.",4,Predicting the perceived quality of a first person shooter: The Quake IV G-model,2006,48,"TNO Information and Communication Technology, Brassersplein 2, 2600 GB Delft, Netherlands; Vrije Universiteit, Faculty of Sciences Business Mathematics and Informatics, Amsterdam, Netherlands; Delft University of Technology, Dept. of Electrical Engineering, Mathematics and Computer Science, Mekelweg 4, 2628 CD Delft, Netherlands",TU Delft;Vrije University,2,Netherlands,1,18,13,"This paper describes the development of an end-to-end quality measurement method that allows us to quantify the perceived quality of Interactive Gaming, with an emphasis on the so-called First Person Shooter (FPS) game Quake IV. We conducted a number of subjective experiments to quantify the impact of network parameters on the perceived quality of this recent FPS game. Making use of a multi-dimensional regression analysis we developed the Quake IV G-model which enables us to predict a gamer's Quake IV quality rating (expressed in a Mean Opinion Score) based on measured ping and jitter values. Our G-model shows a very high correlation (R = 0.98) with the subjective data. Copyright 2006 ACM.",First person shooter; Interactive gaming; Mean opinion score; On-line games; Perceived QoS; Regression analysis,First person shooter; Interactive gaming; Mean opinion scores; On-line games; Perceived QoS; Earthquakes; Jitter; Metal analysis; Quality of service; Statistics; Regression analysis
"Zhao J., Zhu P., Lu X., Zhao F.",4,A practical pricing model of inter-domain multicasting based on game theory,2006,3,"School of Computer, National University of Defense Technology, Changsha 410073, China",National University of Defense Technology,1,China,1,7,3,"A practical pricing mechanism is the foundation for the deploying of IP multicast in the inter-domain Internet. The IP multicast service model and its pricing mechanism are discussed in this paper, by considering the motivations of different partners in the process. A model named ICP-ISPs is proposed for applications in the real environments. In this model, the applied scenarios, resolving method and the complexity of algorithm are described. Here, the Internet is considered as an ecosystem. So our work gives a general discussion on the practical pricing mechanism based on the game theory for the stability of the economic development in the Internet. Copyright 2006 ACM.",Game theory; IP multicast; Pricing mechanism,Complexity of algorithm; Economic development; Inter-domain; IP Multicast; Pricing mechanism; Pricing models; Real environments; Costs; Internet; Internet protocols; Internet service providers; Multicasting; Game theory
"Hadaller D., Keshav S., Brecht T.",3,MV-MAX: Improving wireless infrastructure access for multi-vehicular communication,2006,42,"University of Waterloo, David R. Cheriton School of Computer Science, Canada",University of Waterloo,1,Canada,1,22,20,"When a roadside 802.11-based wireless access point is shared by more than one vehicle, the vehicle with the lowest transmission rate reduces the effective transmission rate of all other vehicles. This performance anomaly [9] degrades both individual and overall throughput in such multi-vehicular environments. Observing that every vehicle eventually receives good performance when it is near the access point, we propose MV-MAX (Multi-Vehicular Maximum), a medium access protocol that opportunistically grants wireless access to vehicles with the maximum transmission rate. Mathematical analysis and trace-driven simulations based on real data show that MV-MAX not only improves overall system throughput, compared to 802.11, by a factor of almost 4, but also improves on the previously proposed time-fairness scheme [20, 22, 15] by a factor of more than 2. Moreover, despite being less fair than 802.11, almost every vehicle benefits by using MV-MAX over the more equitable 802.11 access mechanism. Finally, we show that our results are consistent across different data sets. Copyright 2006 ACM.",802.11p; Delay tolerant networking; Infostations; Opportunistic connectivity; Vehicular communication,Delay tolerant networking; Infostations; Opportunistic connectivity; Vehicular communication; Data sets; Medium access protocols; Multi vehicular communication; Computer simulation; Data transfer; Network protocols; Numerical methods; Carrier communication; Data transfer rates; Ground vehicles; Wireless telecommunication systems; Mobile telecommunication systems
"Leguay J., Lindgren A., Scott J., Friedman T., Crowcroft J.",5,Opportunistic content distribution in an urban setting,2006,123,"UniversitŽ Pierre et Marie Curie, LiP6-CNRS, France; LuleŒ University of Technology, Sweden; Intel Research Cambridge, United Kingdom; University of Cambridge, United Kingdom",Intel;LuleŒ University of Technology;University of Cambridge;University Pierre and Marie Curie,4,France;Sweden;UK,3,14,12,"This paper investigates the feasibility of a city-wide content distribution architecture composed of short range wireless access points. We look at how a target group of intermittently and partially connected mobile nodes can improve the diffusion of information within the group by leveraging fixed and mobile nodes that are exterior to the group. The fixed nodes are data sources, and the external mobile nodes are data relays, and we examine the trade off between the use of each in order to obtain high satisfaction within the target group, which consists of data sinks. We conducted an experiment in Cambridge, UK, to gather mobility traces that we used for the study of this content distribution architecture. In this scenario, the simple fact that members of the target group collaborate leads to a delivery ratio of 90%. In addition, the use of external mobile nodes to relay the information slightly increases the delivery ratio while significantly decreasing the delay. Copyright 2006 ACM.",Content distribution; Delay tolerant networking; Mobility data,Content distribution; Delay tolerant networking; Mobility data; Content distribution architecture; Data sinks; Mobile nodes; Computer architecture; Data transfer; Wireless telecommunication systems; Carrier communication; Data transfer rates; Mobile devices; Mobile telecommunication systems; Telecommunication traffic; Information dissemination; Broadcasting
"Di Battista G., Refice T., Rimondini M.",3,How to extract BGP peering information from the internet routing registry,2006,11,"University of Roma Tre, Italy",University of Roma Tre,1,Italy,1,22,9,"We describe an on-line service, and its underlying methodology, designed to extract BGP peerings from the Internet Routing Registry. Both the method and the service are based on: a consistency manager for integrating information across different registries, an RPSL analyzer that extracts peering specifications from RPSL objects, and a peering classifier that aims at understanding to what extent such peering specifications actually contribute to fully determine a peering. A peering graph is built with different levels of confidence. We compare the effectiveness of our method with the state of the art. The comparison puts in evidence the quality of the proposed method. Copyright 2006 ACM.",BGP; Interdomain routing; Internet routing registry; Policies; RPSL,Interdomain routing; Internet routing registry; On-line service; Peering classifier; Peering graph; Graph theory; Information analysis; Internet; Network routing; Online systems; Specifications; Information retrieval
"Karlsson G., Lenders V., May M.",3,Delay-tolerant broadcasting,2006,45,"Laboratory for Communication Networks, KTH, Royal Inst. of Tech., 100 44 Stockholm, Sweden; Computer Engineering and Networks Laboratory, ETH Zurich, 8092 Zurich, Switzerland",ETH Zurich,1,Sweden;Switzerland,2,29,27,"There are many asynchronous communication situations for which the prevalent continuous connectivity paradigm is not needed. Communication with a fair delay tolerance may instead be provided by intermittent store-and-forwarding between nodes. This paper proposes a design for an open, receiver-driven broadcasting system that relies on delay-tolerant forwarding of data chunks through mobility of wireless nodes. The system provides public broadcast channels, which can be openly used for both transmission and reception. We show by simulation under benchmark mobility models that a delay-tolerant broadcast channel has both a sufficiently high throughput and reach to be interesting as a competitive alternative to the regulated wireless broadcast channel. We also present the design of, and experiences with, a proof-of-concept prototype. Copyright 2006 ACM.",Content distribution; Delay-tolerant communication; Wireless broadcast,Communication channels (information theory); Computer simulation; Mathematical models; Systems analysis; Wireless telecommunication systems; Carrier communication; Logic design; Signal receivers; Throughput; Content distribution; Delay-tolerant communication; Wireless broadcast; Broadcast channels; Delay tolerance; Wireless nodes; Data transfer; Radio broadcasting
"Hampel T., Bopp T., Hinn R.",3,A peer-to-peer architecture for massive multiplayer online games,2006,68,"University of Paderborn, 33102 Paderborn, Germany",University of Paderborn,1,Germany,1,6,3,Massive Multiplayer Online Games with their virtual gaming worlds grow in user numbers as well as in the size of the virtual worlds. With this growth comes a significant increase of the requirements for server hardware. Today an MMOG provider usually faces the problem of serving thousands of users with entire server clusters. Peer-to-Peer networks with their high scalability and flexibility meet the requirements of connecting hundreds of thousands of people all over the world without a central server. In doing so the network bandwidth requirements remain at a reasonable level. In this work we propose to combine MMOGs with a Peer-to-Peer network. We introduce a game architecture capable of exploiting the flexibility and scalability of P2P networks. A P2P architecture based on an overlay network using distributed hash tables with support for persistent object storage and event distribution has been developed to meet MMOG requirements. Copyright 2006 ACM.,Game architecture; MMOG; Peer-to-peer,Central servers; Distributed Hash Table; Game architecture; Massive multiplayer online games; Network bandwidth; P2P architecture; P2P network; Peer to peer; Peer-to-peer architectures; Server cluster; User number; Virtual worlds; Distributed computer systems; Overlay networks; Scalability; Peer to peer networks
"Fritsch T., Voigt B., Schiller J.",3,Distribution of online hardcore player behavior (how hardcore are you?),2006,12,"Freie UniversitŠt Berlin, Takustrasse 9, D-14195 Berlin, Germany",Freie UniversitŠt Berlin,1,Germany,1,15,11,"Within the last few years the game market has seen a tremendous growth. On pair with that, the way games are played has also evolved. Not only the community and variety of gaming has grown in numbers; the way games are understood has fundamentally changed. In fact terms like ""hardcore"" and ""casual"" became well known in the player scene. Even so called pro-gaming (professional gaming for money - like sportsmen) has led to tournaments and world championships. The underlying social deterministic and the changing player behavior are responsible for upcoming game design. First of all one must understand the user's perspective to find effective solutions for open problem fields. This paper introduces a large user survey about hardcore player behavior and gaming. It will show correlations between game types, deterministic factors, game related behavior and different ways of approaching games. Furthermore it features a detailed statistic analysis with surprising results. Copyright 2006 ACM.",Analysis; Characterization; Game behavior; Hardcore; Modeling; Multiplayer mobile and ubiquitous games; Social deterministic; Usage studies; User survey,Effective solution; Game design; Hardcore; Multiplayers; Open problems; Player behavior; Statistic analysis; Ubiquitous games; User surveys; Surveys
"Kawano Y., Yonekura T.",2,Count down protocol: Asynchronous consistent protocol in P2P virtual ball game,2006,1,"Intec NetCore, Inc., 1-3-3, Shinsuna, Koto-ku Tokyo, 136-0075, Japan; Ibaraki University, 4-12-1, Naka-Narusawa, Hitachi-shi, 316-8511, Japan",Ibaraki University;Intec NetCore Inc.,2,Japan,1,8,8,"This paper studies a way to improve consistency of states in a ball game typed DVE with lag, in P2P architecture. We also study how to control shared objects in real-time in a server-less network architecture. Specifically, a priority field called Allocated Topographical Zone (AtoZ) is used for P2P typed DVE. In a critical case (i.e. inconsistent phenomena), a stricter ownership determination algorithm, called dead zone is introduced. Moreover, we propose the method to get rid of a critical case for P2P multi-player virtual ball game. By using proposed method, a robust and effective scheme is achieved for a virtual ball game. As an example of the application, a real-time networked multi-player air-hockey is implemented for evaluation of validity of proposed method. Copyright 2006 ACM.",AtoZ (allocated topographical zone); Count down protocol (CDP); Critical case; DVE (distributed virtual environment); P2P (peer-to-peer),Critical case; Dead zones; Determination algorithm; Distributed Virtual Environments; P2P (peer to peer); P2P architecture; Priority field; Shared objects; Topographical zones; Adaptive filtering; Distributed computer systems; Virtual reality; Spheres
"Broll W., Ohlenburg J., Lindt I., Herbst I., Braun A.-K.",5,Meeting technology challenges of pervasive augmented reality games,2006,38,"Collaborative Virtual and Augmented Environments Department, Fraunhofer FIT, Sankt Augustin, Germany","Fraunhofer FIT,Germany",1,Germany,1,27,24,"Pervasive games provide a new type of game combining new technologies with the real environment of the players. While this already poses new challenges to the game developer, requirements are even higher for pervasive Augmented Reality games, where the real environment is additionally enhanced by virtual game items. In this paper we will review the technological challenges to be met in order to realize pervasive AR games, show how they go beyond those of other pervasive games, and present how our AR framework copes with them. We will further show how these approaches are applied to three pervasive AR games and draw conclusions regarding the future requirements regarding the support of this type of games. Copyright 2006 ACM.",Augmented reality; Mixed reality; Pervasive gaming; Ubiquitous computing,AR framework; Mixed reality; New technologies; Pervasive game; Pervasive gaming; Real environments; Technological challenges; Virtual games; Augmented reality; Interactive computer graphics; Ubiquitous computing; Virtual reality
"Luyten K., Thys K., Huypens S., Coninx K.",4,Telebuddies on the move: Social stitching to enhance the networked gaming experience,2006,6,"Hasselt University - TransNationale Universiteit Limburg, Expertise Center for Digital Media - IBBT, Wetenschapspark 2, Diepenbeek, Belgium",Hasselt University,1,Belgium,1,13,11,"In this paper we report on our work to enable ""laid-back"" social interactions using television as a primary interaction medium and mobile devices that participate as a secondary medium. By integrating semantic web techniques with interactive television we were able to create smart applications that can run as extensions of television shows and stimulate groups of users to communicate. Participants are teamed up to play along with a television show. Teams are composed based on common ground, which can be shared interests as well as shared characteristics that can be found between the users. Participating is possible using a set-top box or a mobile device; this allows people that are co-located and share a television set to participate individually. The usage of a mobile device to participate does not require a television set however: users on the move can also play along in a team. Our system does not require a new television format, but is also able to reuse existing television shows and socialize them in order to be re-broadcasted with support for distributed teams that play along with the show. Copyright 2006 ACM.",Cooperative user interfaces; Interactive television; Semantic web; Social games,Co-located; Common ground; Cooperative users; Distributed teams; Interactive television; Semantic-Web techniques; Set top box; Smart applications; Social interactions; Television set; Television shows; Digital television; Mobile devices; Portable equipment; Semantic Web; Semantics; Television applications; User interfaces; Broadcasting
"Que Y.P., Boustead P., Safaei F.",3,Trading off computation for error in providing immersive voice communications for mobile gaming,2006,1,"Smart Internet CRC, Telecommunications and Information Technology Research Institute, University of Wollongong, Australia",University of Wollongong,1,Australia,1,5,4,"The interactive experiences of players in networked games can be enhanced with the provision of an Immersive Voice Communication Service. Game players are immersed in their voice communication experience as they exchange live voice streams which are rendered in real-time with directional and distance cues corresponding to the users' positions in the virtual game world. In particular, we propose a Mobile Immersive Communication Environment (MICE) which targets mobile game players using platforms such as Sony PSP and Nintendo DS. A computation reduction scheme was proposed in our previous work for the scalable delivery of MICE from a central server. On the basis of that computation reduction scheme, this paper identifies what factors, and to what extent, affect the unacceptable voice rendering error incurred when providing MICE. In the first experimental scenario, we investigate the level of unacceptable voice rendering error incurred in MICE for different avatar densities or avatar population sizes, with a fixed level of processing limit. In the second experimental scenario, we studied the level of unacceptable voice rendering error incurred in MICE for different processing resource limits, with a fixed avatar population size or avatar density. Our findings provide important insights into the planning and dimensioning of processing resources for the support of MICE, with due considerations to the impact on the unacceptable voice rendering error incurred. Copyright 2006 ACM.",Computation cost reduction; Immersive voice communications; Mobile gaming; Voice over IP (VoIP),Central servers; Computation costs; Computation reduction; Game players; Immersive; Immersive voice communication; Mobile games; Mobile gaming; Networked games; Nintendo DS; Population sizes; Processing resources; Virtual games; Voice communication; Voice over IP; Voice stream; Communication; Cost reduction; Interactive computer graphics; Internet telephony; Mesh generation; Population statistics; Voice/data communication systems
"Hashimoto T., Ishibashi Y.",2,Group synchronization control over haptic media in a networked real-time game with collaborative work,2006,16,"Department of Computer Science and Engineering, Graduate School of Engineering, Nagoya Institute of Technology, Nagoya 466-8555, Japan",Nagoya Institute of Technology,1,Japan,1,15,12,"This paper deals with group (or inter-destination) synchronization control over haptic media in the case where two groups each of which consists of two players play a networked real-time game in which the two players in each group work with each other collaboratively. The group synchronization control adjusts the output timing of haptic media among the players' terminals. We enhance the synchronization maestro scheme, which the authors previously proposed, for the control so that we can handle two reference output timings, to which the players' terminals adjust their output timings. We examine the influence of the determination methods of the reference output timings on the fairness among the players and the efficiency of the work. By experiment, we demonstrate the effectiveness of a method which employs two reference output timings. The method adjusts the output timing of a terminal with the smaller network latency in a group to that in the other group, and it also adjusts the remaining two output timings. Copyright 2006 ACM.",Collaborative work; Experiment; Fairness; Group synchronization control; Haptic media; Networked real-time game,Collaborative work; Group synchronization; Group work; Haptic media; Network latencies; Real-time games; Synchronization control; Experiments; Time measurement; Synchronization
"Mortier R., Kiciman E.",2,Autonomic network management: Some pragmatic considerations,2006,37,"Microsoft Research, 7, JJ Thomson Ave, Cambridge CB3 0FB, United Kingdom; Microsoft Research, 1, Microsoft Way, Redmond, WA, United States",Microsoft,1,UK;USA,2,18,11,"Autonomic Network Management (ANM) has the goal of increasing reliability and performance while reducing management cost using various automated techniques. These range from agent-based approaches relying on explicit models and ontologies to emergent techniques relying on gossip protocols, swarming algorithms or other biologically inspired work. In this paper, we review the failures, growing pains and successes of earlier techniques for automated and adaptive network control and management, from the simple control loops in TCP and OSPF to the more complicated emergent behaviors of BGP dynamics and overlay routing. From these examples we extract several lessons relevant to ongoing research in autonomic network management. Copyright 2006 ACM.",Autonomic network management,Network architecture; Network routing; Ontology; Reliability; Transmission control protocol; Adaptive network control; Autonomic Network Management (ANM); Network management
"Brun J., Safaei F., Boustead P.",3,Server topology considerations in online games,2006,11,"Telecommunications and Information Technology Research Institute, University of Wollongong, Australia",University of Wollongong,1,Australia,1,17,16,"The selection of servers within the network affect both the participants' playability and the overall game fairness. This paper defines the concept of critical response time and uses it as the objective function for the server selection optimization problem we formulate and solve for small topologies. An approximate heuristic solution usable for large networks is introduced and its performance compared to the calculable lower bound of the critical response time. In our simulations, the heuristic converges towards a close to optimum critical response time. We also compare this solution to central server selection strategies and show that it outperforms them, both in terms of playability and fairness. Copyright 2006 ACM.",Fairness; Network game; Optimization; Playability; Server selection,Central servers; Critical response; Fairness; Heuristic solutions; Large networks; Lower bounds; Network game; Objective functions; On-line games; Optimization problems; Playability; Server selection; Optimization; Response time (computer systems); Topology; Servers
"Le F., Lee S., Wong T., Kim H.S., Newcomb D.",5,Minerals: Using data mining to detect router misconfigurations,2006,32,"ECE and CyLab., Carnegie Mellon University, United States; Network Operations, CENIC, Cuba",Carnegie Mellon University,1,Cuba;USA,2,13,10,"Recent studies have shown that router misconfigurations are common and have dramatic consequences for the operations of networks. Not only can misconfigurations compromise the security of a single network, they can even cause global disruptions in Internet connectivity. Several solutions have been proposed that can detect a number of problems in real configuration files. However, these solutions share a common limitation: they are rule-based. Rules are assumed to be known beforehand, and violations of these rules are deemed misconfigurations. As policies typically differ among networks, rule-based approaches are limited in the scope of mistakes they can detect. In this paper, we address the problem of router misconfigurations using data mining. We apply association rules mining to the configuration files of routers across an administrative domain to discover local, network-specific policies. Deviations from these local policies are potential misconfigurations. We have evaluated our scheme on configuration files from a large state-wide network provider, a large university campus and a high-performance research network, and found promising results. We discovered a number of errors that were confirmed and later corrected by the network engineers. These errors would have been difficult to detect with current rule-based approaches. Copyright 2006 ACM.",Association rules mining; Network misconfiguration; Routers; Static analysis,Association rules mining; Network misconfiguration; Router misconfigurations; Data mining; Interconnection networks; Internet; Logic programming; Network security; Static analysis; Routers
"Liu L., Ma H.",2,Wireless sensor network based mobile pet game,2006,8,"Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing 100876, China",Beijing University of Posts and Telecommunications,1,China,1,19,12,"Wireless sensor network offers an opportunity to introduce different kinds of physical data into mobile pet games, which enriches recreational elements and practical elements in mobile pet games. Motivated by this, we propose a novel architecture for integrating sensor networks into mobile pet game. In particular, we utilize an environment aware self-reconfiguration mechanism to build a mobile pet gaming platform. This mechanism can effectively support task reconfiguration on each sensor node, it's necessary for wireless sensor network based mobile pet game. Finally, a simple game named as S-Pet is detailed to show the performance of our gaming platform. Copyright 2006 ACM.",Gaming platform; Mobile pet game; Reconfiguration; Wireless sensor networks,Gaming platform; Integrating sensors; Novel architecture; Physical data; Self reconfiguration; Simple games; Sensor networks; Sensor nodes; Telecommunication equipment; Wireless sensor networks
"Mao Z.M., Sekar V., Spatscheck O., Van Der Merwe J., Vasudevan R.",5,Analyzing large DDoS attacks using multiple data sources,2006,35,"University of Michigan, United States; Carnegie Mellon University, United States; AT and T Labs-Research, United States",AT and T Labs;Carnegie Mellon University;University of Michigan at Ann Arbor,3,USA,1,12,9,"We present a measurement study analyzing DDoS attacks from multiple data sources, relying on both direct measurements of flow-level information, and more traditional indirect measurements using backscatter analysis. Understanding the nature of DDoS attacks is critically important to the development of effective counter measures to this pressing problem. While much of the community's current understanding of DDoS attacks result from indirect measurements, our analysis suggests that such studies do not give a comprehensive view of DDoS attacks witnessed in today's Internet. Specifically, our results suggest little use of address spoofing by attackers, which imply that such attacks will be invisible to indirect backscatter measurement techniques. Further, at the detailed packet-level characterization (e.g., attack destination ports), there are significant differences between direct and indirect measurements. Thus, there is tremendous value in moving towards direct observations to better understand DDoS attacks. Direct measurements additionally provide information inaccessible to indirect measurements, enabling us to better understand how to defend against attacks. We find that for 70% of the attacks fewer than 50 source ASes are involved and a relatively small number of ASes produce nearly 72% of the total attack volume. This suggests that network providers can reduce a substantial volume of malicious traffic with targeted deployment of DDoS defenses. Copyright 2006 ACM.",Attack characterization; DDoS attacks; Distributed denial of service attacks; IP spoofing,Attack characterization; Distributed denial of service attacks (DDoS); IP spoofing; Backscattering; Data reduction; Information analysis; Problem solving; Security of data; Telecommunication traffic; Computer crime
Farhat H.,1,Protecting TCP services from denial of service attacks,2006,12,"Computer Science Department, Notre Dame University, Zouk Mosbeh, Lebanon",Notre Dame University,1,Lebanon,1,34,23,"In this paper, we present a scheme that protects legitimate traffic from the large volume of attackers packets during a DDoS attack. Legitimate packets can be recognized by the tokens they carry in the IP header. Obtaining a token does not require protocol additions or changes, rather it is automatically obtained when a TCP connection is established. We believe that the Implicit Token Scheme (ITS) has numerous advantages: (1) It is totally transparent to clients. (2) No new protocols or modification of existing ones is needed to implement ITS. (3) Operations required by intermediate routers are computationally not more intensive than a couple of addition operations which could be easily done at wire-speed. (4) Does not lead to false positives. (5) Can sustain server availability even during attacks involving hundreds of thousands of attackers. Copyright 2006 ACM.",DDoS defense; Path identificatio; Syn cookie,Client server computer systems; Computer crime; Network protocols; Packet loss; Telecommunication services; DDoS defense; Path identification; Syn cookies; Network security
"Neglia G., Zhang X.",2,Optimal delay-power tradeoff in sparse delay tolerant networks: A preliminary study,2006,54,"Universitˆ degli Studi di Palermo, Palermo, Italy; University of Massachusetts, Amherst, MA, United States",University of Massachusetts Amherst;Universitˆ degli Studi di Palermo,2,Italy;USA,2,12,9,"In this paper we present a first attempt to study analytically the tradeoff between delivery delay and resource consumption for epidemic routing in Delay Tolerant Networks. We assume that the nodes cooperate in order to minimize a common cost equal to a weighted sum of the packet delivery delay and the total number of copies, which is strongly related to the power consumption. In this framework we determine the best policy each node should deploy in a very simple scenario where all the nodes have perfect knowledge of the system status. The result is used as an ideal reference to evaluate the performance of some heuristics proposed, investigating potential performance improvements and configuration criteria. Copyright 2006 ACM.",Delay tolerant networks; Epidemic routing; Performance tradeoff,Computer networks; Heuristic methods; Network routing; Optimization; Resource allocation; Electric power utilization; Network management; Packet loss; Delay tolerant networks; Epidemic routing; Performance tradeoff; Delay Tolerant Networks (DTN); Nodes; Packet delivery delay; Fault tolerant computer systems; Congestion control (communication)
"Cevizci I., Erol M., Oktug S.F.",3,Analysis of multi-player online game traffic based on self-similarity,2006,7,"Department of Computer Engineering, Istanbul Technical University, Maslak, 34469, Istanbul, Turkey",Istanbul Technical University,1,Turkey,1,24,15,"When provisioning network resources, ISPs have to tackle with the difficulties imposed by the traffic characteristics and demands of the users. Multi-player online games (MPOG) are constituting a large portion of the Internet traffic. MPOG players demand high bandwidth and low delay due to high interaction in these games. Moreover, they generate bursty traffic. In this paper, we analyze the traffic characteristics of a popular MPOG type game; Call of Duty 2 version 1.0 (CoD2). We use several game sessions to extract packet size and inter-arrival time distributions. In addition to these we investigate the self-similarity of the CoD2 traffic. We observe two different behavior at server and client-side, as expected. For the server-side, traffic characteristics vary with the number of players, but the traffic is long-range dependent most of the time. There are several intervals when the traffic process is non-stationary where the analysis of self-similarity becomes trivial. For the client-side, the traffic shows little variations however there are still some cases where the analysis of self-similarity becomes intricate because the traffic process reveals deviation from stationarity. Copyright 2006 ACM.",Hurst parameter; Multi-player first person shooter games; Self-similarity; Traffic analysis,Bursty traffic; First person shooter games; High bandwidth; Hurst parameter; Inter-arrival time; Internet traffic; Long range dependent; Low delay; Multi-player online games; Network resource; Nonstationary; Packet size; Self-similarities; Stationarity; Traffic analysis; Traffic characteristics; Internet service providers; Three dimensional computer graphics; Online systems
"Trinta F., Ferraz C., Ramalho G.",3,Middleware services for pervasive multiplatform networked games,2006,7,"Informatics Center, Federal University of Pernambuco, P.O. Box 7851, 50.732-970 Recife PE, Brazil",Federal University of Pernambuco,1,Brazil,1,9,8,"This work in progress paper presents a particular view for future Networked Multiplayer Games. In our point of view, these applications will include features from pervasive computing, allowing players to enjoy them using different devices, such as PDAs and Mobile Phones, almost anywhere, anytime. These games demand that users playability must be adapted according their context information, such as players location and device. In this document, we call these applications Pervasive Multiplayer Multiplatform Games - PM2G. We present scenarios that show intended characteristics for these games. From these scenarios, we developed two models, an Application and an Usage Model. The former introduces specific PM2G concepts. The latter guides the players' interaction. Finally, we introduce six services that aims to allow PM2G's development and deployment. Copyright 2006 ACM.",Mobile games; Pervasive computing,Context information; Middleware services; Mobile games; Multi-platform; Multiplayer games; Multiplayers; Networked games; Pervasive computing; Playability; Usage models; Work in progress; Middleware; Multimedia services; Telecommunication equipment; Service oriented architecture (SOA)
"Tan R.T.K.C., Teh J.K.S., Cheok A.D.",3,Metazoa Ludens,2006,0,"National University Singapore, 21, Lower Kent Ridge Road, Singapore, Singapore",National University of Singapore,1,Singapore,1,2,2,"Metazoa Ludens is new gaming model which allows pets to play new mixed reality computer games with humans via custom built technologies and applications. These games for pets and humans will provide new beneficial relations, progressions and evolution of the Metazoa species. Copyright 2006 ACM.",Computer entertainment system; Human-pet interaction,Computer entertainment; Computer game; Metazoa; Mixed reality; Biology; Virtual reality; Human computer interaction
"Zhou Y., Zhang Y., Xie Y.",3,Virtual disk based centralized management for enterprise networks,2006,0,"Tsinghua University, China; Carnegie Mellon University, United States",Carnegie Mellon University;Tsinghua University,2,China;USA,2,24,11,"The rapid advances in hardware, software, and networks have made the management of enterprise network systems an increasingly challenging task. Due to the tight coupling between hardware, software, and data, every one of the hundreds or thousands of PCs that are connected in an enterprise environment has to be administered individually, leading to high Total Cost of Ownership (TCO). We argue that centralized management with distributed, diskless clients, yet centralized repositories of all software and data can reduce the management complexity with reduced software maintenance time, improved system availability, and enhanced security. We instantiate such paradigm with a diskless, thick client based system that supports heterogeneous OSes including Windows - -the dominant commodity OS in the current market. The prototype requires no or minimum OS modification, nor application modification. Our initial deployment and experiment results demonstrate that our approach is a feasible and efficient solution for managing enterprise network systems. Copyright 2006 ACM.",Enterprise networks; System management; Virtual disks,Enterprise network systems; Management complexity; Repositories; Software maintenance time; Computer hardware; Computer software; Computer software maintenance; Enterprise resource planning; Network management; Security of data; Windows operating system; Distributed computer systems
"Izaiku T., Yamamoto S., Murata Y., Shibata N., Yasumoto K., Ito M.",6,Cheat detection for MMORPG on P2P environments,2006,5,"Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara 630-0192, Japan; Department of Information Processing and Management, Shiga University, Hikone, Shiga 522-8522, Japan",Nara Institute of Science and Technology;Shiga University,2,Japan,1,5,4,"In this paper, we propose a new method for detecting cheat in P2P-based MMORPG. We suppose a typical P2P-based event delivery architecture where the entire game space is divided into subareas and a responsible node (selected from player terminals) delivers each event happened in the sub-area to player nodes there every predetermined time interval called timeslot. In the proposed method, we introduce multiple monitor nodes (selected from player terminals) which monitor the game state and detect cheat when it happens. In order to allow monitor nodes to track the correct game states for the corresponding subarea, we let monitor nodes and a responsible node retain a random number seed and player nodes send their events not only to responsible node but also monitor nodes so that the monitor nodes and the responsible node can uniquely calculate the latest game state from the previous game state and game events which happened during the current timeslot. Either responsible node, monitor nodes or player nodes can detect cheat by comparing hash values of game state which are retained by those nodes periodically, and role back events happened since the last correct game state. Through experiments in PlanetLab, we show that our method achieves practical performance to detect cheats. Copyright 2006 ACM.",Cheating; Distributed system; Massively multiplayer online gaming; MMORPG; P2P; Peer to peer,Cheat detection; Delivery architecture; Distributed systems; Game space; Hash value; Massively multiplayer; Multiple monitors; On-line gaming; P2P environment; P2P-based; Peer to peer; PlanetLab; Random Numbers; Sub-areas; Time interval; Time slots; Distributed computer systems; Online systems; Peer to peer networks
"Akashi O., Fukuda K., Hirotsu T., Sugawara T.",4,Policy-based BGP control architecture for autonomous routing management,2006,10,"NTT Network Innovation Laboratories, Japan; National Institute of Informatics, Japan; Toyohashi University of Technology, JST CREST, Japan; NTT Communication Science Laboratories, Japan","NTT Corporation,Japan;National Institute of Informatics;Toyohashi University of Technology",3,Japan,1,17,12,"Unexpected temporal and spatial changes of inter-AS routing behavior often lead to the necessity of on-demand inter-domain routingadjustment. For resolving this problem, we apply the AISLE framework, which is a multi-agent-based model, to a policy-based routingadjustment system for transit ISPs and their customer ASs. This paper describes the BGP-control architecture called VR (Virtual Router) that can dynamically change forwarding paths considering alternative paths, which are inferred from historical data and confirmed when they are actually applied. VR can control conventional multiple border routers in an AS without any protocol extensions. The policy description, which is interpreted by an agent, enables network operators to define autonomous actions for analyzing network status and adjusting inter-AS routing based on these observed results by issuing requests to VR. Some evaluation results indicate that VR can effectively change routing over BGP data on the actual Internet and some control scenarios based on policy descriptions demonstrate the validity of our basic design framework. Copyright 2006 ACM.",BGP; Multi-agents; Policy-based control; Routing,Policy based control; Routing management; Virtual Routers (VR); Autonomous agents; Computational methods; Internet; Multi agent systems; Network routing; Routers; Network architecture
"Hikichi K., Yasuda Y., Fukuda A., Sezaki K.",4,The effect of network delay on remote calligraphic teaching with haptic interfaces,2006,9,"Department of Computer Science, Waseda University, 3-4-1, Okubo, Shinjuku-ku Tokyo, Japan; Graduate School of Information Science, University of Tokyo, 4-6-1 Komaba, Meguro-ku Tokyo, Japan; Center of Spatial Information Science, University of Tokyo, 4-6-1 Komaba, Meguro-ku Tokyo, Japan; Center for Spatial Information Science, University of Tokyo, Japan",University of Tokyo;Waseda University,2,Japan,1,12,8,"For a design of distributed virtual environments (DVEs) system, it is important to clarify the relation between network-level quality of service (QoS) and user-level QoS. This paper examines network QoS problem on a remote calligraphic teaching system with haptics interfaces, where a pair of users (teacher and student) interact directly (not through any virtual objects), and the operation of haptic device of one user is immediately reflected to another user's reaction force. In this system, teacher navigates student to write down the same character on a virtual paper using a constraint force. The constraint force is used to hold the user's stylus of haptic device to follow the remote user's operation. We propose a new method to generate a constraint force, which enables to hold tightly the remote user's stylus with suppressing unexpected vibrations. This system also can show a visual guide, which stands the remote user's information (position of the cursor and writing pressure). We carried out subjective evaluation on the system for assessing the effect of network delay between teacher and student's hosts. We also compared the effect of force feedback and visual guide in the system to evaluate the role of haptics. Copyright 2006 ACM.",Haptics; Network QoS; Remote teaching,Constraint forces; Distributed Virtual Environments; Force feedback; Haptic devices; Haptics; Network delays; Network QoS; Reaction forces; Remote teaching; Remote users; Subjective evaluations; Teaching systems; User-level QoS; Virtual objects; Virtual paper; Quality of service; Students; Virtual reality; Haptic interfaces
"Armitage G., Javier C., Zander S.",3,Post-game estimation of game client RTT and hop count distributions,2006,3,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,13,12,"In first person shooter (FPS) games the round trip time (RTT) between a client and server influences player decisions on which server to join. Game servers do not accurately log the RTT of potential clients who only probed the server. We describe a simple, active method of estimating the RTT and hop-count between server and client when armed only with each client's IP address. For rough approximations this scheme works days or weeks after client IP addresses were collected. We illustrate using data gathered from a Wolfenstein Enemy Territory server operating in Australia, providing after-the-fact comparisons between the RTT and hop-count distributions of clients who probe a server versus clients who actually join a server and play. Copyright 2006 ACM.",Game traffic; Hop count; Post-game estimation; Round trip time,Active method; After-the-fact; Australia; First person shooter games; Game servers; Game traffic; Hop count; IP addresss; Rough approximations; Round-trip time; Estimation; Servers
"Yamakawa S.-N., Yonekura T.",2,On a dynamic caching method for field segmented DVE by multi-server,2006,0,"Ibaraki University, 4-12-1, Naka-Narusawa, Hitachi-shi, 316-8511, Japan",Ibaraki University,1,Japan,1,8,4,"In this paper, we propose a concrete strategy to decrease the divergence of the network traffic in a DVE (distributed virtual environment) and we propose an implementation scheme of a dispersed multi-server type of DVE. Recently, research of the large-scale DVE to support a large number of users is improving. There are many types of DVE model, for example. Server-Client model, multi-server model and P2P (Peer to Peer) model. However, there is a problem of the concentration of the traffic load around the server. And the efficient way against the increasing traffics and the method for effective use for constructing the DVE have been less studied. Our goal is to design a DVE model for the decline of the traffic without sacrificing the smoothness of the operation in the dispersed multi-server type DVE. The DVE is constructed by a large number of small-scale servers that is decentralized management using Xcast (eXplicit multicast) for the communication among the nodes. As an evaluation of the proposed model, we demonstrate the ""Maze game"" for experimentation effective. Copyright 2006 ACM.",Field pre-fetching; Large-scale DVE; Multi-server; Network traffic; Xcast,Concentration of; Decentralized management; Distributed Virtual Environments; Dynamic caching; Implementation scheme; Multi-server; Network traffic; P2P (peer to peer); Prefetching; Server-client model; Traffic loads; Xcast (eXplicit multicast); Virtual reality; Servers
"Cheetancheri S.G., Agosta J.M., Dash D.H., Levitt K.N., Rowe J., Schooler E.M.",6,A distributed host-based worm detection system,2006,21,"UC Davis, Dept. of Computer Science, Davis, CA 95616, United States; Intel Research, 2200 Mission College Blvd., Santa Clara, CA 95052, United States",Intel;University of California Davis,2,USA,1,24,21,We present a method for detecting large-scale worm attacks using only end-host detectors. These detectors propagate and aggregate alerts to cooperating partners to detect large-scale distributed attacks in progress. The properties of the host-based detectors may in fact be relatively poor in isolation but when taken collectively result in a high-quality distributed worm detector. We implement a cooperative alert sharing protocol coupled with distributed sequential hypothesis testing to generate global alarms about distributed attacks. We evaluate the system's response in the presence of a variety of false alarm conditions and in the presence of an Internet worm attack. Our evaluation is conducted with agents on the Emulab and DETER emulated testbeds using real operating systems and computing platforms. Copyright 2006 ACM.,Sequential hypothesis testing; Worm detection,Computer viruses; Correlation detectors; Distributed computer systems; Internet; Large scale systems; Sequential machines; Software testing; Distributed attacks; False alarm conditions; Sequential hypothesis testing; Worm detection; Intrusion detection
"Li S., Chen C.",2,Interest scheme: A new method for path prediction,2006,2,"EIE Department, Beijing Jiaotong University, 3 Shangyuancun, Xizhimenwai Beijing 100044, China",Beijing Jiaotong University,1,China,1,6,3,"Most multiplayer network games use dead-reckoning vectors (DR) to predict movement of an entity controlled by participating game players. Generally, DR contains the current position and velocity of the entity. To get more accurate prediction, time-stamp and acceleration are also included. In this paper, we propose a solution named Interest Scheme (IS) to achieve much more prediction accuracy when network latency is unsteady and package loss is frequent. IS assumes that path prediction of a given player has relations to its nearby objects and players in game space. In IS, the surroundings of a given entity is taken into account in path prediction. Moreover, we consider that different prediction method should be used for different network latency. So, a hybrid method, which is a combination of IS and traditional method, is introduced. We use a 2D tank game for experiment and compare the results of our solution with those of traditional methods. Simulation shows that our method achieves significant improvement in path prediction. Copyright 2006 ACM.",Accuracy; Dead-reckoning; Dead-reckoning vectors; Hybrid method; Interest scheme; Network delay,Accurate prediction; Dead reckoning; Game players; Game space; Hybrid method; Interest scheme; Multiplayers; Network delays; Network game; Network latencies; Path prediction; Prediction accuracy; Prediction methods; Time-stamp; Packet networks; Forecasting
"Ferretti S., Roccetti M.",2,Game time modelling for cheating detection in P2P MOGs: A case study with a fast rate cheat,2006,2,"Department of Computer Science, University of Bologna, Mura Anteo Zamboni 7, 40127 Bologna, Italy",University of Bologna,1,Italy,1,10,8,"Typical cheating avoidance solutions are able to prevent cheats, often at the cost of loosing interactivity in highly distributed games. With the need for responsiveness in view, we claim that (instead of preventing the cheat) cheating detection schemes could represent profitable solutions, which enable the identification of cheaters without impeding a realtime evolution of the game. Based on a general framework able to fairly model game time advancements which was recently proposed [4], we provide evidence of its effectiveness on a specific case of time cheat termed fast rate cheat. According to this malicious scheme, players alter the event generation rate of game events. We show that detection of fast rate cheat can be easily accomplished based on the proposed framework. Copyright 2006 ACM.",Cheating; Online games; Peer-to-peer; Synchronization,Cheating detection; Fast rate; Generation rate; Interactivity; Online games; Peer to peer; Real time; Profitability; Distributed computer systems
"Hashimoto Y., Ishibashi Y.",2,Influences of network latency on interactivity in networked rock-paper-scissors,2006,8,"Department of Computer Science and Engineering, Graduate School of Engineering, Nagoya Institute of Technology, Nagoya 466-8555, Japan",Nagoya Institute of Technology,1,Japan,1,11,11,"This paper investigates the influences of network latency on the interactivity in rock-paper-scissors which two users do over a network by using live voice and video. By subjective assessment, we have assessed the interactivity in two cases. In one case, only one of the two users (referred to as the caller here) says, ""Rock, paper, scissors, go!"" and then both users try to show rock, paper, or scissors at the same time. In the other case, the two try to say, ""Rock, paper, scissors, go!"" simultaneously after one of them (i.e., the caller) has said, ""Here we go,"" and then they try to pick rock, paper, or scissors at the same time. Assessment results show that the mean opinion score (MOS) of the caller tends to decrease as the network latency becomes larger in both cases. The MOS of the other user hardly depends on the network latency. Copyright 2006 ACM.",Interactivity; Network latency; Rock-paper-scissors; Video; Voice,Interactivity; Mean opinion scores; Network latencies; Network latency; Subjective assessments; Voice and video; Packet networks; Tools; Rocks
"Lindgren A., Diot C., Scott J.",3,Impact of communication infrastructure on forwarding in pocket switched networks,2006,18,"LuleŒ University of Technology, Sweden; Thomson Research, France; Intel Research Cambridge, United Kingdom","Intel;LuleŒ University of Technology;Thomson,France",3,France;Sweden;UK,3,12,12,"Recently, it has been established on multiple experimental data sets that human contact processes exhibit heavy-tailed inter-event distributions. This characteristic makes it difficult to transport data with a finite transfer time in a network of mobile devices, relying on opportunistic contacts only. Using various experimental data sets, we analyze how different types of communication infrastructure impact the feasibility of data transfers among mobile devices. The first striking result is that the heavy tailed nature of the contact processes persists after infrastructure is introduced. We establish experimentally that infrastructure improves significantly multiple opportunistic contact properties, relevant to opportunistic forwarding algorithms. We discuss how infrastructure can be used to design simpler and more efficient (in terms of delay and number of hops) opportunistic forwarding algorithms. In addition to this, for the first time in a study like this, the communication pattern of nodes is taken into account in the analysis. We also show that node pairs that have a real-life history of communication have contact properties that are better for opportunistic message forwarding to each other than what other node pairs have. Copyright 2006 ACM.",Delay tolerant networking; Mobility analysis,Communication pattern; Delay tolerant networking; Mobility analysis; Data sets; Forwarding algorithms; Nodes; Algorithms; Data reduction; Database systems; Carrier communication; Data transfer; Message passing; Mobile devices; Telecommunication traffic; Switching networks; Packet networks
"Thawonmas R., Hirano M., Kurashige M.",3,Cellular automata and Hilditch thinning for extraction of user paths in online games,2006,3,"Intelligent Computer Entertainment Laboratory, Ritsumeikan University, 1-1-1 Nojihigashi, Kusatsu Shiga 525-8577, Japan",Ritsumeikan University,1,Japan,1,8,7,"To keep online games interesting to their players, it is important to detect players' behaviors. In this paper, in order to understand players' movement in online games, we propose a method for extraction of players' paths from their trails. In the proposed method, locations in a given map that are frequently visited are first intensified by cellular automata, and paths are then derived by the Hilditch thinning algorithm. Players' trails from an experimental online game, where three typical game missions are available, are used for performance evaluation. For performance evaluation, the proposed method is compared with a method using the median filter and the Hilditch thinning algorithm, a typical recipe in the area of image processing. According to the comparison results, the proposed method significantly outperforms its counter part in all cases, except the case with limited movement patterns. Copyright 2006 ACM.",Cellular automata; Game design; Hilditch thinning; Online games; Path extraction; Trails,Comparison result; Game design; Hilditch thinning; Median filter; Movement pattern; On-line games; Performance evaluation; Thinning algorithm; User path; Image processing; Pattern recognition systems; Robots; Translation (languages); Cellular automata
"Raiciu C., Handley M., Rosenblum D.S.",3,Exploit hijacking: Side effects of smart defenses,2006,4,"Department of Computer Science, University College London, United Kingdom",University College London,1,UK,1,26,23,"Recent advances in the defense of networked computers use instrumented binaries to track tainted data and can detect attempted break-ins automatically. These techniques identify how the transfer of execution to the attacker takes place, allowing the automatic generation of defenses. However, as with many technologies, these same techniques can also be used by the attackers: the information provided by detectors is accurate enough to allow an attacker to create a new worm using the same vulnerability, hijacking the exploit. Hijacking changes the threat landscape by pushing attacks to extremes (targeting selectively or creating a rapidly spreading worm), and increasing the requirements for automatic worm containment mechanisms. In this paper, we show that hijacking is feasible for two categories of attackers: those running detectors and those using Self-Certifying Alerts, a novel mechanism proposed by Costa et al. for end-to-end worm containment. We provide a discussion of the effects of hijacking on the threat landscape and list a series of possible countermeasures. Copyright 2006 ACM.",Exploit hijacking; Self-certifying alerts,Automatic generation; Exploit hijacking; Self-certifying alerts; Automation; Binary codes; Correlation detectors; Intelligent control; Security of data; Tracking (position); Computer crime
"Ott J., Kutscher D., Dwertmann C.",3,Integrating DTN and MANET routing,2006,95,"Helsinki University of Technology, Networking Laboratory, Finland; UniversitŠt Bremen, Technologiezentrum Informatik, Germany",Helsinki University of Technology;University of Bremen,2,Finland;Germany,2,25,22,"Mobile Ad-hoc Network (MANET) routing protocols aim at establishing end-to-end paths between communicating nodes and thus support end-to-end semantics of existing transports and applications. In contrast, DTN-based communication schemes imply asynchronous communication (and thus often require new applications) but achieve better reachability, particularly in sparsely populated environments. In this paper, we suggest a hybrid scheme that combines AODV and DTN-based routing and allows keeping the AODV advantage of maintaining end-to-end semantics whenever possible while, at the same time, also offering DTN-based communication options whenever available - leaving the choice to the application. We present our protocol and system design, particularly including the interaction of AODV and DTN, demonstrate achievable performance gains based upon measurements, and report on initial experiments with our implementation in an emulation environment. Copyright 2006 ACM.",Delay-tolerant networking; Mobile ad-hoc networking; Routing,Delay-tolerant networking; End-to-end semantics; Mobile ad-hoc networking; Asynchronous communication; Delay tolerant networking; Mobile Ad hoc Network (MANET); Data transfer; Measurement theory; Network routing; Semantics; Systems analysis; Ad hoc networks; Carrier communication; Congestion control (communication); Mobile telecommunication systems; Ad hoc networks; Routing protocols
"Hisamatsu T., Yamada A., Nezu T., Yamazaki T., Sugiura K., Inakage M., Nakamura O., Murai J.",8,Andrew Rivolski: Multi-display cooperation game over the internet,2006,1,"Keio University Murai Laboratory, 5322 Endo, Fujisawa Kanagawa, 252-8520, Japan; Keio University Inakage Laboratory, 5322 Endo, Fujisawa Kanagawa, 252-8520, Japan; Program Manager Advanced Technology Initiative Alliance and Technology Cisco Systems K.K., Shinjuku Mitsui Bldg., 2-1-1 Nshishinjuku, Shinjuku-ku Tokyo 163-0409, Japan",Keio University,1,Japan,1,7,7,"Andrew Rivolski is a multiplayer network game played in an environment consisting of multiple displays over the Internet. The players are placed in two different remote locations, and by having mutual interactions the game allows the players to experience a cooperative phenomenon. We have demonstrated three times between SFC, NAIST and USC. Copyright 2006 ACM.",Collaborative working; Delphi theory; Interaction techniques; Internet; Leisure and games,Collaborative working; Cooperative phenomenon; Delphi theory; Interaction techniques; Multiplayers; Multiple displays; Mutual interaction; Network game; Remote location; Distributed computer systems; Internet; Game theory
"Ballani H., Francis P.",2,CONMan: Taking the complexity out of network management,2006,7,"Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,30,21,"Network management is difficult, costly, and error prone, and this is becoming more so as network complexity increases. We argue that this is an outcome of two fundamental flaws in the existing architecture: the management plane depends on the data plane, and network device management interfaces are varied, complex, and constantly evolving. In this paper, we present Complexity Oblivious Network Management (CONMan), a network architecture in which the management plane does not depend on the data plane and all data plane protocols expose a simple generic management interface. This restricts the operational complexity of protocols to their implementation and allows the management plane to achieve high level policies in a structured fashion. Copyright 2006 ACM.",Data plane; Management plane; Network management; Protocol abstraction,Data flow analysis; Interfaces (computer); Network architecture; Network protocols; Management interfaces; Network complexity; Network management
"Parekh J.J., Wang K., Stolfo S.J.",3,Privacy-preserving payload-based correlation for accurate malicious traffic detection,2006,20,"Department of Computer Science, Columbia University, 450 Computer Science Building, 500 W. 120th St., New York, NY 10027, United States",Columbia University,1,USA,1,49,46,"With the increased use of botnets and other techniques to obfuscate attackers' command-and-control centers, Distributed Intrusion Detection Systems (DIDS) that focus on attack source IP addresses or other header information can only portray a limited view of distributed scans and attacks. Packet payload sharing techniques hold far more promise, as they can convey exploit vectors and/or malcode used upon successful exploit of a target system, irrespective of obfuscated source addresses. However, payload sharing has had minimal success due to regulatory or business-based privacy concerns of transmitting raw or even sanitized payloads. The currently accepted form of content exchange has been limited to the exchange of known-suspicious content, e.g., packets captured by honeypots; however, signature generation assumes that each site receives enough traffic in order to correlate a meaningful set of payloads from which common content can be derived, and places fundamental and computationally stressful requirements on signature generators that may miss particularly stealthy or carefully-crafted polymorphic malcode.Instead, we propose a new approach to enable the sharing of suspicious payloads via privacy-preserving technologies. We detail the work we have done with two example payload anomaly detectors, PAYL and Anagram, to support generalized payload correlation and signature generation without releasing identifiable payload data and without relying on single-site signature generation. We present preliminary results of our approaches and suggest how such deployments may practically be used for not only cross-site, but also cross-domain alert sharing and its implications for profiling threats. Copyright 2006 ACM.",Anomaly detection; Distributed intrusion detection; Payload correlation; Privacy preservation; Signature generation,Anomaly detection; Distributed Intrusion Detection Systems (DIDS); Payload correlation; Privacy preservation; Signature generation; Codes (symbols); Correlation methods; Internet protocols; Intrusion detection; Telecommunication traffic; Computer privacy
"Spyropoulos T., Psounis K., Raghavendra C.S.",3,Spray and wait: An efficient routing scheme for intermittently connected mobile networks,2005,854,"Department of Electrical Engineering, USC, United States",University of Southern California,1,USA,1,28,19,"Intermittently connected mobile networks are sparse wireless networks where most of the time there does not exist a complete path from the source to the destination. These networks fall into the general category of Delay Tolerant Networks. There are many real networks that follow this paradigm, for example, wildlife tracking sensor networks, military networks, inter-planetary networks, etc. In this context, conventional routing schemes would fail. To deal with such networks researchers have suggested to use flooding-based routing schemes, While flooding-based schemes have a high probability of delivery, they waste a lot of energy and suffer from severe contention, which can significantly degrade their performance. Furthermore, proposed efforts to significantly reduce the overhead of flooding-based schemes have often be plagued by large delays. With this in mind, we introduce a new routing scheme, called Spray and Wait, that ""sprays"" a number of copies into the network, and then ""waits"" till one of these nodes meets the destination. Using theory and simulations we show that Spray and Wait outperforms all existing schemes with respect to both average message delivery delay and number of transmissions per message delivered; its overall performance is close to the optimal scheme. Furthermore, it is highly scalable retaining good performance under a large range of scenarios, unlike other schemes. Finally, it is simple to implement and to optimize in order to achieve given performance goals in practice. Copyright 2005 ACM.",Ad-hoc networks; Delay tolerant networks; Intermittent connectivity; Routing,Ad-hoc networks; Delay tolerant networks; Intermittent connectivity; Routing; Computer simulation; Delay circuits; Fault tolerant computer systems; Probability; Routers; Wireless telecommunication systems
"Ghose A., Ipeirotis P.G., Sundararajan A.",3,Reputation premiums in electronic peer-to-peer markets: Analyzing textual feedback and network structure,2005,7,"Department of Information, Operations, and Management Sciences, Stern School of Business, New York University, 44 W. 4th Street, New York, NY 10012-1126, United States",NYU,1,USA,1,5,5,"Web-based systems that establish reputation are central to the viability of many electronic markets. We present theory that identifies the different dimensions of online reputation and characterizes their influence on the pricing power of sellers. We provide evidence that existing, numeric reputation scores conceal important seller-specific dimensions of reputation and we validate our theory further by proposing a new text mining technique that identifies and quantitatively evaluates further dimensions of importance in reputation profiles. We also suggest that the buyer-seller network contains critical reputation information that we can further exploit to improve the design of a reputation mechanism. Our experimental evaluation validates the predictions of our model using a new data set containing over 12,000 transactions for consumer software on Amazon.com's online secondary marketplace. This paper is the first attempt to integrate econometric methods and text and link mining techniques towards a more complete analysis of the information captured by reputation systems, and it presents new evidence of the importance of their effective and judicious design. Copyright 2005 ACM.",Econometrics; Electronic markets; Peer to peer; Reputation,Design; Electronic equipment; Feedback; Marketing; Telecommunication systems; Econometrics; Electronic markets; Peer to peer; Reputation; World Wide Web
"Zhang J., Rexford J., Feigenbaum J.",3,Learning-based anomaly detection in BGP updates,2005,13,"Computer Science Dept., Yale University, New Haven, CT 06520, United States; Computer Science Dept., Princeton University, Princeton, NJ 08544, United States",Princeton University;Yale University,2,USA,1,12,10,"Detecting anomalous BGP-route advertisements is crucial for improving the security and robustness of the Internet's interdomain-routing system. In this paper, we propose an instance-learning framework that identifies anomalies based on deviations from the ""normal"" BGP-update dynamics for a given destination prefix and across prefixes. We employ wavelets for a systematic, multi-scaled analysis that avoids the ""magic numbers"" (e.g., for grouping related update messages) needed in previous approaches to BGP-anomaly detection. Our preliminary results show that the update dynamics are generally consistent across prefixes and time. Only a few prefixes differ from the majority, and most prefixes exhibit similar behavior across time. This small set of abnormal prefixes and time intervals may be further examined to determine the source of anomalous behavior. In particular, we observe that many of the unusual prefixes are unstable prefixes that experience frequent routing changes.",Anomaly Detection; Instance-Based Learning; Wavelets,Anomaly Detection; Instance-Based Learning; Interdomain-routing system; Wavelets; Internet; Learning systems; Robustness (control systems); Routers; Security of data; Fault tolerant computer systems
"El-Arini K., Killourhy K.",2,Bayesian detection of router configuration anomalies,2005,8,"Computer Science Department, Carnegie Mellon University, United States; Dependable Systems Laboratory, Computer Science Department, Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,4,2,"Problems arising from router misconfigurations cost time and money. The first step in fixing such misconfigurations is finding them. In this paper, we propose a method for detecting misconfigurations that does not depend on an a priori model of what constitutes a correct configuration. Our hypothesis is that uncommon or unexpected misconfigurations in router data can be identified as statistical anomalies within a Bayesian framework. We present a detection algorithm based on this framework, and show that it is able to detect errors in the router configuration files of a university network.",Router configuration; Statistical anomaly detection,Bayesian framework; Router configuration; Statistical anomaly detection; Data reduction; Fault tolerant computer systems; Mathematical models; Statistical methods; Routers
"Kawadia V., Kumar P.R.",2,Experimental investigations into TCP performance over wireless multihop networks,2005,21,"BBN Technologies, Cambridge, MA, United States; University of Illinois at Urbana-Champaign, Urbana, IL, United States",BBN Technologies;UIUC,2,USA,1,19,14,"The results of an extensive experimental study of the performance of the TCP protocol over wireless multi-hop ad hoc networks are presented. The investigations are performed in a real indoor environment over a network of laptops equipped with off-the-shelf IEEE 802.11b wireless cards. The cards were partially covered with copper tape to reduce their range, which enabled creation of manageable topologies. Several tools were written and assembled to make the entire process of experimentation including topology setup, traffic generation, trace collection, and archival and analysis of data repeatable, reliable and as automated as possible. The experimental observations are subjected to a thorough statistical analysis. The final result of the study is a recommendation of some TCP and IEEE 802.11 parameters that are best for TCP performance over wireless multi-hop networks. The most critical of these include setting a destination dependent clamp on the sender congestion window and disabling the RTC-CTS handshake. The methods and techniques used, as well as the support tools developed, and statistical analysis, may be of larger interest in wireless network experimentation. Copyright 2005 ACM.",Ad hoc networks; Experimentation; TCP,Ad hoc networks; Experimentation; TCP; Computer networks; Standards; Statistical methods; Telecommunication traffic; Wireless telecommunication systems; Network protocols
"Ishibashi K., Toyono T., Toyama K., Ishino M., Ohshima H., Mizukoshi I.",6,Detecting mass-mailing worm infected hosts by mining DNS traffic data,2005,19,"NTT Information Sharing Platform Labs., NTT Corporation, 3-9-11 Midori-cho, Musashino-shi, Tokyo 180-8585, Japan; NTT Communications Corporation, 2-3-5 Otemachi, Chiyoda-ku, Tokyo 100-0004, Japan","NTT Corporation,Japan",1,Japan,1,22,11,"The Domain Name System (DNS) is a critical infrastructure in the Internet; thus, monitoring its traffic, and protecting DNS from malicious activities are important for security in Cyberspace. However, it is often difficult to determine whether a DNS query is caused by malicious or normal activity, because information available in DNS traffic is limited. We focus on the activities of mass-mailing worms and propose a method to detect hosts infected by mass-mailing worms by mining DNS traffic data. Our method begins with a small amount of a priori knowledge about a signature query. By assuming that queries sent by most hosts that have sent the signature query of worms have been sent by worm behavior, we detect infected hosts using Bayesian estimation. We apply our method to DNS traffic data captured at one of the largest commercial Internet Service Providers in Japan, and the experimental result indicates that an 89% reduction of mail exchange queries can be achieved with the method. Copyright 2005 ACM.",Data mining; Domain Name System; Mass-mailing worm,Computer worms; Cybernetics; Data mining; Electronic mail; Security of data; Telecommunication traffic; Domain Name System; Malicious activities; Mass-mailing worm; Internet
"Andrade N., Mowbray M., Lima A., Wagner G., Ripeanu M.",5,Influences on cooperation in BitTorrent communities,2005,31,"Universidade Federal de Campina Grande, Brazil; HP Laboratories Bristol, United Kingdom; University of Chicago, United States",HP Labs;Universidade Federal de Campina Grande;University of Chicago,3,Brazil;UK;USA,3,18,16,We collect BitTorrent usage data across multiple file-sharing communities and analyze the factors that affect users' cooperative behavior. We find evidence that the design of the BitTorrent protocol results in increased cooperative behavior over other P2P protocols used to share similar content (e.g. Gnutella). We also investigate two additional community-specific mechanisms that foster even more cooperation. Copyright 2005 ACM.,BitTorrent; Cooperation; P2P,BitTorrent; Cooperation; P2P; Behavioral research; Network protocols; Resource allocation; Social aspects; Computer networks
"Jones E.P.C., Li L., Ward P.A.S.",3,Practical routing in delay-tolerant networks,2005,55,"Electrical and Computer Engineering, University of Waterloo, Waterloo, Ont., Canada",University of Waterloo,1,Canada,1,19,15,"Delay-tolerant networks (DTNs) have the potential to connect devices and areas of the world that are under-served by current networks. A critical challenge for DTNs is determining routes through the network without ever having an end-to-end connection, or even knowing which ""routers"" will be connected at any given time. Prior approaches have focused either on epidemic message replication or on knowledge of the connectivity schedule. The epidemic approach of replicating messages to all nodes is expensive and does not appear to scale well with increasing load. It can, however, operate without any prior network configuration, The alternatives, by requiring a priori connectivity knowledge, appear infeasible for a self-configuring network. In this paper we present a practical routing protocol that only uses observed information about the network, We designed a metric that estimates how long a message will have to wait before it can be transferred to the next hop. The topology is distributed using a link-state routing protocol, where the link-state packets are ""flooded"" using epidemic routing. The routing is recomputed when connections are established. Messages are exchanged if the topology suggests that a connected node is ""closer"" than the current node. We demonstrate, through simulation that our protocol provides performance similar to that:of schemes that have global knowledge of the network topology, yet without requiring that knowledge. Further, it requires a significantly smaller quantity of buffer, suggesting that our approach will scale with the number of messages in the network, where replication approaches may not. Copyright 2005 ACM.",Delay tolerant network; Route metrics; Routing,Computer simulation; Fault tolerant computer systems; Knowledge acquisition; Telecommunication networks; Delay tolerant network; Replication approaches; Route metrics; Routing; Routers
"Jun S., Ahamad M.",2,Incentives in BitTorrent induce free riding,2005,49,"College of Computing, Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech,1,USA,1,20,14,"We investigate the incentive mechanism of BitTorrent, which is a peer-to-peer file distribution system. As downloaders in BitTorrent are faced with the conflict between the eagerness to download and the unwillingness to upload, we relate this problem to the iterated prisoner's dilemma, which suggests guidelines to design a good incentive mechanism. Based on these guidelines, we propose a new, simple incentive mechanism. Our analysis and the experimental results using PlanetLab show that the original incentive mechanism of BitTorrent can induce free riding because it is not effective in rewarding and punishing downloaders properly. In contrast, a new mechanism proposed by us is shown to be more robust against free riders. Copyright 2005 ACM.",BitTorrent; Data dissemination; Incentive mechanisms; Prisoner's dilemma; Strategy,BitTorrent; Incentive mechanisms; Prisoner's dilemma; Strategy; Data processing; Information dissemination; Problem solving; Robustness (control systems); Distributed computer systems
"Zhao W., Ammar M., Zegura E.",3,Multicasting in delay tolerant networks: Semantic models and routing algorithms,2005,63,"College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, United States",Georgia Tech,1,USA,1,24,17,"Delay tolerant networks (DTNs) are a class of emerging networks that experience frequent and long-duration partitions. These networks have a variety of applications in situations such as crisis environments and deep-space communication. In this paper, we study the problem of multicasting in DTNs. Multicast supports the distribution of data to a group of users, a service needed for many potential DTN applications. While multicasting in the Internet and mobile ad hoc networks has been studied extensively, due to the unique characteristic of frequent partitioning in DTNs, multicasting in DTNs is a considerably different and challenging problem. It not only requires new definitions of multicast semantics but also brings new issues to the design of routing algorithms. In this paper, we propose new semantic models for DTN multicast and develop several multicast routing algorithms with different routing strategies. We present a framework to evaluate these algorithms in DTNs. To the best of our knowledge, this is the first study of multicasting in DTNs. Our objectives are to understand how routing performance is affected by the availability of knowledge about network topology and group membership and to guide the design of DTN routing protocols. Using ns simulations, we find that efficient multicast routing for DTNs can be constructed using only partial knowledge. In addition, accurate topology information is generally more important in routing than up-to-date membership information. We also find that routing algorithms that forward data along multiple paths achieve better delivery ratios, especially when available knowledge is limited. Copyright 2005 ACM.",Delay tolerant networks; Multicast; Semantic model,Delay tolerant networks; Multicast; Semantic model; Topology information; Data communication equipment; Internet; Multicasting; Semantics; Topology; Telecommunication networks
"Harrop W., Armitage G.",2,Greynets: A definition and evaluation of sparsely populated darknets,2005,5,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, Australia",Swinburne University of Technology,1,Australia,1,12,11,"Darknets are often proposed to monitor for anomalous, externally sourced traffic, and require large, contiguous blocks of unused IP addresses - not always feasible for enterprise network operators. We introduce and evaluate the Greynet - a region of IP address space that is sparsely populated with 'darknet' addresses interspersed with active (or 'lit') IP addresses. Based on a small sample of traffic collected within a university campus network we saw that relatively sparse greynets can achieve useful levels of network scan detection.",Darknet; Greynet; Intrusion Detection Systems; Network Security; Network Telescope; Sparse Darknets,Computer networks; Data mining; Information theory; Telecommunication traffic; Darknet; Greynet; Intrusion Detection Systems; Network Security; Network Telescope; Sparse Darknets; Internet
"Kompella R.R., Ramabhadran S., Ramani I., Snoeren A.C.",4,Cooperative packet scheduling via pipelining in 802.11 wireless networks,2005,0,"University of California, San Diego, San Diego, CA 92093, United States",University of California San Diego,1,USA,1,16,9,"The proliferation of 802.11a/b/g based wireless devices has fueled their adoption in many domains - some of which are unforseen. Yet, these devices lack native support for some of the advanced features (such as service differentiation, etc.) required in specific application domains. A subset of these features relies on cooperative scheduling whereby nodes cooperate among each other to effectively manage resources such as power, throughput and interference in wireless networks. The trajectory of evolution in these devices has been primarily through new extension standards (such as 802.11e/s etc.) that offer support for these features. Plagued with long design cycles and cost overhead to upgrade, this process of upgrading creates an uphill task to users who want to use their wireless devices for different applications. In this paper, we argue that such cooperative scheduling extensions can be supported using a new layer on top of the existing MAC layer. We propose a 2 1/2-stage pipeline architecture as a generic mechanism to create such domain specific extensions and propose two such protocols, SPARTA (power conservation) and ARGOS (throughput guarantees) over the native 802.11/b/g MAC layer. Using a prototype we built over open source 802.11 wireless device driver, we present some preliminary evaluation of the architecture. Copyright 2005 ACM.",802.11 wireless networks; Cooperative scheduling; Power conservation; Proportional allocation; Quality of Service; Streaming video,802.11 wireless networks; Cooperative scheduling; Power conservation; Proportional allocation; Streaming video; Network protocols; Quality of service; Standards; Wireless telecommunication systems; Packet networks
"Cheng A., Friedman E.",2,Sybilproof reputation mechanisms,2005,78,"Center for Applied Mathematics, Cornell University, Ithaca, NY 14853, United States; School of Operations Research and Industrial Engineering, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,9,9,"Due to the open, anonymous nature of many P2P networks, new identities - or sybils - may be created cheaply and in large numbers. Given a reputation system, a peer may attempt to falsely raise its reputation by creating fake links between its sybils. Many existing reputation mechanisms are not resistant to these types of strategies. Using a static graph formulation of reputation, we attempt to formalize the notion of sybilproofness. We show that there is no symmetric sybilproof reputation function. For nonsymmetric reputations, following the notion of reputation propagation along paths, we give a general asymmetric reputation function based on flow and give conditions for sybilproofness. Copyright 2005 ACM.",Peer-to-peer; Reputation; Sybils,Peer-to-peer; Reputation; Sybils; Functions; Graph theory; Distributed computer systems
"Xu K., Chandrashekar J., Zhang Z.-L.",3,A first step toward understanding inter-domain routing dynamics,2005,5,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, United States",University of Minnesota,1,USA,1,12,7,"BGP updates are triggered by a variety of events such as link failures, resets, routers crashing, configuration changes, and so on. Making sense of these updates and identifying the underlying events are key to debugging and troubleshooting BGP routing problems. In this paper, as a first step toward the much harder problem of root cause analysis of BGP updates, we discuss if, and how, updates triggered by distinct underlying events can be separated. Specifically, we explore using PCA (Principal Components Analysis), a well known statistical multi-variate technique, to achieve this goal, We propose a method based on PCA to obtain a set of clusters from a BGP update stream; each of these is a set of entities (either prefixes or ASes) which are affected by the same underlying event. Then we demonstrate our approach using BGP data obtained by simulations and show that the method is quite effective. In addition, we perform a high level analysis of BGP data containing well known, large scale events. Copyright 2005 ACM.",BGP; Root Cause Analysis; Routing,Computer simulation; Data processing; Principal component analysis; Telecommunication links; BGP; Large scale events; Root cause analysis; Rooting; Routers
"Wang Y., Jain S., Martonosi M., Fall K.",4,Erasure-coding based routing for opportunistic networks,2005,154,"Princeton University, United States; University of Washington, United States; Intel Research Berkeley, United States",Intel;Princeton University;University of Washington at Seattle,3,USA,1,15,14,"Routing in Delay Tolerant Networks (DTN) with unpredictable node mobility is a challenging problem because disconnections are prevalent and lack of knowledge about network dynamics hinders good decision making. Current approaches are primarily based on redundant transmissions. They have either high overhead due to excessive transmissions or long delays due to the possibility of making wrong choices when forwarding a few redundant copies. In this paper, we propose a novel forwarding algorithm based on the idea of erasure codes. Erasure coding allows use of a large number of relays while maintaining a constant overhead, which results in fewer cases of long delays. We use simulation to compare the routing performance of using erasure codes in DTN with four other categories of forwarding algorithms proposed in the literature. Our simulations are based on a real-world mobility trace collected in a large outdoor wild-life environment. The results show that the erasure-coding based algorithm provides the best worst-case delay performance with a fixed amount of overhead. We also present a simple analytical model to capture the delay characteristics of erasure-coding based forwarding, which provides insights on the potential of our approach. Copyright 2005 ACM.",Delay tolerant network; Erasure coding; Routing,Delay tolerant network; Erasure coding; Erasure-coding based forwarding; Routing; Algorithms; Decision making; Encoding (symbols); Fault tolerant computer systems; Mathematical models; Redundancy; Delay circuits
"Rolli D., Neumann D., Conrad M., Sorge C.",4,An asynchronous and secure ascending peer-to-peer auction,2005,2,"Institute of Information Engineering and Management, University of Karlsruhe, Germany; Institute of Telematics, University of Karlsruhe, Germany",University of Karlsruhe,1,Germany,1,16,11,"In recent years, auctions have become a very popular price discovery mechanism. Among them, second-price auctions are of theoretical importance, as they have the simple dominant strategy of bidding ones true valuation. Sellers, however, are reluctant to do so, as a malicious auctioneer could take advantage of this knowledge. Several distributed auction mechanisms have been suggested that make it possible to determine the auction outcome without revealing the winner's valuation of the good; however, they are only suitable for sealed-bid auctions. This paper suggests a distributed mechanism for ascending second price auctions. The auction protocol has the ability to preserve the privacy of the winning bidder's true valuation or highest bid, respectively, with a high probability. The auction protocol is based on a high number of auctioneers that are distributed to several groups. A bidder generates an encrypted chain of monotonously increasing bidding steps, where each bidding step Can be decrypted by a different auctioneer group reducing the possibilities of manipulation for malicious auctioneers., Another fundamental advantage of this secure approach is that bidders need-not be online except for submitting their bid chain to the auctioneers. Copyright 2005 ACM.",Distributed Auctions; Peer-to-Peer Systems; Privacy; Security Protocols; Trust,Cryptography; Economics; Network protocols; Probability; Distributed Auctions; Peer-to-Peer Systems; Privacy; Security Protocols; Trust; Client server computer systems
"Dahlberg T.A., Nasipuri A., Taylor C.",3,Explorebots: A mobile network experimentation testbed,2005,14,"University of North Carolina-Charlotte, 9201 University City Blvd., Charlotte, NC 28223-0001, United States; Southwest Research Institute, 6220 Culebra Road, San Antonio, TX 78228-0510, United States",Southwest Research Institute;University of North Carolina-Charlotte,2,USA,1,15,5,"In this paper, we detail our development of Explorebots - expandable, vision- and sensor-equipped wireless robots built around MICA motes. We developed Explorebots as a dynamic outreach for an NSF-funded Girl Scouts project. We've extended the capabilities of Explorebots to comprise a mobile network experimentation testbed. The testbed will support experimental analysis of protocols for mobile multi-hop networks. The low-cost Explorebots enable repeatable experiments without complete reliance on human subjects for mobility. Copyright 2005 ACM.",Mobile robotics; Multi-hop networks; Sensor networks; Testbed,Mobile robotics; Multi-hop networks; Sensor networks; Testbed; Computer vision; Mobile robots; Robotics; Sensors; Wireless telecommunication systems; Computer networks
"Irwin D., Chase J., Grit L., Yumerefendi A.",4,Self-recharging virtual currency,2005,16,"Duke University, United States; National Physical Science Consortium, United States",Duke University,1,USA,1,23,16,"Market-based control is attractive for networked computing utilities in which consumers compete for shared resources (computers, storage, network bandwidth). This paper proposes a new self-recharging virtual currency model as a common medium of exchange in a computational market. The key idea is to recycle currency through the economy automatically while bounding the rate of spending by consumers. Currency budgets may be distributed among consumers according to any global policy; consumers spend their budgets to schedule their resource usage through time, but cannot hoard their currency or starve. We outline the design and rationale for self-recharging currency in Cereus, a system for market-based community resource sharing, in which participants are authenticated and sanctions are sufficient to discourage fraudulent behavior. Currency transactions in Cereus are accountable: offline third-party audits can detect and prove cheating, so participants may transfer and recharge currency autonomously without involvement of the trusted banking service. Copyright 2005 ACM.",Market; Virtual Currency,Market; Self-recharging currency; Virtual Currency; Budget control; Computer networks; Mathematical models; Virtual reality
"Jardosh A.P., Ramachandran K.N., Almeroth K.C., Belding-Royer E.M.",4,Understanding link-layer behavior in highly congested IEEE 802.11b wireless networks,2005,19,"Department of Computer Science, University of California, Santa Barbara, United States",University of California Santa Barbara,1,USA,1,12,12,"The growing deployment and concomitant rise in wireless network usage necessitates the comprehensive understanding of its behavior. More importantly, as networks grow in size and number of users, congestion in the wireless portion of the network is likely to increase. We believe there is a strong need to understand the intricacies of the wireless portion of a congested network by interpreting information collected from the network. Congestion in a wireless network can be best analyzed by studying the transmission of frames at the link layer. To this end, we use vicinity sniffing techniques to analyze the link layer in an operational IEEE 802.11b wireless network. In this paper, we discuss how congestion in a network can be estimated using point-to-point link reliability. We then show how link reliability is correlated with the behavior of link-layer properties such as frame retransmissions, frame sizes, and data rates. Based on the results from these correlations, our hypothesis is that the performance of the link layer in congested networks can be improved by (1) sending smaller frames, and/or (2) using higher data rates with a fewer number of frames sent. Copyright 2005 ACM.",IEEE 802.11b; Network Congestion; Performance Analysis,IEEE 802.11b; Network Congestion; Performance Analysis; Computer networks; Congestion control (communication); Performance; Standards; Wireless telecommunication systems
"Ho L., Moh M., Walker Z., Hamada T., Su C.-F.",5,A prototype on RFID and sensor networks for elder healthcare: Progress report,2005,47,"Venturi Wireless, Sunnyvale, CA, United States; Dept of Computer Science, San Jose State University, San Jose, CA, United States; IP Networking Research, Fujitsu Laboratories of America, Sunnyvale, CA, United States",Fujitsu Laboratories Ltd.;San Jose State University,2,USA,1,24,23,"Radio Frequency Identification (RFID) and sensor networks are both wireless technologies that provide limitless future potentials. While the industry has witnessed rapid growth in developing and applying RFID technology, and the network research community has devoted tremendous efforts in sensor networks, these two communities would benefit greatly by learning from each other. In pursuing this effect, a project utilizing and integrating both technologies is described. The goal is to build an in-home elder healthcare system that monitors patients' medication in take. This would help addressing the challenge of a growing aging population. Copyright 2005 ACM.",Healthcare; RFID; Sensor networks,Health care; Patient monitoring; Patient treatment; Sensors; RFID; Sensor networks; Wireless technologies; Computer networks
"Zhang B., Kambhampati V., Lad M., Massey D., Zhang L.",5,Identifying BGP routing table transfers,2005,7,"Computer Science Department, University of Arizona, United States; Computer Science Department, Colorado State University, United States; Computer Science Department, University of California, Los Angeles, United States",Colorado State University;University of Arizona;University of California Los Angeles,3,USA,1,9,7,"BGP routing updates collected by monitoring projects such as RouteViews and RIPE have been a vital source to our understanding of the global routing system. The updates logged by these monitoring projects are generated either by individual route changes, or are part of BGP table transfer. In particular, a session reset between a monitoring station and its BGP peers can result in the peer sending its entire BGP routing table to the monitoring station. In this paper, we present a Minimum Collection Time (MCT) algorithm that accurately identify the start and duration of routing table transfers. Using three months of data from 14 different peers, MCT can identify routing table transfers triggered by BGP session resets with 100% accuracy, and can pinpoint the exact starting time of table transfers in 90% of the cases. Copyright 2005 ACM.",BGP; Collection Time; Routing Table Transfer; Session Reset,BGP; Collection Time; Routing Table Transfer; Session Reset; Algorithms; Data transfer; Monitoring; Routers
"Ng A.C.H., Malone D., Leith D.J.",3,Experimental evaluation of TCP performance and fairness in an 802.11e test-bed,2005,14,"Hamilton Institute, NUI Maynooth, Ireland",Hamilton Institute,1,Ireland,1,17,11,"In this paper we present measurements made using an 802.11e wireless testbed. We demonstrate experimentally how the new 802.11e [1] QoS parameters behave in our testbed. We describe the testing methodology used to validate the operation of the 802.11e TXOP, AIFS and CWmin parameters and compare the experimental results to existing analytical models. We also discuss a number of practical issues encountered during our measurements. We then use the testbed to demonstrate some known problems with TCP's performance caused by cross-layer interaction between the TCP congestion control algorithm and the MAC layer CSMA/CA contention mechanism, Finally, we study how these problems can be mitigated using the flexibility provided by the 802.11e parameters via the scheme suggested in [2]. Copyright 2005 ACM.",802.11; 802.11e; Fairness; TCP; Test-bed,Algorithms; Congestion control (communication); Mathematical models; Performance; Quality of service; Standards; 802.11; 802.11e; Fairness; TCP; Test-bed; Network protocols
"Haffner P., Sen S., Spatscheck O., Wang D.",4,ACAS: Automated construction of application signatures,2005,128,"AT and T Labs-Research, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,14,13,"An accurate mapping of traffic to applications is important for a broad range of network management and measurement tasks. Internet applications have traditionally been identified using well-known default server network-port numbers in the TCP or UDP headers. However this approach has become increasingly inaccurate. An alternate, more accurate technique is to use specific application-level features in the protocol exchange to guide the identification. Unfortunately deriving the signatures manually is very time consuming and difficult. In this paper, we explore automatically extracting application signatures from IP traffic payload content. In particular we apply three statistical machine learning algorithms to automatically identify signatures for a range of applications. The results indicate that this approach is highly accurate and scales to allow online application identification on high speed links. We also discovered that content signatures still work in the presence of encryption. In these cases we were able to derive content signature for unencrypted handshakes negotiating the encryption parameters of a particular connection. Copyright 2005 ACM.",Application signatures; Application-level filter; Machine learning,Application signatures; Application-level filter; Algorithms; Computer applications; Cryptography; Electronic document identification systems; Internet; Learning systems; Telecommunication networks
"Bhattacharjee R., Goel A.",2,Avoiding ballot stuffing in eBay-like reputation systems,2005,22,"Stanford University, United States; Department of Computer Science, Stanford University, United States; Departments of Management Science and Engineering and Computer Science, Stanford University, United States",Stanford University,1,USA,1,14,12,"We present a preliminary study on the robustness of binary feedback reputation systems (e.g. eBay) to ballot stuffing and bad mouthing. In a feedback based reputation system, a seller can collude with other buyers to undertake fake transactions in order to enhance her reputation. This problem is referred to as ballot stuffing. A seller can also be targeted by a group of buyers to deliberately lower her reputation. This problem is referred to as bad mouthing. For the reputations to be meaningful, any practical reputation system needs to be resistant to these problems. We use a simplified model to give an explicit relation between the reputation premium and the transaction cost that needs to hold in order to avoid ballot stuffing. Thus we draw attention to the necessity of transaction costs for a well functioning reputation system. Our conclusions are confirmed by empirical experiments on eBay. Copyright 2005 ACM.",Reputation Systems,Bad mouthing; Ballot stuffing; Feedback reputation systems; Reputation Systems; Costs; Electronic commerce; Robustness (control systems); Feedback
"Jamieson K., Hull B., Miu A., Balakrishnan H.",4,Understanding the real-world performance of carrier sense,2005,23,"MIT Computer Science and Artificial Intelligence Laboratory, Stata Center, 32 Vassar St., Cambridge, MA 02139, United States",MIT,1,USA,1,13,8,"Carrier sense is a fundamental part of most wireless networking stacks in wireless local area- and sensor networks. As increasing numbers of users and more demanding applications push wireless networks to their capacity limits, the efficacy of the carrier sense mechanism becomes a key factor in determining wireless network capacity. We describe how carrier sense works, point out its limitations, and advocate an experimental approach to studying carrier sense. We describe our current testbed setup, and then present preliminary experimental results from both a 60-node sensor network deployment and a small-scale 802.11 deployment. Our preliminary results evaluate how well carrier sense works and expose its limitations. Copyright 2005 ACM.",Carrier sense; Medium access control,802.11; Carrier sense; Medium access control; Computer networks; Sensors; Standards; Wireless telecommunication systems; Carrier sense multiple access
"Ramachandran K., Kaul S., Mathur S., Gruteser M., Seskar I.",5,Towards large-scale mobile network emulation through spatial switching on a wireless grid,2005,3,"WINLAB, Electrical and Computer Engineering Department, Rutgers, The State University of New Jersey, 94 Brett Rd, Piscataway, NJ 08854, United States",Rutgers University,1,USA,1,13,12,"Experimentation with large mobile networks is notoriously tedious and expensive. We present the architecture and work-in-progress implementation of the m-ORBIT testbed, a mobility emulator using spatial switching, which facilitates mobile system experiments with 802.11a/b/g wireless network interfaces. The emulator does not require any physically moving parts - it emulates mobility by switching over an array of 128 spatially distributed radios. Instead of using hardware antenna switches, we implement spatial switching in software over Gigabit Ethernet links to the radio nodes. Preliminary results support the scaling of this approach to a large number of radios at relatively low cost. Packet error rate measurements also indicate that an experimenter can create multi-hop topologies by injecting additive white Gaussian noise into the environment. We demonstrate through an Ad hoc On Demand Distance Vector routing case study how this emulator enables mobile systems experiments and plan to make the emulator available for remote access by the research community. Copyright 2005 ACM.",Mobility emulation; Noise injection; Spatial switching; Testbed,Mobility emulation; Noise injection; Spatial switching; Testbed; Computer hardware; Computer networks; Interfaces (computer); Radio receivers; Standards; Wireless telecommunication systems
"Gopal S., Raychaudhuri D.",2,Experimental evaluation of the TCP simultaneous-send problem in 802.11 wireless local area networks,2005,6,"WINLAB, Rutgers University, 73, Brett Road, Piscataway, NJ 08854-8048, United States",Rutgers University,1,USA,1,14,8,"This paper is an experimental follow up to our earlier paper [1] that investigated the TCP simultaneous-send problem which arises in infrastructure mode 802.11 wireless local area networks. In particular it was observed that for file transfer traffic, 802.11 wireless nodes have a sustained supply of packets to send and hence experience a relatively high rate of MAC contention. We showed that for TCP, this resulted in competition among data and ACK packets for channel access which caused considerable deterioration in flow throughput. Simulations of TCP ACK skipping as an alleviation to the problem, showed improvements as high as 100% when MAC retries were disabled. There were gains in other scenarios too albeit more moderate. We evaluate the same TCP simultaneous-send problem with real world experiments on a wireless-cum-wired network testbed called ORBIT [2] at WINLAB, Rutgers University. ORBIT makes it feasible to conduct controlled and reproducible experiments in a wireless network scenario. The same network setup scenarios evaluated in simulations were considered here., particularly - scenarios with and without MAC retries, multiple TCP flows and multiple skipped ACKs. However not all scenarios could be reproduced in experiments for logistical reasons. In all, the experimental results confirm the original hypothesis on the detrimental effects of simultaneous-send and corroborate the advantages of ACK skipping, However the percentage gains in TCP throughput are far more moderate as compared to those observed in NS simulations. A reason could be differing TCP implementations, particularly with not all TCP optimizations implemented in NS. We share the experiences and challenges faced, particularly given that this work is among the first of its kind for testbed evaluation of transport protocols over wireless networks. Copyright 2005 ACM.",802.11 MAC; Controlled wireless environment; DCF; Delayed ACKs; Experimental evaluation; Full-fledged wireless network testbed; Simultaneous-send; Skipped ACKs; TCP; Wireless networking,802.11 MAC; Controlled wireless environment; DCF; Delayed ACKs; Experimental evaluation; Full-fledged wireless network testbed; Simultaneous-send; Skipped ACKs; TCP; Wireless networking; Computer networks; Local area networks; Problem solving; Standards; Wireless telecommunication systems; Network protocols
"Patwari N., Hero III A.O., Pacholski A.",3,Manifold learning visualization of network traffic data,2005,11,"University of Michigan, Dept. of Electrical Engineering and Computer Science, 1301 Beal Avenue, Ann Arbor, MI, United States",University of Michigan at Ann Arbor,1,USA,1,17,12,"When traffic anomalies or intrusion attempts occur on the network, we expect that the distribution of network traffic will change. Monitoring the network for changes over time, across space (at various routers in the network), over source and destination ports, IP addresses, or AS numbers, is an important part of anomaly detection. We present a manifold learning (ML)-based tool for the visualization of large sets of data which emphasizes the unusually small or large correlations that exist within the data set. We apply the tool to display anomalous traffic recorded by NetFlow on the Abilene backbone network, Furthermore, we present an online Java-based GUI which allows interactive demonstration of the use of the visualization method. Copyright 2005 ACM.",Data mining; Internet traffic anomaly detection&forensics,Computer programming languages; Data mining; Fault tolerant computer systems; Graphical user interfaces; Learning systems; Visualization; Abilene backbone network; Internet traffic anomaly detection&forensics; Manifold learning (ML)-based tool; Traffic anomalies; Telecommunication traffic
"Vaidya N.H., Bernhard J., Veeravalli V.V., Kumar P.R., Iyer R.K.",5,Illinois wireless wind tunnel: A testbed for experimental evaluation of wireless networks,2005,11,"Department of Electrical and Computer Engineering, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, United States",UIUC,1,USA,1,16,11,"This paper describes a proposed testbed named Illinois Wireless Wind Tunnel (iWWT). The goal of the testbed is to implement ""scaled"" versions of wireless networks for the purpose of accurate repeatable evaluation of wireless protocols. The testbed will be implemented in an electromagnetic anechoic chamber at the University of Illinois at Urbana-Champaign. Although the iWWT testbed will be used primarily for evaluation of protocols above the physical layer, the design of the iWWT requires a careful attention to physical characteristics of the environment. This paper presents preliminary thoughts on scaling of wireless networks in the iWWT. Copyright 2005 ACM.",Performance evaluation; Testbeds; Wireless protocols,Performance evaluation; Testbeds; Wireless protocols; Computer networks; Electromagnetic waves; Environmental impact; Network protocols; Performance; Wireless telecommunication systems
"Jurca R., Faltings B.",2,Reputation-based pricing of P2P services,2005,16,"Ecole Polytechnique FŽdŽrale de Lausanne (EPFL), Artificial Intelligence Laboratory, CH-1015 Lausanne, Switzerland","EPFL, Switzerland",1,Switzerland,1,14,10,"In the future peer-to-peer service oriented computing systems, maintaining a cooperative equilibrium is a non-trivial task. In the absence of Trusted Third Parties (TTP's) or verification authorities, rational service providers minimize their costs by providing ever degrading service quality levels. Anticipating this, rational clients are willing to pay only the minimum amounts (often zero) which leads to the collapse of the market. In this paper, we show how a simple reputation mechanism can be used to overcome this moral hazard problem. The mechanism does not act by social exclusion (i.e. exclude providers that cheat) but rather by allowing flexible service level agreements in which quality can be traded for the price. We show that such a mechanism can drive service providers of different types to exert the social efficient effort levels. Copyright 2005 ACM.",Reputation; Service Level Agreement; Service Oriented Computing,Broadband networks; Quality of service; Telecommunication systems; Reputation; Service Level Agreement; Service Oriented Computing; Distributed computer systems
"Sanghavi S., Hajek B.",2,A new mechanism for the free-rider problem,2005,7,"Electrical and Computer Engineering, Coordinated Science Laboratory, UIUC, United States",UIUC,1,USA,1,10,6,"The free-rider problem arises in the provisioning of public resources, when users of the resource have to contribute towards the cost of production, Selfish users may have a tendency to misrepresent preferences - so as to minimize individual contributions - leading to inefficient levels of production of the resource. Groves and Loeb formulated a classic model capturing this problem, and proposed (what later came to be known as) the VCG mechanism as a solution. However, in the presence of heterogeneous users and communication constraints, or in decentralized settings, implementing this mechanism places an unrealistic communication burden. In this paper we propose a class of alternative mechanisms for the same problem as considered by Groves and Loeb, but with the added constraint of severely limited communication between users and the provisioning authority. When these mechanisms are used, efficient production is ensured as a Nash equilibrium outcome, for a broad class of users. Furthermore, a natural bid update strategy is shown to globally converge to efficient Nash equilibria. An extension to multiple public goods with inter-related valuations is also presented. Copyright 2005 ACM.",Algorithms; Economics; Theory,Free-rider problem; Nash equilibrium outcome; Public resources; Algorithms; Constraint theory; Convergence of numerical methods; Costs; Economics; Phase equilibria; Theory; Problem solving
"Kandula S., Katabi D., Vasseur J.-P.",3,Shrink: A tool for failure diagnosis in IP networks,2005,38,"MIT CSAIL, United States; Cisco Systems",MIT,1,USA,1,12,7,"Faults in an IP network have various causes such as the failure of one or more routers at the IP layer, fiber-cuts, failure of physical elements at the optical layer, or extraneous causes like power out-ages. These faults are usually detected as failures of a set of dependent logical entities-the IP links affected by the failed components. We present Shrink, a tool for root cause analysis of network faults which, given a set of failed IP links, identifies the underlying cause of the faulty state. Shrink models the diagnosis problem as a Bayesian network. It has two main contributions. First, it effectively accounts for noisy measurement and inaccurate mapping between the IP and optical layers. Second, it has an efficient inference algorithm that finds the most likely failure causes in polynomial time and with bounded errors. We compare Shrink with two prior approaches and show that it substantially improves the performance. Copyright 2005 ACM.",Bayesian; Fault Diagnosis; IP networks; Optical; Shrink; SRLG,Bayesian; Fault Diagnosis; IP networks; Optical; Shrink; SRLG; Computer system recovery; Error analysis; Optical links; Polynomials; Problem solving; Internet
"Rodrig M., Reis C., Mahajan R., Wetherall D., Zahorjan J.",5,Measurement-based characterization of 802.11 in a hotspot setting,2005,45,"University of Washington, United States",University of Washington,1,USA,1,11,11,"We analyze wireless measurements taken during the SIGCOMM 2004 conference to understand how well 802.11 operates in real deployments. We find that the overhead of 802.11 is high, with only 40% of the transmission time spent in sending original data. Most of the remaining time is consumed by retransmissions due to packet losses that are caused by both contention and transmission errors. Our analysis also shows that wireless nodes adapt their transmission rates with an extremely high frequency. We comment on the difficulties and opportunities of working with wireless traces, rather than the wired traces of wireless activity that are presently more common. Copyright 2005 ACM.",802.11; Measurement; Wireless networks,802.11; Transmission errors; Wireless networks; Error analysis; Measurements; Standards; Wireless telecommunication systems
"Devitt A., Duffin J., Moloney R.",3,Topographical proximity for mining network alarm data,2005,4,"Network Management Research Centre, Ericsson R and D Ireland, Dublin 4, Ireland",Ericsson Research,1,Ireland,1,15,12,"Increasingly powerful fault management systems are required to ensure robustness and quality of service in today's networks. In this context, event correlation is of prime importance to extract meaningful information from the wealth of alarm data generated by the network. Existing sequential data mining techniques address the task of identifying possible correlations in sequences of alarms. The output sequence sets, however, may contain sequences which are not plausible from the point of view of network topology constraints. This paper presents the Topographical Proximity (TP) approach which exploits topographical information embedded in alarm data in order to address this lack of plausibility in mined sequences. An evaluation of the quality of mined sequences is presented and discussed. Results show an improvement in overall system performance for imposing proximity constraints. Copyright 2005 ACM.",Event correlation; Fault data; Mining sequential patterns; Network configuration; Topographical proximity,Constraint theory; Correlation methods; Fault tolerant computer systems; Quality of service; Robustness (control systems); Topology; Event correlation; Fault data; Mining sequential patterns; Network configuration; Topographical proximity; Data mining
"Leguay J., Friedman T., Conan V.",3,DTN routing in a mobility pattern space,2005,26,"Univ. P. and M. Curie, France; Thales, France",University Pierre and Marie Curie,1,France,1,18,14,Routing in delay tolerant networks (DTNs) benefits considerably if one can take advantage of knowledge concerning node mobility. The main contribution of this paper is the definition of a generic routing scheme for DTNs using a high-dimensional Euclidean space constructed upon nodes' mobility patterns. We call this the MobySpace. One way of representing nodes in this space is to give them coordinates that correspond to their probability of being found in each possible location. We present simulation results indicating that such a scheme can be beneficial in a scenario inspired by studies done on real mobility traces. This work should open the way to further use of the virtual space formalism in DTN routing. Copyright 2005 ACM.,Delay Tolerant Networks; Mobility; Routing,Delay Tolerant Networks; DTN routing; Mobility; MobySpace; Routing; Computer networks; Computer operating systems; Computer simulation; Mobile telecommunication systems; Transmission line theory; Data communication systems
"Walsh K., Sirer E.G.",2,Fighting peer-to-peer SPAM and decoys with object reputation,2005,28,"Department of Computer Science, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,23,19,"Peer-to-peer filesharing is now commonplace and its traffic now dominates bandwidth consumption at many Internet peering points. Recent studies indicate that much of this filesharing activity involves corrupt and polluted files. This paper describes Credence, a new object-based reputation system, and shows how it can counteract content pollution in peer-to-peer filesharing networks. Credence allows honest peers to assess the authenticity of online content by securely tabulating and managing endorsements from other peers. We employ a novel voter correlation scheme to weigh the opinions of peers, which gives rise to favorable incentives and system dynamics. We present simulation results indicating that our system is scalable, efficient, and robust. Copyright 2005 ACM.",File Sharing; Pollution; Reputation Systems,Favorable incentives; File Sharing; Reputation Systems; Bandwidth; Computer simulation; Correlation methods; Internet; Pollution; Telecommunication traffic; Distributed computer systems
"Small T., Haas Z.J.",2,Resource and performance tradeoffs in delay-tolerant wireless networks,2005,96,"Wireless Networks Laboratory, Center for Applied Mathematics, Cornell University, Ithaca, NY 14853, United States; Wireless Networks Laboratory, Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,14,11,"Wireless and mobile network technologies often impose severe limitations on the availability of resources, resulting in poor and often unsatisfactory performance of the commonly used wireless networking protocols. For instance, power and memory/storage constraints of miniaturized network nodes reduce the throughput capacity and increase the network latency. Through various approaches and technological advances, researchers attempt to somehow compensate for such hardware limitations. However, this is not; always necessary, Sometimes, the required performance of such networks does not need to adhere to the level of services that would be required for performance-critical applications, For example, for some applications of sensor networks, minimal latency is not a critical factor and it could be traded off for a more limited resource, such as energy or throughput. Such networks are termed delay-tolerant networks. Thus, to reduce the energy expenditure, transmission range of such sensor nodes would be quite short, leading to network topologies in which the average number of neighbors of the network nodes is very small. If the sensor nodes are mobile, then most of the time a node has no neighbors; only infrequently another node migrates into its neighborhood. This means that the classical networking approach of store-and-forward would not work well, as there is nearly never an intact path between a source and a destination. Several routing protocols have been proposed for this type of networking environment, one example is the Shared Wireless Infostation Model (SWIM), where a packet propagates through the network by being copied (rather than forwarded) from a node to a node, as links are sporadically created. The goal is that one of the copies of the packet reaches the destination. SWIM is an example of the way that non-critical performance could be traded off for insufficient resources, such as the tradeoffs between energy, delay, storage, capacity, and processing complexity. In this paper, we examine some of these tradeoffs, exposing the ways in which resources could be saved by compromising on the level of performance, as to satisfy the particular limitations of network technologies. Copyright 2005 ACM.",Carry and forward; Data mules; Delay-tolerant networks; Epidemic routing; Message ferrying; Resource tradeoffs; Sensor networks; Shared wireless infostation model; Sparse networks; Store and forward; SWIM,Information analysis; Mobile telecommunication systems; Network protocols; Sensors; Telecommunication equipment; Carry and forward; Data mules; Delay-tolerant networks; Epidemic routing; Message ferrying; Resource tradeoffs; Sensor networks; Shared wireless infostation model; Store and forward; SWIM; Wireless telecommunication systems
"Wu Z., Ganu S., Seskar I., Raychaudhuri D.",4,Experimental investigation of PHY layer rate control and frequency selection in 802.11-based ad-hoc networks,2005,2,"WINLAB, Department of Electrical and Computer Engineering, Rutgers, The State University of New Jersey, 73 Brett Road, Piscataway, NJ 08554, United States",Rutgers University,1,USA,1,16,13,"This paper presents an experimental investigation of the performance impact of two important PHY layer design options that arise in 802.11 ad-hoc networks. In particular, throughput results are provided for multi-hop ad-hoc networks with and without PHY auto-rate control and for single vs. multiple frequencies. The study is motivated by the fact that default 802.11-based ad-hoc networks using commercially preset auto-rate PHY and a single frequency channel suffer from performance degradations caused by link quality fluctuations and MAC layer self-interference respectively. A baseline ad-hoc network scenario is set up on the ORBIT radio grid testbed at Rutgers and is used to determine end-to-end multi-hop flow throughput with default rate control and single channel operation. These results are then compared with those obtained with multiple channels and alternative PHY-rate selection methods demonstrating the potential for significant performance improvements. We observed significant improvements in end-to-end flow throughput, as much as _4x for multiple channel vs. single channel and _3x for optimally controlled PHY rate vs auto-rate. Copyright 2005 ACM.",Ad-hoc Networks; Experimental evaluation; Multi-hop networks,Channel capacity; Performance; Standards; Throughput; Ad-hoc Networks; Experimental evaluation; Multi-hop networks; Computer networks
"Judd G., Steenkiste P.",2,A simple mechanism for capturing and replaying wireless channels,2005,2,"Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University,1,USA,1,7,4,"Physical layer wireless network emulation has the potential to be a powerful experimental tool. An important challenge in physical emulation, and traditional simulation, is to accurately model the wireless channel. In this paper we examine the possibility of using on-card signal strength measurements to capture wireless channel traces. A key advantage of this approach is the simplicity and ubiquity with which these measurements can be obtained since virtually all wireless devices provide the required metrics. We show that for low delay spread environments wireless traces gathered using this method can be replayed in a physical wireless emulator to produce higher layer network behavior that is similar to the behavior that would have occurred in the real world. Thus, wireless channel traces gathered using on-card metrics are an effective means of enabling existing low delay spread wireless testbeds to be emulated. Copyright 2005 ACM.",Channel capture; Emulation; Wireless,Carrier communication; Computer networks; Computer simulation; Channel capture; Emulation; Wireless channel traces; Wireless telecommunication systems
"Hussain A., Bartlett G., Pryadkin Y., Heidemann J., Papadopoulos C., Bannister J.",6,Experiences with a continuous network tracing infrastructure,2005,7,"USC, Information Sciences Institute, 4676 Admirality Way, Marina del Rey, CA 90292, United States; Sparta Inc., 3415 S. Sepulveda Blvd, Los Angeles, CA 90034, United States",Sparta Inc.;University of Southern California,2,USA,1,12,5,"One of the most pressing problems in network research is the lack of long-term trace data from ISPs. The Internet carries an enormous volume and variety of data; mining this data can provide valuable insight into the design and development of new protocols and applications. Although capture cards for high-speed links exist today, actually making the network traffic available for analysis involves more than just getting the packets off the wire, but also handling large and variable traffic loads, sanitizing and anonymizing the data, and coordinating access by multiple users. In this paper we discuss the requirements, challenges, and design of an effective traffic monitoring infrastructure for network research. We describe our experience in deploying and maintaining a multi-user system for continuous trace collection at a large regional ISP. We evaluate the performance of our system and show that it can support sustained collection and processing rates of over 160-300Mbits/s. Copyright 2005 ACM.",Continuous trace collection; Trace infrastructure,Data mining; Data processing; Network protocols; Telecommunication traffic; Continuous trace collection; Trace infrastructure; Traffic monitoring; Internet
"Widmer J., Le Boudec J.-Y.",2,Network coding for efficient communication in extreme networks,2005,114,"DoCoMo Euro-Labs, Landsbergerstr. 312, 80687 Munich, Germany; Ecole Polytechnique FŽdŽrale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland","EPFL, Switzerland",1,Germany;Switzerland,2,24,21,"Some forms of ad-hoc networks need to operate in extremely performance-challenged environments where end-to-end connectivity is rare. Such environments can be found for example in very sparse mobile networks where nodes ""meet"" only occasionally and are able to exchange information, or in wireless sensor networks where nodes sleep most of the time to conserve energy. Forwarding mechanisms in such networks usually resort to some form of intelligent flooding, as for example in probabilistic routing. We propose a communication algorithm that significantly reduces the overhead of probabilistic routing algorithms, making it a suitable building block for a delay-tolerant network architecture. Our forwarding scheme is based on network coding. Nodes do not simply forward packets they overhear but may send out information that is coded over the contents of several packets they received. We show by simulation that this algorithm achieves the reliability and robustness of flooding at a small fraction of the overhead. Copyright 2005 ACM.",Delay-Tolerant Network; Network Coding,Computer simulation; Data communication equipment; Information science; Mobile telecommunication systems; Network components; Sensors; Delay-Tolerant Network; Network Coding; Routing; Wireless sensor networks; Computer networks
"Ng C., Buonadonna P., Churr B.N., Snoeren A.C., Vahdat A.",5,Addressing strategic behavior in a deployed microeconomic resource allocator,2005,3,"Harvard, United States; Intel Research Berkeley, United States; UC San Diego, United States",Intel;University of California San Diego,2,USA,1,20,14,"While market-based systems have long been proposed as solutions for distributed resource allocation, few have been deployed for production use in real computer systems. Towards this end, we present our initial experience using Mirage, a microeconomic resource allocation system based on a repeated combinatorial auction. Mirage allocates time on a heavily-used 148-node wireless sensor network testbed, In particular, we focus on observed strategic user behavior over a four-month period in which 312,148 node hours were allocated across 11 research projects. Based on these results, we present a set of key challenges for market-based resource allocation systems based on repeated combinatorial auctions. Finally, we propose refinements to the system's current auction scheme to mitigate the strategies observed to date and also comment on some initial steps toward building an approximately strategy proof repeated combinatorial auction. Copyright 2005 ACM.",Market-Based Systems; Resource Allocation; Strategic Behavior,Combinatorial auctions; Market-Based Systems; Strategic Behavior; Approximation theory; Computer systems; Economic and social effects; Resource allocation
"Borgia E., Conti M., Delmastro F., Gregori E.",4,Experimental comparison of routing and middleware solutions for mobile ad hoc networks: Legacy vs cross-layer approach,2005,9,"Pervasive Computing and Networking Lab. (PerLab), IIT Institute, CNR, via G. Moruzzi, 1-56124 Pisa, Italy","CNR,Italy",1,Italy,1,17,11,"In this paper we present an experimental evaluation of a full ad hoc network architecture with particular attention to routing and middleware layers. In particular we set up a MANET prototype on which we performed a large set of experiments: in a first phase, we analyzed performances of a proactive and a reactive routing protocols in case of low mobility scenarios in small-medium scale ad hoc networks; then we studied the performances of a first prototype of an optimized p2p system for ad hoc networks (CrossROAD), based on a cross-layer interaction with a proactive routing protocol. Our analysis shows that the use of a proactive routing protocol does not negatively influence system performances, furthermore it allows the optimization of a structured p2p system on ad hoc networks, providing a complete and timely updated knowledge of the network topology. In this way, the overlay network is completely self-organizing and correctly manages network partitioning and topology changes. © Copyright 2005 ACM.",Cross-layer architecture; Experimental evaluation; P2p systems; Routing protocols,Middleware; Network protocols; Optimization; Performance; Cross-layer architecture; Experimental evaluation; P2p systems; Routing protocols; Computer networks
"Mortier R., Isaacs R., Barham P.",3,Anemone: Using end-systems as a rich network management platform,2005,1,"Microsoft Research, Cambridge, United Kingdom",Microsoft,1,UK,1,1,1,"Enterprise networks contain hundreds, if not thousands, of cooperative end-systems. We advocate devoting a small fraction of their idle cycles, free disk space and network bandwidth to create Anemone, a platform for network management. In contrast to current approaches which rely on traffic statistics provided by network devices, Anemone combines end-system instrumentation with routing protocol collection to provide a semantically rich view of the network.",Distributed enterprise network management,Bandwidth; Information management; Network protocols; Routers; Telecommunication traffic; Cooperative end-systems; Distributed enterprise network management; Network management; Routing protocol; Computer networks
"Karamcheti V., Geiger D., Kedem Z., Muthukrishnan S.",4,Detecting malicious network traffic using inverse distributions of packet contents,2005,28,"Courant Institute of Mathematical Sciences, New York University, United States; Department of Computer Science, Rutgers University, United States",Courant Institute of Mathematical Sciences;NYU;Rutgers University,3,USA,1,15,12,"We study the problem of detecting malicious IP traffic in the network early, by analyzing the contents of packets. Existing systems look at packet contents as a bag of substrings and study characteristics of its base distribution B where B(i) is the frequency of substring i.We propose studying the inverse distribution I where I(f) is the number of substrings that appear with frequency f. As we show using a detailed case study, the inverse distribution shows the emergence of malicious traffic very clearly not only in its ""static"" collection of bumps, but also in its nascent ""dynamic"" state when the phenomenon manifests itself only as a distortion of the inverse distribution envelope. We describe our probabilistic analysis of the inverse distribution in terms of Gaussian mixtures, our preliminary solution for discovering these bumps automatically. Finally, we briefly discuss challenges in analyzing the inverse distribution of IP contents and its applications. © 2005 ACM.",content analysis; inverse distribution; worms,Content analysis; Existing systems; Gaussian mixtures; Inverse distribution; Inverse distribution envelope; Malicious traffic; Probabilistic analysis; worms; Telecommunication traffic
"Hussain A., Bartlett G., Pryadkin Y., Heidemann J., Papadopoulos C., Bannister J.",6,Experiences with a continuous network tracing infrastructure,2005,4,"USC, Information Sciences Institute, 4676 Admirality Way, Marina del Rey, CA 90292, United States; Sparta Inc., 3415 S. Sepulveda Blvd, Los Angeles, CA 90034, United States",Sparta Inc.;University of Southern California,2,USA,1,12,5,"One of the most pressing problems in network research is the lack of long-term trace data from ISPs. The Internet carries an enormous volume and variety of data; mining this data can provide valuable insight into the design and development of new protocols and applications. Although capture cards for high-speed links exist today, actually making the network traffic available for analysis involves more than just getting the packets off the wire, but also handling large and variable traffic loads, sanitizing and anonymizing the data, and coordinating access by multiple users. In this paper we discuss the requirements, challenges, and design of an effective traffic monitoring infrastructure for network research. We describe our experience in deploying and maintaining a multi-user system for continuous trace collection at a large regional ISP@. We evaluate the performance of our system and show that it can support sustained collection and processing rates of over 160 - 300Mbits/s. © 2005 ACM.",continuous trace collection; trace infrastructure,Continuous trace collection; Design and Development; High-speed links; Multiuser system; Network tracing; Processing rates; Trace infrastructure; Traffic monitoring; Internet protocols; Internet service providers
"Hui P., Chaintreau A., Scott J., Gass R., Crowcroft J., Diot C.",6,Pocket switched networks and human mobility in conference environments,2005,713,"University of Cambridge, United Kingdom; Intel Research Cambridge, United Kingdom",Intel;University of Cambridge,2,UK,1,10,10,"Pocket Switched Networks (PSN) make use of both human mobility and local/global connectivity in order to transfer data between mobile users' devices. This falls under the Delay Tolerant Networking (DTN) space, focusing on the use of opportunistic networking. One key problem in PSN is in designing forwarding algorithms which cope with human mobility patterns. We present an experiment measuring forty-one humans' mobility at the Infocom 2005 conference. The results of this experiment are similar to our previous experiments in corporate and academic working environments, in exhibiting a power-law distrbution for the time between node contacts. We then discuss the implications of these results on the design of forwarding algorithms for PSN. © 2005 ACM.",delay-tolerant networking; mobile networking; network measurement; wireless networking,Delay Tolerant Networking; Forwarding algorithms; Mobile networking; Network measurement; Opportunistic networking; Pocket switched networks; Wireless networking; Working environment; Algorithms; Experiments; Packet networks; Wireless ad hoc networks; Wireless networks; Delay tolerant networks
"Ishibashi K., Toyono T., Toyama K., Ishino M., Ohshima H., Mizukoshi I.",6,Detecting mass-mailing worm infected hosts by mining DNS traffic data,2005,11,"NTT Information Sharing Platform Labs., NTT Corporation, 3-9-11 Midori-cho, Musashino-shi, Tokyo 180-8585, Japan; NTT Communications Corporation, 2-3-5 Otemachi, Chiyoda-ku, Tokyo 100-0004, Japan","NTT Corporation,Japan",1,Japan,1,22,11,"The Domain Name System (DNS) is a critical infrastructure in the Internet; thus, monitoring its traffic, and protecting DNS from malicious activities are important for security in cyberspace. However, it is often difficult to determine whether a DNS query is caused by malicious or normal activity, because information available in DNS traffic is limited.We focus on the activities of mass-mailing worms and propose a method to detect hosts infected by mass-mailing worms by mining DNS traffic data. Our method begins with a small amount of a priori knowledge about a signature query. By assuming that queries sent by most hosts that have sent the signature query of worms have been sent by worm behavior, we detect infected hosts using Bayesian estimation.We apply our method to DNS traffic data captured at one of the largest commercial Internet Service Providers in Japan, and the experimental result indicates that an 89% reduction of mail exchange queries can be achieved with the method. © 2005 ACM.",data mining; domain name system; mass-mailing worm,Bayesian; Commercial internet; Cyberspaces; DNS traffics; Domain name system; Malicious activities; Mass-mailing worm; Priori knowledge; Data mining; Internet service providers; Internet protocols
"Leguay J., Friedman T., Conan V.",3,DTN routing in a mobility pattern space,2005,221,"Laboratoire LiP6-CNRS, UniversitŽ Pierre et Marie Curie, France; TAI Laboratory, Thales, France",University Pierre and Marie Curie,1,France,1,18,14,Routing in delay tolerant networks (DTNs) benefits considerably if one can take advantage of knowledge concerning node mobility. The main contribution of this paper is the definition of a generic routing scheme for DTNs using a high-dimensional Euclidean space constructed upon nodes' mobility patterns. We call this the MobySpace. One way of representing nodes in this space is to give them coordinates that correspond to their probability of being found in each possible location. We present simulation results indicating that such a scheme can be beneficial in a scenario inspired by studies done on real mobility traces. This work should open the way to further use of the virtual space formalism in DTN routing. © 2005 ACM.,delay tolerant networks; mobility; routing,Delaytolerant networks (DTNs); Euclidean spaces; Generic routing; High-dimensional; Mobility pattern; Mobility traces; routing; Virtual spaces; Carrier mobility; Wireless networks; Delay tolerant networks
"Jeon S.-E., Ji C.",2,Role of machine learning in configuration management of ad hoc wireless networks,2005,0,"Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,2,0,"In this work, we show that machine learning, e.g., graphical models, plays an important role for the self-configuration of ad hoc wireless network. The role of such a learning approach includes a simple representation of complex dependencies in the network and a distributed algorithm which can adaptively find a nearly optimal configuration. © 2005 ACM.",Distributed Automated Management; I.6.5 [Model Development]: Modeling methodologies,Ad hoc wireless networks; Configuration management; Distributed Automated Management; GraphicaL model; Learning approach; Modeling methodology; Self configuration; Complex networks; Learning systems; Ad hoc networks
"Mortier R., Isaacs R., Barham P.",3,Anemone: Using end-systems as a rich network management platform,2005,3,"Microsoft Research, Cambridge, United Kingdom",Microsoft,1,UK,1,1,1,"Enterprise networks contain hundreds, if not thousands, of cooperative end-systems. We advocate devoting a small fraction of their idle cycles, free disk space and network bandwidth to create Anemone, a platform for network management. In contrast to current approaches which rely on traffic statistics provided by network devices, Anemone combines end-system instrumentation with routing protocol collection to provide a semantically rich view of the network. © 2005 ACM.",distributed enterprise network management,Cooperative end-systems; Distributed enterprise network management; End-systems; Enterprise networks; Management platforms; Network bandwidth; Network devices; Traffic statistics; Industry; Traffic surveys; Network management
"Spyropoulos T., Psounis K., Raghavendra C.S.",3,Spray and wait: An efficient routing scheme for intermittently connected mobile networks,2005,878,"Department of Electrical Engineering, USC, United States",University of Southern California,1,USA,1,28,19,"Intermittently connected mobile networks are sparse wireless networks where most of the time there does not exist a complete path from the source to the destination. These networks fall into the general category of Delay Tolerant Networks. There are many real networks that follow this paradigm, for example, wildlife tracking sensor networks, military networks, inter-planetary networks, etc. In this context, conventional routing schemes would fail.To deal with such networks researchers have suggested to use flooding-based routing schemes. While flooding-based schemes have a high probability of delivery, they waste a lot of energy and suffer from severe contention, which can significantly degrade their performance. Furthermore, proposed efforts to significantly reduce the overhead of flooding-based schemes have often be plagued by large delays. With this in mind, we introduce a new routing scheme, called Spray and Wait, that ""sprays"" a number of copies into the network, and then ""waits"" till one of these nodes meets the destination.Using theory and simulations we show that Spray and Wait outperforms all existing schemes with respect to both average message delivery delay and number of transmissions per message delivered; its overall performance is close to the optimal scheme. Furthermore, it is highly scalable retaining good performance under a large range of scenarios, unlike other schemes. Finally, it is simple to implement and to optimize in order to achieve given performance goals in practice. © 2005 ACM.",ad-hoc networks; delay tolerant networks; intermittent connectivity; routing,Conventional routing; Efficient routing; Intermittent connectivity; Intermittently connected mobile networks; Message delivery delay; Military networks; Number of transmissions; routing; Delay tolerant networks; Floods; Optimization; Routing protocols; Sensor networks; Wireless networks; Computer simulation
"Small T., Haas Z.J.",2,Resource and performance tradeoffs in delay-tolerant wireless networks,2005,118,"Wireless Networks Laboratory, Center for Applied Mathematics, Cornell University, Ithaca, NY 14853, United States; Wireless Networks Laboratory, Department of Electrical and Computer, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,14,11,"Wireless and mobile network technologies often impose severe limitations on the availability of resources, resulting in poor and often unsatisfactory performance of the commonly used wireless networking protocols. For instance, power and memory/storage constraints of miniaturized network nodes reduce the throughput capacity and increase the network latency. Through various approaches and technological advances, researchers attempt to somehow compensate for such hardware limitations. However, this is not always necessary. Sometimes, the required performance of such networks does not need to adhere to the level of services that would be required for performance-critical applications. For example, for some applications of sensor networks, minimal latency is not a critical factor and it could be traded off for a more limited resource, such as energy or throughput. Such networks are termed delay-tolerant networks. Thus, to reduce the energy expenditure, transmission range of such sensor nodes would be quite short, leading to network topologies in which the average number of neighbors of the network nodes is very small. If the sensor nodes are mobile, then most of the time a node has no neighbors; only infrequently another node migrates into its neighborhood. This means that the classical networking approach of store-and-forward would not work well, as there is nearly never an intact path between a source and a destination. Several routing protocols have been proposed for this type of networking environment, one example is the Shared Wireless Infostation Model (SWIM), where a packet propagates through the network by being copied (rather than forwarded) from a node to a node, as links are sporadically created. The goal is that one of the copies of the packet reaches the destination. SWIM is an example of the way that non-critical performance could be traded off for insufficient resources, such as the tradeoffs between energy, delay, storage, capacity, and processing complexity. In this paper, we examine some of these tradeoffs, exposing the ways in which resources could be saved by compromising on the level of performance, as to satisfy the particular limitations of network technologies. © 2005 ACM.",carry and forward; data MULEs; delay-tolerant networks; epidemic routing; message ferrying; resource tradeoffs; sensor networks; shared wireless infostation model; sparse networks; store and forward; SWIM,Carry and forward; Data mules; Delay-Tolerant Network; Epidemic routing; Message ferrying; Resource tradeoffs; Shared wireless infostation model; Sparse network; Store and forward; SWIM; Commerce; Complex networks; Digital storage; Electric network topology; Packet networks; Routing protocols; Sensor networks; Sensor nodes; Wireless networks; Delay tolerant networks
"Patwari N., Hero III A.O., Pacholski A.",3,Manifold learning visualization of network traffic data,2005,8,"University of Michigan, Dept. of Electrical Engineering and Computer Science, 1301 Beal Avenue, Ann Arbor, MI, United States",University of Michigan at Ann Arbor,1,USA,1,17,11,"When traffic anomalies or intrusion attempts occur on the network, we expect that the distribution of network traffic will change. Monitoring the network for changes over time, across space (at various routers in the network), over source and destination ports, IP addresses, or AS numbers, is an important part of anomaly detection. We present a manifold learning (ML)-based tool for the visualization of large sets of data which emphasizes the unusually small or large correlations that exist within the data set. We apply the tool to display anomalous traffic recorded by NetFlow on the Abilene backbone network. Furthermore, we present an online Java-based GUI which allows interactive demonstration of the use of the visualization method. © 2005 ACM.",data mining; internet traffic anomaly detection & forensics,Abilene backbone network; Anomaly detection; Internet traffic; Manifold learning; Manifold learning-based tools; Network traffic; Traffic anomalies; Visualization method; Data mining; Telecommunication traffic; Tools; Visualization
"Wang Y., Jain S., Martonosi M., Fall K.",4,Erasure-coding based routing for opportunistic networks,2005,150,"Princeton University, Princeton, NJ, United States; University of Washington, United States; Intel Research Berkeley, United States",Intel;Princeton University;University of Washington at Seattle,3,USA,1,15,14,"Routing in Delay Tolerant Networks (DTN) with unpredictable node mobility is a challenging problem because disconnections are prevalent and lack of knowledge about network dynamics hinders good decision making. Current approaches are primarily based on redundant transmissions. They have either high overhead due to excessive transmissions or long delays due to the possibility of making wrong choices when forwarding a few redundant copies. In this paper, we propose a novel forwarding algorithm based on the idea of erasure codes. Erasure coding allows use of a large number of relays while maintaining a constant overhead, which results in fewer cases of long delays.We use simulation to compare the routing performance of using erasure codes in DTN with four other categories of forwarding algorithms proposed in the literature. Our simulations are based on a real-world mobility trace collected in a large outdoor wild-life environment. The results show that the erasure-coding based algorithm provides the best worst-case delay performance with a fixed amount of overhead. We also present a simple analytical model to capture the delay characteristics of erasure-coding based forwarding, which provides insights on the potential of our approach. © 2005 ACM.",delay tolerant network; erasure coding; routing,Delay characteristics; Delay performance; Erasure coding; Erasure-coding based forwarding; Forwarding algorithms; Opportunistic networks; routing; Routing performance; Algorithms; Forward error correction; Routers; Wireless networks; Delay tolerant networks
"Kandula S., Katabi D., Vasseur J.-P.",3,Shrink: A tool for failure diagnosis in IP networks,2005,80,"MIT CSAIL, United States; CISCO Systems, United States",MIT,1,USA,1,12,7,"Faults in an IP network have various causes such as the failure of one or more routers at the IP layer, fiber-cuts, failure of physical elements at the optical layer, or extraneous causes like power outages. These faults are usually detected as failures of a set of dependent logical entities - the IP links affected by the failed components. We present Shrink, a tool for root cause analysis of network faults which, given a set of failed IP links, identifies the underlying cause of the faulty state. Shrink models the diagnosis problem as a Bayesian network. It has two main contributions. First, it effectively accounts for noisy measurement and inaccurate mapping between the IP and optical layers. Second, it has an efficient inference algorithm that finds the most likely failure causes in polynomial time and with bounded errors. We compare Shrink with two prior approaches and show that it substantially improves the performance. © 2005 ACM.",Bayesian; fault diagnosis; IP networks; optical; shrink; SRLG,Bayesian; IP networks; optical; shrink; SRLG; Failure analysis; Inference engines; Outages; Polynomial approximation; Routers; Tools; Bayesian networks
"Zhang J., Rexford J., Feigenbaum J.",3,Learning-based anomaly detection in BGP updates,2005,21,"Computer Science Dept., Yale University, New Haven, CT 06520, United States; Computer Science Dept., Princeton University, Princeton, NJ 08544, United States",Princeton University;Yale University,2,USA,1,12,10,"Detecting anomalous BGP-route advertisements is crucial for improving the security and robustness of the Internet's interdomain-routing system. In this paper, we propose an instance-learning framework that identifies anomalies based on deviations from the ""normal"" BGP-update dynamics for a given destination prefix and across prefixes. We employ wavelets for a systematic, multi-scaled analysis that avoids the ""magic numbers"" (e.g., for grouping related update messages) needed in previous approaches to BGP-anomaly detection. Our preliminary results show that the update dynamics are generally consistent across prefixes and time. Only a few prefixes differ from the majority, and most prefixes exhibit similar behavior across time. This small set of abnormal prefixes and time intervals may be further examined to determine the source of anomalous behavior. In particular, we observe that many of the unusual prefixes are unstable prefixes that experience frequent routing changes. © 2005 ACM.",anomaly detection; instance-based learning; wavelets,Anomalous behavior; Anomaly detection; Instance based learning; Interdomain-routing system; Magic numbers; Time interval; Update messages; wavelets; Fault tolerant computer systems
"Haffner P., Sen S., Spatscheck O., Wang D.",4,ACAS: Automated construction of application signatures,2005,173,"AT and T Labs.-Research, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,14,13,"An accurate mapping of traffic to applications is important for a broad range of network management and measurement tasks. Internet applications have traditionally been identified using well-known default server network-port numbers in the TCP or UDP headers. However this approach has become increasingly inaccurate. An alternate, more accurate technique is to use specific application-level features in the protocol exchange to guide the identification. Unfortunately deriving the signatures manually is very time consuming and difficult.In this paper, we explore automatically extracting application signatures from IP traffic payload content. In particular we apply three statistical machine learning algorithms to automatically identify signatures for a range of applications. The results indicate that this approach is highly accurate and scales to allow online application identification on high speed links. We also discovered that content signatures still work in the presence of encryption. In these cases we were able to derive content signature for unencrypted handshakes negotiating the encryption parameters of a particular connection. © 2005 ACM.",application signatures; application-level filter; machine learning,Accurate mapping; Application signatures; Application-level filter; Automated construction; High-speed links; Internet application; On-line applications; Statistical machine learning; Cryptography; Learning systems; Network management; Transmission control protocol; Learning algorithms
"Jones E.P.C., Li L., Ward P.A.S.",3,Practical routing in delay-tolerant networks,2005,103,"Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",University of Waterloo,1,Canada,1,19,15,"Delay-tolerant networks (DTNs) have the potential to connect devices and areas of the world that are under-served by current networks. A critical challenge for DTNs is determining routes through the network without ever having an end-to-end connection, or even knowing which ""routers"" will be connected at any given time. Prior approaches have focused either on epidemic message replication or on knowledge of the connectivity schedule. The epidemic approach of replicating messages to all nodes is expensive and does not appear to scale well with increasing load. It can, however, operate without any prior network configuration. The alternatives, by requiring a priori connectivity knowledge, appear infeasible for a self-configuring network.In this paper we present a practical routing protocol that only uses observed information about the network. We designed a metric that estimates how long a message will have to wait before it can be transferred to the next hop. The topology is distributed using a link-state routing protocol, where the link-state packets are ""flooded"" using epidemic routing. The routing is recomputed when connections are established. Messages are exchanged if the topology suggests that a connected node is ""closer"" than the current node.We demonstrate through simulation that our protocol provides performance similar to that of schemes that have global knowledge of the network topology, yet without requiring that knowledge. Further, it requires a significantly smaller quantity of buffer, suggesting that our approach will scale with the number of messages in the network, where replication approaches may not. © 2005 ACM.",delay tolerant network; route metrics; routing,Critical challenges; Delay-Tolerant Network; Delaytolerant networks (DTNs); End-to-end connections; Network configuration; Replication approaches; Route metrics; routing; Electric network topology; Packet networks; Routers; Routing protocols; Topology; Delay tolerant networks
"El-Arini K., Killourhy K.",2,Bayesian detection of router configuration anomalies,2005,9,"Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States; Dependable Systems Laboratory, Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University,1,USA,1,4,2,"Problems arising from router misconfigurations cost time and money. The first step in fixing such misconfigurations is finding them. In this paper, we propose a method for detecting misconfigurations that does not depend on an a priori model of what constitutes a correct configuration. Our hypothesis is that uncommon or unexpected misconfigurations in router data can be identified as statistical anomalies within a Bayesian framework. We present a detection algorithm based on this framework, and show that it is able to detect errors in the router configuration files of a university network. © 2005 ACM.",router configuration; statistical anomaly detection,Bayesian detection; Bayesian frameworks; Detection algorithm; Misconfigurations; Priori model; Router configuration; Statistical anomaly detection; Routers
"Harrop W., Armitage G.",2,Greynets: A definition and evaluation of sparsely populated darknets,2005,3,"Centre for Advanced Internet Architecture, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,12,11,"Darknets are often proposed to monitor for anomalous, externally sourced traffic, and require large, contiguous blocks of unused IP addresses - not always feasible for enterprise network operators. We introduce and evaluate the Greynet - a region of IP address space that is sparsely populated with 'darknet' addresses interspersed with active (or 'lit') IP addresses. Based on a small sample of traffic collected within a university campus network we saw that relatively sparse greynets can achieve useful levels of network scan detection. © 2005 ACM.",darknet; Greynet; intrusion detection systems; network security; network telescope; sparse darknets,Darknet; Greynet; Intrusion Detection Systems; Network telescopes; Sparse Darknets; Network security
"Zhao W., Ammar M., Zegura E.",3,Multicasting in delay tolerant networks: Semantic models and routing algorithms,2005,100,"College of Computing, Georgia Institute of Technology, Atlanta, GA 30332, United States",Georgia Tech,1,USA,1,24,17,"Delay tolerant networks (DTNs) are a class of emerging networks that experience frequent and long-duration partitions. These networks have a variety of applications in situations such as crisis environments and deep-space communication. In this paper, we study the problem of multicasting in DTNs. Multicast supports the distribution of data to a group of users, a service needed for many potential DTN applications. While multicasting in the Internet and mobile ad hoc networks has been studied extensively, due to the unique characteristic of frequent partitioning in DTNs, multicasting in DTNs is a considerably different and challenging problem. It not only requires new definitions of multicast semantics but also brings new issues to the design of routing algorithms. In this paper, we propose new semantic models for DTN multicast and develop several multicast routing algorithms with different routing strategies. We present a framework to evaluate these algorithms in DTNs. To the best of our knowledge, this is the first study of multicasting in DTNs. Our objectives are to understand how routing performance is affected by the availability of knowledge about network topology and group membership and to guide the design of DTN routing protocols. Using ns simulations, we find that efficient multicast routing for DTNs can be constructed using only partial knowledge. In addition, accurate topology information is generally more important in routing than up-to-date membership information. We also find that routing algorithms that forward data along multiple paths achieve better delivery ratios, especially when available knowledge is limited. © 2005 ACM.",delay tolerant networks; multicast; semantic model,Deep space communications; Delaytolerant networks (DTNs); Membership information; Multicast routing algorithms; Routing performance; Routing strategies; Semantic Model; Topology information; Ad hoc networks; Electric network topology; Mobile ad hoc networks; Multicasting; Network routing; Routing algorithms; Semantics; Delay tolerant networks
"Zhang B., Kambhampati V., Lad M., Massey D., Zhang L.",5,Identifying BGP routing table transfers,2005,23,"Computer Science Department, University of Arizona, United States; Computer Science Department, Colorado State University, United States; Computer Science Department, University of California, Los Angeles, CA, United States",Colorado State University;University of Arizona;University of California Los Angeles,3,USA,1,9,7,"BGP routing updates collected by monitoring projects such as RouteViews and RIPE have been a vital source to our understanding of the global routing system. The updates logged by these monitoring projects are generated either by individual route changes, or are part of BGP table transfer. In particular, a session reset between a monitoring station and its BGP peers can result in the peer sending its entire BGP routing table to the monitoring station. In this paper, we present a Minimum Collection Time (MCT) algorithm that accurately identify the start and duration of routing table transfers. Using three months of data from 14 different peers, MCT can identify routing table transfers triggered by BGP session resets with 100% accuracy, and can pinpoint the exact starting time of table transfers in 90% of the cases. © 2005 ACM.",BGP; collection time; routing table transfer; session reset,BGP; Collection time; Global routing; Monitoring stations; Route changes; Routing Table Transfer; Session Reset; Starting time; Routing protocols; Routers
"Devitt A., Duffin J., Moloney R.",3,Topographical proximity for mining network alarm data,2005,7,"Network Management Research Centre, Ericsson R and D Ireland, Dublin 4, Ireland",Ericsson Research,1,Ireland,1,15,12,"Increasingly powerful fault management systems are required to ensure robustness and quality of service in today's networks. In this context, event correlation is of prime importance to extract meaningful information from the wealth of alarm data generated by the network. Existing sequential data mining techniques address the task of identifying possible correlations in sequences of alarms. The output sequence sets, however, may contain sequences which are not plausible from the point of view of network topology constraints. This paper presents the Topographical Proximity (TP) approach which exploits topographical information embedded in alarm data in order to address this lack of plausibility in mined sequences. An evaluation of the quality of mined sequences is presented and discussed. Results show an improvement in overall system performance for imposing proximity constraints. © 2005 ACM.",event correlation; fault data; mining sequential patterns; network configuration; topographical proximity,Event correlation; Fault data; Mining sequential patterns; Network configuration; Topographical proximity; Alarm systems; Electric network topology; Quality of service; Data mining
"Widmer J., Le Boudec J.-Y.",2,Network coding for efficient communication in extreme networks,2005,145,"DoCoMo Euro-Labs., Landsbergerstr. 312, 80687 Munich, Germany; Ecole Polytechnique FŽdŽrale de Lausanne (EPFL), CH1015 Lausanne, Switzerland","EPFL, Switzerland",1,Germany;Switzerland,2,24,21,"Some forms of ad-hoc networks need to operate in extremely performance-challenged environments where end-to-end connectivity is rare. Such environments can be found for example in very sparse mobile networks where nodes ""meet"" only occasionally and are able to exchange information, or in wireless sensor networks where nodes sleep most of the time to conserve energy. Forwarding mechanisms in such networks usually resort to some form of intelligent flooding, as for example in probabilistic routing.We propose a communication algorithm that significantly reduces the overhead of probabilistic routing algorithms, making it a suitable building block for a delay-tolerant network architecture. Our forwarding scheme is based on network coding. Nodes do not simply forward packets they overhear but may send out information that is coded over the contents of several packets they received. We show by simulation that this algorithm achieves the reliability and robustness of flooding at a small fraction of the overhead. © 2005 ACM.",delay-tolerant network; network coding,Building blockes; Communication algorithms; Delay-Tolerant Network; Efficient communications; End-to-end connectivity; Forwarding mechanisms; Probabilistic routing; Reliability and robustness; Algorithms; Communication; Floods; Network architecture; Network coding; Sensor nodes; Delay tolerant networks
"Xu K., Chandrashekar J., Zhang Z.-L.",3,A first step toward understanding inter-domain routing dynamics,2005,19,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, United States",University of Minnesota,1,USA,1,12,7,"BGP updates are triggered by a variety of events such as link failures, resets, routers crashing, configuration changes, and so on. Making sense of these updates and identifying the underlying events is key to debugging and troubleshooting BGP routing problems. In this paper, as a first step toward the much harder problem of root cause analysis of BGP updates, we discuss if, and how, updates triggered by distinct underlying events can be separated. Specifically, we explore using PCA (Principal Components Analysis), a well known statistical multi-variate technique, to achieve this goal.We propose a method based on PCA to obtain a set of clusters from a BGP update stream; each of these is a set of entities (either prefixes or ASes) which are affected by the same underlying event. Then we demonstrate our approach using BGP data obtained by simulations and show that the method is quite effective. In addition, we perform a high level analysis of BGP data containing well known, large scale events. © 2005 ACM.",BGP; root cause analysis; routing,BGP; High-level analysis; Interdomain Routing; Large scale events; Principal components analysis; Root cause analysis; routing; Routing problems; Routers; Principal component analysis
"Rodrig M., Reis C., Mahajan R., Wetherall D., Zahorjan J.",5,Measurement-based characterization of 802.11 in a hotspot setting,2005,79,"University of Washington, United States",University of Washington at Seattle,1,USA,1,11,11,"We analyze wireless measurements taken during the SIGCOMM 2004 conference to understand how well 802.11 operates in real deployments. We find that the overhead of 802.11 is high, with only 40% of the transmission time spent in sending original data. Most of the remaining time is consumed by retransmissions due to packet losses that are caused by both contention and transmission errors. Our analysis also shows that wireless nodes adapt their transmission rates with an extremely high frequency. We comment on the difficulties and opportunities of working with wireless traces, rather than the wired traces of wireless activity that are presently more common. © 2005 ACM.",802.11; measurement; wireless networks,802.11; Extremely high frequencies; Measurement-based; Transmission error; Transmission rates; Transmission time; Wireless measurements; Wireless traces; Measurements; Wireless networks
"Ghose A., Ipeirotis P.G., Sundararajan A.",3,Reputation premiums in electronic peer-to-peer markets: Analyzing textual feedback and network structure,2005,6,"Department of Information, Operations, and Management Sciences, Stern School of Business, New York University, 44 W. 4th Street, New York, NY 10012-1126, United States",NYU,1,USA,1,5,5,"Web-based systems that establish reputation are central to the viability of many electronic markets. We present theory that identifies the different dimensions of online reputation and characterizes their influence on the pricing power of sellers. We provide evidence that existing, numeric reputation scores conceal important seller-specific dimensions of reputation and we validate our theory further by proposing a new text mining technique that identifies and quantitatively evaluates further dimensions of importance in reputation profiles. We also suggest that the buyer-seller network contains critical reputation information that we can further exploit to improve the design of a reputation mechanism. Our experimental evaluation validates the predictions of our model using a new data set containing over 12,000 transactions for consumer software on Amazon.com's online secondary marketplace. This paper is the first attempt to integrate econometric methods and text and link mining techniques towards a more complete analysis of the information captured by reputation systems, and it presents new evidence of the importance of their effective and judicious design. © 2005 ACM.",econometrics; electronic markets; opinion analysis; peer to peer markets; reputation; text analysis; text mining; transaction network analysis,econometrics; Electronic market; Opinion analysis; Peer to peer; reputation; Text analysis; Text mining; Data mining; Distributed computer systems; Economics; Electronic commerce; Peer to peer networks
"Ramachandran K., Kaul S., Mathur S., Gruteser M., Seskar I.",5,Towards large-scale mobile network emulation through spatial switching on a wireless grid,2005,11,"WINLAB, Electrical and Computer Engineering Department, Rutgers, the State University of New Jersey, 94 Brett Rd, Piscataway, NJ 08854, United States",Rutgers University,1,USA,1,13,12,"Experimentation with large mobile networks is notoriously tedious and expensive. We present the architecture and work-in-progress implementation of the m-ORBIT testbed, a mobility emulator using spatial switching, which facilitates mobile system experiments with 802.11a/b/g wireless network interfaces. The emulator does not require any physically moving parts - it emulates mobility by switching over an array of 128 spatially distributed radios. Instead of using hardware antenna switches, we implement spatial switching in software over Gigabit Ethernet links to the radio nodes. Preliminary results support the scaling of this approach to a large number of radios at relatively low cost. Packet error rate measurements also indicate that an experimenter can create multi-hop topologies by injecting additive white Gaussian noise into the environment. We demonstrate through an Ad hoc On Demand Distance Vector routing case study how this emulator enables mobile systems experiments and plan to make the emulator available for remote access by the research community. © 2005 ACM.",mobility emulation; noise injection; spatial switching; testbed,Ad hoc On demand Distance Vector routing; Additive White Gaussian noise; Mobility emulation; Multi-hop topologies; Noise injection; Packet error rates; Research communities; Spatial switching; Experiments; Mobile telecommunication systems; Radio links; Switching; Telecommunication networks; Testbeds; Wireless networks
"Borgia E., Conti M., Delmastro F., Gregori E.",4,Experimental comparison of routing and middleware solutions for mobile ad hoc networks: Legacy vs cross-layer approach,2005,8,"Pervasive Computing and Networking Lab. (PerLab), IIT Institute, CNR, via G. Moruzzi, 1, 56124 Pisa, Italy",IIT Institute,1,Italy,1,17,11,"In this paper we present an experimental evaluation of a full ad hoc network architecture with particular attention to routing and middleware layers. In particular we set up a MANET prototype on which we performed a large set of experiments: in a first phase, we analyzed performances of a proactive and a reactive routing protocols in case of low mobility scenarios in small-medium scale ad hoc networks; then we studied the performances of a first prototype of an optimized p2p system for ad hoc networks (CrossROAD), based on a cross-layer interaction with a proactive routing protocol. Our analysis shows that the use of a proactive routing protocol does not negatively influence system performances, furthermore it allows the optimization of a structured p2p system on ad hoc networks, providing a complete and timely updated knowledge of the network topology. In this way, the overlay network is completely self-organizing and correctly manages network partitioning and topology changes. © 2005 ACM.",cross-layer architecture; experimental evaluation; p2p systems; routing protocols,Cross-layer architecture; Cross-layer interaction; Experimental comparison; Experimental evaluation; P2P system; Pro-active routing protocols; Reactive routing protocol; Structured P2P systems; Electric network topology; Middleware; Network architecture; Optimization; Overlay networks; Peer to peer networks; Routing protocols; Wireless networks; Mobile ad hoc networks
"Ng A.C.H., Malone D., Leith D.J.",3,Experimental evaluation of TCP performance and fairness in an 802.11e test-bed,2005,23,"Hamilton Institute, NUI Maynooth, Ireland",Hamilton Institute,1,Ireland,1,17,11,"In this paper we present measurements made using an 802.11e wireless testbed. We demonstrate experimentally how the new 802.11e [1] QoS parameters behave in our testbed. We describe the testing methodology used to validate the operation of the 802.11e TXOP, AIFS and CWmin parameters and compare the experimental results to existing analytical models. We also discuss a number of practical issues encountered during our measurements. We then use the testbed to demonstrate some known problems with TCP's performance caused by cross-layer interaction between the TCP congestion control algorithm and the MAC layer CSMA/CA contention mechanism. Finally, we study how these problems can be mitigated using the flexibility provided by the 802.11e parameters via the scheme suggested in [2]. © 2005 ACM.",802.11; 802.11e; fairness; TCP; test-bed,802.11; 802.11e; Cross-layer interaction; Experimental evaluation; fairness; TCP; TCP congestion control algorithm; Testing methodology; Algorithms; Testbeds; Wireless networks
"Kawadia V., Kumar P.R.",2,Experimental investigations into TCP performance over wireless multihop networks,2005,56,"BBN Technologies, Cambridge, MA, United States; University of Illinois at Urbana-Champaign, Urbana, IL, United States",BBN Technologies;UIUC,2,USA,1,19,14,"The results of an extensive experimental study of the performance of the TCP protocol over wireless multi-hop ad hoc networks are presented. The investigations are performed in a real indoor environment over a network of laptops equipped with off-the-shelf IEEE 802.11b wireless cards. The cards were partially covered with copper tape to reduce their range, which enabled creation of manageable topologies. Several tools were written and assembled to make the entire process of experimentation including topology setup, traffic generation, trace collection, and archival and analysis of data repeatable, reliable and as automated as possible. The experimental observations are subjected to a thorough statistical analysis. The final result of the study is a recommendation of some TCP and IEEE 802.11 parameters that are best for TCP performance over wireless multi-hop networks. The most critical of these include setting a destination dependent clamp on the sender congestion window and disabling the RTC-CTS handshake. The methods and techniques used, as well as the support tools developed, and statistical analysis, may be of larger interest in wireless network experimentation. © 2005 ACM.",ad hoc networks; experimentation; TCP,Experimental investigations; experimentation; Indoor environment; Network experimentations; TCP; Traffic generation; Wireless multi-hop; Wireless multi-hop network; Ad hoc networks; Experiments; Standards; Statistical methods; Tools; Topology; Transmission control protocol; Wireless ad hoc networks; Wireless networks
"Jurca R., Faltings B.",2,Reputation-based pricing of P2P services,2005,17,"Ecole Polytechnique FŽdŽrale de Lausanne (EPFL), Artificial Intelligence Laboratory, CH-1015 Lausanne, Switzerland","EPFL, Switzerland",1,Switzerland,1,14,10,"In the future peer-to-peer service oriented computing systems, maintaining a cooperative equilibrium is a non-trivial task. In the absence of Trusted Third Parties (TTP's) or verification authorities, rational service providers minimize their costs by providing ever degrading service quality levels. Anticipating this, rational clients are willing to pay only the minimum amounts (often zero) which leads to the collapse of the market.In this paper, we show how a simple reputation mechanism can be used to overcome this moral hazard problem. The mechanism does not act by social exclusion (i.e. exclude providers that cheat) but rather by allowing flexible service level agreements in which quality can be traded for the price. We show that such a mechanism can drive service providers of different types to exert the social efficient effort levels. © 2005 ACM.",reputation; service level agreement; service oriented computing,Cooperative equilibrium; Non-trivial tasks; Peer-to-peer services; reputation; Reputation mechanism; Service Level Agreements; Service oriented computing; Trusted third parties; Commerce; Computer systems; Costs; Network architecture; Quality of service; Risk management; Telecommunication services; Economics
"Irwin D., Chase J., Grit L., Yumerefendi A.",4,Self-recharging virtual currency,2005,10,"Duke University, United States",Duke University,1,USA,1,23,16,"Market-based control is attractive for networked computing utilities in which consumers compete for shared resources (computers, storage, network bandwidth). This paper proposes a new self-recharging virtual currency model as a common medium of exchange in a computational market. The key idea is to recycle currency through the economy automatically while bounding the rate of spending by consumers. Currency budgets may be distributed among consumers according to any global policy; consumers spend their budgets to schedule their resource usage through time, but cannot hoard their currency or starve.We outline the design and rationale for self-recharging currency in Cereus, a system for market-based community resource sharing, in which participants are authenticated and sanctions are sufficient to discourage fraudulent behavior. Currency transactions in Cereus are accountable: offline third-party audits can detect and prove cheating, so participants may transfer and recharge currency autonomously without involvement of the trusted banking service. © 2005 ACM.",market; virtual currency,Community resources; Computational market; Market-based control; Medium of exchange; Network bandwidth; Networked computing; Self-recharging currency; Virtual currency; Budget control; Commerce; Consumer behavior; Marketing; Economics
"Jamieson K., Hull B., Miu A., Balakrishnan H.",4,Understanding the real-world performance of carrier sense,2005,69,"MIT, Computer Science and Artificial Intelligence Laboratory, Stata Center, 32 Vassar St., Cambridge, MA 02139, United States",MIT,1,USA,1,13,8,"Carrier sense is a fundamental part of most wireless networking stacks in wireless local area- and sensor networks. As increasing numbers of users and more demanding applications push wireless networks to their capacity limits, the efficacy of the carrier sense mechanism becomes a key factor in determining wireless network capacity.We describe how carrier sense works, point out its limitations, and advocate an experimental approach to studying carrier sense. We describe our current testbed setup, and then present preliminary experimental results from both a 60-node sensor network deployment and a small-scale 802.11 deployment. Our preliminary results evaluate how well carrier sense works and expose its limitations. © 2005 ACM.",carrier sense; medium access control,Capacity limit; Carrier sense; Carrier sense mechanism; Experimental approaches; Key factors; Network deployment; Real-world performance; Wireless networking; Medium access control; Sensor networks; Sensor nodes; Wireless networks
"Vaidya N.H., Bernhard J., Veeravalli V.V., Kumar P.R., Iyer R.K.",5,Illinois wireless wind tunnel: A testbed for experimental evaluation of wireless networks,2005,12,"Department of Electrical and Computer Engineering, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, IL, United States",UIUC,1,USA,1,16,11,"This paper describes a proposed testbed named Illinois Wireless Wind Tunnel (iWWT). The goal of the testbed is to implement ""scaled"" versions of wireless networks for the purpose of accurate repeatable evaluation of wireless protocols. The testbed will be implemented in an electromagnetic anechoic chamber at the University of Illinois at Urbana-Champaign. Although the iWWT testbed will be used primarily for evaluation of protocols above the physical layer, the design of the iWWT requires a careful attention to physical characteristics of the environment. This paper presents preliminary thoughts on scaling of wireless networks in the iWWT. © 2005 ACM.",performance evaluation; testbeds; wireless protocols,Electromagnetic anechoic chamber; Experimental evaluation; Illinois; performance evaluation; Physical characteristics; Physical layers; University of Illinois; Wireless protocol; Design; Network layers; Testbeds; Wind tunnels; Wireless networks
"Ho L., Moh M., Walker Z., Hamada T., Su C.-F.",5,A prototype on RFID and sensor networks for elder healthcare: Progress report,2005,51,"Venturi Wireless, Sunnyvale, CA, United States; Dept. of Computer Science, San Jose State University, San Jose, CA, United States; IP Networking Research, Fujitsu Laboratories of America, Sunnyvale, CA, United States",Fujitsu Laboratories Ltd.;IP Networking Research;San Jose State University,3,USA,1,24,23,"Radio Frequency Identification (RFID) and sensor networks are both wireless technologies that provide limitless future potentials. While the industry has witnessed rapid growth in developing and applying RFID technology, and the network research community has devoted tremendous efforts in sensor networks, these two communities would benefit greatly by learning from each other. In pursuing this effect, a project utilizing and integrating both technologies is described. The goal is to build an in-home elder healthcare system that monitors patients' medication in take. This would help addressing the challenge of a growing aging population. © 2005 ACM.",healthcare; RFID; sensor networks,Aging population; Health-care system; Progress report; Rapid growth; Research communities; Rfid and sensors; RFID Technology; Wireless technologies; Health care; Radio frequency identification (RFID); Scheduling; Wireless networks; Wireless telecommunication systems; Sensor networks
"Bhattacharjee R., Goel A.",2,Avoiding ballot stuffing in eBay-like reputation systems,2005,25,"Department of Computer Science, Stanford University, United States; Departments of Management Science and Engineering and Computer Science, Stanford University, United States",Stanford University,1,USA,1,14,12,"We present a preliminary study on the robustness of binary feedback reputation systems (e.g. eBay) to ballot stuffing and bad mouthing. In a feedback based reputation system, a seller can collude with other buyers to undertake fake transactions in order to enhance her reputation. This problem is referred to as ballot stuffing. A seller can also be targeted by a group of buyers to deliberately lower her reputation. This problem is referred to as bad mouthing. For the reputations to be meaningful, any practical reputation system needs to be resistant to these problems. We use a simplified model to give an explicit relation between the reputation premium and the transaction cost that needs to hold in order to avoid ballot stuffing. Thus we draw attention to the necessity of transaction costs for a well functioning reputation system. Our conclusions are confirmed by empirical experiments on eBay. © 2005 ACM.",reputation systems,Bad mouthing; Ballot stuffing; Binary feedback; Empirical experiments; Feed-back based; Reputation systems; Transaction cost; Feedback
"Walsh K., Sirer E.G.",2,Fighting peer-to-peer SPAM and decoys with object reputation,2005,54,"Department of Computer Science, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,23,19,"Peer-to-peer filesharing is now commonplace and its traffic now dominates bandwidth consumption at many Internet peering points. Recent studies indicate that much of this filesharing activity involves corrupt and polluted files. This paper describes Credence, a new object-based reputation system, and shows how it can counteract content pollution in peer-to-peer filesharing networks. Credence allows honest peers to assess the authenticity of online content by securely tabulating and managing endorsements from other peers. We employ a novel voter correlation scheme to weigh the opinions of peers, which gives rise to favorable incentives and system dynamics. We present simulation results indicating that our system is scalable, efficient, and robust. © 2005 ACM.",file sharing; pollution; reputation systems,Bandwidth consumption; Correlation scheme; Favorable incentives; File Sharing; File sharing networks; On-line contents; Reputation systems; System Dynamics; Distributed computer systems; Internet; Pollution; Peer to peer networks
"Judd G., Steenkiste P.",2,A simple mechanism for capturing and replaying wireless channels,2005,15,"Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University,1,USA,1,7,4,"Physical layer wireless network emulation has the potential to be a powerful experimental tool. An important challenge in physical emulation, and traditional simulation, is to accurately model the wireless channel. In this paper we examine the possibility of using on-card signal strength measurements to capture wireless channel traces. A key advantage of this approach is the simplicity and ubiquity with which these measurements can be obtained since virtually all wireless devices provide the required metrics. We show that for low delay spread environments wireless traces gathered using this method can be replayed in a physical wireless emulator to produce higher layer network behavior that is similar to the behavior that would have occurred in the real world. Thus, wireless channel traces gathered using on-card metrics are an effective means of enabling existing low delay spread wireless testbeds to be emulated. © 2005 ACM.",channel capture; emulation; wireless,Channel capture; emulation; Network emulation; Signal strength measurements; Wireless channel; Wireless channel traces; Wireless devices; Wireless testbed; Computer simulation; Radio; Wireless networks; Network layers
"Wu Z., Ganu S., Seskar I., Raychaudhuri D.",4,Experimental investigation of PHY layer rate control and frequency selection in 802.11-based ad-hoc networks,2005,8,"WINLAB, Department of Electrical and Computer Engineering, Rutgers, the State University of New Jersey, 73 Brett Road, Piscataway, NJ 08554, United States",Rutgers University,1,USA,1,16,13,"This paper presents an experimental investigation of the performance impact of two important PHY layer design options that arise in 802.11 ad-hoc networks. In particular, throughput results are provided for multi-hop ad-hoc networks with and without PHY auto-rate control and for single vs. multiple frequencies. The study is motivated by the fact that default 802.11-based ad-hoc networks using commercially preset auto-rate PHY and a single frequency channel suffer from performance degradations caused by link quality fluctuations and MAC layer self-interference respectively. A baseline ad-hoc network scenario is set up on the ORBIT radio grid testbed at Rutgers and is used to determine end-to-end multi-hop flow throughput with default rate control and single channel operation. These results are then compared with those obtained with multiple channels and alternative PHY-rate selection methods demonstrating the potential for significant performance improvements. We observed significant improvements in end-to-end flow throughput, as much as _4x for multiple channel vs. single channel and _3x for optimally controlled PHY rate vs auto-rate. © 2005 ACM.",ad-hoc networks; experimental evaluation; multi-hop networks,Experimental evaluation; Experimental investigations; Frequency selection; Multi-hop ad hoc network; Multihop networks; Performance degradation; Performance impact; Single channel operation; Design; Telecommunication networks; Throughput; Ad hoc networks
"Jun S., Ahamad M.",2,Incentives in BitTorrent induce free riding,2005,107,"College of Computing, Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech,1,USA,1,20,14,"We investigate the incentive mechanism of BitTorrent, which is a peer-to-peer file distribution system. As downloaders in BitTorrent are faced with the conflict between the eagerness to download and the unwillingness to upload, we relate this problem to the iterated prisoner's dilemma, which suggests guidelines to design a good incentive mechanism. Based on these guidelines, we propose a new, simple incentive mechanism. Our analysis and the experimental results using PlanetLab show that the original incentive mechanism of BitTorrent can induce free riding because it is not effective in rewarding and punishing downloaders properly. In contrast, a new mechanism proposed by us is shown to be more robust against free riders. © 2005 ACM.",BitTorrent; data dissemination; incentive mechanisms; prisoner's dilemma; strategy,Bit torrents; Data dissemination; Incentive mechanism; Prisoner's dilemma; strategy; Game theory; Distributed computer systems
"Gopal S., Raychaudhuri D.",2,Experimental evaluation of the TCP simultaneous-send problem in 802.11 wireless local area networks,2005,8,"WINLAB, Rutgers University, 73, Brett Road, Piscataway, NJ 08854-8048, United States",Rutgers University,1,USA,1,14,8,"This paper is an experimental follow up to our earlier paper [1] that investigated the TCP simultaneous-send problem which arises in infrastructure mode 802.11 wireless local area networks. In particular it was observed that for file transfer traffic, 802.11 wireless nodes have a sustained supply of packets to send and hence experience a relatively high rate of MAC contention. We showed that for TCP, this resulted in competition among data and ACK packets for channel access which caused considerable deterioration in flow throughput. Simulations of TCP ACK skipping as an alleviation to the problem, showed improvements as high as 100% when MAC retries were disabled. There were gains in other scenarios too albeit more moderate.We evaluate the same TCP simultaneous-send problem with real world experiments on a wireless-cum-wired network testbed called ORBIT [2] at WINLAB, Rutgers University. ORBIT makes it feasible to conduct controlled and reproducible experiments in a wireless network scenario. The same network setup scenarios evaluated in simulations were considered here., particularly - scenarios with and without MAC retries, multiple TCP flows and multiple skipped ACKs. However not all scenarios could be reproduced in experiments for logistical reasons. In all, the experimental results confirm the original hypothesis on the detrimental effects of simultaneous-send and corroborate the advantages of ACK skipping, However the percentage gains in TCP throughput are far more moderate as compared to those observed in NS simulations. A reason could be differing TCP implementations, particularly with not all TCP optimizations implemented in NS. We share the experiences and challenges faced, particularly given that this work is among the first of its kind for testbed evaluation of transport protocols over wireless networks. © 2005 ACM.",802.11 MAC; controlled wireless environment; DCF; delayed ACKs; experimental evaluation; full-fledged wireless network testbed; simultaneous-send; skipped ACKs; TCP; wireless networking,802.11 MAC; Controlled wireless environment; DCF; Delayed ACKs; Experimental evaluation; Full-fledged wireless network testbed; Simultaneous-send; Skipped ACKs; TCP; Wireless networking; Computer simulation; Experiments; Testbeds; Wireless local area networks (WLAN); Transmission control protocol
"Jardosh A.P., Ramachandran K.N., Almeroth K.C., Belding-Royer E.M.",4,Understanding link-layer behavior in highly congested IEEE 802.11b wireless networks,2005,44,"Department of Computer Science, University of California, Santa Barbara, CA, United States",University of California Santa Barbara,1,USA,1,12,12,"The growing deployment and concomitant rise in wireless network usage necessitates the comprehensive understanding of its behavior. More importantly, as networks grow in size and number of users, congestion in the wireless portion of the network is likely to increase. We believe there is a strong need to understand the intricacies of the wireless portion of a congested network by interpreting information collected from the network. Congestion in a wireless network can be best analyzed by studying the transmission of frames at the link layer. To this end, we use vicinity sniffing techniques to analyze the link layer in an operational IEEE 802.11b wireless network. In this paper, we discuss how congestion in a network can be estimated using point-to-point link reliability. We then show how link reliability is correlated with the behavior of link-layer properties such as frame retransmissions, frame sizes, and data rates. Based on the results from these correlations, our hypothesis is that the performance of the link layer in congested networks can be improved by (1) sending smaller frames, and/or (2) using higher data rates with a fewer number of frames sent. © 2005 ACM.",IEEE 802.11b; network congestion; performance analysis,Congested networks; IEEE 802.11b; Link layers; Link reliability; Network congestions; Performance analysis; Point-to-point link; Retransmissions; Standards; Wireless networks
"Sanghavi S., Hajek B.",2,A new mechanism for the free-rider problem,2005,18,"Electrical and Computer Engineering, Coordinated Science Laboratory, UIUC, United States",UIUC,1,USA,1,10,6,"The free-rider problem arises in the provisioning of public resources, when users of the resource have to contribute towards the cost of production. Selfish users may have a tendency to misrepresent preferences - so as to minimize individual contributions - leading to inefficient levels of production of the resource. Groves and Loeb formulated a classic model capturing this problem, and proposed (what later came to be known as) the VCG mechanism as a solution. However, in the presence of heterogeneous users and communication constraints, or in decentralized settings, implementing this mechanism places an unrealistic communication burden. In this paper we propose a class of alternative mechanisms for the same problem as considered by Groves and Loeb, but with the added constraint of severely limited communication between users and the provisioning authority. When these mechanisms are used, efficient production is ensured as a Nash equilibrium outcome, for a broad class of users. Furthermore, a natural bid update strategy is shown to globally converge to efficient Nash equilibria. An extension to multiple public goods with inter-related valuations is also presented. © 2005 ACM.",Algorithms; Economics; G.1.6 [Optimization] Mechansim Design; Non-cooperative Games; Theory,Communication constraints; Cost of productions; Free-rider problem; Heterogeneous users; Limited communication; Nash equilibrium outcome; Noncooperative game; Theory; Algorithms; Economics; Game theory; Telecommunication networks; Communication
"Rolli D., Conrad M., Neumann D., Sorge C.",4,An asynchronous and secure ascending peer-to-peer auction,2005,5,"Institute of Information Engineering and Management, University of Karlsruhe, Germany; Institute of Telematics, University of Karlsruhe, Germany",University of Karlsruhe,1,Germany,1,16,11,"In recent years, auctions have become a very popular price discovery mechanism. Among them, second-price auctions are of theoretical importance, as they have the simple dominant strategy of bidding ones true valuation. Sellers, however, are reluctant to do so, as a malicious auctioneer could take advantage of this knowledge. Several distributed auction mechanisms have been suggested that make it possible to determine the auction outcome without revealing the winner's valuation of the good; however, they are only suitable for sealed-bid auction.This paper suggests a distributed mechanism for ascending second price auctions. The auction protocol has the ability to preserve the privacy of the winning bidder's true valuation or highest bid, respectively, with a high probability. The auction protocol is based on a high number of auctioneers that are distributed to several groups. A bidder generates an encrypted chain of monotonously increasing bidding steps, where each bidding step can be decrypted by a different auctioneer group reducing the possibilities of manipulation for malicious auctioneers. Another fundamental advantage of this secure approach is that bidders need not be online except for submitting their bid chain to the auctioneers. © 2005 ACM.",distributed auctions; peer-to-peer systems; privacy; security protocols; trust,Auction protocols; Distributed Auctions; Dominant strategy; High probability; Peer-to-Peer system; Second-price auction; Security protocols; trust; Chains; Costs; Data privacy; Commerce
"Ng C., Buonadonna P., Chun B.N., Snoeren A.C., Vahdat A.",5,Addressing strategic behavior in a deployed microeconomic resource allocator,2005,17,"Harvard University, United States; Intel Research Berkeley, United States; UC San Diego, United States",Harvard University;Intel;University of California San Diego,3,USA,1,20,14,"While market-based systems have long been proposed as solutions for distributed resource allocation, few have been deployed for production use in real computer systems. Towards this end, we present our initial experience using Mirage, a microeconomic resource allocation system based on a repeated combinatorial auction. Mirage allocates time on a heavily-used 148-node wireless sensor network testbed. In particular, we focus on observed strategic user behavior over a four-month period in which 312,148 node hours were allocated across 11 research projects. Based on these results, we present a set of key challenges for market-based resource allocation systems based on repeated combinatorial auctions. Finally, we propose refinements to the system's current auction scheme to mitigate the strategies observed to date and also comment on some initial steps toward building an approximately strategyproof repeated combinatorial auction. © 2005 ACM.",market-based systems; resource allocation; strategic behavior,Combinatorial auction; Distributed resource allocation; Market-based resource allocation; Market-Based Systems; Resource allocation systems; Resource allocator; Strategic Behavior; Wireless sensor network test beds; Commerce; Computer systems; Economics; Resource allocation; Sensor nodes; Telecommunication services; Behavioral research
"Dahlberg T.A., Nasipuri A., Taylor C.",3,Explorebots: A mobile network experimentation testbed,2005,11,"University of North Carolina-Charlotte, 9201 University City Blvd., Charlotte, NC 28223-0001, United States; Southwest Research Institute, 6220 Culebra Road, San Antonio, TX 78228-0510, United States",Southwest Research Institute;University of North Carolina-Charlotte,2,USA,1,15,5,"In this paper, we detail our development of Explorebots - expandable, vision- and sensor-equipped wireless robots built around MICA motes. We developed Explorebots as a dynamic outreach for an NSF-funded Girl Scouts project. We've extended the capabilities of Explorebots to comprise a mobile network experimentation testbed. The testbed will support experimental analysis of protocols for mobile multi-hop networks. The low-cost Explorebots enable repeatable experiments without complete reliance on human subjects for mobility. © 2005 ACM.",mobile robotics; multi-hop networks; sensor networks; testbed,Experimental analysis; Human subjects; Mobile robotic; Multihop networks; Network experimentations; Wireless robots; Experiments; Mica; Sensor networks; Testbeds; Wireless networks
"Andrade N., Mowbray M., Lima A., Wagner G., Ripeanu M.",5,Influences on cooperation in BitTorrent communities,2005,57,"Universidade Federal de Campina Grande, Brazil; HP Laboratories Bristol, Brazil; University of Chicago, United States",HP Labs;Universidade Federal de Campina Grande;University of Chicago,3,Brazil;USA,2,18,16,We collect BitTorrent usage data across multiple file-sharing communities and analyze the factors that affect users' cooperative behavior. We find evidence that the design of the BitTorrent protocol results in increased cooperative behavior over other P2P protocols used to share similar content (e.g. Gnutella). We also investigate two additional community-specific mechanisms that foster even more cooperation. © 2005 ACM.,BitTorrent; cooperation; P2P,Bit torrents; Co-operative behaviors; cooperation; File Sharing; Gnutella; P2P; P2P protocols; Usage data; Behavioral research
"Kompella R.R., Ramabhadran S., Ramani I., Snoeren A.C.",4,Cooperative packet scheduling via pipelining in 802.11 wireless networks,2005,7,"University of California, San Diego, San Diego, CA 92093, United States",University of California San Diego,1,USA,1,16,9,"The proliferation of 802.11a/b/g based wireless devices has fueled their adoption in many domains - some of which are unforseen. Yet, these devices lack native support for some of the advanced features (such as service differentiation, etc.) required in specific application domains. A subset of these features relies on cooperative scheduling whereby nodes cooperate among each other to effectively manage resources such as power, throughput and interference in wireless networks. The trajectory of evolution in these devices has been primarily through new extension standards (such as 802.11e/s etc.) that offer support for these features. Plagued with long design cycles and cost overhead to upgrade, this process of upgrading creates an uphill task to users who want to use their wireless devices for different applications. In this paper, we argue that such cooperative scheduling extensions can be supported using a new layer on top of the existing MAC layer. We propose a 21/2- pipeline architecture as a generic mechanism to create such domain specific extensions and propose two such protocols, SPARTA (power conservation) and ARGOS (throughput guarantees) over the native 802.11/b/g MAC layer. Using a prototype we built over open source 802.11 wireless device driver, we present some preliminary evaluation of the architecture. © 2005 ACM.",802.11 wireless networks; cooperative scheduling; power conservation; proportional allocation; quality of service; streaming video,802.11 wireless networks; Cooperative scheduling; Power conservation; Proportional allocation; Streaming videos; Design; Network architecture; Quality of service; Radio; Wireless networks; Packet networks
"Cheng A., Friedman E.",2,Sybilproof reputation mechanisms,2005,78,"Center for Applied Mathematics, Cornell University, Ithaca, NY 14853, United States; School of Operations Research and Industrial Engineering, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,9,9,"Due to the open, anonymous nature of many P2P networks, new identities - or sybils - may be created cheaply and in large numbers. Given a reputation system, a peer may attempt to falsely raise its reputation by creating fake links between its sybils. Many existing reputation mechanisms are not resistant to these types of strategies.Using a static graph formulation of reputation, we attempt to formalize the notion of sybilproofness. We show that there is no symmetric sybilproof reputation function. For nonsymmetric reputations, following the notion of reputation propagation along paths, we give a general asymmetric reputation function based on flow and give conditions for sybilproofness. © 2005 ACM.",peer-to-peer; reputation; sybils,Graph formulations; Nonsymmetric; P2P network; Peer to peer; reputation; Reputation mechanism; Reputation systems; sybils; Distributed computer systems
"Cho K., Luckie M., Huffaker B.",3,Identifying IPv6 network problems in the dual-stack world,2004,40,"Sony CSL, WIDE Project, Japan; U.Waikato, NLANR, CAIDA, United States; CAIDA, SDSC, UCSD, United States","Sony,Japan;University of Waikato",2,Japan;USA,2,15,7,"One of the major hurdles limiting IPv6 adoption is the existence of poorly managed experimental IPv6 sites that negatively affect the perceived quality of the IPv6 Internet. To assist network operators in improving IPv6 networks, we are exploring methods to identify wide-area IPv6 network problems. Our approach makes use of parallel IPv4 and IPv6 connectivity to dual-stacked nodes. We identify the existence of an IPv6 path problem by comparing IPv6 delay measurements to IPv4 delay measurements. Our test results indicate that the majority of IPv6 paths have delay characteristics comparable to those of IPv4, although a small number of paths exhibit a much larger delay with IPv6. Thus, we hope to improve the quality of the IPv6 Internet by identifying the worst set of problems. Our methodology is simple. We create a list of systems with IPv6 and IPv4 addresses in actual use by monitoring DNS messages. We then measure delay to each address in order to select a few systems per site based on their IPv6:IPv4 response-time ratios. Finally, we run traceroute with Path MTU discovery to the selected systems and then visualize the results for comparative path analysis. This paper presents the tools used to support this study, and the results of our measurements conducted from two locations in Japan and one in Spain.",Delay measurement; Dual-stack; IPv6; Path analysis; Path visualization,Delay measurements; Network management tools; Network monitoring; Communication systems; Problem solving; Quality of service; Visualization; Network protocols
"GauthierDickey C., Zappala D., Lo V.",3,A fully distributed architecture for massively multiplayer online games,2004,3,"University of Oregon, Department of Computer Science, 1202 University of Oregon, Eugene, OR 97403-1202, United States",University of Oregon,1,USA,1,1,1,"The design of a fully distributed, peer-to-peer architecture for MMOs is discussed. The architecture is expected to allow individuals to start their own MMO without the incredible investment in resources required by client/server architectures. The architecture needs to provide tamper-resistant storage of characters and game state and it needs to schedule computations across the players. The architecture must maintain consistency, order events, and propagate events to intended recipients.",Architecture; Distributed; Games; Interactive; Multiplayer,Cheat-proof; Long-term storage; Massively multi-player online games (MMO); Tamper-resistant storage; Computational methods; Computer architecture; Computer simulation; Electronic document identification systems; Game theory; Investments; Network protocols; Problem solving; Servers; Online systems
"Aggarwal S., Banavar H., Khandelwal A., Mukherjee S., Rangarajan S.",5,Accuracy in dead-reckoning based distributed multi-player games,2004,1,"Department of Computer Science, Florida State University, Tallahassee, FL, United States; Center for Networking Research, Lucent Technol. Bell Laboratories, Holmdel, NJ, United States",Florida State University;Bell Labs,2,USA,1,12,8,"Distributed multi-player games use dead reckoning vectors to intimate other (at a distance) participating players about the movement of any entity by a controlling player. The dead reckoning vector contains the current position of the entity and the velocity components. When a participating player receives a vector, traditionally it puts the entity at the current position specified by the vector and starts projecting the path of the entity from that point using the local clock of the receiver. In this paper we show that this traditional method of usage of dead reckoning vector brings in inaccuracy in the receivers' rendering of the entity. This inaccuracy can be substantial even with low network delay between the sender-receiver pairs and increases with network delay. We propose the use of globally synchronized clocks among the participating players and a time-stamp augmented dead reckoning vector that enables the receiver to render the entity accurately. We modified the popular game BZFlag with this technique, and compared the accuracy seen in game playing using the traditional method and the proposed technique. We conducted several types of experiments varying the frequency of generation of dead reckoning vectors and the delay between the sender and the receivers. The experiments show significant quantitative improvement in accuracy even for 100ms delay between the sender-receiver pairs and appreciable qualitative improvement in game playing experience.",Accuracy; Clock Synchronization; Dead-Reckoning; Distributed Multi-Player Games; Network Delay,Accuracy; Clock synchronization; Dea reckoning (DR); Distributed multi-player games; Network delay; Computer networks; Control system analysis; Distributed computer systems; Random processes; Synchronization; Vectors; Game theory
"Ahlgren B., Brunner M., Eggert L., Hancock R., Schmid S.",5,Invariants - A new design methodology for network architectures,2004,24,"Swed. Institute of Computer Science, Box 1263, SE-164 29 Kista, Sweden; NEC Network Laboratories, KurfŸrstenanlage 36, 69115 Heidelberg, Germany; Siemens/Roke Manor Research, Old Salisbury Lane, Romsey, Hampshire, SO51 0ZN, United Kingdom",NEC;Siemens Research;Swedish Institute of Computer Science,3,Germany;Sweden;UK,3,21,18,"The first age of Internet architectural thinking concentrated on defining the correct principles for designing a packet-switched network and its application protocol suites. Although these same principles remain valid today, they do not address the question of how to reason about the evolution of the Internet or its interworking with other networks of very different heritages. This paper proposes a complementary methodology, motivated by the view that evolution and interworking flexibility are determined not so much by the principles applied during initial design, but by the choice of fundamental components or ""design invariants"" in terms of which the design is expressed. The paper discusses the characteristics of such invariants, including examples from the Internet and other networks, and considers what attributes of invariants best support architectural flexibility.",Design Methodology; Design Principles; Invariants; Network Architecture Design,Design Methodology; Design Principles; Invariants; Network Architecture Design; Communication systems; Computer networks; Network protocols; Packet networks; Problem solving; Radio links; Internet
"Shu Z., Kadobayashi Y.",2,Troubleshooting on intra-domain routing instability,2004,2,"Natl. Inst. Info./Commun. Technol., 4-2-1 Nukui-kitamachi, Koganei, Tokyo, 184-8795, Japan; Nara Inst. of Science and Technology, 8916-5 Takayama, Ikoma, Nara, 630-0101, Japan","NIICT,Japan",1,Japan,1,8,4,"Routing instability is a problem directly affecting the reliability of the Internet. While a great deal of effort has been committed to inter-domain routing instability, studies on intra-domain routing have been quite limited. Most network operators still do not have sufficient knowledge on this problem and often complain that: (i) They do not know to what extent the intra-domain routing instability can occur on their networks because this is difficult to detect, and (ii) the causes of this instability are difficult to find. In this paper, we first present the results of some passive measurements we did on intra-domain routing instability. We show the statistical results of OSPF routing information (for both IPv4 and IPv6) we collected on the WIDE Internet and APAN Tokyc-XP network. Through the statistics, we demonstrate how seriously routing instability can occur on a service network. We then propose an approach to help network operators isolate the causes of this. We emphasize the importance of gathering useful data for troubleshooting in event-driven fashion and propose using SNMP or telnet for this. We then explain what kind of data should be collected for the purposes of troubleshooting and how to use this data to isolate the problem.",Cause; Instability; Intra-domain; Monitoring; OSPF; Routing,Cause; Intra-domain; OSPF; Routing; Data acquisition; Error analysis; Internet; Monitoring; Stability; Switching networks; Telecommunication links; Routers
"Friedman D., Huberman B.",2,Internet congestion: A laboratory experiment,2004,4,"University of California, Economics Department, Santa Cruz, CA, United States; Hewlett-Packard Laboratories, 1501 Page Mill Road, Palo Alto, CA, United States",HP Labs;University of California Santa Cruz,2,USA,1,10,6,"Human players and automated players (bots) interact in real time in a congested network. A player's revenue is proportional to the number of successful ""downloads"" and his cost is proportional to his total waiting time. Congestion arises because waiting time is an increasing random function of the number of uncompleted download attempts by all players. Surprisingly, some human players earn considerably higher profits than bots. Bots are better able to exploit periods of excess capacity, but they create endogenous trends in congestion that human players are better able to exploit. Nash equilibrium does a good job of predicting the impact of network capacity and noise amplitude. Overall efficiency is quite low, however, and players overdissipate potential rents, i.e., earn lower profits than in Nash equilibrium.",Asynchronous; Automated agents; Congestion; Human subjects,Asynchronous; Automated agents; Congestion; Human factors; Human subjects; Algorithms; Computer software; Cybernetics; Economics; Game theory; Laboratories; Real time systems; Reliability; Servers; Internet
"Busse M., Lamparter B., Mauve M., Effelsberg W.",4,Lightweight QoS-support for networked mobile gaming,2004,4,"Praktische Informatik IV, University of Mannheim, L15, 16, D-68161 Mannheim, Germany; NEC Europe Ltd., Network Laboratories, KurfŸrsten-Anlage 36, D-69115 Heidelberg, Germany; Institut fŸr Informatik, University of DŸsseldorf, UniversitŠtsstra§e 1, D-40225 DŸsseldorf, Germany",University of DŸsseldorf;University of Mannheim,2,Germany,1,24,16,"In this paper, we present an approach to provide Quality of Service (QoS) for networked mobile gaming. In order to examine the QoS requirements of mobile games, we ported a simple real-time game called GAV (GPL Arcade Volleyball) to a PDA and performed several traffic measurements over both GPRS and UMTS networks. We show that due to high end-to-end delay and delay jitter, real-time games are not supported by GPRS. While UMTS improves both delay and jitter, it still does not match the requirements of real-time games. The key reason for this problem is that overprovisioning, as it is used to allow real-time games in the Internet, is very expensive in mobile networks. At the same time, QoS classes for mobile networks are not tailored to real-time games. In order to reduce delay and jitter for this application class, while still accounting for the very bursty nature of real-time game flows, we propose to use a combination of statistical multiplexing and QoS guarantees. The general idea is to aggregate multiple game flows and perform reservation for that aggregate. As a theoretical background, we use a queuing system based model. Through simulation of a sample network with the traffic data generated by GAV, we validate our assumptions and demonstrate the performance and characteristics of our approach.",Admission control; Flow aggregation; Mobile gaming; QoS-support; Queuing systems; Resource reservation,Admission control; Flow aggregation; GPRS; Mobile gaming; Mobile networks; QoS-support; Resource reservation; Algorithms; Computer simulation; Jitter; Local area networks; Multiplexing; Network protocols; Personal computers; Quality of service; Queueing networks; Real time systems; Telecommunication traffic; Mobile telecommunication systems
"Chen B.D., Maheswaran M.",2,A cheat controlled protocol for centralized online multiplayer games,2004,8,"School of Computer Science, McGill University, Montreal, Canada",McGill University,1,Canada,1,8,8,"Ordering of command messages from the clients at the game servers is an important issue that impacts fairness, response times, and smoothness of the game play. Recently, protocols based on ""reaction"" times were proposed to order the command messages. This paper presents a protocol that can be used to control cheating in reaction time based message ordering schemes. We examine the performance of the proposed protocol by emulating wide-area game play scenarios on the Planet-Lab. The results from the experiments indicate that the proposed protocol is able to dramatically reduce the cheating opportunities that exist for the clients.",Cheat prevention; Multiplayer online games; Time cheating,Cheat controlled protocols; Cheat prevention; Multiplayer online games; Time cheating; Computer crime; Information analysis; Mathematical models; Network protocols; Online systems; Servers; Game theory
Wessels D.,1,Is your caching resolver polluting the internet?,2004,11,"CAIDA, Measurement Factory, Inc., United States",University of California San Diego,1,USA,1,16,10,"Previous research has shown that most of the DNS queries reaching the root of the hierarchy are bogus [1], This behavior derives from two constraints on the system: (1) queries that cannot be satisfied locally percolate up to the root of the DNS; (2) some caching nameservers are behind packet filters or firewalls that allow outgoing queries but block incoming replies. These resolvers assume the network failure is temporary and retransmit their queries, often aggressively. DNS pollution may not be causing any perceivable performance problems. The root servers seem well equipped to handle the load. Since DNS messages are small, the pollution does not contribute significantly to the total traffic generated by most organizations. Nonetheless, this paper provides a few reasons why network operators should take the time to investigate and fix these problems.",DNS caching root server,Distributed nodes; Internal networks; Packet filters; Algorithms; Approximation theory; Computer software; Servers; Telecommunication traffic; Internet
"Roughan M., Griffin T., Mao Z.M., Greenberg A., Freeman B.",5,IP forwarding anomalies and improving their detection using multiple data sources,2004,21,"School of Mathematical Sciences, University of Adelaide, Australia; Intel Research Cambridge, United Kingdom; University of Michigan, United States; AT and T Research, United States; AT and T Labs, United States",AT and T Labs;AT and T Labs;Intel;University of Adelaide;University of Michigan at Ann Arbor,5,Australia;UK;USA,3,19,16,"IP forwarding anomalies, triggered by equipment failures, implementation bugs, or configuration errors, can significantly disrupt and degrade network service. Robust and reliable detection of such anomalies is essential to rapid problem diagnosis, problem mitigation, and repair. We propose a simple, robust method that integrates routing and traffic data streams to reliably detect forwarding anomalies, and report on the evaluation of the method in a tier-1 ISP backbone. First, we transform each data stream separately, to produce informative alarm indicators. A forwarding anomaly is then signalled only if the indicators for both streams indicate anomalous behavior concurrently. The overall method is scalable, automated and self-training. We find this technique effectively identifies forwarding anomalies, while avoiding the high false alarms rate that would otherwise result if either stream were used unilaterally.",BGP; Network anomaly detection; Routing; SNMP; Traffic,BGP; Network anomaly detection; Routing; SNMP; Traffic; Algorithms; Codes (symbols); Error analysis; Reliability; Routers; Security of data; Telecommunication traffic; Network protocols
"Calyam P., Mandrawa W., Sridharan M., Khan A., Schopis P.",5,H.323 Beacon: An H.323 application related end-to-end performance troubleshooting tool,2004,15,"OARnet, 1224 Kinnear Road, Columbus, OH 43212, United States","OARnet,USA",1,USA,1,11,4,"H.323 protocol based Voice and Video conferencing solutions are established popular technologies both in industry and academia. However, these bandwidth intensive applications are often plagued by various performance problems. In this paper we describe a few common end-to-end performance problems noticed over several years in our ITU-T H.323 protocol-based ""Video and Voice over IP"" (VVoIP) infrastructure and provide a tool for troubleshooting these performance issues. Based on our operations experiences, we are developing a tool called the ""H.323 Beacon"" to measure, monitor and qualify the performance of H.323 sessions. We describe the development architecture and feature set of the H.323 Beacon, which can be used by a novice end-user, network engineer or conference-operator using VVoIP systems. H.323 Beacon is an application-specific network measurement tool that provides H.323-protocol specific evidence and other information necessary to troubleshoot H.323 application performance in the network and at the host (end-to-end). We also present 2 use-cases for the H.323 Beacon that demonstrate the utility of the tool for VVoIP performance debugging. Finally, we outline essential best practices for prevention and efficient resolution of intermittent and imminent failures of H.323 VVoIP applications.",H.323; Network Measurement; Videoconferencing; VoIP,End-to-end performances; Human factors; Networked measurement; Troubleshooting; Computer networks; Cost effectiveness; Data acquisition; Network protocols; Performance; Societies and institutions; Teleconferencing; Video conferencing
"Mansley K., Scott D., Tse A., Madhavapeddy A.",4,"Feedback, latency, accuracy: Exploring tradeoffs in location-aware gaming",2004,5,"Lab. for Communication Engineering, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom; Intel Research Cambridge, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",Intel,1,UK,1,20,16,"We are witnessing the development of large-scale location systems and a corresponding rise in the popularity of location-aware applications, especially games. Traditional computer games have pushed the limits of CPU and graphics card performance for many years and experience suggests that location-aware games will place similar demands upon location systems. Unlike traditional gaming platforms however, the mobile devices that interact with location systems are heavily constrained especially in the number of ways that feedback can be provided. In this paper we describe a location-aware, fast-paced, close quarters action game and use it to experiment with three key components of future location-aware gaming platforms: (i) the location system, (ii) the network to connect the mobile devices, and (iii) the feedback and computational capabilities of the mobile devices themselves. We investigate the tradeoffs that are possible between these components, the effect of the feedback channel and the suitability of Bluetooth as a network for mobile game devices.",Bluetooth; Location systems; Mobile gaming,Bluetooth; Location systems; Mobile gaming; Mobile phones; Bandwidth; Communication channels (information theory); Feedback; Global positioning system; Mobile computing; Problem solving; Scheduling; Sensors; Mobile telecommunication systems
"Grolmusz V., Kir‡ly Z.",2,Secure routerless routing,2004,1,"Department of Computer Science, Eštvšs University, Budapest, Hungary; Department of Computer Science, Communication Networks Laboratory, Eštvšs University, Budapest, Hungary",Eštvšs University,1,Hungary,1,9,8,"Suppose that there are n Senders and r Receivers. Our goal is to design a communication network such that long messages can be sent from Sender i to Receiver ¹(i) such that no other receiver can retrieve the message intended for Receiver ¹(i). The task can easily be completed using some classical interconnection network and routers in the network. Alternatively, if every Receiver is directly connected to all n Senders, then the Senders can choose which channel to use for communication, without using any router. Fast optical networks are slowed down considerably if routers are inserted in their nodes. Moreover, handling queues or buffers at the routers is extremely hard in all-optical setting. An obvious routerless solution, connecting each possible Sender-Receiver pairs with direct channels seems to be infeasible in most cases. The main result of the present work is the mathematical model of two networks and corresponding network-protocols in which the Senders and the Receivers are connected with only r o(1) channels (in practice no more than 32 channels in both networks); there are no switching or routing-elements in the network, just linear combinations of the signals are computed. Such designs would be usable in fast all-optical networks. In the proof of the security of the networks we do not use any unproven cryptographical or complexity theoretical assumptions: the security is information-theoretically proved, and does not depend on cryptographical primitives.",High speed optical networks; Routerless routing; Secure network protocols,High speed optical networks; Optical memory; Routerless routing; Secure network protocols; Bandwidth; Cryptography; Network protocols; Security of data; Signal processing; Switching; Telecommunication networks; Routers
"Luckie M., McGregor T.",2,Path diagnosis with IPMP,2004,2,"WAND Group, University of Waikato, New Zealand; NLANR, MNA, University of California, San Diego, United States",University of California San Diego;University of Waikato,2,New Zealand;USA,2,18,15,"The ability to measure and identify performance fault locations on an Internet path between two hosts is an important first step towards diagnosing and correcting a fault or avoiding fault locations entirely. The ability to identify fault locations on both the forward and reverse paths from a single point would be very powerful for both operators and users. Rather than describing a tool for path diagnosis per se, this paper describes how one could apply a simple measurement protocol to diagnose faults.",Measurement protocols; Path diagnosis,Capacity estimation; Packet loss; Packet queueing; Code division multiple access; Jitter; Mathematical models; Queueing networks; Routers; Telecommunication links; Telecommunication traffic; Packet networks
McEachen II J.C.,1,A self-similarity traffic analysis of an internet-based multiplayer online game,2004,0,"Naval Postgraduate School, Code EC/Mj, 833 Dyer Road, Monterey, CA 93943, United States",Naval Postgraduate School,1,USA,1,4,2,"An analysis of traffic generated by the popular Internet-based online game engine, Unreal Engine, is presented. Network parameters such as packet length, interarrival time and aggregate data rate are observed for analyzing aspects of self-similarity. Client-side packet traces are collected and analyzed for both client and server traffic. Initial analysis of over three million packets indicates client generated traffic shows strong long-range dependence of a self-similar nature primarily due to packet length associated with user actions. On the contrary, server generated traffic seen at the client, while still exhibiting a heavy tail, is more short-range dependent in regions where self-similarity is observed.",MMOG; Multiplayer; Self-similarity,First person shooter (FPS) games; MMOG; Multiplayers; Self-similarity; Data transfer; Internet; Local area networks; Online systems; Random processes; Telecommunication traffic; Time series analysis; Wide area networks; Game theory
"Nguyen C.D., Safaei F., Boustead P.",3,A distributed proxy system for provisioning immersive audio communication to massively multi-player games,2004,1,"Telecom./Info. Technol. Res. Inst., University of Wollongong, Australia",University of Wollongong,1,Australia,1,1,1,"This paper evaluates the suitability of a distributed proxy architecture for the provision of an immersive audio communication service for massively multi-player online games. The immersive audio communication service enables each avatar to hear a realistic audio mix of conversations in its hearing range. The proxy architecture is presented to address some limitations of previously proposed architectures, namely peer-to-peer and central server. We have developed a simulation model to evaluate the performance these delivery architectures in different game delivery scenarios. In particular, the bandwidth efficiency of network multicast for the proxy architecture in different avatar grouping behaviours and player distribution scenarios is studied. In addition, we investigate the impact of varying the number of proxy servers on the game communication delays.",Immersive audio; Massively multi-player games; Multicast; Provisioning; Simulation,Immersive audio; Massively multi-player games; Multicast; Provisioning; Bandwidth; Communication systems; Computer simulation; Distributed computer systems; Electric network topology; Internet; Multicasting; Online systems; Servers; Game theory
"Limura T., Hazeyama H., Kadobayashi Y.",3,Zoned federation of game servers: A peer-to-peer approach to scalable multi-player online games,2004,40,"Nara Inst. of Science and Technology, Nara, 630-0192, Japan","NIST,Japan",1,Japan,1,13,13,"Today's Multi-player Online Games (MOGs) are challenged by infrastructure requirements, because of their server-centric nature. Peer-to-peer networks are an interesting alternative, if they can implement the set of functions that are traditionally performed by centralized authoritative servers. In this paper, we propose a zoned federation model to adapt MOG to peer-to-peer networks. In this model, zoning layer is inserted between the game program and peer-to-peer networks. We introduce the concept of zone and zone owner to MOG. Zone is some part of the whole game world, and zone owner is an authoritative server of a specifie zone. According to the demands of the game program, each node actively changes its role to zone owner and works in the same way as a centralized authoritative server. By dividing the whole game world into several zones, workloads of the centralized authoritative game server can be distributed to a federation of nodes. We have implemented the zoned federation model, and evaluate it with a prototypical multi-player game. Evaluation results indicate that our proposed approach is applicable to small and medium-sized MOGs, where the number of nodes is less than 500.",Design; Performance,Centralized authoritative servers; Game servers; Multi-player online games (MOG); Peer-to-peer networks; Large scale systems; Multicasting; Multimedia systems; Multiplexing; Network protocols; Servers; Software prototyping; Zoning; Online systems
"Widjaja I., Saniee I.",2,Simplified layering and flexible bandwidth with TWIN,2004,18,"Bell Laboratories, Lucent Technologies, Murray Hill, NJ 07974, United States",Bell Labs,1,USA,1,35,32,"This paper describes a novel network architecture with simplified layering, called Time-domain Wavelength Interleaved Networking (TWIN), that scales end-to-end bandwidth granularity flexibly up to the wavelength capacity. In TWIN, all packet and complex processing functions are pushed to the network edge such that the network core only has to deal with an optical forwarding layer. Furthermore, by avoiding fast optical switching and optical buffering in the core through scheduling fast-tunable lasers and buffering packets at the edge, TWIN effectively makes the network act like a switch. We examine distributed network scheduling for this architecture and show its performance via analysis and simulation. We also explore other research issues that are unique in TWIN.",Bandwidth granularity; Network; Network scheduling; Simplified layering; Switch,Ethernet; Optical buffering; Time-domain Wavelength Interleaved Networking (TWIN); Wavelength capacity; Asynchronous transfer mode; Computer simulation; Internet; Lasers; Packet networks; Scheduling; Time domain analysis; Wavelength division multiplexing; Bandwidth
"Quax P., Monsieurs P., Lamotte W., De Vleeschauwer D., Degrande N.",5,Objective and subjective evaluation of the influence of small amounts of delay and jitter on a recent first person shooter game,2004,16,"Expertise Center for Digital Media, Limburgs Universitair Centrum, Universitaire Campus, B-3590 Diepenbeek, Belgium; Alcatel Bell NV, Network Strategy Group, Francis Wellesplein 1, B-2018 Antwerpen, Belgium",Bell Labs;Limburgs University,2,Belgium,1,11,10,"There have been several studies in the past years that investigate the impact of network delay on multi-user applications. Primary examples of these applications are real-time multiplayer games. These studies have shown that high network delays and jitter may indeed influence the player's perception of the quality of the game. However, the proposed test values, which are often high, are not always representative for a large percentile of on-line game players. We have therefore investigated the influence of delay and jitter with numbers that are more representative for typical access networks. This in effect allows us to simulate a setup with multiplayer game servers that are located at ISP level and players connected through that ISP's access network. To obtain further true-to-life results, we opted to carry out the test using a recent first person shooter (FPS) game, Unreal Tournament 2003. It can, after all, be expected that this new generation of games has built-in features to diminish the effect of small delay values, given the popularity of playing these games over the Internet. In this paper, we have investigated both subjective perceived quality and objective measurements and will show that both are indeed influenced by even these small delay and jitter values.",Analysis; Network influences; On-line games,First person shooter (FPS) games; Multi-user applications; Network influences; On-line games; Analysis; Boolean functions; Computer simulation; Evaluation; Internet; Jitter; Online systems; Game theory
"Delap M., Knutsson B., Lu H., Sokolsky O., Sammapun U., Lee I., Tsarouchis C.",7,Is runtime verification applicable to cheat detection?,2004,11,"Department of Computer Science, University of Pennsylvania, United States",University of Pennsylvania,1,USA,1,10,5,"We investigate the prospect of applying runtime verification to cheat detection. Game implementation bugs are extensively exploited by cheaters, especially in massively multiplayer games. As games are implemented on larger scales and game object interactions become more complex, it becomes increasingly difficult to guarantee that high-level game rules are enforced correctly in the implementation. We observe that although implementing high-level rules in code is complex because of interference between rules, checking for rule compliance at runtime is simple because only a single rule is involved in each check. We demonstrate our idea by applying the Java-MaC runtime verification system to a simple game to detect a transaction bug that is common in massively multiplayer games.",Cheat detection; Multiplayer game; Runtime verification,Cheat detection; Game policies; Multiplayer game; Runtime verification; Java programming language; Large scale systems; Marketing; Mathematical models; Metadata; Personal computers; Real time systems; Semantics; Computer software
"Akkawi A., Schaller S., Wellnitz O., Wolf L.",4,A mobile gaming platform for the IMS,2004,2,"IBR, TU Braunschweig, MŸhlenpfordtstra§e 23, 38106 Braunschweig, Germany; NEC Europe Ltd., KurfŸrstenanlage 36, 69115 Heidelberg, Germany",TU Braunschweig,1,Germany,1,29,3,"Mobile devices offer the opportunity to play games nearly everywhere. Moreover, networked games allow individual players to interact with other people and to participate in a larger gaming world, which also provides for new business opportunities. Hence, we currently see an increased interest from game developers, providers and players in mobile games. In this paper we propose a novel architecture and platform for games on the IMS. This allows games to utilize the features and capabilities that are inherent to the IMS. At the same time existing games can be flexibly adapted to this new type of network and have the possibility to reserve network resources for game data transmission, thus improving the experience of players.",IMS; Mobile Networked Games; Platform Architecture,Data transmission; Mobile networked games; Network resources; Platform architecture; Bandwidth; Client server computer systems; Computer operating systems; Data transfer; Graphical user interfaces; Internet; Local area networks; Multimedia systems; Network protocols; Personal computers; Standards; XML; Mobile telecommunication systems
"Beigbeder T., Coughlan R., Lusher C., Plunkett J., Agu E., Claypool M.",6,The effects of loss and latency on user performance in unreal tournament 2003,2004,59,"Computer Science Department, Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609, United States",Worcester Polytechnic Institute,1,USA,1,14,9,"The growth in the popularity of interactive network games has increased the importance of a better understanding of the effects of packet loss and latency on user performance. While previous work on network games has studied user tolerance for high latencies and has studied the effects of latency on user performance in real-time strategy games, to the best of our knowledge, there has been no systematic study of the effects of loss and latency on user performance. In this paper we study user performance for Unreal Tournament 2003 (UT2003), a popular first person shooter game, under varying amounts of packet loss and latency. First, we deduced typical real world values of packet loss and latency experienced on the Internet by monitoring numerous operational UT2003 game servers. We then used these deduced values of loss and latency in a controlled networked environment that emulated various conditions of loss and latency, allowing us to monitor UT2003 at the network, application and user levels. We designed maps that isolated the fundamental first person shooter interaction components of movement and shooting, and conducted numerous user studies under controlled network conditions. We find that typical ranges of packet loss have no impact on user performance or on the quality of game play. The levels of latency typical for most UT2003 Internet servers, while sometimes unpleasant, do not significantly affect the outcome of the game. Since most first person shooter games typically consist of generic player actions similar to those that we tested, we believe that these results have broader implications.",Latency; Loss; Network Games,Game servers; Latency; Loss; Network games; Bandwidth; Internet; Online systems; Quality of service; Real time systems; Servers; Game theory
"Feldman M., Papadimitriou C., Chuang J., Stoica I.",4,Free-riding and whitewashing in peer-to-peer systems,2004,155,"Sch. of Info. Management and Systems, U.C. Berkeley, United States; Computer Science Division, U.C. Berkeley, United States",University of California Berkeley,1,USA,1,17,17,"We develop a model to study the phenomenon of free-riding in peer-to-peer (P2P) systems. At the heart of our model is a user of a certain type, an intrinsic and private parameter that reflects the user's willingness to contribute resources to the system. A user decides whether to contribute or free-ride based on how the current contribution cost in the system compares to her type. When the societal generosity (i.e., the average type) is low, intervention is required in order to sustain the system. We present the effect of mechanisms that exclude low type users or, more realistic, penalize free-riders with degraded service. We also consider dynamic scenarios with arrivals and departures of users, and with whitewashers: users who leave the system and rejoin with new identities to avoid reputational penalties. We find that when penalty is imposed on all newcomers in order to avoid whitewashing, system performance degrades significantly only when the turnover rate among users is high.",Cheap pseudonyms; Cooperation; Equilibrium; Exclusion; Free-riding; Identity cost; Incentives; Peer-to-peer; Whitewashing,Cheap pseudonyms; Cooperation; Equilibrium; Exclusion; Free-riding; Identity costs; Incentives; Peer-to-peer; Whitewashing; Costs; Decision making; Economics; Mathematical models; Parameter estimation; Resource allocation; Computer systems
Krishnamurthy B.,1,Mohonk: Mobile honeypots to trace unwanted traffic early,2004,4,"AT and T Labs-Research, United States",AT and T Labs,1,USA,1,27,17,Honeypots have been traditionally used to advertise dark address space and gather information about originators of traffic to such addresses. With simple thresholding mechanisms this technique has shown itself to be fairly effective in identifying suspicious IP addresses. Honeypots are however unsuitable to locate the precise entry point of unwanted traffic. Tracing back to the origination of such traffic is hard due to the delay and difficulty of maintaining state along the path of such traffic. We propose a novel mobile honeypot mechanism that allows unwanted traffic to be detected significantly closer to the origin. The mobility in our scheme stems from additional information that is made available to the upstream ASes as well as the changes in the set of dark address space advertised. Sharing information with a network of friendly ASes has the potential to identify and significantly lower unwanted traffic on such links.,Network monitoring; Unwanted packets,Internet mapping; Network monitoring; Unwanted packets; Algorithms; Band structure; Internet; Packet networks; Risk assessment; Telecommunication traffic
"Logg C., Cottrell L., Navratil J.",3,Experiences in traceroute and available bandwidth change analysis,2004,18,"SLAC, 2575 Sand Hill Road, Menlo Park, CA 94025, United States","SLAC,USA",1,USA,1,12,9,"SLAC has been studying end-to-end WAN bandwidth availability and achievability for 2.5 years via IEPM-BW [1]. IEPM-BW performs network intensive tests every 90 minutes. Based on that experience we have also developed a light weight available bandwidth (ABwE [2]) measurement tool that can make a measurement within a second. We are now extending this to a WAN measurement and detection system (IEPM-LITE) aimed at more quickly detecting and troubleshooting network performance problems and also to be more friendly on lower performance paths. IEPM-LITE uses ping, forward traceroutes, and ABwE sensors to monitor, in close to real-time, Round Trip Times (RTT), changes in available bandwidth and routes to and from target hosts. This paper discusses the experiences, techniques and algorithms used to detect and report on significant traceroute and bandwidth changes. The ultimate aim is to develop a lightweight WAN network performance monitoring system that can detect, in near real time, significant changes and generate alerts.",Anomalous events; Availability; Bandwidth; Capacity; Network monitoring; Plateau algorithm; Problem detection; Real-time alerts; Traceroutes; WAN,Non-intensive bandwidth; Performance monitoring systems; Troubleshooting networks; Algorithms; High energy physics; Nuclear physics; Performance; Real time systems; Visualization; Bandwidth
"Shaikh A., Sahu S., Rosu M., Shea M., Saha D.",5,Implementation of a service platform for online games,2004,0,"Network Software and Services, IBM T.J. Watson Research Center, Hawthorne, NY 10532, United States",IBM,1,USA,1,13,9,"Large-scale multiplayer online games require considerable investment in hosting infrastructures. However, the difficulty of predicting the success of a new title makes investing in dedicated server and network resources very risky. A shared infrastructure based on utility computing models to support multiple games offers an attractive option for game providers whose core competency is not in managing large server deployments. In this paper we describe a prototype implementation of a shared, on demand service platform for online games. The platform builds on open standards and off-the-shelf software developed to support utility computing offerings for Web-based business applications. We describe our early experience with identifying appropriate performance metrics for provisioning game servers and with implementing the platform components that we consider essential for its acceptance.",Game hosting; On demand computing; Online games,Game hosting; Network traffic; On demand computing; Online games; Computer software; Electronic commerce; Personal computers; Resource allocation; Servers; World Wide Web; Online systems
"Feamster N., Balakrishnan H., Rexford J., Shaikh A., Van Der Merwe J.",5,The case for separating routing from routers,2004,163,"MIT, Computer Science and AI Lab., United States; AT and T Labs-Research, United States",AT and T Labs;MIT,2,USA,1,42,37,"Over the past decade, the complexity of the Internet's routing infrastructure has increased dramatically. This complexity and the problems it causes stem not just from various new demands made of the routing infrastructure, but also from fundamental limitations in the ability of today's distributed infrastructure to scalably cope with new requirements. The limitations in today's routing system arise in large part from the fully distributed path-selection computation that the IP routers in an autonomous system (AS) must perform. To overcome this weakness, interdomain routing should be separated from today's IP routers, which should simply forward packets (for the most part). Instead, a separate Routing Control Platform (RCP) should select routes on behalf of the IP routers in each AS and exchange reachability information with other domains. Our position is that an approach like RCP is a good way of coping with complexity while being responsive to new demands and can lead to a routing system that is substantially easier to manage than today. We present a design overview of RCP based on three architectural principles-path computation based on a consistent view of network state, controlled interactions between routing protocol layers, and expressive specification of routing policies-and discuss the architectural strengths and weaknesses of our proposal.",BGP; Interdomain routing; Routing architecture,Autonomous systems; BGP; Interdomain routing; Routing architecture; Routing Control Platform (RCP); Algorithms; Formal languages; Network protocols; Problem solving; Routers; Topology; Internet
"Gold R., Gunningberg P., Tschudin C.",3,A virtualized link layer with support for indirection,2004,10,"Department of Information Technology, Uppsala University, Box 337, S-75105 Uppsala, Sweden; CS Dept., University of Basel, Bernoullistrasse 16, CH-4053 Basel, Switzerland",University of Basel;Uppsala University,2,Sweden;Switzerland,2,17,17,"The current Internet today hosts several extensions for indirection like Mobile IP, NAT, proxies, route selection and various network overlays. At the same time, user-controlled indirection mechanisms foreseen in the Internet architecture (e.g., loose source routing) cannot be used to implement these extensions. This is a consequence of the Internet's indirection semantics not being rich enough at some places and too rich at others. In order to achieve a more uniform handling of indirection we propose SelNet, a network architecture that is based on a virtualized link layer with explicit indirection support. Indirection in this context refers to user-controlled steering of packet flows through the network. We discuss the architectural implications of such a scheme and report on implementation progress.",Indirection; Network Architecture; Underlay Networks; Virtualized Link Layer,Indirection; Network architecture; Underlay networks; Virtualized link layer; Computer operating systems; Demultiplexing; Internet; Multicasting; Network protocols; Packet networks; Communication systems
"Mahajan R., Rodrig M., Wetherall D., Zahorjan J.",4,Experiences applying game theory to system design,2004,43,"University of Washington, United States",University of Washington at Seattle,1,USA,1,24,19,We applied techniques from game theory to help formulate and analyze solutions to two systems problems: discouraging selfishness in multi-hop wireless networks and enabling cooperation among ISPs in the Internet. It proved difficult to do so. This paper reports on our experiences and explains the issues that we encountered. It describes the ways in which the straightforward use of results from traditional game theory did not fit well with the requirements of our problems. It also identifies an important characteristic of the solutions we did eventually adopt that distinguishes them from those available using game theoretic approaches. We hope that this discussion will help to highlight formulations of game theory which are well-suited for problems involving computer systems.,Game Theory; Incentives; Interdomain Routing; System Design; Wireless Networks,Incentives; Interdomain Routing; Internet Service Providers (ISP); Multi-Hop Wireless Networks; Bandwidth; Electric network topology; Network protocols; Routers; Systems analysis; Telecommunication networks; Wireless telecommunication systems; Game theory
"Guha S., Takeda Y., Francis P.",3,NUTSS: A SIP-based approach to UDP and TCP network connectivity,2004,54,"Dept. of Computer Science, Cornell University, Ithaca, NY 14853, United States; Panasonic Communications Corp.",Cornell University,1,USA,1,6,6,"The communications establishment capability of the Session Initiation Protocol is being expanded by the IETF to include establishing network layer connectivity for UDP for a range of scenarios, including where hosts are behind NAT boxes, and host are running IPv6. So far, this work has been limited to UDP because of the assumed impossibility of establishing TCP connections through NAT, and because of the difficulty of predicting port assignments on certain common types of NATs. This paper reports on preliminary success in establishing TCP connections through NAT, and on port prediction. In so doing, we suggest that it may be appropriate for SIP to take a broader architectural role in P2P network layer connectivity for both IPv4 and IPv6.",IPv6 transition; NAT traversal; NUTSS; STUNT,IPv6 transition; NAT traversal; NUTSS; STUNT; Client server computer systems; Data communication systems; Internet; Packet networks; Signal encoding; Signal processing; Network protocols
"Huang E., Crowcroft J., Wassell I.",3,Rethinking incentives for mobile ad hoc networks,2004,52,"Lab. for Communication Engineering, University of Cambridge, William Gates Building, Cambridge, United Kingdom; Computer Lab., University of Cambridge, William Gates Building, Cambridge, United Kingdom",University of Cambridge,1,UK,1,20,19,"Without sufficient nodes cooperating to provide relaying functions, a mobile ad hoc network cannot function properly. Consequently various proposals have been made which provide incentives for individual users of an ad hoc mobile network to cooperate with each other. In this paper we examine this problem and analyse the drawbacks of currently proposed incentive systems. We then argue that there may not be a need for incentive systems at all, especially in the early stages of adoption, where excessive complexity can only hurt the deployment of ad hoc networks. We look at the needs of different customer segments at each stage of the technological adoption cycle and propose that incentive systems should not be used until ad hoc networks enter mainstream markets. Even then, incentive systems should be tailored to the needs of each individual application rather than adopting a generalised approach that may be flawed or too technically demanding to be implemented in reality.",Cooperation; Incentives; Mobile ad hoc networks,Ad hoc networks; Incentives; Network capability; Relaying functions; Bandwidth; Computational complexity; Computer hardware; Design; Energy dissipation; Performance; Real time systems; Self organizing storage; Telecommunication networks; Telecommunication traffic; Theory; Mobile telecommunication systems
"Hu S.-V., Liao G.-M.",2,Scalable peer-to-peer networked virtual environment,2004,38,"Dept. of Comp. Science Engineering, Tamkang University, Tamsui, Taipei County 251, Taiwan; Institute of Physics, Academia Sinica, Taipei 11529, Taiwan",Tamkang University,1,Taiwan,1,14,12,"We propose a fully-distributed peer-to-peer architecture to solve the scalability problem of Networked Virtual Environment in a simple and efficient manner. Our method exploits locality of user interest inherent to such systems and is based on the mathematical construct Voronoi diagram. Scalable, responsive, fault-tolerant NVE can thus be constructed and deployed in an affordable way.",Interest management; Massively multiplayer (MMP); Networked Virtual Environment (NVE); Peer-to-peer (P2P); Scalability; Voronoi diagram,Interest management; Massively multiplayer (MMP); Networked virtual environment (NVE); Peer-to-peer (P2P); Scalability; Voronoi diagram; Bandwidth; Computer simulation; Computer software; Computer software maintenance; Fault tolerant computer systems; Problem solving; Reliability; Virtual reality; Computer networks
"Argyraki K., Cheriton D.R.",2,Loose source routing as a mechanism for traffic policies,2004,13,"EE Department, Stanford University, Stanford, CA 94305, United States; CS Department, Stanford University, Stanford, CA 94305, United States",Stanford University,1,USA,1,26,19,"Internet packet delivery policies have been of concern since the earliest times of the Internet, as witnessed by the presence of the Type of Service (ToS) field in the IPv4 header. Efforts continue today with Differentiated Services (DiffServ) and Multiprotocol Label Switching (MPLS). We claim that these approaches have not succeeded because they require, either explicitly or subtly, a network-layer virtual circuit mechanism. In this paper, we describe how adding a form of Loose Source and Record Route (LSRR) capability into the nextgeneration Internet provides adequate support for transmit and receive policies, including filtering, while avoiding the problems of virtual circuits and the original problems with LSRR in IPv4.",Filtering; Loose Source Routing; Quality of Service; Route Control; Traffic Policies,Loose source routing; Route control; Traffic Policies; Type of Service (ToS); Data reduction; Filtration; Internet; Packet networks; Quality of service; Routers; Servers; Switching theory; Telecommunication traffic
"Teixeira R., Rexford J.",2,A measurement framework for pin-pointing routing changes,2004,53,"Univ. Calif. San Diego, San Diego, CA, United States; AT and T Labs-Research, Florham Park, NJ, United States",AT and T Labs,1,USA,1,22,19,"Changes in the end-to-end path between two hosts can lead to sudden changes in the round-trip time and available bandwidth, or even the complete loss of connectivity. Determining the reason for the routing change is crucial for diagnosing and fixing the problem, and for holding a particular domain accountable for the disruption. Active measurement tools like traceroute can infer the current path between two end-points, but not where and why the path changed. Analyzing BGP data from multiple vantage points seems like a promising way to infer the root cause of routing changes. In this paper, we explain the inherent limitations of using BGP data alone and argue for a distributed approach to troubleshooting routing problems. We propose a solution where each AS continuously maintains a view of routing changes in its own network, without requiring additional support from the underlying routers. Then, we describe how to query the measurement servers along the AS-level forwarding path from the source to the destination to uncover the location and the reason for the routing change.",BGP; IGP; Network troubleshooting; Root cause analysis,BGP; IGP; Network troubleshooting; Root cause analysis; Bandwidth; Computer networks; Data acquisition; Packet networks; Performance; Telecommunication traffic; Routers
"Christin N., Grossklags J., Chuang J.",3,Near rationality and competitive equilibria in networked systems,2004,28,"Sch. of Info. Management and Systems, University of California, Berkeley, 102 South Hall, Berkeley, CA 94720-4600, United States",University of California Berkeley,1,USA,1,30,24,"A growing body of literature in networked systems research relies on game theory and mechanism design to model and address the potential lack of cooperation between self-interested users. Most game-theoretic models applied to system research only describe competitive equilibria in terms of pure Nash equilibria, that is, a situation where the strategy of each user is deterministic, and is her best response to the strategies of all the other users. However, the assumptions necessary for a pure Nash equilibrium to hold may be too stringent for practical systems. Using three case studies on network formation, computer security, and TCP congestion control, we outline the limits of game-theoretic models relying on Nash equilibria, and we argue that considering competitive equilibria of a more general form helps in assessing the accuracy of a game theoretic model, and can even help in reconciling predictions from game-theoretic models with empirically observed behavior.",Competitive equilibria; Distributed systems; Game theory; Modeling,Competitive equilibria; Congestion control; Nash equilibria; System architects; Computer networks; Decision making; Game theory; Internet; Mathematical models; Motivation; Security of data; Computer systems
"Chu Y.-H., Chuang J., Zhang H.",3,A case for taxation in peer-to-peer streaming broadcast,2004,64,"Carnegie Mellon University, United States; UC Berkeley, United States",Carnegie Mellon University;University of California Berkeley,2,USA,1,24,17,"Most existing research on peer-to-peer (p2p) has been on file sharing applications. In this paper, we focus on p2p streaming applications. In particular, we argue that the Bit-for-Bit model, widely adopted in p2p file sharing, is not applicable in p2p streaming. In p2p streaming, the bottleneck resource is the upstream bandwidth capacity. Our empirical experience with p2p streaming indicates that a large percent of peers on the Internet have limited upstream bandwidth capacity, and the Bit-for-Bit model severely limits the amount of bandwidth these resource-poor peers can receive. To address this issue, we propose a taxation model. In the taxation model, resource-rich peers contribute more bandwidth to the system, and subsidize for the resource-poor peers. This redistribution of wealth improves social welfare. Such a model is applicable in the streaming context because the publisher of the video stream has the means to enforce taxation on peers and the will to maximize their collective social welfare. We design a simple linear taxation scheme and incorporate it in a distributed streaming protocol. Our simulation results indicate that taxation can significantly improve social welfare without incurring a significant overhead to the system.",Incentive; Peer-to-peer; Taxation; Video Streaming,Incentives; Peer-to-peer; Social welfare; Video streaming; Bandwidth; Broadcasting; Cost effectiveness; Economics; Internet; Taxation; Computer networks
Lintault I.,1,A transaction execution engine architecture for multiplayer online games,2004,0,"Intel Corporation, 3-1-1 Marunouchi, Chiyoda-ku, Tokyo, 100-0005, Japan",Intel,1,Japan,1,3,2,"In the pursuit of massively multiplayer online games, efficient engines capable of processing sophisticated game scenarios are necessary to support large scale virtual worlds. By applying microprocessor microarchitectural design techniques to game server software design, functional parallelism inherent in complex game transactions can be exploited, augmenting server performance. In a given gaming scenario, complex game transactions can be modeled as data flow graphs. An individual graph represents the collective atomic operations of a particular transaction. Analysis of data flow graphs provides a mechanism that identifies opportunities for parallelism by exposing data dependencies. This poster presents an engine architecture that supports spatial and temporal parallel execution of complex game transactions expressed as data flow graphs. The engine takes advantage of data flow enhancement techniques such as dynamic out-of-order execution to enhance performance.",Data flow architecture; Distributed simulation; Dynamic scheduling; Game architecture; Online Games; Task scheduling; Transaction execution; Transaction level parallelism,Data flow architecture; Distributed simulation; Dynamic scheduling; Game architecture; Online games; Task scheduling; Transaction execution; Transaction level parallelism; Computer simulation; Data processing; Microprocessor chips; Online systems; Scheduling; Virtual reality; Game theory
"Singh A., Acharya A.",2,Using session initiation protocol to build context-Aware VoIP Support for multiplayer networked games,2004,0,"Georgia Insitute of Technology, Atlanta, GA, United States; IBM T.J.Watson Research Center, Hawthorne, NY, United States",IBM,1,USA,1,19,18,"Multiplayer networked games are the trend of the day. Receiving a major boost from various commercial ventures like Microsoft Xbox¨ and Sony Playstation¨, the networked gaming industry is set to grow dramatically. These multiplayer games allow geographically dispersed and possibly distant players to participate in a single game. In order to provide interaction amongst players in such environments, text messaging and recently, real-time voice interaction through VoIP is used. However, such interactions are mostly out-of-band (not based on game contexts), user-initiated and limited in operability, failing to exploit the entire potential and functionality of VoIP. In this paper, we present mechanisms and design of a prototype that allows game-context based VoIP communication between players. Thus, in addition to allowing players to talk to each other to coordinate teammates and activities (through a static team-based audio conference) as in some of the current systems, it supports communication among players based on shared contexts like the same physical location or room within the gaming environment. We use the Session Initiation Protocol (SIP) [14] to realize VoIP and describe mechanisms for building network gaming services using SIP. We also propose a sophisticated gaming scenario, in which VoIP is used to relay information about another player's distance and location with respect to the recipient, e.g. players farther away sound farther away.",Context-aware; Gaming; SIP; VoIP,Context-aware; Gaming; Session initiation protocol (SIP); VoIP; Internet; Middleware; Online systems; Real time systems; Video conferencing; Visual communication; Network protocols
"Smed J., Niinisalo H., Hakonen H.",3,Realizing bullet time effect in multiplayer games with local perception filters,2004,0,"Turku Centre for Computer Science, Department of Information Technology, University of Turku, Finland; Department of Information Technology, University of Turku, Finland; LemminkŠisenkatu 14 A, FI-20520, Turku, Finland",University of Turku,1,Finland,1,9,9,"Local perception filters exploit the limitations of human perception to reduce the effects of network latency in multiplayer computer games. Because they allow temporal distortions in the rendered view, they can be modified to realize bullet time effect, where a player can get more reaction time by slowing down the surrounding game world. In this paper, we examine the concepts behind local perception filters and extend them to cover artificially increased delays. The presented methods are implemented in a testbench program, which is used to study the usability and limitations of the approach.",Bullet time; Computer games; Latency; Multiplayer; Networking; Virtual environments,Bullet time; Computer games; Latency; Multiplayer; Networking; Virtual environments; Cameras; Communication systems; Computer networks; Information technology; Multimedia systems; Virtual reality; Computer software
"Shneidman J., Parkes D.C., MassouliŽ L.",3,Faithfulness in internet algorithms,2004,21,"Div. of Eng. and Applied Science, Harvard University, United States; Microsoft Research Ltd., Cambridge, United Kingdom",Harvard University;Microsoft,2,UK;USA,2,22,18,"Proving or disproving faithfulness (a property describing robustness to rational manipulation in action as well as information revelation) is an appealing goal when reasoning about distributed systems containing rational participants. Recent work formalizes the notion of faithfulness and its foundation properties, and presents a general proof technique in the course of proving the ex post Nash faithfulness of a theoretical routing problem [11]. In this paper, we use a less formal approach and take some first steps in faithfulness analysis for existing algorithms running on the Internet. To this end, we consider the expected faithfulness of BitTorrent, a popular file download system, and show how manual backtracing (similar to the the ideas behind program slicing [22]) can be used to find rational manipulation problems. Although this primitive technique has serious drawbacks, it can be useful in disproving faithfulness. Building provably faithful Internet protocols and their corresponding specifications can be quite difficult depending on the system knowledge assumptions and problem complexity. We present some of the open problems that are associated with these challenges.",Backtracing; Computational Failure Models; Computational Mechanism Design; Distributed Algorithmic Mechanism Design; Faithfulness; Program Slicing; Rational Failure; Rational Manipulation,Backtracking; Computational Failure Models; Computational Mechanism Design; Distributed Algorithmic Mechanism Design; Failthfulness; Program slicing; Rational FAilure; Rational Manipulation; Algorithms; Computational complexity; Computer software; Distributed computer systems; Network protocols; Routers; Internet
"Chang D.-F., Govindan R., Heidemann J.",3,Locating BGP missing routes using multiple perspectives,2004,5,"USC, Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292, United States",University of Southern California,1,USA,1,11,11,"There have been many studies on measuring and interpreting interdomain routing dynamics. Most of them, however, are based on the approach of off-line and passive post-processing BGP routing updates. We propose a new methodology that uses real-time and active monitoring to troubleshoot various BGP routing anomalies. This paper focuses on a specific BGP routing problem - missing routes that occur when some ASes can reach a prefix while others can't. The idea is to periodically monitor the BGP routing status at multiple vantage points, like Route Views, and when a possible missing route event is detected issue traceroute queries from various looking glasses to learn of the packet-forwarding path status. By comparing previous and current packet-forwarding paths, we can have an idea of where the missing route event takes place. This paper examines the plausibility of this methodology and discusses preliminary experimental results.",BGP; Inter-domain routing; Missing route,BGP; Inter-domain routing; Missing routes; packet forwarding paths; Filtration; Internet; Oscillations; Packet networks; Problem solving; Telecommunication services; Routers
"Untz V., Heusse M., Rousseau F., Duda A.",4,On demand label switching for spontaneous edge networks,2004,4,"LSR-IMAG Laboratory, Grenoble, France","LSR-IMAG Laboratory, Grenoble, France",1,France,1,20,20,"We consider the problem of interconnecting hosts in spontaneous edge networks composed of various types of wired or wireless physical and link layer technologies. All or some hosts in a spontaneous network can be organized as a multi-hop ad hoc network, connected or not to the global Internet. We argue that this kind of networks requires a more sophisticated approach than standard IP forwarding: communication paths should be managed on a per flow basis, multiple paths need to be maintained to cope with link failures or changing topologies, and the interconnection architecture should provide information on destination reachability. We have designed and implemented Lilith, a prototype of an interconnection node for spontaneous edge networks. We handle network dynamics by establishing MPLS (Multi Protocol Label Switching) label switched paths (LSP) on demand with a reactive ad hoc routing protocol. Interconnection at layer 2.5 makes all the hosts to appear as one single IP subnet so that configuration protocols can use the subnet broadcast for all forms of discovery (addresses, names, services). Performance measurements of the Lilith implementation on Linux show good performance compared with standard IP forwarding and important performance gains when multiple paths are used.",Ad-hoc networks; Autoconfiguration; MPLS; Spontaneous networks,Ad-hoc networks; Autoconfiguration; Interconnecting hosts; Multi Protocol label switching (MPLS); Spontaneous networks; Actuators; Algorithms; Computer operating systems; Consumer electronics; Network protocols; Problem solving; Routers; Sensors; Switching; Internet
"Magnaghi A., Hamada T., Katsuyama T.",3,A wavelet-based framework for proactive detection of network misconfigurations,2004,29,"Fujitsu Laboratories of America, M/S 345, 1240 E. Arques Ave., Sunnyvale, CA 94085, United States; Fujitsu Laboratories Ltd., 1-1 Kamikodanaka 4-chome, Kawasaki 211-8588, Japan",Fujitsu Laboratories Ltd.;Fujitsu Laboratories Ltd.,2,Japan;USA,2,15,9,"An increasing number of misconfigurations and malicious behaviors threaten the normal operation conditions of data networks. Thus, field engineers are constantly presented with the challenge of isolating new misconfigurations and anomalies. In this paper, we present a group of real-world problems reported by a set of six commercial networks we surveyed. Successively, we focus on a well-defined family of misconfigurations. Our analysis identifies common properties such anomalous behaviors share. Misconfigured TCP flows experience packet losses and RTO-based (Retransmission Time-Out) events during the opening phase of the TCP connection (""Early RTO Events""). This introduces precise correlations in misconfigured traffic that we utilize as a ""signature"" in order to isolate the presence of anomalies. We propose a wavelet-based algorithm that is capable of revealing such a family of anomalies from the analysis of MIB data aggregating healthy and anomalous flows. Simulation and the use of real datasets from a commercial network allow us to quantitatively assess the effectiveness of our detection procedure. Numerical results show that our algorithm can effectively isolate the presence of an anomalous traffic component that is a minimal percentage of the overall link throughput. Therefore, our approach provides a general and highly sensitive misconfiguration detection instrument.",Misconfiguration; Network performance; Retransmissions; Wavelets,Network management; Network monitoring; Round-trip time (RTT); Algorithms; Computational complexity; Computer simulation; Telecommunication links; Telecommunication traffic; Telecommunication networks
"Pappas V., FŠltstršm P., Massey D., Zhang L.",4,Distributed DNS,2004,9,"UCLA Computer Science, United States; Cisco Systems; Colorado State University, United States",Colorado State University,1,USA,1,27,13,"In this paper we present a troubleshooting tool designed to identify a number of DNS configuration errors. These errors range from commonly seen misconfigurations that are well known among DNS operators, such as lame delegations, to less known ones, such as cyclic zone dependencies. Left unnoticed, these misconfigurations can seriously affect the availability of the DNS infrastructure. Instead of explicitly enumerating all possible configuration errors, we first identify two essential properties that characterize a correct DNS configuration, and detect misconfigurations as violations of these properties. We also utilize multiple monitoring points to identify configuration errors that are difficult or impossible to pin down with a single vantage point. Furthermore, equipped with a comprehensive graphical user interface, our tool provides network operators with a tangible view of their DNS zones' configuration and the errors that may affect their availability.",DNS; Misconfigurations; Troubleshooting,Lame delegation; Misconfigurations; Troubleshooting tools; Cache memory; Error analysis; Network protocols; Problem solving; Servers; User interfaces; Internet
"Armitage G., Stewart L.",2,Some thoughts on emulating jitter for user experience trials,2004,2,"Ctr. for Adv. Internet Architectures, Swinburne University of Technology, Melbourne, Australia",Swinburne University of Technology,1,Australia,1,13,13,"It is usually hard to control the network conditions affecting public online game servers when studying the impact of latency, loss and jitter on user experience. This leads to a natural desire for running user-experience trials under controlled network conditions, and hence a requirement for accurate (or at least predictable) emulation of IP level latency, loss and jitter on a localized network testbed. In this short paper we reflect on some experiences with running user-experience trials, and specifically evaluate the utility and limitations of using FreeBSD's kernel-resident dummynet module to introduce controlled jitter. We expect these insights will stimulate further user-experience trials built around low-cost, unix-based networking tools.",Games; Internet; Jitter; Latency; Online,Games; Latency; Linux (operating system); Online; C (programming language); Computer operating systems; Evaluation; Internet; Jitter; Online systems; Real time systems; Game theory
"Okanda P., Blair G.",2,OpenPING: A reflective middleware for the construction of adaptive networked game applications,2004,2,"Computing Department, Lancaster University, Lancaster, LA1 4YR, United Kingdom",Lancaster University,1,UK,1,11,5,"The emergence of distributed Virtual Reality (VR) applications that run over the Internet has presented networked game application designers with new challenges. In an environment where the public internet streams multimedia data and is constantly under pressure to deliver over widely heterogeneous user-platforms, there has been a growing need that distributed VR applications be aware of and adapt to frequent variations in their context of execution. In this paper, we argue that in contrast to research efforts targeted at improvement of scalability, persistence and responsiveness capabilities, much less attempts have been aimed at addressing the flexibility, maintainability and extensibility requirements in contemporary distributed VR platforms. We propose the use of structural reflection as an approach that not only addresses these requirements but also offers added value in the form of providing a framework for scalability, persistence and responsiveness that is itself flexible, maintainable and extensible. We also present an adaptive middleware platform implementation called OpenPING 1 that supports our proposal in addressing these requirements.",Adaptation; Middleware platforms; Networked games; Reflection; Virtual reality (VR),Adaptation; Middleware platforms; Networked games; Public internet; Adaptive systems; Client server computer systems; Computer software maintenance; Internet; Multimedia systems; Virtual reality; Middleware
"Handley M., Greenhalgh A.",2,Steps towards a DoS-resistant Internet architecture,2004,32,"University College London, United Kingdom",University College London,1,UK,1,20,17,"Defending against DoS attacks is extremely difficult; effective solutions probably require significant changes to the Internet architecture. We present a series of architectural changes aimed at preventing most flooding DoS attacks, and making the remaining attacks easier to defend against. The goal is to stimulate a debate on trade-offs between the flexibility needed for future Internet evolution and the need to be robust to attack.",Denial-of-Service; Internet; Network Architecture; Security,Denial-of-Service; Network architecture; Security; Zombie systems; Client server computer systems; Computer simulation; Cryptography; Multicasting; Network protocols; Packet networks; Servers; Internet
Malone D.,1,The root of the matter: Hints or slaves,2004,1,"Commun. Network Research Institute, Dublin Institute of Technology, Ireland",Dublin Institute of Technology,1,Ireland,1,9,7,"We consider the possibility of having a (recursive) name server act as a slave to the root zone, rather than caching information after it is requested. Tests, described here, indicate that this technique seems to be comparable to the traditional hints mechanism for moderately busy name servers and may offer other benefits such as reducing the number of bogus requests going to the root servers. With further refinement the technique may be operationally useful, but the impact on root servers would have to be fully assessed. Copyright 2004 ACM.",DNS; Root Name Server; Zone transfer,Cache memory; Client server computer systems; Data transfer; Database systems; Error analysis; Information analysis; Information management; Internet; Query languages; Telecommunication traffic; Web browsers; Computer communication networks; Domain name system (DNS) servers; Root name servers; Zone transfer; Servers
"Feldmann A., Kammenhuber N., Maennel O., Maggs B., De Prisco R., Sundaram R.",6,A methodology for estimating interdomain Web traffic demand,2004,25,"Tech. UniversitŠt MŸnchen, Germany; Akamai Technologies, United States; Carnegie Mellon University, United States; Universitˆ di Salerno, Italy; Northeastern University, United States",Akamai Technologies;Carnegie Mellon University;Northeastern University;TU Munich;Universitˆ di Salerno,5,Germany;Italy;USA,3,58,54,"This paper introduces a methodology for estimating interdomain Web traffic flows between all clients worldwide and the servers belonging to over one thousand content providers. The idea is to use the server logs from a large Content Delivery Network (CDN) to identify client downloads of content provider (i.e., publisher) Web pages. For each of these Web pages, a client typically downloads some objects from the content provider, some from the CDN, and perhaps some from third parties such as banner advertisement agencies. The sizes and sources of the non-CDN downloads associated with each CDN download are estimated separately by examining Web accesses in packet traces collected at several universities. The methodology produces a (time-varying) interdomain HTTP traffic demand matrix pairing several hundred thousand blocks of client IP addresses with over ten thousand individual Web servers. When combined with geographical databases and routing tables, the matrix can be used to provide (partial) answers to questions such as ""How do Web access patterns vary by country?"", ""Which autonomous systems host the most Web content?"", and ""How stable are Web traffic flows over time?"". Copyright 2004 ACM.",Estimation; Interdomain; Traffic demand; Traffic matrix; Web,Interdomain; Traffic demand; Traffic matrix; Web traffic; Client server computer systems; Computer simulation; Information analysis; Mathematical models; Network protocols; Routers; World Wide Web; Telecommunication traffic
"Pang J., De Prisco R., Hendricks J., Maggs B., Akella A., Seshan S.",6,"Availability, usage, and deployment characteristics of the domain name system",2004,32,"Carnegie Mellon University, United States; University of Salerno, Italy",Carnegie Mellon University;University of Salerno,2,Italy;USA,2,36,29,"The Domain Name System (DNS) is a critical part of the Internet's infrastructure, and is one of the few examples of a robust, highly-scalable, and operational distributed system. Although a few studies have been devoted to characterizing its properties, such as its workload and the stability of the top-level servers, many key components of DNS have not yet been examined. Based on large-scale measurements taken from servers in a large content distribution network, we present a detailed study of key characteristics of the DNS infrastructure, such as load distribution, availability, and deployment patterns of DNS servers. Our analysis includes both local DNS servers and servers in the authoritative hierarchy. We find that (1) the vast majority of users use a small fraction of deployed name servers, (2) the availability of most name servers is high, and (3) there exists a larger degree of diversity in local DNS server deployment and usage than for authoritative servers. Furthermore, we use our DNS measurements to draw conclusions about federated infrastructures in general. We evaluate and discuss the impact of federated deployment models on future systems, such as Distributed Hash Tables. Copyright 2004 ACM.",Availability; DNS; Federated,Clustering; Domain name system (DNS) servers; Federated; Load distribution; Availability; Client server computer systems; Communication systems; Distributed computer systems; Fault tolerant computer systems; Mathematical models; Servers; Telecommunication traffic; Internet
"Beigbeder T., Coughlan R., Lusher C., Plunkett J., Agu E., Claypool M.",6,The effects of loss and latency on user performance in unreal tournament 2003¨,2004,103,"Computer Science Department, Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609, United States",100 Institute Road;Worcester Polytechnic Institute,2,USA,1,14,9,"The growth in the popularity of interactive network games has increased the importance of a better understanding of the effects of packet loss and latency on user performance. While previous work on network games has studied user tolerance for high latencies and has studied the effects of latency on user performance in real-time strategy games, to the best of our knowledge, there has been no systematic study of the effects of loss and latency on user performance. In this paper we study user performance for Unreal Tournament 2003 (UT2003), a popular first person shooter game, under varying amounts of packet loss and latency. First, we deduced typical real world values of packet loss and latency experienced on the Internet by monitoring numerous operational UT2003 game servers. We then used these deduced values of loss and latency in a controlled networked environment that emulated various conditions of loss and latency, allowing us to monitor UT2003 at the network, application and user levels. We designed maps that isolated the fundamental first person shooter interaction components of movement and shooting, and conducted numerous user studies under controlled network conditions. We find that typical ranges of packet loss have no impact on user performance or on the quality of game play. The levels of latency typical for most UT2003 Internet servers, while sometimes unpleasant, do not significantly affect the outcome of the game. Since most first person shooter games typically consist of generic player actions similar to those that we tested, we believe that these results have broader implications. Copyright 2004 ACM.",latency; loss; network games,First person shooter; First person shooter games; Game servers; Internet servers; Loss networks; Network condition; Network game; Networked environments; Player action; Real-time strategy games; Systematic study; Unreal tournament; User levels; User performance; User study; User tolerance; Internet; Packet loss
"Katti S., Katabi D., Blake C., Kohler E., Strauss J.",5,MultiQ: Automated detection of multiple bottleneck capacities along a path,2004,38,"MIT CSAIL, United States; UCLA/ICIR",MIT,1,USA,1,23,17,"multiQ is a passive capacity measurement tool suitable for large-scale studies of Internet path characteristics. It is the first passive tool that discovers the capacity of multiple congested links along a path from a single flow trace, and the first tool that effectively extracts capacity information from ack-only traces. It uses equally-spaced mode gaps in TCP flows' packet interarrivai time distributions to detect multiple bottleneck capacities in their relative order. We validate multiQ in depth using the RON overlay network, which provides more than 400 heterogeneous, well-understood Internet paths. We compare multiQ with two other capacity measurement tools (Nettimer and Pathrate) in the first large-scale wide-area evaluation of capacity measurement techniques, and find that multiQ is highly accurate; for instance, though multiQ is passive, it achieves the same accuracy as Pathrate, which is active. Copyright 2004 ACM.",Capacity; Measurement; Modeling,Bottleneck; Capacity measurement tools; Cumulative distribution function (CDF); Timestamps; Bandwidth; Computer simulation; Error analysis; Graph theory; Packet networks; Telecommunication links; Telecommunication traffic; Internet
"Feamster N., Mao Z.M., Rexford J.",3,BorderGuard: Detecting cold potatoes from peers,2004,16,"MIT Computer Science and AI Lab., United States; University of Michigan, United States; AT and T Labs-Research, United States",AT and T Labs;MIT;University of Michigan at Ann Arbor,3,USA,1,9,4,"Internet Service Providers often establish contractual ""peering"" agreements, where they agree to forward traffic to each other's customers at no cost. Consistent route advertisement at all peering points is a common provision in these agreements, because it gives an AS the flexibility to select egress points for the traffic (e.g., performing ""hot potato"" routing). Verifying ""consistent export"" is challenging because route advertisements are exchanged at multiple peering points and may be modified by routing policies. In this paper, we propose two algorithms to detect inconsistent routes using routing and configuration data from an AS's border routers. The first algorithm requires access to all eBGP routes advertised by a peer. Because this data is often unavailable, we propose another algorithm that detects inconsistencies using readily available data. We have applied our algorithms to the routes advertised by the peers of AT&T's commercial IP backbone. Although a peer may intentionally send inconsistent advertisements to prevent its neighbor from performing hot-potato routing, we also discuss several configuration scenarios where a peer may inadvertently advertise inconsistent routes, despite having consistent export policies. Finally, we explain how simple modifications to the routers could make detection of inconsistent advertisements much easier than it is today. Copyright 2004 ACM.",Anomalies; BGP; Inconsistent advertisement; Peering,Border gateway protocol (BGP); Inconsistent advertizement; Internet service providers; Peering; Algorithms; Data reduction; Error analysis; Network protocols; Routers; Set theory; Telecommunication traffic; Internet
"Jehaes T., Quax P., Lamotte W.",3,Analysis of scalable data streams for representations in networked virtual environments,2004,1,"Expertise Center for Digital Media, Limburgs Universitair Centrum, Universitaire Campus, B-3590 Diepenbeek, Belgium",Expertise Center for Digital Media;Limburgs Universitair Centrum;Universitaire Campus,3,Belgium,1,1,1,"Analyzing the data generated by networked applications is a topic of great interest to a number of parties, such as ISPs and Network Equipment Manufacturers. However, it is becoming an increasingly difficult task to accomplish, mainly due to the use of undisclosed protocols. This is especially true when considering applications that stream content in real-time from central servers. There is a clear need for more detailed knowledge of the network behavior of these techniques. In this poster,we analyze the data streams related to 3D objects that are requested by the clients of our own networked virtual environment framework. We employ several LoD optimizations such as the use of image based representations and reduced complexity geometrical models. Using these optimizations,we try to deliver an acceptable visual representation of the virtual world as uickly as possible to a user in an environment that is in its entirety streamed in real-time from a server. Since these techniques are becoming integrated into commercial applications the conclusions drawn are widely applicable.",networked virtual environments; representations; scalability,3D object; Central servers; Commercial applications; Data stream; Geometrical models; Image-based representation; Network behaviors; Network equipment manufacturers; Networked applications; networked virtual environments; Reduced complexity; Virtual worlds; Visual representations; Data communication systems; Scalability; Servers; Virtual reality
"Kumar R., Kaur J.",2,Efficient beacon placement for network tomography,2004,28,"Department of Computer Science, University of North Carolina, Chapel Hill, United States",University of North Carolina at Chapel Hill,1,USA,1,16,14,"Recent interest in using tomography for network monitoring has raised the fundamental issue of whether it is possible to use only a small number of probing nodes (beacons) for monitoring all edges of a network in the presence of dynamic routing. Past work has shown that minimizing the number of beacons is NP-hard, and has provided approximate solutions that may be fairly suboptimal. In this paper, we use a two-pronged approach to compute an efficient beacon set: (i) we formulate the need for, and design algorithms for, computing the set of edges that can be monitored by a beacon under all possible routing states; and (ii) we minimize the number of beacons used to monitor all network edges. We show that the latter problem is NP-complete and use an approximate placement algorithm that yields beacon sets of sizes within 1 + ln (|E|) of the optimal solution, where E is the set of edges to be monitored. Beacon set computations for several Rocketfuel ISP topologies indicate that our algorithm may reduce the number of beacons yielded by past solutions by more than 50%. Copyright 2004 ACM.",Beacon Placement; Network Monitoring; Optimality; Tomography,Beacon placement; Network links; Network monitoring; Optimality; Algorithms; Computational methods; Graph theory; Network protocols; Optimization; Routers; Telecommunication links; Tomography; Internet
"Karagiannis T., Broido A., Faloutsos M., Claffy K.",4,Transport layer identification of P2P traffic,2004,506,"UC Riverside, United States; CAIDA, SDSC, United States",University of California Riverside,1,USA,1,33,23,"Since the emergence of peer-to-peer (P2P) networking in the late '90s, P2P applications have multiplied, evolved and established themselves as the leading 'growth app' of Internet traffic workload. In contrast to first-generation P2P networks which used well-defined port numbers, current P2P applications have the ability to disguise their existence through the use of arbitrary ports. As a result, reliable estimates of P2P traffic require examination of packet payload, a methodological landmine from legal, privacy, technical, logistic, and fiscal perspectives. Indeed, access to user payload is often rendered impossible by one of these factors, inhibiting trustworthy estimation of P2P traffic growth and dynamics. In this paper, we develop a systematic methodology to identify P2P flows at the transport layer, i.e., based on connection patterns of P2P networks, and without relying on packet payload. We believe our approach is the first method for characterizing P2P traffic using only knowledge of network dynamics rather than any user payload. To evaluate our methodology, we also develop a payload technique for P2P traffic identification, by reverse engineering and analyzing the nine most popular P2P protocols, and demonstrate its efficacy with the discovery of P2P protocols in our traces that were previously unknown to us. Finally, our results indicate that P2P traffic continues to grow unabatedly, contrary to reports in the popular media. Copyright 2004 ACM.",Measurements; Peer-to-peer; Traffic classification,Internet service providers (ISP); Measurement analysis; Peer-to-peer (P2P) networks; Traffic classification; Algorithms; Computer software; Computer system firewalls; Cryptography; HTTP; Internet; Packet networks; Reverse engineering; Routers; Telecommunication traffic
"Nguyen C.D., Safaei F., Boustead P.",3,A distributed proxy system for provisioning immersive audio communication to massively multi-player games,2004,2,"Telecommunications and Information Technology Research Institute, University of Wollongong, Australia",University of Wollongong,1,Australia,1,1,1,"This paper evaluates the suitability of a distributed proxy architecture for the provision of an immersive audio communication service for massively multi-player online games. The immersive audio communication service enables each avatar to hear a realistic audio mix of conversations in its hearing range. The proxy architecture is presented to address some limitations of previously proposed architectures, namely peer-to-peer and central server. We have developed a simulation model to evaluate the performance these delivery architectures in different game delivery scenarios. In particular, the bandwidth efficiency of network multicast for the proxy architecture in different avatar grouping behaviours and player distribution scenarios is studied. In addition, we investigate the impact of varying the number of proxy servers on the game communication delays.",immersive audio; massively multi-player games; multicast; provisioning; simulation,Bandwidth efficiency; Central servers; Communication delays; Delivery architecture; Distributed proxies; Distributed proxy architecture; Immersive audio; Massively multi-player online games; Massively multiplayer games; Multicasts; Peer to peer; Proposed architectures; Proxy architecture; Proxy server; Simulation model; Communication; Computer simulation; Multicasting; Servers; Online systems
"Pang R., Barford P., Yegneswaran V., Paxson V., Peterson L.",5,Characteristics of internet background radiation,2004,205,"Dept. of Computer Science, Princeton University, United States; Dept. of Computer Science, University of Wisconsin, Madison, United States; Intl. Computer Science Institute, United States; Lawrence Berkeley Laboratory, United States",University of California Berkeley;Princeton University;University of Wisconsin-Madison,3,USA,1,43,26,"Monitoring any portion of the Internet address space reveals incessant activity. This holds even when monitoring traffic sent to unused addresses, which we term ""background radiation."" Background radiation reflects fundamentally nonproductive traffic, either malicious (flooding backscatter, scans for vulnerabilities, worms) or benign (misconfigurations). While the general presence of background radiation is well known to the network operator community, its nature has yet to be broadly characterized. We develop such a characterization based on data collected from four unused networks in the Internet. Two key elements of our methodology are (i) the use of filtering to reduce load on the measurement system, and (ii) the use of active responders to elicit further activity from scanners in order to differentiate different types of background radiation. We break down the components of background radiation by protocol, application, and often specific exploit; analyze temporal patterns and correlated activity; and assess variations across different networks and over time. While we find a menagerie of activity, probes from worms and autorooters heavily dominate. We conclude with considerations of how to incorporate our characterizations into monitoring and detection activities. Copyright 2004 ACM.",Honeypot; Internet Background Radiation; Network Telescope,Honeypot; Internet background radiation; Network telescopes; Radiation traffic; Backscattering; Computer system recovery; Data acquisition; Database systems; Information analysis; Radiation; Security of data; Telecommunication traffic; Internet
"Raghunath S., Ramakrishnan K.K., Kalyanaraman S., Chase C.",4,Measurement based characterization and provisioning of IP VPNs,2004,15,"Nortel Networks, United States; AT and T Labs - Research, United States; Dept. of ECSE, RPI, United States",AT and T Labs,1,USA,1,5,5,"Virtual Private Networks provide secure and reliable communication between customer sites. With increase in number and size of VPNs, providers need efficient provisioning techniques that adapt to customer demand by leveraging a good understanding of VPN properties. In this paper we analyze two important properties of VPNs that impact provisioning - (a) structure of customer end-point (CE) interactions and (b) temporal characteristics of CE-CE traffic. We deduce these properties by computing traffic matrices from SNMP measurements. We find that existing traffic matrix estimation techniques are not readily applicable to the VPN scenario due to the scale of the problem and limited measurement information. We begin by formulating a scalable technique that makes the most out of existing measurement information and provides good estimates for common VPN structures. We then use this technique to analyze SNMP measurement from a large IP VPN service provider. We find that even with limited measurement information we can realize adaptive provisioning for a significant fraction of VPNs, namely, those constituting the ""Hub-and-Spoke"" category. In addition, the ability to infer the structure of VPNs holds special significance for provisioning tasks arising from topology changes, link failures and maintenance. We are able to provide a classification of VPNs by structure and identify CEs that act as hubs of communication and hence require prioritized treatment during restoration and provisioning. Copyright 2004 ACM.",Provisioning; Traffic Engineering; Traffic Matrix Estimation; VPN,Provisioning; Traffic engineering; Traffic matrix estimation; Virtual private networks (VPN); Communication systems; Information analysis; Mathematical models; Network protocols; Parameter estimation; Problem solving; Telecommunication traffic; Computer networks
"Sommers J., Yegneswaran V., Barford P.",3,A framework for malicious workload generation,2004,27,"University of Wisconsin, Madison, United States",University of Wisconsin-Madison,1,USA,1,18,18,"Malicious traffic from self-propagating worms and denial-of-service attacks constantly threatens the everyday operation of Internet systems. Defending networks from these threats demands appropriate tools to conduct comprehensive vulnerability assessments of networked systems. This paper describes MACE, a unique environment for recreating a wide range of malicious packet traffic in laboratory testbeds. MACE defines a model for flexible composition of malicious traffic that enables both known attacks (such as the Welchia worm) and new attack variants to be created. We implement this model in an extensible library for attack traffic specification and generation. To demonstrate the capability of MACE, we provide an analysis of stress tests conducted on a popular firewall and two popular network intrusion detection systems. Our results expose potential weaknesses of these systems and reveal that modern firewalls and network intrusion detection systems could be easily overwhelmed by simple attacks launched from a small number of hosts. Copyright 2004 ACM.",Network Intrusions; Traffic Generation,Malicious traffic; Network intrusions; Traffic generation; Workloads; Client server computer systems; Computer system firewalls; Internet; Mathematical models; Network protocols; Packet networks; Quality of service; Security of data; Servers; Telecommunication traffic
McEachen II J.C.,1,A self-similarity traffic analysis of an internet-based multiplayer online game,2004,1,"Naval Postgraduate School, Code EC/Mj, 833 Dyer Road, Monterey, CA 93943, United States",Naval Postgraduate School,1,USA,1,4,2,"An analysis of traffic generated by the popular Internet-based online game engine, Unreal Engine, is presented. Network parameters such as packet length, interarrival time and aggregate data rate are observed for analyzing aspects of self-similarity. Client-side packet traces are collected and analyzed for both client and server traffic. Initial analysis of over three million packets indicates client generated traffic shows strong long-range dependence of a self-similar nature primarily due to packet length associated with user actions. On the contrary, server generated traffic seen at the client, while still exhibiting a heavy tail, is more short-range dependent in regions where self-similarity is observed.",MMOG; multiplayer; self-similarity,Data rates; Heavy-tails; Inter-arrival time; Internet based; Long range dependence; Multi-player online games; Multiplayers; Network parameters; On-line games; Packet length; Self-similar; Self-similarities; Short-range dependents; Traffic analysis; User action; Internet
"Roughan M., Sen S., Spatscheck O., Duffield N.",4,Class-of-Service mapping for QoS: A statistical signature-based approach to IP traffic classification,2004,325,"School of Mathematical Sciences, University of Adelaide, SA 5005, Australia; AT and T Labs - Research, Florham Park, NJ 07932-0971, United States",AT and T Labs;University of Adelaide,2,Australia;USA,2,36,29,"The ability to provide different Quality of Service (QoS) guarantees to traffic from different applications is a highly desired feature for many IP network operators, particularly for enterprise networks. Although various mechanisms exist for providing QoS in the network, QoS is yet to be widely deployed. We believe that a key factor holding back widespread QoS adoption is the absence of suitable methodologies/processes for appropriately mapping the traffic from different applications to different QoS classes. This is a challenging task, because many enterprise network operators who are interested in QoS do not know all the applications running on their network, and furthermore, over recent years port-based application classification has become problematic. We argue that measurement based automated Class of Service (CoS) mapping is an important practical problem that needs to be studied. In this paper we describe the requirements and associated challenges, and outline a solution framework for measurement based classification of traffic for QoS based on statistical application signatures. In our approach the signatures are chosen in such as way as to make them insensitive to the particular application layer protocol, but rather to determine the way in which an application is used - for instance is it used interactively, or for bulk-data transport. The resulting application signature can then be used to derive the network layer signatures required to determine the CoS class for individual IP datagrams. Our evaluations using traffic traces from a variety of network locations, demonstrate the feasibility and potential of the approach. Copyright 2004 ACM.",Class of Service (CoS); Quality of Service (QoS); Statistical Signatures; Traffic Classification,Algorithms; Data transfer; Error analysis; Internet; Local area networks; Network protocols; Servers; Statistical methods; Telecommunication traffic; Wide area networks; Class of service (CoS); Network parameters; Statistical signatures; Traffic classification; Quality of service
"Mansley K., Scott D., Tse A., Madhavapeddy A.",4,"Feedback, latency, accuracy: Exploring tradeoffs in location-aware gaming",2004,8,"Laboratory for Communication Engineering, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom; Intel Research Cambridge, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",Intel,1,UK,1,20,16,"We are witnessing the development of large-scale location systems and a corresponding rise in the popularity of location-aware applications, especially games. Traditional computer games have pushed the limits of CPU and graphics card performance for many years and experience suggests that location-aware games will place similar demands upon location systems. Unlike traditional gaming platforms however, the mobile devices that interact with location systems are heavily constrained especially in the number of ways that feedback can be provided.In this paper we describe a location-aware, fast-paced, close quarters action game and use it to experiment with three key components of future location-aware gaming platforms: (i) the location system, (ii) the network to connect the mobile devices, and (iii) the feedback and computational capabilities of the mobile devices themselves.We investigate the tradeoffs that are possible between these components, the effect of the feedback channel and the suitability of Bluetooth as a network for mobile game devices. Copyright 2004 ACM.",bluetooth; location systems; mobile gaming,Computational capability; Feedback channel; Graphics card; Key component; Location systems; Location-aware; Location-aware application; Mobile games; Mobile gaming; Traditional computers; Computer graphics; Mobile devices; Mobile telecommunication systems; Portable equipment; Bluetooth
"Mao Y., Saul L.K.",2,Modeling distances in large-scale networks by matrix factorization,2004,67,"Department of Computer Science, University of Pennsylvania, United States",University of Pennsylvania,1,USA,1,22,18,"In this paper, we propose a model for representing and predicting distances in large-scale networks by matrix factorization. The model is useful for network distance sensitive applications, such as content distribution networks, topology-aware overlays, and server selections. Our approach overcomes several limitations of previous coordinates-based mechanisms, which cannot model sub-optimal routing or asymmetric routing policies. We describe two algorithms singular value decomposition (SVD) and nonnegative matrix factorization (NMF) - for representing a matrix of network distances as the product of two smaller matrices. With such a representation, we build a scalable system - Internet Distance Estimation Service (IDES) - that predicts large numbers of network distances from limited numbers of measurements. Extensive simulations on real-world data sets show that IDES leads to more accurate, efficient and robust predictions of latencies in large-scale networks than previous approaches. Copyright 2004 ACM.",Matrix factorization; Network distance,Matrix factorization; Network distance; Nonnegative matrix factorization (NMF); Singular value decomposition (SVD); Algorithms; Computer simulation; Large scale systems; Mathematical models; Matrix algebra; Optimization; Robustness (control systems); Computer networks
"Okanda P., Blair G.",2,OpenPING: A reflective middleware for the construction of adaptive networked game applications,2004,1,"Computing Department, Lancaster University, Lancaster, LA1 4YR, United Kingdom",Lancaster University,1,UK,1,11,5,"The emergence of distributed Virtual Reality (VR) applications that run over the Internet has presented networked game application designers with new challenges. In an environment where the public internet streams multimedia data and is constantly under pressure to deliver over widely heterogeneous user-platforms, there has been a growing need that distributed VR applications be aware of and adapt to frequent variations in their context of execution. In this paper, we argue that in contrast to research efforts targeted at improvement of scalability, persistence and responsiveness capabilities, much less attempts have been aimed at addressing the flexibility, maintainability and extensibility requirements in contemporary distributed VR platforms. We propose the use of structural reflection as an approach that not only addresses these requirements but also offers added value in the form of providing a framework for scalability, persistence and responsiveness that is itself flexible, maintainable and extensible. We also present an adaptive middleware platform implementation called OpenPING1 that supports our proposal in addressing these requirements. Copyright 2004 ACM.",adaptation; middleware platforms; networked games; reflection; virtual reality (VR),Adaptive middleware; Added values; Distributed virtual reality; Heterogeneous users; middleware platforms; Multimedia data; Networked games; Public internet; Reflective middleware; Research efforts; Structural reflection; VR applications; Internet; Maintainability; Reflection; Scalability; Virtual reality; Middleware
"Lakhina A., Crovella M., Diot C.",3,Characterization of network-wide anomalies in traffic flows,2004,207,"Dept. of Computer Science, Boston University, United States; Intel Research, Cambridge, United Kingdom",Boston University;Intel,2,UK;USA,2,25,17,"Detecting and understanding anomalies in IP networks is an open and ill-defined problem. Toward this end, we have recently proposed the subspace method for anomaly diagnosis. In this paper we present the first large-scale exploration of the power of the subspace method when applied to flow traffic. An important aspect of this approach is that it fuses information from flow measurements taken throughout a network. We apply the subspace method to three different types of sampled flow traffic in a large academic network: multivariate timeseries of byte counts, packet counts, and IP-flow counts. We show that each traffic type brings into focus a different set of anomalies via the subspace method. We illustrate and classify the set of anomalies detected. We find that almost all of the anomalies detected represent events of interest to network operators. Furthermore, the anomalies span a remarkably wide spectrum of event types, including denial of service attacks (single-source and distributed), flash crowds, port scanning, downstream traffic engineering, high-rate flows, worm propagation, and network outage. Copyright 2004 ACM.",Anomaly Detection; Network Traffic Analysis,Anomaly detection; Network traffic analysis; Traffic engineering; Work propagation; Data transfer; Network protocols; Principal component analysis; Routers; Statistical process control; Telecommunication traffic; Time series analysis; Telecommunication networks
"Chen B.D., Maheswaran M.",2,A cheat controlled protocol for centralized online multiplayer games,2004,18,"School of Computer Science, McGill University, Montreal, QC, Canada",McGill University,1,Canada,1,8,8,"Ordering of command messages from the clients at the game servers is an important issue that impacts fairness, response times, and smoothness of the game play. Recently, protocols based on ""reaction"" times were proposed to order the command messages. This paper presents a protocol that can be used to control cheating in reaction time based message ordering schemes. We examine the performance of the proposed protocol by emulating wide-area game play scenarios on the Planet-Lab. The results from the experiments indicate that the proposed protocol is able to dramatically reduce the cheating opportunities that exist for the clients. Copyright 2004 ACM.",cheat prevention; multiplayer online games; time cheating,Cheat controlled protocols; Cheat prevention; Game servers; Message ordering; Multi-player online games; Online multiplayer games; Reaction time; Response time; Time cheating; Wide area; Distributed computer systems
"Lee S., Zhang Z.-L., Nelakuditi S.",3,Exploiting AS hierarchy for scalable route selection in multi-homed stub networks,2004,7,"Computer Sci. and Engg., University of Minnesota, United States; Computer Sci. and Engg., University of South Carolina, United States",University of Minnesota;University of South Carolina,2,USA,1,10,7,"Multi-homing is a common practice among many (especially large) customer (or stub) networks. Although the purpose of multi-homing is primarily for enhanced reliability, it has also increasingly been used for load balancing and latency reduction. In this paper, we address the problem of how to perform scalable route selection in a multi-homed stub network to optimize network latency to various destinations as measured by round-trip-time (RTT). A straightforward method is to simply perform RTT measurements (e.g., using ping) to each destination via each provider and select the one with the minimum RTT as the ""best"" next-hop to the destination. Is there a more scalable alternative? To answer this question, we carry out a measurement-based study to analyze the differences of RTTs in using two different providers in a multi-homed stub network to reach a large number of randomly selected destinations. Our study reveals that because of the AS hierarchy, for a large fraction of the network prefixes, the two AS paths through two providers merge in the core of the Internet. Furthermore, the router at which the two router level paths merge is actually in the AS at which the AS level paths merge. This phenomenon causes the RTT difference between the two paths through the two providers to be determined by the non-shared portion of the paths. Our study reveals that most of the two router level paths through the two upstream providers merge at the AS at which the two AS level paths merge. Based on this finding, we devise a scalable route (next-hop provider) selection algorithm using BGP information in a multi-homed stub network. We also present a preliminary evaluation. Copyright 2004 ACM.",AS hierarchy; Multi-homing; Route selection,Autonomous systems (AS) hierarchy; Multi-homing; Network latency; Route selection; Algorithms; Communication systems; Information analysis; Intelligent agents; Optimization; Parameter estimation; Routers; Computer networks
"Smed J., Niinisalo H., Hakonen H.",3,Realizing bullet time effect in multiplayer games with local perception filters,2004,1,"Turku Centre for Computer Science (TUCS), Department of Information Technology, University of Turku, Finland; Department of Information Technology, University of Turku, Finland",University of Turku,1,Finland,1,9,9,"Local perception filters exploit the limitations of human perception to reduce the effects of network latency in multiplayer computer games. Because they allow temporal distortions in the rendered view, they can be modified to realize bullet time effect, where a player can get more reaction time by slowing down the surrounding game world. In this paper, we examine the concepts behind local perception filters and extend them to cover artificially increased delays. The presented methods are implemented in a testbench program, which is used to study the usability and limitations of the approach. Copyright 2004 ACM.",bullet time; computer games; latency; multiplayer; networking; virtual environments,Bullet time; Computer game; Human perception; Local perception filters; Multiplayer computer games; Multiplayer games; Multiplayers; Network latencies; Reaction time; Temporal distortions; Test-bench; Virtual environments; Computer software; Face recognition; Virtual reality; Projectiles
"Lakshminarayanan K., Padmanabhan V.N., Padhye J.",3,Bandwidth estimation in broadband access networks,2004,96,"University of California, Berkeley, United States; Microsoft Research",Microsoft;University of California Berkeley,2,USA,1,25,19,"There has been much work on developing techniques for estimating the capacity and the available bandwidth of network paths based on end-point measurements. The focus has primarily been on settings where the constrained link can be modeled as a point-to-point link with a well-defined bandwidth, serving packets in FIFO order. In this paper, we point out that broadband access networks, such as cable modem and 802.11-based wireless networks, break this model in various ways. The constrained link could (a) employ mechanisms such as token bucket rate regulation, (b) schedule packets in a non-FIFO manner, and (c) support multiple distinct rates. We study how these characteristics impede the operation of the various existing methods and tools for capacity and available bandwidth estimation, and present a new available bandwidth estimation technique, Probe-Gap, that overcomes some of these difficulties. Our evaluation is based on experiments with actual 802.11a and cable modem links. Copyright 2004 ACM.",Available bandwidth; Broadband networks; Capacity; Network measurement,Bandwidth estimation; Broadband access networks; One-way delay (OWD) samples; Bandwidth; Constraint theory; Internet; Parameter estimation; Telecommunication traffic; Wireless telecommunication systems; Broadband networks
"Papagiannaki K., Taft N., Lakhina A.",3,A distributed approach to measure IP traffic matrices,2004,62,"Intel Research, Cambridge, United Kingdom; Intel Research, Berkeley, CA, United States; Computer Science Department, Boston University, MA, United States",Boston University;Intel,2,UK;USA,2,14,14,"The traffic matrix of a telecommunications network is an essential input for any kind of network design and capacity planning decision. In this paper we address a debate surrounding traffic matrix estimation, namely whether or not the costs of direct measurement are too prohibitive to be practical. We examine the feasibility of direct measurement by outlining the computation, communication and storage overheads, for traffic matrices defined at different granularity levels. We illustrate that today's technology, that necessitates a centralized solution, does indeed incur prohibitive costs. We explain what steps are necessary to move towards fully distributed solutions, that would drastically reduce many overheads. However, we illustrate that the basic distributed solution, in which flow monitors are on all the time, is excessive and unnecessary. By discovering and taking advantage of a key stability property underlying traffic matrices, we are able to propose a new scheme that is distributed and relies only on a limited use of flow measurement data. Our approach is simple, accurate and scalable. Furthermore, it significantly reduces the overheads above and beyond the basic distributed solution. Our results imply that direct measurement of traffic matrices should become feasible in the near future. Copyright 2004 ACM.",Distributed algorithm; Internet measurement; Traffic matrix,Algorithms; Computational methods; Error analysis; Internet; Optimization; Routers; Statistics; Telecommunication networks; Distributed algorithm; Internet measurement; Traffic engineering; Traffic matrices (TM); Telecommunication traffic
"Liu X., Ravindran K., Liu B., Loguinov D.",4,Single-hop probing asymptotics in available bandwidth estimation: Sample-path analysis,2004,30,"City University of New York, New York, NY 10016, United States; City College of New York, New York, NY 10031, United States; Texas A and M University, College Station, TX 77843, United States",City College of New York;Texas A and M University,2,USA,1,23,19,"In this paper, we take the sample-path approach in analyzing the asymptotic behavior of single-hop bandwidth estimation under bursty cross-traffic and show that these results are provably different from those observed under fluid models of prior work. This difference, which we call the probing bias, is one of the previously unknown factors that can cause measurement inaccuracies in available bandwidth estimation. We present an analytical formulation of ""packet probing,"" based on which we derive several major properties of the probing bias. We then experimentally observe the probing bias and investigate its quantitative relationship to several deciding factors such as probing packet size, probing train length, and cross-traffic burstiness. Both our analytical and experimental results show that the probing bias vanishes as the packet-train length or packet size increases. The vanishing rate is decided by the burstiness of cross-traffic. Copyright 2004 ACM.",Bandwidth measurement; Packet train probing,Convergence of numerical methods; Heuristic methods; Mathematical models; Packet networks; Parameter estimation; Telecommunication traffic; Analytical formulation; Bandwidth measurement; Packet train probing; Sample-path analysis; Bandwidth
"Medina A., Allman M., Floyd S.",3,Measuring interactions between transport protocols and middleboxes,2004,35,"ICSI Center for Internet Research, United States","ICSI Center for Internet Research,USA",1,USA,1,29,20,"In this paper we explore the current network environment with respect to how the network's evolution ultimately impacts end-to-end protocols. The traditional end-to-end assumptions about the Internet are increasingly challenged by the introduction of intermediary network elements (middleboxes) that intentionally or unintentionally prevent or alter the behavior of end-to-end communications. This paper provides measurement results showing the impact of the current network environment on a number of traditional and proposed protocol mechanisms (e.g., Path MTU Discovery, Explicit Congestion Notification, etc.). We present results of measurements taken using an active measurement framework to study web servers. We analyze our results to gain further understanding of the differences between the behavior of the Internet in theory versus the behavior we observed through measurements. In addition, these measurements can be used to guide the definition of more realistic Internet modeling scenarios. Copyright 2004 ACM.",Evolution; Internet; Middleboxes; TCP,Evolution; Middleboxes; Transmission control protocols (TCP); Transport protocols; Communication systems; Computer architecture; Computer simulation; Congestion control (communication); Internet; Problem solving; Telecommunication traffic; Network protocols
"Degioanni L., Varenni G.",2,Introducing scalability in network measurement: Toward 10 Gbps with commodity hardware,2004,18,"Computer Science Department, University of California, Davis, One Shields Avenue, Davis, CA 95616, United States; Dipartimento di Automatica, Politecnico di Torino, Corso Duca degli Abruzzi, 24, 10129 Torino, Italy",Politecnico di Torino;University of California Davis,2,Italy;USA,2,13,6,"The capacity of today's network links, along with the heterogeneity of their traffic, is rapidly growing, more than the workstation's processing power. This makes the task of measuring traffic more problematic every day, especially when off-the-shelf hardware is used. A general solution adopted by the computer industry to achieve better performance is to partition the processing among different computing units, exploiting the implicit or explicit parallelism available on today workstations. Parallelism is in fact growing in two dimensions: physical and logical CPUs (e.g. HyperThreading). Unfortunately, most network measurement systems are engineered to process data in a set of sequential tasks; thus, completely ignoring any form of parallelism provided by the hardware. This paper introduces a new approach to build high performance and scalable network measurement tools. It discusses the problem of dispatching packets to different processing entities and describes a technology able to distribute the flow of incoming packets among different processors in an effective and configurable manner, that avoids any copy and optimizes resource usage. Copyright 2004 ACM.",High performance; Scalability; Software tools,High performance network measurement tools; Network traffic; Scalability; Schedulers; Computer aided software engineering; Computer architecture; Computer hardware; Computer software; Computer workstations; Optimization; Packet networks; Telecommunication links; Telecommunication traffic; Computer networks
"Zhang Y., Singh S., Sen S., Duffield N., Lund C.",5,"Online identification of hierarchical heavy hitters: Algorithms, evaluation, and applications",2004,124,"ATandT Labs - Research, Florham Park, NJ 07932, United States; CSE Department, University of California, San Diego, CA 92040, United States",AT and T Labs;University of California San Diego,2,USA,1,35,27,"In traffic monitoring, accounting, and network anomaly detection, it is often important to be able to detect high-volume traffic clusters in near real-time. Such heavy-hitter traffic clusters are often hierarchical (i.e., they may occur at different aggregation levels like ranges of IP addresses) and possibly multidimensional (i.e., they may involve the combination of different IP header fields like IP addresses, port numbers, and protocol). Without prior knowledge about the precise structures of such traffic clusters, a naive approach would require the monitoring system to examine all possible combinations of aggregates in order to detect the heavy hitters, which can be prohibitive in terms of computation resources. In this paper, we focus on online identification of 1-dimensional and 2-dimensional hierarchical heavy hitters (HHHs), arguably the two most important scenarios in traffic analysis. We show that the problem of HHH detection can be transformed to one of dynamic packet classification by taking a top-down approach and adaptively creating new rules to match HHHs. We then adapt several existing static packet classification algorithms to support dynamic packet classification. The resulting HHH detection algorithms have much lower worst-case update costs than existing algorithms and can provide tunable deterministic accuracy guarantees. As an application of these algorithms, we also propose robust techniques to detect changes among heavy-hitter traffic clusters. Our techniques can accommodate variability due to sampling that is increasingly used in network measurement. Evaluation based on real Internet traces collected at a Tier-1 ISP suggests that these techniques are remarkably accurate and efficient. Copyright 2004 ACM.",Change Detection; Data Stream Computation; Hierarchical Heavy Hitters; Network Anomaly Detection; Packet Classification,Algorithms; Data structures; Error analysis; Hierarchical systems; Internet; Network protocols; Online systems; Packet networks; Routers; Set theory; Change detection; Data stream computation; Hierarchical heavy hitters (HHH); Network anomaly detection; Packet classification; Telecommunication traffic
"Gueye B., Crovella M., Ziviani A., Fdida S.",4,Constraint-based geolocation of Internet hosts,2004,23,"Lab. d'Informatique de Paris 6, Univ. Pierre et Marie Curie, 8, rue du Capitaine Scott, 75015 - Paris, France; Department of Computer Science, Boston University, 111 Cummington St., 02215 Boston, MA, United States",Boston University,1,France;USA,2,14,11,"Geolocation of Internet hosts enables a diverse and interesting new class of location-aware applications. Previous measurement-based approaches use reference hosts, called landmarks, with a well-known geographic location to provide the location estimation of a target host. This leads to a discrete space of answers, limiting the number of possible location estimates to the number of adopted landmarks. In contrast, we propose Constraint-Based Geolocation (CBG), which infers the geographic location of Internet hosts using multilateration with distance constraints, thus establishing a continuous space of answers instead of a discrete one. CBG accurately transforms delay measurements to geographic distance constraints, and then uses multilateration to infer the geolocation of the target host. Our experimental results show that CBG outperforms the previous measurement-based geolocation techniques. Moreover, in contrast to previous approaches, our method is able to assign a confidence region to each given location estimate. This allows a location-aware application to assess whether the location estimate is sufficiently accurate for its needs. Copyright 2004 ACM.",Delay measurements; Geolocation; Multilateration,Constraint theory; Data acquisition; Global positioning system; Information analysis; Parameter estimation; Problem solving; Delay measurements; Geolocation; Internet hosts; Multilateration; Internet
"Busse M., Lamparter B., Mauve M., Effelsberg W.",4,Lightweight QoS-support for networked mobile gaming,2004,14,"Praktische Informatik IV, University of Mannheim L15, 16, D-68161 Mannheim, Germany; NEC Europe Ltd., Network Laboratories, KurfŸrsten-Anlage 36, D-69115 Heidelberg, Germany; Institut fŸr Informatik, University of DŸsseldorf, UniversitŠtsstra§e 1, D-40225 DŸsseldorf, Germany",University of DŸsseldorf;University of Mannheim,2,Germany,1,24,16,"In this paper, we present an approach to provide Quality of Service (QoS) for networked mobile gaming. In order to examine the QoS requirements of mobile games, we ported a simple real-time game called GAV (GPL Arcade Volleyball) to a PDA and performed several traffic measurements over both GPRS and UMTS networks. We show that due to high end-to-end delay and delay jitter, real-time games are not supported by GPRS. While UMTS improves both delay and jitter, it still does not match the requirements of real-time games. The key reason for this problem is that overprovisioning, as it is used to allow real-time games in the Internet, is very expensive in mobile networks. At the same time, QoS classes for mobile networks are not tailored to real-time games. In order to reduce delay and jitter for this application class, while still accounting for the very bursty nature of real-time game flows, we propose to use a combination of statistical multiplexing and QoS guarantees. The general idea is to aggregate multiple game flows and perform reservation for that aggregate. As a theoretical background, we use a queuing system based model. Through simulation of a sample network with the traffic data generated by GAV, we validate our assumptions and demonstrate the performance and characteristics of our approach. Copyright 2004 ACM.",admission control; flow aggregation; mobile gaming; QoS-support; queuing systems; resource reservation,Admission Control; Mobile gaming; QoS support; Queuing systems; Resource reservations; Ad hoc networks; Computer simulation; Delay control systems; Jitter; Mobile telecommunication systems; Queueing networks; Queueing theory; Real time systems; Quality of service
"Aggarwal S., Banavar H., Khandelwal A., Mukherjee S., Rangarajan S.",5,Accuracy in dead-reckoning based distributed multi-player games,2004,67,"Department of Computer Science, Florida State University, Tallahassee, FL, United States; Center for Networking Research, Lucent Technologies Bell Laboratories, Holmdel, NJ, United States",Florida State University;Bell Labs,2,USA,1,12,8,"Distributed multi-player games use dead reckoning vectors to intimate other (at a distance) participating players about the movement of any entity by a controlling player. The dead reckoning vector contains the current position of the entity and the velocity components. When a participating player receives a vector, traditionally it puts the entity at the current position specified by the vector and starts projecting the path of the entity from that point using the local clock of the receiver. In this paper we show that this traditional method of usage of dead reckoning vector brings in inaccuracy in the receivers' rendering of the entity. This inaccuracy can be substantial even with low network delay between the sender-receiver pairs and increases with network delay. We propose the use of globally synchronized clocks among the participating players and a time-stamp augmented dead reckoning vector that enables the receiver to render the entity accurately. We modified the popular game BZFlag with this technique, and compared the accuracy seen in game playing using the traditional method and the proposed technique. We conducted several types of experiments varying the frequency of generation of dead reckoning vectors and the delay between the sender and the receivers. The experiments show significant quantitative improvement in accuracy even for 100ms delay between the sender-receiver pairs and appreciable qualitative improvement in game playing experience. Copyright 2004 ACM.",accuracy; clock synchronization; dead-reckoning; distributed multi-player games; network delay,Clock Synchronization; Dead reckoning; Distributed multi-player games; Game playing; Network delays; Sender-receiver pairs; Synchronized clocks; Time-stamp; Velocity components; Mechanical clocks; Navigation; Synchronization; Vectors
"DeLap M., Knutsson B., Lu H., Sokolsky O., Sammapun U., Lee I., Tsarouchis C.",7,Is runtime verification applicable to cheat detection?,2004,7,"Department of Computer and Information Science, University of Pennsylvania, United States",University of Pennsylvania,1,USA,1,10,5,"We investigate the prospect of applying runtime verification to cheat detection. Game implementation bugs are extensively exploited by cheaters, especially in massively multiplayer games. As games are implemented on larger scales and game object interactions become more complex, it becomes increasingly difficult to guarantee that high-level game rules are enforced correctly in the implementation. We observe that although implementing high-level rules in code is complex because of interference between rules, checking for rule compliance at runtime is simple because only a single rule is involved in each check. We demonstrate our idea by applying the Java-MaC runtime verification system to a simple game to detect a transaction bug that is common in massively multiplayer games. Copyright 2004 ACM.",cheat detection; multiplayer game; runtime verification,Cheat detection; Game rules; High-level rules; Massively multiplayer games; Multiplayer games; Object interactions; Run-time verification; Runtimes; Simple games; Single-rule
Paxson V.,1,Strategies for sound internet measurement,2004,74,"Intl. Computer Science Institute, Berkeley, CA 94704, United States",University of California Berkeley,1,USA,1,30,26,"Conducting an Internet measurement study in a sound fashion can be much more difficult than it might first appear. We present a number of strategies drawn from experiences for avoiding or overcoming some of the pitfalls. In particular, we discuss dealing with errors and inaccuracies; the importance of associating meta-data with measurements; the technique of calibrating measurements by examining outliers and testing for consistencies; difficulties that arise with large-scale measurements; the utility of developing a discipline for reliably reproducing analysis results; and issues with making datasets publicly available. We conclude with thoughts on the sorts of tools and community practices that can assist researchers with conducting sound measurement studies. Copyright 2004 ACM.",Calibration; Datasets; Internet measurement; Meta-data; Reproducibility,Calibration; Computer operating systems; Metadata; Network protocols; Telecommunication links; Telecommunication traffic; Datasets; Internet measurement; Packet filters; Reproducibility; Internet
"Mori T., Uchida M., Kawahara R., Pan J., Goto S.",5,Identifying elephant flows through periodically sampled packets,2004,107,"NTT Service Integration Labs, Waseda University, Japan; NTT Service Integration Labs, Japan; NTT MCL; Waseda University, Japan",Waseda University,1,Japan,1,16,11,"Identifying elephant flows is very important in developing effective and efficient traffic engineering schemes. In addition, obtaining the statistics of these flows is also very useful for network operation and management. On the other hand, with the rapid growth of link speed in recent years, packet sampling has become a very attractive and scalable means to measure flow statistics; however, it also makes identifying elephant flows become much more difficult. Based on Bayes' theorem, this paper develops techniques and schemes to identify elephant flows in periodically sampled packets. We show that our basic framework is very flexible in making appropriate trade-offs between false positives (misidentified flows) and false negatives (missed elephant flows) with regard to a given sampling frequency. We further validate and evaluate our approach by using some publicly available traces. Our schemes are generic and require no per-packet processing; hence, they allow a very cost-effective implementation for being deployed in large-scale high-speed networks. Copyright 2004 ACM.",Bayes' theorem; Flow statistics; Measurement; Packet sampling; The elephant and mice phenomenon,Bayes' theorem; Flow statistics; Measurement-based studies; Packet sampling; The elephant and the mice phenomena; Approximation theory; Internet; Packet networks; Probability; Set theory; Statistics; Telecommunication links; Telecommunication traffic
"Gomes L.H., Cazita C., Almeida J.M., Almeida V., Meira Jr. W.",5,Characterizing a spam traffic,2004,63,"Department of Computer Science, Federal University of Minas Gerais, Belo Horizonte, Brazil",Federal University of Minas Gerais,1,Brazil,1,35,26,"The rapid increase in the volume of unsolicited commercial e-mails, also known as spam, is beginning to take its toll in system administrators, business corporations and end-users. Widely varying estimates of the cost associated with spam are available in the literature. However, a quantitative analysis of the determinant characteristics of spam traffic is still an open problem. This work fills this gap and presents what we believe to be the first extensive characterization of a spam traffic. As basis for our characterization, standard spam detection techniques are used to classify over 360 thousand incoming e-mails to a large university into two categories, namely spam and non-spam. For each of the two resulting workloads, as well as for the aggregate workload, we analyze a set of parameters, aiming at identifying the characteristics that significantly distinguish spam from non-spam traffic, assessing the qualitative impact of spam on the aggregate traffic and, possibly, drawing insights into the design of more effective spam detection techniques. Our characterization reveals significant differences in the spam and non-spam traffic patterns. E-mail arrival process, size distribution as well as the distributions of popularity and temporal locality of e-mail recipients are key workload aspects which distinguish spam from traditional e-mail traffic. We conjecture that these differences are consequence of the inherently different mode of operation of spam and non-spam senders. Whereas non-spam e-mail transmissions are typically driven by social bilateral relationships, spam transmission is usually a unilateral action, based solely on the senders's will to reach as many users as possible. Copyright 2004 ACM.",E-mail Traffic; SPAM; Workload Characterization,Communication systems; Computer simulation; Electronic mail; Internet; Parameter estimation; Problem solving; Telecommunication traffic; Detection techniques; E-mail traffic; Spam traffic; Workload characterization; Spamming
"Quax P., Monsieurs P., Lamotte W., De Vleeschauwer D., Degrande N.",5,Objective and subjective evaluation of the influence of small amounts of delay and jitter on a recent first person shooter game,2004,55,"Expertise Center for Digital Media, Limburgs Universitair Centrum, Universitaire Campus, B-3590 Diepenbeek, Belgium; Alcatel Bell NV, Network Strategy Group, Francis Wellesplein 1, B-2018 Antwerpen, Belgium",Bell Labs;Limburgs University,2,Belgium,1,11,10,"There have been several studies in the past years that investigate the impact of network delay on multi-user applications. Primary examples of these applications are real-time multiplayer games. These studies have shown that high network delays and jitter may indeed influence the player's perception of the quality of the game. However, the proposed test values, which are often high, are not always representative for a large percentile of on-line game players. We have therefore investigated the influence of delay and jitter with numbers that are more representative for typical access networks. This in effect allows us to simulate a setup with multiplayer game servers that are located at ISP level and players connected through that ISP's access network. To obtain further true-to-life results, we opted to carry out the test using a recent first person shooter (FPS) game, Unreal Tournament 2003. It can, after all, be expected that this new generation of games has built-in features to diminish the effect of small delay values, given the popularity of playing these games over the Internet. In this paper, we have investigated both subjective perceived quality and objective measurements and will show that both are indeed influenced by even these small delay and jitter values. Copyright 2004 ACM.",analysis; network influences; on-line games,Access network; Built-in feature; Delay and jitter; Delay values; First person shooter games; Multi-user applications; Multiplayer game servers; Multiplayer games; Network delays; Network influences; Objective measurement; On-line games; Perceived quality; Subjective evaluations; Unreal tournament; Internet service providers; Servers; Jitter
"Sripanidkulchai K., Maggs B., Zhang H.",3,An analysis of live streaming workloads on the internet,2004,214,"Carnegie Mellon University, United States; Akamai Technologies, United States",Akamai Technologies;Carnegie Mellon University,2,USA,1,24,19,"In this paper, we study the live streaming workload from a large content delivery network. Our data, collected over a 3 month period, contains over 70 million requests for 5,000 distinct URLs from clients in over 200 countries. To our knowledge, this is the most extensive data of live streaming on the Internet that has been studied to date. Our contributions are two-fold. First, we present a macroscopic analysis of the workload, characterizing popularity, arrival process, session duration, and transport protocol use. Our results show that popularity follows a 2-mode Zipf distribution, session interarrivals within small time-windows are exponential, session durations are heavy-tailed, and that UDP is far from having universal reach on the Internet. Second, we cover two additional characteristics that are more specific to the nature of live streaming applications: the diversity of clients in comparison to traditional broadcast media like radio and TV, and the phenomena that many clients regularly join recurring events. We find that Internet streaming does reach a wide audience, often spanning hundreds of AS domains and tens of countries. More interesting is that small streams also have a diverse audience. We also find that recurring users often have lifetimes of at least as long as one-third of the days in the event. Copyright 2004 ACM.",Content delivery networks; Live streaming,Content delivery networks; Internet traffic; Live streaming; Video traffic; Broadcasting; Client server computer systems; Data acquisition; Digital television; Distributed computer systems; Encoding (symbols); Servers; Telecommunication traffic; Websites; Internet
"Jain M., Dovrolis C.",2,Ten fallacies and pitfalls on end-to-end available bandwidth estimation,2004,74,"Georgia Tech, United States",Georgia Tech,1,USA,1,14,14,"The area of available bandwidth (avail-bw) estimation has attracted significant interest recently, with several estimation techniques and tools developed during the last 2-3 years. Unfortunately, some key issues regarding the avail-bw definition, estimation, and validation remain vague or misinterpreted. In this note, we first review the previous work in the area and classify the existing techniques in two classes: direct probing and iterative probing. We then identify ten misconceptions, in the form of fallacies or pitfalls, that we consider as most important. Some misconceptions relate to basic statistics, such as the impact of the population variance on the sample mean, the variability of the avail-bw in different time scales, and the effect of the probing duration. Other misconceptions relate to the queueing model underlying these estimation techniques. For instance, ignoring that traffic burstiness or the presence of multiple bottlenecks can cause significant underestimation errors. Our objective is not to debunk previous work or to claim that some estimation techniques are better than others, but to clarify a number of important issues that cover the entire area of avail-bw estimation so that this important metric can be better understood and put in practical use. Copyright 2004 ACM.",Active measurements; Available bandwidth; Band-width estimation; Measurement tools; Packet pairs and trains,Active measurements; Available bandwidth; Bandwidth estimation; Measurement tools; Packet pairs and trains; Computer aided software engineering; Computer simulation; Error analysis; Packet networks; Telecommunication links; Telecommunication traffic; Bandwidth
"Sommers J., Barford P.",2,Self-configuring network traffic generation,2004,129,"University of Wisconsin, Madison, United States",University of Wisconsin-Madison,1,USA,1,51,51,"The ability to generate repeatable, realistic network traffic is critical in both simulation and testbed environments. Traffic generation capabilities to date have been limited to either simple sequenced packet streams typically aimed at throughput testing, or to application-specific tools focused on, for example, recreating representative HTTP requests. In this paper we describe Harpoon, a new application-independent tool for generating representative packet traffic at the IP flow level Harpoon generates TCP and UDP packet flows that have the same byte, packet, temporal and spatial characteristics as measured at routers in live environments. Harpoon is distinguished from other tools that generate statistically representative traffic in that it can self-configure by automatically extracting parameters from standard Netflow logs or packet traces. We provide details on Harpoon's architecture and implementation, and validate its capabilities in controlled laboratory experiments using configurations derived from flow and packet traces gathered in live environments. We then demonstrate Harpoon's capabilities in a router benchmarking experiment that compares Harpoon with commonly used throughput test methods. Our results show that the router subsystem load generated by Harpoon is significantly different, suggesting that this kind of test can provide important insights into how routers might behave under actual operating conditions. Copyright 2004 ACM.",Network Flows; Traffic Generation,Network flows; Network traffic; Packet streams; Traffic generation; Client server computer systems; Data acquisition; Database systems; HTTP; Packet networks; Routers; Servers; Throughput; Telecommunication traffic
Lintault I.,1,A transaction execution engine architecture for multiplayer online games,2004,1,"Intel Corporation, 311 Marunouchi, Chiyodaku, Tokyo, 100-0005, Japan",Intel,1,Japan,1,3,2,"In the pursuit of massively multiplayer online games, efficient engines capable of processing sophisticated game scenarios are necessary to support large scale virtual worlds. By applying microprocessor microarchitectural design techniques to game server software design, functional parallelism inherent in complex game transactions can be exploited, augmenting server performance.In a given gaming scenario, complex game transactions can be modeled as data flow graphs. An individual graph represents the collective atomic operations of a particular transaction. Analysis of data flow graphs provides a mechanism that identifies opportunities for parallelism by exposing data dependencies.This poster presents an engine architecture that supports spatial and temporal parallel execution of complex game transactions expressed as data flow graphs. The engine takes advantage of data flow enhancement techniques such as dynamic out-of-order execution to achieve a high level of performance.",data flow architecture; distributed simulation; dynamic scheduling; game architecture; online games; task scheduling; transaction execution; transaction level parallelism,Dataflow architecture; Distributed simulations; Dynamic scheduling; Game architecture; On-line games; Task-scheduling; Transaction execution; Transaction level parallelism; Flow simulation; Graphic methods; Interactive computer graphics; Multitasking; Parallel flow; Scheduling; Scheduling algorithms; Software design; Data flow analysis
"Schweller R., Gupta A., Parsons E., Chen Y.",4,Reversible sketches for efficient and accurate change detection over network data streams,2004,78,"Department of Computer Science, Northwestern University, Evanston, IL 60201-3150, United States",Northwestern University,1,USA,1,27,24,"Traffic anomalies such as failures and attacks are increasing in frequency and severity, and thus identifying them rapidly and accurately is critical for large network operators. The detection typically treats the traffic as a collection of flows and looks for heavy changes in traffic patterns (e.g., volume, number of connections). However, as link speeds and the number of flows increase, keeping per-flow state is not scalable. The recently proposed sketch-based schemes [14] are among the very few that can detect heavy changes and anomalies over massive data streams at network traffic speeds. However, sketches do not preserve the key (e.g., source IP address) of the flows. Hence, even if anomalies are detected, it is difficult to infer the culprit flows, making it a big practical hurdle for online deployment. Meanwhile, the number of keys is too large to record. To address this challenge, we propose efficient reversible hashing algorithms to infer the keys of culprit flows from sketches without storing any explicit key information. No extra memory or memory accesses are needed for recording the streaming data. Meanwhile, the heavy change detection daemon runs in the background with space complexity and computational time sublinear to the key space size. This short paper describes the conceptual framework of the reversible sketches, as well as some initial approaches for implementation. See [23] for the optimized algorithms in details. Evaluated with netflow traffic traces of a large edge router, we demonstrate that the reverse hashing can quickly infer the keys of culprit flows even for many changes with high accuracy. Copyright 2004 ACM.",Change detection; Data stream computation; IP mangling; Modular hashing; Network anomaly detection; Reverse hashing; Sketch,Algorithms; Error analysis; Graph theory; Mathematical models; Network protocols; Routers; Set theory; Telecommunication links; Telecommunication traffic; Time series analysis; Change detection; Data stream computation; IP mangling; Modular hashing; Network anomaly detection; Reverse hashing; Reversible sketches; Telecommunication networks
"Rupp A., Dreger H., Feldmann A., Sommer R.",4,Packet trace manipulation framework for test labs,2004,7,"Ruhr-UniversitŠt Bochum, Germany; TU MŸnchen, Germany",Ruhr-University Bochum;TU Munich,2,Germany,1,19,14,"Evaluating network components such as network intrusion detection systems, firewalls, routers, or switches suffers from the lack of available network traffic traces that on the one hand are appropriate for a specific test environment but on the other hand have the same characteristics as actual traffic. Instead of just capturing traffic and replaying the trace, we identify a set of packet trace manipulation operations that enable us to generate a trace bottom-up: our trace primitives can be traces from different environments or artificially generated ones; our basic operations include merging of two traces, moving a flow across time, duplicating a flow, and stretching a flow's time-scale. After discussing the potential as well as the dangers of each operation with respect to analysis at different protocol layers, we present a frame-work within which these operations can be realized and show an example configuration for our prototype. Copyright 2004 ACM.",Evaluation; Measurement; Network; Network intrusion detection; Trace generation,Network intrusion detection systems (NIDS); Network simulators; Protocol layers; Trace generation; Computer software; Computer system firewalls; Mathematical models; Network protocols; Packet networks; Routers; Servers; Telecommunication traffic; Computer networks
"Hu S.-Y., Liao G.-M.",2,Scalable peer-to-peer networked virtual environment,2004,56,"Dept. of Computer Science and Information Engineering, Tamkang University, Tamsui, Taipei County 251, Taiwan; Institute of Physics, Academia Sinica, Taipei 11529, Taiwan",Tamkang University,1,Taiwan,1,14,12,"We propose a fully-distributed peer-to-peer architecture to solve the scalability problem of Networked Virtual Environment in a simple and efficient manner. Our method exploits locality of user interest inherent to such systems and is based on the mathematical construct Voronoi diagram. Scalable, responsive, fault-tolerant NVE can thus be constructed and deployed in an affordable way. Copyright 2004 ACM.",interest management; massively multiplayer (MMP); networked virtual environment (NVE); peer-to-peer (P2P); scalability; Voronoi diagram,Interest managements; Massively multiplayer; Networked virtual environments; Peer to peer; peer-to-peer (P2P); Voronoi diagrams; Computational geometry; Fault tolerant computer systems; Scalability; Virtual reality; Distributed computer systems
"Gunnar A., Johansson M., Telkamp T.",3,Traffic matrix estimation on a large IP backbone - A comparison on real data,2004,123,"Swed. Institute of Computer Science, P.O. Box 1263, SE-164 29 Kista, Sweden; Department of Signals, KTH, SE-100 44 Stockholm, Sweden; Global Crossing, Ltd., Croeselaan 148, NL-3521 CG Utrecht, Netherlands",Swedish Institute of Computer Science,1,Netherlands;Sweden,2,27,22,"This paper considers the problem of estimating the point-to-point traffic matrix in an operational IP backbone. Contrary to previous studies, that have used a partial traffic matrix or demands estimated from aggregated Netflow traces, we use a unique data set of complete traffic matrices from a global IP network measured over five-minute intervals. This allows us to do an accurate data analysis on the time-scale of typical link-load measurements and enables us to make a balanced evaluation of different traffic matrix estimation techniques. We describe the data collection infrastructure, present spatial and temporal demand distributions, investigate the stability of fan-out factors, and analyze the mean-variance relationships between demands. We perform a critical evaluation of existing and novel methods for traffic matrix estimation, including recursive fanout estimation, worst-case bounds, regularized estimation techniques, and methods that rely on mean-variance relationships. We discuss the weaknesses and strengths of the various methods, and highlight differences in the results for the European and American subnetworks. Copyright 2004 ACM.",MPLS; Optimization; SNMP; Traffic matrix estimation,Computer simulation; Data reduction; Linear programming; Mathematical models; Matrix algebra; Maximum likelihood estimation; Monte Carlo methods; Network protocols; Optimization; Routers; Set theory; Telecommunication links; MPLS; Simple network management protocol (SNMP); Traffic flow; Traffic matrix estimation; Telecommunication traffic
"Maltz D.A., Zhan J., Xie G., Zhang H., Hj‡lmt_sson G., Greenberg A., Rexford J.",7,Structure preserving anonymization of router configuration data,2004,8,"Carnegie Mellon University, United States; AT and T Labs-Research, United States; Reykjav’k University, Iceland",AT and T Labs;Carnegie Mellon University;Reykjav’k University,3,Iceland;USA,2,8,6,"A repository of router configuration files from production networks would provide the research community with a treasure trove of data about network topologies, routing designs, and security policies. However, configuration files have been largely unobtainable precisely because they provide detailed information that could be exploited by competitors and attackers. This paper describes a method for anonymizing router configuration files by removing all information that connects the data to the identity of the originating network, while still preserving the structure of information that makes the data valuable to networking researchers. Anonymizing configuration files has unusual requirements, including preserving relationships between elements of data, anonymizing regular expressions, and robustly coping with more than 200 versions of the configuration language, that mean conventional tools and techniques are poorly suited to the problem. Our anonymization method has been validated with a major carrier, earning unprivileged researchers access to the configuration files of more than 7600 routers in 31 networks. Through example analysis, we demonstrate that the anonymized data retains the key properties of the network design. We believe that applying our single-blind methodology to a large number of production networks from different sources would be of tremendous value to both the research and operations communities. Copyright 2004 ACM.",Data anonymization; Router configuration; Security,Autonomous system number (ASN); Data anonymization; Router configuration; Security policies; Computer networks; Computer operating systems; Network protocols; Program compilers; Security of data; Topology; Routers
"Willinger W., Alderson D., Li L.",3,A pragmatic approach to dealing with high-variability in network measurements,2004,38,"AT and T Labs Research, United States; California Institute of Technology, United States",AT and T Labs;California Institute of Technology,2,USA,1,46,36,"The Internet is teeming with high variability phenomena, from measured IP flow sizes to aspects of inferred router-level connectivity, but there still exists considerable debate about how best to deal with this encountered high variability and model it. While one popular approach favors modeling highly variable event sizes with conventional, finite variance distributions such as lognormal or Weibull distributions, Mandelbrot has argued for the last 40 years that there are compelling mathematical, statistical, and practical reasons for why infinite variance distributions are natural candidates for capturing the essence behind high variability phenomena. In this paper, we elaborate on Mandelbrot's arguments and present a methodology that often allows for a clear distinction between the two approaches. In particular, by requiring the resulting models to be resilient to ambiguities (i.e., robust to real-world deficiencies in the underlying network measurements) and internally self-consistent (i.e., insensitive with respect the duration, location, or time of the data collection), we provide a rigorous framework for a qualitative assessment of the observed high variability. We apply the proposed framework to assess previously reported findings about measured Internet traffic and inferred router- and AS-level connectivity. In the process, we also discuss what our approach has to say about recent discussions concerning network traffic being Poisson or self-similar and router-level or AS-level connectivity graphs of the Internet being scale-free or not. Copyright 2004 ACM.",Borrowing strength; Heavy-tailed distributions; High variability; Lognormal distributions; Model consistency; Model robustness; Pareto distributions; Power-laws; Scaling distributions; Sequential moment plots,Borrowing strength; Heavy-tailed distributions; High variability; Lognormal distributions; Model consistency; Model robustness; Pareto distributions; Power-laws; Scaling distributions; Sequential moment plots; Database systems; Mathematical models; Network protocols; Pareto principle; Probability; Robustness (control systems); Routers; Telecommunication traffic; Internet
"Klemm A., Lindemann C., Vernon M.K., Waldhorst O.P.",4,Characterizing the query behavior in peer-to-peer file sharing systems,2004,93,"University of Dortmund, Department of Computer Science, August-Schmidt-Strasse 12, 44227 Dortmund, Germany; University of Wisconsin - Madison, Department of Computer Sciences, 1210 West Dayton Street, Madison, WI 53706, United States",University of Dortmund;;University of Wisconsin-Madison,3,Germany;USA,2,22,17,"This paper characterizes the query behavior of peers in a peer-to-peer (P2P) file sharing system. In contrast to previous work, which provides various aggregate workload statistics, we characterize peer behavior in a form that can be used for constructing representative synthetic workloads for evaluating new P2P system designs. In particular, the analysis exposes heterogeneous behavior that occurs on different days, in different geographical regions (i.e., Asia, Europe, and North America) or during different periods of the day. The workload measures include the fraction of connected sessions that are passive (i.e., issue no queries), the duration of such sessions, and for each active session, the number of queries issued, time until first query, query interarrival time, time after last query, and distribution of query popularity. Moreover, the key correlations in these workload measures are captured in the form of conditional distributions, such that the correlations can be accurately reproduced in a synthetic workload. The characterization is based on trace data gathered in the Gnutella P2P system over a period of 40 days. To characterize system-independent user behavior, we eliminate queries that are specific to the Gnutella system software, such as re-queries that are automatically issued by some client implementations to improve system responsiveness. Copyright 2004 ACM.",Overlay networks; Peer-to-peer; Synthetic workloads; Workload characterization,Algorithms; Bandwidth; Client server computer systems; Computer software; Database systems; Distributed computer systems; File organization; Query languages; Systems analysis; Telecommunication networks; Overlay networks; Peer-to-peer; Synthetic workloads; Workload characterization; Network protocols
"Pang J., Akella A., Shaikh A., Krishnamurthy B., Seshan S.",5,On the responsiveness of DNS-based network control,2004,46,"Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213-3891, United States; Network Software and Services, IBM T.J. Watson Research Center, Hawthorne, NY 10532-2134, United States; AT and T Labs - Research, Florham Park, NJ 07932-0971, United States",AT and T Labs;Carnegie Mellon University;IBM,3,USA,1,15,13,"For the last few years, large Web content providers interested in improving their scalability and availability have increasingly turned to three techniques: mirroring, content distribution, and ISP multi-homing. The Domain Name System (DNS) has gained a prominent role in the way each of these techniques directs client requests to achieve the goals of scalability and availability. The DNS is thought to offer the transparent and agile control necessary to react quickly to ISP link failures or phenomenon such as flash crowds. In this paper, we investigate this assumption with the objective of quantifying the degree of responsiveness that can be expected from DNS. We use a combination of Web and DNS access measurements from several busy Web sites, as well as a large content distribution network, to characterize the behavior of end-systems and local DNS servers in terms of their adherence to DNS-based controls. Our results suggest that DNS is at best a coarse-grained mechanism, and poorly suited for applications, such as route control, which require quick response to link failures or performance degradations. We then propose several proactive techniques that, when deployed in cooperation between large content providers and important clients, have the potential to improve the responsiveness of DNS-based control. Copyright 2004 ACM.",DNS; Network control; Time-to-live,Content distribution network (CDN); Domain name system (DNS) servers; Network control; Time-to-live; Bandwidth; Cache memory; Client server computer systems; Computer systems; Control systems; Database systems; Distributed computer systems; Internet; Websites; Servers
"Tsang Y., Yildiz M., Barford P., Nowak R.",4,Network radar: Tomography from round trip time measurements,2004,41,"ECE Dept., Rice University, University of Wisconsin, Madison, United States; ECE Dept., University of Wisconsin, Madison, United States; CS Dept., University of Wisconsin, Madison, United States",Rice University;;University of Wisconsin-Madison,3,USA,1,18,17,"Knowledge of link specific traffic characteristics is important in the operation and design of wide area networks. Network tomography is a powerful method for measuring characteristics such as delay and loss on network-internal links using end-to-end active probes. Prior work has established the basic mechanisms for the use of tomographic inference techniques in the networking context. However, the measurement methods described in prior network tomography studies require cooperation between sending and receiving end-hosts, which limits the scope of the paths over which the measurements can be made. In this paper, we describe a new network tomographic technique based on round trip time (RTT) measurements which eliminates the need for special-purpose cooperation from receivers. Our technique uses RTT measurements from TCP SYN and SYN-ACK segments to estimate the delay variance of the shared network segment in the standard one sender - two receivers configuration. We call this approach Network Radar since it is analogous to standard radar. We present an analytic evaluation of Network Radar that specifies the variance bounds within which the technique is effective. We also evaluate Network Radar in a series of tests conducted in a controlled laboratory environment using live end hosts and IP routers. These tests demonstrate the boundaries of effectiveness of the RTT-based approach. Copyright 2004 ACM.",Delay Measurement; Loss Measurement; Network measurement and monitoring; Network Tomography; Performance,Delay measurement; Loss measurement; Network measurement and monitoring; Network tomography; Computer simulation; Internet; Network protocols; Packet networks; Performance; Radar; Routers; Telecommunication links; Tomography; Wide area networks
"Veitch D., Babu S., Pˆsztor A.",3,Robust synchronization of software clocks across the internet,2004,78,"ARC Spec. Res. Ctr. Ultra B.I.N., Dept. of Electrical Engineering, University of Melbourne, Australia; Indian Institute of Technology, New Delhi, India; Ericsson Hungary R and D, Budapest, Hungary",Ericsson Research;IIT Madras;University of Melbourne,3,Australia;Hungary;India,3,13,9,"Accurate, reliable timestamping which is also convenient and inexpensive is needed in many important areas including real-time network applications and network measurement. Recently the TSC register, which counts CPU cycles in popular PC architectures, was proposed as the basis of a new software clock which in terms of rate performance performs as well as more expensive GPS alternatives. Smooth and precise clock rate is essential to measure time differences accurately. We show how to define a TSC based clock which is also accurate with respect to absolute time. The clock is calibrated by processing, in a novel way, timestamps contained in the usual flow of Network Time Protocol (NTP) packets between a NTP server and the existing software clock, and TSC timestamps made independently on the host side. Using real measurements over 4 months, validated with a GPS synchronized hardware timing solution, the algorithm measured absolute time with a median error of only 30 microseconds when using a nearby stratum-1 NTP server. Results for two other servers are given. We also provide new algorithms for the robust determination of clock rate. We exploit the reliability of the available hardware to design synchronization algorithms which are inherently robust to many factors including packet loss, server outages, route changes, temperature environment, and network congestion. Copyright 2004 ACM.",GPS; Network measurement; NTP; Round-trip time; Software clock; Synchronization; Timing,Algorithms; Computer software; Congestion control (communication); Global positioning system; Network protocols; Packet networks; Real time systems; Servers; Synchronization; Tomography; Network measurement; Network time protocol (NTP); Round-trip time (RTT); Software clock; Timing; Internet
"Shaikh A., Sahu S., Rosu M., Shea M., Saha D.",5,Implementation of a service platform for online games,2004,30,"Network Software and Services, IBM T.J. Watson Research Center, Hawthorne, NY 10532, United States",IBM,1,USA,1,12,9,"Large-scale multiplayer online games require considerable investment in hosting infrastructures. However, the difficulty of predicting the success of a new title makes investing in dedicated server and network resources very risky. A shared infrastructure based on utility computing models to support multiple games offers an attractive option for game providers whose core competency is not in managing large server deployments.In this paper we describe a prototype implementation of a shared, on demand service platform for online games. The platform builds on open standards and off-the-shelf software developed to support utility computing offerings for Web-based business applications. We describe our early experience with identifying appropriate performance metrics for provisioning game servers and with implementing the platform components that we consider essential for its acceptance. Copyright 2004 ACM.",game hosting; on demand computing; online games,Core competencies; Dedicated servers; Game hosting; Game servers; Multi-player online games; Network resource; On-demand computing; On-demand services; On-line games; Open Standards; Performance metrics; Prototype implementations; Service platforms; Shared infrastructure; Support utility; Utility computing; Web-based business; Distributed computer systems; Investments; Servers; Software prototyping; Strategic planning; Online systems
"Kompella R.R., Singh S., Varghese G.",3,On scalable attack detection in the network,2004,51,"University of California, San Diego, 9500 Gilman Drive, San Diego, CA 92093, United States",University of California San Diego,1,USA,1,50,34,"Current intrusion detection and prevention systems seek to detect a wide class of network intrusions (e.g., DoS attacks, worms, port scans) at network vantage points. Unfortunately, all the IDS systems we know of keep per-connection or per-flow state. Thus it is hardly surprising that IDS systems (other than signature detection mechanisms) have not scaled to multi-gigabit speeds. By contrast, note that both router lookups and fair queuing have scaled to high speeds using aggregation via prefix lookups or DiffServ. Thus in this paper, we initiate research into the question as to whether one can detect attacks without keeping per-flow state. We will show that such aggregation, while making fast implementations possible, immediately cause two problems. First, aggregation can cause behavioral aliasing where, for example, good behaviors can aggregate to look like bad behaviors. Second, aggregated schemes are susceptible to spoofing by which the intruder sends attacks that have appropriate aggregate behavior. We examine a wide variety of DoS attacks and show that several categories (bandwidth based, claim-and-hold, host scanning) can be scalably detected. By contrast, it appears that stealthy port-scanning cannot be scalably detected without keeping per-flow state. Copyright 2004 ACM.",Denial of Service; Scalability; Security,Denial of service (DoS); Partial completion filters (PCF); Scalability; Spoofing; Algorithms; Computer software; Computer system firewalls; Network protocols; Routers; Security of data; Static random access storage; Telecommunication networks
"Akkawi A., Schaller S., Wellnitz O., Wolf L.",4,A mobile gaming platform for the IMS,2004,14,"IBR, TU Braunschweig, MŸhlenpfordtstra§e 23, 38106 Braunschweig, Germany; NEC Europe Ltd., KurfŸrstenanlage 36, 69115 Heidelberg, Germany",TU Braunschweig,1,Germany,1,29,3,"Mobile devices offer the opportunity to play games nearly everywhere. Moreover, networked games allow individual players to interact with other people and to participate in a larger gaming world, which also provides for new business opportunities. Hence, we currently see an increased interest from game developers, providers and players in mobile games. In this paper we propose a novel architecture and platform for games on the IMS. This allows games to utilize the features and capabilities that are inherent to the IMS. At the same time existing games can be flexibly adapted to this new type of network and have the possibility to reserve network resources for game data transmission, thus improving the experience of players. Copyright 2004 ACM.",IMS; mobile networked games; platform architecture,Business opportunities; Data transmission; Mobile games; Mobile gaming; Mobile networked games; Network resource; Networked games; Novel architecture; Platform architecture; Mobile devices; Wireless networks
"Jung J., Sit E.",2,An empirical study of spam traffic and the use of DNS black lists,2004,108,"MIT Comp. Sci./Artif. Intell. Lab., 32 Vassar Street, Cambridge, MA 02139, United States",MIT,1,USA,1,16,16,"This paper presents quantitative data about SMTP traffic to MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) based on packet traces taken in December 2000 and February 2004. These traces show that the volume of email has increased by 866% between 2000 and 2004. Local mail hosts utilizing black lists generated over 470,000 DNS lookups, which accounts for 14% of all DNS lookups that were observed on the border gateway of CSAIL on a given day in 2004. In comparison, DNS black list lookups accounted for merely 0.4% of lookups in December 2000. The distribution of the number of connections per remote spam source is Zipf-like in 2004, but not so in 2000. This suggests that black lists may be ineffective at fully stemming the tide of spam. We examined seven popular black lists and found that 80% of spam sources we identified are listed in some DNS black list. Some DNS black lists appear to be well-correlated with others, which should be considered when estimating the likelihood that a host is a spam source. Copyright 2004 ACM.",DNS black lists; Spam traffic; Zipf-like distribution,Approximation theory; Database systems; Electronic mail; Internet; Network protocols; Probability; Telecommunication traffic; Domain name system (DNS) black lists; Spam sources; Spam traffic; Zipf-like distribution; Spamming
"Singh A., Acharya A.",2,Using session initiation protocol to build context-aware VoIP support for multiplayer networked games,2004,12,"Georgia Insitute of Technology, Atlanta, GA, United States; IBM T.J.Watson Research Center, Hawthorne, NY, United States",IBM,1,USA,1,19,18,"Multiplayer networked games are the trend of the day. Receiving a major boost from various commercial ventures like Microsoft Xbox¨[19] and Sony Playstation¨[13], the networked gaming industry is set to grow dramatically. These multiplayer games allow geographically dispersed and possibly distant players to participate in a single game. In order to provide interaction amongst players in such environments, text messaging and recently, real-time voice interaction through VoIP is used. However, such interactions are mostly out-of-band (not based on game contexts), user-initiated and limited in operability, failing to exploit the entire potential and functionality of VoIP.In this paper, we present mechanisms and design of a prototype that allows game-context based VoIP communication between players. Thus, in addition to allowing players to talk to each other to coordinate teammates and activities (through a static team-based audio conference) as in some of the current systems, it supports communication among players based on shared contexts like the same physical location or room within the gaming environment. We use the Session Initiation Protocol (SIP) [14] to realize VoIP and describe mechanisms for building network gaming services using SIP. We also propose a sophisticated gaming scenario, in which VoIP is used to relay information about another player's distance and location with respect to the recipient, e.g. players farther away sound farther away. Copyright 2004 ACM.",context-aware; gaming; SIP; VoIP,Audio conferences; Commercial venture; Context-Aware; Context-aware VoIP; Context-based; Current system; MicroSoft; Multiplayer games; Multiplayers; Network gaming; Networked games; Out-of-band; Physical locations; PlayStation; Real-time voice; Relay information; Session initiation protocol; Session Initiation Protocols; Shared context; Text messaging; Audio systems; Internet protocols; Machine design; Voice/data communication systems; Internet telephony
"Armitage G., Stewart L.",2,Some thoughts on emulating jitter for user experience trials,2004,6,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, VIC, Australia",Swinburne University of Technology,1,Australia,1,13,13,"It is usually hard to control the network conditions affecting public online game servers when studying the impact of latency, loss and jitter on user experience. This leads to a natural desire for running user-experience trials under controlled network conditions, and hence a requirement for accurate (or at least predictable) emulation of IP level latency, loss and jitter on a localized network testbed. In this short paper we reflect on some experiences with running user-experience trials, and specifically evaluate the utility and limitations of using FreeBSD's kernel-resident dummynet module to introduce controlled jitter. We expect these insights will stimulate further user-experience trials built around low-cost, unix-based networking tools. Copyright 2004 ACM.",games; internet; jitter; latency; online,Dummynet; FreeBSD; games; Network condition; Network testbeds; Networking tools; Online game servers; User experience; Internet; Internet protocols; Jitter
"Brik V., Stroik J., Banerjee S.",3,Debugging DHCP performance,2004,13,"Department of Computer Sciences, University of Wisconsin, Madison, WI 53706, United States",University of Wisconsin-Madison,1,USA,1,7,6,"Dynamic Host Configuration Protocol (DHCP) was defined to facilitate automatic configuration of IP addresses and other network parameters to hosts in a network. Efficiency of DHCP's address management is especially important today in part due to proliferation of mobile devices with transient network access patterns and the consequent increased demand on transient IP addresses in open-access networks. Unfortunately, DHCP's flexible design makes it susceptible to a variety of misconfigurations. The focus of this work is, therefore, to evaluate the performance and vulnerabilities of DHCP in operational networks today. To this end, we developed a tool called DHCP-Watch that facilitates DHCP-related network debugging and enables better capacity planning. We used this tool to perform a first-of-its-kind detailed measurement study of DHCP performance in operational university campus networks. Our measurements revealed various trends of IP address usage. Additionally, we discovered frequent anomalous operations due to network misconfigurations and presence of misbehaving hosts. Copyright 2004 ACM.",DHCP; Experimentation; Measurement; Performance; Tools,Automation; Gateways (computer networks); Internet; Optimization; Performance; Servers; Telecommunication traffic; Dynamic host configuration protocol (DHCP); Measurement study; Network debugging; Subnet masks; Network protocols
Riley G.F.,1,The Georgia Tech Network Simulator,2003,54,"Georgia Institute of Technology, Sch. of Elec./Computer Engineering, Atlanta, GA 30332-0250, United States",Georgia Tech,1,USA,1,18,16,"We introduce a new network simulation environment, developed by our research group, called the Georgia Tech Network Simulator (GTNetS). Our simulator is designed specifically to allow much larger-scale simulations than can easily be created by existing network simulation tools. The design of the simulator very closely matches the design of real network protocol stacks and hardware. Thus, anyone with a good understanding of networking in general can easily understand how the simulations are constructed. Further, our simulator is implemented completely in object-oriented C++, which leads to easy extension by users to experiment with new or modified behavior of existing simulation models. Our tool is designed from the beginning with scalability in mind, including the support for distributed simulations on a network of workstations as part of the basic design. We give an overview of the features of GTNetS, and present some preliminary scalability results we have obtained by running GTNetS on a computing cluster at the Pittsburgh Supercomputer Center.",Distributed Simulation; Large-Scale Simulations; Network Simulation,Distributed simulation; Large-scale simulations; Network simulation; Computer aided software engineering; Computer simulation; Electric network topology; Network protocols; Packet networks; Systems analysis; Wireless telecommunication systems; Computer networks
"McAuley D., Neugebauer R.",2,A case for Virtual Channel Processors,2003,10,"Intel Research Cambridge, 15 JJ Thomson Av, Cambridge, United Kingdom",Intel,1,UK,1,38,34,"Modern desktop and server computer systems use multiple processors: general purpose CPU(s), graphic processor (GPU), network processors (NP) on Network Interface Cards (NICs), RAID controllers, and signal processors on sound cards and modems. Some of these processors traditionally have been special purpose processors but there is a trend towards replacing some of these with embedded general purpose processors. At the same time main CPUs become more powerful; desktop CPUs start featuring Simultaneous Multi-Threading (SMT); and Symmetric Multi-Processing (SMP) systems are widely used in server systems. However, the structure of operating systems has not really changed to reflect these trends - different types of processors evolve at different timescales (largely driven by market forces) requiring significant changes to operating systems kernels to reflect the appropriate tradeoffs. In this position paper we propose to re-vitalise the old idea of channel processors by encapsulating operating system I/O subsystems in Virtual Channel Processors (VCPs). VCPs perform I/O operations on behalf of an OS. They provide similar development, performance, and fault isolation as dedicated (embedded) I/O processors do while offering the flexibility to split functionality between the main processor(s) and dedicated processors without affecting the rest of the OS. If part of a VCP is executed on the main processor, we propose to make use of virtual machine technology and SMT/SMP features to isolate its performance from that of the rest of the system and to protect the system from faults within the VCP.",I/O virtualisation; Protocol offloading; Virtual Channel Processors,Computer operating systems; Interfaces (computer); Modems; Network protocols; Servers; Software engineering; Symmetric multi-processing (SMP); Virtual channel processors; Program processors
"Feamster N., Balakrishnan H.",2,Towards a Logic for Wide-Area Internet Routing,2003,9,"MIT Laboratory for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States",MIT,1,USA,1,40,32,"Interdomain routing is a massive distributed computing task that propagates topological information for global reachability. Today's interdomain routing protocol, BGP4, is exceedingly complex because the wide variety of goals that it must meet - including fast convergence, failure resilience, scalability, policy expression, and global reachability - are accomplished by mechanisms that have complicated interactions and unintended side effects. The complexity of wide-area routing configuration and protocol dynamics requires mechanisms for expressing wide-area routing that adhere to a set of logical rules. We propose a set of rules, called the routing logic, which can be used to determine whether a routing protocol satisfies various properties. We demonstrate how this logic can aid in analyzing the behavior of BGP4 under various configurations. We also speculate on how the logic can be used to analyze existing configuration in real-world networks, synthesize network-wide router configuration from a high-level policy language, and assist protocol designers in reasoning about new routing protocols.",Design; Performance; Reliability,Global connectivity; Information flow control; Routing logic; Wide-area internet routing; Algorithms; Computational complexity; Congestion control (communication); Electric network topology; Formal logic; Network protocols; Problem solving; Routers; Internet
"Shivam P., Chase J.S.",2,On the Elusive Benefits of Protocol Offload,2003,34,"Department of Computer Science, Duke University, Durham, NC 27708, United States",Duke University,1,USA,1,13,8,"Periodic order-of-magnitude jumps in Ethernet bandwidth regularly reawaken interest in TCP/IP transport protocol offload. This time the jump to 10-Gigabit Ethernet coincides with the emergence of new network storage protocols (iSCSI and DAFS), and vendors are combining these with offload NICs to position IP as a competitor to FibreChannel and other SAN interconnects. But what benefits will offload show for application performance? Several recent studies have presented conflicting data to argue that offload either does or does not benefit applications. But the evidence from empirical studies is often little better than anecdotal. The principles that determine the results are not widely understood, except for the first principle: Your Mileage May Vary. This paper outlines fundamental performance properties of transport offload and other techniques for low-overhead I/O in terms of four key ratios that capture the CPU-intensity of the application and the relative speeds of the host, NIC device, and network path. The study also reflects the role of offload as an enabler for direct data placement, which eliminates some communication overheads rather than merely shifting them to the NIC. The analysis applies to Internet services, streaming data, and other scenarios in which end-to-end throughput is limited by network bandwidth or processing overhead rather than latency.",High-speed networking; IP; Network performance; Network storage; Protocol offload; RDMA; TCP,Bandwidth; Communication; Computer operating systems; Data reduction; Interconnection networks; Internet; Network performance; Protocol offload; RDMA; Network protocols
"Beck M., Moore T., Plank J.S.",3,An End-to-End Approach to Globally Scalable Programmable Networking,2003,26,"Logistical Comp./Internetworking L., Computer Science Department, University of Tennessee, United States",University of Tennessee,1,USA,1,22,18,"The three fundamental resources underlying Information Technology are bandwidth, storage, and computation. The goal of wide area infrastructure is to provision these resources to enable applications within a community. The end-to-end principles provide a scalable approach to the architecture of the shared services on which these applications depend. As a prime example, IP and the Internet resulted from the application of these principles to bandwidth resources. A similar application to storage resources produced the Internet Backplane Protocol and Logistical Networking, which implements a scalable approach to wide area network storage. In this paper, we discuss the use of this paradigm for the design of a scalable service for wide area computation, or programmable networking. While it has usually been assumed that providing computational services in the network will violate the end-to-end principles, we show that this assumption does not hold. We illustrate the point by describing Logistical Network Computing, an extension to Logistical Networking that supports limited computation at intermediate nodes.",Active networking; Asynchronous communications; Distributed state management; End-to-end design; Internet Backplane Protocol; Logistical Network Computing; Network storage; Programmable networking; Scalability; Store and forward network,Active networking; Asynchronous communications; Distributed state management; End-to-end design; Internet blackplane protocol; Logistical network computing; Network storage; Programmable networking; Scalability; Store and forward network; Algorithms; Bandwidth; Computer architecture; Computer programming; Distributed computer systems; Internet; Network protocols; Reduced instruction set computing; Semantics; Computer networks
"Chadalapaka M., Shah H., Elzur U., Thaler P., Ko M.",5,A Study of iSCSI Extensions for RDMA (iSER),2003,18,"Hewlett-Packard Company, United States; Intel Corporation; Broadcom; Agilent Technologies; IBM",Agilent Technologies;IBM,2,USA,1,13,8,"The iSCSI protocol is the IETF standard that maps the SCSI family of application protocols onto TCP/IP enabling convergence of storage traffic on to standard TCP/IP fabrics. The ability to efficiently transfer and place the data on TCP/IP networks is crucial for this convergence of the storage traffic. The iWARP protocol suite provides Remote Direct Memory Access (RDMA) semantics over TCP/IP networks and enables efficient memory-to-memory data transfers over an IP fabric. This paper studies the design process of iSCSI Extensions for RDMA (iSER), a protocol that maps the iSCSI protocol over the iWARP protocol suite. As part of this study, this paper shows how iSER enables efficient data movement for iSCSI using generic RDMA hardware and then presents a discussion of the iWARP architectural features that were conceived during the iSER design. These features potentially enable highly efficient realizations of other I/O protocols as well.",DA; Datamover; DDP; DI; ISCSI; ISER; iWARP; MPA; RDMA; RDMAP; SCSI; Verbs,Datamover; DDP; Remote direct memory access (RDMA); SCSI; Client server computer systems; Data transfer; Mapping; Network protocols; Semantics; Computer networks
"Fineberg S.A., Wilson D.",2,Performance Measurements of a User-Space DAFS Server with a Database Workload,2003,0,"NonStop Labs, Hewlett-Packard Company, M/S 4402, 19333 Vallco Parkway, Cupertino, CA 95014, United States",HP Labs,1,USA,1,19,19,"We evaluate the performance of a user-space Direct Access File System (DAFS) server and Oracle Disk Manager (ODM) client using two synthetic test codes as well as the Oracle database. Tests were run on 4-processor Intel Xeon-based systems running Windows 2000. The systems were connected with ServerNet II, a Virtual Interface Architecture (VIA) compliant system area network. We compare the performance of DAFS/ODM and local-disk based I/O, measuring I/O bandwidth and latency. We also compare the runtime and CPU utilization of the Oracle database running the TPC-H benchmark over DAFS/ODM and local disk.",DAFS; Database; File Systems; I/O; Networks; Performance Evaluation; RDMA,File systems; Performance evaluation; RDMA; Computer networks; Computer operating systems; Database systems; Interfaces (computer); Network protocols; Servers
Davie B.,1,Deployment Experience with Differentiated Services,2003,15,"Cisco Systems, Inc., 1414 Massachusetts Ave., Boxborough, MA 01719, United States",Cisco,1,USA,1,15,9,"While ubiquitous QoS mechanisms are not yet deployed widely across the public Internet, the Differentiated Services (diffserv) architecture has in fact proven itself to be a good match for the technical needs of many service providers. In this paper we consider the state of deployment of QoS mechanisms in large service provider IP networks (many of which happen to be offering VPN or VoIP services rather than public Internet service.) We discuss the factors that have helped and hindered the deployment of QoS mechanisms in general and diffserv in particular. We conclude that many if not most of the barriers to QoS deployment are business issues rather than technical shortcomings of the existing QoS architectures.",Differentiated Services; Quality of Service,Computer simulation; Mathematical models; Network protocols; Personnel training; Problem solving; Public policy; Quality of service; Differentiated services; Weighted random early detection (WRED); Internet
"Hall J., Moore A., Pratt I., Leslie I.",4,Multi-Protocol Visualization: A Tool Demonstration,2003,3,"University of Cambridge, Computer Laboratory, JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,12,9,"This paper describes a system for the visualization of multiple protocols. The visualizer makes possible the identification of both intra and inter-protocol behaviour. This tool has become a critical resource in the development of our multi-protocol monitoring system; allowing the verification of the monitoring system, identification of new modes of behaviour and the easy visualization of potentially overwhelming quantities of information1.",HTTP; Multi -protocol analysis; Multi-protocol visualization; Network event visualization; Network monitoring; TCP,Computer aided software engineering; Computer networks; Data acquisition; Feedback; HTML; HTTP; Information retrieval; Visualization; Web browsers; Multi-protocol visualization; Network event visualization; Network monitoring; TCP; Network protocols
"Burgstahler L., Dolzer K., Hauser C., JŠhnert J., Junghans S., Maci‡n C., Payer W.",7,Beyond Technology: The Missing Pieces for QoS Success,2003,24,"Inst. of Commun. Netwk./Comp. Eng., University of Stuttgart, Pfaffenwaldring 47, 70569 Stuttgart, Germany; T-Systems GEI GmbH, Germany; RUS, University of Stuttgart, Allmandring 30, 70569 Stuttgart, Germany",T-Systems GEI GmbH;University of Stuttgart,2,Germany,1,21,21,"Years of research on QoS architectures for IP networks have delivered sophisticated proposals, which have nevertheless not found broad commercial use. The reasons are not lack of technical soundness or insurmountable technological complexity, but insufficient attention to other, non-QoS-specific matters. First among them is the lack of a commercialization model for the Internet together with the necessary accounting and charging architecture. Another crucial issue is the assurance of end-to-end QoS coherence in the face of multiple intervening parties (network and content providers, users). Furthermore, the practical requirements imposed by those parties to any successful QoS architecture have not been fully taken into account: Ease of management, simplicity and measurable guarantees are some of the main ones. In this paper, the overall constraints on and conditions for the successful deployment of QoS in IP networks are analyzed and some possible directions explored.",Internetworking; Next Generation Internet; QoS,Computational complexity; Computer simulation; Human computer interaction; Internet; Mathematical models; Network protocols; Optimization; Performance; Human factors; Internetworking; Quality of service
"Salamatian K., Fdida S.",2,A framework for interpreting measurement over Internet,2003,2,"LIP6, Univ. Pierre et Marie Curie, Paris, France",University Pierre and Marie Curie,1,France,1,26,25,"This paper introduces a methodology for interpreting measurement obtained over Internet. The paper is motivated by the fact that a large number of published papers in empirical networking analysis follow a generic framework that might be formalized and generalized to a large class of problem. The objective of this paper is to present an interpretation framework and to illustrate it by examples coming from the networking literature. The aim of the paper is rather to give to the researcher who is confronted to measurements coming from a network some guidelines on how to formalize the way to address interpretation of observations. The paper is based on the remark that interpretation is essentially a matter of relating observed effects to hidden causes. This problem might be formalized in its most general setting as an inverse statistical inference problem. The paper illustrates this inverse statistical problem in the context of two well-referred problems: interpretation of active measurement and network tomography. It shows that even if at first glance these two problems are different, the solution framework is the same. We will also give description about how to solve that inverse statistical inference problem by the EM method or the Bayesian framework. The framework provided in this paper is a powerful solution to address the complex problem of interpreting measurement over Internet and network modelling.",Internet; Interpretation; Measurement; Modelling,Computerized tomography; Functions; Mathematical models; Network protocols; Parameter estimation; Problem solving; Quality of service; Simulators; Interpretation; Network modeling; Internet
Sollins K.R.,1,Designing for Scale and Differentiation,2003,7,"MIT Laboratory for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States",MIT,1,USA,1,40,33,"Na•ve pictures of the Internet frequently portray a small collection of hosts or LAN's connected by a ""cloud"" of connectivity. The truth is more complex. The IP-level structure of the Internet is composed from a large number of constituent networks, each of which differs in some or all of transmission technologies, routing protocols, administrative models, security policies, QoS capabilities, pricing mechanisms, and similar attributes. On top of this, a whole new structure of application-layer overlays and content distribution networks, equally diverse in the sorts of ways mentioned above, is rapidly evolving. Virtually any horizontal slice through the current Internet structure reveals a loosely coupled federation of separately defined, operated, and managed entities, interconnected to varying degrees, and often differing drastically in internal requirements and implementation. Intuitively, it is natural to think of each of these entities as existing in a region of the network, with each region having coherent internal technology and policies, and each region managing its interactions with other regions of the net according to some defined set of rules and policies. In this paper, we propose that a key design element in an architecture for extremely large scale, wide distribution and heterogeneous networks is a grouping and partitioning mechanism we call the region. Furthermore we postulate that such a mechanism can provide increased functionality and management of existing unresolved problems in current networks. The paper both describes a proposed definition of the region concept and explores the utility of such a mechanism through a series of examples. We claim that there is significant added benefit to generalizing the idea of the region.",Extensibility; Heterogeneity; Network Architecture; Scalability,Algorithms; Automation; Computer architecture; Local area networks; Network protocols; Optimization; Problem solving; Quality of service; Routers; Topology; Extensibility; Heterogeneity; Network architecture; Scalability; Computer networks
Recio R.J.,1,"Server I/O Networks Past, Present, and Future",2003,16,"IBM eServer I/O, IBM Systems Group, Austin, TX, United States",IBM,1,USA,1,38,23,"Enterprise and technical customers place a diverse set of requirements on server I/O networks. In the past, no single network type has been able to satisfy all of these requirements. As a result several fabric types evolved and several interconnects emerged to satisfy a subset of the requirements. Recently several technologies have emerged that enable a single interconnect to be used as more than one fabric type. This paper will describe the requirements customers place on server I/O networks; the various fabric types and interconnects that have been used to satisfy those requirements; the technologies that are enabling network convergence; and how these new technologies are being deployed on various network families.",10 GigE; And TOE; Cluster; Cluster Networks; Gigabit Ethernet; I/O Expansion Network; InfiniBand; IOEN; iONIC; iSCSI; iSER; LAN; PCI; PCI Express; RDMA; RNIC; SAN; Socket Extensions,Data redundancy; Packet routing; Bandwidth; Packet networks; Routers; Servers; Telecommunication links; Telecommunication traffic; Telecommunication networks
"Burnside M., Keromytis A.D.",2,High-Speed I/O: The Operating System as a Signalling Mechanism,2003,5,"Computer Science Department, Columbia University, United States",Columbia University,1,USA,1,68,60,"The design of modern operating systems is based around the concept of memory as a cache for data that flows between applications, storage, and I/O devices. With the increasing disparity between I/O bandwidth and CPU performance, this architecture exposes the processor and memory subsystems as the bottlenecks to system performance. Furthermore, this design does not easily lend itself to exploitation of new capabilities in peripheral devices, such as programmable network cards or special-purpose hardware accelerators, capable of card-to-card data transfers. We propose a new operating system architecture that removes the memory and CPU from the data path. The role of the operating system becomes that of data-flow management, while applications operate purely at the signaling level. This design parallels the evolution of modern network routers, and has the potential to enable high-performance I/O for end-systems, as well as fully exploit recent trends in programmability of peripheral (I/O) devices.",Architecture; Data Streaming; Operating Systems,Data streaming; Progammable networks; Bandwidth; Buffer storage; Computer hardware; Data transfer; Routers; World Wide Web; Computer operating systems
"Clark D., Braden R., Falk A., Pingali V.",4,FARA: Reorganizing the Addressing Architecture,2003,60,"MIT Laboratory for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States; USC, Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292, United States",MIT;University of Southern California,2,USA,1,15,11,"sloppy This paper describes PARA, a new organization of network architecture concepts. FARA (Forwarding directive, Association, and Rendezvous Architecture) defines an abstract model with considerable generality and flexibility, based upon the decoupling of end-system names from network addresses. The paper explores the implications of FARA and the range of architecture instantiations that may be derived from FARA. As an illustration, the paper outlines a particular derived architecture, M-FARA, which features support for generalized mobility and multiple realms of network addressing.",Architecture; Association; Instantiation; Mobility; Model; Modularity; Network; Rendezvous; Security,Association; Instantiation; Mobility; Model; Modularity; Network architecture; Rendezvous; Security; Computer architecture; Cryptography; Mathematical models; Network protocols; Packet networks; Security systems; Computer networks
Bell G.,1,Failure to Thrive: QoS and the Culture of Operational Networking,2003,18,"Ernest Orlando Lawrence B.N.L., Bldg. 50E0101, One Cyclotron Road, Berkeley, CA 94720, United States","Ernest Orlando Lawrence,USA",1,USA,1,21,8,"Understanding the culture of operational networking can help to illuminate the question of why QoS has floundered. Network administrators have a well-founded aversion to complexity, in part because they experience failures attributable to design complexity on a regular basis. I argue that IP multicast defines a functional limit-case for deployable complexity in today's Internet. That limit is relevant to the deployment of QoS, since many flavors of QoS entail equal or greater complexity. The notion of a functional constraint on complexity draws attention to the economic, historical, and institutional forces which influence the fate of networking technologies. QoS will not be compelling for most network administrators until its design takes account of these forces.",Complexity; Multicast; Operational networking; QoS,Human factors; Operational networking; Computational complexity; Computer simulation; Internet; Mathematical models; Quality of service; Reliability; Switching; Topology; Network protocols
Yang X.,1,NIRA: A New Internet Routing Architecture,2003,23,"MIT LCS, United States",MIT,1,USA,1,44,31,"This paper presents the design of a new Internet routing architecture (NIRA). In today's Internet, users can pick their own ISPs, but once the packets have entered the network, the users have no control over the overall routes their packets take. NIRA aims at providing end users the ability to choose the sequence of Internet service providers a packet traverses. User choice fosters competition, which imposes an economic discipline on the market, and fosters innovation and the introduction of new services. This paper explores various technical problems that would have to be solved to give users the ability to choose: how a user discovers routes and whether the dynamic conditions of the routes satisfy his requirements, how to efficiently represent routes, and how to properly compensate providers if a user chooses to use them. In particular, NIRA utilizes a hierarchical provider-rooted addressing scheme so that a common type of domain-level route can be efficiently represented by a pair of addresses. In NIRA, each user keeps track of the topology information on domains that provide transit service for him. A source retrieves the topology information of the destination on demand and combines this information with his own to discover end-to-end routes. This route discovery process ensures that each user does not need to know the complete topology of the Internet.",Design; Economics,Internet service providers (ISP); New internet routing architecture (NIRA); Algorithms; Broadband networks; Electric network topology; Packet networks; Problem solving; Quality of service; Robustness (control systems); Routers; Telecommunication traffic; Internet
"Clark D.D., Sollins K., Wroclawski J., Faber T.",4,Addressing Reality: An Architectural Response to Real-World Demands on the Evolving Internet,2003,16,"MIT LCS, United States",MIT,1,USA,1,29,17,"A system as complex as the Internet can only be designed effectively if it is based on a core set of design principles, or tenets, that identify points in the architecture where there must be common understanding and agreement. The tenets of the original Internet architecture arose as a response to the technical, governmental, and societal environment of internetworking's earliest days, but have remained central to the Internet as it has evolved. In light of the increasing integration of the Internet into the social, economic, and political aspects of our lives, it is worth revisiting the underlying tenets of what is becoming a central element of the world's infrastructure. This paper examines three key tenets that we believe should guide the evolution of the Internet in its next generation and beyond. They are: design for change, controlled transparency, and the centrality of the tussle space. Our purpose is not to present these ideas as new, but rather to propose that they should be elevated to central tenets of the evolving architecture of the Internet, and explore the ramifications of doing so. The paper first examines the tenets somewhat abstractly, and then in more detail by studying their relation to several design choices needed for a complete architecture. We conclude with a discussion of the relationship between the network architecture and the applications it serves.",Application support; Architectural principles; Architecture design; Design for change; Security; Transparency; Tussle,Application support; Architecture principles; Tussle; Bandwidth; Computer architecture; Computer networks; Packet networks; Public policy; Internet
"Akella A., Seshan S., Shaikh A.",3,An empirical evaluation of wide-area Internet bottlenecks,2003,97,"Carnegie Mellon University, Pittsburgh, PA 15213, United States; IBM T.J. Watson Research Center, Hawthorne, NY 15213, United States",Carnegie Mellon University;IBM,2,USA,1,37,32,"Conventional wisdom has been that the performance limitations in the current Internet lie at the edges of the network - i.e last mile connectivity to users, or access links of stub ASes. As these links are upgraded, however, it is important to consider where new bottlenecks and hot-spots are likely to arise. In this paper, we address this question through an investigation of non-access bottlenecks. These are links within carrier ISPs or between neighboring carriers that could potentially constrain the bandwidth available to long-lived TCP flows. Through an extensive measurement study, we discover, classify, and characterize bottleneck links (primarily in the U.S.) in terms of their location, latency, and available capacity. We find that about 50% of the Internet paths explored have a non-access bottleneck with available capacity less than 50 Mbps, many of which limit the performance of well-connected nodes on the Internet today. Surprisingly, the bottlenecks identified are roughly equally split between intra-ISP links and peering links between ISPs. Also, we find that low-latency links, both intra-ISP and peering, have a significant likelihood of constraining available band-width. Finally, we discuss the implications of our findings on related issues such as choosing an access provider and optimizing routes through the network. We believe that these results could be valuable in guiding the design of future network services, such as overlay routing, in terms of which links or paths to avoid (and how to avoid them) in order to improve performance. Copyright 2003 ACM.",Measurement; Performance,Internet service providers (ISP); Traffic sources; Transfer control protocols (TCP); Wide-area internet bottlenecks; Algorithms; Bandwidth; Characterization; Congestion control (communication); Network protocols; Optimization; Wide area networks; Internet
"Roughan M., Thorup M., Zhang Y.",3,Traffic engineering with estimated traffic matrices,2003,91,"AT and T Labs - Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,28,23,"Traffic engineering and traffic matrix estimation are often treated as separate fields, even though one of the major applications for a traffic matrix is traffic engineering. In cases where a traffic matrix cannot be measured directly, it may still be estimated from indirect data (such as link measurements), but these estimates contain errors. Yet little thought has been given to the effects of inexact traffic estimates on traffic engineering. In this paper we consider how well traffic engineering works with estimated traffic matrices in the context of a specific task; namely that of optimizing network routing to minimize congestion, measured by maximum link-utilization. Our basic question is: how well is the real traffic routed if the routing is only optimized for an estimated traffic matrix? We compare against optimal routing of the real traffic using data derived from an operational tier-1 ISP. We find that the magnitude of errors in the traffic matrix estimate is not, in itself, a good indicator of the performance of that estimate in route optimization. Likewise, the optimal algorithm for traffic engineering given knowledge of the real traffic matrix is no longer the best with only the estimated traffic matrix as input. Our main practical finding is that the combination of a known traffic matrix estimation technique and a known traffic engineering technique can get close to the optimum in avoiding congestion for the real traffic. We even demonstrate stability in the sense that routing optimized on data from one day continued to perform well on subsequent days. This stability is crucial for the practical relevance to off-line traffic engineering, as it can be performed by ISPs today. Copyright 2003 ACM.",MPLS; OSPF; SNMP; Traffic Engineering; Traffic Matrix Estimation,MPLS; OSPF; SNMP; Traffic engineering; Traffic matrix estimation; Computer networks; Congestion control (communication); Data acquisition; Internet; Matrix algebra; Network protocols; Optimization; Real time systems; Routers; Telecommunication traffic
"Aikat J., Kaur J., Smith F.D., Jeffay K.",4,Variability in TCP round-trip times,2003,100,"Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599-3175, United States",University of North Carolina at Chapel Hill,1,USA,1,8,6,"We measured and analyzed the variability in round trip times (RTTs) within TCP connections using passive measurement techniques. We collected eight hours of bidirectional traces containing over 22 million TCP connections between end-points at a large university campus and almost 1 million remote locations. Of these, we used over 1 million TCP connections that yield 10 or more valid RTT samples, to examine RTT variability within a TCP connection. Our results indicate that contrary to observations in several previous studies, RTT values within a connection vary widely. Our results have implications for designing better simulation models, and understanding how round trip times affect the dynamic behavior and throughput of TCP connections. Copyright 2003 ACM.",TCP Round-trip Times,Internet flows; Round-trip times; TCP; Traffic engineering; Approximation theory; Database systems; Internet; Packet networks; Packet switching; Telecommunication links; Telecommunication traffic; Network protocols
"Hohn N., Veitch D.",2,Inverting sampled traffic,2003,123,"Department of Electrical and Electronic Engineering, Special Research Center for Ultra-Broadband Information Networks, University of Melbourne, Vic. 3010, Australia",University of Melbourne,1,Australia,1,36,21,"Routers have the ability to output statistics about packets and flows of packets that traverse them. Since however the generation of detailed traffic statistics does not scale well with link speed, increasingly routers and measurement boxes implement sampling strategies at the packet level, In this paper we study both theoretically and practically what information about the original traffic can be inferred when sampling, or 'thinning', is performed at the packet level. While basic packet level characteristics such as first order statistics can be fairly directly recovered, other aspects require more attention. We focus mainly on the spectral density, a second order statistic, and the distribution of the number of packets per flow, showing how both can be exactly recovered, in theory. We then show in detail why in practice this cannot be done using the traditional packet based sampling, even for high sampling rate. We introduce an alternative flow based thinning, where practical inversion is possible even at arbitrarily low sampling rate. We also investigate the theory and practice of fitting the parameters of a Poisson cluster process, modelling the full packet traffic, from sampled data. Copyright 2003 ACM.",Internet data; Long range dependence; Poisson cluster process; Sampling; TCP flows; Thinning; Traffic modeling; Transform inversion,Computational complexity; Computer networks; Data acquisition; Internet; Network protocols; Packet networks; Poisson distribution; Sampling; Internet data; Long range dependence; Poisson cluster process; TCP flows; Thinning; Traffic modeling; Transform inversion; Telecommunication traffic
"Sridharan A., Moon S.B., Diot C.",3,On the correlation between route dynamics and routing loops,2003,11,"University of Pennsylvania, Philadelphia, PA, United States; KAIST, South Korea; Intel Research, Cambridge, United Kingdom",Intel;KAIST;University of Pennsylvania,3,South Korea;UK;USA,3,11,8,"Routing loops are caused by inconsistencies in the routing state of the network. Although undesirable from this aspect, they can provide insight into the routing dynamics that caused them. In this work we present a methodology that utilizes a priori knowledge of loops to study the correlation between routing loops and routing events that could have caused them. We apply our technique to associate route changes with packet loops detected in actual traffic traces collected from the Sprint Backbone. Our study shows that a strong correlation exists between loops and changes in the BGP routing state while the link state protocols ISIS is seldom responsible for such events. Our analysis also identifies factors that influence the distribution of loop path lengths as well as the effectiveness of our detection techniques. Copyright 2003 ACM.",IP Networks; Measurement; Routing,IP networks; Network paths; Routing; Routing protocols; Computational methods; Internet; Measurements; Network protocols; Packet networks; Packet switching; Telecommunication traffic; Routers
"Jiang H., Dovrolis C.",2,Source-level IP packet bursts: Causes and effects,2003,37,"College of Computing, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,16,15,"By source-level IP packet burst, we mean several IP packets sent back-to-back from the source of a flow. We first identify several causes of source-level bursts, including TCP's slow start, idle restart, window advancement after loss recovery, and segmentation of application messages into multiple UDP packets. We then show that the presence of packet bursts in individual flows can have a major impact on aggregate traffic. In particular, such bursts create scaling in a range of timescales which corresponds to the burst duration. Uniform ""spreading"" of bursts in the time axis reduces the scaling exponent in short timescales (up to 100-200ms) to almost zero, meaning that the aggregate traffic becomes practically uncorrelated in that range. This result provides a plausible explanation for the scaling behavior of Internet traffic in short timescales. We also show that removing packet bursts from individual flows reduces significantly the tail of the aggregate marginal distribution, and it improves queueing performance, especially in moderate utilizations (50-85%). Copyright 2003 ACM.",Capacity estimation; Correlation structure; Network traffic; Packet dispersion; Packet trains; Scaling; TCP,Capacity estimation; Correlation structure; Network traffic; Packet dispersion; Packet trains; Scaling; TCP; Channel capacity; Data communication systems; Internet; Network protocols; Packet switching; Routers; Telecommunication traffic; Wide area networks; Packet networks
"Strauss J., Katabi D., Kaashoek F.",3,A measurement study of available bandwidth estimation tools,2003,416,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,23,17,"Available bandwidth estimation is useful for route selection in overlay networks, QoS verification, and traffic engineering. Recent years have seen a surge in interest in available bandwidth estimation. A few tools have been proposed and evaluated in simulation and over a limited number of Internet paths, but there is still great uncertainty in the performance of these tools over the Internet at large. This paper introduces Spruce, a simple, light-weight tool for measuring available bandwidth, and compares it with two existing tools, IGI and Pathload, over 400 different Internet paths. The comparison focuses on accuracy, failure patterns, probe overhead, and implementation issues. The paper verifies the measured available bandwidth by comparing it to Multi-Router Traffic Grapher (MRTG) data and by measuring how each tool responds to induced changes in available bandwidth. The measurements show that Spruce is more accurate than Pathload and IGI. Pathload tends to overestimate the available bandwidth whereas IGI becomes insensitive when the bottleneck utilization is large. Copyright 2003 ACM.",Available bandwidth,Available bandwidth (ABW); Cumulative distribution function (CDF); Experimentation; Multi-Router Traffic Grapher (MRTG) data; Probe gap model (PGM); Computer simulation; Internet; Mathematical models; Measurements; Packet networks; Performance; Quality of service; Routers; Telecommunication traffic; Bandwidth
"Chen Y., Bindel D., Katz R.H.",3,Tomography-based overlay network monitoring,2003,40,"Computer Science Division, University of California at Berkeley, Berkeley, CA 94720-1776, United States",University of California Berkeley,1,USA,1,27,25,"Overlay network monitoring enables distributed Internet applications to detect and recover from path outages and periods of degraded performance within seconds. For an overlay network with n end hosts, existing systems either require O(n2) measurements, and thus lack scalability, or can only estimate the latency but not congestion or failures. Unlike other network tomography systems, we characterize end-to-end losses (this extends to any additive metrics, including latency) rather than individual link losses. We find a minimal basis set of k linearly independent paths that can fully describe all the O(n2) paths. We selectively monitor and measure the loss rates of these paths, then apply them to estimate the loss rates of all other paths. By extensively studying synthetic and real topologies, we find that for reasonably large n (e.g., 100), k is only in the range of O(n log n). This is explained by the moderately hierarchical nature of Internet routing. Our scheme only assumes the knowledge of underlying IP topology, and any link can become lossy or return to normal. In addition, our technique is tolerant to topology measurement inaccuracies, and is adaptive to topology changes. Copyright 2003 ACM.",Network measurement and monitoring; Network tomography; Numerical linear algebra; Overlay networks,Computer simulation; Congestion control (communication); Internet; Linear algebra; Matrix algebra; Numerical analysis; Routers; Signal filtering and prediction; Tomography; Network measurement and monitoring; Network tomography; Numerical linear algebra; Overlay networks; Telecommunication networks
"Kumar A., Xu J., Li L., Wang J.",4,Space-code bloom filter for efficient traffic flow measurement,2003,43,"College of Computing, Georgia Institute of Technology, United States; Bell Labs Lucent; AT and T Labs - Research, United States",AT and T Labs;Bell Labs;Georgia Tech,3,USA,1,12,10,"Per-flow traffic measurement is critical for usage accounting, traffic engineering, and anomaly detection. Previous methodologies are either based on random sampling (e.g., Cisco's NetFlow), which is inaccurate, or only account for the ""elephants"". Our paper introduces a novel technique for measuring per-flow traffic approximately, for all flows regardless of their sizes, at very high-speed (say, OC192+). The core of this technique is a novel data structure called Space Code Bloom Filter (SCBF). A SCBF is an approximate representation of a multiset; each element in this multiset is a traffic flow and its multiplicity is the number of packets in the flow. SCBF employs a Maximum Likelihood Estimation (MLE) method to measure the multiplicity of an element in the multiset. Through parameter tuning, SCBF allows for graceful tradeoff between measurement accuracy and computational and storage complexity. SCBF also contributes to the foundation of data streaming by introducing a new paradigm called blind streaming. We evaluated the performance of SCBF on packet traces gathered from a tier-1 ISP backbone and through mathematical analysis. Our preliminary results demonstrate that SCBF achieves reasonable measurement accuracy with very low storage and computational complexity. Copyright 2003 ACM.",Bloom Filter; Data Structures; Network Measurement; Statistical Inference; Traffic Analysis,Bloom filters; Network measurements; Statistical inference; Traffic analysis; Approximation theory; Computer networks; Data structures; Dynamic random access storage; Functions; Statistical methods; Telecommunication traffic
"Mao Z.M., Bush R., Griffin T.G., Roughan M.",4,BGP Beacons,2003,46,"University of California, Berkeley, United States; Internet Initiative Japan, Japan; Intel Research; ATandT Labs-Research, United States",AT and T Labs;Intel;University of California Berkeley,3,Japan;USA,2,19,14,"The desire to better understand global BGP dynamics has motivated several studies using active measurement techniques, which inject announcements and withdrawals of prefixes from the global routing domain. From these one can measure quantities such as the BGP convergence time. Previously, the route injection infrastructure of such experiments has either been temporary in nature, or its use has been restricted to the experimenters. The routing research community would benefit from a permanent and public infrastructure for such active probes. We use the term BGP Beacon to refer to a publicly documented prefix having global visibility and a published schedule for announcements and withdrawals. A BGP Beacon is to be used for the ongoing study of BGP dynamics, and so should be supported with a long-term commitment. We describe several BGP Beacons that have been set up at various points in the Internet. We then describe techniques for processing BGP updates when a BGP Beacon is observed from a BGP monitoring point such as Oregon's Route Views. Finally, we illustrate the use of BGP Beacons in the analysis of convergence delays, route flap damping, and update inter-arrival times. Copyright 2003 ACM.",Border Gateway Protocol; Convergence time; Network measurements,Border Gateway Protocols (BGP); Convergence time; Global routing domain; Network measurements; Computer simulation; Computer software; Damping; Dynamics; Gateways (computer networks); Internet; Mathematical models; Robustness (control systems); Signal processing; Network protocols
"Wei W., Wang B., Towsley D., Kurose J.",4,Model-based identification of dominant congested links,2003,13,"Department of Computer Science, University of Massachusetts, Amherst, MA 01003, United States",University of Massachusetts Amherst,1,USA,1,26,23,"In this paper, we propose a. model-based approach that uses periodic end-end probes to identify whether a ""dominant congested link"" exists along an end-end path. Informally, a dominant congested link refers to a link that incurs the most losses and significant queuing delays along the path. We begin by providing a formal yet intuitive definition of dominant congested link and present two simple hypothesis tests to identify whether such a link exists. We then present and examine several novel model-based approaches for identifying a dominant congested link that are based on interpreting probe loss as an unobserved (virtual) delay. We develop parameter inference algorithms for Hidden Markov Model (HMM) and Markov model with a hidden dimension to infer this virtual delay. Our validation using ns simulation and live Internet experiments demonstrate that this approach can correctly identify a dominant congested link with only a small amount of probe data. We further estimate the maximum queuing delay of the dominant congested link, once we identify that a dominant congested link exists. Copyright 2003 ACM.","Bottleneck Link; Dominant Congested Link; End-end Inference, Model-based Identification; Path Characteristic",Bottleneck link; Dominant congested link; End-frame inference; Model-based identification; Path characteristic; Algorithms; Congestion control (communication); Identification (control systems); Internet; Markov processes; Mathematical models; Telecommunication links
"Jin G., Tierney B.L.",2,System capability effects on algorithms for network bandwidth measurement,2003,51,"Distributed Systems Department, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, CA 94720, United States","Lawrence Berkeley National Laboratory,USA",1,USA,1,26,17,"A large number of tools that attempt to estimate network capacity and available bandwidth use algorithms that are based on measuring packet inter-arrival time. However in recent years network bandwidth has become faster than system input/output (I/O) bandwidth. This means that it is getting harder and harder to estimate capacity and available bandwidth using these techniques. This paper examines the current bandwidth measurement and estimation algorithms, and presents an analysis of how these algorithms might work in a high-speed network environment. This paper also discusses the system resource (hardware and software) issues that affect each of these algorithms, especially running on generic platforms built from off-the-shelf components. Copyright 2003 ACM.",Algorithm; Bandwidth; Design; Estimation; Measure; Network; Performance; System Capability,Input/output (I/O) bandwidth; Measure; Simple network management protocols (SNMP); System capability; Algorithms; Bandwidth; Computer aided software engineering; Computer hardware; Computer software; Estimation; Input output programs; Internet; Logic design; Packet networks; Performance; Computer networks
"Papagiannaki K., Cruz R., Diot C.",3,Network performance monitoring at small time scales,2003,35,"Sprint ATL, Burlingame, CA, United States; Electrical and Computer Engineering Department, University of California, San Diego, CA, United States; Intel Research, Cambridge, United Kingdom",Intel;University of California San Diego,2,UK;USA,2,5,4,"SNMP statistics are usually collected over intervals of 5 minutes and correspond to average activity of IP links and network elements for the duration of the interval. Nevertheless, reports of traffic performance across periods of minutes can mask out performance degradation due to short-lived events, such as micro-congestion episodes, that manifest themselves at smaller time scales. In this paper we perform a measurement study of packet traces collected inside the Sprint IP network to identify the time scales over which micro-congestion episodes occur. We characterize these episodes with respect to their amplitude, frequency and duration. We define a new performance metric that could be easily computed by a router and reported every 5 minutes through SNMP to shed light into the micro-behavior of the carried traffic. We show that the proposed performance metric is well suited to track the time scales over which micro-congestion episodes occur, and may be useful for a variety of network provisioning tasks. Copyright 2003 ACM.",Congestion Detection; Internet measurement; Performance Monitoring,Congestion detection; Internet measurement; Management information base (MIB); Performance monitoring; Congestion control (communication); Internet; Management information systems; Packet networks; Packet switching; Performance; Routers; Network protocols
"Lim H., Hou J.C., Choi C.-H.",3,Constructing Internet coordinate system based on delay measurement,2003,80,"School of Electrical Engineering and Computer Science, Seoul National University, Seoul 151-744, South Korea; Department of Computer Science, University of Illinois at Urbana-Champaign, 1304 W. Springfield Avenue, Urbana, IL 61801, United States; Department of Computer Science, University of Illinois, Urbana Champaign, United States",Seoul National University;UIUC,2,South Korea;USA,2,18,12,"In this paper, we consider the problem of how to represent the locations of Internet hosts in a Cartesian coordinate system to facilitate estimate of the network distance between two arbitrary Internet hosts. We envision an infrastructure that consists of beacon nodes and provides the service of estimating network distance between two hosts without direct delay measurement. We show that the principal component analysis (PCA) technique can effectively extract topological information from delay measurements between beacon hosts. Based on PCA, we devise a transformation method that projects the distance data space into a new coordinate system of (much) smaller dimensions. The transformation retains as much topological information as possible and yet enables end hosts to easily determine their locations in the coordinate system. The resulting new coordinate system is termed as the Internet Coordinate System (ICS). As compared to existing work (e.g., IDMaps [1] and GNP [2]), ICS incurs smaller computation overhead in calculating the coordinates of hosts and smaller measurement overhead (required for end hosts to measure their distances to beacon hosts). Finally, we show via experimentation with real-life data sets that ICS is robust and accurate, regardless of the number of beacon nodes (as long as it exceeds certain threshold) and the complexity of network topology. Copyright 2003 ACM.",Coordinate system; Internet distance service; Principal component analysis,Coordinate system; Internet distance service; Internet topology; Peer-to-peer computing; Bandwidth; Computational complexity; Electric network topology; Principal component analysis; Robustness (control systems); Routers; Internet
"Golab L., DeHaan D., Demaine E.D., L—pez-Ortiz A., Munro J.I.",5,Identifying frequent items in sliding windows over on-line packet streams,2003,87,"School of Comp. Sci., University of Waterloo, Canada; Lab. for Comp. Sci., M.I.T., United States",University of Waterloo,1,Canada;USA,2,16,16,"Internet traffic patterns are believed to obey the power law, implying that most of the bandwidth is consumed by a small set of heavy users. Hence, queries that return a list of frequently occurring items are important in the analysis of real-time Internet packet streams. While several results exist for computing frequent item queries using limited memory in the infinite stream model, in this paper we consider the limited-memory sliding window model. This model maintains the last N items that have arrived at any given time and forbids the storage of the entire window in memory, We present a deterministic algorithm for identifying frequent items in sliding windows denned over real-time packet streams. The algorithm uses limited memory, requires constant processing time per packet (amortized), makes only one pass over the data, and is shown to work well when tested on TCP traffic logs. Copyright 2003 ACM.",Frequent item queries; Internet traffic monitoring; On-line stream analysis; Sliding windows,Frequent item queries; Internet traffic monitoring; On-line stream analysis; Sliding windows; Algorithms; Bandwidth; Mathematical models; Network protocols; Online systems; Quality of service; Query languages; Real time systems; Packet networks
"Tang L., Crovella M.",2,Virtual landmarks for the Internet,2003,186,"Department of Computer Science, Boston University, United States",Boston University,1,USA,1,29,18,"Internet coordinate schemes have been proposed as a method for estimating minimum round trip time between hosts without direct measurement. In such a scheme, each host is assigned a set of coordinates, and Euclidean distance is used to form the desired estimate. Two key questions are: How accurate are coordinate schemes across the Internet as a whole? And: are coordinate as-signment schemes fast enough, and scalable enough, for large scale use? In this paper we make contributions toward answering both those questions. Whereas the coordinate assignment problem has in the past been approached by nonlinear optimization, we develop a faster method based on dimensionality reduction of the Lipschitz embedding. We show that this method is reasonably accurate, even when applied to measurements spanning the Internet, and that it naturally leads to a scalable measurement strategy based on the notion of virtual landmarks. Copyright 2003 ACM.",Network Coordinates; Network Distance; Principal Component Analysis,Dimensionality reduction; Euclidean distance approximates; Network coordinates; Network distance; Embedded systems; Nonlinear systems; Optimization; Principal component analysis; Set theory; Vectors; Internet
"Horton J.D., L—pez-Ortiz A.",2,On the number of distributed measurement points for network tomography,2003,59,"Faculty of Computer Science, University of New Brunswick, Fredericton, NB E3B 5A3, Canada; School of Computer Science, University of Waterloo, Waterloo, Ont. N2L 3G1, Canada",University of New Brunswick;University of Waterloo,2,Canada,1,38,35,Internet topology information is only made available in aggregate form by standard routing protocols. Connectivity information and latency characteristics must therefore be inferred using indirect techniques. In this paper we consider measurements using a distributed set of measurement points or beacons. We show that computing the minimum number of required beacons on a network under a BGP-like routing policy is NP-hard and at best ½(log n)-approximable. In the worst case at least (n - 1)/3 and at most (n + 1)/3 beacons are required for a network with n nodes. We then introduce some observations that allow us to propose a relatively small candidate set of beacons for the current Internet topology. The set proposed has properties with relevant applications for all-paths routing on the public Internet and performance based routing. Copyright 2003 ACM.,Approximation algorithms; Internet tomography; Network measurements; NP-hard; Resilient overlay networks; Topology discovery,Algorithms; Approximation theory; Computational complexity; Network protocols; Routers; Tomography; Approximation algorithms; Internet tomography; Network measurements; NP-hard; Resilient overlay networks; Topology discovery; Internet
"Estan C., Varghese G., Fisk M.",3,Bitmap algorithms for counting active flows on high speed links,2003,103,"Computer Science and Engineering Department, University of California San Diego, United States",University of California San Diego,1,USA,1,19,15,"This paper presents a family of bitmap algorithms that address the problem of counting the number of distinct header patterns (flows) seen on a high speed link. Such counting can be used to detect DoS attacks and port scans, and to solve measurement problems. Counting is especially hard when processing must be done within a packet arrival time (8 nsec at OC-768 speeds) and, hence, must require only a small number of accesses to limited, fast memory. A naive solution that maintains a hash table requires several Mbytes because the number of flows can be above a million, By contrast, our new probabilistic algorithms take very little memory and are fast. The reduction in memory is particularly important for applications that run multiple concurrent counting instances. For example, we replaced the port scan detection component of the popular intrusion detection system Snort with one of our new algorithms. This reduced memory usage on a ten minute trace from 50 Mbytes to 5.6 Mbytes while maintaining a 99.77% probability of alarming on a scan within 6 seconds of when the large-memory algorithm would. The best known prior algorithm (probabilistic counting) takes 4 times more memory on port scan detection and 8 times more on a measurement application. Fundamentally, this is because our algorithms can be customized to take advantage of special features of applications such as a large number of instances that have very small counts or prior knowledge of the likely range of the count. Copyright 2003 ACM.",Counting flows; Network traffic measurement,Counting flows; Denial of service (DoS); High speed links; Network traffic management; Algorithms; Congestion control (communication); Network protocols; Packet networks; Quality of service; Static random access storage; Telecommunication links
"Wang F., Gao L.",2,On inferring and characterizing internet routing policies,2003,77,"Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA 01002, United States",University of Massachusetts Amherst,1,USA,1,21,16,"Border Gateway Protocol allows Autonomous Systems (ASs) to apply diverse routing policies for selecting routes and for propagating reachability information to other ASs. Although a significant number of studies have been focused on the Internet topology, little is known about what routing policies network operators employ to configure their networks. In this paper, we infer and characterize routing policies employed in the Internet. We find that routes learned from customers are preferred over those from peers and providers, and those from peers are typically preferred over those from providers. We present an algorithm for inferring and characterizing export policies. We show that ASs announce their prefixes to a selected subset of providers. The main reasons behind the selective announcement are the traffic engineering strategy for controlling incoming traffic. The impact of these routing policies might be significant. For example, many Tier-1 ASs reach their (direct or indirect) customers via their peers instead of customers. Furthermore, the selective announcement routing policies imply that there are much less available paths in the Internet than shown in the AS connectivity graph. We hope that our findings will caution network operators in choosing the selective announcement routing policy for traffic engineering. Finally, we study export policies to peers and find that ASs tend to announce all of their prefixes to other peers. To the best of our knowledge, this is the first study on systematically understanding routing policies applied in the Internet. Copyright 2003 ACM.",BGP; Routing Policies; Traffic Engineering,Data communication systems; Gateways (computer networks); Network protocols; Routers; Telecommunication traffic; Topology; Autonomous systems (AS); Border Gateway Protocols (BGP); Network operators; Routing policies; Traffic engineering; Internet
"Biaz S., Vaidya N.H.",2,Is the round-trip time correlated with the number of packets in flight ?,2003,24,"Computer Science and Software Engineering, Auburn University, United States; Dept. of Electrical and Computer Engineering, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, United States",Auburn University;UIUC,2,USA,1,16,10,"TCP uses packet loss as a feedback from the network to adapt its sending rate. TCP keeps increasing its sending rate as long as no packet loss occurs (unless constrained by buffer size). Alternative congestion avoidance techniques (CATs) have been proposed to avoid such ""aggressive"" behavior. These CATs use simple statistics on observed round-trip times and/or throughput of a TCP connection in response to variations in congestion window size. These CATs have a supposed ability to detect queue build-up. The objective of this paper is to question the ability of these CATs to reliably detect queue build-up under real network conditions. For this purpose, the sample coefficient of correlation between round-trip time and the number of packets in flight is analyzed for 14,218 connections over 737 Internet paths. These coefficients of correlation were extracted from a set of tcpdump traces collected by Vern Paxson. The coefficients of correlation measured confirm that the correlation between RTT and window size is often weak. Copyright 2003 ACM.",Congestion predictors; Congestion window size; Correlation; Roundtrip time; TCP,Congestion predictors; Congestion window size; Roundtrip time; TCP; Air transportation; Bandwidth; Congestion control (communication); Correlation theory; Database systems; Packet networks; Packet switching; Network protocols
"Andersen D.G., Snoeren A.C., Balakrishnan H.",3,Best-path vs. multi-path overlay routing,2003,98,"MIT Laboratory for Computer Science, United States; University of California, San Diego, United States",MIT;University of California San Diego,2,USA,1,33,26,"Time-varying congestion on Internet paths and failures due to software, hardware, and configuration errors often disrupt packet delivery on the Internet. Many aproaches to avoiding these problems use multiple paths between two network locations. These approaches rely on a path-independence assumption in order to work well; i.e., they work best when the problems on different paths between two locations are uncorrelated in time. This paper examines the extent to which this assumption holds on the Internet by analyzing 14 days of data collected from 30 nodes in the RON testbed. We examine two problems that manifest themselves - congestion-triggered loss and path failures - and find that the chances of losing two packets between the same hosts is nearly as high when those packets are sent through an intermediate node (60%) as when they are sent back-to-back on the same path (70%). In so doing, we also compare two different ways of taking advantage of path redundancy proposed in the literature: mesh routing based on packet replication, and reactive routing based on adaptive path selection. Copyright 2003 ACM.",Measurement; Multi-Path Routing; Networking; Overlay Networks,Forward error correction (FEC); Multi-path routing; Networking; Overlay networks; Bandwidth; Computer hardware; Computer software; Congestion control (communication); Error analysis; Error correction; Network protocols; Packet networks; Probability; Telecommunication traffic; Internet
Duffield N.,1,Simple network performance tomography,2003,59,"AT and T Labs - Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,8,7,"In network performance tomography, characteristics of the network interior are inferred by correlating end-to-end measurements. In much previous work, the presence of correlations must be arranged at the packet level, e.g., using multicast probes or unicast emulations of them. This carries costs in deployment and limits coverage. However, it is difficult to determine performance characteristics without correlations. Some recent work has had success in reaching a lesser goal - identifying the lossiest network links -using only uncorrelated end-to-end measurements. In this paper we abstract the required properties of network performance, and show that they are independent of the particular inference algorithm used. This observation allows us to design a quick and simple inference algorithm that identifies the worst performing link in a badly performing subnetwork, with high likelihood when bad links are uncommon. We give several examples of perforance models and that exhibit the required properties. The performance of the algorithm is analyzed explicitly. Copyright 2003 ACM.",Correlation; Estimation; Inference; Networks; Performance,Linear programming; Maximum likelihood estimation; Multicasting; Network protocols; Probability; Routers; Telecommunication links; Telecommunication traffic; Tomography; Correlation; Inference; Multicast probes; Networks; Packet networks
"Teixeira R., Marzullo K., Savage S., Voelker G.M.",4,In search of path diversity in ISP networks,2003,90,"Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,16,14,"Internet Service Providers (ISPs) can exploit path diversity to balance load and improve robustness. Unfortunately, it is difficult to evaluate the potential impact of these approaches without routing and topological data, which are confidential. In this paper, we characterize path diversity in the real Sprint network. We then characterize path diversity in ISP topologies inferred using the Rocketfuel tool. Comparing the real Sprint topology to the one inferred by Rocketfuel, we find that the Rocketfuel topology has significantly higher apparent path diversity. We evaluate heuristics that improve the accuracy of the inferred Rocketfuel topologies. Finally, we discuss limitations of active measurements techniques to capture topological properties such as path diversity. Copyright 2003 ACM.",Internet topology; Path diversity,Internet service providers (ISP); Internet topology; Path diversity; Points of presence (POP); Network protocols; Packet networks; Packet switching; Parallel processing systems; Routers; Telecommunication services; Topology; Internet
"Coates M., Rabbat M., Nowak R.",3,Merging logical topologies using end-to-end measurements,2003,27,"Department of E.G.E., McGill University, Montreal, Que., Canada; Department of E.C.E., Rice University, Houston, TX, United States",McGill University;Rice University,2,Canada;USA,2,19,17,"Knowledge of network topology is useful for understanding the structure of the Internet, for developing and testing new protocols, and as prior information to network tomography algorithms. Building on existing techniques for inferring a single-source tree topology using end-to-end measurements, we address the problem of merging multiple tree topologies. We develop a multiple source active probing methodology and statistical framework for testing whether the paths from two sources to two receivers branch at a common internal node. This information can then be used to determine where portions of the tree topology from one source to a set of receivers overlap with the tree topology from a different source to the same set of receivers. The algorithm uses a novel random probing structure and easily made measurements of packet arrival order. As a result, we do not require precise time synchronization among the participating hosts. Successful experiments performed over a university LAN and over the Internet verify that our methodology is versatile and robust. Copyright 2003 ACM.",End-to-end measurement; Multiple-source network tomography; Network tomography; Packet arrival order; Topology discovery,End-to-end measurement; Multiple-source network tomography; Network tomography; Packet arrival order; Topology discovery; Algorithms; Formal logic; Internet; Local area networks; Packet networks; Synchronization; Electric network topology
"Wills C.E., Mikhailov M., Shang H.",3,Inferring relative popularity of internet applications by actively querying DNS caches,2003,16,"Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609, United States",100 Institute Road;Worcester Polytechnic Institute,2,USA,1,22,12,"In this work, we propose a novel methodology that can be used to assess the relative popularity for any Internet application based on the data servers it uses. The basic idea is to infer popularity of data servers by periodically ""poking"" at local Domain Name servers (LDNSs) that service Domain Name System requests from a set of users running Internet applications and determining if LDNSs have cached resource records for the data servers. This approach allows us to measure the relative percentage of pokes that result in a cache hit as a coarse measure of the relative popularity of a particular data server among the users of a given LDNS. In addition, the time-to-live (TTL) of cached DNS resource records can be used to measure the gaps in time when a resource record for a data server is not cached: The cache gaps can be used to infer request interarrivals for more popular data servers. The methodology can be applied to any Internet application that uses distinguished server names and performs DNS lookups on these names as part of application use. The methodology can be used to collect usage information from any LDNS that accepts DNS queries. As example applications of the methodology, we evaluate the relative popularity of selected Web sites and the relative popularity of different Web servers serving content at a given Web site. We also apply the methodology to servers providing multimedia content, data servers for grid computing, and network game servers. We use data gathered from LDNSs of commercial and educational sites as well as Internet Service Providers serving both commercial and home customers. © Copyright 2003 ACM.",Active Content Measurement; Domain Name System,Access control lists (ACL); Active content measurement; Domain name systems; Local Domain Name Servers (LDNS); Time-to-live (TTL); Buffer storage; Computer software; Multimedia systems; Servers; Web browsers; Websites; Internet
"Krishnamurthy B., Sen S., Zhang Y., Chen Y.",4,"Sketch-based change detection: Methods, evaluation, and applications",2003,304,"AT and T Labs-Research, 180 Park Avenue, Florham Park, NJ, United States; University of California, Berkeley, CA, United States",AT and T Labs;University of California Berkeley,2,USA,1,40,27,"Traffic anomalies such as failures and attacks are commonplace in today's network, and identifying them rapidly and accurately is critical for large network operators. The detection typically treats the traffic as a collection of flows that need to be examined for significant changes in traffic pattern (e.g., volume, number of connections). However, as link speeds and the number of flows increase, keeping per-flow state is either too expensive or too slow. We propose building compact summaries of the traffic data using the notion of sketches. We have designed a variant of the sketch data structure, k-ary sketch, which uses a constant, small amount of memory, and has constant per-record update and reconstruction cost. Its linearity property enables us to summarize traffic at various levels. We then implement a variety of time series forecast models (ARIMA, Holt-Winters, etc.) on top of such summaries and detect significant changes by looking for flows with large forecast errors. We also present heuristics for automatically configuring the model parameters. Using a large amount of real Internet traffic data from an operational tier-1 ISP, we demonstrate that our sketch-based change detection method is highly accurate, and can be implemented at low computation and memory costs. Our preliminary results are promising and hint at the possibility of using our method as a building block for network anomaly detection and traffic measurement. Copyright 2003 ACM.",Change Detection; Data Stream Computation; Forecasting; Network Anomaly Detection; Sketch; Time Series Analysis,Automation; Computer networks; Computer science; Cost effectiveness; Data flow analysis; Forecasting; Signal detection; Software engineering; Telecommunication traffic; Time series analysis; Change detection; Data stream computation; Network anomaly detection; Sketch; Telecommunication networks
Allman M.,1,On the performance of middleboxes,2003,15,"BBN Technologies, United States",BBN Technologies,1,USA,1,11,8,"This paper presents a preliminary performance analysis of a complex middlebox infrastructure in a real-world production environment that serves several thousand people. While prevalent, middleboxes (firewalls, NATs, etc.) have yet to be systematically measured. This paper makes two contributions: (i) we outline several methodologies and metrics by which to measure middleboxes and (ii) we offer preliminary application-layer measurements of one particular production middlebox system. We show that the middlebox infrastructure in question offers a mixed bag of performance implications (both positive and negative). In addition, we quantify several failure modes introduced by the middlebox infrastructure. Copyright 2003 ACM.",Firewalls; Middleboxes; TCP performance,Firewalls; Middleboxes; Port number; TCP performance; Computer architecture; Data communication systems; Internet; Network protocols; Packet networks; Packet switching; Real time systems; Computer system firewalls
"Dewes C., Wichmann A., Feldmann A.",3,An analysis of internet chat systems,2003,105,"UniversitŠt des Saarlandes, Germany; TU MŸnchen, Germany",TU Munich;UniversitŠt des Saarlandes,2,Germany,1,39,30,"In our quest to better understand network traffic dynamics, we examine Internet chat systems. Although chat as an application does not contribute huge amounts of traffic, chat systems are known to be habit-forming. This implies that catering to such users can be a promising way of attracting them, especially in low bandwidth environments such as wireless networks. Unfortunately there is no common protocol base for chat systems. Rather there are a multitude of protocol variants whose specifications, with some exceptions, such as IRC and ICQ, are unavailable or ill defined. In addition, chat systems are often layered on top of other application protocols like HTTP. Therefore there is no simple way of even identifying chat traffic. In this paper we show how to separate chat traffic from other Internet traffic and present the results of an extensive validation of our methodology. Using our methodology we gather a week long trace of all chat traffic that crosses a 155 Mbit/s link from the Saarland University to the Internet and present an initial characterization. Copyright 2003 ACM.",Chat; IRC; Network Measurements,AOL Instant Messenger (AIM); Internet Relay Chat (IRC); Network measurements; Short message service (SMS); Bandwidth; Computational complexity; Computer networks; Heuristic methods; Network protocols; Online conferencing; Open systems; Telecommunication traffic; Web browsers; Wireless telecommunication systems; Internet
"Cui J.-H., Faloutsos M., Maggiorini D., Gerla M., Boussetta K.",5,Measuring and modelling the group membership in the internet,2003,11,"Computer Science and Engineering Department, University of Connecticut, Storrs, CT 06029, United States; Computer Science Department, University of California, Los Angeles, CA 90095, United States; Computer Science and Engineering, University of California, Riverside, CA 92521, United States; Computer Science Department, University of Milan, via Comelico 39, I-20135, Milano, Italy",University of California Los Angeles;University of California Riverside;University of Connecticut;University of Milan,4,Italy;USA,2,34,27,"In this paper, we measure and model the distribution of multicast group members. Multicast research has traditionally been plagued by a lack of real data and an absence of a systematic simulation methodology. Although temporal group properties have received some attention, the location of group members has not been measured and modelled. However, the placement of members can have significant impact on the design and evaluation of multicast schemes and protocols as shown in previous studies. In our work, we identify properties of members that reflect their spatial clustering and the correlation among them (such as participation probability, and pairwise correlation). Then, we obtain values for these properties by monitoring the membership of network games and large audio-video broadcasts from IETF and NASA. Finally, we provide a comprehensive model that can generate realistic groups. We evaluate our model against the measured data with excellent results. A realistic group membership model can help us improve the effectiveness of simulations and guide the design of group-communication protocols. Copyright 2003 ACM.",Group Membership; Maximum Entropy; Member Clustering; Pairwise Correlation; Skewed Distribution,Group membership; Maximum entropy; Member clustering; Pairwise correlation; Skewed distributions; Algorithms; Computer simulation; Correlation methods; Data reduction; Entropy; Groupware; Mathematical models; Multicasting; Network protocols; Probability; Telecommunication networks; Internet
"Duffield N., Lund C.",2,Predicting resource usage and estimation accuracy in an IP flow measurement collection infrastructure,2003,53,"AT and T Labs - Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,21,12,"This paper describes a measurement infrastructure used to collect detailed IP traffic measurements from an IP backbone. Usage, i.e, bytes transmitted, is determined from raw NetFlow records generated by the backbone routers. The amount of raw data is immense. Two types of data sampling in order to manage data volumes: (i) (packet) sampled NetFlow in the routers; (ii) size-dependent sampling of NetFlow records. Furthermore, dropping of NetFlow records in transmission can be regarded as an uncontrolled form of sampling. We show how to manage the trade-off between estimation accuracy and data volume. Firstly, we describe the sampling error that arises from all three types of sampling when estimating usage per traffic class: how it can be predicted from models and raw data, and how it can be estimated directly from the sampled data itself. Secondly, we show how to determined the usage of resources - bandwidth, computational cycle, storage - within the components of the infrastructure. These two sets of methods allow dimensioning of the measurement infrastructure in order to meet accuracy goals for usage estimation. Copyright 2003 ACM.",Bandwidth; Estimation; Sampling; Variance,Bandwidth; Interfaces (computer); Network protocols; Optimization; Routers; Sampling; Telecommunication links; Estimation accuracy; Resource usage; Traffic analysis platform (TAP); Variance; Internet
"Lakshminarayanan K., Padmanabhan V.N.",2,Some findings on the network performance of broadband hosts,2003,48,"University of California, Berkeley, United States; Microsoft Research",Microsoft;University of California Berkeley,2,USA,1,14,12,"With the rapid growth in the popularity of and the research interest in peer-to-peer (P2P) systems, an interesting question is what the quality of network connectivity between peers in the ""real world"" is and what implications this has for applications. In this paper, we describe an effort called PeerMetric to directly measure P2P network performance from the vantage point of broadband-connected residential hosts. Our measurements indicate significant asymmetry in bandwidth, with median downstream and upstream available bandwidths of 900 Kbps and 212 Kbps, respectively. We argue that the availability of last-hop bandwidth is more important than the traditional consideration of locality for overlay multicast over broadband hosts. We also consider the peer selection problem and find that a simple delay-vector based approach is effective for finding proximate peers in terms of latency. However, P2P latency turns out to be a poor predictor of P2P TCP throughput, which may be the metric of interest for applications such as file sharing. Copyright 2003 ACM.",Broadband hosts; Network measurement,Broadband hosts; Content distributions; Network measurements; Peer-to-peer (P2P) systems; Bandwidth; Computer networks; Correlation methods; Heuristic methods; Network protocols; Packet networks; Performance; Personal computers; Servers; Broadband networks
"Lu G., Li X.",2,On the correspondency between TCP acknowledgment packet and data packet,2003,14,"Dept. of Electronic Engineering, Tsinghua University, 100084, China",Tsinghua University,1,China,1,19,16,"At the TCP sender side, the arrival of an ack packet always triggers the sender to send data packets, which establishes a correspondency between the arrived ack packet and the sent data packets. In a TCP connection, the correspondency between every ack packet and its corresponding data packets forms a sequence. This sequence characterizes the sender's behavior. In this paper, we propose a method to estimate this correspondency sequence from the dump trace measured at the receiver side. Because many possible correspondency sequences can be constructed based on the trace, the problem here is an estimation problem, which is to select a most possible one from those candidate sequences. The method proposed first eliminates some candidates that violate basic TCP congestion behavior. Then, it chooses the most possible one among the remaining sequences using the statistical characteristics of delays between the acks and their corresponding data packets under maximum-likelihood criterion. The method can work in the condition when the TCP connection experiences various network delay and loss, and it applies to TCP senders of different versions. Simulations and Internet experiments have been performed to validate the method. Copyright 2003 ACM.",Maximum-Likelihood Estimation; Non-deterministic Finite State Machine; TCP,Computer simulation; Congestion control (communication); Data acquisition; Internet; Maximum likelihood estimation; Network protocols; Queueing networks; Routers; Telecommunication traffic; Data packets; Network delay; Non-deterministic finite state machine; TCP; Packet networks
"Clark D., Braden R., Falk A., Pingali V.",4,FARA: Reorganizing the addressing architecture,2003,74,"MIT Laboratory for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States; USC/Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA 90292, United States",MIT;University of Southern California,2,USA,1,14,11,"Sloppy This paper describes FARA, a new organization of network architecture concepts. FARA (Forwarding directive, Association, and Rendezvous Architecture) defines an abstract model with considerable generality and flexibility, based upon the decoupling of end-system names from network addresses. The paper explores the implications of FARA and the range of architecture instantiations that may be derived from FARA. As an illustration, the paper outlines a particular derived architecture, M-FARA, which features support for generalized mobility and multiple realms of network addressing. Copyright 2003 ACM.",Architecture; Association; Instantiation; Mobility; Model; Modularity; Network; Rendezvous; Security,Abstract models; Association; Mobility model; Network address; Network addressing; Fuzzy control; Network security; Network architecture
Sollins K.R.,1,Designing for scale and differentiation,2003,6,"MIT Laboratory for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States",MIT,1,USA,1,40,33,"Na•ve pictures of the Internet frequently portray a small collection of hosts or LAN's connected by a ""cloud"" of connectivity. The truth is more complex. The IP-level structure of the Internet is composed from a large number of constituent networks, each of which differs in some or all of transmission technologies, routing protocols, administrative models, security policies, QoS capabilities, pricing mechanisms, and similar attributes. On top of this, a whole new structure of application-layer overlays and content distribution networks, equally diverse in the sorts of ways mentioned above, is rapidly evolving. Virtually any horizontal slice through the current Internet structure reveals a loosely coupled federation of separately defined, operated, and managed entities, interconnected to varying degrees, and often differing drastically in internal requirements and implementation. Intuitively, it is natural to think of each of these entities as existing in a region of the network, with each region having coherent internal technology and policies, and each region managing its interactions with other regions of the net according to some defined set of rules and policies. In this paper, we propose that a key design element in an architecture for extremely large scale, wide distribution and heterogeneous networks is a grouping and partitioning mechanism we call the region. Furthermore we postulate that such a mechanism can provide increased functionality and management of existing unresolved problems in current networks. The paper both describes a proposed definition of the region concept and explores the utility of such a mechanism through a series of examples. We claim that there is significant added benefit to generalizing the idea of the region. Copyright 2003 ACM.",Extensibility; Heterogeneity; Network architecture; Scalability,Content distribution networks; Design elements; Extensibility; Heterogeneity; Internet structure; Level structure; New structures; Partitioning mechanism; Pricing mechanism; Security policy; Set of rules; Transmission technologies; Distributed parameter networks; Heterogeneous networks; Internet; Internet protocols; Machine design; Network security; Scalability; Network architecture
"Clark D.D., Sollins K., Wroclawski J., Faber T.",4,Addressing reality: An architectural response to real-world demands on the evolving Internet,2003,30,"MIT LCS, United States; USC ISI, United States",MIT,1,USA,1,28,17,"A system as complex as the Internet can only be designed effectively if it is based on a core set of design principles, or tenets, that identify points in the architecture where there must be common understanding and agreement. The tenets of the original Internet architecture [6] arose as a response to the technical, governmental, and societal environment of internetworking's earliest days, but have remained central to the Internet as it has evolved. In light of the increasing integration of the Internet into the social, economic, and political aspects of our lives, it is worth revisiting the underlying tenets of what is becoming a central element of the world's infrastructure. This paper examines three key tenets that we believe should guide the evolution of the Internet in its next generation and beyond. They are: design for change, controlled transparency, and the centrality of the tussle space. [8] Our purpose is not to present these ideas as new, but rather to propose that they should be elevated to central tenets of the evolving architecture of the Internet, and explore the ramifications of doing so. The paper first examines the tenets somewhat abstractly, and then in more detail by studying their relation to several design choices needed for a complete architecture. We conclude with a discussion of the relationship between the network architecture and the applications it serves. Copyright 2003 ACM.",Application support; Architectural principles; Architecture design; Design for change; Security; Transparency; Tussle,Architectural principles; Architecture designs; Common understanding; Core set; Design Principles; Internet architecture; Internetworking; Political aspects; Real-world; Security; Design; Internet; Transparency; Network architecture
"Beck M., Moore T., Plank J.S.",3,An end-to-end approach to globally scalable programmable networking,2003,14,"Logistical Computing and Internetworking Laboratory, Computer Science Department, University of Tennessee, United States",University of Tennessee,1,USA,1,22,18,"The three fundamental resources underlying Information Technology are bandwidth, storage, and computation. The goal of wide area infrastructure is to provision these resources to enable applications within a community. The end-to-end principles provide a scalable approach to the architecture of the shared services on which these applications depend. As a prime example, IP and the Internet resulted from the application of these principles to bandwidth resources. A similar application to storage resources produced the Internet Backplane Protocol and Logistical Networking, which implements a scalable approach to wide area network storage. In this paper, we discuss the use of this paradigm for the design of a scalable service for wide area computation, or programmable networking. While it has usually been assumed that providing computational services in the network will violate the end-to-end principles, we show that this assumption does not hold. We illustrate the point by describing Logistical Network Computing, an extension to Logistical Networking that supports limited computation at intermediate nodes. Copyright 2003 ACM.",Active networking; Asynchronous communications; Distributed state management; End-to-end design; Internet backplane protocol; Logistical network computing; Network storage; Programmable networking; Scalability; Store and forward network,Active networking; Asynchronous communication; Backplanes; Distributed state; End-to-end design; Logistical network; Network storage; Programmable networking; Store and forward; Design; Internet; Network architecture; Scalability; Internet protocols
Yang X.,1,NIRA: A new Internet routing architecture,2003,52,"MIT LCS, United States",MIT,1,USA,1,44,31,"This paper presents the design of a new Internet routing architecture (NIRA). In today's Internet, users can pick their own ISPs, but once the packets have entered the network, the users have no control over the overall routes their packets take. NIRA aims at providing end users the ability to choose the sequence of Internet service providers a packet traverses. User choice fosters competition, which imposes an economic discipline on the market, and fosters innovation and the introduction of new services. This paper explores various technical problems that would have to be solved to give users the ability to choose: how a user discovers routes and whether the dynamic conditions of the routes satisfy his requirements, how to efficiently represent routes, and how to properly compensate providers if a user chooses to use them. In particular, NIRA utilizes a hierarchical provider-rooted addressing scheme so that a common type of domain-level route can be efficiently represented by a pair of addresses. In NIRA, each user keeps track of the topology information on domains that provide transit service for him. A source retrieves the topology information of the destination on demand and combines this information with his own to discover end-to-end routes. This route discovery process ensures that each user does not need to know the complete topology of the Internet. Copyright 2003 ACM.",C.2.1 [computer-communication networks]: network architecture and design; C.2.2 [network protocols]: routing protocols; Design; Economics,C.2.1 [computer-communication networks]: network architecture and design; C.2.2 [network protocols]: routing protocols; Computer communication networks; Computer architecture; Design; Internet; Internet protocols; Internet service providers; Routing protocols; Telecommunication networks; Topology; Network architecture
"Feamster N., Balakrishnan H.",2,Towards a logic for wide-area Internet routing,2003,5,"MIT Laboratory for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States",MIT,1,USA,1,40,31,"Interdomain routing is a massive distributed computing task that propagates topological information for global reachability. Today's interdomain routing protocol, BGP4, is exceedingly complex because the wide variety of goals that it must meet - including fast convergence, failure resilience, scalability, policy expression, and global reachability - are accomplished by mechanisms that have complicated interactions and unintended side effects. The complexity of wide-area routing configuration and protocol dynamics requires mechanisms for expressing wide-area routing that adhere to a set of logical rules. We propose a set of rules, called the routing logic, which can be used to determine whether a routing protocol satisfies various properties. We demonstrate how this logic can aid in analyzing the behavior of BGP4 under various configurations. We also speculate on how the logic can be used to analyze existing configuration in real-world networks, synthesize network-wide router configuration from a high-level policy language, and assist protocol designers in reasoning about new routing protocols. Copyright 2003 ACM.",C.2.2 [computer-communication networks]: routing protocols; Design; Performance; Protocol verification; Reliability,C.2.2 [computer-communication networks]: routing protocols; Computer communication networks; Design performance; Distributed Computing; Failure resilience; Fast convergence; High level policies; Interdomain Routing; Logical rules; Policy expressions; Protocol designers; Protocol verification; Reachability; Real-world networks; Router configuration; Set of rules; Side effect; Topological information; Various configuration; Wide area; Wide-area Internet; Design; Distributed computer systems; High level languages; Network architecture; Routers; Routing protocols; Internet protocols
"Hall J., Moore A., Pratt I., Leslie I.",4,Multi-protocol visualization: A tool demonstration,2003,2,"University of Cambridge, Computer Laboratory, JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,12,9,"This paper describes a system for the visualization of multiple protocols. The visualizer makes possible the identification of both intra and inter-protocol behaviour. This tool has become a critical resource in the development of our multi-protocol monitoring system; allowing the verification of the monitoring system, identification of new modes of behaviour and the easy visualization of potentially overwhelming quantities of information. Copyright 2003 ACM.",HTTP; Multi-protocol analysis; Multi-protocol visualization; Network event visualization; Network monitoring; TCP,Multi-protocol visualization; Multiprotocols; Network event visualization; Network Monitoring; TCP; HTTP; Hypertext systems; Monitoring; Visualization; Transmission control protocol
"Salamatian K., Fdida S.",2,A framework for interpreting measurement over internet,2003,1,"LIP6, UniversitŽ Pierre et Marie Curie (UPMC), Paris, France",University Pierre and Marie Curie,1,France,1,26,25,"This paper introduces a methodology for interpreting measurement obtained over Internet. The paper is motivated by the fact that a large number of published papers in empirical networking analysis follow a generic framework that might be formalized and generalized to a large class of problem. The objective of this paper is to present an interpretation framework and to illustrate it by examples coming from the networking literature. The aim of the paper is rather to give to the researcher who is confronted to measurements coming from a network some guidelines on how to formalize the way to address interpretation of observations.The paper is based on the remark that interpretation is essentially a matter of relating observed effects to hidden causes. This problem might be formalized in its most general setting as an inverse statistical inference problem. The paper illustrates this inverse statistical problem in the context of two well-referred problems: interpretation of active measurement and network tomography. It shows that even if at first glance these two problems are different, the solution framework is the same. We will also give description about how to solve that inverse statistical inference problem by the EM method or the Bayesian framework.The framework provided in this paper is a powerful solution to address the complex problem of interpreting measurement over Internet and network modelling. Copyright 2003 ACM.",Internet; Interpretation; Measurement; Modelling,Active measurement; Bayesian; Complex problems; Generic frameworks; Interpretation; Interpretation frameworks; Large class; Network modelling; Network tomography; Statistical inference; Statistical problems; Internet; Inverse problems; Research; Statistical methods; Tomography; Measurements
Riley G.F.,1,The Georgia Tech network simulator,2003,125,"Georgia Institute of Technology, School of Electrical and Computer Engineering, Atlanta, GA 30332-0250, United States",Georgia Tech,1,USA,1,18,16,"We introduce a new network simulation environment, developed by our research group, called the Georgia Tech Network Simulator (GTNetS). Our simulator is designed specifically to allow much larger-scale simulations than can easily be created by existing network simulation tools. The design of the simulator very closely matches the design of real network protocol stacks and hardware. Thus, anyone with a good understanding of networking in general can easily understand how the simulations are constructed. Further, our simulator is implemented completely in object-oriented C++, which leads to easy extension by users to experiment with new or modified behavior of existing simulation models. Our tool is designed from the beginning with scalability in mind, including the support for distributed simulations on a network of workstations as part of the basic design.We give an overview of the features of GTNetS, and present some preliminary scalability results we have obtained by running GTNetS on a computing cluster at the Pittsburgh Supercomputer Center. Copyright 2003 ACM.",Distributed simulation; Large-scale simulations; Network simulation,Computing clusters; Distributed simulations; Georgia; Large scale simulations; Network of workstations; Network simulation; Network simulation tools; Network simulators; Object oriented; Pittsburgh; Real networks; Research groups; Simulation model; Cluster computing; Research; Scalability; Simulators; Supercomputers; Network protocols
"Fineberg S.A., Wilson D.",2,Performance measurements of a user-space DAFS server with a database workload,2003,0,"NonStop Labs, Hewlett-Packard Company, 19333 Vallco Parkway, M/S 4402, Cupertino, CA  95014, United States",HP Labs,1,USA,1,19,19,"We evaluate the performance of a user-space Direct Access File System (DAFS) server and Oracle Disk Manager (ODM) client using two synthetic test codes as well as the Oracle database. Tests were run on 4-processor Intel Xeon-based systems running Windows 2000. The systems were connected with ServerNet II, a Virtual Interface Architecture (VIA) compliant system area network. We compare the performance of DAFS/ODM and local-disk based I/O, measuring I/O bandwidth and latency. We also compare the runtime and CPU utilization of the Oracle database running the TPC-H benchmark over DAFS/ODM and local disk. Copyright 2003 ACM.",DAFS; Database; File systems; I/O; Networks; Performance evaluation; RDMA,File organization; Networks (circuits); Software testing; DAFS; Database workload; File systems; Performance evaluation; Performance measurements; RDMA; System area networks; Virtual interface architecture; Database systems
"Burnside M., Keromytis A.D.",2,High-speed I/O: The operating system as a signalling mechanism,2003,0,"Computer Science Department, Columbia University, United States",Columbia University,1,USA,1,68,60,"The design of modern operating systems is based around the concept of memory as a cache for data that flows between applications, storage, and I/O devices. With the increasing disparity between I/O bandwidth and CPU performance, this architecture exposes the processor and memory subsystems as the bottlenecks to system performance. Furthermore, this design does not easily lend itself to exploitation of new capabilities in peripheral devices, such as programmable network cards or special-purpose hardware accelerators, capable of card-to-card data transfers. We propose a new operating system architecture that removes the memory and CPU from the data path. The role of the operating system becomes that of data-flow management, while applications operate purely at the signaling level. This design parallels the evolution of modern network routers, and has the potential to enable high-performance I/O for end-systems, as well as fully exploit recent trends in programmability of peripheral (I/O) devices. Copyright 2003 ACM.",Architecture; Data streaming; Operating systems,Architecture; Cache memory; Computer architecture; Computer operating systems; Data transfer; Digital storage; Memory architecture; Network architecture; Routers; Data streaming; Memory subsystems; Operating system architecture; Peripheral devices; Programmability; Programmable network; Signalling mechanisms; Special purpose hardware; Information management
"Shivam P., Chase J.S.",2,On the elusive benefits of protocol offload,2003,3,"Department of Computer Science, Duke University, Durham, NC  27708, United States",Duke University,1,USA,1,13,8,"Periodic order-of-magnitude jumps in Ethernet bandwidth regularly reawaken interest in TCP/IP transport protocol offload. This time the jump to 10-Gigabit Ethernet coincides with the emergence of new network storage protocols (iSCSI and DAFS), and vendors are combining these with offload NICs to position IP as a competitor to FibreChannel and other SAN interconnects. But what benefits will offload show for application performance? Several recent studies have presented conflicting data to argue that offload either does or does not benefit applications. But the evidence from empirical studies is often little better than anecdotal. The principles that determine the results are not widely understood, except for the first principle: Your Mileage May Vary. This paper outlines fundamental performance properties of transport offload and other techniques for low-overhead I/O in terms of four key ratios that capture the CPU-intensity of the application and the relative speeds of the host, NIC device, and network path. The study also reflects the role of offload as an enabler for direct data placement, which eliminates some communication overheads rather than merely shifting them to the NIC. The analysis applies to Internet services, streaming data, and other scenarios in which end-to-end throughput is limited by network bandwidth or processing overhead rather than latency. Copyright 2003 ACM.",High-speed networking; IP; Network performance; Network storage; Protocol offload; RDMA; TCP,Bandwidth; Digital storage; Ethernet; Negative impedance converters; Network performance; Transmission control protocol; Application performance; Communication overheads; End-to-end throughput; High-speed networking; Network storage; Performance properties; Protocol offload; RDMA; Internet protocols
Recio R.J.,1,"Server I/O networks past, present, and future",2003,0,"IBM eServer I/O, IBM Systems Group, Austin, TX, United States",IBM,1,USA,1,38,23,"Enterprise and technical customers place a diverse set of requirements on server I/O networks. In the past, no single network type has been able to satisfy all of these requirements. As a result several fabric types evolved and several interconnects emerged to satisfy a subset of the requirements. Recently several technologies have emerged that enable a single interconnect to be used as more than one fabric type. This paper will describe the requirements customers place on server I/O networks; the various fabric types and interconnects that have been used to satisfy those requirements; the technologies that are enabling network convergence; and how these new technologies are being deployed on various network families. Copyright 2003 ACM.",10 GigE; Cluster; Cluster networks; Gigabit ethernet; I/O expansion network; InfiniBand; IOEN; IONIC; ISCSI; ISER; LAN; PCI; PCI Express; RDMA; RNIC; SAN; Socket extensions; TOE,Computer peripheral equipment; Local area networks; 10 GigE; Cluster; Cluster networks; Gigabit Ethernet; Infiniband; IOEN; IONIC; ISCSI; ISER; PCI Express; RDMA; RNIC; Socket extensions; Customer satisfaction
"McAuley D., Neugebauer R.",2,A case for virtual channel processors,2003,2,"Intel Research Cambridge, 15 JJ Thomson Av, Cambridge, United Kingdom",Intel,1,UK,1,38,34,"Modern desktop and server computer systems use multiple processors: general purpose CPU(s), graphic processor (GPU), network processors (NP) on Network Interface Cards (NICs), RAID controllers, and signal processors on sound cards and modems. Some of these processors traditionally have been special purpose processors but there is a trend towards replacing some of these with embedded general purpose processors. At the same time main CPUs become more powerful; desktop CPUs start featuring Simultaneous Multi-Threading (SMT); and Symmetric Multi-Processing (SMP) systems are widely used in server systems. However, the structure of operating systems has not really changed to reflect these trends - different types of processors evolve at different timescales (largely driven by market forces) requiring significant changes to operating systems kernels to reflect the appropriate tradeoffs. In this position paper we propose to re-vitalise the old idea of channel processors by encapsulating operating system I/O subsystems in Virtual Channel Processors (VCPs). VCPs perform I/O operations on behalf of an OS. They provide similar development, performance, and fault isolation as dedicated (embedded) I/O processors do while offering the flexibility to split functionality between the main processor(s) and dedicated processors without affecting the rest of the OS. If part of a VCP is executed on the main processor, we propose to make use of virtual machine technology and SMT/SMP features to isolate its performance from that of the rest of the system and to protect the system from faults within the VCP. Copyright 2003 ACM.",I/O virtualisation; Protocol offloading; Virtual channel processors,Commerce; General purpose computers; Interfaces (computer); Program processors; Signal processing; General purpose processors; Protocol offloading; Simultaneous multi-threading; Special purpose processors; Symmetric multi processing; Virtual channels; Virtual machine technology; Virtualisation; Embedded systems
"Chadalapaka M., Elzur U., Ko M., Shah H., Thaler P.",5,A study of iSCSI extensions for RDMA (iSER),2003,0,"Hewlett-Packard Company, United States; Broadcom, United States; IBM, United States; Intel Corporation, United States; Agilent Technologies, United States",Agilent Technologies;IBM,2,USA,1,13,8,"The iSCSI protocol is the IETF standard that maps the SCSI family of application protocols onto TCP/IP enabling convergence of storage traffic on to standard TCP/IP fabrics. The ability to efficiently transfer and place the data on TCP/IP networks is crucial for this convergence of the storage traffic. The iWARP protocol suite provides Remote Direct Memory Access (RDMA) semantics over TCP/IP networks and enables efficient memory-to-memory data transfers over an IP fabric. This paper studies the design process of iSCSI Extensions for RDMA (iSER), a protocol that maps the iSCSI protocol over the iWARP protocol suite. As part of this study, this paper shows how iSER enables efficient data movement for iSCSI using generic RDMA hardware and then presents a discussion of the iWARP architectural features that were conceived during the iSER design. These features potentially enable highly efficient realizations of other I/O protocols as well. Copyright 2003 ACM.",DA; Datamover; DDP; DI; ISCSI; ISER; IWARP; MPA; RDMA; RDMAP; SCSI; Verbs,Data transfer; Digital storage; Semantics; Transmission control protocol; Datamover; ISCSI; ISER; IWARP; RDMA; RDMAP; SCSI; Verbs; Internet protocols
Bell G.,1,Failure to thrive: QoS and the culture of operational networking,2003,0,"Ernest Orlando Lawrence Berkeley National Laboratory, One Cyclotron Road, Bldg. 50E0101, Berkeley, CA  94720, United States","Ernest Orlando Lawrence,USA",1,USA,1,21,8,"Understanding the culture of operational networking can help to illuminate the question of why QoS has floundered. Network administrators have a well-founded aversion to complexity, in part because they experience failures attributable to design complexity on a regular basis. I argue that IP multicast defines a functional limit-case for deployable complexity in today's Internet. That limit is relevant to the deployment of QoS, since many flavors of QoS entail equal or greater complexity. The notion of a functional constraint on complexity draws attention to the economic, historical, and institutional forces which influence the fate of networking technologies. QoS will not be compelling for most network administrators until its design takes account of these forces. Copyright 2003 ACM.",Complexity; Multicast; Operational networking; QoS,Complex networks; Multicasting; Quality of service; Complexity; Design complexity; Functional constraints; Institutional forces; IP Multicast; Network administrator; Networking technology; Operational networking; Internet protocols
Davie B.,1,Deployment experience with differentiated services,2003,0,"Cisco Systems, Inc., 1414 Massachusetts Ave., Boxborough, MA  01719, United States",Cisco,1,USA,1,15,9,"While ubiquitous QoS mechanisms are not yet deployed widely across the public Internet, the Differentiated Services (diffserv) architecture has in fact proven itself to be a good match for the technical needs of many service providers. In this paper we consider the state of deployment of QoS mechanisms in large service provider IP networks (many of which happen to be offering VPN or VoIP services rather than public Internet service.) We discuss the factors that have helped and hindered the deployment of QoS mechanisms in general and diffserv in particular. We conclude that many if not most of the barriers to QoS deployment are business issues rather than technical shortcomings of the existing QoS architectures. Copyright 2003 ACM.",Differentiated services; Quality of service,Internet protocols; Internet service providers; Network architecture; Routers; Business issues; Differentiated Services; Differentiated services architectures; Public internet; QoS architecture; QoS mechanisms; Service provider; Technical needs; Quality of service
"Burgstahler L., Dolzer K., Hauser C., JŠhnert J., Junghans S., MaCi‡n C., Payer W.",7,Beyond technology: The missing pieces for QoS success,2003,2,"Institute of Communication Networks and Computer Engineering, University of Stuttgart, Pfaffenwaldring 47, Stuttgart, 70569, Germany; T-Systems GEI GmbH, Germany; RUS, University of Stuttgart, Allmandring 30, Stuttgart, 70569, Germany",T-Systems GEI GmbH;University of Stuttgart,2,Germany,1,21,21,"Years of research on QoS architectures for IP networks have delivered sophisticated proposals, which have nevertheless not found broad commercial use. The reasons are not lack of technical soundness or insurmountable technological complexity, but insufficient attention to other, non-QoS-specific matters. First among them is the lack of a commercialization model for the Internet together with the necessary accounting and charging architecture. Another crucial issue is the assurance of end-to-end QoS coherence in the face of multiple intervening parties (network and content providers, users). Furthermore, the practical requirements imposed by those parties to any successful QoS architecture have not been fully taken into account: Ease of management, simplicity and measurable guarantees are some of the main ones. In this paper, the overall constraints on and conditions for the successful deployment of QoS in IP networks are analyzed and some possible directions explored. Copyright 2003 ACM.",Internetworking; Next generation internet; QoS,Mobile telecommunication systems; Network architecture; Quality of service; Content providers; End-to-end QoS; Internetworking; Next generation Internet; Practical requirements; QoS architecture; QOS in IP networks; Technological complexity; Internet protocols
"Shaikh A., Greenberg A.",2,Experience in Black-box OSPF Measurement,2001,58,"University of California, Santa Cruz, CA 95064, United States; AT and T Research, Florham Park, NJ 07932, United States",AT and T Labs;University of California Santa Cruz,2,USA,1,11,9,"OSPF (Open Shortest Path First) is a widely used ultra-domain routing protocol in IP networks. Internal processing delays in OSPF implementations impact the speed at which updates propagate in the network, the load on individual routers, and the time needed for both intra-domain and inter-domain routing to reconverge following an internal topology or a configuration change. An OSPF user, such as an Internet Service Provider, typically has no access to the software implementation, and no way to estimate these delays directly. In this paper, we present black-box methods (i.e., measurements that rely only on external observations) for estimating and trending delays for key internal tasks in OSPF: processing Link State Advertisements (LSAs), performing Shortest Path First calculations, updating the Forwarding Information Base, and flooding LSAs. Corresponding measurements are reported for production routers from Cisco Systems. To help validate the methodology, black-box and white-box (i.e., measurements that rely on internal instrumentation) are reported for a open source OSPF implementation, GateD.",Black-box measurements; OSPF; Routing; SPF calculation,Black-box measurements; Open shortest path first (OSPF); OSPF; Routing; SPF calculations; Computer simulation; Internet; Routers; Topology; Network protocols
"Micheel J., Donnelly S., Graham I.",3,Precision Timestamping of Network Packets,2001,40,"WAND, Computer Science, University of Waikato, Hillcrest Road, Gate 8, Hamilton, New Zealand; NLANR MOAT, SDSC, USCD, 10100 John Hopkins Dr, San Diego, CA 92093-0505, United States",University of Waikato,1,New Zealand;USA,2,9,4,"When recording network traffic, accurate timestamping of the arrival of packets is essential for the subsequent analysis of performance metrics. Until the mid-1990s using off-the-shelf network interface cards and computer clocks proved sufficient. With the introduction of ever increasing link data rates the task of proper timestamping becomes increasingly important for continued network research. In the past five years the Dag development team in the WAND research group has undertaken substantial efforts to meet those demands and in this paper we discuss the advantages and limits of this new, hardware driven approach and explain how to interpret high precision timing information for packet arrivals.",Computer networks; Measurement; Performance; Timestamping,Computer clocks; Timestamping; Algorithms; Bandwidth; Clocks; Code division multiple access; Computer hardware; Computer software; Interfaces (computer); Network protocols; Synchronization; Telecommunication traffic; Packet networks
"Huang P., Feldmann A., Willinger W.",3,"A non-intrusive, wavelet-based approach to detecting network performance problems",2001,77,"Comp. Eng. and Networks Laboratory, ETH ZŸrich, ZŸrich, Switzerland; Computer Science Department, UniversitŠt des Saarlandes, SaarbrŸcken, Germany; AT and T Labs-Research, Florham Park, NJ, United States",AT and T Labs;ETH Zurich;UniversitŠt des Saarlandes,3,Germany;Switzerland;USA,3,44,26,"The main objective of this paper is to explore how much information about the characteristics of end-to-end network paths can be inferred from relying solely on passive packet-level traces of existing traffic collected from a single tap point in the network. To this end, we show that a number of structural properties of aggregate TCP/IP packet traces reveal themselves and can be compared across different time periods and across parts of the traffic destined to different subnets by exploiting the built-in scale-localization ability of wavelets. In turn, these structural properties and the resulting comparisons suggest the feasibility of new approaches for inferring and detecting qualitative aspects of network performance in a fashion that is similar to relying on active measurements, but without disturbing or biasing the metrics of interest. To showcase the feasibility, we developed WIND, a prototype tool for wavelet-based INference for Detecting network performance problems and illustrate its capabilities to detect anomalies in underlying network path conditions with two examples of passively measured packet traces from two different networking environments. We address and experiment with ways of validating the output of WIND and end with a discussion of the potential of fullfledged wavelet-based analysis (i.e., the ability to localize a signal in scale and time) for future measurement studies.",Energy Function; Network Performance; Passive Measurements; Scale-Localization; Wavelets,Energy function; Network performance; Passive measurements; Scale-localization; Wavelets; Heuristic methods; Network protocols; Problem solving; Software prototyping; Statistical methods; Telecommunication traffic; Wavelet transforms; Packet networks
"Shannon C., Moore D., Claffy K.",3,Characteristics of Fragmented IP Traffic on Internet Links,2001,20,"CAIDA, San Diego Supercomputer Center, University of California, San Diego, United States",University of California San Diego,1,USA,1,17,9,"Fragmented IP traffic is a unique component of the overall mix of traffic on the Internet. Many assertions about the nature and extent of fragmented traffic are anecdotal rather than empirical. In this paper we examine the causes and attributes of measured fragment traffic and contrast those results with commonly cited beliefs. In particular, the effects of NFS, streaming media, networked video games, and tunneled traffic are quantified, and we estimate the prevalence of packet fragmentation due to improperly configured machines. To understand the prevalence, causes, and effects of fragmented IP traffic, we have collected and analyzed seven multi-day traces from three sources. These sources include a university commodity access link, a highly aggregated commercial exchange point, and a local NAP. Although there is no practical method of ascertaining whether any data provide a representative sample of all Internet traffic, we do include data sources that cover several different types of WANs with traffic from commercial entities, educational and research institutions, and large government facilities.",CoralReef; Fragment; Fragmentation; TCP/IP,CoralReef; Fragment; Fragmentation; TCP/IP; Bandwidth; Computer architecture; Local area networks; Network protocols; Packet switching; Telecommunication links; Telecommunication traffic; Wide area networks; Internet
"Barford P., Bestavros A., Byers J., Crovella M.",4,On the Marginal Utility of Network Topology Measurements,2001,109,"University of Wisconsin, Madison, United States; Computer Science Department, Boston University, United States",Boston University;;University of Wisconsin-Madison,3,USA,1,33,22,"The cost and complexity of deploying measurement infrastructure in the Internet for the purpose of analyzing its structure and behavior is considerable. Basic questions about the utility of increasing the number of measurements and measurement sites have not yet been addressed which has led to a ""more is better"" approach to wide-area measurement studies. In this paper, we step toward a more quantifiable understanding of the marginal utility of performing wide-area measurements in the context of Internet topology discovery. We characterize the observable topology in terms of nodes, links, node degree distribution, and distribution of end-to-end flows using statistical and information-theoretic techniques. We classify nodes discovered on the routes between a set of 8 sources and 1277 destinations to differentiate nodes which make up the so called ""backbone"" from those which border the backbone and those on links between the border nodes and destination nodes. This process includes reducing nodes that advertise multiple interfaces to single IP addresses. We show that the utility of adding sources beyond the second source quickly diminishes from the perspective of interface, node, link and node degree discovery. We also show that the utility of adding destinations is constant for interfaces, nodes, links and node degree indicating that it is more important to add destinations than sources.",Internet tomography; Network measurement; Topology discovery; Traceroute,Internet tomography; Network measurement; Topology discovery; Traceroute; Algorithms; Information theory; Network protocols; Packet switching; Internet
Peuhkuri M.,1,A Method to Compress and Anonymize Packet Traces,2001,30,"Helsinki University of Technology, Networking Laboratory, Espoo, Finland",Helsinki University of Technology,1,Finland,1,13,9,Data volume and privacy issues are one of problems related to large-scale packet capture. Utilizing flow nature of Internet traffic can reduce data volume. Removing sensitive information such as IP addresses enchanges privacy. Our method makes possible to have same replacement value for given IP address even if capture location or time is different.,Anonymization; Data compression; Packet capture,Cryptography; Data acquisition; Data compression; Data reduction; Large scale systems; Microprocessor chips; Network protocols; Random access storage; Sensitivity analysis; Telecommunication traffic; Anonymization; Electronic codebooks (ECB); Packet capture; Packet networks
"Sarvotham S., Riedi R., Baraniuk R.",3,Connection-level Analysis and Modeling of Network Traffic,2001,93,"Department of Electrical Engineering, Rice University, Houston, TX 77005, United States",Rice University,1,USA,1,14,11,"Most network traffic analysis and modeling studies lump all connections together into a single flow. Such aggregate traffic typically exhibits long-range-dependent (LRD) correlations and non-Gaussian marginal distributions. Importantly, in a typical aggregate traffic model, traffic bursts arise from many connections being active simultaneously. In this paper, we develop a new framework for analyzing and modeling network traffic that moves beyond aggregation by incorporating connection-level information. A careful study of many traffic traces acquired in different networking situations reveals (in opposition to the aggregate modeling ideal) that traffic bursts typically arise from just a few high-volume connections that dominate all others. We term such dominating connections alpha traffic. Alpha traffic is caused by large file transmissions over high bandwidth links and is extremely bursty (non-Gaussian). Stripping the alpha traffic from an aggregate trace leaves a beta traffic residual that is Gaussian, LRD, and shares the same fractal scaling exponent as the aggregate traffic. Beta traffic is caused by both small and large file transmissions over low bandwidth links. In our alpha/beta traffic model, the heterogeneity of the network resources give rise to burstiness and heavy-tailed connection durations give rise to LRD. Queuing experiments suggest that the alpha component dictates the tail queue behavior for large queue sizes, whereas the beta component controls the tail queue behavior for small queue sizes.",Animal kingdom; Network traffic modeling,Animal kingdom; Network traffic modeling; Bandwidth; Computer simulation; Correlation methods; Gaussian noise (electronic); Markov processes; Network protocols; Queueing networks; Telecommunication traffic
Allman M.,1,Measuring End-to-End Bulk Transfer Capacity,2001,22,"BBN Technologies, NASA Glenn Research Center, United States",BBN Technologies;NASA Glenn Research Center,2,USA,1,20,19,"This paper provides a preliminary assessment of the effectiveness of an application layer tool that measures the Bulk Transfer Capacity (BTC) of a network path. BTC is roughly defined as the throughput that a flow using standard congestion control techniques would obtain across a given network path at a given time. We utilize the NIMI mesh of measurement hosts to compare stock BSD TCP with a new BTC measurement tool, cap. While BTC tools have been around for some time, no systematic evaluation of their accuracy with respect to standard TCP congestion control across a wide variety of network paths has been conducted. The goal of this paper is to provide such an empirical evaluation of a BTC tool and therefore assess the reliability of the measurements obtained using BTC tools.",Bandwidth Measurement; Bulk Transfer Capacity; Congestion Control; TCP,Bandwidth measurement; Bulk transfer capacity; TCP; Algorithms; Bandwidth; Computer operating systems; Data transfer; Failure analysis; Network protocols; Problem solving; Reliability; Scheduling; Congestion control (communication)
"Luckie M.J., McGregor A.J., Braun H.-W.",3,Towards Improving Packet Probing Techniques,2001,26,"Msrmt. and Network Analysis Group, San Diego Supercomputer Center, University of California, San Diego, San Diego, United States; University of Waikato, Hamilton, New Zealand",University of California San Diego;University of Waikato,2,New Zealand;USA,2,22,15,"Packet probing is an important Internet measurement technique, supporting the investigation of packet delay, path, and loss. Current packet probing techniques use Internet Protocols such as the Internet Control Message Protocol (ICMP), the User Datagram Protocol (UDP), and the Transmission Control Protocol (TCP). These protocols were not originally designed for measurement purposes. Current packet probing techniques have several limitations that can be avoided. The IP Measurement Protocol (IPMP) is presented as a protocol that addresses several of the limitations discussed.",Network Path; Packet Delay; Packet Probing Techniques,Congestion control (communication); Costs; Information analysis; Internet; Network protocols; Problem solving; Routers; Synchronization; Transmitters; Internet control message protocol (ICMP); Network path; Packet delay; Packet probing techniques; Transmission control protocol (TCP); Packet networks
"Biaz S., Vaidya N.H.",2,Is the round-trip time correlated with the number of packets in flight ?,2000,24,"Computer Science and Software Engineering, Auburn University, United States; Dept. of Electrical and Computer Engineering, Coordinated Science Laboratory, University of Illinois, Urbana-Champaign, United States",Auburn University;UIUC,2,USA,1,16,10,"TCP uses packet loss as a feedback from the network to adapt its sending rate. TCP keeps increasing its sending rate as long as no packet loss occurs (unless constrained by buffer size). Alternative congestion avoidance techniques (CATs) have been proposed to avoid such ""aggressive"" behavior. These CATs use simple statistics on observed round-trip times and/or throughput of a TCP connection in response to variations in congestion window size. These CATs have a supposed ability to detect queue build-up. The objective of this paper is to question the ability of these CATs to reliably detect queue build-up under real network conditions. For this purpose, the sample coefficient of correlation between round-trip time and the number of packets in flight is analyzed for 14,218 connections over 737 Internet paths. These coefficients of correlation were extracted from a set of tcpdump traces collected by Vern Paxson. The coefficients of correlation measured confirm that the correlation between RTT and window size is often weak. Copyright 2003 ACM.",Congestion predictors; Congestion window size; Correlation; Roundtrip time; TCP,Congestion predictors; Congestion window size; Roundtrip time; TCP; Air transportation; Bandwidth; Congestion control (communication); Correlation theory; Database systems; Packet networks; Packet switching; Network protocols
"Andersen D.G., Snoeren A.C., Balakrishnan H.",3,Best-path vs. multi-path overlay routing,2000,98,"MIT Laboratory for Computer Science, United States; University of California, San Diego, United States",MIT;University of California San Diego,2,USA,1,33,26,"Time-varying congestion on Internet paths and failures due to software, hardware, and configuration errors often disrupt packet delivery on the Internet. Many aproaches to avoiding these problems use multiple paths between two network locations. These approaches rely on a path-independence assumption in order to work well; i.e., they work best when the problems on different paths between two locations are uncorrelated in time. This paper examines the extent to which this assumption holds on the Internet by analyzing 14 days of data collected from 30 nodes in the RON testbed. We examine two problems that manifest themselves - congestion-triggered loss and path failures - and find that the chances of losing two packets between the same hosts is nearly as high when those packets are sent through an intermediate node (60%) as when they are sent back-to-back on the same path (70%). In so doing, we also compare two different ways of taking advantage of path redundancy proposed in the literature: mesh routing based on packet replication, and reactive routing based on adaptive path selection. Copyright 2003 ACM.",Measurement; Multi-Path Routing; Networking; Overlay Networks,Forward error correction (FEC); Multi-path routing; Networking; Overlay networks; Bandwidth; Computer hardware; Computer software; Congestion control (communication); Error analysis; Error correction; Network protocols; Packet networks; Probability; Telecommunication traffic; Internet
Duffield N.,1,Simple network performance tomography,2000,59,"AT and T Labs - Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,8,7,"In network performance tomography, characteristics of the network interior are inferred by correlating end-to-end measurements. In much previous work, the presence of correlations must be arranged at the packet level, e.g., using multicast probes or unicast emulations of them. This carries costs in deployment and limits coverage. However, it is difficult to determine performance characteristics without correlations. Some recent work has had success in reaching a lesser goal - identifying the lossiest network links -using only uncorrelated end-to-end measurements. In this paper we abstract the required properties of network performance, and show that they are independent of the particular inference algorithm used. This observation allows us to design a quick and simple inference algorithm that identifies the worst performing link in a badly performing subnetwork, with high likelihood when bad links are uncommon. We give several examples of perforance models and that exhibit the required properties. The performance of the algorithm is analyzed explicitly. Copyright 2003 ACM.",Correlation; Estimation; Inference; Networks; Performance,Linear programming; Maximum likelihood estimation; Multicasting; Network protocols; Probability; Routers; Telecommunication links; Telecommunication traffic; Tomography; Correlation; Inference; Multicast probes; Networks; Packet networks
"Teixeira R., Marzullo K., Savage S., Voelker G.M.",4,In search of path diversity in ISP networks,2000,90,"Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,16,14,"Internet Service Providers (ISPs) can exploit path diversity to balance load and improve robustness. Unfortunately, it is difficult to evaluate the potential impact of these approaches without routing and topological data, which are confidential. In this paper, we characterize path diversity in the real Sprint network. We then characterize path diversity in ISP topologies inferred using the Rocketfuel tool. Comparing the real Sprint topology to the one inferred by Rocketfuel, we find that the Rocketfuel topology has significantly higher apparent path diversity. We evaluate heuristics that improve the accuracy of the inferred Rocketfuel topologies. Finally, we discuss limitations of active measurements techniques to capture topological properties such as path diversity. Copyright 2003 ACM.",Internet topology; Path diversity,Internet service providers (ISP); Internet topology; Path diversity; Points of presence (POP); Network protocols; Packet networks; Packet switching; Parallel processing systems; Routers; Telecommunication services; Topology; Internet
"Coates M., Rabbat M., Nowak R.",3,Merging logical topologies using end-to-end measurements,2000,27,"Department of E.G.E., McGill University, Montreal, Que., Canada; Department of E.C.E., Rice University, Houston, TX, United States",McGill University;Rice University,2,Canada;USA,2,19,17,"Knowledge of network topology is useful for understanding the structure of the Internet, for developing and testing new protocols, and as prior information to network tomography algorithms. Building on existing techniques for inferring a single-source tree topology using end-to-end measurements, we address the problem of merging multiple tree topologies. We develop a multiple source active probing methodology and statistical framework for testing whether the paths from two sources to two receivers branch at a common internal node. This information can then be used to determine where portions of the tree topology from one source to a set of receivers overlap with the tree topology from a different source to the same set of receivers. The algorithm uses a novel random probing structure and easily made measurements of packet arrival order. As a result, we do not require precise time synchronization among the participating hosts. Successful experiments performed over a university LAN and over the Internet verify that our methodology is versatile and robust. Copyright 2003 ACM.",End-to-end measurement; Multiple-source network tomography; Network tomography; Packet arrival order; Topology discovery,End-to-end measurement; Multiple-source network tomography; Network tomography; Packet arrival order; Topology discovery; Algorithms; Formal logic; Internet; Local area networks; Packet networks; Synchronization; Electric network topology
"Wills C.E., Mikhailov M., Shang H.",3,Inferring relative popularity of internet applications by actively querying DNS caches,2000,16,"Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609, United States",100 Institute Road;Worcester Polytechnic Institute,2,USA,1,22,12,"In this work, we propose a novel methodology that can be used to assess the relative popularity for any Internet application based on the data servers it uses. The basic idea is to infer popularity of data servers by periodically ""poking"" at local Domain Name servers (LDNSs) that service Domain Name System requests from a set of users running Internet applications and determining if LDNSs have cached resource records for the data servers. This approach allows us to measure the relative percentage of pokes that result in a cache hit as a coarse measure of the relative popularity of a particular data server among the users of a given LDNS. In addition, the time-to-live (TTL) of cached DNS resource records can be used to measure the gaps in time when a resource record for a data server is not cached: The cache gaps can be used to infer request interarrivals for more popular data servers. The methodology can be applied to any Internet application that uses distinguished server names and performs DNS lookups on these names as part of application use. The methodology can be used to collect usage information from any LDNS that accepts DNS queries. As example applications of the methodology, we evaluate the relative popularity of selected Web sites and the relative popularity of different Web servers serving content at a given Web site. We also apply the methodology to servers providing multimedia content, data servers for grid computing, and network game servers. We use data gathered from LDNSs of commercial and educational sites as well as Internet Service Providers serving both commercial and home customers. © Copyright 2003 ACM.",Active Content Measurement; Domain Name System,Access control lists (ACL); Active content measurement; Domain name systems; Local Domain Name Servers (LDNS); Time-to-live (TTL); Buffer storage; Computer software; Multimedia systems; Servers; Web browsers; Websites; Internet
"Krishnamurthy B., Sen S., Zhang Y., Chen Y.",4,"Sketch-based change detection: Methods, evaluation, and applications",2000,304,"AT and T Labs-Research, 180 Park Avenue, Florham Park, NJ, United States; University of California, Berkeley, CA, United States",AT and T Labs;University of California Berkeley,2,USA,1,40,27,"Traffic anomalies such as failures and attacks are commonplace in today's network, and identifying them rapidly and accurately is critical for large network operators. The detection typically treats the traffic as a collection of flows that need to be examined for significant changes in traffic pattern (e.g., volume, number of connections). However, as link speeds and the number of flows increase, keeping per-flow state is either too expensive or too slow. We propose building compact summaries of the traffic data using the notion of sketches. We have designed a variant of the sketch data structure, k-ary sketch, which uses a constant, small amount of memory, and has constant per-record update and reconstruction cost. Its linearity property enables us to summarize traffic at various levels. We then implement a variety of time series forecast models (ARIMA, Holt-Winters, etc.) on top of such summaries and detect significant changes by looking for flows with large forecast errors. We also present heuristics for automatically configuring the model parameters. Using a large amount of real Internet traffic data from an operational tier-1 ISP, we demonstrate that our sketch-based change detection method is highly accurate, and can be implemented at low computation and memory costs. Our preliminary results are promising and hint at the possibility of using our method as a building block for network anomaly detection and traffic measurement. Copyright 2003 ACM.",Change Detection; Data Stream Computation; Forecasting; Network Anomaly Detection; Sketch; Time Series Analysis,Automation; Computer networks; Computer science; Cost effectiveness; Data flow analysis; Forecasting; Signal detection; Software engineering; Telecommunication traffic; Time series analysis; Change detection; Data stream computation; Network anomaly detection; Sketch; Telecommunication networks
Allman M.,1,On the performance of middleboxes,2000,15,"BBN Technologies, United States",BBN Technologies,1,USA,1,11,8,"This paper presents a preliminary performance analysis of a complex middlebox infrastructure in a real-world production environment that serves several thousand people. While prevalent, middleboxes (firewalls, NATs, etc.) have yet to be systematically measured. This paper makes two contributions: (i) we outline several methodologies and metrics by which to measure middleboxes and (ii) we offer preliminary application-layer measurements of one particular production middlebox system. We show that the middlebox infrastructure in question offers a mixed bag of performance implications (both positive and negative). In addition, we quantify several failure modes introduced by the middlebox infrastructure. Copyright 2003 ACM.",Firewalls; Middleboxes; TCP performance,Firewalls; Middleboxes; Port number; TCP performance; Computer architecture; Data communication systems; Internet; Network protocols; Packet networks; Packet switching; Real time systems; Computer system firewalls
"Dewes C., Wichmann A., Feldmann A.",3,An analysis of internet chat systems,2000,105,"UniversitŠt des Saarlandes, Germany; TU MŸnchen, Germany",TU Munich;UniversitŠt des Saarlandes,2,Germany,1,39,30,"In our quest to better understand network traffic dynamics, we examine Internet chat systems. Although chat as an application does not contribute huge amounts of traffic, chat systems are known to be habit-forming. This implies that catering to such users can be a promising way of attracting them, especially in low bandwidth environments such as wireless networks. Unfortunately there is no common protocol base for chat systems. Rather there are a multitude of protocol variants whose specifications, with some exceptions, such as IRC and ICQ, are unavailable or ill defined. In addition, chat systems are often layered on top of other application protocols like HTTP. Therefore there is no simple way of even identifying chat traffic. In this paper we show how to separate chat traffic from other Internet traffic and present the results of an extensive validation of our methodology. Using our methodology we gather a week long trace of all chat traffic that crosses a 155 Mbit/s link from the Saarland University to the Internet and present an initial characterization. Copyright 2003 ACM.",Chat; IRC; Network Measurements,AOL Instant Messenger (AIM); Internet Relay Chat (IRC); Network measurements; Short message service (SMS); Bandwidth; Computational complexity; Computer networks; Heuristic methods; Network protocols; Online conferencing; Open systems; Telecommunication traffic; Web browsers; Wireless telecommunication systems; Internet