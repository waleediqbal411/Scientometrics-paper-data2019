Authors,No. of Authors,Title,Year,Cited by,Affiliations,Institutes,No. of Institutes,Countries,No. of Countries,Total References,10 Years,Abstract,Author Keywords,Index Keywords
"Al-Dalky R., Rabinovich M., Allman M.",3,Practical challenge-response for DNS,2018,0,"Case Western, Reserve University, United States; International Computer, Science Institute, United States",Case Western Reserve University,1,USA,1,31,22,"Authoritative DNS servers are susceptible to being leveraged in denial of service attacks in which the attacker sends DNS queries while masquerading as a victim - and hence causing the DNS server to send the responses to the victim. This reflection off innocent DNS servers hides the attackers identity and often allows the attackers to amplify their traffic by employing small requests to elicit large responses. Several challenge-response techniques have been proposed to establish a requester's identity before sending a full answer. However, none of these are practical in that they do not work in the face of ""resolver pools"" - or groups of DNS resolvers that work in concert to lookup records in the DNS. In these cases a challenge transmitted to some resolver R1 may be handled by a resolver R2, hence leaving an authoritative DNS server wondering whether R2 is in fact another resolver in the pool or a victim. We offer a practical challenge-response mechanism that uses challenge chains to establish identity in the face of resolver pools. We illustrate that the practical cost of our scheme in terms of added delay is small. © 2018 Association for Computing Machinery. All rights reserved.",DNS; Network security; Performance,Denial-of-service attack; Lakes; Network security; Challenge response; Challenge response techniques; DNS server; Lookups; Performance; Internet protocols
"Nikaein N., Chang C.-Y., Alexandris K.",3,Mosaic5G: Agile and flexible service platforms for 5G research,2018,2,"Communication Systems Department, EURECOM, France",EURECOM,1,France,1,18,18,"Network slicing is one of the key enablers to provide the required flexibility and to realize the service-oriented vision toward fifth generation (5G) mobile networks. In that sense, virtualization, softwarization, and disaggregation are core concepts to accommodate the requirements of an end-to-end (E2E) service to be either isolated, shared, or customized. They lay the foundation for a multi-service and multi-tenant architecture, and are realized by applying the principles of software-defined networking (SDN), network function virtualization (NFV), and cloud computing to the mobile networks. Research on these principles requires agile and flexible platforms that offer a wide range of real-world experimentations over different domains to open up innovations in 5G. To this end, we present Mosaic5G, a community-led consortium for sharing platforms, providing a number of software components, namely FlexRAN, LL-MEC, JOX and Store, spanning application, management, control and user plane on top of OpenAirInterface (OAI) platform. Finally, we show several use cases of Mosaic5G corresponding to widely-mentioned 5G research directions. © 2018 Association for Computing Machinery. All rights reserved.",5G; Network slicing; Open-source platforms; Service-orientation,Application programs; Distributed computer systems; Mobile telecommunication systems; Network function virtualization; Open source software; Quality of service; Virtual reality; Wireless networks; Fifth generation (5g); Flexible platforms; Multi-tenant architectures; Network slicing; Open source platforms; Service orientation; Software component; Software defined networking (SDN); 5G mobile communication systems
"Zhang H., Li Y., Zhang Z., Afanasyev A., Zhang L.",5,NDN host model,2018,0,"University of California, Los Angeles, United States; Florida International University, United States",Florida International University;University of California Los Angeles,2,USA,1,24,18,"As a proposed Internet architecture, Named Data Networking (NDN) changes the network communication model from delivering packets to destinations identified by IP addresses to fetching data packets by names. This architectural change leads to changes of host functions and initial configurations. In this paper we present an overview of the basic functions of a host in an NDN network, together with necessary operations to configure an NDN host. We also compare and contrast the functionality and configuration between an NDN host and an IP host, to show the differences resulted from the different architecture designs. © 2018 Association for Computing Machinery. All rights reserved.",Host configuration; Host function; NDN,Network architecture; Architectural changes; Different architectures; Host configuration; Host function; Initial configuration; Internet architecture; Named data networkings; Network communications; Internet protocols
"Böttger T., Cuadrado F., Uhlig S.",3,Looking for hypergiants in PeeringDB,2018,0,"Queen Mary University of London, United Kingdom",Queen Mary University of London,1,UK,1,12,11,"Hypergiants, such as Google or Netflix, are important organisations in the Internet ecosystem, due to their sheer impact in terms of traffic volume exchanged. However, beyond naming specific instances, the research community still lacks a sufficiently crisp understanding of them. In this paper we analyse PeeringDB data and identify features that differentiate hypergiants from the other organisations. To this end, we first characterise the organisations present in PeeringDB, allowing us to identify discriminating properties of these organisations.We then use these properties to separate the data in two clusters, differentiating hypergiants from other organisations. We conclude this paper by investigating how hypergiants and other organisations exploit the IXP ecosystem to reach the global IPv4 space. © 2018 Association for Computing Machinery. All rights reserved.",Hypergiants; Internet exchange points; PeeringDB,Communication; Hypergiants; Internet exchange points; Netflix; PeeringDB; Research communities; Traffic volumes; Ecosystems
"Zhou Y., Alipourfard O., Yu M., Yang T.",4,Accelerating network measurement in software,2018,0,"Peking University, China; Yale University, United States; Harvard University, United States",Harvard University;Peking University;Yale University,3,China;USA,2,42,25,"Network measurement plays an important role for many network functions such as detecting network anomalies and identifying big flows. However, most existing measurement solutions fail to achieve high performance in software as they often incorporate heavy computations and a large number of random memory accesses. We present Agg-Evict, a generic framework for accelerating network measurement in software. Agg-Evict aggregates the incoming packets on the same flows and sends them as a batch, reducing the number of computations and random memory accesses in the subsequent measurement solutions. We perform extensive experiments on top of DPDK with 10G NIC and observe that almost all the tested measurement solutions under Agg-Evict can achieve 14.88 Mpps throughput and see up to 5.7× lower average processing latency per packet. © 2018 Association for Computing Machinery. All rights reserved.",Network measurement; Software packet processing,Generic frameworks; Incoming packets; Lower average; Network anomalies; Network functions; Network measurement; Packet processing; Random memory access; Communication
"Bano S., Richter P., Javed M., Sundaresan S., Durumeric Z., Murdoch S.J., Mortier R., Paxson V.",8,Scanning the internet for liveness,2018,1,"University College London, United Kingdom; MIT, United Kingdom; LUMS Pakistan, ICSI Berkeley, United States; Princeton University, United States; Stanford University, United States; University of Cambridge, United Kingdom; UC Berkeley, ICSI Berkeley, United States",LUMS Pakistan;MIT;Princeton University;Stanford University;University College London;University of California Berkeley;University of Cambridge,7,Pakistan;UK;USA,3,40,26,"Internet-wide scanning depends on a notion of liveness: Does a target IP address respond to a probe packet? However, the interpretation of such responses, or lack of them, is nuanced and depends on multiple factors, including: How we probed, how different protocols in the network stack interact, the presence of filtering policies near the target, and temporal churn in IP responsiveness. Although often neglected, these factors can significantly affect the results of active measurement studies. We develop a taxonomy of liveness which we employ to develop a method to perform concurrent IPv4 scans using ICMP, five TCP-based, and two UDP-based protocols, comprehensively capturing all responses to our probes, including negative and cross-layer responses. Leveraging our methodology, we present a systematic analysis of liveness and how it manifests in active scanning campaigns, yielding practical insights and methodological improvements for the design and the execution of active Internet measurement studies. © 2018 Association for Computing Machinery. All rights reserved.",Active Measurement; Census; Cross-protocol; Scanning,Probes; Scanning; Active measurement; Active scanning; Census; Different protocols; Internet measurement; Multiple factors; Network stack; Systematic analysis; Internet protocols
"Cavalcanti E.R., Rodrigues de Souza J.A., Spohn M.A., De Morais Gomes R.C., Ferreira Da Costa A.F.B.",5,"VANETs’ research over the past decade: Overview, credibility, and trends",2018,1,"Federal Institute of Pernambuco, Brazil; Federal University of Campina, Grande, Brazil; Federal University of Fronteira Sul, Brazil; Federal Institute of Paraiba, Brazil",Federal Institute of Paraiba;Federal Institute of Pernambuco;Federal University of Campina;Federal University of Fronteira Sul,4,Brazil,1,31,23,"Since its inception, Vehicular Ad hoc Networks (VANETs) have been attracting much attention from both academia and industry. As for other wireless networking areas, scientific advancements are mainly due to the employment of simulation tools and mathematical models. After surveying 283 papers published in the last decade on vehicular networking, we pinpoint the main studied topics as well as the most employed tools, pointing out the changes in research subject preference over the years. As a key contribution, we also evaluate to what extent the research community has evolved concerning the principles of credibility in simulation-based studies, such as repeatability and replicability, comparing our results with previous studies. © 2018 Association for Computing Machinery. All rights reserved.",Reproducibility; Simulation; Survey; Vehicular networks,Surveying; Surveys; Reproducibilities; Research communities; Research subjects; Simulation; Vehicular Adhoc Networks (VANETs); Vehicular networkings; Vehicular networks; Wireless networking; Vehicular ad hoc networks
"Breza M., Tomic I., McCann J.",3,"Failures from the environment, A report on the first FAILSAFE workshop",2018,0,"AESE, Imperial College, London, United Kingdom",Imperial College London,1,UK,1,31,21,"This document presents the views expressed in the submissions and discussions at the FAILSAFE workshop about the common problems that plague embedded sensor system deployments in the wild. We present analysis gathered from the submissions and the panel session of the FAILSAFE 2017 workshop held at the SenSys 2017 conference. The FAILSAFE call for papers specifically asked for descriptions of wireless sensor network (WSN) deployments and their problems and failures. The submissions, the questions raised at the presentations, and the panel discussion give us a sufficient body of work to review, and draw conclusions regarding the effect that the environment has as the most common cause of embedded sensor system failures. © 2018 Association for Computing Machinery. All rights reserved.",Adversarial Models; Taxonomy,Systems engineering; Taxonomies; Embedded sensors; Failsafe; Panel discussions; Panel session; Wireless sensor networks
Dogar F.R.,1,Towards slack-aware networking,2018,0,"Tufts University, United States",Tufts University,1,USA,1,39,21,"We are moving towards an Internet where most of the packets may be consumed by machines – set-top-boxes or smartphone apps prefetching content, Internet of Things (IoT) devices uploading their data to the cloud, or data centers doing geo-distributed replication. We observe that such machine centric communication can aord to have slack built into it: Every packet can be marked as to when it will be consumed in future. Slack could be anywhere from seconds to hours or even days. In this paper, we make a case for slack-aware networking by illustrating slack opportunities that arise for a wide range of applications as they interact with the cloud and its pricing models (e.g., spot pricing). We also sketch the design of SlackStack, a network stack with explicit support for slack at multiple levels of the stack, from a slack-based interface to slack-aware optimizations at the transport and network layers. © 2018 Association for Computing Machinery. All rights reserved.",Architecture; Cloud-pricing; Delay-tolerant; IoT; Slack,Architecture; Costs; Internet of things; Set-top boxes; Data centers; Delay tolerant; Internet of Things (IOT); Multiple levels; Network stack; Pricing models; Slack; Smartphone apps; Network layers
"Scheitle Q., Chung T., Hiller J., Gasser O., Naab J., Rijswijk-Deij R., Hohlfeld O., Holz R., Choffnes D., Mislove A., Carle G.",11,A first look at certification authority authorization (CAA),2018,5,"Technical University of Munich (TUM), Germany; Northeastern University, United States; RWTH Aachen, Germany; University of Twente and SURFnet, Netherlands; University of Sydney, Australia",Northeastern University;TU Munich;University of Sydney;University of Twente,4,Australia;Germany;Netherlands;USA,4,84,65,"Shaken by severe compromises, the Web’s Public Key Infrastructure has seen the addition of several security mechanisms over recent years. One such mechanism is the Certification Authority Authorization (CAA) DNS record, that gives domain name holders control over which Certification Authorities (CAs) may issue certificates for their domain. First defined in RFC 6844, adoption by the CA/B forum mandates that CAs validate CAA records as of September 8, 2017. The success of CAA hinges on the behavior of three actors: CAs, domain name holders, and DNS operators. We empirically study their behavior, and observe that CAs exhibit patchy adherence in issuance experiments, domain name holders configure CAA records in encouraging but error-prone ways, and only six of the 31 largest DNS operators enable customers to add CAA records. Furthermore, using historic CAA data, we uncover anomalies for already-issued certificates. We disseminated our results in the community. This has already led to specific improvements at several CAs and revocation of mis-issued certificates. Furthermore, in this work, we suggest ways to improve the security impact of CAA. To foster further improvements and to practice reproducible research, we share raw data and analysis tools. © 2018 Association for Computing Machinery. All rights reserved.",CAA; HTTPS Security; Web PKI,Distributed computer systems; HTTP; Public key cryptography; Analysis tools; Certification authorities; Error prones; HTTPS Security; Public key infrastructure; Reproducible research; Security mechanism; Web PKI; Internet protocols
"Cascone C., Pontarelli S., Bifulco R., Capone A.",4,Relaxing state-access constraints in stateful programmable data planes,2018,0,"Open Networking Foundation, United States; CNIT, Univ. Roma Tor Vergata, Italy; NEC Laboratories Europe, Germany; Politecnico di Milano, Italy",NEC;Politecnico di Milano;University Roma Tor Vergata,3,Germany;Italy;USA,3,25,18,"Supporting programmable stateful packet forwarding functions in hardware requires a tight balance between functionality and performance. Current state-of-the-art solutions are based on a very conservative model that assumes worst-case workloads. This finally limits the programmability of the system, even if actual deployment conditions may be very different from the worst-case scenario. We use trace-based simulations to highlight the benefits of accounting for specific workload characteristics. Furthermore, we show that relatively simple additions to a switching chip design can take advantage of such characteristics. In particular, we argue that introducing stalls in the switching chip pipeline enables stateful functions to be executed in a larger but bounded time without harming the overall forwarding performance. Our results show that, in some cases, the stateful processing of a packet could use 30x the time budget provided by state of the art solutions. © 2018 Association for Computing Machinery. All rights reserved.",Network data plane; NFV; Programmable switch; SDN,Budget control; Conservative modeling; Network data; Packet forwarding; Programmable switches; State of the art; Trace-based simulation; Workload characteristics; Worst case scenario; Network function virtualization
"Amiri S.A., Foerster K.-T., Jacob R., Schmid S.",4,Charting the algorithmic complexity of waypoint routing,2018,0,"MPI Saarland, Germany; Aalborg University, Denmark; IT University of Copenhagen, Denmark; University of Vienna, Austria",Aalborg University;IT University of Copenhagen;University of Vienna,3,Austria;Denmark;Germany,3,30,19,"Modern computer networks support interesting new routing models in which traffic flows from a source s to a destination t can be flexibly steered through a sequence of waypoints, such as (hardware) middleboxes or (virtualized) network functions (VNFs), to create innovative network services like service chains or segment routing. While the benefits and technological challenges of providing such routing models have been articulated and studied intensively over the last years, less is known about the underlying algorithmic traffic routing problems. The goal of this paper is to provide the network community with an overview of algorithmic techniques for waypoint routing and also inform about limitations due to computational hardness. In particular, we put the waypoint routing problem into perspective with respect to classic graph theoretical problems. For example, we find that while computing a shortest path from a source s to a destination t is simple (e.g., using Dijkstra’s algorithm), the problem of finding a shortest route from s to t via a single waypoint already features a deep combinatorial structure. © 2018 Association for Computing Machinery. All rights reserved.",Algorithms; Complexity; VNFs; Waypoints,Algorithms; Complex networks; Computer hardware; Graph theory; Parallel processing systems; Routing algorithms; Algorithmic complexity; Algorithmic techniques; Combinatorial structures; Complexity; Computational hardness; Technological challenges; VNFs; Waypoints; Computational complexity
"Saucez D., Iannone L.",2,Thoughts and recommendations from the ACM SIGCOMM 2017 reproducibility workshop,2018,1,"Univresit C te d’Azur, Inria, France; Telecom Paristech, France",Univresit C te d’Azur,1,France,1,12,7,"Ensuring the reproducibility of results is an essential part of experimental sciences, including computer networking. Unfortunately, as highlighted recently, a large portion of research results are hardly, if not at all, reproducible, raising reasonable lack of conviction on the research carried out around the world. Recent years have shown an increasing awareness about reproducibility of results as an essential part of research carried out by members of the ACM SIGCOMM community. To address this important issue, ACM has introduced a new policy on results and artifacts review and badging. The policy defines the terminology to be used to assess results and artifacts but does not specify the review process or how to make research reproducible. During SIGCOMM’17 a side workshop has been organized with the specific purpose to tackle this issue. The objective being to trigger discussion and activity in order to craft recommendations on how to introduce incentives for authors to share their artifacts, and the details on how to use them, as well as defining the process to be used. This editorial overviews the workshop activity and summarizes the main discussions and outcomes. © 2018 Association for Computing Machinery. All rights reserved.",Artifacts; Reproducibility; SIGCOMM,Artifacts; Computer networking; Editorial overview; Experimental science; Reproducibilities; Research results; Review process; SIGCOMM; Communication
"Foerster K.-T., Pignolet Y.-A., Schmid S., Tredan G.",4,Local fast failover routing with low stretch,2018,3,"Aalborg University, Denmark; ABB Corporate Research, Switzerland; University of Vienna, Austria; CNRS-LAAS, France",ABB Corporate Research;Aalborg University;University of Vienna,3,Austria;Denmark;France;Switzerland,4,22,12,"Network failures are frequent and disruptive, and can significantly reduce the throughput even in highly connected and regular networks such as datacenters. While many modern networks support some kind of local fast failover to quickly reroute flows encountering link failures to new paths, employing such mechanisms is known to be non-trivial, as conditional failover rules can only depend on local failure information. While over the last years, important insights have been gained on how to design failover schemes providing high resiliency, existing approaches have the shortcoming that the resulting failover routes may be unnecessarily long, i.e., they have a large stretch compared to the original route length. This is a serious drawback, as long routes entail higher latencies and introduce loads, which may cause the rerouted flows to interfere with existing flows and harm throughput. This paper presents the first deterministic local fast failover algorithms providing provable resiliency and failover route lengths, even in the presence of many concurrent failures. We present stretch-optimal failover algorithms for dierent network topologies, including multi-dimensional grids, hypercubes and Clos networks, as they are frequently deployed in the context of HPC clusters and datacenters. We show that the computed failover routes are optimal in the sense that no failover algorithm can provide shorter paths for a given number of link failures. © 2018 Association for Computing Machinery. All rights reserved.",Fast Reroute; Network Algorithms; Static Resiliency,Communication; Concurrent failures; Fast reroute; Multi-dimensional grids; Network algorithms; Network failure; Network topology; Regular networks; Static Resiliency; Clustering algorithms
"Flittner M., Mahfoudi M.N., Saucez D., Hlisch M.W., Iannone L., Bajpai V., Afanasyev A.",7,"A survey on artifacts from CoNEXT, ICN, IMC, and SIGCOMM conferences in 2017",2018,1,"Karlsruhe Institute of Technology, Germany; Universit Cote d’Azur, Inria, France; Freie Universit t Berlin, Germany; Telecom Paristech, France; Technical University of Munich, Germany; Florida International University, United States",Florida International University;Freie University Berlin;Karlsruhe Institute of Technology;TU Munich;Universit Cote d’Azur,5,France;Germany;USA,3,63,60,"Reproducibility of artifacts is a cornerstone of most scientific publications. To improve the current state and strengthen ongoing community efforts towards reproducibility by design, we conducted a survey among the papers published at leading ACM computer networking conferences in 2017: CoNEXT, ICN, IMC, and SIGCOMM. The objective of this paper is to assess the current state of artifact availability and reproducibility based on a survey. We hope that it will serve as a starting point for further discussions to encourage researchers to ease the reproduction of scientific work published within the SIGCOMM community. Furthermore, we hope this work will inspire program chairs of future conferences to emphasize reproducibility within the ACM SIGCOMM community as well as will strengthen awareness of researchers. © 2018 Association for Computing Machinery. All rights reserved.",Artifacts; Reproducibility; Survey,Communication; Surveying; Artifacts; Computer networking; Reproducibilities; Scientific publications; Surveys
"Arashloo M.T., Shirshov P., Gandhi R., Lu G., Yuan L., Rexford J.",6,A scalable VPN gateway for multi-tenant cloud services,2018,0,"Princeton University, United States; Microsoft, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Microsoft;Princeton University,3,USA,1,24,19,"Major cloud providers oer networks of virtual machines with private IP addresses as a service on the cloud. To isolate the address space of dierent customers, customers are required to tunnel their traffic to a Virtual Private Network (VPN) gateway, which is typically a middlebox inside the cloud that internally tunnels each packet to the correct destination. To improve performance, an increasing number of enterprises connect directly to the cloud provider’s network at the edge, to a device we call the provider’s edge (PE). PE is a chokepoint for customer’s traffic to the cloud, and therefore a natural candidate for implementing network functions concerning customers’ virtual networks, including the VPN gateway, to avoid a detour to middleboxes inside the cloud. At the scale of today’s cloud providers, VPN gateways need to maintain information for around a million internal tunnels. We argue that no single commodity device can handle these many tunnels while providing a high enough port density to connect to hundreds of cloud customers at the edge. Thus, in this paper, we propose a hybrid architecture for the PE, consisting of a commodity switch, connected to a commodity server which uses Data-Plane Development Kit (DPDK) for fast packet processing. This architecture enables a variety of network functions at the edge by oering the benefits of both hardware and software data planes. We implement a scalable VPN gateway on our proposed PE and show that it matches the scale requirements of today’s cloud providers while processing packets close to line rate. © 2018 Association for Computing Machinery. All rights reserved.",Cloud Provider Edge; Middleboxes; Virtual Private Network Gateway,Network architecture; Sales; Transfer functions; Virtual addresses; Virtual private networks; Web services; Cloud providers; Commodity switches; Hardware and software; Hybrid architectures; Improve performance; Middleboxes; Network functions; Virtual private networks (VPN); Gateways (computer networks)
Ammar M.H.,1,"The service-infrastructure cycle, ossification, and the fragmentation of the Internet",2018,0,"School of Computer Science, Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech,1,USA,1,65,29,"In this article I will first argue that a Service-Infrastructure Cycle is fundamental to networking evolution. Networks are built to accommodate certain services at an expected scale. New applications and/or a significant increase in scale require a rethinking of network mechanisms which results in new deployments. Four decades-worth of iterations of this process have yielded the Internet as we know it today, a common and shared global networking infrastructure that delivers almost all services. I will further argue, using brief historical case studies, that success of network mechanism deployments often hinges on whether or not mechanism evolution follows the iterations of this Cycle. Many have observed that this network, the Internet, has become ossified and unable to change in response to new demands. In other words, after decades of operation, the Service-Infrastructure Cycle has become stuck. However, novel service requirements and scale increases continue to exert significant pressure on this ossified infrastructure. The result, I will conjecture, will be a fragmentation, the beginnings of which are evident today, that will ultimately fundamentally change the character of the network infrastructure. By ushering in a ManyNets world, this fragmentation will lubricate the Service-Infrastructure Cycle so that it can continue to govern the evolution of networking. I conclude this article with a brief discussion of the possible implications of this emerging ManyNets world on networking research. © 2018 Association for Computing Machinery. All rights reserved.",Bypass networks; Internet fragmentation; Network evolution; Network ossification; Routing protocol evolution,Bypass networks; Global networking; Network evolution; Network infrastructure; Network mechanism; New applications; Service infrastructure; Service requirements; Communication
"Reuter A., Bush R., Cunha I., Katz-Bassett E., Schmidt T.C., Wählisch M.",6,Towards a rigorous methodology for measuring adoption of RPKI route validation and filtering,2018,3,"Freie Universität Berlin, Germany; IIJ Research Lab, Dragon Research, Brazil; Universidade Federal de Minas Gerais, Brazil; Columbia University, United States; HAW Hamburg, Germany",Columbia University;Dragon Research;Freie University Berlin;IIJ Research Lab;Universidade Federal de Minas Gerais,5,Brazil;Germany;USA,3,24,20,"A proposal to improve routing security—Route Origin Authorization (ROA)—has been standardized. A ROA specifies which network is allowed to announce a set of Internet destinations. While some networks now specify ROAs, little is known about whether other networks check routes they receive against these ROAs, a process known as Route Origin Validation (ROV). Which networks blindly accept invalid routes? Which reject them outright? Which de-preference them if alternatives exist? Recent analysis attempts to use uncontrolled experiments to characterize ROV adoption by comparing valid routes and invalid routes [5]. However, we argue that gaining a solid understanding of ROV adoption is impossible using currently available data sets and techniques. Instead, we devise a verifiable methodology of controlled experiments for measuring ROV. Our measurements suggest that, although some ISPs are not observed using invalid routes in uncontrolled experiments, they are actually using dierent routes for (non-security) traffic engineering purposes, without performing ROV. We conclude with presenting three AS that do implement ROV as confirmed by the operators. © 2018 Association for Computing Machinery. All rights reserved.",BGP; Internet security; Routing policies; RPKI,Controlled experiment; Internet security; Rigorous methodologies; Routing policies; Routing security; RPKI; Traffic Engineering; Communication
"Cicalese D., Rossi D.",2,A longitudinal study of IP anycast,2018,1,"Telecom ParisTech, Université Paris Saclay, France",Université Paris Saclay,1,France,1,66,48,"IP anycast is a commonly used technique to share the load of a variety of global services. For more than one year, leveraging a lightweight technique for IP anycast detection, enumeration and geolocation, we perform regular IP monthly censuses. This paper provides a brief longitudinal study of the anycast ecosystem, and we additionally make all our datasets (raw measurements from PlanetLab and RIPE Atlas), results (monthly geolocated anycast replicas for all IP/24) and code available to the community. © 2018 Association for Computing Machinery. All rights reserved.",BGP; Geolocation; IP anycast; IP Census; Network monitoring,Surveys; Anycast; Geolocations; Global services; IP Census; Longitudinal study; Network Monitoring; PlanetLab; Raw measurements; Internet protocols
"Böttger T., Cuadrado F., Tyson G., Castro I., Uhlig S.",5,Open connect everywhere: A glimpse at the internet ecosystem through the lens of the netflix CDN,2018,1,"Queen Mary University of London, United Kingdom",Queen Mary University of London,1,UK,1,23,18,"The importance of IXPs to interconnect dierent networks and exchange trac locally has been well studied over the last few years. However, far less is known about the role IXPs play as a platform to enable large-scale content delivery and to reach a world-wide customer base. In this paper, we study the infrastructure deployment of a content hypergiant, Netix, and show that the combined worldwide IXP substrate is the major corner stone of its Content Delivery Network. This highlights the additional role that IXPs play in the Internet ecosystem, not just in terms of interconnection, but also allowing players such as Netix to deliver signicant amounts of trac. © 2018 Association for Computing Machinery. All rights reserved.",Content Delivery Networks; Hypergiants; Internet eXchange Points; Netix,Communication; Content delivery; Content delivery network; Customerbase; Hypergiants; Infrastructure deployments; Internet exchange points; Netix; Through the lens; Ecosystems
"Shadi K., Natarajan P., Dovrolis C.",3,Hierarchical IP flow clustering,2017,0,"Georgia Institute of Technology, United States; Cisco Systems, United States",Georgia Tech,1,USA,1,13,2,"The analysis of flow traces can help to understand a net-work's usage patterns. We present a hierarchical clustering algorithm for network flow data that can summarize ter-abytes of IP traffic into a parsimonious tree model. The method automatically finds an appropriate scale of aggregation so that each cluster represents a local maximum of the traffic density from a block of source addresses to a block of destination addresses. We apply this clustering method on NetFlow data from an enterprise network, find the largest traffic clusters, and analyze their stationarity across time. The existence of heavy-volume clusters that persist over long time scales can help network operators to perform usage-based accounting, capacity provisioning and traffic engineering. Also, changes in the layout of hierarchical clusters can facilitate the detection of anomalies and significant changes in the network workload.",Hierarchical clustering; NetFlow; Unsuper-learning,Hierarchical systems; Internet protocols; Trees (mathematics); Clustering methods; Enterprise networks; Hier-archical clustering; Hierarchical clustering algorithms; Hierarchical clusters; NetFlows; Traffic Engineering; Unsuper-learning; Clustering algorithms
"Bajpai V., Eravuchira S.J., Schönwälder J.",3,Dissecting last-mile latency characteristics,2017,1,"TU Munich, Germany; SamKnows Limited, United States; Jacobs University Bremen, Germany",Jacobs University Bremen;TU Munich,2,Germany;USA,2,33,31,"Recent research has shown that last-mile latency is a key network performance indicator that contributes heavily to DNS lookup and page load times. Using a month-long dataset collected from 696 residential RIPE Atlas probes and 1245 SamKnows probes, we measure last-mile latencies from 19 ISPs (RIPE Atlas) in the US and the EU, and 9 ISPs (SamKnows) in the UK. We show that DSL deployments not only tend to enable interleaving on the lastmile, but also employ multiple depth levels that change over time. We also witness that last-mile latency is considerably stable over time and not affected by diurnal load patterns. Unlike observations from prior studies, we show that cable providers in the US do not generally exhibit lower last-mile latencies when compared to that of DSL. We instead identify that last-mile latencies vary by subscriber location and show that last-mile latencies of cable providers in the US are considerably different across the US east and west coast. We further show that last-mile latencies vary depending on the access technology used by the DSL modem wherein VDSL deployments show last-mile latencies lower than ADSL1/ADSL2+ broadband speeds. The entire dataset and software used in this study is made available [2] to the measurement community.Grant:-We like to thank Sam Crawford (SamKnows) for providing us traceroute datasets collected within UK access networks and giving us permission to release an anonymised version of the trace. We also thank Philip Eardley (BT) and Trevor Burbridge (BT) for reviewing our analysis. This work received funding from the European Unionâ?A Zs Horizon 2020 research and innovation programme 2014-2018 under grant agreement No. 644866, Scalable and Secure Infrastructures for Cloud Operations (SSICLOPS). This work was also partially supported by the European Communityâ?A Zs Seventh Framework Programme in (FP7/2007-2013) Grant No. 317647 (Leone) and by Flamingo, a Network of Excellence project (ICT-318488) supported by the European Commission under its Seventh Framework Programme.",Home networks; Last-mile latency; RIPE atlas; SamKnows,Cables; Digital subscriber lines; Home networks; International law; Internet service providers; Modems; Personal communication systems; Probes; European Commission; European community; Last mile; Performance indicators; Recent researches; RIPE atlas; SamKnows; Subscriber locations; DSL
"Panwar G., Tourani R., Mick T., Mtibaa A., Misra S.",5,DICE: Dynamic multi-RAT selection in the ICN-enabled wireless edge,2017,1,"New Mexico State University, United States",New Mexico State University,1,Mexico;USA,2,22,17,"Coupled with the rapid increase in mobile device users and the bandwidth and latency demands are the continuous increase of devices' processing capabilities, storage, and wireless connectivity options. The multiple radio access technology (multi-RAT) is proposed to satisfy mobile users' increasing needs. The Information-Centric Networking (ICN) paradigm is better tuned (than the current Internet Protocol approach) to support multi-RAT communications. ICN eschews the connection-based content retrieval model used today and has desirable features such as data naming, in-network caching, and device mobility-a paradigm ripe for exploration. We propose DICE, an ICN forwarding strategy that helps a device dynamically select a subset of its multi-RAT interfaces for communication. DICE assesses the state of edge links and network congestion to determine the minimum number of interfaces required to to perform data delivery. We perform simulations to compare DICE's performance with bestroute2 and multicast strategies (part of the named data networking simulator, ndnSIM). We show that DICE is the best of both worlds: providing a higher delivery ratio (0.2-2 times) and much lower overhead (by 2-8 times) for different packet rates.",5G; Forwarding strategy; ICN; Multi-RAT; NDN,Digital storage; Interface states; Mobile devices; Mobile telecommunication systems; Desirable features; Forwarding strategies; Information-centric networkings (ICN); Mobile device users; Named data networkings; Network congestions; Processing capability; Wireless connectivities; Rats
"Bajpai V., Ahsan S., Schönwälder J., Ott J.",4,Measuring YouTube content delivery over IPv6,2017,1,"TU Munich, Germany; Aalto University, Finland; Jacobs University Bremen, Germany",Aalto University;Jacobs University Bremen;TU Munich,3,Finland;Germany,2,38,37,"We measure YouTube content delivery over IPv6 using ?100 Sam-Knows probes connected to dual-stacked networks representing 66 different origin ASes. Using a 34-months long (Aug 2014-Jun 2017) dataset, we show that success rates of streaming a stall-free version of a video over IPv6 have improved over time. We show that a Happy Eyeballs (HE) race during initial TCP connection establishment leads to a strong (more than 97%) preference over IPv6. However, even though clients prefer streaming videos over IPv6, we observe worse performance over IPv6 than over IPv4. We witness consistently higher TCP connection establishment times and startup delays (?100 ms or more) over IPv6. We also observe consistently lower achieved throughput both for audio and video over IPv6. We observe less than 1% stall rates over both address families. Due to lower stall rates, bitrates that can be reliably streamed over both address families are comparable. However, in situations, where a stall does occur, 80% of the samples experience higher stall durations that are at least 1s longer over IPv6 and have not reduced over time. The worse performance over IPv6 is due to the disparity in the availability of Google Global Caches (GGC) over IPv6. The measurements performed in this work using the youtube test and the entire dataset is made available [5] to the measurement communityGrant:-We like to thank Sam Crawford and Jamie Mason for providing us support on the SamKnows infrastructure and to all volunteers who host a probe for us. This work was supported by the European Commission Horizon 2020 Programme RIFE Project Grant No. 644663. This work was also supported by the European Communitys Seventh Framework Programme in (FP7/2007-2013) Grant No. 317647 (Leone) and funded by Flamingo, a Network of Excellence project (ICT-318488) supported by the European Commission under its Seventh Framework Programme.",IPv6; Performance; SamKnows; YouTube,Probes; Statistical tests; Transmission control protocol; Content delivery; Different origins; European Commission; IPv6; Performance; SamKnows; Streaming videos; YouTube; Internet protocols
"Primorac M., Bugnion E., Argyraki K.",3,How to measure the killer microsecond,2017,0,"EPFL, Switzerland","EPFL,Switzerland",1,Switzerland,1,31,27,"Datacenter-networking research requires tools to both generate traffic and accurately measure latency and throughput. While hardware-based tools have long existed commercially, they are primarily used to validate ASICs and lack exibility, e.g., to study new protocols. They are also too expensive for academics. The recent development of kernel-bypass networking and advanced NIC features such as hardware timestamping have created new opportunities for accurate latency measurements. This paper compares these two approaches, and in particular whether commodity servers and NICs, when properly configured, can measure the latency distributions as precisely as specialized hardware. Our work shows that well-designed commodity solutions can capture subtle differences in the tail latency of stateless UDP traffic. We use hardware devices as the ground truth, both to measure latency and to forward traffic. We compare the ground truth with observations that combine five latency-measuring clients and five diffent port forwarding solutions and configurations. State-of-the-art software such as MoonGen that uses NIC hardware timestamping provides sufficient visibility into tail latencies to study the effect of subtle operating system configuration changes. We also observe that the kernel-bypass-based TRex software, that only relies on the CPU to timestamp traffic, can also provide solid results when NIC timestamps are not available for a particular protocol or device.Grant:-The authors thank Intel Corp, who gave us access to the hard-ware we used, and in particular Mesut A. Ergin, Ren Wang and Charlie Tai. This research is suppored in part by an Intel grant, a VMware grant, and the Microsoft-EPFL Joint Research Center.",Microsecond latency,Hardware; Negative impedance converters; Rhenium compounds; Hardware devices; Joint Research centers; Kernel bypass; Latency measurements; Microsecond latency; Specialized hardware; State of the art; System configurations; Computer hardware
"Raman A., Sastry N., Sathiaseelan A., Chandria J., Secker A.",5,Wi-stitch: Content delivery in converged edge networks,2017,0,"King's College London, United Kingdom; University of Cambridge, United Kingdom; BBC R and D, United Kingdom",BBC R and D;Kings College London;University of Cambridge,3,UK,1,31,25,"Wi-Fi, the most commonly used access technology at the very edge, supports download speeds that are orders of mag-nitude faster than the average home broadband or cellular data connection. Furthermore, it is extremely common for users to be within reach of their neighbours' Wi-Fi access points. Given the skewed nature of interest in content items, it is likely that some of these neighbours are interested in the same items as the users. We sketch the design of Wi-Stitch, an architecture that exploits these observations to construct a highly efficient content sharing infrastructure at the very edge and show through analysis of a real workload that it can deliver substantial (up to 70%) savings in network traffic. The Wi-Stitch approach can be used both by clients of fixed-line broadband, as well as mobile devices obtaining indoors access in converged networks.",Content sharing; Edge cooperation; Wifi ofloading,Communication; Access technology; Content delivery; Content Sharing; Converged networks; Data connection; Edge cooperation; Real workloads; Wi-fi access points; Wireless local area networks (WLAN)
"Sheoran A., Sharma P., Fahmy S., Saxena V.",4,Contain-ed: An NFV micro-service system for containing E2E latency,2017,0,"Purdue University, United States; Hewlett Packard Labs, United States; Hewlett Packard Enterprise, United States",Purdue University,1,USA,1,19,8,"Network Functions Virtualization (NFV) has enabled opera-tors to dynamically place and allocate resources for network services to match workload requirements. However, un-bounded end-to-end (e2e) latency of Service Function Chains (SFCs) resulting from distributed Virtualized Network Func-tion (VNF) deployments can severely degrade performance. In particular, SFC instantiations with inter-data center links can incur high e2e latencies and Service Level Agreement (SLA) violations. These latencies can trigger timeouts and protocol errors with latency-sensitive operations. Traditional solutions to reduce e2e latency involve physi-cal deployment of service elements in close proximity. These solutions are, however, no longer viable in the NFV era. In this paper, we present our solution that bounds the e2e la-tency in SFCs and inter-VNF control message exchanges by creating micro-service aggregates based on the affinity between VNFs. Our system, Contain-ed, dynamically cre-ates and manages affinity aggregates using light-weight vir-tualization technologies like containers, allowing them to be placed in close proximity and hence bounding the e2e la-tency. We have applied Contain-ed to the Clearwater [1] IP Multimedia Subsystem and built a proof-of-concept. Our results demonstrate that, by utilizing application and pro-tocol specific knowledge, affinity aggregates can effectively bound SFC delays and significantly reduce protocol errors and service disruptions.",Containers; Network functions virtualization,Aggregates; Cesium compounds; Containers; Quality of service; Transfer functions; Virtual reality; Virtualization; IP multimedia subsystems; Network functions; Network services; Service disruptions; Service elements; Service functions; Service Level Agreements; Specific knowledge; Network function virtualization
"Bjørner N., Canini M., Sultana N.",3,Report on networking and programming languages 2017,2017,1,"Microsoft Research, United States; KAUST, Saudi Arabia; University of Pennsylvania, United States",Microsoft;University of Pennsylvania,2,Saudi Arabia;USA,2,4,4,"The third workshop on Networking and Programming Lan-guages, NetPL 2017, was held in conjunction with SIG-COMM 2017. The workshop series attracts invited speakers from academia and industry and a selection of contributed abstracts for short presentations. NetPL brings together re-searchers from the networking community and researchers from the programming languages and verification communities. The workshop series is a timely forum for exciting trends, technological and scientific advances in the intersection of these communities. We describe some of the high-lights from the invited talks through the lens of three trends: Advances in network machine architectures, network programming abstractions, and network verification. NetPL included five invited speakers, four from academia, and one from industry. The program contained six contributed talks out of eight submitted for presentation. The workshop organizers reviewed the abstracts for quality and scope. A total of 42 registrations were received and the attendance occupied the lecture room to the brink. Slides and abstracts from all talks are available from the workshop home page.1 Videos of the presentations are available in the NetPL YouTube channel.2.",Network verification; Programming languages; Software defined networking,Abstracting; Computer programming languages; Network architecture; Software defined networking; Verification; High lights; In networks; Invited talk; Network programming; Networking community; Scientific advances; Through the lens; YouTube; Computer programming
"Gao Q., Dey P., Ahammad P.",3,Perceived performance of top retail webpages in the wild,2017,0,"Instart Logic Inc, 450 Lambert Ave, Palo Alto, CA, United States",Instart Logic,1,USA,1,22,11,"Clearly, no one likes webpages with poor quality of experience (QoE). Being perceived as slow or fast is a key element in the overall perceived QoE of web applications. While extensive effort has been put into optimizing web applications (both in industry and academia), not a lot of work exists in characterizing what aspects of webpage loading process truly inuence human end-user's perception of the Speed of a page. In this paper we present SpeedPerception, a large-scale web performance crowdsourcing framework focused on understanding the perceived loading performance of above-the-fold (ATF) webpage content. Our end goal is to create free open-source benchmarking datasets to advance the systematic analysis of how humans perceive webpage loading process. In Phase-1 of our SpeedPerception study using Internet Retailer Top 500 (IR 500) websites, we found that commonly used navigation metrics such as onLoad and Time To First Byte (TTFB) fail (less than 60% match) to represent majority human perception when comparing the speed of two webpages. We present a simple 3-variable-based machine learning model that explains the majority end-user choices better (with 87 2% accuracy). In addition, our results suggest that the time needed by end-users to evaluate relative perceived speed of webpage is far less than the time of its visualComplete eventGrant:-We thank Estelle Weyl, Patrick Meenan (WebPagetest), and Ilya Grigorik for evangelizing SpeedPerception and gen-erating significant user participation. We thank Paul Irish, Pierre-Marie Dartus, Shubhie Panicker, and Addy Osmani for independently evaluating and porting PSI to Google Chrome Lighthouse project.",Above-the-fold; Crowdsourcing; OnLoad; Perceived speed; Perceptual SpeedIndex; Quality of experience; SpeedIndex; TTFB; Web performance,Crowdsourcing; Learning systems; Open systems; Websites; Above-the-fold; OnLoad; Perceptual SpeedIndex; Quality of experience (QoE); SpeedIndex; TTFB; Web performance; Quality of service
"Mastorakis S., Afanasyev A., Zhang L.",3,On the evolution of ndn SIM: An open-source simulator for NDN experimentation,2017,13,"UCLA, United States",University of California Los Angeles,1,USA,1,56,35,"As a proposed Internet architecture, Named Data Networking (NDN) takes a fundamental departure from today's TCP/IP architecture, thus requiring extensive experimentation and evaluation. To facilitate such experimentation, we have developed ndnSIM, an open-source NDN simulator based on the NS-3 simulation framework. Since its first release in 2012, ndnSIM has gone through five years of active development and integration with the NDN prototype implementations, and has become a popular platform used by hundreds of researchers around the world. This paper presents an overview of the ndnSIM design, the ndnSIM development process, the design tradeoffs, and the reasons behind the design decisions. We also share with the community a number of lessons we have learned in the process.",Evaluation; Information-centric networking; Named data networking; NdnSIM; NS-3; Simulation,Communication; Evaluation; Information-centric networkings; Named data networkings; NdnSIM; Simulation; Network architecture
"Voitalov I., Aldecoa R., Wang L., Krioukov D.",4,Geohyperbolic routing and addressing schemes,2017,3,"Northeastern University, United States; University of Memphis, United States",Northeastern University;University of Memphis,2,USA,1,34,26,"The key requirement to routing in any telecommunication network, and especially in Internet-of-Things (IoT) networks, is scalability. Routing must route packets between any source and destination in the network without incurring unmanageable routing overhead that grows quickly with increasing network size and dynamics. Here we present an addressing scheme and a coupled network topology design scheme that guarantee essentially optimal routing scalability. The FIB sizes are as small as they can be, equal to the number of adjacencies a node has, while the routing control overhead is minimized as nearly zero routing control messages are exchanged even upon catastrophic failures in the network. The key new ingredient is the addressing scheme, whichis purelylocal, based onlyongeographic coordinates of nodes and a centrality measure, and does not require any sophisticated non-local computations or global network topology knowledge for network embedding. The price paid for these benefits is that network topology cannot be arbitrary but should follow a specific design, resulting in Internet-like topologies. The proposed schemes can be most easily deployed in overlay networks, and also in other network deployments, where geolocation information is available, and where network topology can grow following the design specifications.",Addressing; Hyperbolic routing; Routing; Scalability,Internet of things; Scalability; Topology; Addressing; Catastrophic failures; Design specification; Hyperbolic routing; Internet of Things (IOT); Internet-like topology; Routing; Routing control messages; Network routing
"Schönwälder J., Friedman T., Pras A.",3,Using networks to teach about networks (report on dagstuhl seminar #17112),2017,0,"Jacobs University, Bremen, Germany; UPMC Sorbonne Universités, Paris, France; University of Twente, Enschede, Netherlands",Jacobs University Bremen;UPMC Sorbonne Universités;University of Twente,3,France;Germany;Netherlands,3,16,11,"This report summarizes a two and a half days Dagstuhl seminar on Using Networks to Teach About Networks. The seminar brought together people with mixed backgrounds in order to exchange experiences gained with different approaches to teach computer networking. Despite the obvious question of what to teach, special attention was given to the questions of how to teach and which tools and infrastructures can be used effectively today for teaching purposes.",Computer networks; Education,Communication; Education; Computer networking; Computer networks
"Claffy K.C., Clark D.",2,Workshop on internet economics (WIE2016) final report,2017,0,"UCSD/CAIDA, United States; MIT/CSAIL, United States",MIT,1,USA,1,27,22,"On December 8-9 2016, CAIDA hosted the 7th interdis- ciplinary Workshop on Internet Economics (WIE) at the UC San Diego's Supercomputer Center. This workshop se- ries provides a forum for researchers, Internet facilities and service providers, technologists, economists, theorists, pol- icy makers, and other stakeholders to inform current and emerging regulatory and policy debates. This year we first returned to the list of aspirations we surveyed at the 2014 workshop, and described the challenges of mapping them to actions and measurable progress. We then reviewed evo- lutionary shifts in traffic, topology, business, and regula-Tory models, and (our best understanding of) the economics of the ecosystem. These discussions inspired an extended thought experiment for the second day of the workshop: out- lining a new telecommunications legislative framework, in- cluding proposing a set of goals and scope of such regulation, and minimal list of sections required to pursue and measure progress toward those goals. The format was a series of fo- cused sessions, where presenters prepared 10-minute talks on relevant issues, followed by in-depth discussions. This report highlights the discussions and presents relevant open research questions identified by participants.",Economics; Interconnection; Internet; Network management,Internet; Network management; Supercomputers; Interconnection; Internet economics; Legislative frameworks; Policy debates; Research questions; San Diego; Service provider; Thought experiments; Economics
Choffnes D.,1,Summary of the works-in-progress session at IMC 2016,2017,0,"Northeastern University, United States",Northeastern University,1,USA,1,2,2,"The Internet Measurement Conference provided a formal worksin- progess (WiP) session in November, 2016. This report describes the process for organizing and selecting participants, the format of the event, and summaries of the work presented.",Internet measurement; Work in progress,Internet measurement; Work in progress; Communication
"Durairajan R., Barford P.",2,A techno-economic approach for broadband deployment in underserved areas,2017,1,"University of Wisconsin-Madison, United States; University of Wisconsin-Madison, ComScore, Inc., United States",University of Wisconsin-Madison,1,USA,1,42,17,"A large body of economic research has shown the strong correlation between broadband connectivity and economic productivity (e.g., [1-3]). These findings motivate government agencies such as the FCC in the US to provide incentives to services providers to deploy broadband infrastructure in unserved or underserved areas. In this paper, we describe a framework for identifying target areas for network infrastructure deployment. Our approach considers (i) infrastructure availability, (ii) user demographics, and (iii) deployment costs. We use multi-objective optimization to identify geographic areas that have the highest concentrations of un/underserved users and that can be upgraded at the lowest cost. To demonstrate the efficacy of our framework, we consider physical infrastructure and demographic data from the US and two different deployment cost models. Our results identify a list of counties that would be attractive targets for broadband deployment from both cost and impact perspectives. We conclude with discussion on the implications and broader applications of our framework.",Broadband deployment targets; Multi-criteria optimization; Underserved areas,Costs; Multiobjective optimization; Population statistics; Broadband connectivity; Broadband deployment; Broadband infrastructure; Economic productivity; Government agencies; Multicriteria optimization; Network infrastructure; Under-served areas; Broadband networks
"Yan L., McKeown N.",2,Learning networking by reproducing research results,2017,11,"Stanford University, United States",Stanford University,1,USA,1,30,27,"In the past five years, the graduate networking course at Stanford has assigned over 200 students the task of repro- ducing results from over 40 networking papers. We began the project as a means of teaching both engineering rigor and critical thinking, qualities that are necessary for careers in networking research and industry. We have observed that reproducing research can simultaneously be a tool for edu- cation and a means for students to contribute to the net- working community. Through this editorial we describe our project in reproducing network research and show through anecdotal evidence that this project is important for both the classroom and the networking community at large, and we hope to encourage other institutions to host similar class projects.",Reproducible research; Teaching computer networks,Industrial research; Professional aspects; Teaching; Anecdotal evidences; Class projects; Critical thinking; Networking community; Reproducible research; Research results; Show through; Teaching computer network; Students
"Sargent M., Kristoff J., Paxson V., All M.",4,On the potential abuse of IGMP,2017,2,"Case Western Reserve University, Berkeley, United States; DePaul University, Berkeley, United States; International Computer Science Institute, Berkeley, United States; University of California, Berkeley, United States",Case Western Reserve University;DePaul University;University of California Berkeley,3,USA,1,24,10,"In this paper we investigate the vulnerability of the Internet Group Management Protocol (IGMP) to be leveraged for denial-of-service (DoS) attacks. IGMP is a connectionless protocol and therefore susceptible to attackers spoofing a third-party victim's source address in an e?ort to coax responders to send their replies to the victim. We find 305K IGMP responders that will indeed answer queries from arbitrary Internet hosts. Further, the responses are often larger than the requests, hence amplifying the attacker's own expenditure of bandwidth. We conclude that attackers can coordinate IGMP responders to mount sizeable DoS attacks.",Attacks; Denial-of-Service; IGMP; Security,Computer crime; Internet protocols; Query processing; Attacks; Denial of Service; IGMP; Internet group management protocol; Internet hosts; Security; Source address; Third parties; Denial-of-service attack
"Ngai E., Ohlman B., Tsudik G., Uzun E., Wahlisch M., Wood C.A.",6,Can we make a cake and eat it too? a discussion of icn security and privacy,2017,3,"Uppsala UniversitySE, Sweden; Ericsson ResearchSE, Sweden; University of California Irvine, United States; Xerox PARC, United States; Freie University BerlinDE, Germany",Ericsson Research;Freie University Berlin;University of California Irvine;Uppsala University,4,Germany;Sweden;USA,3,32,31,"In recent years, Information-centric Networking (ICN) has received much attention from both academic and industry participants. ICN offers data-centric inter-networking that is radically different from today's host-based IP networks. Security and privacy features on today's Internet were originally not present and have been incrementally retrofitted over the last 35 years. As such, these issues have become increasingly important as ICN technology gradually matures towards real-world deployment. Thus, while ICN-based architectures (e.g., NDN, CCNx, etc.) are still evolving, it is both timely and important to explore ICN security and privacy issues as well as devise and assess possible mitigation techniques. This report documents the highlights and outcomes of the Dagstuhl Seminar 16251 on ""Information-centric Networking and Security."" The goal of which was to bring together researchers to discuss and address security and privacy issues particular to ICN-based architectures. Upon finishing the three-day workshop, the outlook of ICN is still unclear. Many unsolved and ill-addressed problems remain, such as namespace and identity management, object security and forward secrecy, and privacy. Regardless of the fate of ICN, one thing is certain: much more research and practical experience with these systems is needed to make progress towards solving these arduous problems.",Information-Centric Networking; Security and Privacy,Communication; Identity management; Information-centric networkings; Information-centric networkings (ICN); Mitigation techniques; nocv1; Practical experience; Real world deployment; Security and privacy; Security and privacy issues; Network architecture
"Hollick M., Nita-Rotaru C., Papadimitratos P., Perrig A., Schmid S.",5,Toward a taxonomy and attacker model for secure routing protocols,2017,4,"TU Darmstadt, Germany; Northeastern University, United States; KTH, Sweden; ETH, Switzerland; Aalborg University, Denmark",Aalborg University;Northeastern University;TU Darmstadt,3,Denmark;Germany;Sweden;Switzerland;USA,5,19,8,"A secure routing protocol represents a foundational building block of a dependable communication system. Unfortunately, currently no taxonomy exists to assist in the design and analysis of secure routing protocols. Based on the Dagstuhl Seminar 15102, this paper initiates the study of more structured approaches to describe secure routing protocols and the corresponding attacker models, in an effort to better understand existing secure routing protocols, and to provide a framework for designing new protocols. We decompose the routing system into its key components based on a functional model of routing. This allows us to classify possible attacks on secure routing protocols. Using our taxonomy, we observe that the most effective attacks target the information in the control plane. Accordingly, unlike classic attackers whose capabilities are often described in terms of computation complexity we propose to classify the power of an attacker with respect to the reach, that is, the extent to which the attacker can influence the routing information indirectly, beyond the locations under its direct control.",Adversarial Models; Taxonomy,Classification (of information); Taxonomies; Attacker models; Building blockes; Computation complexity; Design and analysis; Functional model; Routing information; Secure routing protocols; Structured approach; Routing protocols
"Davie B., Koponen T., Pfaff B., Pettit J., Chanda A., Casado M., Duda K., Gude N., Padmanabhan A., Petty T.",10,A database approach to SDN control plane design,2017,9,"VMware, Canada; Styra, Canada; Arista Networks, United States; Facebook, United States",Facebook,1,Canada;USA,2,33,24,"Software-defined networking (SDN) is a well-known example of a research idea that has been reduced to practice in numerous settings. Network virtualization has been successfully developed commercially using SDN techniques. This paper describes our experience in developing production-ready, multi-vendor implementations of a complex network virtualization system. Having struggled with a traditional network protocol approach (based on OpenFlow) to achieving interoperability among vendors, we adopted a new approach. We focused first on defining the control information content and then used a generic database protocol to synchronize state between the elements. Within less than nine months of starting the design, we had achieved basic interoperability between our network virtualization controller and the hardware switches of six vendors. This was a qualitative improvement on our decidedly mixed experience using OpenFlow. We found a number of benefits to the database approach, such as speed of implementation, greater hardware diversity, the ability to abstract away implementation details of the hardware, clarified state consistency model, and extensibility of the overall system.",databases; interoperability; protocol design; protocols; Software-Defined Networking (SDN),Complex networks; Database systems; Hardware; Interoperability; Network protocols; Software defined networking; Virtual reality; Consistency model; Control information; Database approaches; Generic database; Hardware diversity; Network virtualization; Protocol design; Software defined networking (SDN); Internet protocols
"Bustamante F.E., Clark D., Feamster N.",3,Workshop on tracking quality of experience in the internet: Summary and outcomes,2017,0,"Northwestern U., Norway; MIT, Norway; Princeton U., Norway",MIT;Northwestern University;Princeton University,3,Norway,1,22,20,"This is a report on the Workshop on Tracking Quality of Experience in the Internet, held at Princeton, October 21{ 22, 2015, jointly sponsored by the National Science Foundation and the Federal Communication Commission. The term Quality of Experience (QoE) describes a user's subjective assessment of their experience when using a particular application. In the past, network engineers have typically focused on Quality of Service (QoS): performance metrics such as throughput, delay and jitter, packet loss, and the like. Yet, performance as measured by QoS parameters only matters if it affects the experience of users, as they attempt to use a particular application. Ultimately, the user's experience is determined by QoE impairments (e.g., rebuffering). Although QoE and QoS are related|for example, a video rebuffering event may be caused by high packet-loss rate| QoE metrics ultimately affect a user's experience. Identifying the causes of QoE impairments is complex, since the impairments may arise in one or another region of the network, in the home network, on the user's device, in servers that are part of the application, or in supporting services such as the DNS. Additionally, metrics for QoE continue to evolve, as do the methods for relating QoE impairments to underlying causes that could be measurable using standard network measurement techniques. Finally, as the capabilities of the underlying network infrastructure continues to evolve, researchers should also consider how to design infrastructure and tools can best support measurements that can better identify the locations and causes of QoE impairments. The workshop's aim was to understand the current state of QoE research and to contemplate a community agenda to integrate ongoing threads of QoE research into a collaboration. This summary report describes the topics discussed and summarize the key points of the discussion. Materials related to the workshop are available at http://aqualab.cs. northwestern.edu/NSFWorkshop-InternetQoE.",Internet; measurement techniques; Quality of Experience,Complex networks; Internet; Packet loss; Packet networks; Personal communication systems; Wireless telecommunication systems; Design infrastructures; Federal Communication Commission; Measurement techniques; National Science Foundations; Network measurement; Quality of experience (QoE); Subjective assessments; Underlying networks; Quality of service
"Posch D., Rainer B., Hellwagner H.",3,Towards a context-aware forwarding plane in named data networking supporting QoS,2017,6,"Institute of Information Technology, Alpen-Adria-Universitat Klagenfurt, Austria",Alpen-Adria-Universitat Klagenfurt,1,Austria,1,16,15,"The emergence of Information-Centric Networking (ICN) provides considerable opportunities for context-aware data distribution in the network's forwarding plane. While packet forwarding in classical IP-based networks is basically predetermined by routing, ICN foresees an adaptive forwarding plane considering the requirements of network applications. As research in this area is still at an early stage, most of the work so far focused on providing the basic functionality, rather than on considering the available context information to improve Quality of Service (QoS). This article investigates to which extent existing forwarding strategies take account of the available context information and can therefore increase service quality. The article examines a typical scenario encompassing di?erent user applications (Voice over IP, video streaming, and classical data transfer) with varying demands (context), and evaluates how well the applications' requirements are met by the existing strategies.",Context-Awareness; Forwarding; Information-Centric Networking; Named Data Networking; Quality of Service,Data transfer; Internet protocols; Network architecture; Semantics; Video streaming; Voice/data communication systems; Context information; Context- awareness; Forwarding; Forwarding strategies; Information-centric networkings; Information-centric networkings (ICN); Named data networkings; Network applications; Quality of service
"Qadir J., Sathiaseelan A., Wang L., Crowcroft J.",4,"""resource pooling"" for wireless networks: Solutions for the developing world",2016,2,"Information Technology University (ITU)-Punjab, Lahore, Pakistan; Computer Laboratory, University of Cambridge, United Kingdom",Information Technology University (ITU)-Punjab;University of Cambridge,2,Pakistan;UK,2,36,29,"We live in a world in which there is a great disparity between the lives of the rich and the poor. Technology offers great promise in bridging this gap. In particular, wireless technology unfetters developing communities from the constraints of infrastructure providing a great opportunity to leapfrog years of neglect and technological waywardness. In this paper, we highlight the role of resource pooling for wireless networks in the developing world. Resource pooling involves: (i) abstracting a collection of networked resources to behave like a single unified resource pool and (ii) developing mechanisms for shifting load between the various parts of the unified resource pool. The popularity of resource pooling stems from its ability to provide resilience, high utilization, and exibility at an acceptable cost. We show that ""resource pooling"", which is very popular in its various manifestations, is the key unifying principle underlying a diverse number of successful wireless technologies (such as white space networking, community networks, etc.). We discuss various applications of resource pooled wireless technologies and provide a discussion on open issues.",Network design principles; Resource pooling,Developing countries; Wireless telecommunication systems; Community networks; Developing communities; Developing world; High utilizations; Network design; Networked resources; Resource pooling; Wireless technologies; Wireless networks
"Bocchi E., De Cicco L., Rossi D.",3,Measuring the quality of experience of web users,2016,2,"Telecom ParisTech, France; Politecnico di Bari, Italy",Politecnico di Bari,1,France;Italy,2,21,10,"Measuring quality of Web users experience (WebQoE) faces the following trade-off. On the one hand, current practice is to resort to metrics, such as the document completion time (onLoad), that are simple to measure though knowingly inaccurate. On the other hand, there are metrics, like Google's SpeedIndex, that are better correlated with the actual user experience, but are quite complex to evaluate and, as such, relegated to lab experiments. In this paper, we first provide a comprehensive state of the art on the metrics and tools available for WebQoE assessment. We then apply these metrics to a representative dataset (the Alexa top-100 webpages) to better illustrate their similarities, differences, advantages, and limitations. We next introduce novel metrics, inspired by Google's SpeedIndex, that offer significant advantages in terms of computational complexity, while maintaining a high correlation with the SpeedIndex. These properties make our proposed metrics highly relevant and of practical use.",Above-the-fold; ByteIndex; DOM; MOS; ObjectIndex; OnLoad; Quality of experience; SpeedIndex; TTFB; TTFP; Web,Economic and social effects; Molybdenum; Websites; Above-the-fold; ByteIndex; ObjectIndex; OnLoad; Quality of experience (QoE); SpeedIndex; TTFB; TTFP; Quality of service
"Laufer R., Gallo M., Perino D., Nandugudi A.",4,CliMB: Enabling network function composition with click middleboxes,2016,0,"Nokia Bell Labs, United States; Telefonica Research, United States; INRIA, France",INRIA;Nokia;Telefonica Research,3,France;USA,2,20,18,"Click has significant advantages for middlebox development, including modularity, extensibility, and reprogrammability. Despite these features, Click still has no native TCP support and only uses nonblocking I/O, preventing its applicability to middleboxes that require access to application data and blocking I/O. In this paper, we attempt to bridge this gap by introducing Click middleboxes (CliMB). CliMB provides a full-edged modular TCP layer supporting TCP options, congestion control, both blocking and nonblocking I/O, as well as socket and zero-copy APIs to applications. As a result, any TCP network function may now be realized in Click using a modular L2-L7 design. As proof of concept, we develop a zero-copy SOCKS proxy using CliMB that shows up to 4x gains compared to an equivalent implementation using the Linux in-kernel network stack.",Click router; Middle boxes; TCP,Computer operating systems; Transfer functions; Application data; Middle boxes; Network functions; Network stack; Non-blocking; Proof of concept; Re-programmability; TCP networks; Transmission control protocol
Claffy K.,1,The 8th workshop on active internet measurements (AIMS-8) report,2016,0,"CAIDA, UCSD, United States",University of California San Diego,1,USA,1,17,7,"On 10-12 February 2016, CAIDA hosted the eighth Workshop on Active Internet Measurements (AIMS-8) as part of our series of Internet Statistics and Metrics Analysis (ISMA) workshops. This workshop series provides a forum for stake-holders in Internet active measurement projects to communicate their interests and concerns, and explore cooperative approaches to maximizing the collective benefit of deployed infrastructure and gathered measurements. Discussion topics included: infrastructure development status and plans; experimental design, execution, and cross-validation; challenges to incentivize hosting, sharing, and using measurement infrastructure; data access, sharing, and analytics; and challenges of emerging high bandwidth network measurement infrastructure. Other recurrent topics included paths toward increased interoperability and cooperative use of infrastructures, and ethical frameworks to support active Internet measurement. Materials related to the workshop are at http://www.caida.org/workshops/aims/1602/.",Active internet measurement; Active measurement; Validation cection,Communication; Active measurement; Cross validation; Data access; High-bandwidth networks; Infrastructure development; Internet measurement; nocv1; Stake holders; Validation cection; Internet
"Drago I., Ricciato F., Sadre R.",3,Report from the 6th PhD school on traffic monitoring and analysis (TMA),2016,0,"Politecnico di Torino, Italy; University of Ljubljana, Slovenia; Université Catholique de Louvain, Belgium",Politecnico di Torino;University of Ljubljana;Universite Catholique de Louvain,3,Belgium;Italy;Slovenia,3,9,3,This is a summary report by the organizers of the 6th TMA PhD school held in Louvain-la-Neuve on 5-6 April 2016. The insight and feedback received about the event might turn useful for the organization of future editions and similar events targeting students and young researchers.,Feedback; Lessons learned; Organization; PhD school,Feedback; Societies and institutions; Lessons learned; nocv1; PhD school; Traffic monitoring; Communication
"McCauley J., Liu Z., Panda A., Koponen T., Raghavan B., Rexford J., Shenker S.",7,Recursive SDN for carrier networks,2016,5,"UC Berkeley, United States; ICSI, United States; Tsinghua University, China; Styra, Greece; Princeton, United States",Tsinghua University;University of California Berkeley,2,China;Greece;USA,3,13,7,"Control planes for global carrier networks should be programmable and scalable. Neither traditional control planes nor new SDN-based control planes meet both of these goals. Here we propose a framework for recursive routing computations that combines the best of SDN (programmability through centralized controllers) and traditional networks (scalability through hierarchy) to achieve these two desired properties. Through simulation on graphs of up to 10,000 nodes, we evaluate our design's ability to support a variety of unicast routing and traffic engineering solutions, while incorporating a fast failure recovery mechanism based on network virtualization.",Carrier networks; Hierarchical networks; Network routing; SDN; Software defined networking,Communication; Software defined networking; Carrier networks; Centralized controllers; Fast failure recovery; Hierarchical network; Network virtualization; nocv1; Programmability; Traffic Engineering; Unicast routing; Network routing
"Gkounis D., Kotronis V., Liaskos C., Dimitropoulos X.",4,On the interplay of link-flooding attacks and traffic engineering,2016,10,"NEC Labs Europe, Germany; ETH Zurich, Switzerland; FORTH, Greece",ETH Zurich,1,Germany;Greece;Switzerland,3,25,19,"Link-flooding attacks have the potential to disconnect even entire countries from the Internet. Moreover, newly proposed indirect link-flooding attacks, such as ""Crossfire"", are extremely hard to expose and, subsequently, mitigate effectively. Traffic Engineering (TE) is the network's natural way of mitigating link overload events, balancing the load and restoring connectivity. This work poses the question: Do we need a new kind of TE to expose an attack as well? The key idea is that a carefully crafted, attack-aware TE could force the attacker to follow improbable traffic patterns, revealing his target and his identity over time. We show that both existing and novel TE modules can efficiently expose the attack, and study the benefits of each approach. We implement defense prototypes using simulation mechanisms and evaluate them extensively on multiple real topologies.",DDoS defense; Link-flooding attack; Traffic engineering,Communication; DDoS defense; Flooding attacks; Simulation mechanisms; Traffic Engineering; Traffic pattern; Floods
"Orwat C., Bless R.",2,Values and networks - Steps toward exploring their relationships,2016,3,"Karlsruhe Institute of Technology (KIT), Institute for Technology Assessment and Systems Analysis (ITAS), Germany; Karlsruhe Institute of Technology (KIT), Institute of Telematics (TM), Germany",Karlsruhe Institute of Technology,1,Germany,1,45,31,"Many technical systems of the Information and Communication Technology (ICT) sector enable, structure and/or constrain social interactions. Thereby, they influence or implement certain values, including human rights, and affect or raise conflicts among values. The ongoing developments toward an ""Internet of everything"" is likely to lead to further value conflicts. This trend illustrates that a better understanding of the relationships between social values and networks is urgently needed because it is largely unknown what values lie behind protocols, design principles, or technical and organizational options of the Internet. This paper focuses on the complex steps of realizing human rights in Internet architectures and protocols as well as in Internetbased products and services. Besides direct implementation of values in Internet protocols, there are several other options that can indirectly contribute to realizing human rights via political processes and market choices. Eventually, a better understanding of what values can be realized by networks in general, what technical measures may affect certain values, and where complementary institutional developments are needed may lead toward a methodology for considering technical and institutional systems together.",Communication protocols; Governance; Human rights; Institutions; Network design; Rules; Values,Complex networks; Internet; Network architecture; Network protocols; Social aspects; Societies and institutions; Governance; Human rights; Network design; Rules; Values; Internet protocols
"Bajpai V., Berger A.W., Eardley P., Ott J., Schönwälder J.",5,Global measurements: Practice and experience (report on dagstuhl seminar # 16012),2016,3,"Jacobs University, Bremen, Germany; Akamai Technologies, Cambridge, United States; British Telecom R and D, Ipswich, United Kingdom; TU München, München, Germany",Akamai Technologies;British Telecom R and D;Jacobs University Bremen;TU Munich,4,Germany;UK;USA,3,55,47,"This article summarises a 2.5 day long Dagstuhl seminar on Global Measurements: Practice and Experience held in January 2016. This seminar was a followup of the seminar on Global Measurement Frameworks held in 2013, which focused on the development of global Internet measurement platforms and associated metrics. The second seminar aimed at discussing the practical experience gained with building these global Internet measurement platforms. It brought together people who are actively involved in the design and maintenance of global Internet measurement platforms and who do research on the data delivered by such platforms. Researchers in this seminar have used data derived from global Internet measurement platforms in order to manage networks or services or as input for regulatory decisions. The entire set of presentations delivered during the seminar is made publicly available at [1].",Internet measurements; Network management; Quality of experience; Traffic engineering,Network management; Quality of service; Global Internet; Global measurements; Internet measurement; Practical experience; Practice and experience; Quality of experience (QoE); Regulatory decisions; Traffic Engineering; Internet
"Lukovszki T., Rost M., Schmid S.",3,It's a match! Near-optimal and incremental middlebox deployment,2016,22,"Eötvös Loránd University, Hungary; Technische Universität, Germany; Berlin Aalborg University, Germany",Aalborg University;Eotvos Lorand University;TU Berlin,3,Germany;Hungary,2,23,14,"The virtualization and softwarization of modern computer networks offers new opportunities for the simplified management and exible placement of middleboxes as e.g. firewalls and proxies. This paper initiates the study of algorithmically exploiting the exibilities present in virtualized and software-defined networks. Particularly, we are interested in the initial as well as the incremental deployment of middleboxes. We present a deterministic O(log(min{n; κ})) approximation algorithm for n-node computer networks, where κ is the middlebox capacity. The algorithm is based on optimizing over a submodular function which can be computed efficiently using a fast augmenting path approach. The derived approximation bound is optimal: the underlying problem is computationally hard to approximate within sublogarithmic factors, unless P = NP holds. We additionally present an exact algorithm based on integer programming, and complement our formal analysis with simulations. In particular, we consider the number of used middleboxes and highlight the benefits of the approximation algorithm in incremental deployments. Our approach also finds interesting applications, e.g., in the context of incremental deployment of software-defined networks.",Capacitated Set Cover; Facility Location; Network Virtualization; NFV; NP-hardness; Software-Defined Networking,Application programs; Computer networks; Computer software; Computer system firewalls; Computer viruses; Integer programming; Network function virtualization; Software defined networking; Virtual reality; Virtualization; Approximation bounds; Exact algorithms; Facility locations; Incremental deployment; Network virtualization; NP-hardness; Set cover; Submodular functions; Approximation algorithms
"Carlucci G., De Cicco L., Mascolo S.",3,Controlling queuing delays for real-time communication: The interplay of E2E and AQM algorithms,2016,2,"Politecnico di Bari, Italy",Politecnico di Bari,1,Italy,1,24,21,"Real-time media communication requires not only congestion control, but also minimization of queuing delays to provide interactivity. In this work we consider the case of real-time communication between web browsers (WebRTC) and we focus on the interplay of an end-to-end delay-based congestion control algorithm, i.e. the Google congestion control (GCC), with two delay-based AQM algorithms, namely CoDel and PIE, and two ow queuing schedulers, i.e. SFQ and Fq Codel. Experimental investigations show that, when only GCC ows are considered, the end-to-end algorithm is able to contain queuing delays without AQMs. Moreover the interplay of GCC ows with PIE or CoDel leads to higher packet losses with respect to the case of a DropTail queue. In the presence of concurrent TCP traffic, PIE and CoDel reduce the queuing delays with respect to DropTail at the cost of increased packet losses. In this scenario ow queuing schedulers offer a better solution.",Active Queue Management; Congestion Control; WebRTC,Congestion control (communication); Packet loss; Queueing theory; Scheduling; Web browsers; Active Queue Management; AQM algorithms; End to end delay; Experimental investigations; Interactivity; Real-time communication; Real-time media communication; WebRTC; Queueing networks
"Afanasyev A., Yu Y., Zhang L., Burke J., Claffy K., Polterock J.",6,The second named data networking Community Meeting (NDNcomm 2015),2016,2,"UCLA, United States; CAIDA, UCSD, United States",University of California Los Angeles;University of California San Diego,2,USA,1,26,13,"This report is a brief summary of the second NDN Community Meeting held at UCLA in Los Angeles, California on September 28-29, 2015. The meeting provided a platform for the attendees from 49 institutions across 13 countries to exchange their recent NDN research and development results, to debate existing and proposed functionality in NDN forwarding, routing, and security, and to provide feedback to the NDN architecture design evolution.",Architecture; Information-Centric Networking; Named Data Networking,Architecture; Architecture designs; California; Community meetings; Information-centric networkings; Los angeles; Named data networkings; Research and development; Communication
"Klöti R., Ager B., Kotronis V., Nomikos G., Dimitropoulos X.",5,A comparative look into public IXP datasets,2016,5,"ETH Zurich, Switzerland; FORTH, Greece",ETH Zurich,1,Greece;Switzerland,2,20,16,"Internet eXchange Points (IXPs) are core components of the Internet infrastructure where Internet Service Providers (ISPs) meet and exchange traffic. During the last few years, the number and size of IXPs have increased rapidly, driving the flattening and shortening of Internet paths. However, understanding the present status of the IXP ecosystem and its potential role in shaping the future Internet requires rigorous data about IXPs, their presence, status, participants, etc. In this work, we do the first cross-comparison of three well-known publicly available IXP databases, namely of PeeringDB, Euro-IX, and PCH. A key challenge we address is linking IXP identifiers across databases maintained by different organizations. We find different AS-centric versus IXP-centric views provided by the databases as a result of their data collection approaches. In addition, we highlight differences and similarities w.r.t. IXP participants, geographical coverage, and co-location facilities. As a side-product of our linkage heuristics, we make publicly available the union of the three databases, which includes 40.2% more IXPs and 66.3% more IXP participants than the commonly-used PeeringDB. We also publish our analysis code to foster reproducibility of our experiments and shed preliminary insights into the accuracy of the union dataset.",Internet Exchange Points; Internet topology; Peering databases,Database systems; Data collection; Future internet; Geographical coverage; Internet exchange points; Internet infrastructure; Internet topologies; Number and size; Reproducibilities; Internet service providers
"Shirali-Shahreza S., Ganjali Y.",2,ReWiFlow: Restricted wildcard openflow rules,2015,9,"Department of Computer Science, University of Toronto, Toronto, Canada",University of Toronto,1,Canada,1,20,19,"The ability to manage individual flows is a major benefit of Software-Defined Networking. The overheads of this fine-grained control, e.g. initial flow setup delay, can overcome the benefits, for example when we have many time-sensitive short flows. Coarse-grained control of groups of flows, on the other hand, can be very complex: each packet may match multiple rules, which requires conflict resolution. In this paper, we present ReWiFlow, a restricted class of OpenFlow wildcard rules (the fundamental way to control groups of flows in OpenFlow), which allows managing groups of flows with flexibility and without loss of performance. We demonstrate how ReWiFlow can be used to implement applications such as dynamic proactive routing. We also present a generalization of ReWiFlow, called Multi-ReWiFlow, and show how it can be used to efficiently represent access control rules collected from Stanford's backbone network.",Open Flow; Proactive Routing; SDN; Wildcard Rule,Complex networks; Network routing; Back-bone network; Conflict Resolution; Control groups; Fine-grained control; Loss of performance; Open flow; Proactive routing; Wildcard Rule; Access control
"Sarlis D., Papailiou N., Konstantinou I., Smaragdakis G., Koziris N.",5,Datix: A system for scalable network analytics,2015,6,"CSLAB, NTUA, Greece",";NTUA,Greece",2,Greece,1,32,23,"The ever-increasing Internet traffic poses challenges to net-work operators and administrators that have to analyze large network datasets in a timely manner to make decisions re-garding network routing, dimensioning, accountability and security. Network datasets collected at large networks such as Internet Service Providers (ISPs) or Internet Exchange Points (IXPs) can be in the order of Terabytes per hour. Un-fortunately, most of the current network analysis approaches are ad-hoc and centralized, and thus not scalable. In this paper, we present Datix, a fully decentralized, open-source analytics system for network traffic data that relies on smart partitioning storage schemes to support fast join algorithms and ecient execution of ltering queries. We outline the architecture and design of Datix and we present the evaluation of Datix using real traces from an operational IXP. Datix is a system that deals with an im-portant problem in the intersection of data management and network monitoring while utilizing state-of-The-Art dis-Tributed processing engines. In brief, Datix manages to ef-ciently answer queries within minutes compared to more than 24 hours processing when executing existing Python-based code in single node setups. Datix also achieves nearly 70% speedup compared to baseline query implementations of popular big data analytics engines such as Hive and Shark.",Hadoop; HBase; K-d Tree; Map-Join; MapReduce; sFlow,Big data; Digital storage; Engines; Internet; Internet service providers; Open systems; Query processing; Search engines; Hadoop; HBase; K-d tree; Map-reduce; sFlow; Information management
"Van Rijswijk-Deij R., Sperotto A., Pras A.",3,Making the case for elliptic curves in DNSSEC,2015,7,"University of Twente And SURFnet Bv, Netherlands; University of Twente, Netherlands",University of Twente;University of Twente,2,Netherlands,1,14,14,"The Domain Name System Security Extensions (DNSSEC) add authenticity and integrity to the DNS, improving its security. Unfortunately, DNSSEC is not without problems. DNSSEC adds digital signatures to the DNS, significantly increasing the size of DNS responses. This means DNSSEC is more susceptible to packet fragmentation and makes DNSSEC an attractive vector to abuse in amplificationbased denial-of-service attacks. Additionally, key management policies are often complex. This makes DNSSEC fragile and leads to operational failures. In this paper, we argue that the choice for RSA as default cryptosystem in DNSSEC is a major factor in these three problems. Alternative cryptosystems, based on elliptic curve cryptography (ECDSA and EdDSA), exist but are rarely used in DNSSEC. We show that these are highly attractive for use in DNSSEC, although they also have disadvantages. To address these, we have initiated research that aims to investigate the viability of deploying ECC at a large scale in DNSSEC.",Amplification attack; DDOS; DNS; DNSSEC; ECDSA; EDDSA; Elliptic curve cryptography; Fragmentation,Cryptography; Denial-of-service attack; Geometry; Internet protocols; Network security; Public key cryptography; Servers; DDOS; DNSSEC; ECDSA; EDDSA; Elliptic curve cryptography; Fragmentation; Intrusion detection
"Metwalley H., Traverso S., Mellia M., Miskovic S., Baldi M.",5,CrowdSurf: Empowering transparency in the web,2015,1,"DET, Politecnico di Torino, Italy; Politecnico di Torino, Italy; Symantec Corp, United States",Politecnico di Torino,1,Italy;USA,2,14,13,"Individuals lack proper means to supervise the services they contact and the information they exchange when surfing the web. This security task has become challenging due to the complexity of the modern web, of the data delivering technology, and even to the adoption of encryption, which, while improving privacy, makes innetwork services ineffective. The implications are serious, from a person contacting undesired services or unwillingly exposing private information, to a company being unable to control the flow of its information to the outside world. To empower transparency and the capability of taking informed choices in the web, we propose CROWDSURF, a system for comprehensive and collaborative auditing of data exchanged with Internet services. Similarly to crowdsourced efforts, we enable users to contribute in building awareness, supported by the semi-Automatic analysis of data offered by a cloud-based system. The result is the creation of ""suggestions"" that individuals can transform in enforceable ""rules"" to customize their web browsing policy. CROWDSURF provides the core infrastructure to let individuals and enterprises regain visibility and control on their web activity. Preliminary results obtained executing a prototype implementation demonstrate the feasibility and potential of CROWDSURF.",Crowdsourced systems; Privacy; Web Browsing,Data privacy; Electronic data interchange; Internet; Web browsers; Core infrastructure; Crowdsourced systems; In-network services; Internet services; Private information; Prototype implementations; Semi-automatics; Web activities; Transparency
"Sharma S., Jena S.K.",2,Cluster based multipath routing protocol for wireless sensor networks,2015,20,"International Institute of Information Technology, Bhubaneswar, India; National Institute of Technology, Rourkela, India",National Institute of Technology,1,India,1,12,10,"Wireless Sensor Network (WSN) consists of low power sensor nodes. Energy is the main constraint associated with the sensor nodes. In this paper, we propose a cluster based multipath routing protocol, which uses the clustering and multipath techniques to reduce energy consumption and increase the reliability. The basic idea is to reduce the load of the sensor node by giving more responsibility to the base station (sink). We have implemented and compared the protocol with existing protocols and found that it is more energy-efficient and reliable. © 2015, Association for Computing Machinery. All rights reserved.",Clustering; Energy efficient; Multipath; Routing protocol; Wireless sensor networks,Energy efficiency; Energy utilization; Internet protocols; Low power electronics; Mobile telecommunication systems; Network routing; Power management (telecommunication); Routing protocols; Sensor nodes; Cluster-based; Clustering; Energy efficient; Low power sensor; Multi-path techniques; Multipath; Multipath routing protocols; Reduce energy consumption; Wireless sensor networks
"Rost M., Fuerst C., Schmid S.",3,Beyond the stars: Revisiting virtual cluster embeddings,2015,11,"TU Berlin, Germany",TU Berlin,1,Germany,1,17,12,"It is well-known that cloud application performance can critically depend on the network. Over the last years, several systems have been developed which provide the application with the illusion of a virtual cluster : A star-shaped virtual network topology connecting virtual machines to a logical switch with absolute bandwidth guarantees. In this paper, we debunk some of the myths around the virtual cluster embedding problem. First, we show that the virtual cluster embedding problem is not NP-hard, and present the fast and optimal embedding algorithm VC-ACE for arbitrary datacenter topologies. Second, we argue that resources may be wasted by enforcing star-Topology embeddings, and alternatively promote a hose embedding approach. We discuss the computational complexity of hose embeddings and derive the HVC-ACE algorithm. Using simulations we substantiate the benets of hose embeddings in terms of acceptance ratio and resource footprint.",Datacenter; Hose Model; Network Virtualization; Resource Allocation; Virtual Cluster,Complex networks; Hose; Resource allocation; Stars; Topology; Bandwidth guarantee; Cloud applications; Datacenter; Embedding problems; Hose models; Network virtualization; Virtual clusters; Virtual network topology; Distributed computer systems
"Steffie V.B., Eravuchira J., Schönwälder J.",3,Lessons learned from using the RIPE atlas platform for measurement research,2015,17,"Jacobs University Bremen, Germany",Jacobs University Bremen,1,Germany,1,11,8,"We reflect upon our experience in using the RIPE Atlas platform for measurement-based research. We show how in addition to credits, control checks using rate limits are in place to ensure that the platform does not get overloaded with measurements. We show how the Autonomous System (AS)-based distribution of RIPE Atlas probes is heavily skewed which limits possibilities of measurements sourced from a specific origin-AS. We discuss the significance of probe calibration and how we leverage it to identify load issues in older hardware versions (38.6% overall as of Sep 2014) of probes. We show how performance measurement platforms (such as RIPE Atlas, SamKnows, BISmark and Dasu) can benefit from each other by demonstrating two example use-cases. We also open discussion on how RIPE Atlas deployment can be made more useful by relaying more probe metadata information back to the scientific community and by strategically deploying probes to reduce the inherent sampling bias embedded in probe-based measurement platforms.",Access networks; RIPE atlas,Communication; Access network; Autonomous systems; Measurement research; Metadata information; Performance measurements; Probe calibration; RIPE atlas; Scientific community; Probes
"Coady Y., Hohlfeld O., Kempf J., McGeer R., Schmid S.",5,"Distributed cloud computing: Applications, status quo, and challenges",2015,15,"University of Victoria, Canada; RWTH Aachen University, Germany; Ericsson San Jose, United States; CDG, SAP America, US Ignite, United States; TU Berlin, T-Labs., Germany",RWTH Aachen University;TU Berlin;University of Victoria,3,Canada;Germany;USA,3,24,15,"A distributed cloud connecting multiple, geographically distributed and smaller datacenters, can be an attractive alternative to today's massive, centralized datacenters. A distributed cloud can reduce communication overheads, costs, and latencies by offering nearby computation and storage resources. Better data locality can also improve privacy. In this paper, we revisit the vision of distributed cloud computing, and identify different use cases as well as research challenges. This article is based on the Dagstuhl Seminar on Distributed Cloud Computing, which took place in February 2015 at Schloss Dagstuhl. © 2015, Association for Computing Machinery. All rights reserved.",Dagstuhl seminar; Distributed cloud computing; Distributed systems,Cloud computing; Digital storage; Communication overheads; Data centers; Data locality; Distributed clouds; Distributed systems; Research challenges; Status quo; Storage resources; Distributed computer systems
"Claffy K.C., Polterock J., Afanasyev A., Burke J., Zhang L.",5,The first Named Data Networking Community Meeting (NDNcomm),2015,5,"CAIDA/UCSD, United States; UCLA, United States",University of California San Diego,1,USA,1,22,22,"This report is a brief summary of the first NDN Community Meeting held at UCLA in Los Angeles, California on September 4-5, 2014. The meeting provided a platform for the attendees from 39 institutions across seven countries to exchange their recent NDN research and development results, to debate existing and proposed functionality in security support, and to provide feedback into the NDN architecture design evolution. © 2015, Association for Computing Machinery. All rights reserved.",Architecture; Information-centric networking; Named data networking,Architecture; Architecture designs; California; Community meetings; Information-centric networkings; Los angeles; Named data networkings; nocv1; Research and development; Security support; Communication
"Richter P., Allman M., Bush R., Paxson V.",4,A primer on IPv4 scarcity,2015,15,"TU Berlin, ICSI, Germany; ICSI, United States; Internet Initiative Japan, Japan; UC Berkeley, ICSI, United States",TU Berlin;University of California Berkeley,2,Germany;Japan;USA,3,89,37,"With the ongoing exhaustion of free address pools at the registries serving the global demand for IPv4 address space, scarcity has become reality. Networks in need of address space can no longer get more address allocations from their respective registries. In this work we frame the fundamentals of the IPv4 address exhaustion phenomena and connected issues. We elaborate on how the current ecosystem of IPv4 address space has evolved since the standardization of IPv4, leading to the rather complex and opaque scenario we face today. We outline the evolution in address space management as well as address space use patterns, identifying key factors of the scarcity issues. We characterize the possible solution space to overcome these issues and open the perspective of address blocks as virtual resources, which involves issues such as differentiation between address blocks, the need for resource certification, and issues arising when transferring address space between networks. © 2015, Association for Computing Machinery. All rights reserved.",IPv4 address exhaustion; IPv6 transition,Complex networks; Internet protocols; Address allocation; Address space; Global demand; IPv4 address exhaustion; IPv6 transition; Solution space; Virtual resource; Virtual addresses
"Nikitopoulos K., Zhou J., Congdon B., Jamieson K.",4,Geosphere: Consistently turning MIMO capacity into throughput,2015,3,"5G Innovation Centre, University of Surrey, United Kingdom; Department of Computer Science, University College London, United Kingdom",University College London;University of Surrey,2,UK,1,70,45,"This paper presents the design and implementation of Geosphere, a physical- and link-layer design for access point-based MIMO wireless networks that consistently improves network throughput. To send multiple streams of data in a MIMO system, prior designs rely on a technique called zero-forcing, a way of ""nulling"" the interference between data streams by mathematically inverting the wireless channel matrix. In general, zero-forcing is highly effective, significantly improving throughput. But in certain physical situations, the MIMO channel matrix can become ""poorly conditioned,"" harming performance. With these situations in mind, Geosphere uses sphere decoding, a more computationally demanding technique that can achieve higher throughput in such channels. To overcome the sphere decoder's computational complexity when sending dense wireless constellations at a high rate, Geosphere introduces search and pruning techniques that incorporate novel geometric reasoning about the wireless constellation. These techniques reduce computational complexity of 256-QAM systems by almost one order of magnitude, bringing computational demands in line with current 16- and 64-QAM systems already realized in ASIC. Geosphere thus makes the sphere decoder practical for the first time in a 4 × 4 MIMO, 256-QAM system. Results from our WARP testbed show that Geosphere achieves throughput gains over multi-user MIMO of 2× in 4 × 4 systems and 47% in 2 × 2 MIMO systems.",Distributed MIMO; MIMO; Sphere decoder,Complex networks; Computational complexity; Decoding; Design; Matrix algebra; Throughput; Computational demands; Design and implementations; Distributed MIMO; Geometric reasoning; Multiple streams; Network throughput; Pruning techniques; Sphere decoders; MIMO systems
"Netravali R., Sivaraman A., Winstein K., Das S., Goyal A., Balakrishnan H.",6,Mahimahi: A lightweight toolkit for reproducible web measurement,2015,1,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,2,0,"This demo presents a measurement toolkit, Mahimahi, that records websites and replays them under emulated network conditions. Mahimahi is structured as a set of arbitrarily composable UNIX shells. It includes two shells to record and replay Web pages, RecordShell and ReplayShell, as well as two shells for network emulation, DelayShell and LinkShell. In addition, Mahimahi includes a corpus of recorded websites along with benchmark results and link traces (https://github.com/ravinet/sites). Mahimahi improves on prior record-and-replay frameworks in three ways. First, it preserves the multi-origin nature ofWeb pages, present in approximately 98% of the Alexa U.S. Top 500, when replaying. Second, Mahimahi isolates its own network traffic, allowing multiple instances to run concurrently with no impact on the host machine and collected measurements. Finally, Mahimahi is not inherently tied to browsers and can be used to evaluate many different applications. A demo of Mahimahi recording and replaying a Web page over an emulated link can be found at http://youtu.be/vytwDKBA-8s. The source code and instructions to use Mahimahi are available at http://mahimahi.mit.edu/.",Page load time; Record-and-replay; Web measurements,Websites; Multiple instances; Network condition; Network emulation; Network traffic; Page load time; Record-and-replay; Source codes; Web measurements; HTTP
"Lee J., Turner Y., Lee M., Popa L., Banerjee S., Kang J.-M., Sharma P.",7,Application-driven bandwidth guarantees in datacenters,2015,22,"HP Labs, United States; University of Edinburgh, United Kingdom; Databricks, United States",HP Labs;University of Edinburgh,2,UK;USA,2,48,29,"Providing bandwidth guarantees to specific applications is becoming increasingly important as applications compete for shared cloud network resources. We present CloudMirror, a solution that provides bandwidth guarantees to cloud applications based on a new network abstraction and workload placement algorithm. An effective network abstraction would enable applications to easily and accurately specify their requirements, while simultaneously enabling the infrastructure to provision resources efficiently for deployed applications. Prior research has approached the bandwidth guarantee specification by using abstractions that resemble physical network topologies. We present a contrasting approach of deriving a network abstraction based on application communication structure, called Tenant Application Graph or TAG. CloudMirror also incorporates a new workload placement algorithm that efficiently meets bandwidth requirements specified by TAGs while factoring in high availability considerations. Extensive simulations using real application traces and datacenter topologies show that CloudMirror can handle 40% more bandwidth demand than the state of the art (e.g., the Oktopus system), while improving high availability from 20% to 70%. Copyright 2014 ACM.",Application; Availability; Bandwidth; Cloud; Datacenter; Virtual network,Abstracting; Applications; Availability; Clouds; Electric network topology; Telecommunication networks; Topology; Bandwidth requirement; Communication structures; Datacenter; Deployed applications; Extensive simulations; Network abstractions; Physical network topologies; Virtual networks; Bandwidth
"Sundaresan S., Feamster N., Teixeira R.",3,Locating throughput bottlenecks in home networks,2015,0,"Georgia Tech, United States; INRIA, France",Georgia Tech;INRIA,2,France;USA,2,2,1,"We present a demonstration of WTF (Where's The Fault?), a system that localizes performance problems in home and access networks. We implement WTF as custom firmware that runs in an off-the-shelf home router. WTF uses timing and buffering information from passively monitored traffic at home routers to detect both access link and wireless network bottlenecks. Copyright 2014 ACM.",Bottleneck location; Home networks; Performance diagnosis; Troubleshooting,Diagnosis; Firmware; Personal communication systems; Routers; Access links; Access network; Bottleneck location; Home routers; Network bottlenecks; Performance diagnosis; Performance problems; Home networks
"Zhang B., Wang J., Wang X., Cheng Y., Jia X., He J.",6,AI3: Application-independent information infrastructure,2015,0,"City University of Hong Kong, Hong Kong; Huawei Technologies Co. Ltd., China",City University of Hong Kong;Huawei Technologies,2,China;Hong Kong,2,4,3,"In the current Internet architecture, application service providers (ASPs) own users' data and social groups information, which made a handful of ASP companies growing bigger and bigger and denied small and medium companies from entering this business. We propose a new architecture, called Application Independent Information Infrastructure (AI3). The design goals of AI3 are: 1) Decoupling users' data from ASPs and users' social relations from ASPs, such that ASPs become independent from users' data and social relations. 2) Open architecture, such that different ASPs can interoperate with each other. This demo is to show a prototype of AI3. The demo has four parts: 1) ASPindependent data management in AI3; 2) ASP-independent management of users' social relations in AI3; 3) inter-domain data transport and user roaming; 4) real-time communications by using AI3. The demo video can be watched at: http://www.cs.cityu.edu.hk/~jia/AI3-DemoVideo.mp4.",Internet architecture; Network infrastructure; Storage system,Computer architecture; Data storage equipment; Information management; Internet; Network architecture; Application service provider; Information infrastructures; Internet architecture; Network infrastructure; Open architecture; Real-time communication; Social relations; Storage systems; Digital storage
"Jiang A.H., Bischof Z.S., Bustamante F.E.",3,A Cliq of content curators,2015,1,"Northwestern University, United States",Northwestern University,1,USA,1,1,0,"A social news site presents user-curated content, ranked by popularity. Popular curators like Reddit, or Facebook have become effective way of crowdsourcing news or sharing for personal opinions. Traditionally, these services require a centralized authority to aggregate data and determine what to display. However, the trust issues that arise from a centralized system are particularly damaging to the \Web democracy"" that social news sites are meant to provide. In this poster, we present cliq, a decentralized social news curator. cliq is a P2P based social news curator that pro- vides private and unbiased reporting. All users in cliq share responsibility for tracking and providing popular content. Any user data that cliq needs to store is also managed across the network. We first inform our design of cliq through an analysis of Reddit. We design a way to provide content curation without a persistent moderator, or usernames.",P2P systems; Social news curation,Social networking (online); Aggregate datum; Centralized systems; Content curation; Crowdsourcing; Curation; P2P system; P2P-based; Social news; Peer to peer networks
"Hamedazimi N., Qazi Z., Gupta H., Sekar V., Das S.R., Longtin J.P., Shah H., Tanwery A.",8,FireFly: A reconfigurable wireless data center fabric using free-space optics,2015,30,"Stony Brook University, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Stony Brook University,2,USA,1,52,33,"Conventional static datacenter (DC) network designs offer extreme cost vs. performance tradeoffs-simple leaf-spine networks are costeffective but oversubscribed, while ""fat tree""-like solutions offer good worst-case performance but are expensive. Recent results make a promising case for augmenting an oversubscribed network with reconfigurable inter-rack wireless or optical links. Inspired by the promise of reconfigurability, this paper presents FireFly, an inter-rack network solution that pushes DC network design to the extreme on three key fronts: (1) all links are reconfigurable; (2) all links are wireless; and (3) non top-of-rack switches are eliminated altogether. This vision, if realized, can offer significant benefits in terms of increased flexibility, reduced equipment cost, and minimal cabling complexity. In order to achieve this vision, we need to look beyond traditional RF wireless solutions due to their interference footprint which limits range and data rates. Thus, we make the case for using free-space optics (FSO). We demonstrate the viability of this architecture by (a) building a proof-of-concept prototype of a steerable small form factor FSO device using commodity components and (b) developing practical heuristics to address algorithmic and system-level challenges in network design and management.",Data centers; Free-space optics; Reconfigurablility,Bioluminescence; Design; Space optics; Commodity components; Data centers; Free space optics; Increased flexibility; Performance trade-off; Reconfigurablility; Small form factors; Worst-case performance; Complex networks
"Roy A.R., Bari Md.F., Zhani M.F., Ahmed R., Boutaba R.",5,DOT: Distributed openflow testbed,2015,4,"David R. Cheriton School of Computer Science, University of Waterloo, Canada",University of Waterloo,1,Canada,1,5,5,"With the growing adoption of Software Defined Networking (SDN) technology, there is a compelling need for an SDN emulator that can facilitate experimenting with new SDN solutions. In this context, Mininet [1] has been proposed as an emulator for prototyping a network on a single machine. It allows users to create, control, and customize an emulated network on which they can run and test new control applications like routing, traffic engineering, etc. However, Mininet cannot scale for large networks and high traffic volumes [3].",Emulator; Software defined networking; Testbed,Control applications; Emulator; Large networks; Single- machines; Software defined networking (SDN); Software-defined networkings; Traffic Engineering; Traffic volumes; Testbeds
"Zhang Z., Mara O., Argyraki K.",3,Network neutrality inference,2015,4,"UESTC, China; EPFL, Switzerland","EPFL,Switzerland",1,China;Switzerland,2,32,17,"When can we reason about the neutrality of a network based on external observations? We prove conditions under which it is possible to (a) detect neutrality violations and (b) localize them to specific links, based on external observations. Our insight is that, when we make external observations from different vantage points, these will most likely be inconsistent with each other if the network is not neutral. Where existing tomographic techniques try to form solvable systems of equations to infer network properties, we try to form unsolvable systems that reveal neutrality violations. We present an algorithm that relies on this idea to identify sets of nonneutral links based on external observations, and we show, through network emulation, that it achieves good accuracy for a variety of network conditions.",Network neutrality; Network tomography,Infer networks; Network condition; Network emulation; Network neutralities; Network tomography; Network-based; Systems of equations; Tomographic techniques; Internet
"Obstfeld J., Knight S., Kern E., Wang Q.S., Bryan T., Bourque D.",6,VIRL: The virtual internet routing lab,2015,1,"University of Adelaide, Cisco Systems, Australia; Cisco Systems, United States",University of Adelaide,1,Australia;USA,2,7,4,"The increasing demand to provide new network services in a timely and efficient manner is driving the need to design, test and deploy networks quickly and consistently. Testing and verifying at scale is a challenge: network equipment is expensive, requires space, power and cooling, and there is never enough test equipment for everyone who wants to use it! Network virtualization technologies enable a flexible environment for educators, researchers, and operators to create functional models of current, planned, or theoretical networks. This demonstration will show VIRL the Virtual Internet Routing Lab a platform that can be used for network change validation, training, education, research, or network-aware applications development. The platform combines network virtualization technologies with virtual machines (VMs) running open-source and commercial operating systems; VM orchestration capabilities; a context-aware configuration engine; and an extensible data-collection frame-work. The system simplifies the process to create both simple and complex environments, run simulations, and collect measurement data.",Emulation; Network design; Network modelling; Simulation,Data acquisition; Distance education; Equipment testing; Internet; Open systems; Virtual reality; Commercial operating systems; Context-aware configuration; Emulation; Flexible environments; Network design; Network modelling; Network virtualization; Simulation; Complex networks
"Czyz J., Allman M., Zhang J., Iekel-Johnson S., Osterweil E., Bailey M.",6,Measuring IPv6 adoption,2015,9,"International Computer Science Institute, United States; University of Michigan, United States; Arbor Networks, Inc., United States; Verisign Labs, United States",University of California Berkeley;University of Michigan at Ann Arbor,2,USA,1,44,32,"After several IPv4 address exhaustion milestones in the last three years, it is becoming apparent that the world is running out of IPv4 addresses, and the adoption of the next generation Internet protocol, IPv6, though nascent, is accelerating. In order to better understand this unique and disruptive transition, we explore twelve metrics using ten global-scale datasets to create the longest and broadest measurement of IPv6 adoption to date. Using this perspective, we find that adoption, relative to IPv4, varies by two orders of magnitude depending on the measure examined and that care must be taken when evaluating adoption metrics in isolation. Further, we find that regional adoption is not uniform. Finally, and perhaps most surprisingly, we find that over the last three years, the nature of IPv6 utilization-in terms of traffic, content, reliance on transition technology, and performance-has shifted dramatically from prior findings, indicating a maturing of the protocol into production mode. We believe IPv6's recent growth and this changing utilization signal a true quantum leap. Copyright 2014 ACM.",DNS; Internet; IP; IPv4; IPv6; Measurement,Internet; Measurements; DNS; IP; IPv4; IPv6; Next generation Internet; Orders of magnitude; Production modes; Transition technologies; Internet protocols
"Wu Y., Zhao M., Haeberlen A., Zhou W., Loo B.T.",5,Diagnosing missing events in distributed systems with negative provenance,2015,4,"Georgetown University, United States; University of Pennsylvania, United States",Georgetown University;University of Pennsylvania,2,USA,1,37,27,"When debugging a distributed system, it is sometimes necessary to explain the absence of an event - for instance, why a certain route is not available, or why a certain packet did not arrive. Existing debuggers offer some support for explaining the presence of events, usually by providing the equivalent of a backtrace in conventional debuggers, but they are not very good at answering ""Why not?"" questions: there is simply no starting point for a possible backtrace. In this paper, we show that the concept of negative provenance can be used to explain the absence of events in distributed systems. Negative provenance relies on counterfactual reasoning to identify the conditions under which the missing event could have occurred. We define a formal model of negative provenance for distributed systems, and we present the design of a system called Y! that tracks both positive and negative provenance and can use them to answer diagnostic queries. We describe how we have used Y! to debug several realistic problems in two application domains: softwaredefined networks and BGP interdomain routing. Results from our experimental evaluation show that the overhead of Y! is moderate.",Debugging; Diagnostics; Provenance,Computer debugging; Plasma diagnostics; Program diagnostics; Query processing; Debuggers; Distributed systems; Experimental evaluation; Formal model; Interdomain Routing; Provenance; Software-defined networks; Program debugging
"Hu H., Jin Y., Wen Y., Chua T.-S., Li X.",5,Toward a biometric-aware cloud service engine for multi-screen video applications,2015,0,"School of Computing, National Univ. of Singapore117417, Singapore; School of Computer Eng., Nanyang Tech. University639798, Singapore; Center for Optical Imagery Analysis and Learning (OPTIMAL), XIOPM of CAS, Xi'an, 710119, China",Center for Optical Imagery Analysis and Learning (OPTIMAL);Nanyang Tech. University;National University of Singapore,3,China;Singapore,2,3,3,"The emergence of portable devices and online social networks (OSNs) has changed the traditional video consumption paradigm by simultaneously providing multi-screen video watching, social networking engagement, etc. One challenge is to design a unified solution to support ever-growing features while guarantee system performance. In this demo, we design and implement a multi-screen technology to provide multi-screen interactions over wide area network (WAN). Furthermore, we incorporate face-detection technology into our system to identify users' bio-features and employ a machine learning based traffic scheduling mechanism to improve the system performance.",Cloud; Internet video; Second screen,Artificial intelligence; Biometrics; Clouds; Face recognition; Learning systems; Scheduling; Wide area networks; Design and implements; Detection technology; Internet video; Online social networks (OSNs); Second screens; Traffic scheduling; Unified solutions; Video applications; Social networking (online)
"Munir A., Baig G., Irteza S.M., Qazi I.A., Liu A.X., Dogar F.R.",6,"Friends, not foes - Synthesizing existing transport strategies for data center networks",2015,8,"Michigan State University, United States; LUMS, United States; Microsoft Research, United States",LUMS Pakistan;Michigan State University;Microsoft,3,USA,1,25,3,"Many data center transports have been proposed in recent times (e.g., DCTCP, PDQ, pFabric, etc). Contrary to the common perception that they are competitors (i.e., protocol A vs. protocol B), we claim that the underlying strategies used in these protocols are, in fact, complementary. Based on this insight, we design PASE, a transport framework that synthesizes existing transport strategies, namely, self-adjusting endpoints (used in TCP style protocols), innetwork prioritization (used in pFabric), and arbitration (used in PDQ). PASE is deployment friendly: it does not require any changes to the network fabric; yet, its performance is comparable to, or better than, the state-of-the-art protocols that require changes to network elements (e.g., pFabric). We evaluate PASE using simulations and testbed experiments. Our results show that PASE performs well for a wide range of application workloads and network settings. Copyright 2014 ACM.",Datacenter; Scheduling; Transport,Scheduling; Data center networks; Datacenter; Network element; Network settings; Prioritization; State-of-the art protocols; Transport; Transport strategies; Transmission control protocol
"Vallentin M., Charousset D., Schmidt T.C., Paxson V., Wählisch M.",5,Native actors: How to scale network forensics,2015,0,"UC Berkeley, United States; HAW Hamburg, Germany; ICSI, UC Berkeley, United States; FU Berlin, Germany",University of California Berkeley,1,Germany;USA,2,5,2,"When an organization detects a security breach, it undertakes a forensic analysis to figure out what happened. This investigation involves inspecting a wide range of heterogeneous data sources spanning over a long period of time. The iterative nature of the analysis procedure requires an interactive experience with the data. However, the distributed processing paradigms we find in practice today fail to provide this requirement: the batch-oriented nature of MapReduce cannot deliver sub-second round-trip times, and distributed in-memory processing cannot store the terabytes of activity logs needed to inspect during an incident. We present the design and implementation of Visibility Across Space and Time (VAST), a distributed database to support interactive network forensics, and libcppa, its exceptionally scalable messaging core. The extended actor framework libcppa enables VAST to distribute lightweight tasks at negligible overhead. In our live demo, we showcase how VAST enables security analysts to grapple with the huge amounts of data often associated with incident investigations.",Message-oriented middleware; Network forensics; Security,Middleware; Design and implementations; Distributed database; Distributed processing; Heterogeneous data sources; Incident investigation; Message oriented middleware; Network forensics; Security; Mobile security
"Li J., Berg S., Zhang M., Reiher P., Wei T.",5,Drawbridge-Software-defined DDoS-resistant traffic engineering,2015,7,"University of Oregon, Eugene, OR, United States; University of California, Los Angeles, CA, United States; University of California, Berkeley, CA, United States",University of California Berkeley;University of California Los Angeles;University of Oregon,3,USA,1,4,3,"End hosts in today's Internet have the best knowledge of the type of Traffic they should receive, but they play no active role in Traffic engineering. Traffic engineering is conducted by ISPs, which unfortunately are blind to specific user needs. End hosts are therefore subject to unwanted Traffic, particularly from Distributed Denial of Service (DDoS) attacks. This research proposes a new system called DrawBridge to address this Traffic engineering dilemma. By realizing the potential of software-defined networking (SDN), in this research we investigate a solution that enables end hosts to use their knowledge of desired Traffic to improve Traffic engineering during DDoS attacks.",DDoS; Software-defined networking; Traffic engineering,Internet service providers; Network security; Telecommunication traffic; DDoS; DDoS Attack; Distributed denial of service attack; Software defined networking (SDN); Software-defined networkings; Traffic Engineering; Unwanted traffic; User need; Denial-of-service attack
"Ghorbani S., Godfrey B.",2,Towards correct network virtualization,2015,1,"University of Illinois, Urbana-Champaign, United States",UIUC,1,USA,1,23,21,"In SDN, the underlying infrastructure is usually abstracted for applications that can treat the network as a logical or virtual entity. Commonly, the \mappings"" between virtual abstractions and their actual physical implementations are not one-to-one, e.g., a single \big switch"" abstract object might be implemented using a distributed set of physical devices. A key question is, what abstractions could be mapped to multiple physical elements while faithfully preserving their native semantics? E.g., can an application developer always expect her abstract \big switch"" to act exactly as a physical big switch, despite being implemented using multiple physical switches in reality? We show that the answer to that question is \no"" for existing virtual-to-physical mapping techniques: behavior can differ between the virtual \big switch"" and the physical network, providing incorrect application-level behavior. We also show that that those incorrect behaviors occur despite the fact that the most pervasive correctness invariants, such as per-packet consistency, are preserved throughout. These examples demonstrate that for practical notions of correctness, new systems and a new analytical framework are needed. We take the first steps by defining end-to-end correctness, a correctness condition that focuses on applications only, and outline a research vision to obtain virtualization systems with correct virtual to physical mappings.",Correctness; Network virtualization; One big switch,Abstracting; Mapping; Semantics; Virtual reality; Application developers; Application level; Correctness; Correctness conditions; End-to-end correctness; Network virtualization; Physical devices; Physical elements; Switching circuits
"Donovan S., Feamster N.",2,NetAssay: Providing new monitoring primitives for network operators,2015,0,"Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,6,4,"Home and business network operators have limited network statistics available over which management decisions can be made. Similarly, there are few triggered behaviors, such as usage or bandwidths cap for individual users, that are available. By looking at sources of traffic, based on Do- main Name System (DNS) cues for content of particular web addresses or source Autonomous System (AS) of the traffic, network operators could create new and interesting rules for their network. NetAssay is a Software-Defined Net- working (SDN)-based, network-wide monitoring and reaction framework. By integrating information from Border Gateway Protocol (BGP) and the Domain Name System, NetAssay is able to integrate formerly disparate sources of control information, and use it to provide better monitoring, more useful triggered events, and security benefits for network operators.",Network management; Network monitoring; Software-defined networking,Gateways (computer networks); Internet protocols; Network management; Network security; Autonomous systems; Border gateway protocol; Control information; Integrating information; Management decisions; Network Monitoring; Network statistics; Software-defined networkings; Network protocols
"Bischof Z.S., Bustamante F.E.",2,A time for reliability - The growing importance of being always on,2015,0,"Northwestern University, United States",Northwestern University,1,USA,1,4,3,"When a new technology reaches the market, we often focus on the want or need that it can fulfill. However, as the market for a technology matures, reliability often becomes a key differentiating factor between competing products. Examples of this abound, from cars to passenger fights, phones and televisions.",Access link reliability; Broadband access networks,Broadband networks; Commerce; Access links; Broad-band access networks; Reliability
"Islam S., Welzl M., Gjessing S., Khademi N.",4,Coupled congestion control for RTP media,2015,2,"Department of Informatics, University of Oslo, Norway",University of Oslo,1,Norway,1,15,9,Congestion occurs at a bottleneck along an Internet path; multiple ows between the same sender and receiver pairs can benefit from using only a single congestion control instance when they share the same bottleneck. These benefits include the ability to control the rate allocation between ows and reduced overall delay (multiple congestion control instances cause more queuing delay than one since each has no knowledge of the congestion episodes experienced by the others). We present a mechanism for coupling congestion control for real-time media and show its benefits by coupling multiple congestion controlled ows that share the same bottleneck. Copyright 2014 ACM.,Congestion control; FSE; RMCAT; WebRTC,Congestion control (communication); FSE; Internet paths; Multiple congestion; Queuing delay; Rate allocation; RMCAT; Sender and receivers; WebRTC; Traffic congestion
"Gabielkov M., Rao A., Legout A.",3,Sampling online social networks: An experimental study of twitter,2015,1,"Inria, Sophia Antipolis, France",INRIA,1,France,1,4,3,"Online social networks (OSNs) are an important source of information for scientists in different fields such as computer science, sociology, economics, etc. However, it is hard to study OSNs as they are very large. For instance, Facebook has 1.28 billion active users in March 2014 and Twitter claims 255 million active users in April 2014. Also, companies take measures to prevent crawls of their OSNs and refrain from sharing their data with the research community. For these reasons, we argue that sampling techniques will be the best technique to study OSNs in the future. In this work, we take an experimental approach to study the characteristics of well-known sampling techniques on a full social graph of Twitter crawled in 2012 [2]. Our contribution is to evaluate the behavior of these techniques on a real directed graph by considering two sampling scenarios: (a) obtaining most popular users (b) obtaining an unbiased sample of users, and to find the most suitable sampling techniques for each scenario.",Sampling; Social graph; Social networks; Twitter,Directed graphs; Economics; Sampling; Experimental approaches; Facebook; On-line social networks; Online social networks (OSNs); Research communities; Sampling technique; Social graphs; Twitter; Social networking (online)
"Huang T.-Y., Johari R., McKeown N., Trunnell M., Watson M.",5,A buffer-based approach to rate adaptation: Evidence from a large video streaming service,2015,116,"Stanford University, Netflix, United States",Stanford University,1,USA,1,21,18,"Existing ABR algorithms face a significant challenge in estimating future capacity: capacity can vary widely over time, a phenomenon commonly observed in commercial services. In this work, we suggest an alternative approach: rather than presuming that capacity estimation is required, it is perhaps better to begin by using only the buffer, and then ask when capacity estimation is needed. We test the viability of this approach through a series of experiments spanning millions of real users in a commercial service. We start with a simple design which directly chooses the video rate based on the current buffer occupancy. Our own investigation reveals that capacity estimation is unnecessary in steady state; however using simple capacity estimation (based on immediate past throughput) is important during the startup phase, when the buffer itself is growing from empty. This approach allows us to reduce the rebuffer rate by 10-20% compared to Netflix's then-default ABR algorithm, while delivering a similar average video rate, and a higher video rate in steady state.",HTTP-based video streaming; Video rate adaptation algorithm,Algorithms; Buffer amplifiers; Capacity estimation; Commercial services; Current buffer; HTTP-based video streaming; Rate adaptation; Start-up phase; Video rate adaptation; Video streaming services; Video streaming
"Dogar F.R., Karagiannis T., Ballani H., Rowstron A.",4,Decentralized task-aware scheduling for data center networks,2015,24,"Microsoft Research, United States",Microsoft,1,USA,1,29,24,"Many data center applications perform rich and complex tasks (e.g., executing a search query or generating a user's news-feed). From a network perspective, these tasks typically comprise multiple flows, which traverse different parts of the network at potentially different times. Most network resource allocation schemes, however, treat all these flows in isolation - rather than as part of a task - and therefore only optimize flow-level metrics. In this paper, we show that task-aware network scheduling, which groups flows of a task and schedules them together, can reduce both the average as well as tail completion time for typical data center applications. To achieve these benefits in practice, we design and implement Baraat, a decentralized task-aware scheduling system. Baraat schedules tasks in a FIFO order but avoids head-of-line blocking by dynamically changing the level of multiplexing in the network. Through experiments with Memcached on a small testbed and large-scale simulations, we show that Baraat outperforms state-of-the-art decentralized schemes (e.g., pFabric) as well as centralized schedulers (e.g., Orchestra) for a wide range of workloads (e.g., search, analytics, etc). Copyright 2014 ACM.",Datacenter; Response time; Scheduling; Transport,Complex networks; Response time (computer systems); Centralized schedulers; Data center networks; Datacenter; Design and implements; Head of line blocking; Large scale simulations; Network resource allocations; Transport; Scheduling
"Moshref M., Yu M., Govindan R., Vahdat A.",4,DREAM: Dynamic resource allocation for software-defined measurement,2015,26,"University of Southern California, United States; Google and UC, San Diego, United States",Google;University of Southern California,2,USA,1,42,29,"Software-defined networks can enable a variety of concurrent, dynamically instantiated, measurement tasks, that provide fine-grain visibility into network traffic. Recently, there have been many proposals to configure TCAM counters in hardware switches to monitor traffic. However, the TCAM memory at switches is fundamentally limited and the accuracy of the measurement tasks is a function of the resources devoted to them on each switch. This paper describes an adaptive measurement framework, called DREAM, that dynamically adjusts the resources devoted to each measurement task, while ensuring a user-specified level of accuracy. Since the trade-off between resource usage and accuracy can depend upon the type of tasks, their parameters, and traffic characteristics, DREAM does not assume an a priori characterization of this trade-off, but instead dynamically searches for a resource allocation that is sufficient to achieve a desired level of accuracy. A prototype implementation and simulations with three network-wide measurement tasks (heavy hitter, hierarchical heavy hitter and change detection) and diverse traffic show that DREAM can support more concurrent tasks with higher accuracy than several other alternatives. Copyright 2014 ACM.",Resource allocation; Software-defined measurement,Resource allocation; Ternary content adressable memory; Adaptive measurements; Change detection; Concurrent tasks; Dynamic resource allocations; Hierarchical heavy hitters; Prototype implementations; Software-defined networks; Traffic characteristics; Economic and social effects
"Dong M., Li Q., Zarchy D., Godfrey B., Schapira M.",5,Rethinking congestion control architecture: Performance-oriented congestion control,2015,0,"University of Illinois, Urbana-Champaign, United States; Hebrew University of Jerusalem, Israel",Hebrew University of Jerusalem;UIUC,2,Israel;USA,2,10,7,"After more than two decades of evolution, TCP and its end host based modifications can still suffer from severely degraded performance under real-world challenging network conditions. The reason, as we observe, is due to TCP family's fundamental architectural deficiency, which hardwires packet-level events to control responses and ignores emprical performance. Jumping out of TCP lineage's architectural deficiency, we propose Performanceoriented Congestion Control (PCC), a new congestion control architecture in which each sender controls its sending strategy based on empirically observed performance metrics. We show through preliminary experimental results that PCC achieves consistently high performance under various challenging network conditions.",Congestion control,Congestion control (communication); Network architecture; Control architecture; Control response; Degraded performance; Network condition; Packet level; Performance metrics; Performance-oriented; Show through; Transmission control protocol
"Koll D., Li J., Fu X.",3,"SOUP: An online social network by the people, for the people",2015,2,"University of Oregon, Eugene, United States; University of Göttingen, Göttingen, Germany",University of Göttingen;University of Oregon,2,Germany;USA,2,3,1,"With increasing frequency, users raise concerns about data privacy and protection in centralized Online Social Networks (OSNs), in which providers have the unprecedented privilege to access and exploit every user's private data at will. To mitigate these concerns, researchers have suggested to decentralize OSNs and thereby enable users to control and manage access to their data themselves. However, previously proposed decentralization approaches suffer from several drawbacks. To tackle their deficiencies, we introduce the Self-Organized Universe of People (SOUP). In this demonstration, we present a prototype of SOUP and share our experiences from a real-world deployment.",Decentralization; DOSN; Online social networks,Access control; Data privacy; Online systems; Websites; Decentralization; DOSN; On-line social networks; Online social networks (OSNs); Private data; Real world deployment; Social networking (online)
"Sharma A., Tie X., Uppal H., Venkataramani A., Westbrook D., Yadav A.",6,A global name service for a highly mobile internetwork,2015,8,"School of Computer Science, University of Massachusetts, Amherst, United States",University of Massachusetts Amherst,1,USA,1,57,33,"Mobile devices dominate the Internet today, however the Internet rooted in its tethered origins continues to provide poor infrastructure support for mobility. Our position is that in order to address this problem, a key challenge that must be addressed is the design of a massively scalable global name service that rapidly resolves identities to network locations under high mobility. Our primary contribution is the design, implementation, and evaluation of Auspice, a nextgeneration global name service that addresses this challenge. A key insight underlying Auspice is a demand-aware replica placement engine that intelligently replicates name records to provide low lookup latency, low update cost, and high availability. We have implemented a prototype of Auspice and compared it against several commercial managed DNS providers as well as state-of-the-art research alternatives, and shown that Auspice significantly outperforms both. We demonstrate proof-of-concept that Auspice can serve as a complete end-to-end mobility solution as well as enable novel context-based communication primitives that generalize nameor address-based communication in today's Internet.",Distributed systems; Mobility; Network architecture,Carrier mobility; Mobile devices; Mobile telecommunication systems; Network architecture; Context-Based Communication; Distributed systems; Global name services; High availability; Mobility solutions; Primary contribution; Proof of concept; Replica placement; Internet
"Chatzis N., Smaragdakis G., Feldmann A., Willinger W.",4,Quo vadis Open-IX?: Trying to boost public peering in the US,2015,6,"TU Berlin, Germany; MIT/TU Berlin, Germany; NIKSUN, Germany",MIT;TU Berlin,2,Germany,1,54,27,"The recently launched initiative by the Open-IX Association (OIX) to establish the European-style Internet eXchange Point (IXP) model in the US suggests an intriguing strategy to tackle a problem that some Internet stakeholders in the US consider to be detrimental to their business; i.e., a lack of diversity in available peering opportunities. We examine in this paper the cast of Internet stakeholders that are bound to play a critical role in determining the fate of this Open-IX effort. These include the large content and cloud providers, CDNs, Tier-1 ISPs, the well-established and some of the newer commercial datacenter and colocation companies, and the largest IXPs in Europe. In particular, we comment on these different parties' current attitudes with respect to public and private peering and discuss some of the economic arguments that will ultimately determine whether or not the currently pursued strategy by OIX will succeed in achieving the main OIX-articulated goal - A more level playing field for private and public peering in the US such that the actual demand and supply for the different peering opportunities will be reflected in the cost structure.",Content delivery; Internet exchange point; Peering,Internet; Cloud providers; Colocations; Content delivery; Cost structure; Demand and supply; Internet exchange points; Level playing fields; Peering; Internet service providers
"Csoma A., Sonkoly B., Csikor L., Németh F., Gulyás A., Tavernier W., Sahhaf S.",7,"ESCAPE: Extensible service ChAin prototyping environment using mininet, click, NETCONF and POX",2015,13,"Budapest Univ. of Technology and Economics, Hungary; MTA-BME Future Internet Research Group, Budapest Univ. of Technology and Economics, Hungary; Ghent University - IMinds, Ghent, Belgium; MTA-BME Information systems research group, Budapest Univ. of Technology and Economics, Hungary",Budapest University of Technology and Economics;Ghent University;MTA-BME,3,Belgium;Hungary,2,4,2,"Mininet is a great prototyping tool which combines existing SDN-related software components (e.g., Open vSwitch, OpenFlow controllers, network namespaces, cgroups) into a framework, which can automatically set up and configure customized OpenFlow testbeds scaling up to hundreds of nodes. Standing on the shoulders of Mininet, we implement a similar prototyping system called ESCAPE, which can be used to develop and test various components of the service chaining architecture. Our framework incorporates Click for implementing Virtual Network Functions (VNF), NETCONF for managing Click-based VNFs and POX for taking care of traffic steering. We also add our extensible Orchestrator module, which can accommodate mapping algorithms from abstract service descriptions to deployed and running service chains.",Click; Mininet; NETCONF; Prototyping; SDN; Service chain,Conformal mapping; Software prototyping; Click; Mininet; NETCONF; SDN; Service chain; Chains
"Chowdhury M., Zhong Y., Stoica I.",3,Efficient coflow scheduling with varys,2015,35,"UC Berkeley, United States; Columbia University, United States",Columbia University;University of California Berkeley,2,USA,1,41,29,"Communication in data-parallel applications often involves a collection of parallel flows. Traditional techniques to optimize flow-level metrics do not perform well in optimizing such collections, because the network is largely agnostic to application-level requirements. The recently proposed coflow abstraction bridges this gap and creates new opportunities for network scheduling. In this paper, we address inter-coflow scheduling for two different objectives: decreasing communication time of data-intensive jobs and guaranteeing predictable communication time. We introduce the concurrent open shop scheduling with coupled resources problem, analyze its complexity, and propose effective heuristics to optimize either objective. We present Varys, a system that enables data-intensive frameworks to use coflows and the proposed algorithms while maintaining high network utilization and guaranteeing starvation freedom. EC2 deployments and trace-driven simulations show that communication stages complete up to 3:16× faster on average and up to 2× more coflows meet their deadlines using Varys in comparison to per-flow mechanisms. Moreover, Varys outperforms non-preemptive coflow schedulers by more than 5×.",Coflow; Data-intensive applications; Datacenter networks,Complex networks; Optimization; Parallel flow; Co-flow; Data center networks; Data-intensive application; Data-parallel applications; Net work utilization; Open shop scheduling; Trace driven simulation; Traditional techniques; Scheduling
"Kellogg B., Parks A., Gollakota S., Smith J.R., Wetherall D.",5,Wi-Fi backscatter: Internet connectivity for RF-powered devices,2015,70,"University of Washington, United States",University of Washington at St. Louis,1,USA,1,29,22,"RF-powered computers are small devices that compute and communicate using only the power that they harvest from RF signals. While existing technologies have harvested power from ambient RF sources (e.g., TV broadcasts), they require a dedicated gateway (like an RFID reader) for Internet connectivity. We present Wi-Fi Backscatter, a novel communication system that bridges RF-powered devices with the Internet. Specifically, we show that it is possible to reuse existing Wi-Fi infrastructure to provide Internet connectivity to RF-powered devices. To show Wi-Fi Backscatter's feasibility, we build a hardware prototype and demonstrate the first communication link between an RF-powered device and commodity Wi-Fi devices. We use off-the-shelf Wi-Fi devices including Intel Wi-Fi cards, Linksys Routers, and our organization's Wi-Fi infrastructure, and achieve communication rates of up to 1 kbps and ranges of up to 2.1 meters. We believe that this new capability can pave the way for the rapid deployment and adoption of RF-powered devices and achieve ubiquitous connectivity via nearby mobile devices that are Wi-Fi enabled. Copyright 2014 ACM.",Backscatter; Energy harvesting; Internet of things; Wireless,Backscattering; Energy harvesting; Internet; Internet of things; Mobile devices; Radio; Television broadcasting; Communication rate; Hardware prototype; Internet connectivity; Powered devices; Rapid deployments; RFID readers; Small devices; TV broadcast; Gateways (computer networks)
"Kogan K., Nikolenko S., Rottenstreich O., Culhane W., Eugster P.",5,SAX-PAC (Scalable and expressive packet classification),2015,5,"Purdue University and NetSysAlgo, United States; Higher School of Economics, Steklov Mathematical Institute, National Research University, St. Petersburg, Russian Federation; Mellanox, Israel; Purdue University, United States; Purdue University and Technical University of Darmstadt, United States",National Research University;Purdue University;TU Darmstadt;Steklov Mathematical Institute,4,Israel;Russia;USA,3,43,29,"Efficient packet classification is a core concern for network services. Traditional multi-field classification approaches, in both software and ternary content-addressable memory (TCAMs), entail tradeoffs between (memory) space and (lookup) time. TCAMs cannot efficiently represent range rules, a common class of classification rules confining values of packet fields to given ranges. The exponential space growth of TCAM entries relative to the number of fields is exacerbated when multiple fields contain ranges. In this work, we present a novel approach which identifies properties of many classifiers which can be implemented in linear space and with worst-case guaranteed logarithmic time and allows the addition of more fields including range constraints without impacting space and time complexities. On real-life classifiers from Cisco Systems and additional classifiers from ClassBench [7] (with real parameters), 90-95% of rules are thus handled, and the other 5- 10% of rules can be stored in TCAM to be processed in parallel. Copyright 2014 ACM.",Packet classification; TCAM,Logic gates; Packet networks; Classification rules; Logarithmic time; Network services; Packet classification; Range constraints; Space and time complexity; TCAM; Ternary content addressable memory; Ternary content adressable memory
"Rajiullah M., Hurtig P., Brunstrom A., Petlund A., Welzl M.",5,An evaluation of tail loss recovery mechanisms for TCP,2015,8,"Karlstad University, Sweden; Oslo University, Norway; Simular Research Laboratory, Norway",Karlstad University;Oslo University;Simular Research Laboratory,3,Norway;Sweden,2,23,14,"Interactive applications do not require more bandwidth to go faster. Instead, they require less latency. Unfortunately, the current design of transport protocols such as TCP limits possible latency reductions. In this paper we evaluate and compare different loss recovery enhancements to fight tail loss latency. The two recently proposed mechanisms ""RTO Restart"" (RTOR) and ""Tail Loss Probe"" (TLP) as well as a new mechanism that applies the logic of RTOR to the TLP timer management (TLPR) are considered. The results show that the relative performance of RTOR and TLP when tail loss occurs is scenario dependent, but with TLP having potentially larger gains. The TLPR mechanism reaps the benefits of both approaches and in most scenarios it shows the best performance.",Congestion control; Latency; Packet loss; Recovery; TCP,Congestion control (communication); Packet loss; Recovery; Interactive applications; Latency; Latency reduction; Loss recovery; New mechanisms; Relative performance; Transport protocols; Transmission control protocol
"Naylor D., Mukerjee M.K., Steenkiste P.",3,Balancing accountability and privacy in the network,2015,6,"Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,38,20,"Though most would agree that accountability and privacy are both valuable, today's Internet provides little support for either. Previous efforts have explored ways to offer stronger guarantees for one of the two, typically at the expense of the other; indeed, at first glance accountability and privacy appear mutually exclusive. At the center of the tussle is the source address: in an accountable Internet, source ad- dresses undeniably link packets and senders so hosts can be punished for bad behavior. In a privacy-preserving Internet, source addresses are hidden as much as possible. In this paper, we argue that a balance is possible. We introduce the Accountable and Private Internet Protocol (APIP), which splits source addresses into two separate fields | an accountability address and a return address | and in- Troduces independent mechanisms for managing each. Ac- countability addresses, rather than pointing to hosts, point to accountability delegates, which agree to vouch for packets on their clients' behalves, taking appropriate action when misbehavior is reported. With accountability handled by delegates, senders are now free to mask their return ad- dresses; we discuss a few techniques for doing so. Copyright 2014 ACM.",Accountability; Privacy; Source address,Data privacy; Internet; Accountability; Privacy preserving; Source address; Internet protocols
"Schmidt M., Heimgaertner F., Menth M.",3,Demo: A virtualized lab testbed with physical network outlets for hands-on computer networking education,2015,0,"Dept. of Computer Science, University of Tuebingen, Tuebingen, Germany",University of Tuebingen,1,Germany,1,5,2,"This demo presents a testbed for computer networking education. It leverages hardware virtualization to accommodate 6 PCs and 2 routers on a single testbed host to reduce costs, energy consumption, space requirements, and heat emission. The testbed excels by providing dedicated physical Ethernet and USB interfaces for virtual machines so that students can interconnect them with cables and switches like in a nonvirtualized testbed.",Computer networking education; Virtual machines; VLAN,Education; Energy utilization; Testbeds; Computer networking educations; Hardware virtualization; Heat emission; Physical network; Space requirements; USB interface; Virtual machines; VLAN; Computer networks
"Samadi P., Gupta V., Birand B., Wang H., Zussman G., Bergman K.",6,Accelerating incast and multicast traffic delivery for data-intensive applications using physical layer optics,2015,0,"Department of Electrical Engineering, Columbia University, New York, NY  10027, United States",Columbia University,1,USA,1,4,4,We present a control plane architecture to accelerate multicast and incast traffic delivery for data-intensive applications in cluster-computing interconnection networks. The architecture is experimentally examined by enabling physical layer optical multicasting on-demand for the application layer to achieve non-blocking performance.,Hybrid data center networks; Incast; Multicast; Optics,Cluster computing; Network architecture; Network layers; Optics; Application layers; Control planes; Data-intensive application; Hybrid datum; Incast; Multicast traffic; Optical multicasting; Physical layers; Multicasting
"Kandula S., Menache I., Schwartz R., Babbula S.R.",4,Calendaring for wide area networks,2015,13,"Microsoft, United States",Microsoft,1,USA,1,24,16,"DatacenterWANtra.c consists of high priority transfers that have to be carried as soon as they arrive, alongside large transfers with preassigned deadlines on their completion. The ability to o.er guarantees to large transfers is crucial for business needs and impacts overall cost-of-business. State-of-the-art traffic engineering solutions only consider the current time epoch or minimize maximum utilization and hence cannot provide pre-facto promises to long-lived transfers. We present TEMPUS, an online temporal planning scheme that appropriately packs long-running transfers across network paths and future timesteps, while leaving capacity slack for future changes. TEMPUS builds on a tailored approximate solution to a mixed packing-covering linear program, which is parallelizable and scales well in both running time and memory usage. Consequently, TEMPUS can quickly and effectively update the promised future flow allocation when new transfers arrive or unexpected changes happen. Our experiments on traces from a large productionWANshow, TEMPUS can o.er and keep promises to longlived transfers well in advance of their actual deadlines; the promise on minimal transfer size is comparable with an o.ine optimal solution and outperforms state-of-the-art solutions by 2-3X. Copyright 2014 ACM.",Deadlines; Inter-datacenter; Mixed packing covering; Software-defined networking; Wide area networks,Linear programming; Approximate solution; Datacenter; Deadlines; Mixed packing; Optimal solutions; Software-defined networkings; Temporal planning; Traffic Engineering; Wide area networks
"Shelly N., Jackson E.J., Koponen T., McKeown N., Rajahalme J.",5,Flow caching for high entropy packet fields,2015,3,"Stanford University, United States; VMware, Inc., United States",Stanford University,1,USA,1,11,7,"Packet classification on general purpose CPUs remains expensive regardless of advances in classification algorithms. Unless the packet forwarding pipeline is both simple and static in function, finetuning the system for optimal forwarding is a time-consuming and brittle process. Network virtualization and network function virtualization value general purpose CPUs exactly for their flexibility: in such systems, a single x86 forwarding element does not implement a single, static classification step but a sequence of dynamically reconfigurable and potentially complex forwarding operations. This leaves a software developer looking for maximal packet forwarding throughput with few options besides flow caching. In this paper, we consider the problem of flow caching and more specifically, how to cache forwarding decisions that depend on packet fields with high entropy (and therefore, change often); to this end, we arrive at algorithms that allow us to efficiently compute near optimal flow cache entries spanning several transport connections, even if forwarding decisions depend on transport protocol headers. Copyright 2014 ACM.",Caching; Packet classification,Algorithms; Entropy; Packet networks; Program processors; Virtual reality; Caching; Classification algorithm; General purpose CPUs; Network virtualization; Packet classification; Static classification; Transport connections; Transport protocols; Complex networks
"Tu G.-H., Li Y., Peng C., Li C.-Y., Wang H., Lu S.",6,Control-plane protocol interactions in cellular networks,2015,6,"University of California, Los Angeles, United States; Ohio State University, Columbus, United States",Ohio State University;University of California Los Angeles,2,USA,1,27,18,"Control-plane protocols are complex in cellular networks. They communicate with one another along three dimensions of cross layers, cross (circuit-switched and packet-switched) domains, and cross (3G and 4G) systems. In this work, we propose signaling diagnosis tools and uncover six instances of problematic interactions. Such control-plane issues span both design defects in the 3GPP standards and operational slips by carriers. They are more damaging than data-plane failures. In the worst-case scenario, users may be out of service in 4G, or get stuck in 3G. We deduce root causes, propose solutions, and summarize learned lessons. Copyright 2014 ACM.",Cellular networks; Control-plane; Protocol verification,Complex networks; Mobile security; Wireless networks; Cellular network; Control planes; Design defects; Diagnosis tools; Packet-switched; Protocol verification; Three dimensions; Worst case scenario; Mobile telecommunication systems
"Gebert S., Hock D., Zinner T., Tran-Gia P., Hoffmann M., Jarschel M., Schmidt E.-D., Braun R.-P., Banse C., Köpsel A.",10,Demonstrating the optimal placement of virtualized cellular network functions in case of large crowd events,2015,3,"University of Würzburg, Germany; Nokia, Munich, Germany; Deutsche Telekom T-Labs, Berlin, Germany; Fraunhofer AISEC, Garching, Germany; BISDN, Berlin, Germany",University of Wurzburg,1,Germany,1,6,5,"This demonstration highlights how Network Functions Virtualization (NFV) [1] can be used by a mobile network operator to dynamically provide required mobile core network functions for a large ""Mega"" event like a football game or a concert. Economic reasons may not justify the deployment or continuous maintenance of expensive dedicated hardware at the event site, which is necessary to cope with the extra load temporarily generated by the visitors.",Function placement; Network functions virtualization,Virtual reality; Wireless networks; Cellular network; Continuous maintenance; Dedicated hardware; Mobile core network; Mobile network operators; Network functions; Optimal placements; Virtualizations; Mobile security
"Sun P., Mahajan R., Rexford J., Yuan L., Zhang M., Arefin A.",6,A network-state management service,2015,11,"Princeton, United States; Microsoft, United States",Microsoft,1,USA,1,30,28,"We present Statesman, a network-state management service that allows multiple network management applications to operate independently, while maintaining network-wide safety and performance invariants. Network state captures various aspects of the network such as which links are alive and how switches are forwarding traffic. Statesman uses three views of the network state. In observed state, it maintains an up-to-date view of the actual network state. Applications read this state and propose state changes based on their individual goals. Using a model of dependencies among state variables, Statesman merges these proposed states into a target state that is guaranteed to maintain the safety and performance invariants. It then updates the network to the target state. Statesman has been deployed in ten Microsoft Azure datacenters for several months, and three distinct applications have been built on it. We use the experience from this deployment to demonstrate how Statesman enables each application to meet its goals, while maintaining network-wide invariants.",Datacenter network; Network state; Software-defined networking,Windows operating system; Data center networks; Data centers; Management applications; Multiple networks; Network state; Software-defined networkings; State variables; Target state; Network management
"Fiadino P., Schiavone M., Casas P.",3,Vivisecting WhatsApp through large-scale measurements in mobile networks,2015,9,"FTW, Vienna, Austria","FTW,Austria",1,Austria,1,3,3,"WhatsApp, the new giant in instant multimedia messaging in mobile networks is rapidly increasing its popularity, taking over the traditional SMS/MMS messaging. In this paper we present the first large-scale characterization of WhatsApp, useful among others to ISPs willing to understand the impacts of this and similar applications on their networks. Through the combined analysis of passive measurements at the core of a national mobile network, worldwide geo-distributed active measurements, and traffic analysis at end devices, we show that: (i) the WhatsApp hosting architecture is highly centralized and exclusively located in the US; (ii) video sharing covers almost 40% of the total WhatsApp traffic volume; (iii) flow characteristics depend on the OS of the end device; (iv) despite the big latencies to US servers, download throughputs are as high as 1.5 Mbps; (v) users react immediately and negatively to service outages through social networks feedbacks.",Large-scale measurements; Mobile networks; WhatsApp,Internet service providers; Message passing; Wireless networks; Active measurement; Combined analysis; Flow charac-teristics; Large-scale measurement; Multimedia messaging; Passive measurements; Scale characterization; WhatsApp; Mobile telecommunication systems
"Jeyakumar V., Alizadeh M., Geng Y., Kim C., Mazières D.",5,Millions of little minions: Using packets for low latency network programming and visibility,2015,10,"Stanford University, United States; Cisco Systems, United States; Barefoot Networks, United States",Stanford University,1,USA,1,38,32,"This paper presents a practical approach to rapidly introducing new dataplane functionality into networks: End-hosts embed tiny programs into packets to actively query and manipulate a network's internal state. We show how this ""tiny packet program"" (TPP) interface gives end-hosts unprecedented visibility into network behavior, enabling them to work with the network to achieve a desired functionality. Our design leverages what each component does best: (a) switches forward and execute tiny packet programs (at most 5 instructions) in-band at line rate, and (b) end-hosts perform arbitrary (and easily updated) computation on network state. By implementing three different research proposals, we show that TPPs are useful. Using a hardware prototype on a NetFPGA, we show our design is feasible at a reasonable cost.",Active networks; Network architecture; SDN; Software-defined networks; Switch ASIC design,Active networks; Computer programming; Design; Integrated circuits; Switching circuits; Visibility; ASIC design; Hardware prototype; Internal state; Low-latency networks; Network behaviors; Research proposals; SDN; Software-defined networks; Network architecture
"Rasley J., Stephens B., Dixon C., Rozner E., Felter W., Agarwal K., Carter J., Fonseca R.",8,Planck: Millisecond-scale monitoring and control for commodity networks,2015,15,"Brown University, United States; Rice University, United States; IBM Research, Austin, TX, United States; Brocade, United States",Brown University;IBM;Rice University,3,USA,1,44,28,"Software-defined networking introduces the possibility of building self-tuning networks that constantly monitor network conditions and react rapidly to important events such as congestion. Unfortunately, state-of-the-art monitoring mechanisms for conventional networks require hundreds of milliseconds to seconds to extract global network state, like link utilization or the identity of ""elephant"" flows. Such latencies are adequate for responding to persistent issues, e.g., link failures or long-lasting congestion, but are inadequate for responding to transient problems, e.g., congestion induced by bursty workloads sharing a link. In this paper, we present Planck, a novel network measurement architecture that employs oversubscribed port mirroring to extract network information at 280 us-7 ms timescales on a 1 Gbps commodity switch and 275 us-4 ms timescales on a 10 Gbps commodity switch, over 11x and 18x faster than recent approaches, respectively (and up to 291x if switch firmware allowed buffering to be disabled on some ports). To demonstrate the value of Planck's speed and accuracy, we use it to drive a traffic engineering application that can reroute congested flows in milliseconds. On a 10 Gbps commodity switch, Planck-driven traffic engineering achieves aggregate throughput within 1-4% of optimal for most workloads we evaluated, even with flows as small as 50 MiB, an improvement of up to 53% over previous schemes.",Networking measurement; Software-defined networking; Traffic engineering,Aggregate throughput; Monitoring and control; Monitoring mechanisms; Network information; Network measurement; Software-defined networkings; Traffic Engineering; Transient problems; Firmware
"Gupta A., Vanbever L., Shahbaz M., Donovan S.P., Schlinker B., Feamster N., Rexford J., Shenker S., Clark R., Katz-Bassett E.",10,SDX: A software defined internet exchange,2015,22,"Georgia Tech, United States; Princeton University, United States; UC Berkeley, United States; Univ. of Southern California, United States",Georgia Tech;Princeton University;University of California Berkeley;University of Southern California,4,USA,1,23,12,"BGP severely constrains how networks can deliver traffic over the Internet. Today's networks can only forward traffic based on the destination IP prefix, by selecting among routes offered by their immediate neighbors. We believe Software Defined Networking (SDN) could revolutionize wide-area traffic delivery, by offering direct control over packet-processing rules that match on multiple header fields and perform a variety of actions. Internet exchange points (IXPs) are a compelling place to start, given their central role in interconnecting many networks and their growing importance in bringing popular content closer to end users. To realize a Software Defined IXP (an ""SDX""), we must create compelling applications, such as ""application-specific peering""-where two networks peer only for (say) streaming video traffic. We also need new programming abstractions that allow participating networks to create and run these applications and a runtime that both behaves correctly when interacting with BGP and ensures that applications do not interfere with each other. Finally, we must ensure that the system scales, both in rule-table size and computational overhead. In this paper, we tackle these challenges and demonstrate the flexibility and scalability of our solutions through controlled and in-the-wild experiments. Our experiments demonstrate that our SDX implementation can implement representative policies for hundreds of participants who advertise full routing tables while achieving sub-second convergence in response to configuration changes and routing updates.",BGP; Internet exchange point (IXP); Software defined networking (SDN),Application programs; Computer programming; Internet; Packet networks; Application specific; BGP; Computational overheads; Internet Exchange; Internet exchange points; Programming abstractions; Software defined networking (SDN); Wide-area traffic; Computer systems programming
"Wamser F., Zinner T., Iffländer L., Tran-Gia P.",4,Demonstrating the prospects of dynamic application-aware networking in a home environment,2015,2,"Institute of Computer Science, University of Würzburg, Germany",Institute of Computer Science;University of Wurzburg,2,Germany,1,5,3,"The success of tablet computers, game consoles, and Smart TVs reects the increased user demand for Internet-based services at home. The users in the home network can access value-added services offered directly by the network provider, such as IPTV. Likewise, they also use Over-The- Top (OTT) services like YouTube, Netix, or online gaming and browse the web or download files. All these services have specific requirements with respect to the network re- sources which have to be fulfilled to ensure a good Quality- of-Experience (QoE) for the users. Furthermore, multiple users may concurrently access different services via the central Internet access point in the home network, the home gateway, cf. Figure 1.",Application-aware networking; Dynamic resource allocation; Home networks; Youtube,Carrier communication; Computer games; Home networks; Internet; Personal communication systems; Quality of service; Social networking (online); Different services; Dynamic applications; Dynamic resource allocations; Home environment; Internet-based services; Quality of experience (QoE); Value added service; YouTube; Gateways (computer networks)
"Bao J., Zhao B., Yu W., Feng Z., Wu C., Gong Z.",6,OpenSAN: A software-defined satellite network architecture,2015,18,"College of Computer, National University of Defense Technology, Changsha, Hunan, China",National University of Defense Technology,1,China,1,4,3,"In recent years, with the rapid development of satellite technology including On Board Processing (OBP) and Inter Satellite Link (ISL), satellite network devices such as space IP routers have been experimentally carried in space. However, there are many difficulties to build a future satellite network with current terrestrial Internet technologies due to the distinguished space features, such as the severely limited resources, remote hardware/software upgrade in space. In this paper, we propose OpenSAN, a novel architecture of software-defined satellite network. By decoupling the data plane and control plane, OpenSAN provides satellite network with high efficiency, finegrained control, as well as flexibility to support future advanced network technology. Furthermore, we also discuss some practical challenges in the deployment of OpenSAN.",Satellite network; Software-defined network,Satellite links; Satellites; Advanced network technologies; Fine-grained control; Inter-satellite link; Internet technology; On-board processing; Satellite network; Satellite technology; Software-defined networks; Network architecture
"Zhu L., Hu Z., Heidemann J., Wessels D., Mankin A., Somaiya N.",6,T-DNS: Connection-oriented DNS to improve privacy and security (poster abstract),2015,2,"University of Southern California, United States; Verisign Labs, United States",University of Southern California,1,USA,1,17,16,"DNS is the canonical protocol for connectionless UDP. Yet DNS today is challenged by eavesdropping that compromises privacy, source-address spoofing that results in denial-of-service (DoS) attacks on the server and third parties, injection attacks that exploit fragmentation, and size limitations that constrain policy and operational choices. We propose T-DNS to address these problems. It uses TCP to smoothly support large payloads and to mitigate spoofing and amplification for DoS. T-DNS uses transport-layer security (TLS) to provide privacy from users to their DNS re- solvers and optionally to authoritative servers. Expectations about DNS suggest connections will balloon client latency and overwhelm servers with state, but our evaluation shows costs are modest: end-to-end latency from TLS to the recursive resolver is only about 9% slower with UDP to the authoritative server, and 22% slower with TCP to the authoritative. With diverse traces we show that frequent connection reuse is possible (60{95% for stub and recursive resolvers, al-Though half that for authoritative servers), and after connection establishment, we show TCP and TLS latency is equivalent to UDP. With conservative timeouts (20 s at authoritative servers and 60 s elsewhere) and conservative estimates of connection state memory requirements, we show that server memory requirements match current hardware: a large recursive resolver may have 24k active connections requiring about 3.6GB additional RAM. We identify the key design and implementation decisions needed to minimize overhead: query pipelining, out-of-order responses, TLS connection resumption, and plausible timeouts.",Domain name system (DNS); Network protocols; Performance; Privacy; Security; Transport layer security (TLS),Balloons; Data privacy; Denial-of-service attack; Mobile security; Network protocols; Network security; Random access storage; Seebeck effect; Transmission control protocol; Design and implementations; Domain name system; End to end latencies; Memory requirements; Performance; Privacy and security; Security; Transport layer security; Internet protocols
"Liu Y.J., Gao P.X., Wong B., Keshav S.",4,Quartz: A new design element for low-latency DCNs,2015,8,"UC Berkeley, United States; University of Waterloo, Canada",University of California Berkeley;University of Waterloo,2,Canada;USA,2,43,38,"Most datacenter network (DCN) designs focus on maximizing bisection bandwidth rather than minimizing server-to-server latency. We explore architectural approaches to building low-latency DCNs and introduce Quartz, a design element consisting of a full mesh of switches. Quartz can be used to replace portions of either a hierarchical network or a random network. Our analysis shows that replacing high port-count core switches with Quartz can significantly reduce switching delays, and replacing groups of top of- rack and aggregation switches with Quartz can significantly reduce congestion-related delays from cross-traffic. We overcome the complexity of wiring a complete mesh using low-cost optical multiplexers that enable us to efficiently implement a logical mesh as a physical ring. We evaluate our performance using both simulations and a small working prototype. Our evaluation results confirm our analysis, and demonstrate that it is possible to build low-latency DCNs using inexpensive commodity elements without significant concessions to cost, scalability, or wiring complexity. Copyright 2014 ACM.",Datacenter; Latency; Optical technologies; WDM,Complex networks; Cost benefit analysis; Quartz; Telecommunication networks; Wavelength division multiplexing; Architectural approach; Bisection bandwidth; Data center networks; Datacenter; Hierarchical network; Latency; Optical multiplexers; Optical technology; Design
"Marinos I., Watson R.N.M., Handley M.",3,Network stack specialization for performance,2015,15,"University of Cambridge, United Kingdom; University College London, United Kingdom",University College London;University of Cambridge,2,UK,1,33,9,"Contemporary network stacks are masterpieces of generality, supporting many edge-node and middle-node functions. Generality comes at a high performance cost: current APIs, memory models, and implementations drastically limit the effectiveness of increasingly powerful hardware. Generality has historically been required so that individual systems could perform many functions. However, as providers have scaled services to support millions of users, they have transitioned toward thousands (or millions) of dedicated servers, each performing a few functions. We argue that the overhead of generality is now a key obstacle to effective scaling, making specialization not only viable, but necessary. We present Sandstorm and Namestorm, web and DNS servers that utilize a clean-slate userspace network stack that exploits knowledge of application-specific workloads. Based on the netmap framework, our novel approach merges application and network-stack memory models, aggressively amortizes protocol-layer costs based on application-layer knowledge, couples tightly with the NIC event model, and exploits microarchitectural features. Simultaneously, the servers retain use of conventional programming frameworks. We compare our approach with the FreeBSD and Linux stacks using the nginx web server and NSD name server, demonstrating 2-10× and 9× improvements in web-server and DNS throughput, lower CPU usage, linear multicore scaling, and saturated NIC hardware. Copyright 2014 ACM.",Clean-slate design; Network performance; Network stacks; Networkstack specialization,Computer operating systems; Hardware; Internet protocols; Network performance; Slate; Social networking (online); Storms; Web services; World Wide Web; Application layers; Application specific; Clean slates; Dedicated servers; Individual systems; Network stack; Networkstack specialization; Programming framework; Computer hardware
"Manco F., Martins J., Huici F.",3,Towards the super fluid cloud,2015,5,"NEC Europe Ltd., United States",NEC,1,USA,1,11,10,"Traditionally, the number of VMs running on a server and how quickly these can be migrated has been less than optimal mostly because of the memory and CPU requirements imposed on the system by the full-edged OSes that the VMs run. More recently, work towards VMs based on minimalistic or specialized OSes has started pushing the envelope of how reactive or uid the cloud can be. In this demo we will demonstrate how to concurrently execute thousands of Xenbased VMs on a single inexpensive server. We will also show instantiation and migraion of such VMs in tens of milliseconds, and transparent, wide area migration of virtualized middleboxes by combining such VMs with the multi-path TCP (MPTCP) protocol.",Cloud; Performance; Server consolidation; Virtualization; Xen,Clouds; Middleboxes; Multipaths; Performance; Server consolidation; Virtualizations; Xen; Transmission control protocol
"Mukerjee M.K., Hong J.A.H., Jiang J., Naylor D., Han D., Seshan S., Zhang H.",7,Enabling near real-time central control for live video delivery in CDNs,2015,2,"Carnegie Mellon University, United States; KAIST, South Korea",Carnegie Mellon University;KAIST,2,South Korea;USA,2,11,12,"nternet video delivery is experiencing a dramatic change. Live video dominates on-demand video in user engagement| PC viewers watch live video 11x more than VoD [2]. Live streaming services like Twitch, YouTube Live, and Ustream support many workloads: from mega-events (e.g., sporting events) viewed by tens of millions of users, to thousands of popular channels (>1,000 viewers), to many more less popular channels in the \long-tail"". However, the addition of user-created live content is causing a fundamental shift towards unpredictable popularity dynamics.",CDNs; Central optimization; Hybrid control; Live video,CDNs; Central control; Hybrid controls; Live streaming; Live video; Near-real time; User engagement; Video delivery; Video streaming
"Cao Z., Kodialam M., Lakshman T.V.",3,Traffic steering in software defined networks: Planning and online routing,2015,2,"5 MetroTech Center, Polytechnic School of Engineering, New York University, Brooklyn, NY  11201, United States; Alcatel-Lucent, Bell Laboratories, 791 Holmdel Road, HolmdelNJ  07733, United States",Bell Laboratories;New York University,2,USA,1,16,15,"Middleboxes have become ubiquitous in data center as well as wide area networks. Simple routing of flows from ingress to egress along shortest paths has been replaced by policy aware paths that have to pass through the required set of middleboxes. The complex routing is one of the major impetus for the Software Defined Networking (SDN) paradigm. In this paper, we consider both offline planning and online routing problems in SDN framework. The offline planning problem is one where aggregate demands are specified and the objective is to determine whether there is enough capacity in the network to handle the demands. We develop a fast FPTAS for the problem based on segmentation and lazy dual update. In the online routing problem, flow requests are given one at a time and the objective is to steer the flows to maximize the total amount of traffic accepted over time. We develop a log-competitive algorithm based on time-dependent duals. Copyright 2014 ACM.",FPTAS; Middlebox; Software defined networks; Traffic scheduling,Complex networks; Scheduling; Social networking (online); Competitive algorithms; FPTAS; Middleboxes; Off-line planning; Online routing problems; Software defined networking (SDN); Software-defined networks; Traffic scheduling; Wide area networks
"Kumar S., Hamed E., Katabi D., Li L.E.",4,LTE radio analytics made easy and accessible,2015,12,"Massachusetts Institute of Technology, United States; Bell Labs, Alcatel-Lucent, United States",Bell Labs;MIT,2,USA,1,31,20,"Despite the rapid growth of next-generation cellular networks, researchers and end-users today have limited visibility into the performance and problems of these networks. As LTE deployments move towards femto and pico cells, even operators struggle to fully understand the propagation and interference patterns affecting their service, particularly indoors. This paper introduces LTEye, the first open platform to monitor and analyze LTE radio performance at a fine temporal and spatial granularity. LTEye accesses the LTE PHY layer without requiring private user information or provider support. It provides deep insights into the PHY-layer protocols deployed in these networks. LTEye's analytics enable researchers and policy makers to uncover serious deficiencies in these networks due to inefficient spectrum utilization and inter-cell interference. In addition, LTEye extends synthetic aperture radar (SAR), widely used for radar and backscatter signals, to operate over cellular signals. This enables businesses and end-users to localize mobile users and capture the distribution of LTE performance across spatial locations in their facility. As a result, they can diagnose problems and better plan deployment of repeaters or femto cells. We implement LTEye on USRP software radios, and present empirical insights and analytics from multiple AT&T and Verizon base stations in our locality.",Analytics; Cellular; LTE; PHY; Wireless,Femtocell; Mobile security; Mobile telecommunication systems; Next generation networks; Radar; Radio; Synthetic aperture radar; Analytics; Cellular; Intercell interference; Interference patterns; LTE; Next generation cellular networks; PHY; Spectrum utilization; Wireless telecommunication systems
"Mok R.K.P., Li W., Chang R.K.C.",3,A user behavior based cheat detection mechanism for crowdtesting,2015,0,"Department of Computing, Hong Kong Polytechnic University, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,5,2,"Crowdtesting is increasingly popular among researchers to carry out subjective assessments of different services. Experimenters can easily assess to a huge pool of human subjects through crowdsourcing platforms. The workers are usually anonymous, and they participate in the experiments independently. Therefore, a fundamental problem threatening the integrity of these platforms is to detect various types of cheating from the workers. In this poster, we propose cheat-detection mechanism based on an analysis of the workers' mouse cursor trajectories. It provides a jQuery-based library to record browser events. We compute a set of metrics from the cursor traces to identify cheaters. We deploy our mechanism to the survey pages for our video quality assessment tasks published on Amazon Mechanical Turk. Our results show that cheaters' cursor movement is usually more direct and contains less pauses.",Cheat-detection; Crowdsourcing; Cursor submovement,Amazon mechanical turks; Cheat detection; Crowdsourcing; Crowdsourcing platforms; Different services; Subjective assessments; Submovements; Video quality assessment; Behavioral research
"Liu H.H., Kandula S., Mahajan R., Zhang M., Gelernter D.",5,Traffic engineering with forward fault correction,2015,21,"Yale University, United States; Microsoft Research, United States",Microsoft;Yale University,2,USA,1,30,2,"Network faults such as link failures and high switch configuration delays can cause heavy congestion and packet loss. Because it takes time for the traffic engineering systems to detect and react to such faults, these conditions can last long-even tens of seconds. We propose forward fault correction (FFC), a proactive approach for handling faults. FFC spreads network traffic such that freedom from congestion is guaranteed under arbitrary combinations of up to k faults. We show how FFC can be practically realized by compactly encoding the constraints that arise from this large number of possible faults and solving them efficiently using sorting networks. Experiments with data from real networks show that, with negligible loss in overall network throughput, FFC can reduce data loss by a factor of 7-130 in well-provisioned networks, and reduce the loss of high-priority traffic to almost zero in wellutilized networks. Copyright 2014 ACM.",Congestion-free; Fault tolerance; Traffic engineering,Fault tolerance; Congestion-free; Fault corrections; Network traffic; Overall networks; Pro-active approach; Sorting network; Switch configuration; Traffic Engineering; Traffic congestion
"Jin X., Liu H.H., Gandhi R., Kandula S., Mahajan R., Zhang M., Rexford J., Wattenhofer R.",8,Dynamic scheduling of network updates,2015,27,"Microsoft Research, United States; Princeton University, United States; Yale University, United States; Purdue University, United States; ETH Zurich, Switzerland",ETH Zurich;Microsoft;Princeton University;Purdue University;Yale University,5,Switzerland;USA,2,35,29,"We present Dionysus, a system for fast, consistent network updates in software-defined networks. Dionysus encodes as a graph the consistency-related dependencies among updates at individual switches, and it then dynamically schedules these updates based on runtime differences in the update speeds of different switches. This dynamic scheduling is the key to its speed; prior update methods are slow because they pre-determine a schedule, which does not adapt to runtime conditions. Testbed experiments and data-driven simulations show that Dionysus improves the median update speed by 53-88% in both wide area and data center networks compared to prior methods. Copyright 2014 ACM.",Network update; Software-defined networking,Wide area networks; Consistent network; Data center networks; Data-driven simulation; Dynamic scheduling; Runtimes; Software-defined networkings; Software-defined networks; Scheduling
"Gember-Jacobson A., Viswanathan R., Prakash C., Grandl R., Khalid J., Das S., Akella A.",7,OpenNF: Enabling innovation in network function control,2015,65,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,38,21,"Network functions virtualization (NFV) together with softwaredefined networking (SDN) has the potential to help operators satisfy tight service level agreements, accurately monitor and manipulate network traffic, and minimize operating expenses. However, in scenarios that require packet processing to be redistributed across a collection of network function (NF) instances, simultaneously achieving all three goals requires a framework that provides efficient, coordinated control of both internal NF state and network forwarding state. To this end, we design a control plane called OpenNF. We use carefully designed APIs and a clever combination of events and forwarding updates to address race conditions, bound overhead, and accommodate a variety of NFs. Our evaluation shows that OpenNF offers efficient state control without compromising flexibility, and requires modest additions to NFs. Copyright 2014 ACM.",Middleboxes; Network functions; Software-defined networking,Packet networks; Co-ordinated control; Forwarding state; Middleboxes; Network functions; Operating expense; Packet processing; Service Level Agreements; Software-defined networkings; Network architecture
"Yang T., Xie G., Li Y.B., Fu Q., Liu A.X., Li Q., Mathy L.",7,Guarantee IP lookup performance with FIB explosion,2015,7,"ICT, CAS, China; Hunan University, China; Department of Computer Science and Engineering, Michigan State University, United States; University of Liege, Belgium",Hunan University;Michigan State University;University of Liege,3,Belgium;China;USA,3,42,19,"The Forwarding Information Base (FIB) of backbone routers has been rapidly growing in size. An ideal IP lookup algorithm should achieve constant, yet small, IP lookup time and on-chip memory usage. However, no prior IP lookup algorithm achieves both requirements at the same time. In this paper, we first propose SAIL, a Splitting Approach to IP Lookup. One splitting is along the dimension of the lookup process, namely finding the prefix length and finding the next hop, and another splitting is along the dimension of prefix length, namely IP lookup on prefixes of length less than or equal to 24 and IP lookup on prefixes of length longer than 24. Second, we propose a suite of algorithms for IP lookup based on our SAIL framework. Third, we implemented our algorithms on four platforms: CPU, FPGA, GPU, and many-core. We conducted extensive experiments to evaluate our algorithms using real FIBs and real traffic from a major ISP in China. Experimental results show that our SAIL algorithms are several times or even two orders of magnitude faster than well known IP lookup algorithms. Copyright 2014 ACM.",IP lookup; LPM; SAIL; Virtual router multi-FIB lookup,Algorithms; Field programmable gate arrays (FPGA); Routers; Information base; IP lookup; IP lookup algorithm; Lookups; LPM; On chip memory; Orders of magnitude; SAIL; Microprocessor chips
"Grandl R., Ananthanarayanan G., Kandula S., Rao S., Akella A.",5,Multi-resource packing for cluster schedulers,2015,37,"Microsoft, United States; Univ. of Wisconsin, Madison, United States; Univ. of California, Berkeley, United States",Microsoft;University of California Berkeley;University of Wisconsin-Madison,3,USA,1,30,19,"Tasks in modern data-parallel clusters have highly diverse resource requirements along CPU,memory, disk and network. We presentTetris, amulti-resource cluster scheduler that packs tasks to machines based on their requirements of all resource types. Doing so avoids resource fragmentation as well as over-allocation of the resources that are not explicitly allocated, both of which are drawbacks of current schedulers. Tetris adapts heuristics for the multidimensional bin packing problem to the context of cluster schedulers wherein task arrivals and machine availability change in an online manner and wherein task's resource needs change with time and with the machine that the task is placed at. In addition, Tetris improves average job completion time by preferentially serving jobs that have less remaining work. We observe that fair allocations do not o.er the best performance and the above heuristics are compatible with a large class of fairness policies; hence, we show how to simultaneously achieve good performance and fairness. Tracedriven simulations and deployment of our Apache YARN prototype on a 250 node cluster show gains of over 30% in makespan and job completion time while achieving nearly perfect fairness. Copyright 2014 ACM.",Cluster schedulers; Completion time; Fairness; Makespan; Multi-dimensional packing,Scheduling; Scheduling algorithms; Cluster schedulers; Completion time; Fairness; Makespan; Multi dimensional; Job shop scheduling
"Bharadia D., Joshi K.R., Katti S.",3,Robust full duplex radio link,2015,0,"Stanford University, United States",Stanford University,1,USA,1,8,6,"This paper presents demonstration of a real-time full duplex point-to-point link, where transmission and reception occurs in the same spectrum band simultaneously between a pair of full-duplex radios. This demo first builds a full duplex radio by implementing selfinterference cancellation technique on top of a traditional half duplex radio architecture. We then establish a point-to-point link using a pair of these radios that can transmit and receive OFDM packets. By changing the environmental conditions around the full-duplex radios we then demonstrate the robustness of the self-interference cancellation to adapt to the changing environment.",Full duplex; Interference cancellation; Non-linear cancellation,Radio links; Cancellation techniques; Changing environment; Environmental conditions; Full-duplex; Interference cancellation; Non linear; Point-to-point link; Radio architectures; Radio transmission
"Gupta A., Vanbever L., Shahbaz M., Donovan S.P., Schlinker B., Feamster N., Rexford J., Shenker S., Clark R., Katz-Bassett E.",10,SDX: Software defined internet exchange,2015,1,"Georgia Tech, United States; Princeton University, United States; UC Berkeley, United States; Univ. of Southern California, United States",Georgia Tech;Princeton University;University of California Berkeley;University of Southern California,4,USA,1,3,2,"BGP severely constrains how networks can deliver traffic over the Internet. Today's networks can only forward traffic based on the destination IP prefix, by selecting among routes offered by their immediate neighbors. We believe Software Defined Networking (SDN) could revolutionize wide-area traffic delivery, by offering direct control over packet-processing rules that match on multiple header fields and perform a variety of actions. Internet exchange points (IXPs) are a compelling place to start, given their central role in interconnecting many networks and their growing importance in bringing popular content closer to end users. To realize a Software Defined IXP (an ""SDX""), need new programming abstractions that allow participating networks to create and run these applications and a runtime that both behaves correctly when interacting with BGP and ensures that applications do not interfere with each other. We must also ensure that the system scales, both in rule-table size and computational overhead. In this demo, we show how we tackle these challenges demonstrating the flexibility and scalability of our SDX platform. The paper also appears in the main program [1].",BGP; Internet exchange point (IXP); Software defined networking (SDN),Application programs; Computer programming; Internet; Packet networks; BGP; Computational overheads; Internet Exchange; Internet exchange points; Packet processing; Programming abstractions; Software defined networking (SDN); Wide-area traffic; Computer systems programming
"Ge X., Liu Y., Du D.H.C., Zhang L., Guan H., Chen J., Zhao Y., Hu X.",8,OpenANFV: Accelerating network function virtualization with a consolidated framework in openstack,2015,11,"Department of Computer Science and Engineering, University of Minnesota, United States; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Huawei Corporation, China",Shenzhen Institutes of Advanced Technology;University of Minnesota,2,China;USA,2,5,4,"Specified appliances or middleboxes (MBs) have been explosively used to satisfy a various set of functions in operational modern networks, such as enhancing security (e.g. firewalls), improving performance (e.g. WAN optimized accelerators), providing QoS (e.g. Deep Packet Inspection (DPI)), and meeting the requisite others [3]. Network Function Virtualization (NFV) recently has been proposed to optimize the deployment of multiple network functions through shifting the MB processing from customized MBs to softwarecontrolled inexpensive and commonly used hardware platforms (e.g. Intel standard x86 servers) [4]. However, for some functions (e.g. DPI and Network Deduplication (Dedup), Network Address Translation (NAT)), the commodity shared hardware substrate remain limited performance. For a standard software based Dedup MB (Intel E5645, 2.4GHZ, 6 cores, exclusive mode), we can only achieve 267Mbps throughput in each core at most. Therefore, the resources of dedicated accelerators (e.g. FPGA) are still required to bridge the gap between software-based MB and the commodity hardware.",FPGA; Middlebox; Network function virtualization; OpenStack,Computer viruses; Field programmable gate arrays (FPGA); Hardware; Packet networks; Virtual reality; Commodity hardware; Deep packet inspection (DPI); Hardware platform; Improving performance; Middleboxes; Network address translations; OpenStack; Virtualizations; Computer hardware
"Peter S., Javed U., Zhang Q., Woos D., Anderson T., Krishnamurthy A.",6,One tunnel is (often) enough,2015,3,"University of Washington, United States",University of Washington at St. Louis,1,USA,1,39,29,"A longstanding problem with the Internet is that it is vulnerable to outages, black holes, hijacking and denial of service. Although architectural solutions have been proposed to address many of these issues, they have had difficulty being adopted due to the need for widespread adoption before most users would see any benefit. This is especially relevant as the Internet is increasingly used for applications where correct and continuous operation is essential. In this paper, we study whether a simple, easy to implement model is sufficient for addressing the aforementioned Internet vulnerabilities. Our model, called ARROW(Advertised Reliable Routing Over Waypoints), is designed to allow users to configure reliable and secure end to end paths through participating providers. With ARROW, a highly reliable ISP offers tunneled transit through its network, along with packet transformation at the ingress, as a service to remote paying customers. Those customers can stitch together reliable end to end paths through a combination of participating and non-participating ISPs in order to improve the faulttolerance, robustness, and security of mission critical transmissions. Unlike efforts to redesign the Internet from scratch, we show that ARROW can address a set of well-known Internet vulnerabilities, for most users, with the adoption of only a single transit ISP. To demonstrate ARROW, we have added it to a small-scale wide-area ISP we control. We evaluate its performance and failure recovery properties in both simulation and live settings.",BGP; Internet; Overlay networks; Reliability; Source routing,Denial-of-service attack; Internet; Mobile security; Overlay networks; Reliability; Telecommunication networks; Architectural solutions; BGP; Continuous operation; Denial of Service; Mission critical; Packet transformations; Reliable routing; Source routing; Internet service providers
"Kim T.H.-J., Basescu C., Jia L., Lee S.B., Hu Y.-C., Perrig A.",6,Lightweight source authentication and path validation,2015,12,"CyLab, CMU, United States; Qualcomm, United States; UIUC, United States; ETH Zürich, Switzerland",ETH Zurich;UIUC,2,Switzerland;USA,2,40,26,"In-network source authentication and path validation are fundamental primitives to construct higher-level security mechanisms such as DDoS mitigation, path compliance, packet attribution, or protection against flow redirection. Unfortunately, currently proposed solutions either fall short of addressing important security concerns or require a substantial amount of router overhead. In this paper, we propose lightweight, scalable, and secure protocols for shared key setup, source authentication, and path validation. Our prototype implementation demonstrates the efficiency and scalability of the protocols, especially for software-based implementations. Copyright 2014 ACM.",Path validation; Retroactive key setup; Source authentication,Compliant mechanisms; Mobile security; Routers; Ddos mitigations; Higher-level security; In networks; Key setups; Path validation; Prototype implementations; Secure protocols; Source authentication; Authentication
"Gandhi R., Liu H.H., Hu Y.C., Lu G., Padhye J., Yuan L., Zhang M.",7,Duet: Cloud scale load balancing with hardware and software,2015,12,"Microsoft, United States; Purdue University, United States; Yale University, United States",Microsoft;Purdue University;Yale University,3,USA,1,23,15,"Load balancing is a foundational function of datacenter infrastructures and is critical to the performance of online services hosted in datacenters. As the demand for cloud services grows, expensive and hard-to-scale dedicated hardware load balancers are being replaced with software load balancers that scale using a distributed data plane that runs on commodity servers. Software load balancers offer low cost, high availability and high flexibility, but suffer high latency and low capacity per load balancer, making them less than ideal for applications that demand either high throughput, or low latency or both. In this paper, we present DUET, which offers all the benefits of software load balancer, along with low latency and high availability - at next to no cost. We do this by exploiting a hitherto overlooked resource in the data center networks - The switches themselves. We show how to embed the load balancing functionality into existing hardware switches, thereby achieving organic scalability at no extra cost. For flexibility and high availability, DUET seamlessly integrates the switch-based load balancer with a small deployment of software load balancer. We enumerate and solve several architectural and algorithmic challenges involved in building such a hybrid load balancer. We evaluate DUET using a prototype implementation, as well as extensive simulations driven by traces from our production data centers. Our evaluation shows that DUET provides 10x more capacity than a software load balancer, at a fraction of a cost, while reducing latency by a factor of 10 or more, and is able to quickly adapt to network dynamics including failures. Copyright 2014 ACM.",Datacenter; Load balancing; SDN,Application programs; Computer hardware; Costs; Hardware; Parallel architectures; Resource allocation; Data center networks; Datacenter; Dedicated hardware; Extensive simulations; Hardware and software; High availability; Prototype implementations; SDN; Network management
"Ashok A., Subbiah I., Varga G., Schrey M., Heinen S., Achtzehn A., Petrova M.",7,WhiteLAN: Facilitate cost-efficient SDR research with COTS IEEE 802.11b/g devices,2015,0,"Integrated Analog Circuits and RF Systems, RWTH Aachen University, Aachen, D-52062, Germany; Institute for Networked Systems, RWTH Aachen University, Aachen, D-52062, Germany",RWTH Aachen University,1,Germany,1,15,8,"To build large and scalable setups, researchers usually employ mixed testbeds of regular SDR devices and cheaper, generally less exible COTS devices. Such hybrid setups often face uncontrollable interference from other users in the ISM bands, which leads to incomparable results and requires frequent repetitions of experiments. Maintaining the ability to use COTS devices and ISM band-only SDR devices while moving experiments to less crowded frequency bands is thus of high interest to practical wireless communications research. In this paper we present whiteLAN, a frequency converter that enables IEEE 802.11b/g devices to operate over UHF frequencies. We discuss the advantages of a ISM- UHF converter setup, present the hardware architecture of our solution, and provide key performance metrics of the physical implementation. Through a comparative study of ISM vs. UHF operations we show that whiteLAN is viable for use as a plug-and-play extension for wireless research deployments. Copyright 2014 ACM.",IEEE 802.11; ISM bands; SDR; Testbed; UHF; Wi-Fi,Frequency bands; Standards; Wi-Fi; Wireless telecommunication systems; Comparative studies; Hardware architecture; IEEE 802.11s; ISM bands; Performance metrics; SDR; UHF; Wireless communications; Testbeds
"Chen S., Fang D., Chen X., Xia T., Jin M.",5,Aerial wireless localization using target-guided flight route,2015,1,"Northwest University, China",Northwest University,1,China,1,3,3,"This poster presents GuideLoc, a highly efficient aerial wireless localization system that uses directional antennas mounted on a mini Multirotor Unmanned Aerial Vehicle (UAV) to enable detecting and positioning of targets. Taking advantage of angle and signal strength of frames transmitted from targets, GuideLoc can directly fly towards the targets with the minimum flight route and time. We implement a prototype of GuideLoc and evaluate the performance by simulations and experiments. Experimental results show that GuideLoc achieves an average location accuracy of 2.7 meters and reduces flight distance more than 50% compared with existing localization approaches using UAV.",Flight routes; Multi-rotor UAV; Wireless localization,Directive antennas; Unmanned vehicles; Directional Antenna; Flight route; Location accuracy; Signal strengths; Wireless localization; Wireless localization systems; Unmanned aerial vehicles (UAV)
"Scott C., Wundsam A., Raghavan B., Panda A., Or A., Lai J., Huang E., Liu Z., El-Hassany A., Whitlock S., Acharya H.B., Zarifis K., Shenker S.",13,Troubleshooting blackbox SDN control software with minimal causal sequences,2015,14,"UC Berkeley, United States; Big Switch Networks, United States; ICSI, United States; Tshinghua University, China; EPFL, Switzerland; USC, United States","EPFL,Switzerland;Tsinghua University;University of California Berkeley;University of Southern California",4,China;Switzerland;USA,3,61,0,"Software bugs are inevitable in software-defined networking control software, and troubleshooting is a tedious, time-consuming task. In this paper we discuss how to improve control software troubleshooting by presenting a technique for automatically identifying a minimal sequence of inputs responsible for triggering a given bug, without making assumptions about the language or instrumentation of the software under test. We apply our technique to five open source SDN control platforms-Floodlight, NOX, POX, Pyretic, ONOS-and illustrate how the minimal causal sequences our system found aided the troubleshooting process.",SDN control software; Test case minimization; Troubleshooting,Diagnosis; Electric lighting; Open source software; Open systems; Program debugging; Black boxes; Control platform; Control software; Open sources; Software bug; Software-defined networkings; Test-case minimizations; Time-consuming tasks; Software testing
"Sivaraman A., Winstein K., Thaker P., Balakrishnan H.",4,An experimental study of the learnability of congestion control,2015,9,"Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,31,10,"When designing a distributed network protocol, typically it is infeasible to fully define the target network where the protocol is intended to be used. It is therefore natural to ask: How faithfully do protocol designers really need to understand the networks they design for? What are the important signals that endpoints should listen to? How can researchers gain confidence that systems that work well on well-characterized test networks during development will also perform adequately on real networks that are inevitably more complex, or future networks yet to be developed? Is there a tradeoff between the performance of a protocol and the breadth of its intended operating range of networks? What is the cost of playing fairly with cross-traffic that is governed by another protocol? We examine these questions quantitatively in the context of congestion control, by using an automated protocol-design tool to approximate the best possible congestion-control scheme given imperfect prior knowledge about the network. We found only weak evidence of a tradeoff between operating range in link speeds and performance, even when the operating range was extended to cover a thousand-fold range of link speeds. We found that it may be acceptable to simplify some characteristics of the network-such as its topology-when modeling for design purposes. Some other features, such as the degree of multiplexing and the aggressiveness of contending endpoints, are important to capture in a model.",Congestion control; Learnability; Machine learning; Measurement; Protocol; Simulation,Artificial intelligence; Congestion control (communication); Design; Learning systems; Measurements; Network protocols; Distributed network protocols; Future networks; Learnability; Operating ranges; Prior knowledge; Protocol design; Protocol designers; Simulation; Complex networks
"Craven R., Beverly R., Allman M.",3,A middlebox-cooperative TCP for a non end-to-end internet,2015,3,"Naval Postgraduate School, United States; ICSI, United States",Naval Postgraduate School,1,USA,1,46,31,"Understanding, measuring, and debugging IP networks, particularly across administrative domains, is challenging. One particularly daunting aspect of the challenge is the presence of transparent middleboxes which are now common in today's Internet. In-path middleboxes that modify packet headers are typically transparent to a TCP, yet can impact end-to-end performance or cause blackholes. We develop TCP HICCUPS to reveal packet header manipulation to both endpoints of a TCP connection. HICCUPS permits endpoints to cooperate with currently opaque middleboxes without prior knowledge of their behavior. For example, with visibility into end-to-end behavior, a TCP can selectively enable or disable performance enhancing options. This cooperation enables protocol innovation by allowing new IP or TCP functionality (e.g., ECN, SACK, Multipath TCP, Tcpcrypt) to be deployed without fear of such functionality being misconstrued, modified, or blocked along a path. HICCUPS is incrementally deployable and introduces no new options. We implement and deploy TCP HICCUPS across thousands of disparate Internet paths, highlighting the breadth and scope of subtle and hard to detect middlebox behaviors encountered. We then show how path diagnostic capabilities provided by HICCUPS can benefit applications and the network. Copyright 2014 ACM.",Header integrity; Header modifications; Middlebox; TCP,Internet; Internet protocols; Diagnostic capabilities; End-to-end performance; Header integrity; Header modifications; Middleboxes; Performance enhancing; Prior knowledge; TCP; Transmission control protocol
"Nam H., Kim K.-H., Schulzrinne H., Calin D.",4,YouSlow: A performance analysis tool for adaptive bitrate video streaming,2015,3,"Columbia University, New York, NY, United States; Alcatel-Lucent, Bell Laboratories, Murray Hill, NJ, United States",Bell Laboratories;Columbia University,2,USA,1,7,3,"Adaptive bitrate (ABR) technologies are being widely used in today's popular HTTP-based video streaming such as YouTube and Netix. Such a rate-switching algorithm em- bedded in a video player is designed to improve video quality- of-experience (QoE) by selecting an appropriate resolution based on the analysis of network conditions while the video is playing. However, a bad viewing experience is often caused by the video player having difficulty estimating transit or client-side network conditions accurately. In order to ana- lyze the ABR streaming performance, we developed YouS- low, a web browser plug-in that can detect and report live buffer stalling events to our analysis tool. Currently, YouS- low has collected more than 20,000 of YouTube video stalling events over 40 countries.",Adaptive bitrate streaming (ABR); HTTP video streaming; Video quality of experience,HTTP; Quality of service; Video streaming; Bit rates; Http video streaming; HTTP-based video streaming; Network condition; Performance analysis; Rate switching; Video quality; Web browser plug-in; Quality control
"Gao Z., Venkataramani A., Kurose J., Heimlicher S.",4,Towards a quantitative comparison of location-independent network architectures,2015,7,"School of Computer Science, University of Massachusetts, Amherst, United States",University of Massachusetts Amherst,1,USA,1,58,33,"This paper presents a quantitative methodology and results comparing different approaches for location-independent communication. Our approach is empirical and is based on real Internet topologies, routing tables from real routers, and a measured workload of the mobility of devices and content across network addresses today. We measure the extent of network mobility exhibited by mobile devices with a homebrewed Android app deployed on hundreds of smartphones, and measure the network mobility of Internet content from distributed vantage points. We combine this measured data with our quantitative methodology to analyze the different cost-benefit tradeoffs struck by location-independent network architectures with respect to routing update cost, path stretch, and forwarding table size. We find that more than 20% of users change over 10 IP addresses a day, suggesting that mobility is the norm rather than the exception, so intrinsic and efficient network support for mobility is critical. We also find that with purely name-based routing approaches, each event involving the mobility of a device or popular content may result in an update at up to 14% of Internet routers; but, the fraction of impacted routers is much smaller for the long tail of unpopular content. These results suggest that recent proposals for pure name-based networking may be suitable for highly aggregateable content that moves infrequently but may need to be augmented with addressing-assisted approaches to handle device mobility.",Location-independence; Mobility; Network architecture,Carrier mobility; Cost effectiveness; Internet; Mobile devices; Network routing; Routers; Telecommunication networks; Cost-benefit tradeoffs; Device mobilities; Forwarding tables; Internet topologies; Location independence; Location independent; Quantitative comparison; Quantitative methodology; Network architecture
"Bharadia D., Katti S.",2,Fast forward: Fast and constructive full duplex relays,2015,8,"Stanford University, United States",Stanford University,1,USA,1,31,17,"This paper presents, FastForward (FF), a novel full-duplex relay that constructively forwards signals such that wireless network throughput and coverage is significantly enhanced. FF is a Layer 1 in-band full-duplex device, it receives and transmits signals directly and simultaneously on the same frequency. It cleanly integrates into existing networks (bothWiFi and LTE) as a separate device and does not require changes to the clients. FF's key invention is a constructive filtering algorithm that transforms the signal at the relay such that when it reaches the destination, it constructively combines with the direct signals from the source and provides a significant throughput gain. We prototype FF using off-the-shelf software radios running a stock WiFi PHY and show experimentally that it provides a 3× median throughput increase and nearly a 4× gain at the edge of the coverage area.",Cancellation; Full duplex; Full duplex relay; Lowlatency cancelation,Throughput; Cancellation; Coverage area; Filtering algorithm; Full-duplex; Full-duplex relays; Low-latency; Network throughput; Separate devices; Wireless telecommunication systems
"Alizadeh M., Edsall T., Dharmapurikar S., Vaidyanathan R., Chu K., Fingerhut A., Lam V.T., Matus F., Pan R., Yadav N., Varghese G.",11,CONGA: Distributed congestion-aware load balancing for datacenters,2015,42,"Microsoft, United States; Google, United States; Cisco Systems, United States",Google;Microsoft,2,USA,1,52,39,"We present the design, implementation, and evaluation of CONGA, a network-based distributed congestion-aware load balancing mechanism for datacenters. CONGA exploits recent trends including the use of regular Clos topologies and overlays for network virtualization. It splits TCP flows into flowlets, estimates real-time congestion on fabric paths, and allocates flowlets to paths based on feedback from remote switches. This enables CONGA to efficiently balance load and seamlessly handle asymmetry, without requiring any TCP modifications. CONGA has been implemented in custom ASICs as part of a new datacenter fabric. In testbed experiments, CONGA has 5× better flow completion times than ECMP even with a single link failure and achieves 2-8× better throughput than MPTCP in Incast scenarios. Further, the Price of Anarchy for CONGA is provably small in Leaf-Spine topologies; hence CONGA is nearly as effective as a centralized scheduler while being able to react to congestion in microseconds. Our main thesis is that datacenter fabric load balancing is best done in the network, and requires global schemes such as CONGA to handle asymmetry. Copyright 2014 ACM.",Datacenter fabric; Distributed; Load balancing,Parallel architectures; Resource allocation; Time switches; Topology; Centralized schedulers; Congestion-aware; Datacenter; Distributed; Load-balancing mechanisms; Network virtualization; Price of anarchy; Single-link failures; Network management
"Alwabel A., Yu M., Zhang Y., Mirkovic J.",4,SENSS: Observe and control your own traffic in the internet,2015,0,"USC, United States; Ericsson Research, United States; USC, ISI, United States",Ericsson Research;University of Southern California,2,USA,1,5,3,"We propose a new software-defined security service - SENSS - That enables a victim network to request services from remote ISPs for traffic that carries source IPs or destination IPs from this network's address space. These services range from statistics gathering, to filtering or quality of service guarantees, to route reports or modifications. The SENSS service has very simple, yet powerful, interfaces. This enables it to handle a variety of data plane and control plane attacks, while being easily implementable in today's ISP. Through extensive evaluations on realistic traffic traces and Internet topology, we show how SENSS can be used to quickly, safely and effectively mitigate a variety of large-scale attacks that are largely unhandled today.",Design; Management; Privacy; SDN; Security,Data privacy; Design; Internet; Management; Mobile security; Quality of service; Internet topologies; Large-scale attacks; Quality of service guarantees; Realistic traffics; SDN; Security; Security services; Statistics gathering; Internet service providers
"Yuan Z., Lu Y., Wang Z., Xue Y.",4,Droid-Sec: Deep learning in android malware detection,2015,34,"Baidu Inc., Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Research Institute of Information Technology, Tsinghua University, Beijing, China; Tsinghua National Lab for Information Science and Technology, Beijing, China; Harbin Institute of Technology, School of Computer Science and Technology, Harbin, China",Baidu Inc.;Harbin Institute of Technology;Tsinghua University,3,China,1,3,3,"As smartphones and mobile devices are rapidly becoming indispensable for many network users, mobile malware has become a serious threat in the network security and privacy. Especially on the popular Android platform, many malicious apps are hiding in a large number of normal apps, which makes the malware detection more challenging. In this paper, we propose a ML-based method that utilizes more than 200 features extracted from both static analysis and dynamic analysis of Android app for malware detection. The comparison of modeling results demonstrates that the deep learning technique is especially suitable for Android malware detection and can achieve a high level of 96% accuracy with real-world Android application sets.",Android malware; Deep learning; Detection,Computer crime; Error detection; Malware; Mobile devices; Network security; Static analysis; Android applications; Android malware; Android platforms; Comparison of models; Deep learning; Malware detection; Mobile malware; Network security and privacy; Android (operating system)
"Kalia A., Kaminsky M., Andersen D.G.",3,Using RDMA efficiently for key-value services,2015,22,"Carnegie Mellon University, United States; Intel Labs, United States",Carnegie Mellon University;Intel,2,USA,1,31,20,"This paper describes the design and implementation of HERD, a keyvalue system designed to make the best use of an RDMA network. Unlike prior RDMA-based key-value systems, HERD focuses its design on reducing network round trips while using efficient RDMA primitives; the result is substantially lower latency, and throughput that saturates modern, commodity RDMA hardware. HERD has two unconventional decisions: First, it does not use RDMA reads, despite the allure of operations that bypass the remote CPU entirely. Second, it uses a mix of RDMA and messaging verbs, despite the conventional wisdom that the messaging primitives are slow. A HERD client writes its request into the server's memory; the server computes the reply. This design uses a single round trip for all requests and supports up to 26 million key-value operations per second with 5 μs average latency. Notably, for small key-value items, our full system throughput is similar to native RDMA read throughput and is over 2X higher than recent RDMA-based keyvalue systems. We believe that HERD further serves as an effective template for the construction of RDMA-based datacenter services.",Infiniband; Key-value stores; Rdma; RoCE,Throughput; Datacenter; Design and implementations; Infiniband; Key-value stores; Rdma; RoCE; Round trip; System throughput; Design
"Parks A.N., Liu A., Gollakota S., Smith J.R.",4,Turbocharging ambient backscatter communication,2015,39,"University of Washington, United States",University of Washington at St. Louis,1,USA,1,41,28,"Communication primitives such as coding and multiple antenna processing have provided significant benefits for traditional wireless systems. Existing designs, however, consume significant power and computational resources, and hence cannot be run on low complexity, power constrained backscatter devices. This paper makes two main contributions: (1) we introduce the first multi-antenna cancellation design that operates on backscatter devices while retaining a small form factor and power footprint, (2) we introduce a novel coding mechanism that enables long range communication as well as concurrent transmissions and can be decoded on backscatter devices. We build hardware prototypes of the above designs that can be powered solely using harvested energy from TV and solar sources. The results show that our designs provide benefits for both RFID and ambient backscatter systems: they enable RFID tags to communicate directly with each other at distances of tens of meters and through multiple walls. They also increase the communication rate and range achieved by ambient backscatter systems by 100X and 40X respectively. We believe that this paper represents a substantial leap in the capabilities of backscatter communication. Copyright 2014 ACM.",Backscatter; Energy harvesting; Internet of things; Wireless,Antennas; Design; Energy harvesting; Internet of things; Radio; Television antennas; Communication primitives; Communication rate; Computational resources; Concurrent transmission; Hardware prototype; Long-range communications; Multiple-antenna processing; Small form factors; Backscattering
"Shirali-Shahreza S., Ganjali Y.",2,Traffic statistics collection with FleXam,2015,5,"Department of Computer Science, University of Toronto, Canada",University of Toronto,1,Canada,1,7,7,"One of the limitations of wildcard rules in Software Defined Networks, such as OpenFlow, is losing visibility. FleXam is a flexible sampling extension for OpenFlow that allows the controller to define which packets should be sampled, what parts of each packet should be selected, and where they should be sent. Here, we present an interactive demo showing how FleXam enables the controller to dynamically adjust sampling rates and change the sampling scheme to optimally keep up with a sampling budget in the context of a traffic statistics collection application.",Openflow; Sampling; SDN; Traffic statistics,Budget control; Traffic surveys; Openflow; Sampling rates; Sampling schemes; SDN; Software-defined networks; Traffic statistics; Sampling
"Claffy K.C., Clark D.D., Wittie M.",3,The 6th Workshop on Active Internet Measurements (AIMS-6) report,2014,2,"CAIDA/UCSD, United States; CSAIL/MIT, United States; Montana State U., United States",MIT;Montana State University,2,USA,1,9,9,"On 26-27 March 2014, CAIDA hosted the sixth Workshop on Active Internet Measurements (AIMS-6) as part of our series of Internet Statistics and Metrics Analysis (ISMA) workshops. As with previous AIMS workshops, the goals were to further our understanding of the potential and limitations of active measurement research and infrastructure in the wide-area Internet, and to promote cooperative solutions and coordinated strategies between academics, industry, policymakers, and funding agencies in the area of active Internet measurement. This year, we explored capabilities and opportunities for network measurement in the wireless domain, and research infrastructure to support it. Participants found the workshop content challengingly diverse, with substantial knowledge exchange regarding the wireless research infrastructure landscape(s) and existing measurement capabilities. But attendees agreed that the conversation was only beginning, and that some challenges merit further discussion, such as finding consensus on standard metrics to measure, and constructing a road map for wireless measurement research infrastructure and activities for the next decade. This report describes topics discussed at the workshop, and summarizes participants' views of priorities for future funding as well as follow-on workshops in this area. Materials related to the workshop are available at http://www.caida.org/workshops/aims/1403/. © 2014, Association for Computing Machinery. All rights reserved.",Active Internet measurement; Cellular; Validation; Wireless,Distributed computer systems; Knowledge management; Radio; Cellular; Coordinated strategies; Internet measurement; Network measurement; Research infrastructure; Validation; Wide-area Internet; Wireless measurements; Internet
"Nikaein N., Marina M.K., Manickam S., Dawson A., Knopp R., Bonnet C.",6,OpenAirInterface: A flexible platform for 5G research,2014,81,"EURECOM, Sophia Antipolis, France; University of Edinburgh, Edinburgh, United Kingdom",EURECOM;University of Edinburgh,2,France;UK,2,18,15,"Driven by the need to cope with exponentially growing mobile data traffic and to support new traffic types from massive numbers of machine-type devices, academia and industry are thinking beyond the current generation of mobile cellular networks to chalk a path towards fifth generation (5G) mobile networks. Several new approaches and technologies are being considered as potential elements making up such a future mobile network, including cloud RANs, application of SDN principles, exploiting new and unused portions of spectrum, use of massive MIMO and full-duplex communications. Research on these technologies requires realistic and flexible experimentation platforms that offer a wide range of experimentation modes from real-world experimentation to controlled and scalable evaluations while at the same time retaining backward compatibility with current generation systems. Towards this end, we present OpenAirInterface (OAI) as a suitably flexible platform. In addition, we discuss the use of OAI in the context of several widely mentioned 5G research directions. © 2014, Association for Computing Machinery. All rights reserved.",4G/5G mobile networks; Emulation; Experimentation; LTE; OpenAirInterface; Software-defined radio (SDR) platform,Mobile telecommunication systems; Real time systems; Software radio; Wireless networks; Backward compatibility; Emulation; Experimentation; Experimentation platforms; Full duplex communication; Mobile cellular networks; OpenAirInterface; Software-defined radios; Wireless telecommunication systems
"Coull S.E., Dyer K.P.",2,Traffic analysis of encrypted messaging services: Apple iMessage and beyond,2014,14,"RedJack, LLC., Silver Spring, MD, United States; Portland State University, Portland, OR, United States",Portland State University,1,USA,1,20,19,"Instant messaging services are quickly becoming the most dominant form of communication among consumers around the world. Apple iMessage, for example, handles over 2 billion messages each day, while WhatsApp claims 16 billion messages from 400 million international users. To protect user privacy, many of these services typically implement end-to-end and transport layer encryption, which are meant to make eavesdropping infeasible even for the service providers themselves. In this paper, however, we show that it is possible for an eavesdropper to learn information about user actions, the language of messages, and even the length of those messages with greater than 96% accuracy despite the use of state-of-the-art encryption technologies simply by observing the sizes of encrypted packets. While our evaluation focuses on Apple iMessage, the attacks are completely generic and we show how they can be applied to many popular messaging services, including WhatsApp, Viber, and Telegram. © 2014, Association for Computing Machinery. All rights reserved.",Encryption; Privacy; Traffic analysis,Data privacy; Fruits; Encryption technologies; Instant messaging service; Messaging services; Service provider; State of the art; Traffic analysis; Transport layers; User privacy; Cryptography
"Hofstede R., Hendriks L., Sperotto A., Pras A.",4,SSH compromise detection using NetFlow/IPFIX,2014,19,"Centre for Telematics and Information Technology (CTIT), University of Twente, Enschede, Netherlands",University of Twente,1,Netherlands,1,9,9,"Flow-based approaches for SSH intrusion detection have been developed to overcome the scalability issues of host-based alternatives. Although the detection of many SSH attacks in a flow-based fashion is fairly straightforward, no insight is typically provided in whether an attack was successful. We address this shortcoming by presenting a detection algorithm for the flow-based detection of compromises, i.e., hosts that have been compromised during an attack. Our algorithm has been implemented as part of our open-source IDS SSHCure and validated using almost 100 servers, workstations and honeypots, featuring an accuracy close to 100%. © 2014, Association for Computing Machinery. All rights reserved.",Intrusion detection; IPFIX; NetFlow; Network measurement; SSH,Internet protocols; Mercury (metal); Detection algorithm; Flow based; Host-based; IPFIX; NetFlows; Network measurement; Open sources; Scalability issue; Intrusion detection
"Vaquero L.M., Rodero-Merino L.",2,Finding your way in the fog: Towards a comprehensive definition of fog computing,2014,303,"Hewlett-Packard Labs., Bristol, United Kingdom; Gradiant, Vigo, Spain",HP Labs,1,Spain;UK,2,19,18,"The cloud is migrating to the edge of the network, where routers themselves may become the virtualisation infrastructure, in an evolution labelled as ""the fog"". However, many other complementary technologies are reaching a high level of maturity. Their interplay may dramatically shift the information and communication technology landscape in the following years, bringing separate technologies into a common ground. This paper offers a comprehensive definition of the fog, comprehending technologies as diverse as cloud, sensor networks, peer-to-peer networks, network virtualisation functions or configuration management techniques. We highlight the main challenges faced by this potentially breakthrough technology amalgamation. © 2014, Association for Computing Machinery. All rights reserved.",Cloud computing; Configuration management; Fog computing; Internet of Things (IoT); Network Function Virtualisation (NFV); Peer-to-peer (P2P); Sensor networks,Cloud computing; Fog; Internet of things; Metals; Peer to peer networks; Sensor networks; Virtual reality; Breakthrough technology; Common ground; Configuration management; Information and Communication Technologies; Internet of Things (IOT); Network virtualisation; Peer to peer; Virtualisation; Distributed computer systems
"Yu M., Raju M., Wundsam A.",3,NOSIX: A lightweight portability layer for the SDN OS,2014,18,"USC, United States; Big Switch Networks, United States",University of Southern California,1,USA,1,29,18,"In spite of the standardization of the OpenFlow API, it is very difficult to write an SDN controller application that is portable (i.e., guarantees correct packet processing over a wide range of switches) and achieves good performance (i.e., fully leverages switch capabilities). This is because the switch landscape is fundamentally diverse in performance, feature set and supported APIs. We propose to address this challenge via a lightweight portability layer that acts as a rendezvous point between the requirements of controller application and the vendor knowledge of switch implementations. Above, applications specify rules in virtual flow tables annotated with semantic intents and expectations. Below, endor specific drivers map them to optimized switch-specific rule sets. NOSIX represents a first step towards achieving both portability and good performance across a diverse set of switches.",Openflow; Portability; Software-defined networks; Switch diversity,Application programming interfaces (API); Computer software portability; Semantics; Feature sets; Flow tables; Lightweight portability; Openflow; Packet processing; Rendezvous point; Rule set; Software-defined networks; Switching circuits
"Wang Y., Matta I., Esposito F., Day J.",4,Introducing protorinA: A prototype for programming recursive-Networking policies,2014,8,"Boston University, United States; Exegy, Inc, Boston University, United States",Boston University,1,USA,1,19,12,"ProtoRINA is a user-space prototype of the Recursive InterNetwork Architecture. RINA is a new architecture that builds on the fundamental principle that networking is inter- process communication. As a consequence, RINA overcomes inherent weaknesses of the current Internet, e:g:, security, mobility support, and manageability. ProtoRINA serves not only as a prototype that demonstrates the advantages of RINA, but also as a network experimental tool that enables users to program different policies using its built-in mechanisms. In this note, we introduce ProtoRINA as a vehicle for making RINA concepts concrete and for encouraging researchers to use and benefit from the prototype.",Experimental Evaluation; Future Network; Policy-based Programming; Recursive Networking; RINA,Network architecture; Experimental evaluation; Future networks; Policy-based; Recursive Networking; RINA; Software prototyping
"Huffaker B., Fomenkov M., Claffy K.C.",3,DRoP: DNS-based router positioning,2014,10,"CAIDA, University of California, San Diego, CA, United States",University of California San Diego,1,USA,1,31,22,"In this paper we focus on geolocating Internet routers, using a methodology for extracting and decoding geography-related strings from fully qualified domain names (hostnames). We first compiled an extensive dictionary associating geographic strings (e.g., airport codes) with geophysical locations. We then searched a large set of router hostnames for these strings, assuming each autonomous naming domain uses geographic hints consistently within that domain. We used topology and performance data continually collected by our global measurement infrastructure to discern whether a given hint appears to co-locate different hostnames in which it is found. Finally, we generalized geolocation hints into domainspecific rule sets. We generated a total of 1,711 rules covering 1,398 different domains and validated them using domain-specific ground truth we gathered for six domains. Unlike previous efforts which relied on labor-intensive domain-specific manual analysis, we automate our process for inferring the domain specific heuristics, substantially advancing the state-of-the-art of methods for geolocating Internet resources.",Active measurement; DNS; Internet topology; Router geolocation,Internet; Topology; Tracking (position); Active measurement; Different domains; DNS; Geolocations; Global measurements; Internet resources; Internet topologies; Performance data; Internet protocols
"Singh R.P., Brecht T., Keshav S.",3,IP address multiplexing for VEEs,2014,0,"University of Waterloo, Canada",University of Waterloo,1,Canada,1,37,26,"The number of publicly accessible virtual ex- ecution environments (VEEs) has been growing steadily in the past few years. To be accessible by clients, such VEEs need either a public IPv4 or a public IPv6 address. However, the pool of available public IPv4 addresses is nearly depleted and the low rate of adoption of IPv6 precludes its use. There- fore, what is needed is a way to share precious IPv4 public addresses among a large pool of VEEs. Our insight is that if an IP address is assigned at the time of a client DNS re- quest for the VEE's name, it is possible to share a single public IP address amongst a set of VEEs whose workloads are not network intensive, such as those hosting personal servers or performing data analytics. We investigate several approaches to multiplexing a pool of global IP addresses among a large number of VEEs, and design a system that overcomes the limitations of current approaches.We perform a qualitative and quantitative comparison of these solutions. We find that upon receiving a DNS request from a client, our solution has a latency as low as 1 ms to allocate a public IP address to a VEE, while keeping the size of the required IP address pool close to the minimum possible.",Cloud computing; DHCP; DNS; IP ad- dresses; IPv6; Multiplexing; Personal servers; Virtual machines,Cloud computing; Lakes; Multiplexing; Servers; DHCP; DNS; IP ad- dresses; IPv6; Virtual machines; Internet protocols
"Naylor D., Mukerjee M.K., Agyapong P., Grandl R., Kang R., Machado M.",6,XIA: Architecting a more trustworthy and evolvable internet,2014,24,"Carnegie Mellon University, United States; University of Wisconsin, United States; Boston University, United States",Boston University;Carnegie Mellon University;University of Wisconsin-Madison,3,USA,1,31,26,"Motivated by limitations in today's host-centric IP network, recent studies have proposed clean-slate network architec-tures centered around alternate first-class principals, such as content, services, or users. However, much like the host-centric IP design, elevating one principal type above oth-ers hinders communication between other principals and in-hibits the network's capability to evolve. This paper presents the eXpressive Internet Architecture (XIA), an architecture with native support for multiple principals and the ability to evolve its functionality to accommodate new, as yet un- foreseen, principals over time. We present the results of our ongoing research motivated by and building on the XIA ar- chitecture, ranging from topics at the physical level (""how fast can XIA go"") up through to the user level.",Internet architecture; Network addressing,Internet; Clean slates; Evolvable; Internet architecture; IP design; IP networks; Network addressing; Physical level; User levels; Network architecture
"Venkataramani A., Kurose J.F., Raychaudhuri D., Nagaraja K., Banerjee S., Mao Z.M.",6,MobilityFirst: A mobility-centric and trustworthy internet architecture,2014,44,"University of Massachusetts, Amherst, United States; Rutgers University, United States; University of Wisconsin, Madison, AL, United States; University of Michigan, United States",Rutgers University;University of Massachusetts Amherst;University of Michigan at Ann Arbor;University of Wisconsin-Madison,4,USA,1,31,19,"MobilityFirst is a future Internet architecture with mobility and trustworthiness as central design goals. Mobility means that all endpoints-devices, services, content, and networks-should be able to frequently change network attachment points in a seamless manner. Trustworthiness means that the network must be resilient to the presence of a small num-ber of malicious endpoints or network routers. MobilityFirst enhances mobility by cleanly separating names or identifiers from addresses or network locations, and enhances secu-rity by representing both in an intrinsically verifiable man-ner, relying upon a massively scalable, distributed, global name service to bind names and addresses, and to facilitate services including device-to-service, multicast, anycast, and context-aware communication, content retrieval, and more. A key insight emerging from our experience is that a log-ically centralized global name service can significantly en-hance mobility and security and transform network-layer functionality. Recognizing and validating this insight is the key contribution of the MobilityFirst architectural effort.",Global name service; Mobility; Network architecture; Security,Carrier mobility; Internet; Network layers; Network security; Attachment points; Content retrieval; Context-aware communications; Design goal; Future internet architecture; Global name services; Security; Trustworthy Internet; Network architecture
Ford M.,1,"Workshop report: Reducing internet latency, 2013",2014,5,"ISOC, United States","ISOC,UK",1,USA,1,14,4,"This paper reports on a workshop convened to develop an action plan to reduce Internet latency. Internet latency has become a focus of attention at the leading edge of the industry as the desire to make Internet applications more responsive outgrows the ability of increased bandwidth to address this problem. There are fundamental limits to the extent to which latency can be reduced, but there is considerable capacity for improvement throughout the system, making Internet latency a multifaceted challenge. Perhaps the greatest challenge of all is to re-educate the mainstream of the industry to understand that bandwidth is not the panacea, and other optimizations, such as reducing packet loss, are at odds with latency reduction. For Internet applications, reducing the latency impact of sharing the communications medium with other users and applications is key. Current Internet network devices were often designed with a belief that additional buffering would reduce packet loss. In practice, this additional buffering leads to intermittently excessive latency and even greater packet loss under saturating load. For this reason, getting smarter queue management techniques more widely deployed is a high priority. We can reduce these intermittent increases in delay, sometimes by up to two orders of magnitude, by shifting the focus from packet loss avoidance to delay avoidance using technology that we already have developed, tested, implemented and deployed today. There is also plenty of scope for removing other major sources of delay. For instance, connecting to a website could be completed in one roundtrip (the time it takes for packets to travel from source to destination and back again) rather than three or four, by folding two or three rounds of low and security set-up into the first data exchange, without compromising security or efficiency. Motivating the industry to deploy these advances needs to be aided by the availability of mass-market latency testing tools that could give consumers the information they need to gravitate to- wards low latency services, providers and products. There is no single network latency metric but several alternatives have been identified that compactly express aggregate delay (e.g. as relationships or a constellation), and tools that make use of these will give greater insight into the impact of changes and the diversity of Internet connections around the world. In many developing countries (and in rural regions of developed countries), aside from Internet access itself, there are significant structural issues, such as trombone routes through the developed world and a lack of content distribution networks (CDNs), that need to be addressed with more urgency than Active Queue Management (AQM) deployment, but the 'blank slate' of new deployments provides an opportunity to consider latency now. More widespread use of Internet exchange points for hosting local con- tent and fostering local interconnections is key to addressing some of these structural challenges.",Algorithms; Characterisation; Co-ordination; Congestion; Delay; Metrics; Overhead; Performance; QoS; Standardization,Algorithms; Bandwidth; Developing countries; Electronic data interchange; Gravitation; Industry; Packet loss; Quality of service; Queueing networks; Standardization; Tools; Characterisation; Co-ordination; Congestion; Delay; Metrics; Overhead; Performance; Internet
"Krenc T., Hohlfeld O., Feldmann A.",3,An internet census taken by an illegal botnet - A qualitative assessment of published Measurements,2014,7,"TU Berlin, Germany; RWTH Aachen University, Germany",RWTH Aachen University;TU Berlin,2,Germany,1,28,29,"On March 17, 2013, an Internet census data set and an ac- companying report were released by an anonymous author or group of authors. It created an immediate media buzz, mainly because of the unorthodox and unethical data collec-tion methodology (i.e., exploiting default passwords to form the Carna botnet), but also because of the alleged unprece-dented large scale of this census (even though legitimate census studies of similar and even larger sizes have been performed in the past). Given the unknown source of this released data set, little is known about it. For example, can it be ruled out that the data is faked? Or if it is indeed real, what is the quality of the released data? The purpose of this paper is to shed light on these and re-lated questions and put the contributions of this anonymous Internet census study into perspective. Indeed, our findings suggest that the released data set is real and not faked, but that the measurements suffer from a number of methodolog- ical flaws and also lack adequate meta-data information. As a result, we have not been able to verify several claims that the anonymous author(s) made in the published report. In the process, we use this study as an educational ex- ample for illustrating how to deal with a large data set of unknown quality, hint at pitfalls in Internet-scale measure- ment studies, and discuss ethical considerations concerning third-party use of this released data set for publications.",Carna botnet; Census; IPv4,Internet; Population statistics; Carna botnet; Census; Census data; Data set; Ethical considerations; IPv4; Large datasets; Qualitative assessments; Surveys
"Vissicchio S., Vanbever L., Bonaventure O.",3,Opportunities and research challenges of hybrid software defined networks,2014,108,"Universite Catholique de Louvain, Belgium; Princeton University, United States",Princeton University;Universite Catholique de Louvain,2,Belgium;USA,2,25,24,"Software Defined Networking (SDN) promises to ease de- sign, operation and management of communication networks. However, SDN comes with its own set of challenges, including incremental deployability, robustness, and scalability. Those challenges make a full SDN deployment difficult in the short-term and possibly inconvenient in the longer-term. In this paper, we explore hybrid SDN models that combine SDN with a more traditional networking approach based on distributed protocols. We show a number of use cases in which hybrid models can mitigate the respective limitations of traditional and SDN approaches, providing incentives to (partially) transition to SDN. Further, we expose the qualitatively diverse tradeos that are naturally achieved in hybrid models, making them convenient for different transition strategies and long-term network designs. For those reasons, we argue that hybrid SDN architectures deserve more attention from the scientific community.",Hybrid SDN; Network design; Partial deployment; Transition,Distributed protocols; Hybrid SDN; Network design; Operation and management; Partial deployment; Software defined networking (SDN); Software-defined networks; Transition; Communication
Luckie M.,1,Spurious routes in public BGP data,2014,4,"CAIDA, University of California, San Diego, CA, United States",University of California San Diego,1,USA,1,24,18,"Researchers depend on public BGP data to understand the structure and evolution of the AS topology, as well as the operational security and resiliency of BGP. BGP data is provided voluntarily by network operators who establish BGP sessions with route collectors that record this data. In this paper, we show how trivial it is for a single vantage point (VP) to introduce thousands of spurious routes into the collection by providing examples of five VPs that did so. We explore the impact these misbehaving VPs had on AS relationship inference, showing these misbehaving VPs introduced thousands of AS links that did not exist, and caused relationship inferences for links that did exist to be corrupted. We evaluate methods to automatically identify misbehaving VPs, although we find the result unsatisfying because the limitations of real-world BGP practices and AS relationship inference algorithms produce signatures similar to those created by misbehaving VPs. The most recent misbehaving VP we discovered added thousands of spurious routes for nine consecutive months until 8 November 2012. This misbehaving VP barely impacts (0.1%) our validation of our AS relationship inferences, but this number may be misleading since most of our validation data relies on BGP and RPSL which validates only existing links, rather than asserting the non-existence of links. We have only a few assertions of non-existent routes, all received via our public-facing website that allows operators to provide validation data through our interactive feedback mechanism. We only discovered this misbehavior because two independent operators corrected some inferences, and we noticed that the spurious routes all came from the same VP. This event highlights the limitations of even the best available topology data, and provides additional evidence that comprehensive ground truth validation from operators is essential to scientific research on Internet topology.",AS relationships; Routing policies,Inference engines; Network security; AS relationships; Inference algorithm; Interactive feedback; Internet topologies; Network operator; Operational security; Routing policies; Scientific researches; Topology
"Honda M., Huici F., Raiciu C., Araujo J., Rizzo L.",5,Rekindling network protocol innovation with user-level stacks,2014,28,"NEC Europe Ltd., United Kingdom; Universitatea Politehnica Bucuresti, Romania; University College London, United Kingdom; Universitá di Pisa, Italy; International Computer Science Institute, Berkeley, CA, United States",University of California Berkeley;Universitatea Politehnica Bucuresti;University College London;Universitá di Pisa,4,Italy;Romania;UK;USA,4,28,19,"Recent studies show that more than 86% of Internet paths allow well-designed TCP extensions, meaning that it is still possible to deploy transport layer improvements despite the existence of middleboxes in the network. Hence, the blame for the slow evolution of protocols (with extensions taking many years to become widely used) should be placed on end systems. In this paper, we revisit the case for moving protocols stacks up into user space in order to ease the deployment of new protocols, extensions, or performance optimizations. We present MultiStack, operating system support for userlevel protocol stacks. MultiStack runs within commodity operating systems, can concurrently host a large number of isolated stacks, has a fall-back path to the legacy host stack, and is able to process packets at rates of 10Gb/s. We validate our design by showing that our mux/demux layer can validate and switch packets at line rate (up to 14.88 Mpps) on a 10 Gbit port using 1-2 cores, and that a proof-of-concept HTTP server running over a basic userspace TCP outperforms by 18-90% both the same server and nginx running over the kernel's stack.",Deployability; Operating systems; Ttransport protocols,Computer operating systems; HTTP; Commodity operating systems; Deployability; Internet paths; Operating system support; Performance optimizations; Process packets; Proof of concept; Transport layers; Transmission control protocol
"Bianchi G., Bonola M., Capone A., Cascone C.",4,Openstate: Programming platform-independent stateful openflow applications inside the switch,2014,132,"CNIT / Univ., Roma Tor Vergata, Italy; Politecnico di Milano, Italy",CNIT University;Politecnico di Milano,2,Italy,1,19,16,"Software Defined Networking envisions smart centralized con- trollers governing the forwarding behavior of dumb low- cost switches. But are ""dumb"" switches an actual strategic choice, or (at least to some extent) are they a consequence of the lack of viable alternatives to OpenFlow as program- matic data plane forwarding interface? Indeed, some level of (programmable) control logic in the switches might be ben- eficial to offload logically centralized controllers (de facto complex distributed systems) from decisions just based on local states (versus network-wide knowledge), which could be handled at wire speed inside the device itself. Also, it would reduce the amount of ow processing tasks currently delegated to specialized middleboxes. The underlying challenge is: can we devise a stateful data plane programming abstraction (versus the stateless OpenFlow match/action table) which still entails high performance and remains consis- tent with the vendors' preference for closed platforms? We posit that a promising answer revolves around the usage of extended finite state machines, as an extension (super-set) of the OpenFlow match/action abstraction. We concretely turn our proposed abstraction into an actual table-based API, and, perhaps surprisingly, we show how it can be sup- ported by (mostly) reusing core primitives already implemented in OpenFlow devices.",Openflow; Programming interfaces; SDN; State machines,Complex networks; Computer programming; Complex distributed system; Extended finite state machine; Openflow; Programming abstractions; Programming interface; SDN; Software-defined networkings; State machine; Abstracting
"Yao X.-W., Wang W.-L., Yang S.-H., Cen Y.-F., Yao X.-M., Pan T.-Q.",6,Public review for IPB-frame adaptive mapping mechanism for video transmission over IEEE 802.11e WLANs,2014,15,"College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; Department of Computer Science, Loughborough University, Leicestershire, United Kingdom; College of Electrical and Information Engineering, Quzhou University, Quzhou, China",Loughborough University;Quzhou University;Zhejiang University of Technology,3,China;UK,2,20,17,"This paper proposed an IPB-frame Adaptive Mapping Mechanism (AMM) to improve the video transmission quality over IEEE 802.11e Wireless Local Area Networks (WLANs). Based on the frame structure of hierarchical coding technology, the probability of each frame allocated to the most appropriate Access Category (AC) was dynamically updated according to its importance and traffic load of each AC. Simulation results showed the superior performance of the proposed AMM by comparing with three other existing mechanisms in terms of three objective metrics.",Hierarchical video coding; Mapping mechanism; Video transmission; WLANs 802.11e,Image communication systems; Wireless local area networks (WLAN); Access category; Frame structure; Hierarchical coding; Hierarchical video coding; Mapping mechanism; Objective metrics; Video transmissions; WLANs 802.11e; Image coding
"Davids C., Ormazabal G., State R.",3,Real-Time communications: Topics for research and methods of collaboration,2014,0,"Illinois Institute of Technology, School of Applied Technology, 201 East Loop Road, Wheaton, IL, United States; Columbia University, Dept. of Computer Science, 520 West 120th Street, New York, N.Y. 10027, United States; University of Luxembourg, Interdisciplinary Centre for Security, Reliability and Trust, 4, Rue Alphonse Weicker, L-2721 Luxembourg, Luxembourg",Columbia University;Illinois Institute of Technology;Interdisciplinary Centre for Security;University of Luxembourg,4,Luxembourg;USA,2,12,4,"In this article we describe the discussion and conclusions of the ""Roundtable on Real-Time Communications Research: What to Study and How to Collaborate"" held at the Illinois Institute of Technology's Real-Time Communications Conference and Expo, co-located with the IPTComm Conference, October 15-17, 2013.",Cloud communications; Collaboration; Heterogeneous networks; IPTComm; Mobility; Real time communications; Research; RTC; SDN; Software defined networks; Telecommunications; Web; WebRTC,Carrier mobility; Communication; Research; Telecommunication; Cloud communications; Collaboration; IPTComm; Real-time communication; RTC; SDN; Software-defined networks; Web; WebRTC; Heterogeneous networks
"Ge F., Tan L.",2,Network utility maximization in two-way flow scenario,2014,2,"Computer Science Department, Central China Normal University, Wuhan, Hubei 430079, China",Central China Normal University,1,China,1,17,9,"A communication network usually has data packets and ac- knowledge (ACK) packets being transmitted in opposite di- rections. ACK packet ows may affect the performance of data packet ows, which is unfortunately not considered in the usual network utility maximization (NUM) model. This paper presents a NUM model in networks with two-way ows (NUMtw) by adding a routing matrix to cover ACK packet ows. The source rates are obtained by solving the dual model and the relation to the routing matrix of ACK packet ows is disclosed. Furthermore, the source rates in networks with one-way ows by the usual NUM model are compared to those in networks with two-way ows by the NUMtw model.",Maximization; Network; Through- put Rates; Two-way Flows; Utility,Networks (circuits); Optimization; Data packet; In networks; Network utility maximization; Network utility maximizations (NUM); Routing matrix; Source rate; Two-way Flows; Utility; Communication
Carpenter B.E.,1,IP addresses considered harmful,2014,3,"Department of Computer Science, University of Auckland, Auckland, New Zealand",University of Auckland,1,New Zealand,1,47,28,This note describes how the Internet has got itself into deep trouble by over-reliance on IP addresses and discusses some possible ways forward.,IP Address,Communication; IP addresss; Internet protocols
"Sivaraman A., Winstein K., Varley P., Batalha J., Goyal A., Das S., Ma J., Balakrishnan H.",8,Protocol design contests,2014,2,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,12,5,"In fields like data mining and natural language processing, design contests have been successfully used to advance the state of the art. Such contests offer an opportunity to bring the excitement and challenges of protocol design-one of the core intellectual elements of research and practice in networked systems-to a broader group of potential contributors, whose ideas may prove important. Moreover, it may lead to an increase in the number of students, especially undergraduates or those learning via online courses, interested in pursuing a career in the field. We describe the creation of the infrastructure and our experience with a protocol design contest conducted in MIT's graduate Computer Networks class. This contest involved the design and evaluation of a congestion-control protocol for paths traversing cellular wireless networks. One key to the success of a design contest is an unambiguous, measurable objective to compare protocols. In practice, protocol design is the art of trading off conflicting goals with each other, but in this contest, we specified that the goal was to maximize log(throughput=delay). This goal is a good match for applications such as video streaming or videoconferencing that care about high throughput and low interactive delays. Some students produced protocols whose performance was better than published protocols tackling similar goals. Furthermore, the convex hull of the set of all student protocols traced out a tradeoff curve in the throughput-delay space, providing useful insights into the entire space of possible protocols. We found that student protocols diverged in performance between the training and testing traces, indicating that some students had overtrained (""overfitted"") their protocols to the training trace. Our conclusion is that, if designed properly, such contests could benefit networking research by making new proposals more easily reproducible and amenable to such ""gamification,"" improve networked systems, and provide an avenue for outreach.",Congestion control; Design contest; Gamification; Machine learning; Protocol,Artificial intelligence; Congestion control (communication); E-learning; Learning algorithms; Learning systems; Natural language processing systems; Network protocols; Students; Video conferencing; Video streaming; Cellular wireless networks; Design and evaluations; Design contests; Gamification; NAtural language processing; Networked systems; Trade-off curves; Training and testing; Design
"Awara K., Jamjoom H., Kanlis P.",3,"To 4,000 compute nodes and beyond: Network-aware vertex placement in large-scale graph processing systems",2013,0,"KAUST, Thuwal, Saudi Arabia; IBM Watson Research Center, Yorktown Heights, NY, United States",IBM,1,Saudi Arabia;USA,2,5,5,"The explosive growth of ""big data"" is giving rise to a new breed of large scale graph systems, such as Pregel. This poster describes our ongoing work in characterizing and minimizing the communication cost of Bulk Synchronous Parallel (BSP) graph mining systems, like Pregel, when scaling to 4,096 compute nodes. Existing implementations generally assume a fixed communication cost. This is sufficient in small deployments as the BSP programming model (i.e., overlapping computation and communication) masks small variations in the underlying network. In large scale deployments, such variations can dominate the overall runtime characteristics. In this poster, we first quantify the impact of network communication on the total compute time of a Pregel system. We then propose an efficient vertex placement strategy that subsamples highly connected vertices and applies the Reverse Cuthill-McKee (RCM) algorithm to efficiently partition the input graph and place partitions closer to each other based on their expected communication patterns. We finally describe a vertex replication strategy to further reduce communication overhead. © 2013 Authors.",bulk synchronous parallel; extreme scaling; graph mining systems; network topology; vertex placement,Bulk synchronous parallel; extreme scaling; Graph mining; Network topology; vertex placement; Communication; Computer architecture; Electric network topology; Mining machinery; Network architecture; Graph theory
"Liu H.H., Wu X., Zhang M., Yuan L., Wattenhofer R., Maltz D.",6,zUpdate: Updating data center networks with zero loss,2013,53,"Yale University, New Haven, CT, United States; Duke University, Durham, NC, United States; Microsoft Research, Redmond, WA, United States",Duke University;Microsoft;Yale University,3,USA,1,19,2,"Datacenter networks (DCNs) are constantly evolving due to various updates such as switch upgrades and VM migrations. Each update must be carefully planned and executed in order to avoid disrupting many of the mission-critical, interactive applications hosted in DCNs. The key challenge arises from the inherent difficulty in synchronizing the changes to many devices, which may result in unforeseen transient link load spikes or even congestions. We present one primitive, zUpdate, to perform congestion-free network updates under asynchronous switch and traffic matrix changes. We formulate the update problem using a network model and apply our model to a variety of representative update scenarios in DCNs. We develop novel techniques to handle several practical challenges in realizing zUpdate as well as implement the zUpdate prototype on OpenFlow switches and deploy it on a testbed that resembles real DCN topology. Our results, from both real-world experiments and large-scale trace-driven simulations, show that zUpdate can effectively perform congestion-free updates in production DCNs. © 2013 ACM.",congestion; data center network; network update,congestion; Data center networks; Interactive applications; Network modeling; Openflow switches; Real world experiment; Trace driven simulation; Traffic matrices; Computer architecture; Network architecture; Switching circuits
"Dixit A., Hao F., Mukherjee S., Lakshman T.V., Kompella R.",5,Towards an elastic distributed SDN controller,2013,133,"Purdue University, West Lafayette, IN, United States; Bell Labs. Alcatel-Lucent, Holmdel, NJ, United States",Bell Labs;Purdue University,2,USA,1,17,14,"Distributed controllers have been proposed for Software Defined Networking to address the issues of scalability and reliability that a centralized controller suffers from. One key limitation of the distributed controllers is that the mapping between a switch and a controller is statically configured, which may result in uneven load distribution among the controllers. To address this problem, we propose ElastiCon, an elastic distributed controller architecture in which the controller pool is dynamically grown or shrunk according to traffic conditions and the load is dynamically shifted across controllers. We propose a novel switch migration protocol for enabling such load shifting, which conforms with the Openflow standard. We also build a prototype to demonstrate the efficacy of our design. © 2013 ACM.",data center networks; software-defined networks,Centralized controllers; Data center networks; Distributed controller; Load distributions; Migration protocols; Software-defined networkings; Software-defined networks; Traffic conditions; Computer architecture; Network architecture; Controllers
"Wang T., Wang G., Li X., Zheng H., Zhao B.Y.",5,Characterizing and detecting malicious crowdsourcing,2013,2,"Electronic Engineering, Tsinghua University, Beijing, China; Department of Computer Science, University of California, Santa Barbara, CA, United States",Tsinghua University;University of California Santa Barbara,2,China;USA,2,5,5,"Popular Internet services in recent years have shown that remarkable things can be achieved by harnessing the power of the masses. However, crowd-sourcing systems also pose a real challenge to existing security mechanisms deployed to protect Internet services, particularly those tools that identify malicious activity by detecting activities of automated programs such as CAPTCHAs. In this work, we leverage access to two large crowdturfing sites to gather a large corpus of ground-truth data generated by crowdturfing campaigns. We compare and contrast this data with ""organic"" content generated by normal users to identify unique characteristics and potential signatures for use in real-time detectors. This poster describes first steps taken focused on crowdturfing campaigns targeting the Sina Weibo microblogging system. We describe our methodology, our data (over 290K campaigns, 34K worker accounts, 61 million tweets...), and some initial results. © 2013 Authors.",crowdturfing; malicious crowdsourcing; user behavior,Crowdsourcing; crowdturfing; Detecting activities; Internet services; Malicious activities; Microblogging; Security mechanism; User behaviors; Computer architecture; Internet; Network architecture; Network security; Behavioral research
"Pu Q., Jiang S., Gollakota S.",3,Whole-home gesture recognition using wireless signals (demo),2013,5,"University of Washington, Seattle, WA, United States",University of Washington at St. Louis,1,USA,1,5,5,"This demo presents WiSee, a novel human-computer interaction system that leverages wireless networks (e.g., Wi-Fi), to enable sensing and recognition of human gestures and motion. Since wire- less signals do not require line-of-sight and can traverse through walls, WiSee enables novel human-computer interfaces for remote device control and building automation. Further, it achieves this goal without requiring instrumentation of the human body with sensing devices. We integrate WiSee with applications and demonstrate how WiSee enables users to use gestures and control applications including music players and gaming systems. Specifically, our demo will allow SIGCOMM attendees to control a music player and a lighting control device using gestures. © 2013 Authors.",gestures; user interface; wireless,Building automation; Control applications; gestures; Human computer interfaces; Human-computer interaction system; Lighting controls; Sensing devices; Wireless signals; Computer architecture; Gesture recognition; Intelligent buildings; Network architecture; Radio; Sensors; User interfaces
"Yang Q., Li X., Yao H., Fang J., Tan K., Hu W., Zhang J., Zhang Y.",8,BigStation: Enabling scalable real-time signal processingin large mu-mimo systems,2013,14,"Microsoft Research Asia, Beijing, China; CUHK, China; Tsinghua University, China; UTSC, China; BJTU, China",Microsoft;Tsinghua University,2,China,1,26,18,"Multi-user multiple-input multiple-output (MU-MIMO) is the latest communication technology that promises to linearly increase the wireless capacity by deploying more antennas on access points (APs). However, the large number of MIMO antennas will generate a huge amount of digital signal samples in real time. This imposes a grand challenge on the AP design by multiplying the computation and the I/O requirements to process the digital samples. This paper presents BigStation, a scalable architecture that enables realtime signal processing in large-scale MIMO systems which may have tens or hundreds of antennas. Our strategy to scale is to extensively parallelize the MU-MIMO processing on many simple and low-cost commodity computing devices. Our design can incrementally support more antennas by proportionally adding more computing devices. To reduce the overall processing latency, which is a critical constraint for wireless communication, we parallelize the MU-MIMO processing with a distributed pipeline based on its computation and communication patterns. At each stage of the pipeline, we further use data partitioning and computation partitioning to increase the processing speed. As a proof of concept, we have built a BigStation prototype based on commodity PC servers and standard Ethernet switches. Our prototype employs 15 PC servers and can support real-time processing of 12 software radio antennas. Our results show that the BigStation architecture is able to scale to tens to hundreds of antennas. With 12 antennas, our BigStation prototype can increase wireless capacity by 6.8x with a low mean processing delay of 860μs. While this latency is not yet low enough for the 802.11 MAC, it already satisfies the real-time requirements of many existing wireless standards, e.g., LTE and WCDMA. © 2013 ACM.",bigstation; mu-mimo; parallel signal processing; software radio,bigstation; Communication technologies; MU-MIMO; Multi user multiple input multiple outputs; Parallel signal processing; Real-time signal processing; Scalable architectures; Wireless communications; Computer architecture; MIMO systems; Mobile telecommunication systems; Network architecture; Personal computers; Pipeline processing systems; Pipelines; Signal processing; Software radio; Wireless telecommunication systems; Antennas
"Liu V., Parks A., Talla V., Gollakota S., Wetherall D., Smith J.R.",6,Ambient backscatter: Wireless communication out of thin air,2013,153,"University of Washington, Seattle, WA, United States",University of Washington at St. Louis,1,USA,1,39,24,"We present the design of a communication system that enables two devices to communicate using ambient RF as the only source of power. Our approach leverages existing TV and cellular transmissions to eliminate the need for wires and batteries, thus enabling ubiquitous communication where devices can communicate among themselves at unprecedented scales and in locations that were previously inaccessible. To achieve this, we introduce ambient backscatter, a new communication primitive where devices communicate by backscattering ambient RF signals. Our design avoids the expensive process of generating radio waves; backscatter communication is orders of magnitude more power-efficient than traditional radio communication. Further, since it leverages the ambient RF signals that are already around us, it does not require a dedicated power infrastructure as in traditional backscatter communication. To show the feasibility of our design, we prototype ambient backscatter devices in hardware and achieve information rates of 1 kbps over distances of 2.5 feet and 1.5 feet, while operating outdoors and indoors respectively. We use our hardware prototype to implement proof-of-concepts for two previously infeasible ubiquitous communication applications. © 2013 ACM.",backscatter; energy harvesting; internet of things; wireless,Communication primitives; Hardware prototype; Information rates; Internet of Things (IOT); Orders of magnitude; Power infrastructures; Ubiquitous communication; Wireless communications; Communication systems; Computer architecture; Computer hardware; Design; Energy harvesting; Hardware; Network architecture; Radio; Ubiquitous computing; Wireless telecommunication systems; Backscattering
"Hong C.-Y., Kandula S., Mahajan R., Zhang M., Gill V., Nanduri M., Wattenhofer R.",7,Achieving high utilization with software-driven WAN,2013,162,"University of Illinois at Urbana-Champaign, Urbana, IL, United States; Microsoft, Redmond, WA, United States; ETH Zurich, Zurich, Switzerland",ETH Zurich;Microsoft;UIUC,3,Switzerland;USA,2,36,28,"We present SWAN, a system that boosts the utilization of inter-datacenter networks by centrally controlling when and how much traffic each service sends and frequently re-configuring the network's data plane to match current traffic demand. But done simplistically, these re-configurations can also cause severe, transient congestion because different switches may apply updates at different times. We develop a novel technique that leverages a small amount of scratch capacity on links to apply updates in a provably congestion-free manner, without making any assumptions about the order and timing of updates at individual switches. Further, to scale to large networks in the face of limited forwarding table capacity, SWAN greedily selects a small set of entries that can best satisfy current demand. It updates this set without disrupting traffic by leveraging a small amount of scratch capacity in forwarding tables. Experiments using a testbed prototype and data-driven simulations of two production networks show that SWAN carries 60% more traffic than the current practice. © 2013 ACM.",inter-dc wan; software-defined networking,Current practices; Data-driven simulation; Forwarding tables; High utilizations; Novel techniques; Production network; Re-configurations; Software-defined networkings; Computer architecture; Network architecture
"Alizadeh M., Yang S., Sharif M., Katti S., McKeown N., Prabhakar B., Shenker S.",7,pFabric: Minimal near-optimal datacenter transport,2013,83,"Stanford University, Stanford, CA, United States; Insieme Networks, Stanford, CA, United States; U.C. Berkeley, ICSI, Berkeley, CA, United States",Stanford University;University of California Berkeley,2,USA,1,22,17,"In this paper we present pFabric, a minimalistic datacenter transport design that provides near theoretically optimal flow completion times even at the 99th percentile for short flows, while still minimizing average flow completion time for long flows. Moreover, pFabric delivers this performance with a very simple design that is based on a key conceptual insight: datacenter transport should decouple flow scheduling from rate control. For flow scheduling, packets carry a single priority number set independently by each flow; switches have very small buffers and implement a very simple priority-based scheduling/dropping mechanism. Rate control is also correspondingly simpler; flows start at line rate and throttle back only under high and persistent packet loss. We provide theoretical intuition and show via extensive simulations that the combination of these two simple mechanisms is sufficient to provide near-optimal performance. © 2013 ACM.",datacenter network; flow scheduling; packet transport,Data center networks; Extensive simulations; Flow scheduling; Near-optimal performance; packet transport; Priority number; Priority-based scheduling; Transport design; Computer architecture; Network architecture; Scheduling; Optimization
"Chowdhury M., Kandula S., Stoica I.",3,Leveraging endpoint flexibility in data-intensive clusters,2013,20,"UC Berkeley, Berkeley, CA, United States; Microsoft Research, Redmond, WA, United States",Microsoft;University of California Berkeley,2,USA,1,45,33,"Many applications do not constrain the destinations of their network transfers. New opportunities emerge when such transfers contribute a large amount of network bytes. By choosing the endpoints to avoid congested links, completion times of these transfers as well as that of others without similar flexibility can be improved. In this paper, we focus on leveraging the flexibility in replica placement during writes to cluster file systems (CFSes), which account for almost half of all cross-rack traffic in data-intensive clusters. The replicas of a CFS write can be placed in any subset of machines as long as they are in multiple fault domains and ensure a balanced use of storage throughout the cluster. We study CFS interactions with the cluster network, analyze optimizations for replica placement, and propose Sinbad - a system that identifies imbalance and adapts replica destinations to navigate around congested links. Experiments on EC2 and trace-driven simulations show that block writes complete 1.3x (respectively, 1.58x) faster as the network becomes more balanced. As a collateral benefit, end-to-end completion times of data-intensive jobs improve as well. Sinbad does so with little impact on the long-term storage balance. © 2013 ACM.",cluster file systems; constrained anycast; data-intensive applications; datacenter networks; replica placement,Anycast; Cluster File Systems; Data center networks; Data-intensive application; Replica placement; Computer architecture; Computer simulation; Digital storage; Network architecture; File organization
"Porter G., Strong R., Farrington N., Forencich A., Chen-Sun P., Rosing T., Fainman Y., Papen G., Vahdat A.",9,Integrating microsecond circuit switching into the data center,2013,69,"UC San Diego, San Diego, CA, United States; Google, Inc., United States",Google;University of California San Diego,2,USA,1,25,16,"Recent proposals have employed optical circuit switching (OCS) to reduce the cost of data center networks. However, the relatively slow switching times (10 - 100 ms) assumed by these approaches, and the accompanying latencies of their control planes, has limited its use to only the largest data center networks with highly aggregated and constrained workloads. As faster switch technologies become available, designing a control plane capable of supporting them becomes a key challenge. In this paper, we design and implement an OCS prototype capable of switching in 11.5 μs, and we use this prototype to expose a set of challenges that arise when supporting switching at microsecond time scales. In response, we propose a microsecond-latency control plane based on a circuit scheduling approach we call Traffic Matrix Scheduling (TMS) that proactively communicates circuit assignments to communicating entities so that circuit bandwidth can be used efficiently. © 2013 ACM.",data center networks; optical networks,Circuit switching; Control planes; Data center networks; Design and implements; Optical circuit switching; Switch technologies; Switching time; Traffic matrices; Computer architecture; Fiber optic networks; Network architecture; Scheduling; Switching
"Fayazbakhsh S.K., Lin Y., Tootoonchian A., Ghodsi A., Koponen T., Maggs B., Ng K.C., Sekar V., Shenker S.",9,"Less pain, most of the gain: Incrementally deployable ICN",2013,79,"Stony Brook University, Stony Brook, NY, United States; Duke University, Durham, NC, United States; University of Toronto, Toronto, ON, Canada; ICSI, United States; UC Berkeley, Berkeley, CA, United States; KTH, United States; VMware, San Francisco, CA, United States; Akamai, Cambridge, MA, United States",Duke University;Stony Brook University;University of California Berkeley;University of Toronto,4,Canada;USA,2,53,34,"Information-Centric Networking (ICN) has seen a significant resurgence in recent years. ICN promises benefits to users and service providers along several dimensions (e.g., performance, security, and mobility). These benefits, however, come at a non-trivial cost as many ICN proposals envision adding significant complexity to the network by having routers serve as content caches and support nearest-replica routing. This paper is driven by the simple question of whether this additional complexity is justified and if we can achieve these benefits in an incrementally deployable fashion. To this end, we use trace-driven simulations to analyze the quantitative benefits attributed to ICN (e.g., lower latency and congestion). Somewhat surprisingly, we find that pervasive caching and nearest-replica routing are not fundamentally necessary - most of the performance benefits can be achieved with simpler caching architectures. We also discuss how the qualitative benefits of ICN (e.g., security, mobility) can be achieved without any changes to the network. Building on these insights, we present a proof-of-concept design of an incrementally deployable ICN architecture. © 2013 ACM.",information-centric networking; internet architecture,Caching architecture; Information-centric networkings; Information-centric networkings (ICN); Internet architecture; Performance benefits; Proof-of-concept design; Quantitative benefits; Trace driven simulation; Complex networks; Computer architecture; Network architecture
"Xue L., Mok R.K.P., Chang R.K.C.",3,OMware: An open measurement ware for stable residential broadband measurement,2013,0,"Department of Computing, Hong Kong Polytechnic University, Hong Kong, Hong Kong",Hong Kong Polytechnic University,1,Hong Kong,1,5,2,"A number of home-installed middleboxes, e.g., BISMark and SamKnows, and web-based tools, e.g., Netalyzr and Ookla's speedtest service, have been developed recently to enable residential broadband users to gauge their network service quality. One challenge to designing these systems is to provide stable network measurement. That is, the measurement results will not be fluctuated by sporadic overheads incurred inside the middlebox or web browser. In this poster, we propose a network measurement ware, OMware, to increase the stability of residential broadband measurement. The key feature is to implement the send and receive functions for measurement packets in the kernel. Our preliminary evaluation for an OpenWrt implementation shows that OMware provides very stable throughput and delay measurement, compared with typical socket-based measurement at the user level. © 2013 Authors.",high performance; network measurement; openwrt kernel module,Broadband measurements; Broadband users; Delay measurements; high performance; Kernel modules; Network measurement; Network services; Stable throughput; Computer architecture; Housing; Network architecture; Measurements
"Ferguson A.D., Guha A., Liang C., Fonseca R., Krishnamurthi S.",5,Participatory networking: An API for application control of SDNs,2013,50,"Brown University, Providence, RI, United States; Cornell University, Ithaca, NY, United States",Brown University;Cornell University,2,USA,1,52,7,"We present the design, implementation, and evaluation of an API for applications to control a software-defined network (SDN). Our API is implemented by an OpenFlow controller that delegates read and write authority from the network's administrators to end users, or applications and devices acting on their behalf. Users can then work with the network, rather than around it, to achieve better performance, security, or predictable behavior. Our API serves well as the next layer atop current SDN stacks. Our design addresses the two key challenges: how to safely decompose control and visibility of the network, and how to resolve conflicts between untrusted users and across requests, while maintaining baseline levels of fairness and security. Using a real OpenFlow testbed, we demonstrate our API's feasibility through microbenchmarks, and its usefulness by experiments with four real applications modified to take advantage of it. © 2013 ACM.",openflow; participatory networking; software-defined networks,Application-control; Better performance; Micro-benchmarks; Openflow; OR applications; Participatory networkings; Real applications; Software-defined networks; Computer architecture; Network architecture; Application programming interfaces (API)
"Adib F., Katabi D.",2,See through walls with WiFi!,2013,98,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,41,28,"Wi-Fi signals are typically information carriers between a transmitter and a receiver. In this paper, we show that Wi-Fi can also extend our senses, enabling us to see moving objects through walls and behind closed doors. In particular, we can use such signals to identify the number of people in a closed room and their relative locations. We can also identify simple gestures made behind a wall, and combine a sequence of gestures to communicate messages to a wireless receiver without carrying any transmitting device. The paper introduces two main innovations. First, it shows how one can use MIMO interference nulling to eliminate reflections off static objects and focus the receiver on a moving target. Second, it shows how one can track a human by treating the motion of a human body as an antenna array and tracking the resulting RF beam. We demonstrate the validity of our design by building it into USRP software radios and testing it in office buildings. © 2013 ACM.",gesture-based user interface; mimo; seeing through walls; wireless,Information carriers; Moving objects; Moving targets; Number of peoples; Relative location; Static objects; Through walls; Wireless receivers; Antenna arrays; Computer architecture; MIMO systems; Network architecture; Office buildings; Radio; User interfaces; Walls (structural partitions)
"Voellmy A., Wang J., Yang Y.R., Ford B., Hudak P.",5,Maple: Simplifying SDN programming using algorithmic policies,2013,63,"Yale University, New Haven, CT, United States; University of Science and Technology of China, China",University of Science and Technology of China;Yale University,2,China;USA,2,24,19,"Software-Defined Networking offers the appeal of a simple, centralized programming model for managing complex networks. However, challenges in managing low-level details, such as setting up and maintaining correct and efficient forwarding tables on distributed switches, often compromise this conceptual simplicity. In this paper, we present Maple, a system that simplifies SDN programming by (1) allowing a programmer to use a standard programming language to design an arbitrary, centralized algorithm, which we call an algorithmic policy, to decide the behaviors of an entire network, and (2) providing an abstraction that the programmer-defined, centralized policy runs, conceptually, ""afresh"" on every packet entering a network, and hence is oblivious to the challenge of translating a high-level policy into sets of rules on distributed individual switches. To implement algorithmic policies efficiently, Maple includes not only a highly-efficient multicore scheduler that can scale efficiently to controllers with 40+ cores, but more importantly a novel tracing runtime optimizer that can automatically record reusable policy decisions, offload work to switches when possible, and keep switch flow tables up-to-date by dynamically tracing the dependency of policy decisions on packet contents as well as the environment (system state). Evaluations using real HP switches show that Maple optimizer reduces HTTP connection time by a factor of 100 at high load. During simulated benchmarking, Maple scheduler, when not running the optimizer, achieves a throughput of over 20 million new flow requests per second on a single machine, with 95-percentile latency under 10 ms. © 2013 ACM.",algorithmic policies; openflow; software-defined networking,Centralized algorithms; Centralized programming model; Conceptual simplicity; Forwarding tables; High level policies; Openflow; Software-defined networkings; Standard programming language; Algorithms; Computer architecture; Decision making; Network architecture; Program translators; Scheduling; Time switches; Distributed computer systems
"Han S., Liu V., Pu Q., Peter S., Anderson T., Krishnamurthy A., Wetherall D.",7,Expressive privacy control with pseudonyms,2013,6,"University of Washington, Seattle, WA, United States",University of Washington at St. Louis,1,USA,1,27,22,"As personal information increases in value, the incentives for remote services to collect as much of it as possible increase as well. In the current Internet, the default assumption is that all behavior can be correlated using a variety of identifying information, not the least of which is a user's IP address. Tools like Tor, Privoxy, and even NATs, are located at the opposite end of the spectrum and prevent any behavior from being linked. Instead, our goal is to provide users with more control over linkability - which activites of the user can be correlated at the remote services - not necessarily more anonymity. We design a cross-layer architecture that provides users with a pseudonym abstraction. To the user, a pseudonym represents a set of activities that the user is fine with linking, and to the outside world, a pseudonym gives the illusion of a single machine. We provide this abstraction by associating each pseudonym with a unique, random address drawn from the IPv6 address space, which is large enough to provide each device with multiple globally-routable addresses. We have implemented and evaluated a prototype that is able to provide unlinkable pseudonyms within the Chrome web browser in order to demonstrate the feasibility, efficacy, and expressiveness of our approach. © 2013 ACM.",ipv6; privacy; pseudonym; web tracking,Cross-layer architecture; ipv6; Ipv6 address; Personal information; Privacy control; pseudonym; Remote services; Single- machines; Abstracting; Computer architecture; Data privacy; Network architecture; Internet protocols
Zhang J.,1,Greedy forwarding for mobile social networks embedded in hyperbolic spaces,2013,4,"Department of Computer Science, Columbia University, New York, NY, United States",Columbia University,1,USA,1,7,7,"In this work, we design and evaluate a novel greedy forwarding algorithm using metrics in hyperbolic spaces. Hyperbolic geometry has a natural topological reflection of scale-free networks, and greedy algorithm failed in Euclidean space becomes possible in hyperbolic one. We show that mobile social networks can be successfully embedded in such spaces, and obtains competitive performance in terms of message delivery ratio and cost. Under this result, we thus intuitively reveal the fundamental reason that why the famous BUBBLE Rap achieves the optimal performance. © 2013 Author.",greedy forwarding; hyperbolic spaces; mobile social networks,Competitive performance; Greedy algorithms; Greedy forwarding; Hyperbolic geometry; Hyperbolic spaces; Mobile social networks; Optimal performance; Scale free networks; Algorithms; Computer architecture; Geometry; Network architecture; Social networking (online)
"Kumar S., Cifuentes D., Gollakota S., Katabi D.",4,Bringing cross-layer MIMO to today's wireless LANs,2013,18,"Massachusetts Institute of Technology, Cambridge, MA, United States; University of Washington, Seattle, WA, United States",MIT;University of Washington at St. Louis,2,USA,1,35,30,"Recent years have seen major innovations in cross-layer wireless designs. Despite demonstrating significant throughput gains, hardly any of these technologies have made it into real networks. Deploying cross-layer innovations requires adoption from Wi-Fi chip manufacturers. Yet, manufacturers hesitate to undertake major investments without a better understanding of how these designs interact with real networks and applications. This paper presents the first step towards breaking this stalemate, by enabling the adoption of cross-layer designs in today's networks with commodity Wi-Fi cards and actual applications. We present OpenRF, a cross-layer architecture for managing MIMO signal processing. OpenRF enables access points on the same channel to cancel their interference at each other's clients, while beamforming their signal to their own clients. OpenRF is self-configuring, so that network administrators need not understand MIMO or physical layer techniques. We patch the iwlwifi driver to support OpenRF on off-the-shelf Intel cards. We deploy OpenRF on a 20-node network, showing how it manages the complex interaction of cross-layer design with a real network stack, TCP, bursty traffic, and real applications. Our results demonstrate an average gain of 1.6x for TCP traffic and a significant reduction in response time for real-time applications, like remote desktop. © 2013 ACM.",cross-layer; mimo; sdn; wireless,Chip manufacturers; Cross-layer; Cross-layer architecture; Cross-layer design; Network administrator; Real applications; Real-time application; sdn; Complex networks; Computer architecture; Design; Manufacture; MIMO systems; Network layers; Radio; Signal processing; Transmission control protocol; Wi-Fi; Network architecture
"Biswas T., Chakraborti A., Ravindran R., Zhang X., Wang G.",5,Contextualized information-centric home network,2013,4,"North Carolina State University, Raleigh, NC, United States; Huawei Research Center, Santa Clara, CA, United States",Huawei Technologies;North Carolina State University,2,USA,1,3,2,"We deploy information-centric networks (ICN) to serve several applications including content distribution, vehicle-to-vehicle communication (V2V), home networks (homenet), and sensor networks. These applications require policy and context-based interaction between service producers and consumers. We visualize the ICN service layer as a contextualized information-centric bus (CIBUS), over which diverse sets of service producers and consumers co-exist. We develop a prototype and demonstrate several desirable features of ICN for homenets such as contextual service publishing and subscription, zero-configuration based node and service discovery, policy based routing and forwarding with name-based firewall, and device-to-device communication. Furthermore the prototype is applicable to both ad hoc and infrastructure settings, and can deal with diverse devices and services. © 2013 Authors.",content centric networking; home networks; information-centric networks; named data networks; node discovery; policy based routing; service discovery; zero-configuration,Content-centric networkings; Information-centric; Named data networks; Node discovery; Policy based routing; Service discovery; zero-configuration; Carrier communication; Communication; Computer architecture; Home networks; Network architecture; Sensor networks; Vehicle to vehicle communications; Personal communication systems
"Balachandran A., Sekar V., Akella A., Seshan S., Stoica I., Zhang H.",6,Developing a predictive model of quality of experience for internet video,2013,98,"Carnegie Mellon University, Pittsburgh, PA, United States; Stony Brook University, Stony Brook, NY, United States; University of Wisconsin-Madison, Madison, WI, United States; University of California Berkeley, Berkeley, CA, United States",Carnegie Mellon University;Stony Brook University;University of California Berkeley;University of Wisconsin-Madison,4,USA,1,41,26,"Improving users' quality of experience (QoE) is crucial for sustaining the advertisement and subscription based revenue models that enable the growth of Internet video. Despite the rich literature on video and QoE measurement, our understanding of Internet video QoE is limited because of the shift from traditional methods of measuring video quality (e.g., Peak Signal-to-Noise Ratio) and user experience (e.g., opinion scores). These have been replaced by new quality metrics (e.g., rate of buffering, bitrate) and new engagement centric measures of user experience (e.g., viewing time and number of visits). The goal of this paper is to develop a predictive model of Internet video QoE. To this end, we identify two key requirements for the QoE model: (1) it has to be tied in to observable user engagement and (2) it should be actionable to guide practical system design decisions. Achieving this goal is challenging because the quality metrics are interdependent, they have complex and counter-intuitive relationships to engagement measures, and there are many external factors that confound the relationship between quality and engagement (e.g., type of video, user connectivity). To address these challenges, we present a data-driven approach to model the metric interdependencies and their complex relationships to engagement, and propose a systematic framework to identify and account for the confounding factors. We show that a delivery infrastructure that uses our proposed model to choose CDN and bitrates can achieve more than 20% improvement in overall user engagement compared to strawman approaches. © 2013 ACM.",human factors; measurement; peformance; video quality,Complex relationships; Data-driven approach; Peak signal-to-noise ratio; peformance; Predictive modeling; Quality of experience (QoE); Systematic framework; Video quality; Computer architecture; Human computer interaction; Human engineering; Internet; Measurements; Network architecture; Quality of service
"Han D., Grandl R., Akella A., Seshan S.",4,FCP: A flexible transport framework for accommodating diversity,2013,5,"Korea Advanced Institute of Science and Technology, Daejon, South Korea; University of Wisconsin-Madison, Madison, WI, United States; Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University;KAIST;University of Wisconsin-Madison,3,South Korea;USA,2,52,29,"Transport protocols must accommodate diverse application and network requirements. As a result, TCP has evolved over time with new congestion control algorithms such as support for generalized AIMD, background flows, and multipath. On the other hand, explicit congestion control algorithms have been shown to be more efficient. However, they are inherently more rigid because they rely on in-network components. Therefore, it is not clear whether they can be made flexible enough to support diverse application requirements. This paper presents a flexible framework for network resource allocation, called FCP, that accommodates diversity by exposing a simple abstraction for resource allocation. FCP incorporates novel primitives for end-point flexibility (aggregation and preloading) into a single framework and makes economics-based congestion control practical by explicitly handling load variations and by decoupling it from actual billing. We show that FCP allows evolution by accommodating diversity and ensuring coexistence, while being as efficient as existing explicit congestion control algorithms. © 2013 ACM.",congestion control; end-point flexibility; transport protocol,Background flow; Diverse applications; End points; Explicit congestion controls; Flexible framework; Network requirements; Network resource allocations; Transport protocols; Algorithms; Computer architecture; Congestion control (communication); Economics; Network architecture; Point contacts; Queueing networks; Resource allocation; Transmission control protocol
"Xia W., Tsou T., Lopez D.R., Sun Q., Lu F., Xie H.",6,A software defined approach to unified IPv6 transition,2013,1,"University of Science and Technology of China, Hefei, China; Huawei, Santa Clara, CA, United States; Telefónica I+D, Madrid, Spain; China Telecom, Beijing, China; Huawei, Shenzhen, China",University of Science and Technology of China,1,China;Spain;USA,3,4,4,"The IPv6 transition has been an ongoing process throughout the world due to the exhaustion of the IPv4 address space. However, this transition leads to costly end-to-end network upgrades and poses new challenges of managing a large number of devices with a variety of transitioning protocols. Recognizing these difficulties, we propose an software defined approach to unifying the deployment of IPv6 in a cost-effective, flexible manner. Our deployment and experiments demonstrate significant benefits of this approach, including low complexity, low cost and high flexibility of adopting different existing transition mechanisms. © 2013 Authors.",ipv6 transition; software defined network,Address space; End-to-end network; High flexibility; IPv6 transition; Low costs; Software-defined networks; Transition mechanism; Complex networks; Computer architecture; Network architecture
"Calder M., Miao R., Zarifis K., Katz-Bassett E., Yu M., Padhye J.",6,"Don't drop, detour!",2013,2,"Univ. of Southern California, Los Angeles, CA, United States; Microsoft Research, Redmond, WA, United States",Microsoft;University of Southern California,2,USA,1,8,7,"Today's data centers must support a range of workloads with different demands. While existing approaches handle routine traffic smoothly, ephemeral but intense hotspots cause excessive packet loss and severely degrade performance. This loss occurs even though the congestion is typically highly localized, with spare buffer capacity available at nearby switches. We argue that switches should share buffer capacity to effectively handle this spot congestion without the latency or monetary hit of deploying large buffers at individual switches. We present detour-induced buffer sharing (DIBS), a mechanism that achieves a near lossless network without requiring additional buffers. Using DIBS, a congested switch detours packets randomly to neighboring switches to avoid dropping the packets. We implement DIBS in hardware, on software routers in a testbed, and in simulation, and we demonstrate that it reduces the 99th percentile of query completion time by 85%, with very little impact on background traffic. © 2013 Authors.",buffers; data center; packet loss,Background traffic; Buffer capacity; Buffer sharing; Completion time; Congested switches; Data centers; Near-lossless; Software routers; Buffer storage; Computer architecture; Packet loss; Railroad car buffers; Satellite communication systems; Network architecture
"Ming Z., Xu M., Wang D.",3,In-network caching assisted wireless AP storage management: Challenges and algorithms,2013,1,"Tsinghua University, 4-104 FIT Building, Haidian, Beijing, 100084, China; Hong Kong Polytechnic University, Hung Hom, KL, Hong Kong",Hong Kong Polytechnic University;Tsinghua University,2,China;Hong Kong,2,5,5,"The goal of this paper is to improve wireless AP caching by leveraging in-network caching. We observe that by treating routers as an in-network storage extension, we can relieve the storage limitation of APs. The unique challenge is that APs and routers cannot have a full collaboration, which makes the problem different from traditional cooperative caching problems. We study how APs can optimize caching decisions by using in-network caching information without controlling routers. © 2013 Authors.",algorithm; information-centric networking; wireless caching,Caching decisions; Cooperative caching; In networks; In-network storages; Information-centric networkings; Storage limitation; Computer architecture; Network architecture; Algorithms
"Roverso R., El-Ansary S., Högqvist M.",3,On HTTP live streaming in large enterprises,2013,1,"Peerialism AB, KTH - Royal Institute of Technology, Stockholm, Sweden; Peerialism AB, Stockholm, Sweden",KTH Royal Institute of Technology,1,Sweden,1,5,4,"In this work, we present a distributed caching solution which addresses the problem of efficient delivery of HTTP live streams in large private networks. With our system, we have conducted tests on a number of pilot deployments. The largest of them, with 3000 concurrent viewers, consistently showed that our system saves more than 90% of traffic towards the source of the stream while providing the same quality of user experience of a CDN. Another result is that our solution was able to reduce the load on the bottlenecks in the network by an average of 91.6%. © 2013 Authors.",content delivery network; distributed caching; http live; private networks,Content delivery network; Distributed caching; Http-live streaming; Large enterprise; Private networks; User experience; Computer architecture; Network architecture; Video streaming; HTTP
"Roy S., Feamster N.",2,Characterizing correlated latency anomalies in broadband access networks,2013,0,"School of Computer Science, Georgia Tech., Atlanta, GA, United States",Georgia Tech,1,USA,1,3,1,"The growing prevalence of broadband Internet access around the world has made understanding the performance and reliability of broadband access networks extremely important. To better understand the performance anomalies that arise in broadband access networks, we have deployed hundreds of routers in home broadband access networks around the world and are studying the performance of these networks. One of the performance pathologies that we have observed is correlated, sudden latency increases simultaneously and to multiple destinations. In this work, we provide an preliminary glimpse into these sudden latency increases and attempt to understand their causes. Although we do not isolate root cause in this study, observing the sets of destinations that experience correlated latency increases can provide important clues as to the locations in the network that may be inducing these pathologies. We present an algorithm to better identify the network locations that are likely responsible for these pathologies. We then analyze latency data from one month across our home router deployment to determine where in the network latency issues are arising, and how those pathologies differ across regions, ISPs, and countries. Our preliminary analysis suggests that most latency pathologies are to a single destination and a relatively small percentage of these pathologies are likely in the last mile, suggesting that peering within the network may be a more likely culprit for these pathologies than access link problems. © 2013 Authors.",active probing; measurement; performance,Active probing; Broad-band access networks; Broadband internet access; Multiple destinations; performance; Performance and reliabilities; Performance anomaly; Preliminary analysis; Computer architecture; Measurements; Network architecture; Routers; Pathology
"Bosshart P., Gibb G., Kim H.-S., Varghese G., McKeown N., Izzard M., Mujica F., Horowitz M.",8,Forwarding metamorphosis: Fast programmable match-action processing in hardware for SDN,2013,100,"Texas Instruments, Dallas, TX, United States; Stanford University, Stanford, CA, United States; Microsoft Research, Mountain View, CA, United States",Microsoft;Stanford University,2,USA,1,35,18,"In Software Defined Networking (SDN) the control plane is physically separate from the forwarding plane. Control software programs the forwarding plane (e.g., switches and routers) using an open interface, such as OpenFlow. This paper aims to overcomes two limitations in current switching chips and the OpenFlow protocol: i) current hardware switches are quite rigid, allowing ''Match-Action'' processing on only a fixed set of fields, and ii) the OpenFlow specification only defines a limited repertoire of packet processing actions. We propose the RMT (reconfigurable match tables) model, a new RISC-inspired pipelined architecture for switching chips, and we identify the essential minimal set of action primitives to specify how headers are processed in hardware. RMT allows the forwarding plane to be changed in the field without modifying hardware. As in OpenFlow, the programmer can specify multiple match tables of arbitrary width and depth, subject only to an overall resource limit, with each table configurable for matching on arbitrary fields. However, RMT allows the programmer to modify all header fields much more comprehensively than in OpenFlow. Our paper describes the design of a 64 port by 10 Gb/s switch chip implementing the RMT model. Our concrete design demonstrates, contrary to concerns within the community, that flexible OpenFlow hardware switch implementations are feasible at almost no additional cost or power. © 2013 ACM.",reconfigurable match tables; rmt model; sdn,Additional costs; Current switching; Forwarding planes; Packet processing; Pipelined architecture; Reconfigurable; sdn; Software defined networking (SDN); Computer architecture; Hardware; Network architecture; Reconfigurable hardware; Computer hardware
"Qazi Z.A., Tu C.-C., Chiang L., Miao R., Sekar V., Yu M.",6,SIMPLE-fying middlebox policy enforcement using SDN,2013,161,"Stony Brook University, Stony Brook, NY, United States; University of Southern California, Los Angeles, CA, United States",Stony Brook University;University of Southern California,2,USA,1,46,31,"Networks today rely on middleboxes to provide critical performance, security, and policy compliance capabilities. Achieving these benefits and ensuring that the traffic is directed through the desired sequence of middleboxes requires significant manual effort and operator expertise. In this respect, Software-Defined Networking (SDN) offers a promising alternative. Middleboxes, however, introduce new aspects (e.g., policy composition, resource management, packet modifications) that fall outside the purvey of traditional L2/L3 functions that SDN supports (e.g., access control or routing). This paper presents SIMPLE, a SDN-based policy enforcement layer for efficient middlebox-specific ""traffic steering"". In designing SIMPLE, we take an explicit stance to work within the constraints of legacy middleboxes and existing SDN interfaces. To this end, we address algorithmic and system design challenges to demonstrate the feasibility of using SDN to simplify middlebox traffic steering. In doing so, we also take a significant step toward addressing industry concerns surrounding the ability of SDN to integrate with existing infrastructure and support L4-L7 capabilities. © 2013 ACM.",middlebox; network management; software-defined networking,Design challenges; Middleboxes; Packet modifications; Policy compliance; Policy compositions; Policy enforcement; Resource management; Software-defined networkings; Network architecture; Network management; Computer architecture
"Liu Z., Li Y., Su L., Jin D., Zeng L.",5,M2cloud: Software defined multi-site data center network control framework for multi-tenant,2013,8,"Department of Electronic Engineering, Tsinghua University, Beijing 100084, China",Tsinghua University,1,China,1,4,4,"A significant concern for cloud operators is to provide global network performance isolation for concurrent tenants. To address this, we propose M2cloud, a software defined framework providing scalable network control for multi-site data centers (DCs). M2cloud employs two-level controllers with decoupled functions, providing each tenant with flexible virtualization support in both intra- and inter-DC networks. © 2013 Authors.",data center networks; multi-site; multi-tenant; sdn,Data center (DCs); Data center networks; Multi tenants; Multi-site; Scalable networks; sdn; Virtualizations; Computer architecture; Network architecture
"Wang X., Chen C., Li J.",3,Replication free rule grouping for packet classification,2013,5,"Department of Automation, Tsinghua University, Beijing, China; Research Institute of Information, Tsinghua University, Beijing, China; Tsinghua National Lab. for Information Science and Technology, Beijing, China",Tsinghua University,1,China,1,4,4,"Most recent works demonstrate that grouping methodology could bring significant reduction of memory usage to decision-tree packet classification algorithms, with insignificant impact on throughput. However, these grouping techniques can hardly eliminate rule-replication completely. This work proposes a novel rule grouping algorithm without any replication. At each space decomposition step, all rules projecting on the split dimension form the maximum number of non-overlapped ranges, which guarantees the modest memory usage and grouping speed. Evaluation shows that the proposed algorithm achieves comparable memory size with less pre-processing time. © 2013 Authors.",algorithms; packet classification; rule replication,Grouping algorithm; Grouping technique; Memory usage; Packet classification; Packet classification algorithm; Pre-processing; rule replication; Space decomposition; Computer architecture; Network architecture; Packet networks; Algorithms
"Jiang X., Bi J.",2,Interest set mechanism to improve the transport of named data networking,2013,6,"Institute for Network Sciences and Cyberspace, Tsinghua University, Department of Computer Science, Beijing, China",Tsinghua University,1,China,1,3,2,"In this paper, we proposal an Interest Set mechanism which aggregate similar Interest packets from same flow to one packet to improve the efficient of transport of NDN. The trick here is to reset lifetime of corresponding PIT entry in the immediate routers every time when valid Data packet is passed by. This mechanism covers the time and space uncertainty of data generating, reduce the cost of maintaining the pipeline and improve the transport of NDN. © 2013 Authors.",icn; ndn; transport,Data packet; icn; Named data networkings; ndn; Set mechanism; Similar Interests; transport; Computer architecture; Network architecture
"Wu Z., Butkiewicz M., Perkins D., Katz-Bassett E., Madhyastha H.V.",5,CSPAN: Cost-effective geo-replicated storage spanning multiple cloud services,2013,1,"University of California, Riverside, Riverside, CA, United States; University of Southern California, Los Angeles, CA, United States",University of California Riverside;University of Southern California,2,USA,1,4,1,"Existing cloud computing platforms leave it up to applications to deal with the complexities associated with data replication and propagation across data centers. In our work, we propose the CSPAN key-value store to instead export a unified view of storage services in several geographically distributed data centers. To minimize the cost incurred by application providers, we combine two principles. First, CSPAN spans the data centers of multiple cloud providers. Second, CSPAN judiciously trades off the lower latencies and the higher storage and data propagation costs based on an application's anticipated workload, latency goals, and consistency requirements. © 2013 Authors.",cloud services; optimization; storage system,Application providers; Cloud computing platforms; Cloud services; Consistency requirements; Data propagation; Distributed data; Storage services; Storage systems; Computer architecture; Distributed database systems; Network architecture; Optimization; Web services; Digital storage
"Yen Y.-C., Chu C.-Y., Chen C.-N., Yeh S.-L., Chu H.-H., Huang P.",6,Exponential quantization: User-centric rate control for Skype calls,2013,0,"National Taiwan University, Taipei, Taiwan; University of Illinois at Urbana-Champaign, Urbana, IL, United States",National Taiwan University;UIUC,2,Taiwan;USA,2,5,3,"As Skype has become popular and a profitable business, the long-standing problem of how to deliver Skype calls deserves a serious revisit from an economic viewpoint. This study proposes a rate control mechanism for Skype calls that satisfies more users and satisfies users more than the greedy-naïve mechanism, as well as the mechanism implemented in Skype. © 2013 Authors.",proportional fairness; qoe; rate control; skype; voip,Proportional fairness; qoe; Rate controls; skype; voip; Computer architecture; Internet telephony; Network architecture
"Crisan D., Birke R., Cressier G., Minkenberg C., Gusat M.",5,Got loss? Get zOVN!,2013,1,"IBM Research - Zurich Research Laboratory, Säumerstrasse 4, CH-8803 Rüschlikon, Switzerland",IBM,1,Switzerland,1,42,32,"Datacenter networking is currently dominated by two major trends. One aims toward lossless, flat layer-2 fabrics based on Converged Enhanced Ethernet or InfiniBand, with benefits in efficiency and performance. The other targets flexibility based on Software Defined Networking, which enables Overlay Virtual Networking. Although clearly complementary, these trends also exhibit some conflicts: In contrast to physical fabrics, which avoid packet drops by means of flow control, practically all current virtual networks are lossy. We quantify these losses for several common combinations of hypervisors and virtual switches, and show their detrimental effect on application performance. Moreover, we propose a zero-loss Overlay Virtual Network (zOVN) designed to reduce the query and flow completion time of latency-sensitive datacenter applications. We describe its architecture and detail the design of its key component, the zVALE lossless virtual switch. As proof of concept, we implemented a zOVN prototype and benchmark it with Partition-Aggregate in two testbeds, achieving an up to 15-fold reduction of the mean completion time with three widespread TCP versions. For larger-scale validation and deeper introspection into zOVN, we developed an OMNeT++ model for accurate cross-layer simulations of a virtualized datacenter, which confirm the validity of our results. © 2013 ACM.",datacenter networking; lossless; overlay networks; partition-aggregate; virtualization,Application performance; Datacenter; Efficiency and performance; Lossless; Mean completion time; partition-aggregate; Software-defined networkings; Virtualizations; Aggregates; Computer architecture; Computer simulation; Overlay networks; Transmission control protocol; Network architecture
"Wang K., Li J.",2,Towards fast regular expression matching in practice,2013,1,"Department of Automation, Tsinghua University, Beijing, 10084, China; Research Institute of Information Technology, Tsinghua University, Beijing, 10084, China; Tsinghua National Lab. for Information Science and Technology, Beijing, 10084, China",Tsinghua University,1,China,1,5,3,"Regular expression matching is popular in today's network devices with deep inspection function, but due to lack of algorithmic scalability, it is still the performance bottleneck in practical network processing. To address this problem, our method first partition regular expression patterns into simple segments to avoid state explosion, and then compile these segments into a compact data structure to achieve fast matching. Preliminary experiments illustrate that our matching engine scales linearly with the size of the real-world pattern set, and outperforms state-of-the-art solutions. © 2013 Authors.",deep inspection; dfa; regular expression matching,Compact data structure; Deep inspection; dfa; Matching engines; Performance bottlenecks; Practical networks; Regular expressions; Regular-expression matching; Computer architecture; Network architecture; Pattern matching
"Huang H., Liao X., Li S., Peng S., Liu X., Lin B.",6,The architecture and traffic management of wireless collaborated hybrid data center network,2013,1,"School of Computer Science, National University of Defense Technology, Changsha, China",National University of Defense Technology,1,China,1,3,2,"This paper introduces a novel wireless collaborated hybrid data center architecture called RF-HYBRID that could optimize the effect of wireless transmission while reduce the complexity of wired network. RF-HYBRID improves throughput and packet delivery latency through flexible wireless detours and shortcuts, with a comprehensive routing and congestion control method. © 2013 Authors.",data center network; wireless technology,Data center networks; Hybrid datum; Packet Delivery; Traffic management; Wired networks; Wireless technologies; Wireless transmissions; Complex networks; Computer architecture; Network architecture; Wireless telecommunication systems; Information management
"Grosvenor M.P., Schwarzkopf M., Moore A.W.",3,"R2D2: Bufferless, switchless data center networks using commodity ethernet hardware",2013,1,"University of Cambridge, Computer Laboratory, Cambridge, United Kingdom",University of Cambridge,1,UK,1,12,11,"Modern data centers commonly run distributed applications that require low-latency communication, and whose performance is critical to service revenue. If as little as one machine in 10,000 is a latency outlier, around 18% of requests will experience high latency. The sacrifice of latency determinism for bandwidth, however, is not an inevitable one. In our R2D2 architecture, we conceptually split the data centre network into an unbuffered, unswitched low-latency network (LLNet) and a deeply buffered bandwidth centric network (BBNet). Through explicitly scheduling network multiplexing in software, our prototype implementation achieves 99.995% and 99.999% messaging latencies of 35us and 75us respectively for 1514-byte packets on a fully loaded network. Furthermore, we show that it is possible to merge the conceptually separate LLNet and BBNet networks onto the same physical infrastructure using commodity switched Ethernet hardware. © 2013 Authors.",broadcast; data centers; ethernet; latency; scheduling,Buffered bandwidth; Data center networks; Data centers; Distributed applications; latency; Low-latency communication; Low-latency networks; Prototype implementations; Broadcasting; Communication; Computer architecture; Computer hardware; Ethernet; Hardware; Scheduling; Software prototyping; Network architecture
"Mtibaa A., Fahim A., Harras K.A., Ammar M.H.",4,Towards resource sharing in mobile device clouds: Power balancing across mobile devices,2013,3,"Texas A and M University, Doha, Qatar; Carnegie Mellon University, Doha, Qatar; Georgia Institute of Technology, Atlanta, GA, United States",Carnegie Mellon University;Georgia Tech;Texas A and M University,3,Qatar;USA,2,15,12,"Despite the increased capabilities of mobile devices, mobile application resource requirements can often transcend what can be accomplished on a single device. This has been addressed through several proposals for efficient computation offloading from mobile devices to remote cloud resources or closely located computing resources known as cloudlets. In this paper we consider an environment in which computational offloading is performed among a set of mobile devices. We call this environment a Mobile Device Cloud (MDC). We are interested in MDCs where nodes are {\em highly collaborative}. We develop computational offloading schemes that {\em maximize the lifetime} of the ensemble of mobile devices where we consider the network to be alive as long as no device has depleted its battery. As a secondary contribution in this work, we develop and use an experimentation platform that allows us to evaluate a range of computational models and profiles derived from a realistic testbed. We use this platform as a first step in an evaluation exercise that demonstrates the effectiveness of our computation offloading algorithms in extending the lifetime of an MDC. © 2013 ACM.",energy saving; opportunistic computing; resomobile computing; resource sharing,Computation offloading; Computational model; Efficient computation; Experimentation platforms; Opportunistic computing; resomobile computing; Resource requirements; Resource sharing; Computer applications; Computer architecture; Energy conservation; Network architecture; Mobile devices
"Hua Y., Liu X., Feng D.",3,Smart in-network deduplication for storage-aware SDN,2013,4,"WNLO, School of Computer, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science, McGill University, Montreal, QC, Canada",Huazhong University of Science and Technology;McGill University,2,Canada;China,2,5,4,"In order to efficiently handle the rapid growth of data and reduce the overhead of network transmission, we propose an in-network deduplication for storage-aware Software Defined Network (SDN), called SMIND. Unlike conventional source or destination deduplication schemes, SMIND implements in-network deduplication via SDN. Moreover, to address the performance bottleneck of accessing and indexing SDN controller, we implement an SDN-enabled Flash Translation Layer (FTL) in a real prototype of Solid State Disk (SSD). Experimental results demonstrate the efficiency and efficacy of SMIND. © 2013 Authors.",deduplication; software defined network; storage systems,De duplications; Flash translation layer; Network transmission; Performance bottlenecks; Rapid growth; Software-defined networks; Solid state disks (SSD); Storage systems; Computer architecture; Network architecture; Data storage equipment
"Le Blond S., Choffnes D., Zhou W., Druschel P., Ballani H., Francis P.",6,Towards efficient traffic-analysis resistant anonymity networks,2013,8,"MPI-SWS, Kaiserslautern, Germany; University of Washington, Seattle, WA, United States; Northeastern University, Boston, MA, United States; UIUC, Urbana-Champaign, IL, United States; Microsoft Research, Cambridge, United Kingdom",Microsoft;Northeastern University;UIUC;University of Washington at St. Louis,4,Germany;UK;USA,3,33,20,"Existing IP anonymity systems tend to sacrifice one of low latency, high bandwidth, or resistance to traffic-analysis. High-latency mix-nets like Mixminion batch messages to resist traffic-analysis at the expense of low latency. Onion routing schemes like Tor deliver low latency and high bandwidth, but are not designed to withstand traffic analysis. Designs based on DC-nets or broadcast channels resist traffic analysis and provide low latency, but are limited to low bandwidth communication. In this paper, we present the design, implementation, and evaluation of Aqua, a high-bandwidth anonymity system that resists traffic analysis. We focus on providing strong anonymity for BitTorrent, and evaluate the performance of Aqua using traces from hundreds of thousands of actual BitTorrent users. We show that Aqua achieves latency low enough for efficient bulk TCP flows, bandwidth sufficient to carry BitTorrent traffic with reasonable efficiency, and resistance to traffic analysis within anonymity sets of hundreds of clients. We conclude that Aqua represents an interesting new point in the space of anonymity network designs. © 2013 ACM.",anonymity networks; p2p file sharing; strong anonymity,Anonymity networks; Anonymity sets; Broadcast channels; High bandwidth; Low-bandwidth communications; P2P file sharing; strong anonymity; Traffic analysis; Bandwidth; Communication; Computer architecture; Design; Distributed computer systems; Network architecture; Network security; Transmission control protocol; Telecommunication systems
"So W., Narayanan A., Oran D., Stapp M.",4,Named data networking on a router: Forwarding at 20Gbps and beyond,2013,8,"Cisco Systems, Inc., Boxborough, MA, United States",Cisco,1,USA,1,3,3,"Named data networking (NDN) is a new networking paradigm using named data instead of named hosts for communication. Implementation of scalable NDN packet forwarding remains a challenge because NDN requires fast variable-length hierarchical name-based lookup, per-packet data plane state update, and large-scale forwarding tables. We have designed and implemented an NDN data plane with a software forwarding engine on an Intel Xeon-based line card in a Cisco ASR9000 router. In order to achieve high-speed forwarding, our design features (1) name lookup via hash tables with fast collision-resistant hash computation, (2) an efficient and secure FIB lookup algorithm that provides good average and bounded worst-case FIB lookup time, (3) PIT partitioning that enables linear multi-core speedup, and (4) an optimized data structure and software prefetching to maximize data cache utilization. In this demonstration, we showcase our NDN router implementation on the ASR9000 and demonstrate that it can forward real NDN traffic at 20Gbps or higher. © 2013 Authors.",named data networking; packet forwarding engine; router,Design features; Forwarding tables; Hash computation; Lookup algorithms; Named data networkings; Packet forwarding; Packet forwarding engines; Software prefetching; Communication; Computer architecture; Engines; Microprocessor chips; Network architecture; Routers; Computational efficiency
"Ion M., Zhang J., Schooler E.M.",3,Toward content-centric privacy in ICN: Attribute-based encryption and routing,2013,8,"University of Trento, CREATE-NET, Via Alla Cascata 56D, Trento, 38123, Italy; Intel Labs., 3600 Juliette Lane, Santa Clara, CA 95054, United States",Intel;University of Trento,2,Italy;USA,2,7,6,"We design a content-centric privacy scheme for Information-Centric Networking (ICN). We enhance ICN's ability to support data confidentiality by introducing attribute-based encryption into ICN and making it specific to the data attributes. Our approach is unusual in that it preserves ICN's goal to decouple publishers and subscribers for greater data accessibility, scalable multiparty communication and efficient data distribution. Inspired by application-layer publish-subscribe, we enable fine-grained access control with more expressive policies. Moreover, we propose an attribute-based routing scheme that offers interest confidentiality. A prototype system is implemented based on CCNx, a popular open source version of ICN, to showcase privacy preservation in Smart Neighborhood and Smart City applications. © 2013 Authors.",attribute-based encryption; icn; privacy; security,Attribute-based encryptions; Data accessibility; Data confidentiality; icn; Information-centric networkings (ICN); Multi-party communication; Privacy preservation; security; Communication; Computer architecture; Data privacy; Network architecture; Open systems; Cryptography
"Jalaparti V., Bodik P., Kandula S., Menache I., Rybalkin M., Yan C.",6,Speeding up distributed request-response workflows,2013,14,"University of Illinois at Urbana-Champaign, Champaign, IL, United States; Microsoft Research, Redmond, WA, United States; St. Petersburg Department, Steklov Institute of Mathematics, Russian Academy of Sciences, St. Petersburg, Russian Federation; Microsoft Bing, Bellevue, WA, United States",Bellevue;Microsoft;Steklov Mathematical Institute;UIUC,4,Russia;USA,2,30,26,"We found that interactive services at Bing have highly variable datacenter-side processing latencies because their processing consists of many sequential stages, parallelization across 10s-1000s of servers and aggregation of responses across the network. To improve the tail latency of such services, we use a few building blocks: reissuing laggards elsewhere in the cluster, new policies to return incomplete results and speeding up laggards by giving them more resources. Combining these building blocks to reduce the overall latency is non-trivial because for the same amount of resource (e.g., number of reissues), different stages improve their latency by different amounts. We present Kwiken, a framework that takes an end-to-end view of latency improvements and costs. It decomposes the problem of minimizing latency over a general processing DAG into a manageable optimization over individual stages. Through simulations with production traces, we show sizable gains; the 99th percentile of latency improves by over 50% when just 0.1% of the responses are allowed to have partial results and by over 40% for 25% of the services when just 5% extra resources are used for reissues. © 2013 ACM.",distributed services.; incomplete results; interactive services; optimization; reissues; tail latency,Distributed service; incomplete results; Interactive services; reissues; tail latency; Computer architecture; Network architecture; Optimization
"Quan L., Heidemann J., Pradkin Y.",3,Trinocular: Understanding internet reliability through adaptive probing,2013,11,"USC, Information Sciences Institute, Marina del Rey, CA, United States",University of Southern California,1,USA,1,35,32,"Natural and human factors cause Internet outages - from big events like Hurricane Sandy in 2012 and the Egyptian Internet shutdown in Jan. 2011 to small outages every day that go unpublicized. We describe Trinocular, an outage detection system that uses active probing to understand reliability of edge networks. Trinocular is principled: deriving a simple model of the Internet that captures the information pertinent to outages, and populating that model through long-term data, and learning current network state through ICMP probes. It is parsimonious, using Bayesian inference to determine how many probes are needed. On average, each Trinocular instance sends fewer than 20 probes per hour to each /24 network block under study, increasing Internet ""background radiation"" by less than 0.7%. Trinocular is also predictable and precise: we provide known precision in outage timing and duration. Probing in rounds of 11 minutes, we detect 100% of outages one round or longer, and estimate outage duration within one-half round. Since we require little traffic, a single machine can track 3.4M /24 IPv4 blocks, all of the Internet currently suitable for analysis. We show that our approach is significantly more accurate than the best current methods, with about one-third fewer false conclusions, and about 30% greater coverage at constant accuracy. We validate our approach using controlled experiments, use Trinocular to analyze two days of Internet outages observed from three sites, and re-analyze three years of existing data to develop trends for the Internet. © 2013 ACM.",adaptive probing; bayesian inference; internet reliability; network outages,adaptive probing; Background radiation; Bayesian inference; Controlled experiment; Detection system; Internet reliabilities; Network outages; Single- machines; Bayesian networks; Computer architecture; Inference engines; Internet; Network architecture; Outages; Probes; Reliability; Internet protocols
"Striegel A., Liu S., Meng L., Poellabauer C., Hachen D., Lizardo O.",6,Lessons learned from the NetSense smartphone study,2013,4,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, United States; Department of Sociology, University of Notre Dame, Notre Dame, IN, United States",University of Notre Dame,1,USA,1,7,7,"Over the past few years, smartphones have emerged as one of the most popular mechanisms for accessing content across the Internet driving considerable research to improve wireless performance. A key foundation for such research efforts is the proper understanding of user behavior. However, the gathering of live smartphone data at scale is often difficult and expensive. The focus of this paper is to explore the lessons learned from a two year study of two hundred smart phone users at the University of Notre Dame. In this paper, we offer commentary with regards to the entire process of the study covering aspects including funding considerations, technical architecture design, lessons learned, and recommendations for future efforts gathering live user data. © 2013 ACM.",cellular networks; smartphone; user study; wifi; wireless,Cellular network; Research efforts; Technical architecture; University of Notre Dame; User behaviors; User data; User study; Behavioral research; Computer architecture; Radio; Signal encoding; Smartphones; Wi-Fi; Network architecture
"Shen W.-L., Lin K.C.-J., Chen M.-S.",3,An empirical study of analog channel feedback,2013,0,"Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taiwan",National Taiwan University,1,Taiwan,1,3,3,"Exchanging the channel state information (CSI) in a multiuser WLAN is considered an extremely expensive overhead. A possible solution to reduce the overhead is to notify the analog value of the CSI, which is also known as analog channel feedback. It however only allows nodes to overhear an imperfect channel information. While some previous studies have theoretically analyzed the performance of analog channel feedback, this work aims at addressing issues of realizing it in practice and empirically demonstrating its effectiveness. Our prototype implementation using USRP-N200 shows that analog channel feedback produces a small error comparable to that of estimating CSI using reciprocity, but however can be applied to more general scenarios. © 2013 Authors.",analog channel feedback; mimo,Analog channels; Analog values; Empirical studies; Imperfect channel informations; Multi-user; Prototype implementations; Computer architecture; MIMO systems; Network architecture; Channel state information
"Liu B., Zhao B., Wei Z., Wu C., Su J., Yu W., Wang F., Sun S.",8,Qphone: A quantum security VoIP phone,2013,2,"School of Computer, National University of Defense Technology, Changsha, Hunan, China",National University of Defense Technology,1,China,1,5,4,"This work presents a novel quantum security VoIP phone, called Qphone. Qphone integrates quantum key distribution (QKD) and VoIP steganography, and achieves peer-to-peer communication with information-theoretical security (ITS) guaranteeing. Qphone consists of three parts, a real-time QKD system, RT-QKD, a steganography software, VS-Phone, and an audio encryption and authentication hardware, AE-KEY. RT-QKD explores QKD technologies, and is able establish a shared key between two peers ensuring ITS. VS-Phone utilizes VoIP steganography to protect transmission channels of sensitive information. Qphone can provide efficient and real-time security protections to meet different security demands. © 2013 Authors.",quantum communication; security; steganography; voip,Audio encryption; Peer-to-peer communications; Real-time security; security; Sensitive informations; Steganography software; Transmission channels; voip; Authentication; Communication; Computer architecture; Internet telephony; Quantum communication; Quantum cryptography; Steganography; Telephone sets; Telephone systems; Voice/data communication systems; Network architecture
"Wette P., Karl H.",2,Which flows are hiding behind my wildcard rule? Adding packet sampling to OpenFlow,2013,6,"University of Paderborn, Warburger Straße 100, 33098 Paderborn, Germany",University of Paderborn,1,Germany,1,2,2,"In OpenFlow, multiple switches share the same control plane which is centralized at what is called the OpenFlow controller. A switch only consists of a forwarding plane. Rules for forwarding individual packets (called flow entries in OpenFlow) are pushed from the controller to the switches. In a network with a high arrival rate of new flows, such as in a data center, the control traffic between the switch and controller can become very high. As a consequence, routing of new flows will be slow. One way to reduce control traffic is to use wildcarded flow entries. Wildcard flow entries can be used to create default routes in the network. However, since switches do not keep track of flows covered by a wildcard flow entry, the controller no longer has knowledge about individual flows. To find out about these individual flows we propose an extension to the current OpenFlow standard to enable packet sampling of wildcard flow entries. © 2013 Authors.",openflow,Arrival rates; Control planes; Control traffic; Forwarding planes; Keep track of; Multiple switches; Openflow; Packet sampling; Computer architecture; Network architecture; Controllers
"Rétvári G., Tapolcai J., Korösi A., Majdán A., Heszberger Z.",5,Compressing IP forwarding tables: Towards entropy bounds and beyond,2013,17,"Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary",Budapest University of Technology and Economics,1,Hungary,1,62,32,"Lately, there has been an upsurge of interest in compressed data structures, aiming to pack ever larger quantities of information into constrained memory without sacrificing the efficiency of standard operations, like random access, search, or update. The main goal of this paper is to demonstrate how data compression can benefit the networking community, by showing how to squeeze the IP Forwarding Information Base (FIB), the giant table consulted by IP routers to make forwarding decisions, into information- theoretical entropy bounds, with essentially zero cost on longest prefix match and FIB update. First, we adopt the state-of-the-art in compressed data structures, yielding a static entropy-compressed FIB representation with asymptotically optimal lookup. Then, we re-design the venerable prefix tree, used commonly for IP lookup for at least 20 years in IP routers, to also admit entropy bounds and support lookup in optimal time and update in nearly optimal time. Evaluations on a Linux kernel prototype indicate that our compressors encode a FIB comprising more than 440K prefixes to just about 100 - 400 KBytes of memory, with a threefold increase in lookup throughput and no penalty on FIB updates. © 2013 ACM.",data compression; ip forwarding table lookup; prefix tree,Asymptotically optimal; Compressed data structures; Forwarding tables; Information base; Longest prefix matches; Lookups; Networking community; Prefix trees; Computer architecture; Data compression; Data structures; Forestry; Network architecture; Optimization; Routers; Table lookup; Entropy; Data Processing; Entropy; Forestry
"Németh F., Sonkoly B., Csikor L., Gulyás A.",4,A large-scale multipath playground for experimenters and early adopters,2013,0,"HSN Lab., Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary; MTA-BME Future Internet Research Group, Hungary; MTA-BME Information Systems Research Group, Hungary",Budapest University of Technology and Economics;MTA-BME Future Internet Research Group;MTA-BME,3,Hungary,1,6,4,"Multipath TCP is an experimental transport protocol with remarkable recent past and non-negligible future potential. However the lack of available large-scale testbeds and publicly accessible multiple paths grossly prohibits the adoption of the technology. Here, we demonstrate a large-scale multipath playground deployed on PlanetLab Europe, which can be used either by experimenters and researchers to test and verify their multipath-related ideas (e.g. enhancing congestion control, fairness or even the arrangement of multiple paths) and also by early adopters to enhance their Internet connection even if single-homed. © 2013 Authors.",multipath tcp; openflow; planetlab; sdn,Internet connection; Multipath TCP; Openflow; PlanetLab; Publicly accessible; sdn; Test and verify; Transport protocols; Computer architecture; Transmission control protocol; Network architecture
"Shankaranarayanan P.N., Sivakumar A., Rao S., Tawarmalani M.",4,D-tunes: Self tuning datastores for geo-distributed interactive applications,2013,0,"Purdue University, West Lafayette, IN, United States",Purdue University,1,USA,1,9,6,"Modern internet applications have resulted in users sharing data with each other in an interactive fashion. These applications have very stringent service level agreements (SLAs) which place tight constraints on the performance of the underlying geo-distributed datastores. Deploying these systems in the cloud to meet such constraints is a challenging task, as application architects have to strike an optimal balance among different contrasting objectives such as maintaining consistency between multiple replicas, minimizing access latency and ensuring high availability. Achieving these objectives requires carefully configuring a number of low-level parameters of the datastores, such as the number of replicas, which DCs contain which data, and the underlying consistency protocol parameters. In this work, we adopt a systematic approach where we develop analytical models that capture the performance of a datastore based on application workload and build a system that can automatically configure the datastore for optimal performance. © 2013 Authors.",storage networks; wide-area replication,Consistency protocol; High availability; Interactive applications; Internet application; Optimal performance; Service level agreement (SLAs); Storage networks; wide-area replication; Computer architecture; Network architecture; Optimization; Digital storage
"Carzaniga A., Khazaei K., Papalini M., Wolf A.L.",4,Is information-centric multi-tree routing feasible?,2013,2,"University of Lugano, Lugano, Switzerland; Imperial College London, London, United Kingdom",Imperial College London;University of Lugano,2,Switzerland;UK,2,11,7,"We have argued that an information-centric network should natively support publish/subscribe event notification in addition to on-demand content delivery. We have also argued that both primitives could use the same forwarding information base and, furthermore, that both primitives can easily support addresses that are more expressive than simple hierarchical names. In this paper we present a concrete routing scheme that realizes this: ""push"" as well as ""pull"" communication; anycast as well as multicast; and descriptor-based (as opposed to name-based) addressing. The scheme is founded on multiple tree covers that can be arranged and composed hierarchically following the structure of network domains. On each tree, the scheme combines addresses so as to reduce forwarding state. We demonstrate the feasibility and scalability of the scheme through simulations on Internet-scale workloads in realistic network settings. © 2013 ACM.",content-based; content-centric; information-centric networking; named-data; publish/subscribe; routing,Content-based; content-centric; Information-centric networkings; named-data; Publish/subscribe; routing; Communication; Computer architecture; Forestry; Network architecture; Computer simulation; Communication; Forestry; Simulation
"Zhang X., Niu T., Lao F., Guo Z.",4,Topology-aware content-centric networking,2013,1,"Institute of Computer Science and Technology, Peking University, Beijing, 100871, China",Peking University,1,China,1,4,3,"Making data the first class entity, Information-Centric Networking (ICN) replaces conventional host-to-host model with content sharing model. However, the huge amount of content and the volatility of replicas cached across the Internet pose significant challenges for addressing content only by name. In this paper, we propose a topology-aware name-based routing protocol which combines the benefits of location-oriented routing and content-centric routing together. We adopt a URL-like naming scheme, which defines register locations and content identifier. Node with copies sends Register messages towards a register using location-oriented routing protocols. All en-path routers record forwarding entries in forwarding table (FIB) as the ""bread crumb"" to this content. Following the bread crumb, routers know the ""best"" topology path to the available copies. An Interest is either forwarded towards a ""known"" copy by the content identifier, or towards the register nodes where it would find the bread crumb to the ""best"" copies. Compared with the existing flooding or name resolution methods, Our design shows a good potential in terms of scalability, availability and overhead. © 2013 Authors.",distributed registration; information-centric networking; name-based routing; topology-aware fib; url-like naming,distributed registration; Information-centric networkings; name-based routing; Topology aware; url-like naming; Computer architecture; Food products; Network architecture; Routers; Routing protocols; Topology
"Wang L., Bayhan S., Kangasharju J.",3,Cooperation policies for efficient in-network caching,2013,0,"University of Helsinki, Helsinki, Finland; HIIT, Aalto University, Helsinki, Finland",Aalto University;University of Helsinki,2,Finland,1,5,5,"Caching is a key component of information-centric networking, but most of the work in the area focuses on simple en-route caching with limited cooperation between the caches. In this paper we model cache cooperation under a game theoretical framework and show how cache cooperation policy can allow the system to converge to a Pareto optimal configuration. Our work shows how cooperation impacts network caching performance and how it takes advantage of the structural properties of the underlying network. © 2013 Authors.",cooperative caching; game theory; in-network caching,Cooperative caching; En-route; Game-theoretical framework; In networks; Information-centric networkings; Network caching; Pareto-optimal configurations; Underlying networks; Game theory; Network architecture; Computer architecture
"Krishnamoorthi V., Bergström P., Carlsson N., Eager D., Mahanti A., Shahmehri N.",6,Empowering the creative user: Personalized HTTP-based adaptive streaming of multi-path nonlinear video,2013,0,"Linköping University, Linköping, Sweden; University of Saskatchewan, Saskatoon, SK, Canada; NICTA, Sydney, NSW, Australia",Linköping University;NICTA;University of Saskatchewan,3,Australia;Canada;Sweden,3,15,13,"This paper presents the design, implementation, and validation of a novel system that supports streaming and playout of personalized, multi-path, nonlinear video. In contrast to regular video, in which the file content is played sequentially, our design allows multiple nonlinear video sequences of the underlying (linear) video to be stitched together and played in any personalized order, and clients can be provided multiple path choices. The design combines the ideas of HTTP-based adaptive streaming (HAS) and multi-path nonlinear video. Personalization of the content is achieved with the use of a customized metafile, which is downloaded separately from the underlying media and the manifest file that defines the HAS structure. An extension to the user interface allows path choices to be presented to and made by the user. Novel buffer management and prefetching policies are used to ensure seamless uninterrupted playback regardless of client path choices, even under scenarios in which clients defer their choices until the last possible moment. Our solution allows creative home users to easily create their own multi-path nonlinear video, opening the door to an endless possibility of new opportunities and media forms. © 2013 ACM.",http-based adaptive streaming; multi-path video; nonlinear video; seamless playback,Adaptive streaming; Buffer management; File contents; multi-path video; Multiple-path; Non-linear videos; Personalizations; Seamless playbacks; Computer architecture; Design; Network architecture; User interfaces; HTTP
"Liu Y., Liu J., Liu T., Guan X., Sun Y.",5,Security risks evaluation toolbox for smart grid devices,2013,1,"Ministry of Education Key Lab. for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China",Xian Jiaotong University,1,China,1,5,4,"Numerous smart devices are deployed in smart grid for state measurement, decision-making and remote control. The security issues of smart devices attract more and more attention. In our work, the communication protocol, storage mechanism and authentication of smart devices are analyzed and a toolbox is developed to evaluate the security risks of smart devices. In this demo, our toolbox is applied to scan 3 smart meters/power monitor systems. A potential risk list is generated and the vulnerabilities are further verified. © 2013 Authors.",security risk evaluation; smart device; smart grid,Monitor system; Potential risks; Security issues; Security risk evaluations; Smart devices; Smart grid; State measurements; Storage mechanism; Computer architecture; Network architecture; Smart power grids
"Xia N., Song H.H., Liao Y., Iliofotou M., Nucci A., Zhang Z.-L., Kuzmanovic A.",7,Mosaic: Quantifying privacy leakage in mobile networks,2013,11,"Northwestern University, Evanston, IL, United States; Narus Inc., Sunnyvale, CA, United States; University of Minnesota, Minneapolis, MN, United States",Narus Inc.;Northwestern University;University of Minnesota,3,USA,1,31,28,"With the proliferation of online social networking (OSN) and mobile devices, preserving user privacy has become a great challenge. While prior studies have directly focused on OSN services, we call attention to the privacy leakage in mobile network data. This concern is motivated by two factors. First, the prevalence of OSN usage leaves identifiable digital footprints that can be traced back to users in the real-world. Second, the association between users and their mobile devices makes it easier to associate traffic to its owners. These pose a serious threat to user privacy as they enable an adversary to attribute significant portions of data traffic including the ones with NO identity leaks to network users' true identities. To demonstrate its feasibility, we develop the Tessellation methodology. By applying Tessellation on traffic from a cellular service provider (CSP), we show that up to 50% of the traffic can be attributed to the names of users. In addition to revealing the user identity, the reconstructed profile, dubbed as ""mosaic,"" associates personal information such as political views, browsing habits, and favorite apps to the users. We conclude by discussing approaches for preventing and mitigating the alarming leakage of sensitive user information. © 2013 ACM.",mobile network; online social network; privacy; security; user profile,Cellular services; On-line social networks; Online social networkings (OSN); Personal information; Privacy leakages; security; User information; User profile; Computer architecture; Data privacy; Mobile devices; Mobile telecommunication systems; Network architecture; Social networking (online); Wireless networks
"Dietrich D., Rizk A., Papadimitriou P.",3,AutoEmbed: Automated multi-provider virtual network embedding,2013,4,"Leibniz Universität Hannover, Hannover, Germany",Leibniz Universität Hannover,1,Germany,1,8,6,"We present AutoEmbed, a fully-automated framework for VN embedding across multiple substrate networks. To automate VN embedding, AutoEmbed deploys functions over three layers: (i) Service Providers, (ii) VN Providers, and (iii) Infrastructure Providers (InPs). AutoEmbed enables VN Providers to partition VN requests among multiple substrate networks based on resource and network topology information that is not treated as confidential by InPs. Subsequently, each VN segment is mapped by the corresponding InP onto its substrate network. AutoEmbed enables the evaluation of various aspects of multi-provider VN embedding, such as the efficiency and scalability of embedding algorithms, the impact of different levels of information disclosure on VN embedding efficiency, and the suitability of VN request specifications. © 2013 Authors.",network virtualization; performance evaluation; resource assignment,Embedding algorithms; Embedding efficiency; Information disclosure; Infrastructure providers; Network virtualization; performance evaluation; Resource assignment; Virtual network embedding; Electric network topology; Network architecture; Computer architecture
Knight S.,1,Automated configuration and measurement of emulated networks with AutoNetkit,2013,0,"University of Adelaide, Cisco Systems, Adelaide, SA, Australia",University of Adelaide,1,Australia,1,8,5,"Emulated networks enable educators, researchers, and operators to conduct realistic network scenarios on commodity hardware. However each network device must be configured, typically in a low-level syntax. This time-consuming and error-prone process limits scalability and discourages repeated experimentation. This demonstration will show a platform to automate emulated network configuration and measurement, making large-scale network experimentation accessible. © 2013 Author.",configuration management; emulation,Automated configuration; Commodity hardware; Configuration management; emulation; Error-prone process; Large-scale network; Network configuration; Network scenario; Experiments; Network architecture; Computer architecture
"Sharma S., Staessens D., Colle D., Pickavet M., Demeester P.",5,Automatic configuration of routing control platforms in OpenFlow networks,2013,2,"Department of Information Technology (INTEC), Ghent University - iMinds, Ghent, Belgium",Ghent University,1,Belgium,1,5,1,"RouteFlow provides a way to run routing control platforms (e.g. Quagga) in OpenFlow networks. One of the issues of RouteFlow is that an administrator needs to devote a lot of time (typically 7 hours for 28 switches) in manual configurations. We propose and demonstrate a framework that can automatically configure RouteFlow. For this demonstration, we use an emulated pan-European topology of 28 switches. In the demonstration, we stream a video clip from a server to a remote client, and show that the video clip reaches at the remote client within 4 minutes (including the configuration time). In addition, we show automatic configuration of RouteFlow using a GUI (Graphical User Interface). © 2013 Authors.",openflow; quagga; virtualization,Automatic configuration; GUI (graphical user interface); Openflow; Openflow networks; quagga; Remote clients; Routing control platforms; Virtualizations; Computer architecture; Graphical user interfaces; Network architecture; Time switches; Video cameras; Network routing
"Gao H., Yegneswaran V., Chen Y., Porras P., Ghosh S., Jiang J., Duan H.",7,An empirical reexamination of global DNS behavior,2013,12,"Northwestern University, Evanston, IL, United States; SRI International, Menlo Park, CA, United States; Tsinghua University, Beijing, China",Northwestern University;Tsinghua University,2,China;USA,2,46,29,"The performance and operational characteristics of the DNS protocol are of deep interest to the research and network operations community. In this paper, we present measurement results from a unique dataset containing more than 26 billion DNS query-response pairs collected from more than 600 globally distributed recursive DNS resolvers. We use this dataset to reaffirm findings in published work and notice some significant differences that could be attributed both to the evolving nature of DNS traffic and to our differing perspective. For example, we find that although characteristics of DNS traffic vary greatly across networks, the resolvers within an organization tend to exhibit similar behavior. We further find that more than 50% of DNS queries issued to root servers do not return successful answers, and that the primary cause of lookup failures at root servers is malformed queries with invalid TLDs. Furthermore, we propose a novel approach that detects malicious domain groups using temporal correlation in DNS queries. Our approach requires no comprehensive labeled training set, which can be difficult to build in practice. Instead, it uses a known malicious domain as anchor, and identifies the set of previously unknown malicious domains that are related to the anchor domain. Experimental results illustrate the viability of this approach, i.e. , we attain a true positive rate of more than 96%, and each malicious anchor domain results in a malware domain group with more than 53 previously unknown malicious domains on average. © 2013 ACM.",dns; malicious domain detection; measurement,dns; DNS traffics; Domain detections; Network operations; Operational characteristics; Temporal correlations; Training sets; True positive rates; Computer architecture; Intrusion detection; Measurements; Network architecture; Internet protocols
"Yang M., Li Y., Jin D., Su L., Ma S., Zeng L.",6,OpenRAN: A software-defined RAN architecture via virtualization,2013,50,"Department of Electronic Engineering, Tsinghua University, Beijing 100084, China; Research Institution of China Unicom, Beijing 100084, China",Research Institution of China Unicom;Tsinghua University,2,China,1,6,6,"With the rapid growth of the demands for mobile data, wireless network faces several challenges, such as lack of efficient interconnection among heterogeneous wireless networks, and shortage of customized QoS guarantees between services. The fundamental reason for these challenges is that the radio access network (RAN) is closed and ossified. We propose OpenRAN, an architecture for software-defined RAN via virtualization. It achieves complete virtualization and programmability vertically, and benefits the convergence of heterogeneous network horizontally. It provides open, controllable, flexible and evolvable wireless networks. © 2013 Authors.",radio access network; software-defined network; wireless virtualization,Heterogeneous wireless network; Programmability; QoS guarantee; Radio access networks; RAN architecture; Software-defined networks; Virtualizations; Wireless virtualization; Computer architecture; Heterogeneous networks; Quality of service; Virtual reality; Wireless networks; Network architecture
"Chen Y., Mahajan R., Sridharan B., Zhang Z.-L.",4,A provider-side view of web search response time,2013,9,"Microsoft Corporation, Redmond, WA, United States; University of Minnesota - Twin Cities, Minneapolis, MN, United States",Microsoft;University of Minnesota - Twin Cities,2,USA,1,34,22,"Using a large Web search service as a case study, we highlight the challenges that modern Web services face in understanding and diagnosing the response time experienced by users. We show that search response time (SRT) varies widely over time and also exhibits counter-intuitive behavior. It is actually higher during off-peak hours, when the query load is lower, than during peak hours. To resolve this paradox and explain SRT variations in general, we develop an analysis framework that separates systemic variations due to periodic changes in service usage and anomalous variations due to unanticipated events such as failures and denial-of-service attacks. We find that systemic SRT variations are primarily caused by systemic changes in aggregate network characteristics, nature of user queries, and browser types. For instance, one reason for higher SRTs during off-peak hours is that during those hours a greater fraction of queries come from slower, mainly-residential networks. We also develop a technique that, by factoring out the impact of such variations, robustly detects and diagnoses performance anomalies in SRT. Deployment experience shows that our technique detects three times more true (operator-verified) anomalies than existing techniques. © 2013 ACM.",anomaly detection and diagnosis; performance monitoring; search response time; web services,Analysis frameworks; Anomaly detection; Denial of service attacks; Network characteristics; Performance anomaly; Performance monitoring; Periodic changes; Service usage; Computer architecture; Information retrieval; Network architecture; Web services; Websites
"Yin J., Sun P., Wen Y., Gong H., Liu M., Li X., You H., Gao J., Lin C.",9,Cloud3DView: An interactive tool for cloud data center operations,2013,2,"Nanyang Tech. Univ., 50 Nanyang Avenue, Singapore 639798, Singapore; Univ. of Elec. Sci. and Tech. of China, Chengdu 610054, China; Center for OPTical IMagery Analysis and Learning, Xi'an 710119, China",Center for Optical Imagery Analysis and Learning (OPTIMAL);Nanyang Tech. University;University of Electronic Science and Technology of China,3,China;Singapore,2,2,2,"The emergence of cloud computing has promoted growing demand and rapid deployment of data centers. However, data center operations require a set of sophisticated skills (e.g., command-line-interface), resulting in a high operational cost. In this demo, to reduce the data center operational cost, we design and build a novel cloud data center management system, based on the concept of 3D gamification. In particular, we apply data visualization techniques to overlay operational status upon a data center 3D model, allowing the operators to monitor the real-time situation and control the data center from a friendly user interface. This demo highlights: (1)a data center 3D view from a First Person Shooter (FPS) camera, (2)a run-time presentation of visualized infrastructures information. Moreover, to improve the user experience, we employ cutting-edge HCI technologies from multi-touch, for remote access to Cloud3DView. © 2013 Authors.",data center operation; data visualization,Cloud data centers; Data center operations; Design and build; First person shooter; Interactive tool; Rapid deployments; User experience; Visualization technique; Computer architecture; Data visualization; Network architecture; Three dimensional; Three dimensional computer graphics; User interfaces; Information management
"Nandakumar R., Chintalapudi K.K., Padmanabhan V., Venkatesan R.",4,Dhwani: Secure peer-to-peer acoustic NFC,2013,29,"Microsoft Research India, Bangalore, India",Microsoft,1,India,1,21,16,"Near Field Communication (NFC) enables physically proximate devices to communicate over very short ranges in a peer-to-peer manner without incurring complex network configuration overheads. However, adoption of NFC-enabled applications has been stymied by the low levels of penetration of NFC hardware. In this paper, we address the challenge of enabling NFC-like capability on the existing base of mobile phones. To this end, we develop Dhwani, a novel, acoustics-based NFC system that uses the microphone and speakers on mobile phones, thus eliminating the need for any specialized NFC hardware. A key feature of Dhwani is the JamSecure technique, which uses self-jamming coupled with self-interference cancellation at the receiver, to provide an information-theoretically secure communication channel between the devices. Our current implementation of Dhwani achieves data rates of up to 2.4 Kbps, which is sufficient for most existing NFC applications. © 2013 ACM.",nfc; security; wireless,Key feature; Near field communications; Network configuration; nfc; Peer to peer; Secure communication channels; security; Self-interferences; Cellular telephones; Communication systems; Computer architecture; Hardware; Mobile devices; Mobile phones; Network architecture; Radio; Computer hardware
"Lychev R., Goldberg S., Schapira M.",3,BGP security in partial deployment: Is the juice worth the squeeze?,2013,12,"Georgia Tech., Atlanta, GA, United States; Boston University, Boston, MA, United States; Hebrew University, Jerusalem, Israel",Boston University;Georgia Tech;Hebrew University of Jerusalem,3,Israel;USA,2,46,37,"As the rollout of secure route origin authentication with the RPKI slowly gains traction among network operators, there is a push to standardize secure path validation for BGP (i.e., S*BGP: S-BGP, soBGP, BGPSEC, etc.). Origin authentication already does much to improve routing security. Moreover, the transition to S*BGP is expected to be long and slow, with S*BGP coexisting in ""partial deployment"" alongside BGP for a long time. We therefore use theoretical and experimental approach to study the security benefits provided by partially-deployed S*BGP, vis-a-vis those already provided by origin authentication. Because routing policies have a profound impact on routing security, we use a survey of 100 network operators to find the policies that are likely to be most popular during partial S*BGP deployment. We find that S*BGP provides only meagre benefits over origin authentication when these popular policies are used. We also study the security benefits of other routing policies, provide prescriptive guidelines for partially-deployed S*BGP, and show how interactions between S*BGP and BGP can introduce new vulnerabilities into the routing system. © 2013 ACM.",bgp; partial deployment; routing; security,bgp; Experimental approaches; Network operator; Origin authentications; Partial deployment; routing; Routing policies; security; Computer architecture; Network architecture; Authentication
"Chen Y., Crespi N., Lv L., Li M., Ortiz A.M., Shu L.",6,Locating using prior information: Wireless indoor localization algorithm,2013,0,"Institute Mines-Telecom, Evry, France; Dalian University of Technology, Liaoning, China; Guangdong University of Petrochemical Technology, Guangdong, China",Dalian University of Technology;Guangdong University of Petrochemical Technology;Institute Mines-Telecom,3,China;France,2,3,3,"Most indoor localization algorithms are based on Received Signal Strength (RSS), in which RSS signatures of an interested area are annotated with their real recorded locations. However, according to our experiments, RSS signatures are not suitable as the unique annotations (like Fingerprints) of recorded locations. In this study, we investigate the characteristics of RSS (e.g., how the RSS values change as time goes on and between consecutive positions?). On this basis, we design LuPI (Locating using Prior Information) that exploits the characteristics of RSS: with user motion, LuPI uses novel sensors integrated in smartphones to construct the RSS variation space (like radio map) of a floor plan as prior information. The deployment of LuPI is easy and rapid since little human intervention is needed. In LuPI, the calibration of ""radio map"" is crowd-sourced, automatic and scheduled. Experimental results show that LuPI achieves comparable location accuracy to previous approaches, even without the statistical information of site survey. © 2013 Authors.",floor plan; indoor localization; smart devices; wireless networks,Floorplans; Human intervention; Indoor localization; Location accuracy; Prior information; Received signal strength; Smart devices; Statistical information; Algorithms; Computer architecture; Floors; Information use; Network architecture; Telecommunication networks; Wireless networks; RSS
"Huang J., Qian F., Guo Y., Zhou Y., Xu Q., Mao Z.M., Sen S., Spatscheck O.",8,An in-depth study of LTE: Effect of network protocol and application behavior on performance,2013,62,"University of Michigan, Ann Arbor, MI, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,37,27,"With lower latency and higher bandwidth than its predecessor 3G networks, the latest cellular technology 4G LTE has been attracting many new users. However, the interactions among applications, network transport protocol, and the radio layer still remain unexplored. In this work, we conduct an in-depth study of these interactions and their impact on performance, using a combination of active and passive measurements. We observed that LTE has significantly shorter state promotion delays and lower RTTs than those of 3G networks. We discovered various inefficiencies in TCP over LTE such as undesired slow start. We further developed a novel and lightweight passive bandwidth estimation technique for LTE networks. Using this tool, we discovered that many TCP connections significantly under-utilize the available bandwidth. On average, the actually used bandwidth is less than 50% of the available bandwidth. This causes data downloads to be longer, and incur additional energy overhead. We found that the under-utilization can be caused by both application behavior and TCP parameter setting. We found that 52.6% of all downlink TCP flows have been throttled by limited TCP receive window, and that data transfer patterns for some popular applications are both energy and network unfriendly. All these findings highlight the need to develop transport protocol mechanisms and applications that are more LTE-friendly. © 2013 ACM.",4g; bandwidth estimation; lte; resource underutilization; tcp performance,4g; Bandwidth estimation; lte; resource underutilization; TCP performance; 3G mobile communication systems; Bandwidth; Computer architecture; Data transfer; Network architecture; Network protocols; Transmission control protocol; Wireless telecommunication systems
"Wang J., Katabi D.",2,"Dude, where's my card? RFID positioning that works with multipath and non-line of sight",2013,86,"Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,45,26,"RFIDs are emerging as a vital component of the Internet of Things. In 2012, billions of RFIDs have been deployed to locate equipment, track drugs, tag retail goods, etc. Current RFID systems, however, can only identify whether a tagged object is within radio range (which could be up to tens of meters), but cannot pinpoint its exact location. Past proposals for addressing this limitation rely on a line-of-sight model and hence perform poorly when faced with multipath effects or non-line-of-sight, which are typical in real-world deployments. This paper introduces the first fine-grained RFID positioning system that is robust to multipath and non-line-of-sight scenarios. Unlike past work, which considers multipath as detrimental, our design exploits multipath to accurately locate RFIDs. The intuition underlying our design is that nearby RFIDs experience a similar multipath environment (e.g., reflectors in the environment) and thus exhibit similar multipath profiles. We capture and extract these multipath profiles by using a synthetic aperture radar (SAR) created via antenna motion. We then adapt dynamic time warping (DTW) techniques to pinpoint a tag's location. We built a prototype of our design using USRP software radios. Results from a deployment of 200 commercial RFIDs in our university library demonstrate that the new design can locate misplaced books with a median accuracy of 11 cm. © 2013 ACM.",dtw; localization; RFID; sar,dtw; Dynamic time warping; Internet of Things (IOT); localization; Multi-path effect; Multi-path environments; sar; University libraries; Antennas; Computer architecture; Network architecture; Radar antennas; Radio frequency identification (RFID); Synthetic aperture radar; Design
"Bharadia D., McMilin E., Katti S.",3,Full duplex radios,2013,517,"Stanford University, Stanford, CA, United States",Stanford University,1,USA,1,21,17,"This paper presents the design and implementation of the first in-band full duplex WiFi radios that can simultaneously transmit and receive on the same channel using standard WiFi 802.11ac PHYs and achieves close to the theoretical doubling of throughput in all practical deployment scenarios. Our design uses a single antenna for simultaneous TX/RX (i.e., the same resources as a standard half duplex system). We also propose novel analog and digital cancellation techniques that cancel the self interference to the receiver noise floor, and therefore ensure that there is no degradation to the received signal. We prototype our design by building our own analog circuit boards and integrating them with a fully WiFi-PHY compatible software radio implementation. We show experimentally that our design works robustly in noisy indoor environments, and provides close to the expected theoretical doubling of throughput in practice. © 2013 ACM.",full duplex; interference cancellation; non-linear cancellation,Compatible software; Deployment scenarios; Design and implementations; Digital cancellation; Full-duplex; Indoor environment; Interference cancellation; non-linear cancellation; Antennas; Computer architecture; Network architecture; Signal receivers; Design
"Pupatwibul P., Banjar A., Braun R.",3,Using DAIM as a reactive interpreter for openflow networks to enable autonomic functionality,2013,1,"CRIN, University of Technology Sydney, Sydney, NSW, Australia",University of Technology Sydney,1,Australia,1,6,6,"OpenFlow is the first standardization of Software Defined Networks. OpenFlow approach, however, has number of limitations: it restricts its use within a single-domain, it is not scalable, and it does not adapt well to changes in local environments. We evaluate the number of approaches to solve these limitations, and propose DAIM model (Distributed Active information Model) which can be integrated into the OpenFlow structure at the level of the switches to provide a reactive interpreter that will manage the flow tables autonomically. © 2013 Authors.",autonomic functionality; distributed systems; openflow,autonomic functionality; Distributed systems; Information Modeling; Local environments; Openflow; Openflow networks; Single domains; Software-defined networks; Computer architecture; Network architecture
"Javed U., Cunha I., Choffnes D., Katz-Bassett E., Anderson T., Krishnamurthy A.",6,PoiRoot: Investigating the root cause of interdomain path changes,2013,12,"University of Washington, Seattle, WA, United States; Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Northeastern University, United States; University of Southern California, Los Angeles, CA, United States",Northeastern University;Universidade Federal de Minas Gerais;University of Southern California;University of Washington at St. Louis,4,Brazil;USA,2,44,31,"Interdomain path changes occur frequently. Because routing protocols expose insufficient information to reason about all changes, the general problem of identifying the root cause remains unsolved. In this work, we design and evaluate PoiRoot, a real-time system that allows a provider to accurately isolate the root cause (the network responsible) of path changes affecting its prefixes. First, we develop a new model describing path changes and use it to provably identify the set of all potentially responsible networks. Next, we develop a recursive algorithm that accurately isolates the root cause of any path change. We observe that the algorithm requires monitoring paths that are generally not visible using standard measurement tools. To address this limitation, we combine existing measurement tools in new ways to acquire path information required for isolating the root cause of a path change. We evaluate PoiRoot on path changes obtained through controlled Internet experiments, simulations, and 'in-the-wild' measurements. We demonstrate that PoiRoot is highly accurate, works well even with partial information, and generally narrows down the root cause to a single network or two neighboring ones. On controlled experiments PoiRoot is 100% accurate, as opposed to prior work which is accurate only 61.7% of the time. © 2013 ACM.",bgp; measurement; monitoring; path changes; root cause analysis,bgp; Controlled experiment; Internet experiments; Isolating the roots; path changes; Recursive algorithms; Root cause analysis; Standard measurements; Algorithms; Computer architecture; Experiments; Monitoring; Network architecture; Real time systems; Tools; Measurements
"Winstein K., Balakrishnan H.",2,TCP ex machina: Computer-generated congestion control,2013,37,"Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States",MIT,1,USA,1,46,21,"This paper describes a new approach to end-to-end congestion control on a multi-user network. Rather than manually formulate each endpoint's reaction to congestion signals, as in traditional protocols, we developed a program called Remy that generates congestion-control algorithms to run at the endpoints. In this approach, the protocol designer specifies their prior knowledge or assumptions about the network and an objective that the algorithm will try to achieve, e.g., high throughput and low queueing delay. Remy then produces a distributed algorithm - the control rules for the independent endpoints - that tries to achieve this objective. In simulations with ns-2, Remy-generated algorithms outperformed human-designed end-to-end techniques, including TCP Cubic, Compound, and Vegas. In many cases, Remy's algorithms also outperformed methods that require intrusive in-network changes, including XCP and Cubic-over-sfqCoDel (stochastic fair queueing with CoDel for active queue management). Remy can generate algorithms both for networks where some parameters are known tightly a priori, e.g. datacenters, and for networks where prior knowledge is less precise, such as cellular networks. We characterize the sensitivity of the resulting performance to the specificity of the prior knowledge, and the consequences when real-world conditions contradict the assumptions supplied at design-time. © 2013 ACM.",computer-designed algorithms; congestion control,Active Queue Management; Cellular network; End-to-end congestion control; High throughput; Multi-user networks; Prior knowledge; Protocol designers; Queueing delays; Algorithms; Computer architecture; Congestion control (communication); Network architecture; Queueing networks; Transmission control protocol
"Woo J., Kang A.R., Kim H.K.",3,The contagion of malicious behaviors in online games,2013,3,"Graduate School of Information Security, Korea University, 5-Ga Anam-Dong, Seongbuk-Gu, Seoul, 136-701, South Korea",Korea University,1,South Korea,1,5,4,"This article investigates whether individual users are more likely to display malicious behavior after receiving social reinforcement from friends in their online social networks. We analyze the dynamics of game bot diffusion on the basis of real data supplied by a major massively multiplayer online role-playing game company. We find that the social reinforcement, measured by the ratio of bot friends over total friends, affects the likelihood of game bot adoption and the commitment in terms of usage time. © 2013 Authors.",diffusion model; game bot; online game; social contagion,Diffusion model; Game bots; Malicious behavior; Massively multiplayer online role-playing games; On-line games; On-line social networks; social contagion; Social reinforcement; Computer architecture; Network architecture; Reinforcement; Social networking (online); Internet
"Angel S., Walfish M.",2,Verifiable auctions for online ad exchanges,2013,2,"University of Texas at Austin, Austin, TX, United States",University of Texas at Austin,1,USA,1,61,37,"This paper treats a critical component of the Web ecosystem that has so far received little attention in our community: ad exchanges. Ad exchanges run auctions to sell publishers' inventory - space on Web pages - to advertisers who want to display ads in those spaces. Unfortunately, under the status quo, the parties to an auction cannot check that the auction was carried out correctly, which raises the following more general question: how can we create verifiability in low-latency, high-frequency auctions where the parties do not know each other? We address this question with the design, prototype implementation, and experimental evaluation of VEX. VEX introduces a technique for efficient, privacy-preserving integer comparisons; couples these with careful protocol design; and adds little latency and tolerable overhead. © 2013 ACM.",ad exchanges; online advertising; verifiable auctions,Ad exchanges; Critical component; Experimental evaluation; High frequency HF; Online advertising; Privacy preserving; Prototype implementations; verifiable auctions; Computer architecture; Network architecture; Commerce
"Chen B.-S., Lin K.C.-J., Wei H.-Y.",3,Harnessing receive diversity in distributed multi-user MIMO networks,2013,1,"National Taiwan University, Taipei, Taiwan; Academia Sinica, Taipei, Taiwan",National Taiwan University,1,Taiwan,1,2,2,"In existing multiuser MIMO (MU-MIMO) MAC protocols, a multi-antenna node sends as many concurrent streams as possible once it wins the contention. Though such a scheme allows nodes to utilize the multiplex gain of a MIMO system, it however fails to leverage receive diversity gains provided by multiple receive antennas across nodes. We introduce Multiplex-Diversity Medium Access (MDMA), a MU-MIMO MAC protocol that achieves both the multiplex gain and the receive diversity gain at the same time. Instead of letting a node pair use all the available degrees of freedom, MDMA allows as many contending node pairs to communicate concurrently as possible and share all the degrees of freedom. It hence can exploit the antennas equipped on different receivers to further provide some of concurrent streams more receive diversity, without losing the achievable multiplex gain. We implement a prototype on software radios to demonstrate the throughput gain of MDMA. © 2013 Authors.",diversity gain; medium access control; multi-user mimo,Diversity gain; MAC protocol; Medium access; Multi-antenna; Multi-user MIMO; Multiple receive antennas; Node pairs; Receive diversity; Computer architecture; Degrees of freedom (mechanics); Mechanics; Medium access control; MIMO systems; Multipath propagation; Network architecture; Receiving antennas; Multiplexing
"Popa L., Yalagandula P., Banerjee S., Mogul J.C., Turner Y., Santos J.R.",6,ElasticSwitch: Practical work-conserving bandwidth guarantees for cloud computing,2013,41,"HP Labs., Palo Alto, CA, United States; Avi Networks, Sunnyvale, CA, United States; Google, Mountain View, CA, United States",Google;HP Labs,2,USA,1,27,22,"While cloud computing providers offer guaranteed allocations for resources such as CPU and memory, they do not offer any guarantees for network resources. The lack of network guarantees prevents tenants from predicting lower bounds on the performance of their applications. The research community has recognized this limitation but, unfortunately, prior solutions have significant limitations: either they are inefficient, because they are not work-conserving, or they are impractical, because they require expensive switch support or congestion-free network cores. In this paper, we propose ElasticSwitch, an efficient and practical approach for providing bandwidth guarantees. ElasticSwitch is efficient because it utilizes the spare bandwidth from unreserved capacity or underutilized reservations. ElasticSwitch is practical because it can be fully implemented in hypervisors, without requiring a specific topology or any support from switches. Because hypervisors operate mostly independently, there is no need for complex coordination between them or with a central controller. Our experiments, with a prototype implementation on a 100-server testbed, demonstrate that ElasticSwitch provides bandwidth guarantees and is work-conserving, even in challenging situations. © 2013 ACM.",bandwidth guarantees; cloud computing; work-conserving,Bandwidth guarantee; Hypervisors; Lower bounds; Network core; Network resource; Prototype implementations; Research communities; work-conserving; Cloud computing; Complex networks; Computer architecture; Coordination reactions; Network architecture; Bandwidth
"Patel P., Bansal D., Yuan L., Murthy A., Greenberg A., Maltz D.A., Kern R., Kumar H., Zikos M., Wu H., Kim C., Karri N.",12,Ananta: Cloud scale load balancing,2013,38,"Microsoft, Redmond, WA, United States",Microsoft,1,USA,1,31,10,"Layer-4 load balancing is fundamental to creating scale-out web services. We designed and implemented Ananta, a scale-out layer-4 load balancer that runs on commodity hardware and meets the performance, reliability and operational requirements of multi-tenant cloud computing environments. Ananta combines existing techniques in routing and distributed systems in a unique way and splits the components of a load balancer into a consensus-based reliable control plane and a decentralized scale-out data plane. A key component of Ananta is an agent in every host that can take over the packet modification function from the load balancer, thereby enabling the load balancer to naturally scale with the size of the data center. Due to its distributed architecture, Ananta provides direct server return (DSR) and network address translation (NAT) capabilities across layer-2 boundaries. Multiple instances of Ananta have been deployed in the Windows Azure public cloud with combined bandwidth capacity exceeding 1Tbps. It is serving traffic needs of a diverse set of tenants, including the blob, table and relational storage services. With its scale-out data plane we can easily achieve more than 100Gbps throughput for a single public IP address. In this paper, we describe the requirements of a cloud-scale load balancer, the design of Ananta and lessons learnt from its implementation and operation in the Windows Azure public cloud. © 2013 ACM.",distributed systems; server load balancing; software defined networking,Cloud computing environments; Distributed architecture; Distributed systems; Network address translations; Operational requirements; Packet modifications; Server loads; Software-defined networkings; Computer architecture; Computer supported cooperative work; Computer systems; Digital storage; Network architecture; Parallel architectures; Web services; Windows operating system
"Wang Y., Rozhnova N., Narayanan A., Oran D., Rhee I.",5,An improved hop-by-hop interest shaper for congestion control in named data networking,2013,9,"North Carolina State University, Raleigh, NC, United States; Université Pierre et Marie Curie (UPMC), Paris, France; Cisco System, Boxborough, MA, United States",North Carolina State University;University Pierre and Marie Curie,2,France;USA,2,11,10,"Hop-by-hop interest shaping has been proposed as a viable congestion control mechanism in Named Data Networking (NDN). Interest shaping exploits the strict receiver-driven traffic pattern and the symmetric bidirectional forwarding in NDN to control the returning data rate. In this paper, we point out that both interests and contents contribute to congestion and their interdependence must be considered in any interest shaping algorithm. We first analyze this issue mathematically by formulating it as an optimization problem to obtain the optimal shaping rate. Then a practical interest shaping algorithm is proposed to achieve high link utilization without congestive data loss. We further note that flow differentiation in NDN is complicated and design our scheme independently of traffic flows. We demonstrate our hop-by-hop interest shaper in conjunction with simple Additive-Increase-Multiplicative-Decrease (AIMD) clients using the ns3-based NDN simulator (ndnSIM). Our results show that the proposed shaping algorithm can effectively control congestion and achieve near-optimal throughput. © 2013 ACM.",congestion control; information-centric networking,Congestion control mechanism; Information-centric networkings; Link utilization; Named data networkings; Near-optimal; Optimization problems; Shaping algorithm; Traffic pattern; Algorithms; Computer architecture; Congestion control (communication); Network architecture; Optimization
"Chen R., Akkus I.E., Francis P.",3,SplitX: High-performance private analytics,2013,9,"Bell Labs., Alcatel-Lucent, Stuttgart, Germany; MPI-SWS, Kaiserslautern, Germany",Bell Labs,1,Germany,1,33,26,"There is a growing body of research on mechanisms for preserving online user privacy while still allowing aggregate queries over private user data. A common approach is to store user data at users' devices, and to query the data in such a way that a differentially private noisy result is produced without exposing individual user data to any system component. A particular challenge is to design a system that scales well while limiting how much the malicious users can distort the result. This paper presents SplitX, a high-performance analytics system for making differentially private queries over distributed user data. SplitX is typically two to three orders of magnitude more efficient in bandwidth, and from three to five orders of magnitude more efficient in computation than previous comparable systems, while operating under a similar trust model. SplitX accomplishes this performance by replacing public-key operations with exclusive-or operations. This paper presents the design of SplitX, analyzes its security and performance, and describes its implementation and deployment across 416 users. © 2013 ACM.",analytics; differential privacy; xor cryptography,Aggregate queries; analytics; Analytics systems; Differential privacies; Orders of magnitude; Security and performance; System components; Three orders of magnitude; Computer architecture; Network architecture; Search engines
"Dainotti A., Benson K., King A., Claffy K., Kallitsis M., Glatz E., Dimitropoulos X.",7,Estimating Internet address space usage through passive measurements,2013,23,"CAIDA, UC San Diego, San Diego, CA, United States; Merit Network, Inc., Ann Arbor, MI, United States; ETH Zurich, Zurich, Switzerland",ETH Zurich;University of California San Diego,2,Switzerland;USA,2,3,2,"One challenge in understanding the evolution of Internet infrastructure is the lack of systematic mechanisms for monitoring the extent to which allocated IP addresses are actually used. Address utilization has been monitored via actively scanning the entire IPv4 address space. We evaluate the potential to leverage passive network traffic measurements in addition to or instead of active probing. Passive traffic measurements introduce no network traffic overhead, do not rely on unfiltered responses to probing, and could potentially apply to IPv6 as well. We investigate two challenges in using passive traffic for address utilization inference: the limited visibility of a single observation point; and the presence of spoofed IP addresses in packets that can distort results by implying faked addresses are active. We propose a methodology for removing such spoofed traffic on both darknets and live networks, which yields results comparable to inferences made from active probing. Our preliminary analysis reveals a number of promising findings, including novel insight into the usage of the IPv4 address space that would expand with additional vantage points.",Darknet; Internet address space; Internet census; IPv4 address space; Network telescope; Passive measurements; Spoofed traffic,Internet; Address space; Darknet; Internet infrastructure; Network telescopes; Network traffic measurement; Passive measurements; Preliminary analysis; Traffic measurements; Internet protocols
"Jain S., Kumar A., Mandal S., Ong J., Poutievski L., Singh A., Venkata S., Wanderer J., Zhou J., Zhu M., Zolla J., Hölzle U., Stuart S., Vahdat A.",14,B4: Experience with a globally-deployed software defined WAN,2013,460,"Google, Inc., Mountain View, United States",Google,1,USA,1,40,30,"We present the design, implementation, and evaluation of B4, a private WAN connecting Google's data centers across the planet. B4 has a number of unique characteristics: i) massive bandwidth requirements deployed to a modest number of sites, ii) elastic traffic demand that seeks to maximize average bandwidth, and iii) full control over the edge servers and network, which enables rate limiting and demand measurement at the edge. These characteristics led to a Software Defined Networking architecture using OpenFlow to control relatively simple switches built from merchant silicon. B4's centralized traffic engineering service drives links to near 100% utilization, while splitting application flows among multiple paths to balance capacity against application priority/demands. We describe experience with three years of B4 production deployment, lessons learned, and areas for future work. © 2013 ACM.",centralized traffic engineering; openflow; routing; software- defined networking; wide-area networks,Bandwidth requirement; Centralized traffic; Elastic traffic; Multiple-path; Openflow; Rate limiting; routing; Software-defined networkings; Bandwidth; Computer architecture; Wide area networks; Network architecture
"Qazi Z.A., Lee J., Jin T., Bellala G., Arndt M., Noubir G.",6,Application-awareness in SDN,2013,35,"Stony Brook University, Stony Brook, NY, United States; HP Labs., Palo Alto, CA, United States; Qualcomm Research, San Diego, CA, United States; HP Networking, Sacramento, CA, United States; Northeastern University, Boston, MA, United States",HP Labs;Northeastern University;Qualcomm;Stony Brook University,4,USA,1,3,2,"We present a framework, Atlas, which incorporates application-awareness into Software-Defined Networking (SDN), which is currently capable of L2/3/4-based policy enforcement but agnostic to higher layers. Atlas enables fine-grained, accurate and scalable application classification in SDN. It employs a machine learning (ML) based traffic classification technique, a crowd-sourcing approach to obtain ground truth data and leverages SDN's data reporting mechanism and centralized control. We prototype Atlas on HP Labs wireless networks and observe 94% accuracy on average, for top 40 Android applications. © 2013 Authors.",application awareness; software-defined networking (sdn),Android applications; Application awareness; Application classifications; Centralized control; Ground truth data; Policy enforcement; Software-defined networkings; Traffic classification; Computer architecture; Network architecture; Telecommunication traffic
"Flach T., Dukkipati N., Terzis A., Raghavan B., Cardwell N., Cheng Y., Jain A., Hao S., Katz-Bassett E., Govindan R.",10,Reducing web latency: The virtue of gentle aggression,2013,32,"Department of Computer Science, University of Southern California, Los Angeles, CA, United States; Google Inc., Mountain View, CA, United States",Google;University of Southern California,2,USA,1,46,32,"To serve users quickly, Web service providers build infrastructure closer to clients and use multi-stage transport connections. Although these changes reduce client-perceived round-trip times, TCP's current mechanisms fundamentally limit latency improvements. We performed a measurement study of a large Web service provider and found that, while connections with no loss complete close to the ideal latency of one round-trip time, TCP's timeout-driven recovery causes transfers with loss to take five times longer on average. In this paper, we present the design of novel loss recovery mechanisms for TCP that judiciously use redundant transmissions to minimize timeout-driven recovery. Proactive, Reactive, and Corrective are three qualitatively-different, easily-deployable mechanisms that (1) proactively recover from losses, (2) recover from them as quickly as possible, and (3) reconstruct packets to mask loss. Crucially, the mechanisms are compatible both with middleboxes and with TCP's existing congestion control and loss recovery. Our large-scale experiments on Google's production network that serves billions of flows demonstrate a 23% decrease in the mean and 47% in 99th percentile latency over today's TCP. © 2013 ACM.",congestion control; internet measurements; packet loss; recovery; redundancy; tcp; web latency,Current mechanisms; Internet measurement; Large scale experiments; Production network; tcp; Transport connections; web latency; Web service providers; Computer architecture; Congestion control (communication); Packet loss; Recovery; Redundancy; Telecommunication networks; Transmission control protocol; Web services; Websites; Network architecture
"Chatzis N., Smaragdakis G., Feldmann A., Willinger W.",4,There is more to IXPs than meets the eye,2013,36,"T-Labs, TU Berlin, Germany; Niksun, Inc., Germany",TU Berlin,1,Germany,1,85,44,"Internet eXchange Points (IXPs) are generally considered to be the successors of the four Network Access Points (NAPs) that were mandated as part of the decommissioning of the National Science Foundation Network (NSFNET) in 1994/95 to facilitate the transition from the NSFNET to the ""public Internet"" as we know it today. While this popular view does not tell the whole story behind the early beginnings of IXPs, what is true is that since around 1994, the number of operational IXPs worldwide has grown to more than 300 (as of May 20131), with the largest IXPs handling daily traffic volumes comparable to those carried by the largest Tier-1 ISPs. However, IXPs have never really attracted much attention from the networking research community. At first glance, this lack of interest seems understandable as IXPs have apparently little to do with current ""hot"" topic areas such as data centers and cloud services or Software Defined Networking (SDN) and mobile communication. However, we argue in this article that, in fact, IXPs are all about data centers and cloud services and even SDN and mobile communication and should be of great interest to networking researchers interested in understanding the current and future Internet ecosystem. To this end, we survey the existing but largely fragmented sources of publicly available information about IXPs to describe their basic technical and operational aspects and highlight the critical differences among the various IXPs in the different regions of the world, especially in Europe and North America. More importantly, we illustrate the important role that IXPs play in today's Internet ecosystem and discuss how IXP-driven innovation in Europe is shaping and redefining the Internet marketplace, not only in Europe but increasingly so around the world.",Content delivery; Internet exchange point; Peering,Content delivery; Internet exchange points; Mobile communications; National Science Foundations; Networking researchers; Peering; Research communities; Software defined networking (SDN); Distributed database systems; Ecosystems; Web services; Internet service providers
"Traverso S., Ahmed M., Garetto M., Giaccone P., Leonardi E., Niccolini S.",6,Temporal locality in today's content caching: Why it matters & how to model it,2013,69,"Politecnico di Torino, Torino, Italy; NEC Labs Europe, Heidelberg, Germany; Università di Torino, Torino, Italy",Politecnico di Torino;Università di Torino,2,Germany;Italy,2,33,24,"The dimensioning of caching systems represents a difficult task in the design of infrastructures for content distribution in the current Internet. This paper addresses the problem of defining a realistic arrival process for the content requests generated by users, due its critical importance for both analytical and simulative evaluations of the performance of caching systems. First, with the aid of YouTube traces collected inside operational residential networks, we identify the characteristics of real traffic that need to be considered or can be safely neglected in order to accurately predict the performance of a cache. Second, we propose a new parsimonious traffic model, named the Shot Noise Model (SNM), that enables users to natively capture the dynamics of content popularity, whilst still being sufficiently simple to be employed effectively for both analytical and scalable simulative studies of caching systems. Finally, our results show that the SNM presents a much better solution to account for the temporal locality observed in real traffic compared to existing approaches.",Caching,Arrival process; Caching; Content caching; Content distribution; Content popularities; Noise modeling; Residential networks; Temporal locality; Communication
"Crowcroft J., Fidler M., Nahrstedt K., Steinmetz R.",4,Is SDN the de-constraining constraint of the future internet?,2013,5,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom; Institute of Communications Technology, Leibniz Universiẗ at Hannover, Hannover, Germany; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, United States; Multimedia Communications Lab, Technische Universiẗ at Darmstadt, Darmstadt, Germany",Leibniz Universität Hannover;TU Darmstadt;University of Cambridge;UIUC,4,Germany;UK;USA,3,8,8,"Dagstuhl hosted a three-day seminar on the Future Internet on March 25-27, 2013. At the seminar, about 40 invited researchers from academia and industry discussed the promises, approaches, and open challenges of the Future Internet. This report gives a general overview of the presentations and outcomes of discussions of the seminar.",Future internet; Network design; Openflow; Software defined networking; Testbed; Virtualization,Future internet; Network design; Openflow; Software-defined networkings; Virtualizations; Communication; Testbeds; Internet
"Braem B., Barz C., Freitag F., Blondia C., Rogge H., Navarro L., Bonicioli J., Escrich P., Kaplan A.L., Papathanasiou S., Viñas R.B., Neumann A., Tatum B., Balaguer I.V.I., Matson M.",15,A case for research with and on community networks,2013,70,"University of Antwerp - IMinds, Belgium; Fraunhofer FKIE, Belgium; Universitat Politecnica de Catalunya, Spain; AWMN, Greece; Guifi, Spain; Funkfeuer, Austria; Pangea, Spain; OPLAN, United Kingdom",Universitat Politecnica de Catalunya;University of Antwerp,2,Austria;Belgium;Greece;Spain;UK,5,23,6,"Community Networks are large scale, self-organized and de- centralized networks, built and operated by citizens for citizens. In this paper, we make a case for research on and with community networks, while explaining the relation to Community-Lab. The latter is an open, distributed infrastructure for researchers to experiment with community net- works. The goal of Community-Lab is to advance research and empower society by understanding and removing obstacles for these networks and services.",Community networks; Community-lab; Testbed,Testbeds; Centralized networks; Community networks; Community-lab; Distributed infrastructure; Communication
"Sathiaseelan A., Crowcroft J.",2,Internet on the move: Challenges and solutions,2013,16,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,22,18,"The Computer Laboratory, University of Cambridge hosted a workshop on ""Internet on the Move"" on September 22, 2012. The objective of the workshop was to bring academia, industry and regulators to discuss the challenges in realizing the notion of ubiquitous mobile Internet. The editorial summarises a general overview of the issues discussed on enabling universal mobile coverage and some of the solutions that have been proposed to alleviate the problem of having ubiquitous mobile connectivity.",Congestion; Internet; Mobile; Resource pooling,Computer laboratory; Congestion; Mobile; Mobile connectivity; Mobile coverage; Mobile Internet; Resource pooling; University of Cambridge; Communication; Internet
"Lee Y., Lee Y.",2,Toward scalable internet traffic measurement and analysis with hadoop,2013,123,"Dept. of Computer Engineering, Chungnam National University, South Korea",Chungnam National University,1,South Korea,1,24,12,"Internet traffic measurement and analysis has long been used to characterize network usage and user behaviors, but faces the problem of scalability under the explosive growth of Internet traffic and high-speed access. Scalable Internet traffic measurement and analysis is difficult because a large data set requires matching computing and storage resources. Hadoop, an open-source computing platform of MapReduce and a distributed file system, has become a popular infrastructure for massive data analytics because it facilitates scalable data processing and storage services on a distributed computing system consisting of commodity hardware. In this paper, we present a Hadoop-based traffic monitoring system that performs IP, TCP, HTTP, and NetFlow analysis of multi-terabytes of Internet traffic in a scalable manner. From experiments with a 200-node testbed, we achieved 14 Gbps throughput for 5 TB files with IP and HTTP-layer analysis MapReduce jobs. We also explain the performance issues related with traffic analysis MapReduce jobs.",Analysis; Hadoop; Hive; MapReduce; NetFlow; Packet; Pcap; Traffic measurement,Analysis; Hadoop; Hive; Map-reduce; NetFlows; Packet; Pcap; Traffic measurements; Behavioral research; Data processing; Distributed computer systems; Internet; Internet protocols; HTTP
Godfrey P.B.,1,HotNets 2012 highlights,2013,0,"University of Illinois at Urbana-Champaign, United States",UIUC,1,USA,1,2,2,This article captures some of the discussion and insights from this year's ACM Workshop on Hot Topics in Networks (HotNets-XI).,HotNets,HotNets; Communication
"Salvador P., Cominardi L., Gringoli F., Serrano P.",4,A first implementation and evaluation of the IEEE 802.11aa Group Addressed Transmission Service,2013,25,"Institute IMDEA Networks, University Carlos III de Madrid, Spain; University of Brescia, University Carlos III de Madrid, Spain",Institute IMDEA Networks;University Carlos III of Madrid;University of Brescia,3,Spain,1,9,7,"The IEEE 802.11aa Task Group has recently standardized a set of mechanisms to efficiently support video multicasting, namely, the Group Addressed Transmission Service (GATS). In this article, we report the implementation of these mechanisms over commodity hardware, which we make publicly available, and conduct a study to assess their performance under a variety of real-life scenarios. To the best of our knowledge, this is the first experimental assessment of GATS, which is performed along three axes: we report their complexity in terms of lines of code, their effectiveness when delivering video traffic, and their efficiency when utilizing wireless resources. Our results provide key insights on the resulting trade-offs when using each mechanism, and paves the way for new enhancements to deliver video over 802.11 Wireless LANs.",802.11aa; Groupcast; WLAN,Economic and social effects; 802.11 wireless LAN; 802.11aa; Commodity hardware; Experimental assessment; Groupcast; Transmission service; Video multicasting; WLAN; Multicasting
"Grunenberger Y., Smith J.M.",2,Observations from the 2012 mobile world congress in Barcelona,2013,0,"Telefonica i and D, Spain; University of Pennsylvania, United States",University of Pennsylvania,1,Spain;USA,2,4,4,"We attended the 2012 Mobile World Congress in Barcelona, Spain. This note reports on some of our observations that we believe might be relevant to the SIGCOMM community.",Mobile Applications; Mobile Telephony; Mobility; Security; Wireless Networking,"Barcelona; Barcelona , Spain; Mobile applications; Mobile telephony; Security; Wireless networking; Carrier mobility; Communication; Global system for mobile communications"
"Wang H., Xia Y., Bergman K., Ng T.S.E., Sahu S., Sripanidkulchai K.",6,Rethinking the physical layer of data center networks of the next decade: Using optics to enable efficient ∗-cast connectivity,2013,32,"Columbia University, United States; Rice University, United States; IBM T.J. Watson Research Center, United States; NECTEC Thailand, Thailand",Columbia University;IBM;Rice University,3,Thailand;USA,2,22,16,"Not only do big data applications impose heavy bandwidth demands, they also have diverse communication patterns (denoted as ∗-cast) that mix together unicast, multicast, incast, and all-to-all-cast. Effectively supporting such traffic demands remains an open problem in data center networking. We propose an unconventional approach that leverages physical layer photonic technologies to build custom communication devices for accelerating each ∗-cast pattern, and integrates such devices into an application-driven, dynamically configurable photonics accelerated data center network. We present preliminary results from a multicast case study to highlight the potential benefits of this approach. © 2013 Association for Computing Machinery. All rights reserved.",All-to-All-Cast; Data Center Networks; Hybrid Networks; Incast; Multicast; Optical Networks; Photonics; Unicast,Fiber optic networks; Multicasting; Network layers; Photonics; All to alls; Data center networks; Hybrid network; Incast; Unicast; Big data
"Beverly R., Allman M.",2,Findings and implications from data mining the IMC review process,2013,1,"Naval Postgraduate School, United States; International Computer Science Institute, United States",University of California Berkeley;Naval Postgraduate School,2,USA,1,25,20,"The computer science research paper review process is largely human and time-intensive. More worrisome, review processes are frequently questioned, and often non-transparent. This work advocates applying computer science methods and tools to the computer science review process. As an initial exploration, we data mine the submissions, bids, re- views, and decisions from a recent top-tier computer net- working conference. We empirically test several common hypotheses, including the existence of readability, citation, call-for-paper adherence, and topical bias. From our findings, we hypothesize review process methods to improve fairness, efficiency, and transparency.",Conference review; Paper review process; Review bias,Computer science research; Initial exploration; Review process; Communication; Computer science
"Rexford J., Zave P.",2,"Report of the DIMACS working group on abstractions for network services, architecture, and implementation",2013,5,"Princeton University, United States; AT and T Laboratories-Research, United States",AT and T Labs;Princeton University,2,USA,1,14,3,"A workshop on Abstractions for Network Services, Architecture, and Implementation brought together researchers interested in creating better abstractions for creating and analyzing networked services and network architectures. The workshop took place at DIMACS on May 21-23, 2012. This report summarizes the presentations and discussions that took place at the workshop, organized by areas of abstractions such as layers, domains, and graph properties.",Abstractions; Architecture; Education; Services,Abstractions; Graph properties; Network services; Networked services; Services; Working groups; Abstracting; Architecture; Education; Network architecture
"Arslan E., Yuksel M., Gunes M.H.",3,Network management game,2013,0,"SUNY at Buffalo, United States; University of Nevada, Reno, United States",University of Nevada,1,USA,1,28,10,"Management and automated configuration of large-scale networks is one of the crucial issues for Internet Service Providers (ISPs). Since wrong configurations may lead to loss of an enormous amount of customer traffic, highly experienced network administrators are typically the ones who are trusted for the management and configuration of a running ISP network. We frame the management and experimentation of a network as a ""game"" for training network administrators without having to risk the network operation. The interactive environment treats the trainee network administrators as players of a game and tests them with various network failures or dynamics.",Network Game; Network Training,Automated configuration; Interactive Environments; Large-scale network; Network administrator; Network failure; Network game; Network operations; Network training; Training network; Internet service providers; Network management; Intelligent systems
"Simoncelli D., Gringoli F., Dusi M., Niccolini S.",4,Stream-monitoring with blockmon: Convergence of network measurements and data analytics platforms?,2013,13,"University of Brescia - CNIT, Italy; NEC Laboratories Europe, Germany",NEC;University of Brescia,2,Germany;Italy,2,25,17,"Recent work in network measurements focuses on scaling the performance of monitoring platforms to 10Gb/s and beyond. Concurrently, IT community focuses on scaling the analysis of big-data over a cluster of nodes. So far, combinations of these approaches have targeted flexibility and usability over real-timeliness of results and efficient allocation of resources. In this paper we show how to meet both objectives with BlockMon, a network monitoring platform originally designed to work on a single node, which we extended to run distributed stream-data analytics tasks. We compare its performance against Storm and Apache S4, the state-ofthe-art open-source stream-processing platforms, by implementing a phone call anomaly detection system and a Twitter trending algorithm: our enhanced BlockMon has a gain in performance of over 2.5x and 23x, respectively. Given the different nature of those applications and the performance of BlockMon as single-node network monitor [1], we expect our results to hold for a broad range of applications, making distributed BlockMon a good candidate for the convergence of network-measurement and IT-analysis platforms.",Data analysis; Distributed computing; Performance analysis,Data reduction; Distributed computer systems; Open systems; Anomaly detection systems; Convergence of networks; Efficient allocations; Monitoring platform; Network Monitoring; Network monitors; Performance analysis; Stream processing; Big data
Allman M.,1,Comments on bufferbloat,2013,38,"International Computer Science Institute, United States",University of California Berkeley,1,USA,1,24,12,"While there has been much buzz in the community about the large depth of queues throughout the Internet-the so-called ""bufferbloat"" problem-there has been little empirical understanding of the scope of the phenomenon. Yet, the supposed problem is being used as input to engineering decisions about the evolution of protocols. While we know from wide scale measurements that bufferbloat can happen, we have no empirically-based understanding of how often bufferbloat does happen. In this paper we use passive measurements to assess the bufferbloat phenomena.",Bufferbloat; Delay; Queues; TCP,Bufferbloat; Delay; Engineering decisions; Passive measurements; Queues; TCP; Communication; Transmission control protocol
"Bianchi G., Detti A., Caponi A., Blefari-Melazzi N.",4,Check before storing: What is the performance price of content integrity verification in LRU caching?,2013,42,"CNIT, Univ. Roma Tor Vergata, Italy",University Roma Tor Vergata,1,Italy,1,34,26,"In some network and application scenarios, it is useful to cache content in network nodes on the y, at line rate. Resilience of in-network caches can be improved by guaranteeing that all content therein stored is valid. Digital signatures could be indeed used to verify content integrity and provenance. However, their operation may be much slower than the line rate, thus limiting caching of cryptographically verified objects to a small subset of the forwarded ones. How this affects caching performance? To answer such a question, we devise a simple analytical approach which permits to assess performance of an LRU caching strategy storing a randomly sampled subset of requests. A key feature of our model is the ability to handle traffic beyond the traditional Independent Reference Model, thus permitting us to understand how performance vary in different temporal locality conditions. Results, also verified on real world traces, show that content integrity verification does not necessarily bring about a performance penalty; rather, in some specific (but practical) conditions, performance may even improve.",Caching; Digital signatures; Information centric networks; Performance modeling,Communication; Electronic document identification systems; Analytical approach; Application scenario; Caching; Content integrity verifications; Independent reference models; Information Centric Networks; Performance Model; Performance penalties; Authentication
"Liu Y., Amin S.O., Wang L.",3,Efficient FIB caching using minimal non-overlapping prefixes,2013,23,"Dept. of Computer Science, University of Memphis, Memphis, TN, United States",University of Memphis,1,USA,1,17,10,"The size of the global Routing Information Base (RIB) has been increasing at an alarming rate. This directly leads to the rapid growth of the global Forwarding Information Base (FIB) size, which raises serious concerns for ISPs as the FIB memory in line cards is much more expensive than regular memory modules and it is very costly to increase this memory capacity frequently for all the routers in an ISP. One potential solution is to install only the most popular FIB entries into the fast memory (i.e., a FIB cache), while storing the complete FIB in slow memory. In this paper, we propose an effective FIB caching scheme that achieves a considerably higher hit ratio than previous approaches while preventing the cache-hiding problem. Our experimental results show that with only 20K prefixes in the cache (5.36% of the actual FIB size), the hit ratio of our scheme is higher than 99.95%. Our scheme can also handle cache misses, cache replacement and routing updates efficiently.",FIB caching; Routing; Scalability,Cache Miss; Cache replacement; Caching scheme; Fast memory; FIB caching; Global routing; Hit ratio; Information base; Line card; Memory capacity; Memory modules; Potential solutions; Rapid growth; Routing; Routers; Scalability; Cache memory
"Mogul J.C., Popa L.",2,What we talk about when we talk about cloud network performance,2012,48,"HP Labs, United States",HP Labs,1,USA,1,18,15,"Infrastructure-as-a-Service (""Cloud"") data-centers intrinsically depend on high-performance networks to connect servers within the data-center and to the rest of the world. Cloud providers typically offer different service levels, and associated prices, for different sizes of virtual machine, memory, and disk storage. However, while all cloud providers provide network connectivity to tenant VMs, they seldom make any promises about network performance, and so cloud tenants suffer from highly-variable, unpredictable network performance. Many cloud customers do want to be able to rely on network performance guarantees, and many cloud providers would like to offer (and charge for) these guarantees. But nobody really agrees on how to define these guarantees, and it turns out to be challenging to define ""network performance"" in a way that is useful to both customers and providers. We attempt to bring some clarity to this question.",Cloud networks; Performance guarantees,Cloud providers; Data centers; Different services; Different sizes; High performance networks; Network connectivity; Performance guarantees; Virtual machines; Communication; Network performance
"Zseby T., Claffy K.",2,Workshop report: Darkspace and unsolicited traffic analysis (DUST 2012),2012,2,"Fraunhofer FOKUS, CAIDA, Germany; CAIDA, United States",University of California San Diego,1,Germany;USA,2,10,8,"On May 14-15, 2012, CAIDA hosted the first international Workshop on Darkspace and UnSolicited Traffic Analysis (DUST 2012) to provide a forum for discussion of the science, engineering, and policy challenges associated with darkspace and unsolicited traffic analysis. This report captures threads discussed at the workshop and lists resulting collaborations.",Data sharing; Internet measurement techniques; IP darkspace; Passivemeasurement; Traffic analysis,Data Sharing; Internet measurement; IP darkspace; Passivemeasurement; Traffic analysis; Communication; Dust
"Wei X., Valler N., Prakash B.A., Neamtiu I., Faloutsos M., Faloutsos C.",6,Competing memes propagation on networks: A case study of composite networks,2012,21,"Computer Science Department, University of California, Riverside, United States; Computer Science Department, Virginia Tech., United States; Computer Science Department, Carnegie Mellon University, United States",Carnegie Mellon University;University of California Riverside;Virginia Tech,3,USA,1,21,13,"If a false rumor propagates via Twitter, while the truth propagates between friends in Facebook, which one will prevail? This question captures the essence of the problem we ad- dress here. We study the intertwined propagation of two competing \memes"" (or viruses, rumors, products etc.) in a composite network. A key novelty is the use of a composite network, which in its simplest model is defined as a single set of nodes with two distinct types of edges interconnecting them. Each meme spreads across the composite network in accordance to an SIS-like propagation model (a u-like infection-recovery). To study the epidemic behavior of our system, we formulate it as a non-linear dynamic system (NLDS). We develop a metric for each meme that is based on the eigenvalue of an appropriately constructed matrix and argue that this metric plays a key role in determining the \winning"" meme. First, we prove that our metric determines the tipping point at which both memes become extinct eventually. Second, we conjecture that the meme with the strongest metric will most likely prevail over the other, and we show evidence of that via simulations in both real and synthetic composite networks. Our work is among the first to study the interplay between two competing memes in composite networks.",Competition; Composite networks; Propagation,Constructed matrices; Eigen-value; Facebook; Non-linear dynamic systems; Propagation models; Synthetic composites; Tipping point; Competition; Computer simulation; Eigenvalues and eigenfunctions; Linear control systems; Social networking (online); Viruses; Wave propagation; Computer viruses
"Zander S., Andrew L.L.H., Armitage G., Huston G., Michaelson G.",5,Investigating the IPv6 teredo tunnelling capability and performance of internet clients,2012,8,"CAIA, Swinburne University of Technology, Melbourne, Australia; Asia Pacific Network Information Centre (APNIC), Brisbane, Australia",Asia Pacific Network Information Centre (APNIC);Swinburne University of Technology,2,Australia,1,21,12,"The Teredo auto-tunnelling protocol allows IPv6 hosts behind IPv4 NATs to communicate with other IPv6 hosts. It is enabled by default on Windows Vista and Windows 7. But Windows clients are self-constrained: if their only IPv6 access is Teredo, they are unable to resolve host names to IPv6 addresses. We use web-based measurements to investigate the (latent) Teredo capability of Internet clients, and the delay introduced by Teredo. We compare this with native IPv6 and 6to4 tunnelling capability and delay. We find that only 6-7% of connections are from fully IPv6-capable clients, but an additional 15-16% of connections are from clients that would be IPv6-capable if Windows Teredo was not constrained. However, Teredo increases the median latency to fetch objects by 1-1.5 seconds compared to IPv4 or native IPv6, even with an optimally located Teredo relay. Furthermore, in many cases Teredo fails to establish a tunnel.",IPv6; Teredo,IPv6; Teredo; Windows Vista; Internet; Internet protocols
"Tilak S., Papadopoulos P.",2,The case for a rigorous approach to automating software operations and management of large-scale sensor networks,2012,1,"Calit2, UCSD, United States; SDSC, UCSD, United States",University of California San Diego,1,USA,1,13,6,"Software Operations and Management (O&M) i.e., installing, configuring, and updating thousands of software components within a conventional Data Center is a well-understood issue. Existing frameworks such as the Rocks toolkit [8] have revolutionized the way system administrators deploy and manage large-scale compute clusters, storage servers, and visualization facilities. However, existing tools like Rocks are designed for a friendly Data Center environment where stable power along with high-performance compute, storage, and networking is the norm. In contrast, sensor networks are embedded deeply within the harsh physical environment where node failures, node mobility and idiosyncrasies of wireless networks are the norm. In addition, device heterogeneity and resource-constrained nature (e.g., power, memory, CPU capability) of the sensor cyberinfrastructure (CI) are realities that must be addressed and reconciled. Although sensor CI must be more adaptable and more-rapidly reconfigurable than the data center equivalents, few if any of the existing software O&M tools and techniques have been adapted to the significantly more challenging environment of sensor networks. A more automated approach to software O&M would provide significant benefits to system builders, operators, and sensor network researchers. We argue that by starting with software O&M techniques developed for data centers, and then adapting and extending them to the world of resource-constrained sensor networks, we will be able to provide robust and scientifically reproducible mechanisms for defining the software footprint of individual sensors and networks of sensors. This paper describes the current golden-image based software O&M practice in Android world. We then propose an approach that adapts the Rocks toolkit to allow one to rapidly and reliably build complete Android environments (firmware ashes) at the individual sensor level and extend to a large networks of diverse sensors.",Android; Sensor networks; Smartphone; Software operations and management,Android; Automated approach; Cyberinfrastructure; Data centers; Large networks; Large scale sensor network; Node failure; Node mobility; Physical environments; Resource-constrained; Rigorous approach; Sensor level; Software component; Storage servers; System administrators; System builders; Tools and techniques; Digital storage; Firmware; Robots; Sensor networks; Sensor nodes
"Poese I., Frank B., Smaragdakis G., Uhlig S., Feldmann A., Maggs B.",6,Enabling content-aware traffic engineering,2012,40,"T-Labs, TU Berlin, Germany; Queen Mary, U. London, United Kingdom; Duke, Akamai, United States",Queen Mary University of London;TU Berlin,2,Germany;UK;USA,3,31,25,"Today, a large fraction of Internet traffic is originated by Content Delivery Networks (CDNs). To cope with increasing demand for content, CDNs have deployed massively distributed infrastructures. These deployments pose challenges for CDNs as they have to dynamically map end-users to appropriate servers without being fully aware of the network conditions within an Internet Service Provider (ISP) or the end-user location. On the other hand, ISPs struggle to cope with rapid traffic shifts caused by the dynamic server selection policies of the CDNs. The challenges that CDNs and ISPs face separately can be turned into an opportunity for collaboration. We argue that it is sufficient for CDNs and ISPs to coordinate only in server selection, not routing, in order to perform traffic engineering. To this end, we propose Content-aware Traffic Engineering (CaTE), which dynamically adapts server selection for content hosted by CDNs using ISP recommendations on small time scales. CaTE relies on the observation that by selecting an appropriate server among those available to deliver the content, the path of the traffic in the network can be influenced in a desired way. We present the design and implementation of a prototype to realize CaTE, and show how CDNs and ISPs can jointly take advantage of the already deployed distributed hosting infrastructures and path diversity, as well as the ISP detailed view of the network status without revealing sensitive operational information. By relying on tier-1 ISP traces, we show that CaTE allows CDNs to enhance the end-user experience while enabling an ISP to achieve several traffic engineering goals.",Content distribution; Network optimization; Traffic engineering,Content delivery network; Content distribution; Content-aware; Distributed infrastructure; End users; End-user experience; Internet traffic; Network condition; Network optimization; Network status; Path diversity; Server selection; Server selection policies; Time-scales; Traffic Engineering; Communication; Internet service providers
"Papadimitriou D., Fàbrega L., Vilà P., Careglio D., Demeester P.",5,"Measurement-based research: Methodology, experiments, and tools",2012,0,"Alcatel-Lucent Bell Labs, Antwerp, Belgium; Universitat de Girona, Girona, Spain; Universitat Politècnica de Catalunya, Barcelona, Spain; Ghent University, Gent, Belgium",Bell Labs;Ghent University;Universitat Politecnica de Catalunya;Universitat de Girona,4,Belgium;Spain,2,14,2,"In this paper, we report the results of the workshop organized by the FP7 EULER project on measurement-based research and associated methodology, experiments and tools. This workshop aimed at gathering all Future Internet Research and Experimentation (FIRE) experimental research projects under this thematic. Participants were invited to present the usage of measurement techniques in their experiments, their developments on measurement tools, and their foreseeable needs with respect to new domains of research not currently addressed by existing measurement techniques and tools.",Experimental research; Measurement; Methodology; Tools,Experimental research; Future internet; Measurement techniques; Measurement tools; Measurement-based; Methodology; Measurements; Tools; Experiments
"Whiteaker J., Schneider F., Teixeira R., Diot C., Soule A., Picconi F., May M.",7,Expanding home services with advanced gateways,2012,12,"Technicolor, United Kingdom; NEC Laboratories Europe, United States; CNRS, UPMC Sorbonne Universités, France",NEC;UPMC Sorbonne Universités,2,France;UK;USA,3,14,14,"The success of over-the-top (OTT) services reflects users' demand for personalization of digital services at home. ISPs propose fulfilling this demand with a cloud delivery model, which would simplify the management of the service port- folio and bring them additional revenue streams. We argue that this approach has many limitations that can be fixed by turning the home gateway into a flexible execution platform. We define requirements for such a ""service-hosting gateway"" and build a proof of concept prototype using a virtualized Intel Groveland system-on-a-chip platform. We discuss remaining challenges such as service distribution, security and privacy, management, and home integration.",Cloud; Gateway; Sevice; Virtualization,Digital services; Home gateway; Home services; Personalizations; Proof of concept; Revenue streams; Security and privacy; Service distribution; Sevice; System-on-a-chip; Virtualizations; Application specific integrated circuits; Clouds; Fixed platforms; Gateways (computer networks); Microprocessor chips; Internet service providers
"Lauinger T., Laoutaris N., Rodriguez P., Strufe T., Biersack E., Kirda E.",6,Privacy risks in named data networking: What is the cost of performance?,2012,37,"Northeastern University, Boston, United States; Telefónica Research, Barcelona, Spain; Technische Universität, Darmstadt, Germany; Eurécom, Sophia-Antipolis, France",Northeastern University;TU Berlin;Telefonica Research,3,France;Germany;Spain;USA,4,10,10,"Named Data Networking architectures have been proposed to improve various shortcomings of the current Internet architecture. A key part of these proposals is the capability of caching arbitrary content in arbitrary network locations. While caching has the potential to improve network performance, the data stored in caches can be seen as transient traces of past communication that attackers can exploit to compromise the users' privacy. With this editorial note, we aim to raise awareness of privacy attacks as an intrinsic and relevant issue in Named Data Networking architectures. Countermeasures against privacy attacks are subject to a trade-off between performance and privacy. We discuss several approaches to countermeasures representing different incarnations of this tradeoff, along with open issues to be looked at by the research community.",Attacks; Caching; Named data networking; Next-generation internet architecture; Privacy,Arbitrary networks; Attacks; Caching; Data networking; Internet architecture; Key parts; Privacy Attacks; Privacy risks; Research communities; Internet; Network architecture; Network performance; Data privacy
"Zec M., Rizzo L., Mikuc M.",3,DXR: Towards a billion routing lookups per second in software,2012,28,"Faculty of Electrical Engineering and Computing, University of Zagreb, Croatia; Università di Pisa, Italy",University of Zagreb;Università di Pisa,2,Croatia;Italy,2,20,8,"Can a software routing implementation compete in a field generally reserved for specialized lookup hardware? This paper presents DXR, an IPv4 lookup scheme based on transforming large routing tables into compact lookup structures which easily fit into cache hierarchies of modern CPUs. DXR supports various memory/speed tradeoffs and scales almost linearly with the number of CPU cores. The smallest configuration, D16R, distills a real-world BGP snapshot with 417,000 IPv4 prefixes and 213 distinct next hops into a structure consuming only 782 Kbytes, less than 2 bytes per prefix, and achieves 490 million lookups per second (MLps) in synthetic tests using uniformly random IPv4 keys on a commodity 8-core CPU. Some other DXR configurations exceed 700 MLps at the cost of increased memory footprint. DXR significantly outperforms a software implementation of DIR-24-8-BASIC, has better scalability, and requires less DRAM bandwidth. Our prototype works inside the FreeBSD kernel, which permits DXR to be used with standard APIs and routing daemons such as Quagga and XORP, and to be validated by comparing lookup results against the BSD radix tree.",Packet lookup and classification; Software routers,Cache hierarchies; CPU cores; FreeBSD; Lookup structures; Lookups; Memory footprint; Next-hop; Routing lookup; Routing table; Software implementation; Software routers; Software routing; Synthetic tests; Dynamic random access storage; Program processors; Routers; Internet protocols
"Sofia R., Mendes P., Damásio M.J., Henriques S., Giglietto F., Giambitto E., Bogliolo A.",7,Moving towards a socially-driven internet architectural design,2012,6,"SITI, University Lusófona, Lusófona, Portugal; CICANT, University Lusófona, Lusófona, Portugal; Department of Communication Studies, University of Urbino, Urbino, Italy; STI-DiSBeF, University of Urbino, Urbino, Italy",University Lusófona;University of Urbino,2,Italy;Portugal,2,31,20,"This paper provides an interdisciplinary perspective concerning the role of prosumers on future Internet design based on the current trend of Internet user empowerment. The paper debates the prosumer role, and addresses models to develop a symmetric Internet architecture and supply-chain based on the integration of social capital aspects. It has as goal to ignite the discussion concerning a socially-driven Internet architectural design.",Future Internet foundations; Internet architectural design; Knowledge; Prosumer; Social capital; Supply-chain,Future internet; Internet architecture; Internet users; Knowledge; Prosumer; Social capitals; Architectural design; Internet
Trossen D.,1,"Turing, the internet and a theory for architecture: A (fictional) tale in three parts",2012,1,"Computer Laboratory, Cambridge University, Cambridge, United Kingdom",University of Cambridge,1,UK,1,29,20,"The late noughties have seen an influx of work in different scientific disciplines, all addressing the question of 'design' and 'architecture'. It is a battle between those advocating the theory of 'emergent properties' and others who strive for a 'theory for architecture'. We provide a particular insight into this battle, represented in the form of a story that focuses on the role of a possibly unusual protagonist and his influence on computer science, the Internet, architecture and beyond. We show his relation to one of the great achievements of system engineering, the Internet, and the possible future as it might unfold. Note from the writer: The tale is placed in a mixture of reality and fiction, while postulating a certain likelihood for this fiction. There is no proof for the assertions made in this tale, leaving the space for a sequel to be told.",Architecture; Constraints; Turing,Constraints; Emergent property; Possible futures; Scientific discipline; Turing; Architecture; Communication; Internet
Claffy K.,1,Border gateway protocol (BGP) and traceroute data workshop report,2012,7,"CAIDA, UCSD, United States",University of California San Diego,1,USA,1,27,25,"On Monday, 22 August 2011, CAIDA hosted a one-day workshop to discuss scalable measurement and analysis of BGP and traceroute topology data, and practical applica- tions of such data analysis including tracking of macroscopic censorship and filtering activities on the Internet. Discus- sion topics included: the surprisingly stability in the number of BGP updates over time; techniques for improving mea- surement and analysis of inter-domain routing policies; an update on Colorado State's BGPMon instrumentation; us- ing BGP data to improve the interpretation of traceroute data, both for real-time diagnostics (e.g., AS traceroute) and for large-scale topology mapping; using both BGP and traceroute data to support detection and mapping infras- tructure integrity, including different types of of filtering and censorship; and use of BGP data to analyze existing and proposed approaches to securing the interdomain routing system. This report briefly summarizes the presentations and discussions that followed.",Censorship; Data analy- sis; Filtering; Internet measurement techniques; Routing; Topology; Validation,Censorship; Data analy- sis; Internet measurement; Routing; Validation; Filtration; Topology; Gateways (computer networks)
Claffy K.,1,The 4th workshop on active internet measurements (AIMS-4) report,2012,1,"CAIDA, UCSD, United States",University of California San Diego,1,USA,1,3,3,"On February 8-10, 2012, CAIDA hosted the fourth Work- shop on Active Internet Measurements (AIMS-4) as part of our series of Internet Statistics and Metrics Analysis (ISMA) workshops. As with the previous three AIMS workshops, the goals were to further our understanding of the potential and limitations of active measurement research and infrastruc- ture in the wide-area Internet, and to promote cooperative solutions and coordinated strategies to address future data needs of the network and security operations and research communities. This year we continued to focus on how mea- surement can illuminate two specific public policy concerns: IPv6 deployment and broadband performance. This report briefly describes topics discussed at this year's workshop. Slides and other materials related to the workshop are avail- able at [1].",Active measurement; Internet measurement techniques; Valida- tion,Active measurement; Broadband performance; Internet measurement; Research communities; Security operations; Valida- tion; Wide-area Internet; Communication; Internet
Crowcroft J.,1,Differential piracy,2012,0,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,6,0,"In all seriousness, Differential Privacy is a new technique and set of tools for managing responses to statistical queries over secured data, in such a way that the user cannot reconstruct more precise identification of principles in the dataset beyond a formally well-specified bound. This means that personally sensitive data such as Internet packet traces or social network measurements can be shared between researchers without invading personal privacy, and that assurances can be made with accuracy. With less seriousness, I would like to talk about Differential Piracy, but not without purpose. For sure, while there are legitimate reasons for upstanding citizens to live without fear of eternal surveillance, there is also a segment of society that gets away with things they shouldn't, under a cloak. Perhaps that is the (modest) price we have to pay for a modicum less paranoia in this brave new world. So, there has been a lot of work recently on Piracy Preserving Queries and Differential Piracy. These two related technologies exploit new ideas in statistical security. Rather than security through obscurity, the idea is to offer privacy through lack of differentiation (no, not inability to perform basic calculus, more the inability to distinguish between large numbers of very similar things).",Communications Systems Research; Privacy; The Internet,Communications systems; Data sets; Differential privacies; Internet packets; Personal privacy; Sensitive datas; Social Networks; Statistical queries; Crime; Data privacy; Internet; Network security; Social networking (online); Differentiation (calculus)
"Himura Y., Yasuda Y.",2,Discovering configuration templates of virtualized tenant networks in multi-tenancy datacenters via graph-mining,2012,3,"Hitachi Yokohama Research Laboratory, Hitachi, Japan",Hitachi Yokohama Research Laboratory,1,Japan,1,20,16,"Multi-tenant datacenter networking, with which multiple customer (tenant) networks are virtualized over a single shared physical infrastructure, is cost-effective but poses sig- nificant costs on manual configuration. Such tasks would be alleviated with configuration templates, whereas a crucial difficulty stems from creating appropriate (i.e., reusable) ones. In this work, we propose a graph-based method of mining configurations of existing tenants to extract their re- current patterns that would be used as reusable templates for upcoming tenants. The effectiveness of the proposed method is demonstrated with actual configuration files ob- tained from a business datacenter network.",Configuration analysis; Datacenter network; Graph-mining; Multi-tenancy; Network configuration; Template,Configuration analysis; Graph-mining; Multi-tenancy; Network configuration; Template; Communication
"Lam V.T., Radhakrishnan S., Vahdat A., Varghese G., Pan R.",5,NetShare and stochastic netshare: Predictable bandwidth allocation for data centers,2012,35,"University of California, San Diego, United States; Cisco Systems, San Diego, United States",University of California San Diego,1,USA,1,16,4,"Application performance in cloud data centers often depends crucially on network bandwidth, not just the aggregate data transmitted as in typical SLAs. We describe a mechanism for data center networks called NetShare that requires no hardware changes to routers but allows bandwidth to be allocated predictably across services based on weights. The weights are either specified by a manager, or automatically assigned at each switch port based on a virtual machine heuristic for isolation. Bandwidth unused by a service is shared proportionately by other services, providing weighted hierarchical max-min fair sharing. On a testbed of Fulcrum switches, we demonstrate that NetShare provides bandwidth isolation in various settings, including multipath networks.",Bandwidth virtualization; Data center networks,Application performance; Cloud data; Data centers; Fair sharing; Max-min; Network bandwidth; Switch ports; Virtual machines; Virtualizations; Managers; Bandwidth
"Yi C., Afanasyev A., Wang L., Zhang B., Zhang L.",5,Adaptive forwarding in named data networking,2012,167,"University of Arizona, AZ, United States; UCLA, United States; University of Memphis, Memphis, United States",University of Arizona;University of Memphis,2,USA,1,9,7,"In Named Data Networking (NDN) architecture, packets carry data names rather than source or destination addresses. This change of paradigm leads to a new data plane: data consumers send out Interest packets, routers forward them and maintain the state of pending Interests, which is used to guide Data packets back to the consumers. NDN routers' forwarding process is able to detect network problems by observing the two-way traffic of Interest and Data packets, and explore multiple alternative paths without loops. This is in sharp contrast to today's IP forwarding process which follows a single path chosen by the routing process, with no adaptability of its own. In this paper we outline the design of NDN's adaptive forwarding, articulate its potential benefits, and identify open research issues.",Adaptive forwarding; Data plane; NDN,Adaptive forwarding; Alternative path; Data networking; Data packet; Data planes; NDN; Network problems; Potential benefits; Research issues; Routing process; Sharp contrast; Single path; Communication; Routers
Arlitt M.,1,The top ten similarities between playing hockey and building a better internet,2012,1,"HP Labs, Palo Alto, CA, United States; University of Calgary, Calgary, AB, Canada",HP Labs;University of Calgary,2,Canada;USA,2,1,1,"Time tends to pass more quickly than we would like. Sometimes it is helpful to reflect on what you have accomplished, and to derive what you have learned from the experiences. These ""lessons learned"" may then be leveraged by yourself or others in the future. Occasionally, an external event will motivate this self reflection. For me, it was the 50th anniversary reunion of the St. Walburg Eagles, held in July 2011. The Eagles are a full-contact (ice) hockey team I played with between 1988 and 19961, while attending university. What would I tell my friends and former teammates that I had been doing for the past 15+ years? After some thought, I realized that my time as an Eagle had prepared me for a research career, in ways I would never have imagined. This article2 shares some of these similarities, to motivate others to reflect on their own careers and achievements, and perhaps make proactive changes as a result.",Fun; Hockey; Internet; Similarities; St. Walburg Eagles,Fun; Hockey; Self reflection; Similarities; St. Walburg Eagles; Internet; SportS
"Shue C.A., Kalafut A.J., Allman M., Taylor C.R.",4,On building inexpensive network capabilities,2012,13,"Worcester Polytechnic Institute, United States; Grand Valley State University, United States; International Computer Science Institute, United States; Oak Ridge National Laboratory, United States",Grand Valley State University;University of California Berkeley;Worcester Polytechnic Institute,3,USA,1,25,22,"There are many deployed approaches for blocking unwanted traffic, either once it reaches the recipient's network, or closer to its point of origin. One of these schemes is based on the notion of traffic carrying capabilities that grant access to a network and/or end host. However, leveraging capabilities results in added complexity and additional steps in the communication process: Before communication starts a remote host must be vetted and given a capability to use in the subsequent communication. In this paper, we propose a lightweight mechanism that turns the answers provided by DNS name resolution-which Internet communication broadly depends on anyway-into capabilities. While not achieving an ideal capability system, we show the mechanism can be built from commodity technology and is therefore a pragmatic way to gain some of the key benefits of capabilities without requiring new infrastructure.",Capabilities; DNS; NAT,Capabilities; Carrying capability; Communication process; DNS; Internet communication; NAT; Network capability; Remote host; Unwanted traffic; Internet protocols; Communication
"Donnet B., Luckie M., Mérindol P., Pansiot J.-J.",4,Revealing MPLS tunnels obscured from traceroute,2012,25,"Université de Liège, Belgium; CAIDA / UC San Diego, United States; Université de Strasbourg, France",University of California San Diego;University of Liege;Universite of Strasbourg,3,Belgium;France;USA,3,16,11,"Operators have deployed Multiprotocol Label Switching (MPLS) in the Internet for over a decade. However, its im- pact on Internet topology measurements is not well known, and it is possible for some MPLS configurations to lead to false router-level links in maps derived from traceroute data. In this paper, we introduce a measurement-based classifica- tion of MPLS tunnels, identifying tunnels where IP hops are revealed but not explicitly tagged as label switching routers, as well as tunnels that obscure the underlying path. Us- ing a large-scale dataset we collected, we show that paths frequently cross MPLS tunnels in today's Internet: in our data, at least 30% of the paths we tested traverse an MPLS tunnel. We also propose and evaluate several methods to reveal MPLS tunnels that are not explicitly flagged as such: we discover that their fraction is significant (up to half the explicit tunnel quantity) but most of them do not obscure IP-level topology discovery.",MPLS; Taxonomy; Topology; Traceroute,Data sets; Internet topology measurement; Label switching routers; Measurement-based; MPLS; Multi protocol label switching; Topology discovery; Traceroute; Internet; Taxonomies; Topology; Internet protocols
Zave P.,1,Using lightweight modeling to understand chord,2012,40,"AT and T Laboratories-Research, Florham Park, NJ, United States",AT and T Labs,1,USA,1,15,12,"Correctness of the Chord ring-maintenance protocol would mean that the protocol can eventually repair all disruptions in the ring structure, given ample time and no further dis- ruptions while it is working. In other words, it is ""eventual reachability."" Under the same assumptions about failure behavior as made in the Chord papers, no published version of Chord is correct. This result is based on modeling the protocol in Alloy and analyzing it with the Alloy Analyzer. By combining the right selection of pseudocode and tex- tual hints from several papers, and fixing aws revealed by analysis, it is possible to get a version that may be correct. The paper also discusses the significance of these results, de- scribes briey how Alloy is used to model and reason about Chord, and compares Alloy analysis to model-checking.",Alloy; Distributed hash table (DHT); Spin,Alloy analyzers; Distributed hash tables; Failure behaviors; Pseudo-code; Reachability; Ring structures; Spin; Alloys; Model checking; Repair; Cerium alloys
"Alcock S., Lorier P., Nelson R.",3,Libtrace: A packet capture and analysis library,2012,22,"University of Waikato, Hamilton, New Zealand",University of Waikato,1,New Zealand,1,11,3,"This paper introduces libtrace, an open-source software li- brary for reading and writing network packet traces. Lib- trace offers performance and usability enhancements com- pared to other libraries that are currently used. We de- scribe the main features of libtrace and demonstrate how the libtrace programming API enables users to easily develop portable trace analysis tools without needing to consider the details of the capture format, file compression or inter- mediate protocol headers. We compare the performance of libtrace against other trace processing libraries to show that libtrace offers the best compromise between development ef- fort and program run time. As a result, we conclude that libtrace is a valuable contribution to the passive measure- ment community that will aid the development of better and more reliable trace analysis and network monitoring tools.",Packet Capture; Protocol De-coding; Trace Analysis,File compression; Network monitoring tools; Network packet traces; Open-source softwares; Packet capture; Protocol headers; Runtimes; Application programming interfaces (API); Libraries; Trace analysis
"Yu Y., Wessels D., Larson M., Zhang L.",4,Authority server selection of DNS caching resolvers,2012,23,"UCLA, United States; Verisign, United States",University of California Los Angeles,1,USA,1,19,6,"Operators of high-profile DNS zones utilize multiple author- ity servers for performance and robustness. We conducted a series of trace-driven measurements to understand how current caching resolver implementations distribute queries among a set of authority servers. Our results reveal areas for improvement in the \apparently sound"" server selection schemes used by some popular implementations. In some cases, the selection schemes lead to sub-optimal behavior of caching resolvers, e.g. sending a significant amount of queries to unresponsive servers. We believe that most of these issues are caused by careless implementations, such as keeping decreasing a server's SRTT after the server has been selected, treating unresponsive servers as responsive ones, and using constant SRTT decaying factor. For the problems identified in this work, we recommended corre- sponding solutions.",DNS; Server Selection,DNS; Multiple authors; Selection scheme; Server selection; Communication; Internet protocols
"Keller E., Schapira M., Rexford J.",3,Rehoming edge links for better traffic engineering,2012,3,"University of Pennsylvania, United States; Hebrew University of Jerusalem, Israel; Princeton University, United States",Hebrew University of Jerusalem;Princeton University;University of Pennsylvania,3,Israel;USA,2,17,12,"Traditional traffic engineering adapts the routing of traffic within the network to maximize performance. We propose a new approach that also adaptively changes where traffic enters and leaves the network-changing the ""traffic matrix"", and not just the intradomain routing configuration. Our approach does not affect traffic patterns and BGP routes seen in neighboring networks, unlike conventional inter-domain traffic engineering where changes in BGP policies shift traffic and routes from one edge link to another. Instead, we capitalize on recent innovations in edge-link migration that enable seamless rehoming of an edge link to a different internal router in an ISP backbone network-completely transparent to the router in the neighboring domain. We present an optimization framework for traffic engineering with migration and develop algorithms that determine which edge links should migrate, where they should go, and how often they should move. Our experiments with Internet2 traffic and topology data show that edge-link migration allows the network to carry 18.8% more traffic (at the same level of performance) over optimizing routing alone.",Architecture; Internet; Migration; Routing; Traffic engineering,Inter-domain traffic; Internet2; Intra-domain routing; Migration; Optimization framework; Routing; Traffic Engineering; Traffic matrices; Traffic pattern; Architecture; Internet; Internet service providers; Optimization; Telecommunication traffic; Network routing
"Zúquete A., Frade C.",2,A new location layer for the TCP/IP protocol stack,2012,2,"DETI, IEETA / IT, University of Aveiro, Portugal; IT, Portugal",University of Aveiro,1,Portugal,1,32,18,"The IPv4 address space is quickly getting exhausted, putting a tremendous pressure on the adoption of even more NAT levels or IPv6. On the other hand, many authors propose the adoption of new Internet addressing capabilities, namely content-based addressing, to complement the existing IP host-based addressing. In this paper we propose the intro- duction of a location layer, between transport and network layers, to address both problems. We keep the existing IPv4 (or IPv6) host-based core routing functionalities, while we enable hosts to become routers between separate address spaces by exploring the new location header. For a proof of concept, we modified the TCP/IP stack of a Linux host to handle our new protocol layer and we designed and con- ceived a novel NAT box to enable current hosts to interact with the modified stack.",Addressing; Identification; Internet; Location; Routing,Address space; Addressing; Content-based; Host-based; New protocol; Proof of concept; Routing; Routing functionality; TCP/IP protocol; Computer operating systems; Identification (control systems); Internet; Location; Network layers; Routers; Internet protocols
"Huang C., Batanov I., Li J.",3,A practical solution to the client-LDNS mismatch problem,2012,5,"Microsoft Research, China; Microsoft Corporation, United States",Microsoft,1,China;USA,2,22,16,"Internet services are often deployed in multiple (tens to hundreds) of geographically distributed data centers. They rely on Global Traffic Management (GTM) solutions to direct clients to the optimal data center based on a number of criteria like network performance, geographic location, availability, etc. The GTM solutions, however, have a fundamental design limitation in their ability to accurately map clients to data centers - they use the IP address of the local DNS resolver (LDNS) used by a client as a proxy for the true client identity, which in some cases causes suboptimal performance. This issue is known as the client-LDNS mismatch problem. We argue that recent proposals to address the problem suffer from serious limitations. We then propose a simple new solution, named ""FQDN extension"", which can solve the client- LDNS mismatch problem completely. We build a prototype system and demonstrate the effectiveness of the proposed solution. Using JavaScript, the solution can be deployed immediately for some online services, such as Web search, without modifying either client or local resolver.",DNS; GTM; Latency,Data centers; Distributed data; DNS; Fundamental design; Geographic location; GTM; Internet services; IP addresss; Javascript; Latency; Mismatch problems; On-line service; Optimal data; Practical solutions; Prototype system; Sub-optimal performance; Traffic management; Web searches; Network performance; Internet protocols
Claffy K.C.,1,Workshop on internet economics (WIE2011) report,2012,2,"CAIDA/UC, San Diego, San Diego, CA, United States",University of California San Diego,1,USA,1,11,12,"The secondWorkshop on Internet Economics [2], hosted by CAIDA and Georgia Institute of Technology on December 1-2, 2011, brought together network technology and policy researchers with providers of commercial Internet facilities and services (network operators) to further explore the common objective of framing an agenda for the emerging but empirically stunted field of Internet infrastructure economics. This report describes the workshop discussions and presents relevant open research questions identified by its participants.",Economics; Internet; Network management,Commercial internet; Georgia Institute of Technology; Internet economics; Internet infrastructure; Network operator; Network technologies; Research questions; Economics; Network management; Internet
"Choochaisri S., Apicharttrisorn K., Korprasertthaworn K., Taechalertpaisarn P., Intanagonwiwat C.",5,Desynchronization with an artificial force field for wireless networks,2012,10,"Department of Computer Engineering, Chulalongkorn University, Bangkok, Thailand",Chulalongkorn University,1,Thailand,1,17,17,"Desynchronization is useful for scheduling nodes to perform tasks at different time. This property is desirable for re- source sharing, TDMA scheduling, and collision avoiding. Inspired by robotic circular formation, we propose DWARF (Desynchronization With an ARtificial Force field), a novel technique for desynchronization in wireless networks. Each neighboring node has artificial forces to repel other nodes to perform tasks at different time phases. Nodes with closer time phases have stronger forces to repel each other in the time domain. Each node adjusts its time phase proportion- ally to its received forces. Once the received forces are bal- anced, nodes are desynchronized. We evaluate our imple- mentation of DWARF on TOSSIM, a simulator for wire- less sensor networks. The simulation results indicate that DWARF incurs significantly lower desynchronization error and scales much better than existing approaches.",Desynchronization; Self-organizing; Sensor networks; Wireless networks,Artificial force fields; Artificial forces; Desynchronization; Neighboring nodes; Novel techniques; Self organizing; TDMA scheduling; Time domain; Scheduling; Sensor networks; Wireless networks
Crowcroft J.,1,The DNS is not a right. oh yes it is. oh no it isn't. oh yes it is...,2012,0,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,4,3,"The Internet is not a Universal service, but then neither is democracy. So should the Internet be viewed as a right? It's certainly sometimes wrong. In this brief article, we depend on the Internet to reach our readers, and we hope that they don't object our doing that.",Communications Systems Research; The Internet,Communications systems; Universal service; Communication; Internet
"Haddadi H., Mortier R., Hand S., Brown I., Yoneki E., Crowcroft J., McAuley D.",7,Privacy analytics,2012,15,"Queen Mary University of London, United Kingdom; University of Nottingham, United Kingdom; University of Cambridge, United Kingdom; Oxford Internet Institute, United Kingdom",Oxford University;Queen Mary University of London;University of Cambridge;University of Nottingham,4,UK,1,29,26,"People everywhere are generating ever-increasing amounts of data, often without being fully aware of who is recording what about them. For example, initiatives such as mandated smart metering, expected to be widely deployed in the UK in the next few years and already attempted in countries such as the Netherlands, will generate vast quantities of detailed, personal data about huge segments of the population. Nei- ther the impact nor the potential of this society-wide data gathering are well understood. Once data is gathered, it will be processed - and society is only now beginning to grapple with the consequences for privacy, both legal and ethical, of these actions, e.g., Brown et al. [4]. There is the potential for great harm through, e.g., invasion of privacy; but also the potential for great benefits by using this data to make more efficient use of resources, as well as releasing its vast economic potential [28]. In this editorial we briey discuss work in this area, the challenges still faced, and some potential avenues for addressing them.",Aggregation; Mobility; Privacy; Profiling; Surveys,Data gathering; Economic potentials; Netherlands; Profiling; Smart metering; Agglomeration; Carrier mobility; Communication; Surveys; Data privacy
"Restrepo J.C.C., Stanojevic R.",2,A history of an internet exchange point,2012,14,"Institute IMDEA Networks, Universidad Carlos III de Madrid, Madrid, Spain; Telefonica Research, Barcelona, Spain",Institute IMDEA Networks;Telefonica Research;University Carlos III of Madrid,3,Spain,1,28,20,"In spite of the tremendous amount of measurement efforts on understanding the Internet as a global system, little is known about the 'local' Internet (among ISPs inside a region or a country) due to limitations of the existing measurement tools and scarce data. In this paper, empirical in nature, we characterize the evolution of one such ecosystem of lo- cal ISPs by studying the interactions between ISPs happen- ing at the Slovak Internet eXchange (SIX). By crawling the web archive waybackmachine.org we collect 158 snapshots (spanning 14 years) of the SIX website, with the relevant data that allows us to study the dynamics of the Slovak ISPs in terms of: the local ISP peering, the traffic distri- bution, the port capacity/utilization and the local AS-level traffic matrix. Examining our data revealed a number of invariant and dynamic properties of the studied ecosystem that we report in detail.",Internet eXchange; Internet traffic; Peering; Traffic matrix,Dynamic property; Global systems; Internet Exchange; Internet traffic; Measurement tools; Peering; Port capacities; Traffic matrices; Web archives; Ecosystems; Measurements; Internet service providers
"Lin K.C.-J., Chuang Y.-J., Katabi D.",3,A light-weight wireless handshake,2012,9,"Research Center for IT, Innovation Academia Sinica, Taiwan; CSAIL, MIT, United States",MIT,1,Taiwan;USA,2,20,16,"In many wireless systems, it is desirable to precede a data transmission with a handshake between the sender and the receiver. For example, RTS-CTS is a handshake that prevents collisions due to hidden terminals. Past work, however, has shown that the overhead of such handshake is too high for practical deployments. We present a new approach to wireless handshake that is almost overhead free. The key idea underlying the design is to separate a packet's PLCP header and MAC header from its body and have the sender and receiver first exchange the data and ACK headers, then exchange the bodies of the data and ACK packets without additional headers. The header exchange provides a natural handshake at almost no extra cost. We empirically evaluate the feasibility of such lightweight handshake and some of its applications. Our testbed evaluation shows that header-payload separation does not hamper packet decodabilty. It also shows that a light handshake enables hidden terminals, i.e., nodes that interfere with each other without RTS/CTS, to experience less than 4% of collisions. Furthermore, it improves the accuracy of bit rate selection in bursty and mobile environments producing a throughput gain of about 2x.",Handshake; Testbed,Bit rates; Handshake; Hidden terminal; Light weight; Mobile environments; RTS/CTS; Wireless systems; Data communication systems; Testbeds
Kalmanek C.,1,The essential elements of successful innovation,2012,3,"AT and T Labs Research, 180 Park Avenue, Florham Park NJ 07932, United States",AT and T Labs,1,USA,1,15,6,"It has become a truism that innovation in the information and communications technology (ICT) fields is occurring faster than ever before. This paper posits that successful innovation requires three essential elements: a need, know-how or knowledge, and favorable economics. The paper examines this proposition by considering three technical areas in which there has been significant innovation in recent years: server virtualization and the cloud, mobile application optimization, and mobile speech services. An understanding of the elements that contribute to successful innovation is valuable to anyone that does either fundamental or applied research in fields of information and communication technology.",Application optimization; Cloud computing; Innovation; Speech recognition; Virtualization,Applied research; Essential elements; In-field; Information and Communication Technologies; Information and communications technology; Mobile applications; Speech services; Virtualizations; Cloud computing; Information technology; Optimization; Speech recognition; Technology transfer; Virtual reality; Innovation
"Sarrar N., Uhlig S., Feldmann A., Sherwood R., Huang X.",5,Leveraging zipf's law for traffic offloading,2012,44,"T-Labs, TU Berlin, Germany; Big Switch Networks, United States; R and D Lab, Deutsche Telekom Inc., United States",Deutsche Telekom Laboratories;TU Berlin,2,Germany;USA,2,27,17,"Internet traffic has Zipf-like properties at multiple aggregation levels. These properties suggest the possibility of offloading most of the traffic from a complex controller (e.g., a software router) to a simple forwarder (e.g., a commodity switch), by letting the for- warder handle a very limited set of flows; the heavy hitters. As the volume of traffic from a set of flows is highly dynamic, maintaining a reliable set of heavy hitters over time is challenging. This is especially true when we face a volume limit in the non-offloaded traffic in combination with a constraint in the size of the heavy hitter set or its rate of change. We propose a set selection strategy that takes advantage of the properties of heavy hitters at different time scales. Based on real Internet traffic traces, we show that our strategy is able to offload most of the traffic while limiting the rate of change of the heavy hitter set, suggesting the feasibility of alter- native router designs.",Heavy hitters; Software defined network; Software router,Aggregation level; Different time scale; Heavy-hitter; Internet traffic; Rate of change; Router design; Software routers; Zipf's law; Internet; Computational linguistics
"Motiwala M., Dhamdhere A., Feamster N., Lakhina A.",4,Towards a cost model for network traffic,2012,13,"Georgia Tech, United States; CAIDA, United States; Guavus, United States",Georgia Tech,1,USA,1,12,10,"We develop a holistic cost model that operators can use to help evaluate the costs of various routing and peering decisions. Using real traffic data from a large carrier network, we show how network operators can use this cost model to significantly reduce the cost of carrying traffic in their networks. We find that adjusting the routing for a small fraction of total flows (and total traffic volume) significantly reduces cost in many cases. We also show how operators can use the cost model both to evaluate potential peering arrangements and for other network operations problems.",Cost optimization; Traffic cost model,Carrier networks; Cost models; Cost optimization; Network operations; Network operator; Network traffic; Real traffic; Traffic volumes; Communication; Cost reduction
Chung Y.,1,Distributed denial of service is a scalability problem,2012,10,"National Institute for Mathematical Sciences, 463-1 Jeonmin-dong, Yuseong-gu Daejeon, South Korea","National Institute for Mathematical Sciences,South Korea",1,South Korea,1,6,5,"Distributed denial of service attacks are often considered just a security problem. While this may be the way to view the problem with the Internet of today, perhaps new network architectures attempting to address the issue should view it as a scalability problem. In addition, they may need to approach the problem based on a rigorous foundation.",Distributed denial of service; Scalability; Security,Distributed denial of service; Distributed denial of service attack; Problem-based; Scalability problems; Security; Security problems; Network architecture; Scalability; Network security
"Duerig J., Ricci R., Stoller L., Strum M., Wong G., Carpenter C., Fei Z., Griffioen J., Nasir H., Reed J., Wu X.",11,Getting started with GENI: A user tutorial,2012,22,"University of Utah, United States; University of Kentucky, United States",University of Kentucky;University of Utah,2,USA,1,2,1,"GENI, the Global Environment for Network Innovations, is a National Science Foundation project to create a ""virtual laboratory at the frontiers of network science and engineering for exploring future internets at scale."" It provides researchers, educators, and students with resources that they can use to build their own networks that span the country and-through federation-the world. GENI enables experimenters to try out bold new network architectures and designs for networked systems, and to deploy and evaluate these systems on a diverse set of resources over a large footprint. This tutorial is a starting point for running experiments on GENI. It provides an overview of GENI and covers the process of creating a network and running a simple experiment using two tools: the Flack GUI and the INSTOOLS instrumentation service.",GENI; Instrumentation; Testbed; Virtualization,Future internet; GENI; Global environment; Instrumentation; National Science Foundations; Network science; Networked systems; Virtual laboratories; Virtualizations; Experiments; Network architecture; Testbeds; Innovation
"Podlesny M., Williamson C.",2,Improving TCP performance in residential broadband networks: A simple and deployable approach,2012,9,"University of Waterloo, Waterloo, Canada; University of Calgary, Calgary, Canada",University of Calgary;University of Waterloo,2,Canada,1,23,7,"ADSL and cable connections are the prevalent technologies available from Internet Service Providers (ISPs) for residential Internet access. Asymmetric access technologies such as these offer high download capacity, but moderate upload capacity. When the Transmission Control Protocol (TCP) is used on such access networks, performance degradation can occur. In particular, sharing a bottleneck link with different upstream and downstream capacities among competing TCP flows in opposite directions can degrade the throughput of the higher speed link. Despite many research efforts to solve this problem in the past, there is no solution that is both highly effective and easily deployable in residential networks. In this paper, we propose an Asymmetric Queueing (AQ) mechanism that enables full utilization of the bottleneck access link in residential networks with asymmetric capacities. The extensive simulation evaluation of our design shows its effectiveness and robustness in a variety of network conditions. Furthermore, our solution is easy to deploy and configure in residential networks.",Asymmetric links; Residential networks; TCP,Access links; Access network; Access technology; Asymmetric links; Bottleneck link; Cable connection; Extensive simulations; Internet access; Network condition; Performance degradation; Research efforts; Residential networks; TCP; TCP flows; TCP performance; Internet service providers; Transmission control protocol; Computer simulation
"Fusco F., Dimitropoulos X., Vlachos M., Deri L.",4,PcapIndex: An index for network packet traces with legacy compatibility,2012,9,"IBM Research, ETH Zurich, Switzerland; ETH Zurich, Switzerland; IBM Research, United States; Ntop, United States",ETH Zurich;IBM,2,Switzerland;USA,2,12,9,"Long-term historical analysis of captured network traffic is a topic of great interest in network monitoring and network security. A critical requirement is the support for fast discovery of packets that satisfy certain criteria within largescale packet repositories. This work presents the first indexing scheme for network packet traces based on compressed bitmap indexing principles. Our approach supports very fast insertion rates and results in compact index sizes. The proposed indexing methodology builds upon libpcap, the defacto reference library for accessing packet-trace repositories. Our solution is therefore backward compatible with any solution that uses the original library. We experience impressive speedups on packet-trace search operations: our experiments suggest that the index-enabled libpcap may reduce the packet retrieval time by more than 1100 times.",Packet indexing,Backward compatible; Historical analysis; Indexing scheme; Insertion rates; Legacy compatibility; Network Monitoring; Network packet traces; Network traffic; Packet indexing; Retrieval time; Search operations; Communication; Indexing (of information)
"Dainotti A., Ammann R., Aben E., Claffy K.C.",4,Extracting benefit from harm: Using malware pollution to analyze the impact of political and geophysical events on the internet,2012,20,"University of Napoli Federico II, Italy; Auckland University of Technology, New Zealand; RIPE NCC, United States; CAIDA/UCSD, United States",Auckland University of Technology;University of Napoli Federico II,2,Italy;New Zealand;USA,3,45,38,"Unsolicited one-way Internet traffic, also called Internet background radiation (IBR), has been used for years to study malicious activity on the Internet, including worms, DoS attacks, and scanning address space looking for vulnerabilities to exploit. We show how such traffic can also be used to analyze macroscopic Internet events that are unrelated to malware. We examine two phenomena: country-level censorship of Internet communications described in recent work [17], and natural disasters (two recent earthquakes). We introduce a new metric of local IBR activity based on the number of unique IP addresses per hour contributing to IBR. The advantage of this metric is that it is not affected by bursts of traffic from a few hosts. Although we have only scratched the surface, we are convinced that IBR traffic is an important building block for comprehensive monitoring, analysis, and possibly even detection of events unrelated to the IBR itself. In particular, IBR offers the opportunity to monitor the impact of events such as natural disasters on network infrastructure, and in particular reveals a view of events that is complementary to many existing measurement platforms based on (BGP) control-plane views or targeted active ICMP probing.",Censorship; Earthquakes; Malware; Network telescope; Outages,Activity-based; Address space; Building blockes; Censorship; DoS attacks; Internet background radiation; Internet communication; Internet traffic; IP addresss; Malicious activities; Malwares; Natural disasters; Network infrastructure; Network telescopes; Disasters; Earthquakes; Internet; Internet protocols; Outages; Computer crime
"Bonald T., Roberts J.",2,Internet and the erlang formula,2012,29,"Telecom ParisTech, Paris, France; INRIA, Rocquencourt, France",INRIA,1,France,1,16,8,"We demonstrate that the Internet has a formula linking demand, capacity and performance that in many ways is the analogue of the Erlang loss formula of telephony. Surprisingly, this formula is none other than the Erlang delay formula. It provides an upper bound on the probability a flow of given peak rate suffers degradation when bandwidth sharing is max-min fair. Apart from the flow rate, the only relevant parameters are link capacity and overall demand. We explain why this result is valid under a very general and realistic traffic model and discuss its significance for network engineering.",Congestion; Erlang formula; Traffc,Bandwidth sharing; Congestion; Erlang formula; Erlang loss formula; Link capacities; Max-min; Network engineering; Traffc; Traffic model; Upper Bound; Communication; Internet
"Kanuparthy P., Dovrolis C., Papagiannaki K., Seshan S., Steenkiste P.",5,Can user-level probing detect and diagnose common home-WLAN pathologies?,2012,13,"Georgia Institute of Technology, United States; Telefonica Research, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Georgia Tech;Telefonica Research,3,USA,1,24,22,"Common Wireless LAN (WLAN) pathologies include low signal-to-noise ratio, congestion, hidden terminals or interference from non-802.11 devices and phenomena. Prior work has focused on the detection and diagnosis of such problems using layer-2 information from 802.11 devices and specialpurpose access points and monitors, which may not be generally available. Here, we investigate a user-level approach: is it possible to detect and diagnose 802.11 pathologies with strictly user-level active probing, without any cooperation from, and without any visibility in, layer-2 devices? In this paper, we present preliminary but promising results indicating that such diagnostics are feasible.",802.11; Diagnosis; Home networks; Performance; Probing,802.11; Access points; Active probing; Detection and diagnosis; Hidden terminal; Home networks; Low signal-to-noise ratio; Performance; Probing; Diagnosis; Pathology; Personal communication systems; Diseases
"Seny S., Guérin R., Hosanagar K.",3,Functionality-rich versus minimalist platforms: A two-sided market analysis,2011,6,"EE, Princeton University, United States; ESE, U. Pennsylvania, United States; Wharton, U. Pennsylvania, United States",Princeton University;University Pennsylvania,2,USA,1,29,25,"Should a new ""platform"" target a functionality-rich but complex and expensive design or instead opt for a bare-bone but cheaper one? This is a fundamental question with profound implications for the eventual success of any platform. A general answer is, however, elusive as it involves a complex trade-off between benefits and costs. The intent of this paper is to introduce an approach based on standard tools from the field of economics, which can offer some insight into this difficult question. We demonstrate its applicability by developing and solving a generic model that incorporates key interactions between platform stakeholders. The solution confirms that the ""optimal"" number of features a platform should offer strongly depends on variations in cost factors. More interestingly, it reveals a high sensitivity to small relative changes in those costs. The paper's contribution and motivation are in establishing the potential of such a cross-disciplinary approach for providing qualitative and quantitative insights into the complex question of platform design.",Economics of networks; Platforms; Two-sided markets,Benefits and costs; Complex questions; Cost factors; Cross-disciplinary approaches; Generic models; High sensitivity; Platform design; Platforms; Standard tools; Two-sided markets; Economic and social effects; Costs
Claffy K.C.,1,"""Network neutrality"": The meme, its cost, its future",2011,2,"CAIDA, United States",University of California San Diego,1,USA,1,21,17,"In June 2011 I participated on a panel on network neutrality hosted at the June cybersecurity meeting of the DHS/SRI Infosec Technology Transition Council (ITTC) [1], where ""experts and leaders from the government, private, financial, IT, venture capitalist, and academia and science sectors came together to address the problem of identity theft and related criminal activity on the Internet."" I recently wrote up some of my thoughts on that panel, including what network neutrality has to do with cybersecurity.",Internet measurement; Management; Public policy; Regulation,Criminal activities; Cyber security; Identity theft; Internet measurement; Regulation; Technology transition; Venture capitalists; Computer crime; Crime; Management; Public policy; Internet
"Callahan T., Allman M., Rabinovich M., Bell O.",4,On grappling with meta-information in the internet,2011,1,"Case Western Reserve University, United States; International Computer Science Institute, United States",Case Western Reserve University;University of California Berkeley,2,USA,1,24,16,"The Internet has changed dramatically in recent years. In particular, the fundamental change has occurred in terms of who generates most of the content, the variety of applica- tions used anl d the diverse ways normal users connect to the Internet. These factors have led to an explosion of the amount of user-specific meta-information that is required to access Internet content (e.g., email addresses, URLs, social graphs). In this paper we describe a foundational service for storing and sharing user-specific meta-information and de- scribe how this new abstraction could be utilized in current and future applications.",Abstractions; Architecture; Meta-information; User-centric networking,Abstractions; E-mail address; Fundamental changes; Future applications; Internet content; Meta information; Social graphs; User-centric; Abstracting; Architecture; Internet
Partridge C.,1,Forty data communications research questions,2011,4,"Raytheon BBN Technologies, United States",Raytheon BBN Technologies,1,USA,1,78,53,"About ten years ago, Bob Lucky asked me for a list of open research questions in networking. I didn't have a ready list and reacted it would be good to have one. This essay is my (longbelated) reply.",Data communications; Data networking; Research; Research agenda,Data networking; Data-communication; Research agenda; Research questions; Convolutional codes; Research
"Bianchi G., D'Heureuse N., Niccolini S.",3,On-demand time-decaying bloom filters for telemarketer detection,2011,13,"CNIT, Univ. Roma Tor Vergata, Italy; NEC Laboratories Europe, NEC Europe Ltd, United Kingdom",NEC;University Roma Tor Vergata,2,Italy;UK,2,14,11,"Several traffic monitoring applications may benefit from the availability of efficient mechanisms for approximately track- ing smoothed time averages rather than raw counts. This paper provides two contributions in this direction. First, our analysis of Time-decaying Bloom filters, formerly proposed data structures devised to perform approximate Exponen- tially Weighted Moving Averages on streaming data, reveals two major shortcomings: biased estimation when measure- ments are read in arbitrary time instants, and slow opera- tion resulting from the need to periodically update all the filter's counters at once. We thus propose a new construc- tion, called On-demand Time-decaying Bloom filter, which relies on a continuous-time operation to overcome the accu- racy/performance limitations of the original window-based approach. Second, we show how this new technique can be exploited in the design of high performance stream-based monitoring applications, by developing VoIPSTREAM, a proof-of-concept real-time analysis version of a formerly pro- posed system for telemarketing call detection. Our valida- tion results, carried out over real telephony data, show how VoIPSTREAM closely mimics the feature extraction pro- cess and traffic analysis techniques implemented in the of- ine system, at a significantly higher processing speed, and without requiring any storage of per-user call detail records.",Bloom filters; Monitoring; Rate metering; Spam; Tele-marketing detection; VoIP,Arbitrary time; Biased estimation; Bloom filters; Call detail records; Monitoring applications; Moving averages; Processing speed; Proof of concept; Rate metering; Real time analysis; Spam; Streaming data; Time averages; Traffic monitoring; Traffic-analysis techniques; VoIP; Window-based; Data structures; Feature extraction; Internet telephony; Monitoring; Digital storage
Claffy K.C.,1,Underneath the hood: Ownership vs. stewardship of the internet,2011,0,"CAIDA, United States",University of California San Diego,1,USA,1,15,10,"I recently published this essay on CircleID [14] on my thoughts on ICANN's recent decision to launch .XXX and the larger new gTLD program this year. Among other observations, I describe how .XXX marks a historical inflection point, where ICANN's board formally abandoned any responsibility to present an understanding of the ramifications of probable negative externalities (""harms"") in setting its policies. That ICANN chose to relinquish this responsibility puts the U.S. government in the awkward position of trying to tighten the few inadequate controls that remain over ICANN, and leaves individual and responsible corporate citizens in the unenviable yet familiar position of bracing for the consequences.",DNS; Policy; Regulation; Security; TLDs,DNS; Inflection points; Negative externalities; Regulation; Security; TLDs; Public policy; Communication
"Bagnulo M., Eardley P., Eggert L., Winter R.",4,How to contribute research results to internet standardization,2011,0,"UC3M, Madrid, Spain; BT, Ipswich, United Kingdom; Nokia, Helsinki, Finland; NEC, Heidelberg, Germany",NEC;Nokia,2,Finland;Germany;Spain;UK,4,7,4,"The development of new technology is driven by scientific research The Internet, with its roots in the ARPANET and NSFNet, is no exception Many of the fundamental, long-term improvements to the architecture, security, end-to-end protocols and management of the Internet originate in the related academic research communities Even shorter-term, more commercially driven extensions are oftentimes derived from academic research When interoperability is required, the IETF standardizes such new technology Timely and relevant standardization benefits from continuous input and review from the academic research community For an individual researcher, it can however by quite puzzling how to begin to most effectively participate in the IETF and - arguably to a much lesser degree - in the IRTF The interactions in the IETF are much different than those in academic conferences, and effective participation follows different rules The goal of this document is to highlight such differences and provide a rough guideline that will hopefully enable researchers new to the IETF to become successful contributors more quickly.",IETF; Research,Academic conferences; Academic research; Arpanet; Continuous input; End-to-end protocol; IETF; Research results; Scientific researches; Education; Internet; Internet protocols; Network architecture; Standardization; Research
Claffy K.C.,1,The 3rd workshop on active internet measurements (AIMS-3) report,2011,0,"CAIDA, United States",University of California San Diego,1,USA,1,39,27,"On February 10-12, 2011, CAIDA hosted the third Work- shop on Active Internet Measurements (AIMS-3) as part of our series of Internet Statistics and Metrics Analysis (ISMA) workshops As with the previous two AIMS workshops, the goals were to further our understanding of the potential and limitations of active measurement research and infrastruc- ture in the wide-area Internet, and to promote cooperative solutions and coordinated strategies to address future data needs of the network and security research communities For three years, the workshop has fostered interdisciplinary con- versation among researchers, operators, and government, fo- cused on analysis of goals, means, and emerging issues in ac- tive Internet measurement projects The first workshop em- phasized discussion of existing hardware and software plat- forms for macroscopic measurement and mapping of Internet properties, in particular those related to cybersecurity The second workshop included more performance evaluation and data-sharing approaches This year we expanded the work- shop agenda to include active measurement topics of more recent interest: broadband performance; gauging IPv6 de- ployment; and measurement activities in international re- search networks.",Active measurement; Internet measurement techniques; Manage-ment techniques; Validation,Active measurement; Broadband performance; Cyber security; Hardware and software; Internet measurement; Macroscopic measurements; Manage-ment techniques; Performance evaluation; Security research; Validation; Wide-area Internet; Internet; Research; Computer aided network analysis
"Yoneki E., Crowcroft J., Lio P., Walton N., Vojnovic M., Whitaker R.",6,Message from the workshop on the future of social networking,2011,0,"Computer Laboratory, University of Cambridge, United Kingdom; Statistical Laboratory, University of Cambridge, United Kingdom; Microsoft Research, United Kingdom; Cardiff University, United Kingdom",Cardiff University;Microsoft;University of Cambridge,3,UK,1,10,0,"Electronic social networks are a relatively new pervasive phenomenon that has changed the way in which we communicate and interact They are now supporting new applications, leading to new trends and posing new challenges The workshop titled ""Future of Social Networking: Experts from Industry and Academia"" took place in Cambridge on November 18, 2010 to expose how the future of social networking may develop and be exploited in new technologies and systems We provide a summary of this event and some observations on the key outcomes.",Privacy; Recommendation; Social networks,Cambridge; New applications; Recommendation; Social Networks; Communication; Data privacy; Social networking (online)
"Koponen T., Shenker S., Balakrishnan H., Feamster N., Ganichev I., Ghodsi A., Godfrey P.B., McKeown N., Parulkar G., Raghavan B., Rexford J., Arianfar S., Kuptsov D.",13,Architecting for innovation,2011,53,"Nicira Networks, United States; ICSI, UC Berkeley, United States; MIT, United States; Georgia Tech, United States; UC Berkeley, United States; KTH, UC Berkeley, United States; UIUC, United States; ICSI, India; Aalto, Finland; HIIT, Finland",Georgia Tech;MIT;Nicira Networks;UIUC;University of California Berkeley,5,Finland;India;USA,3,44,35,"We argue that the biggest problem with the current Internet architecture is not a particular functional deficiency, but its inability to accommodate innovation To address this problem we propose a minimal architectural ""framework"" in which comprehensive architectures can reside The proposed Framework for Internet Innovation (FII) - which is derived from the simple observation that network interfaces should be extensible and abstract - allows for a diversity of architectures to coexist, communicate, and evolve We demonstrate FII's ability to accommodate diversity and evolution with a detailed examination of how information flows through the architecture and with a skeleton implementation of the relevant interfaces.",Diversity; Evolution; Innovation; Internet Architecture,Diversity; Evolution; Information flows; Internet architecture; Skeleton implementation; Innovation; Internet; Architecture
"Hossfeld T., Phuoc T.-G.",2,"Euro view 2010: Visions of future generation networks: Report of the 10th Würzburg workshop on IP: Joint ITG, ITC, Euro-NF Event",2011,0,"Institute of Computer Science, University of Wurzburg, D-97074 Würzburg, Germany",University of Wurzburg,1,Germany,1,7,5,"On August 2nd - 3rd, 2010, the EuroView 2010 workshop on ""Visions of Future Generation Networks"" was held at the University of Wiirzburg. The event was sponsored by the European Network of Excellence Euro-NF [1], the German Information Technology Society ITG [2], and the International Teletraffic Congress ITC [3]. EuroView 2010 brought together Internet and network technology researchers, network providers, as well as equipment and device manufacturers. In 2010, the focus was on ""Future Internet Design and Experimental Facilities"" and on current efforts towards a Future Internet. Special sessions were organized reflecting the latest results of selected testbed expert groups as well as current and future national and international collaborative projects: (1) the German G-Lab project [4] offering a national platform for Future Internet studies, (2) the Future Internet Activities in the European Framework FP7 organized by Max Lemke, and (3) the GENI project [5] in US organized by Aaron Falk. A keynote talk was given by Lawrence Landweber on the challenges and paradigms emerging in the Future (Inter)Network.",Cloud Computing; Data Plane and Control Plane; Federation; Future Internet; Protocols and Interfaces; Prototypes and Testbeds; Routing; Security; Virtualization,Control planes; Federation; Future internet; Routing; Security; Virtualizations; Cloud computing; Information technology; Internet; Testbeds; Internet protocols
Claffy K.C.,1,Tracking IPv6 evolution: Data we have and data we need,2011,23,"CAIDA, United States",University of California San Diego,1,USA,1,57,43,"Exhaustion of the Internet addressing authority's (IANA) available IPv4 address space, which occurred in February 2011, is finally exerting exogenous pressure on network operators to begin to deploy IPv6 There are two possible outcomes from this transition IPv6 may be widely adopted and embraced, causing many existing methods to measure and monitor the Internet to be ineffective A second possibility is that IPv6 languishes, transition mechanisms fail, or performance suffers Either scenario requires data, measurement, and analysis to inform technical, business, and policy decisions We survey available data that have allowed limited tracking of IPv6 deployment thus far, describe additional types of data that would support better tracking, and offer a perspective on the challenging future of IPv6 evolution.",Active measurement; Internet measurement techniques; Network; Validation,Active measurement; Address space; Internet measurement; Network operator; Policy decisions; Transition mechanism; Validation; Computer aided network analysis; Internet; Networks (circuits); Internet protocols
"Cheng X., Su S., Zhang Z., Wang H., Yang F., Luo Y., Wang J.",7,Virtual network embedding through topology-aware node ranking,2011,306,"Beijing University of Posts and Telecommunications, China; University of Massachusetts, Lowell, United States",Beijing University of Posts and Telecommunications;University of Massachusetts Amherst,2,China;USA,2,29,20,"Virtualizing and sharing networked resources have become a growing trend that reshapes the computing and networking architectures. Embedding multiple virtual networks (VNs) on a shared substrate is a challenging problem on cloud computing platforms and large-scale sliceable network testbeds. In this paper we apply the Markov Random Walk (RW) model to rank a network node based on its resource and topological attributes. This novel topology-aware node ranking measure reflects the relative importance of the node. Using node ranking we devise two VN embedding algorithms. The first algorithm maps virtual nodes to substrate nodes according to their ranks, then embeds the virtual links between the mapped nodes by finding shortest paths with unsplittable paths and solving the multi-commodity flow problem with splittable paths. The second algorithm is a backtracking VN embedding algorithm based on breadth-first search, which embeds the virtual nodes and links during the same stage using node ranks. Extensive simulation experiments show that the topology-aware node rank is a better resource measure and the proposed RW-based algorithms increase the long-term average revenue and acceptance ratio compared to the existing embedding algorithms.",Cloud computing; Markov chain; Network virtualization; Random walk; Topology-aware; Virtual network embedding,Acceptance ratio; Breadth-first search; Computing platform; Embedding algorithms; Extensive simulations; Multi-commodity flow; Network node; Network testbeds; Network virtualization; Networked resources; Networking architecture; Random Walk; Ranking measures; Shortest path; Topology aware; Virtual Link; Virtual networks; Virtual node; Algorithms; Cloud computing; Economics; Markov processes; Topology
"Poese I., Uhlig S., Kaafar M.A., Donnet B., Gueye B.",5,IP geolocation databases: Unreliable?,2011,129,"Deutsche Telekom Laboratories, TU Berlin, Germany; INRIA Rhone-Alpes, France; Universite catholique de Louvain, Belgium; Universite Cheikh Anta Diop de Dakar, Senegal",Deutsche Telekom Laboratories;INRIA;TU Berlin;Universite Cheikh Anta Diop de Dakar;Universite Catholique de Louvain,5,Belgium;France;Germany;Senegal,4,18,7,"The most widely used technique for IP geolocation consists in building a database to keep the mapping between IP blocks and a geographic location. Several databases are available and are frequently used by many services and web sites in the Internet. Contrary to widespread belief, geolocation databases are far from being as reliable as they claim. In this paper, we conduct a comparison of several current geolocation databases -both commercial and free- to have an insight of the limitations in their usability. First, the vast majority of entries in the databases refer only to a few popular countries (e.g., U.S.). This creates an imbalance in the representation of countries across the IP blocks of the databases. Second, these entries do not reflect the original allocation of IP blocks, nor BGP announcements. In addition, we quantify the accuracy of geolocation databases on a large European ISP based on ground truth information. This is the first study using a ground truth showing that the overly fine granularity of database entries makes their accuracy worse, not better. Geolocation databases can claim country-level accuracy, but certainly not city-level.",Accuracy; Reliability,Accuracy; Database entry; Fine granularity; Geographic location; Geolocations; Ground truth; In-buildings; IP block; Ip geolocation; Internet protocols; Internet service providers; Reliability; Database systems
"Heusse M., Merritt S.A., Brown T.X., Duda A.",4,"Two-way TCP connections: Old problem, new insight",2011,18,"CNRS Grenoble Informatics Laboratory UMR 5217, Grenoble Institute of Technology, France; University of Colorado, Boulder, United States",Grenoble Institute of Technology;University of Colorado at Boulder,2,France;USA,2,11,4,"Many papers explain the drop of download performance when two TCP connections in opposite directions share a common bottleneck link by ACK compression, the phenomenon in which download ACKs arrive in bursts so that TCP self clocking breaks. Efficient mechanisms to cope with the performance problem exist and we do not consider proposing yet another solution. We rather thoroughly analyze the interactions between connections and show that actually ACK compression only arises in a perfectly symmetrical setup and it has little impact on performance. We provide a different explanation of the interactions-data pendulum, a core phenomenon that we analyze in this paper. In the data pendulum effect, data and ACK segments alternately fill only one of the link buffers (on the upload or download side) at a time, but almost never both of them. We analyze the effect in the case in which buffers are structured as arrays of bytes and derive an expression for the ratio between the download and upload throughput. Simulation results and measurements confirm our analysis and show how appropriate buffer sizing alleviates performance degradation. We also consider the case of buffers structured as arrays of packets and show that it amplifies the effects of data pendulum.",Asymmetric links; TCP,Asymmetric links; Bottleneck link; Buffer sizing; Performance degradation; Performance problems; TCP; TCP connections; Communication; Pendulums
"Yeow W.-L., Westphal C., Kozat U.C.",3,Designing and embedding reliable virtual infrastructures,2011,46,"Institute for Infocomm Research, 1 Fusionopolis Way, Singapore 138632, Singapore; DOCOMO USA Labs, 3240 Hillview Ave, Palo Alto, CA 94304, United States",DOCOMO USA Labs,1,Singapore;USA,2,26,21,"In a virtualized infrastructure where physical resources are shared, a single physical server failure will terminate several virtual servers and crippling the virtual infrastructures which contained those virtual servers. In the worst case, more failures may cascade from overloading the remaining servers. To guarantee some level of reliability, each virtual infrastructure, at instantiation, should be augmented with backup virtual nodes and links that have sufficient capacities. This ensures that, when physical failures occur, sufficient computing resources are available and the virtual network topology is preserved. However, in doing so, the utilization of the physical infrastructure may be greatly reduced. This can be circumvented if backup resources are pooled and shared across multiple virtual infrastructures, and intelligently embedded in the physical infrastructure. These techniques can reduce the physical footprint of virtual backups while guaranteeing reliability.",Infrastructure virtualization,Backup resources; Computing resource; Physical resources; Virtual infrastructures; Virtual network topology; Virtual node; Virtual servers; Virtualizations; Communication
"Lundén M., Dunkels A.",2,The politecast communication primitive for low-power wireless,2011,5,"Swedish Institute of Computer Science, Kista, Sweden",Swedish Institute of Computer Science,1,Sweden,1,14,14,"In low-power wireless networks, nodes need to duty cycle their radio transceivers to achieve a long system lifetime. Counter-intuitively, in such networks broadcast becomes expensive in terms of energy and bandwidth since all neighbors must be woken up to receive broadcast messages. We argue that there is a class of traffic for which broadcast is overkill: periodic redundant transmissions of semi-static information that is already known to all neighbors, such as neighbor and router advertisements. Our experiments show that such traffic can account for as much as 20% of the network power consumption. We argue that this calls for a new communication primitive and present politecast, a communication primitive that allows messages to be sent without explicitly waking neighbors up. We have built two systems based on politecast: a low-power wireless mobile toy and a full-scale low-power wireless network deployment in an art gallery and our experimental results show that politecast can provide up to a four-fold lifetime improvement over broadcast.",Duty cycling; Low-power wireless; Sensor networks,Art gallery; Broadcast messages; Communication primitives; Duty-cycling; Lifetime improvement; Low Power; Network deployment; Radio transceivers; Router Advertisements; Communication; Sensor networks; Wireless networks; Radio broadcasting
"Alcock S., Nelson R.",2,Application flow control in youtube video streams,2011,68,"University of Waikato, Hamilton, New Zealand",University of Waikato,1,New Zealand,1,17,9,"This paper presents the results of an investigation into the application flow control technique utilised by YouTube. We reveal and describe the basic properties of YouTube application flow control, which we term block sending, and show that it is widely used by YouTube servers. We also examine how the block sending algorithm interacts with the flow control provided by TCP and reveal that the block sending approach was responsible for over 40% of packet loss events in YouTube flows in a residential DSL dataset and the retransmission of over 1% of all YouTube data sent after the application flow control began. We conclude by suggesting that changing YouTube block sending to be less bursty would improve the performance and reduce the bandwidth usage of YouTube video streams.",Block sending; DSL; Flow control; Packet loss; Youtube,Bandwidth usage; Basic properties; Block sending; Data sets; Flow control techniques; Retransmissions; Video streams; YouTube; DSL; Flow control; Packet loss; Video streaming; Websites
"Wu J., Wang J.H., Yang J.",3,CNGI-CERNET2: An IPv6 deployment in China,2011,34,"CNGI-CERNET2, China; CERNET, Tsinghua University, China",Tsinghua University,1,China,1,4,0,"Research and promotion of next generation Internet have drawn attention of researchers in many countries. In USA, FIND initiative takes a clean-slate approach. In EU, EIFFEL think tank concludes that both clean slate and evolutionary approach are needed. While in China, researchers and the country are enthusiastic on the promotion and immediate deployment of IPv6 due to the imminent problem of IPv4 address exhaustion. Since 2003, China launched a strategic programme called China Next Generation Internet (CNGI). China is expecting that Chinese industry is better positioned on future Internet technologies and services than it was for the first generation. Under the support of CNGI grant, China Education and Research Network (CERNET) started to build an IPv6- only network, i.e. CNGI-CERNET2. Currently it provides IPv6 access service for students and staff in many Chinese universities. In this article, we will introduce the CNGI programme, the architecture of CNGI-CERNET2, and some aspects of CNGI-CERNET2's deployment and operation, such as transition, security, charging and roaming service etc.",Deployment; Internet; IPv6,Access service; China education and research networks; Chinese industry; Chinese universities; Deployment; Evolutionary approach; Future internet; IPv6; Next generation Internet; Roaming services; Internet; Research; Slate; Internet protocols
"Ekiz N., Rahman A.H., Amer P.D.",3,Misbehaviors in TCP SACK generation,2011,7,"Computer and Information Sciences Department, University of Delaware, Newark, DE 19716, United States",University of Delaware,1,USA,1,21,0,"While analyzing CAIDA Internet traces of TCP traffic to detect instances of data reneging, we frequently observed seven misbehaviors in the generation of SACKs. These misbehaviors could result in a data sender mistakenly thinking data reneging occurred. With one misbehavior, the worst case could result in a data sender receiving a SACK for data that was transmitted but never received. This paper presents a methodology and its application to test a wide range of operating systems using TBIT to fingerprint which ones misbehave in each of the seven ways. Measuring the performance loss due to these misbehaviors is outside the scope of this study; the goal is to document the misbehaviors so they may be corrected. One can conclude that the handling of SACKs while simple in concept is complex to implement.",SACK; Selective acknowledgment; TBIT; TCP,Internet traces; Performance loss; SACK; Selective acknowledgment; TBIT; TCP; TCP SACK; TCP traffic; Communication
"Whiteaker J., Schneider F., Teixeira R.",3,Explaining packet delays under virtualization,2011,43,"UPMC Sorbonne Universit́es and CNRS, France",UPMC Sorbonne Universités,1,France,1,31,18,"This paper performs controlled experiments with two popular virtualization techniques, Linux-VServer and Xen, to examine the effects of virtualization on packet sending and receiving delays. Using a controlled setting allows us to independently investigate the influence on delay measurements when competing virtual machines (VMs) perform tasks that consume CPU, memory, I/O, hard disk, and network bandwidth. Our results indicate that heavy network usage from competing VMs can introduce delays as high as 100 ms to round-trip times. Furthermore, virtualization adds most of this delay when sending packets, whereas packet reception introduces little extra delay. Based on our findings, we discuss guidelines and propose a feedback mechanism to avoid measurement bias under virtualization.",Packet delay; Timestamping; Virtualization; VServer; Xen,Packet delay; Timestamping; Virtualization; VServer; Xen; Computer operating systems
"Yang L., Zhang Z., Hou W., Zhao B.Y., Zheng H.",5,Papyrus: A software platform for distributed dynamic spectrum sharing using SDRs,2011,22,"Department of Computer Science, University of California, Santa Barbara, United States; Department of Electronic Engineering, Tsinghua University, Beijing, China",Tsinghua University;University of California Santa Barbara,2,China;USA,2,15,10,"Proliferation and innovation of wireless technologies require significant amounts of radio spectrum. Recent policy reforms by the FCC are paving the way by freeing up spectrum for a new generation of frequency-agile wireless devices based on software defined radios (SDRs). But despite recent advances in SDR hardware, research on SDR MAC protocols or applications requires an experimental platform for managing physical access. We introduce Papyrus, a software platform for wireless researchers to develop and experiment dynamic spectrum systems using currently available SDR hardware. Papyrus provides two fundamental building blocks at the physical layer: flexible non-contiguous frequency access and simple and robust frequency detection. Papyrus allows researchers to deploy and experiment new MAC protocols and applications on USRP GNU Radio, and can also be ported to other SDR platforms. We demonstrate the use of Papyrus using Jello, a distributedMAC overlay for high-bandwidth media streaming applications and Ganache, a SDR layer for adaptable guardband configuration. Full implementations of Papyrus and Jello are publicly available.",Cognitive radio; Dynamic spectrum access; Testbed,Cognitive radio; Distributed dynamics; Dynamic spectrum; Dynamic spectrum access; Experimental platform; Frequency detection; Fundamental building blocks; GNU radio; Guard band configuration; High bandwidth; MAC protocol; Physical layers; Policy reforms; Radio spectra; Software platforms; Software-defined radios; Streaming applications; Wireless devices; Wireless technologies; Dynamics; Innovation; Media streaming; Network protocols; Radio communication; Radio systems; Research; Spectroscopy; Test facilities; Testbeds; Wireless telecommunication systems; Radio
"Chen Y., Borrel V., Ammar M., Zegura E.",4,A framework for characterizing the wireless and mobile network continuum,2011,9,"School of Computer Science, Georgia Institute of Technology, Atlanta, GA, United States",Georgia Tech,1,USA,1,16,13,"The vast majority of research in wireless and mobile (WAM) networking falls in the MANET (Mobile Ad Hoc Network) category where end-to-end paths are the norm. More recently research has focused on a dierent Disruption Tolerant Network (DTN) paradigm where end-to-end paths are the exception and intermediate nodes may store data while waiting for transfer opportunities towards the destination. Protocols developed for MANETs are generally not appropriate for DTNs and vice versa, since the connectivity assumptions are so dierent. We make the simple but powerful observation that MANETs and DTNst into a continuum that generalizes these two previously distinct categories In this paper building on this observation, we develop a WAM continuum framework that goes further to scope the entire space of Wireless and Mobile networks so that a network can be characterized by its position in this continuum. Certain network equivalence classes can be dened over subsets of this WAM continuum. We instantiate our framework that allows network connectivity classication and show how that classication relates to routing. We illustrate our approach by applying it to networks described by traces and by mobility models. We also outline how our framework can be used to guide network design and operation.",Disruption-tolerant networks; Mobile ad-Hoc networks; Wireless and mobile networks,Disruption tolerant networks; End-to-end path; Intermediate node; Mobile networks; Mobility model; Network connectivity; Network design; Wireless and mobile networks; Equivalence classes; Mobile ad hoc networks; Mobile telecommunication systems; Telecommunication networks; Ad hoc networks
"Luckie M., Dhamdhere A., Claffy K., Murrell D.",4,Measured impact of crooked traceroute,2011,15,"Computer Science, University of Waikato, Hamilton, New Zealand; CAIDA, University of California, San Diego, CA, United States",University of California San Diego;University of Waikato,2,New Zealand;USA,2,35,22,"Data collected using traceroute-based algorithms underpins research into the Internet′s router-level topology, though it is possible to infer false links from this data. One source of false inference is the combination of per-flow load-balancing, in which more than one path is active from a given source to destination, and classic traceroute, which varies the UDP destination port number or ICMP checksum of successive probe packets, which can cause per-flow load-balancers to treat successive packets as distinct flows and forward them along different paths. Consequently, successive probe packets can solicit responses from unconnected routers, leading to the inference of false links. This paper examines the inaccuracies induced from such false inferences, both on macroscopic and ISP topology mapping. We collected macroscopic topology data to 365k destinations, with techniques that both do and do not try to capture load balancing phenomena. We then use alias resolution techniques to infer if a measurement artifact of classic traceroute induces a false router-level link. This technique detected that 2.71% and 0.76% of the links in our UDP and ICMP graphs were falsely inferred due to the presence of load-balancing. We conclude that most per-flow load-balancing does not induce false links when macroscopic topology is inferred using classic traceroute. The effect of false links on ISP topology mapping is possibly much worse, because the degrees of a tier-1 ISP′s routers derived from classic traceroute were inflated by a median factor of 2.9 as compared to those inferred with Paris traceroute.",Internet topology; Traceroute,Checksum; Internet topologies; Load-Balancing; Measurement artifacts; Port numbers; Probe packets; Resolution techniques; Topology mapping; Traceroute; Internet; Internet protocols; Internet service providers; Network management; Probes; Routers; Topology
"Yin D., Unnikrishnan D., Liao Y., Gao L., Tessier R.",5,Customizing virtual networks with partial FPGA reconfiguration,2011,16,"Dept. of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA 01003, United States",University of Massachusetts Amherst,1,USA,1,20,17,"Recent FPGA-based implementations of network virtualization represent a significant step forward in network performance and scalability. Although these systems have been shown to provide orders of magnitude higher performance than solutions using software-based routers, straightforward reconfiguration of hardware-based virtual networks over time is a challenge. In this paper, we present the implementation of a reconfigurable network virtualization substrate that combines several partially-reconfigurable hardware virtual routers with software virtual routers. The update of hardware-based virtual networks in our system is supported via real-time partial FPGA reconfiguration. Hardware virtual networks can be dynamically reconfigured in a fraction of a second without affecting other virtual networks operating in the same FPGA. A heuristic has been developed to allocate virtual networks with diverse bandwidth requirements and network characteristics on this heterogeneous virtualization substrate. Experimental results show that the reconfigurable virtual routers can forward packets at line rate. Partial reconfiguration allows for 20x faster hardware reconfiguration than a previous approach which migrated hardware virtual networks to software.",FPGA; Network virtualization; Partial reconfiguration,Bandwidth requirement; Forward packets; FPGA; FPGA-based implementation; Line rate; Network characteristics; Network virtualization; Orders of magnitude; Partial reconfiguration; Re-configurable; Reconfigurable network; Software-based router; Virtual networks; Virtualizations; Hardware; Network performance; Routers; Reconfigurable hardware
"Krioukov A., Mohan P., Alspaugh S.., Keys L., Culler D., Katz R.",6,NapSAC: Design and implementation of a power-proportional web cluster,2011,43,"Computer Science Division, University of California, Berkeley, United States",University of California Berkeley,1,USA,1,24,17,"Energy consumption is a major and costly problem in data centers. A large fraction of this energy goes to powering idle machines that are not doing any useful work. We identify two causes of this inefficiency: low server utilization and a lack of power-proportionality. To address this problem we present a design for an power-proportional cluster consisting of a power-aware cluster manager and a set of heterogeneous machines. Our design makes use of currently available energy-efficient hardware, mechanisms for transitioning in and out of low-power sleep states, and dynamic provisioning and scheduling to continually adjust to workload and minimize power consumption. With our design we are able to reduce energy consumption while maintaining acceptable response times for a web service workload based on Wikipedia. With our dynamic provisioning algorithms we demonstrate via simulation a 63% savings in power usage in a typically provisioned datacenter where all machines are left on and awake at all times. Our results show that we are able to achieve close to 90% of the savings a theoretically optimal provisioning scheme would achieve. We have also built a prototype cluster which runs Wikipedia to demonstrate the use of our design in a real environment.",Cluster; Data center; Energya; Heterogenous hardware; Power management; Power proportional; Web application; Web server,Cluster; Data center; Energya; Heterogenous hardware; Power management; Power proportional; WEB application; Web servers; Computer hardware; Energy utilization; Machine design; Satellite communication systems; Websites; Web services
"Erman J., Gerber A., Sen S.",3,HTTP in the home: It is not just about PCs,2011,10,"AT and T Labs - Research, Florham Park, NJ, United States",AT and T Labs,1,USA,1,9,6,"HTTP (Hypertext Transport Protocol) was originally primarily used for human-initiated client-server communications launched from web browsers, traditional computers and laptops. However, today it has become the protocol of choice for a bewildering range of applications from a wide array of emerging devices like smart TVs and gaming consoles. This paper presents an initial study characterizing the non-traditional sources of HTTP traffic such as consumer devices and automated updates in the overall HTTP traffic for residential Internet users. Among our findings, 13% of all HTTP traffic in terms of bytes is due to nontraditional sources, with 5% being from consumer devices such as WiFi enabled smartphones and 8% generated from automated software updates and background processes. Our findings show that 11% of all HTTP requests are caused by communications with advertising servers from as many as 190 countries worldwide, suggesting the widespread prevalence of such activities. Overall, our findings start to answer questions about what is the state of traffic generated in these smart homes.",Consumer devices; Home networks; Traffic classification,Client-server communication; Consumer devices; Gaming consoles; Home networks; HTTP traffic; Internet users; Non-traditional; Smart homes; Smartphones; Software updates; Traditional computers; Traffic classification; Transport protocols; Hypertext systems; Internet protocols; Laptop computers; Personal communication systems; Servers; Telecommunication traffic; Web browsers; World Wide Web; HTTP
"Keshav S., Rosenberg C.",2,How internet concepts and technologies can help green and smarten the electrical grid,2011,38,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON N2L 3G1, Canada; Dept. of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada",University of Waterloo,1,Canada,1,25,24,"Several powerful forces are gathering to make fundamental and irrevocable changes to the century-old grid. The nextgeneration grid, often called the 'smart grid,' will feature distributed energy production, vastly more storage, tens of millions of stochastic renewable-energy sources, and the use of communication technologies both to allow precise matching of supply to demand and to incentivize appropriate consumer behaviour. These changes will have the effect of reducing energy waste and reducing the carbon footprint of the grid, making it 'smarter' and 'greener.' In this position paper, we discuss how the concepts and techniques pioneered by the Internet, the fruit of four decades of research in this area, are directly applicable to the design of a smart, green grid. This is because both the Internet and the electrical grid are designed to meet fundamental needs, for information and for energy, respectively, by connecting geographically dispersed suppliers with geographically dispersed consumers. Keeping this and other similarities (and fundamental differences, as well) in mind, we propose several specific areas where Internet concepts and technologies can contribute to the development of a smart, green grid. We also describe some areas where the Internet operations can be improved based on the experience gained in the electrical grid. We hope that our work will initiate a dialogue between the Internet and the smart grid communities.",Electrical grid; Green networking,Carbon footprint; Communication technologies; Consumer behaviour; Distributed energies; Electrical grids; Energy source; Energy wastes; Green Grid; Green networking; Next-generation grids; Position papers; Smart grid; Specific areas; Behavioral research; Energy conversion; Internet; Renewable energy resources; Smart power grids
"Calvert K.L., Edwards W.K., Feamster N., Grinter R.E., Deng Y., Zhou X.",6,Instrumenting home networks,2011,25,"Lab for Advanced Networking, University of Kentucky, Lexington, KY, United States; College of Computing, Georgia Tech, Atlanta, GA, United States",Georgia Tech;University of Kentucky,2,USA,1,19,18,"In managing and troubleshooting home networks, one of the challenges is in knowing what is actually happening. Availability of a record of events that occurred on the home network before trouble appeared would go a long way toward addressing that challenge. In this position/work-in-progress paper, we consider requirements for a general-purpose logging facility for home networks. Such a facility, if properly designed, would potentially have other uses. We describe several such uses and discuss requirements to be considered in the design of a logging platform that would be widely supported and accepted. We also report on our initial deployment of such a facility.",Home network management; Home network troubleshooting,Home network management; Home networks; Troubleshooting; Carrier communication; Personal communication systems; Network management
"FitzRoy-Dale N., Kuz I., Heiser G.",3,Architecture optimisation with currawong,2011,1,"NICTA, University of New South Wales, Sydney, Australia; NICTA, University of New South Wales, Open Kernel Labs, Sydney, Australia",NICTA;University of New South Wales,2,Australia,1,12,4,"We describe Currawong, a tool to perform system software architecture optimisation. Currawong is an extensible tool which applies optimisations at the point where an application invokes framework or library code. Currawong does not require source code to perform optimisations, e ectively decoupling the relationship between compilation and optimisation. We show, through examples written for the popular Android smartphone platform, that Currawong is capable of signi cant performance improvement to existing applications.",Android; Optimization; Performance; Prolog,Android; Architecture optimisation; Library codes; Optimisations; Performance; Performance improvements; Prolog; Smart phones; Source codes; System software architecture; Robots; Software architecture; Optimization
"Jang K., Han S., Han S., Moon S., Park K.",5,Accelerating SSL with GPUs,2011,3,"Department of Computer Science, KAIST, South Korea; Department of Computer Science and Engineering, University of Washington, United States; Department of Electrical Engineering, KAIST, South Korea",KAIST;University of Washington at St. Louis,2,South Korea;USA,2,6,6,"SSL/TLS is a standard protocol for secure Internet communication. Despite its great success, today's SSL deployment is largely limited to security-critical domains. The low adoption rate of SSL is mainly due to high computation overhead on the server side. In this paper, we propose Graphics Processing Units (GPUs) as a new source of computing power to reduce the server-side overhead. We have designed and implemented an SSL proxy that opportunistically offloads cryptographic operations to GPUs. The evaluation results show that our GPU implementation of cryptographic operations, RSA, AES, and HMAC-SHA1, achieves high throughput while keeping the latency low. The SSL proxy significantly boosts the throughput of SSL transactions, handling 21.5K SSL transactions per second, and has comparable response time even when overloaded.",CUDA; GPU; SSL,Computation overheads; Computing power; Critical domain; Cryptographic operations; CUDA; Evaluation results; GPU; GPU implementation; Graphics processing units; High throughput; Internet communication; New sources; Response time; SSL; SSL/TLS; Standard protocols; Cryptography; Internet protocols; Program processors
"He Y., Fang J., Zhang J., Shen H., Tan K., Zhang Y.",6,MPAP: Virtualization architecture for heterogenous wireless APs,2011,7,"Microsoft Research Asia, Beijing, China",Microsoft,1,China,1,4,2,"This demonstration shows a novel virtualization architecture, called Multi-Protocol Access Point (MPAP), which exploits the software radio technology to virtualize multiple heterogenous wireless standards on single radio hardware. The basic idea is to deploy a wideband radio front-end to receive radio signals from all wireless standards sharing the same spectrum band, and use separate software base-bands to demodulate information stream for each wireless standard. Based on software radio, MPAP consolidates multiple wireless devices into single hardware platform, allowing them to share the common general-purpose computing resource. Different software base-bands can easily communicate and coordinate via a software coordinator and coexist better with one another. As one example, we demonstrate to use non-contiguous OFDM in 802.11g PHY to avoid the mutual interference with narrow-band ZigBee communication.",Software radio; Virtualization; Wireless,802.11g; Access points; Basic idea; General-purpose computing; Hardware platform; Information streams; Multiprotocols; Mutual interference; Narrow bands; Radio hardware; Radio signals; Software Radio; Software radio technology; Spectrum bands; Virtualization; Virtualizations; Wide-band; Wireless; Wireless devices; Wireless standards; Zig-Bee; Network architecture; Radio receivers; Standards; Radio
"Pervilä M., Kangasharju J.",2,Running servers around zero degrees,2011,4,"Department of Computer Science, P.O. box 68 (Gustaf Hällströmin katu 2b), FI-00014 University of Helsinki, Finland; Helsinki Institute for Information Technology, Department of Computer Science, FI-00014 University of Helsinki, Finland",University of Helsinki;Helsinki Institute of Information Technology,2,Finland,1,6,6,"Data centers are a major consumer of electricity and a signi cant fraction of their energy use is devoted to cooling the data center. Recent prototype deployments have investigated the possibility of using outside air for cooling and have shown large potential savings in energy consumption. In this paper, we push this idea to the extreme, by running servers outside in Finnish winter. Our results show that commercial, off-the-shelf computer equipment can tolerate extreme conditions such as outside air temperatures below -20° C and still function correctly over extended periods of time. Our experiment improves upon the other recent results by conrming their fndings and extending them to cover a wider range of intake air temperatures and humidity. This paper presents our experimentation methodology and setup, and our mainndings and observations.",Cooling; Empirical system reliability; Sustainable computing,Computer equipments; Data centers; Energy consumption; Energy use; Extreme conditions; Finnish; Intake air temperature; Outside-air temperature; Prototype deployment; Sustainable computing; System reliability; Air intakes; Atmospheric temperature; Cooling; Energy utilization; Satellite communication systems; Experiments
"Kone V., Zheleva M., Wittie M., Zhao B.Y., Belding E.M., Zheng H., Almeroth K.C.",7,"AirLab: Consistency, fidelity and privacy in wireless measurements",2011,1,"Department of Computer Science, University of California, Santa Barbara, United States",University of California Santa Barbara,1,USA,1,29,28,"Accurate measurements of deployed wireless networks are vital for researchers to perform realistic evaluation of proposed systems. Unfortunately, the difficulty of performing detailed measurements limits the consistency in parameters and methodology of current datasets. Using different datasets, multiple research studies can arrive at conflicting conclusions about the performance of wireless systems. Correcting this situation requires consistent and comparable wireless traces collected from a variety of deployment environments. In this paper, we describe AirLab, a distributed wireless data collection infrastructure that uses uniformly instrumented measurement nodes at heterogeneous locations to collect consistent traces of both standardized and user-defined experiments. We identify four challenges in the AirLab platform, consistency, fidelity, privacy, security, and describe our approaches to address them.",Airlab; Wireless measurements,Accurate measurement; Airlab; Data sets; Distributed wireless; Measurement nodes; Multiple research; Wireless measurements; Wireless systems; Data processing
"Lee G., Tolia N., Ranganathan P., Katz R.H.",4,Topology-aware resource allocation for data-intensive workloads,2011,21,"University of California, Berkeley, United States; HP Labs, Palo Alto, United States",HP Labs;University of California Berkeley,2,USA,1,20,15,"cation in Infrastructure-as-a-Service (IaaS)-based cloud systems. Current IaaS systems are usually unaware of the hosted application's requirements and therefore allocate resources independently of its needs, which can significantly impact performance for distributed data-intensive applications. To address this resource allocation problem, we propose an architecture that adopts a ""what if"" methodology to guide allocation decisions taken by the IaaS. The architecture uses a prediction engine with a lightweight simulator to estimate the performance of a given resource allocation and a genetic algorithm to find an optimized solution in the large search space. We have built a prototype for Topology-Aware Resource Allocation (TARA) and evaluated it on a 80 server cluster with two representative MapReduce-based benchmarks. Our results show that TARA reduces the job completion time of these applications by up to 59% when compared to application-independent allocation policies.",Hadoop; IaaS; Infrastructure-as-a-service; MapReduce; Modeling; Performance; Topology awareness; Virtualization,Hadoop; IaaS; Infrastructure-as-a-service; Map-reduce; Modeling; Performance; Topology awareness; Virtualizations; Topology; Resource allocation
"Vaquero L.M., Rodero-Merino L., Buyya R.",3,Dynamically scaling applications in the cloud,2011,209,"Hewlett Packard Labs, Bristol, United Kingdom; LIP ENS Lyon, Graal/Avalon Group, INRIA, France; University of Melbourne, Australia",INRIA;University of Melbourne,2,Australia;France;UK,3,45,42,"Scalability is said to be one of the major advantages brought by the cloud paradigm and, more specifically, the one that makes it different to an advanced outsourcing solution. However, there are some important pending issues before making the dreamed automated scaling for applications come true. In this paper, the most notable initiatives towards whole application scalability in cloud environments are presented. We present relevant efforts at the edge of state of the art technology, providing an encompassing overview of the trends they each follow. We also highlight pending challenges that will likely be addressed in new research efforts and present an ideal scalable cloud system.",Cloud computing; Scalability,Application scalability; Cloud systems; Outsourcing solution; Research efforts; State-of-the-art technology; Computer systems; Outsourcing; Scalability; Cloud computing
"Lee S., Hyun-chul K., Barman D., Lee S., Kim C.-K., Kwon T.T.",6,NeTraMark: A network traffic classification benchmark,2011,33,"Seoul National University, South Korea; Juniper Networks, United States",Seoul National University,1,South Korea;USA,2,23,18,"Recent research on Internet traffic classification has produced a number of approaches for distinguishing types of traffic. However, a rigorous comparison of such proposed algorithms still remains a challenge, since every proposal considers a different benchmark for its experimental evaluation. A lack of clear consensus on an objective and scientific way for comparing results has made researchers uncertain of fundamental as well as relative contributions and limitations of each proposal. In response to the growing necessity for an objective method of comparing traffic classifiers and to shed light on scientifically grounded traffic classification research, we introduce an Internet traffic classification benchmark tool, NeTraMark. Based on six design guidelines (Comparability, Reproducibility, Efficiency, Extensibility, Synergy, and Flexibility/Ease-of-use), NeTraMark is the first Internet traffic classification benchmark where eleven different state-of-the-art traffic classifiers are integrated. NeTraMark allows researchers and practitioners to easily extend it with new classification algorithms and compare them with other built-in classifiers, in terms of three categories of performance metrics: per-whole-trace flow accuracy, per-application flow accuracy, and computational performance.",Benchmark; Traffic classification,Benchmark; Classification algorithm; Computational performance; Design guidelines; Experimental evaluation; Flow accuracy; Internet traffic; Network traffic classification; Objective methods; Performance metrics; Relative contribution; Reproducibilities; Traffic classification; Traffic classifiers; Algorithms; Arts computing; Classifiers; Internet; Research; Telecommunication traffic
"Pujol J.M., Erramilli V., Siganos G., Yang X., Laoutaris N., Chhabra P., Rodriguez P.",7,The little engine(s) that could: Scaling online social networks,2010,33,"Telefonica Research, Spain",Telefonica Research,1,Spain,1,34,18,"The difficulty of scaling Online Social Networks (OSNs) has introduced new system design challenges that has often caused costly re-architecting for services like Twitter and Facebook. The complexity of interconnection of users in social networks has introduced new scalability challenges. Conventional vertical scaling by resorting to full replication can be a costly proposition. Horizontal scaling by partitioning and distributing data among multiples servers - e.g. using DHTs - can lead to costly inter-server communication. We design, implement, and evaluate SPAR, a social partitioning and replication middle-ware that transparently leverages the social graph structure to achieve data locality while minimizing replication. SPAR guarantees that for all users in an OSN, their direct neighbor's data is co-located in the same server. The gains from this approach are multi-fold: application developers can assume local semantics, i.e., develop as they would for a single server; scalability is achieved by adding commodity servers with low memory and network I/O requirements; and redundancy is achieved at a fraction of the cost. We detail our system design and an evaluation based on datasets from Twitter, Orkut, and Facebook, with a working implementation. We show that SPAR incurs minimum overhead, and can help a well-known open-source Twitter clone reach Twitter's scale without changing a line of its application logic and achieves higher throughput than Cassandra, Facebook's DHT based key-value store database. Copyright 2010 ACM.",Partition; Replication; Scalability; Social networks,Application developers; Cassandras; Co-located; Data locality; Design challenges; Facebook; Horizontal scaling; Inter-server communications; ITS applications; Key-value stores; Local semantics; Low memory; Network I/O; On-line social networks; Online social networks (OSNs); Open-source; Replication; Single server; Social graphs; Social Networks; Vertical scaling; Heterojunction bipolar transistors; Partitions (building); Scalability; Semantics; Systems analysis; Social networking (online)
"Aggarwal B., Chitnis P., Dey A., Jain K., Navda V., Padmanabhan V.N., Ramjee R., Schulman A., Spring N.",9,Stratus: Energy-efficient mobile communication using cloud support,2010,10,"Microsoft Research, India; Microsoft Research, United States; University of Maryland, United States",Microsoft;University of Maryland College Park,2,India;USA,2,6,3,"Cellular radio communication is a significant contributor to battery energy drain on smartphones, in some cases inflating the energy cost by a factor of 5 or more compared to the energy cost of the base device. Stratus is a system to reduce this energy consumption by leveraging cloud resources to make data communication on smartphones more efficient. Using a cloud-based proxy, Stratus employs optimizations that adapt an application's incoming and outgoing traffic to better match the energy characteristics of the radio interface. The optimizations include (a) aggregation to bunch up sporadic transmissions, (b) asymmetric dictionary-based compression to reduce the number of bits transmitted over the air, and (c) opportunistic scheduling to avoid communication during periods of poor signal reception. These optimizations can be used individually, or in combination, subject to an application's delay tolerance. For example, using our Stratus prototype, the aggregation and compression optimizations together achieve up to 50% energy savings for web browsing, while the aggregation and scheduling optimizations together achieve up to 35% energy savings for a media streaming application.",Cloud proxy; Energy; Smartphone,Battery energy; Cloud-based; Data-communication; Delay tolerances; Dictionary-based compressions; Energy; Energy characteristics; Energy cost; Energy efficient; Mobile communications; Opportunistic scheduling; Over the airs; Radio interface; Scheduling optimization; Signal reception; Streaming applications; Energy conservation; Energy utilization; Optimization; Scheduling; Smartphones; Clouds
"Sen S., Gilani S., Srinath S., Schmitt S., Banerjee S.",5,"Design and implementation of an ""approximate"" communication system for wireless media applications",2010,5,"University of Wisconsin-Madison, United States",University of Wisconsin-Madison,1,USA,1,38,21,"All practical wireless communication systems are prone to errors. At the symbol level such wireless errors have a well-defined structure: when a receiver decodes a symbol erroneously, it is more likely that the decoded symbol is a good ""approximation"" of the transmitted symbol than a randomly chosen symbol among all possible transmitted symbols. Based on this property, we define approximate communication, a method that exploits this error structure to natively provide unequal error protection to data bits. Unlike traditional (FEC-based) mechanisms of unequal error protection that consumes additional network and spectrum resources to encode redundant data, the approximate communication technique achieves this property at the PHY layer without consuming any additional network or spectrum resources (apart from a minimal signaling overhead). Approximate communication is particularly useful to media delivery applications that can benefit significantly from unequal error protection of data bits. We show the usefulness of this method to such applications by designing and implementing an end-to-end media delivery system, called Apex. Our Software Defined Radio (SDR)-based experiments reveal that Apex can improve video quality by 5 to 20 dB (PSNR) across a diverse set of wireless conditions, when compared to traditional approaches. We believe that mechanisms such as Apex can be a cornerstone in designing future wireless media delivery systems under any error-prone channel condition. Copyright 2010 ACM.",Cross layer; Media delivery; Wireless PHY,Communication techniques; Cross layer; Data bits; Design and implementations; Error structures; Error-prone channel; Media delivery; Media delivery systems; Redundant data; Signaling overheads; Software-defined radios; Traditional approaches; Unequal error protections; Video quality; Well-defined structures; Wireless communication system; Wireless errors; Wireless media; Communication systems; Image coding
"Choffnes D.R., Bustamante F.E., Ge Z.",3,Crowdsourcing service-level network event monitoring,2010,13,"Northwestern University, United States; AT and T Labs. - Research, United States",AT and T Labs;Northwestern University,2,USA,1,37,33,"The user experience for networked applications is becoming a key benchmark for customers and network providers. Perceived user experience is largely determined by the frequency, duration and severity of network events that impact a service. While today's networks implement sophisticated infrastructure that issues alarms for most failures, there remains a class of silent outages (e.g., caused by configuration errors) that are not detected. Further, existing alarms provide little information to help operators understand the impact of network events on services. Attempts to address this through infrastructure that monitors end-to-end performance for customers have been hampered by the cost of deployment and by the volume of data generated by these solutions. We present an alternative approach that pushes monitoring to applications on end systems and uses their collective view to detect network events and their impact on services - an approach we call Crowdsourcing Event Monitoring (CEM). This paper presents a general framework for CEM systems and demonstrates its effectiveness for a P2P application using a large dataset gathered from BitTorrent users and confirmed network events from two ISPs. We discuss how we designed and deployed a prototype CEM implementation as an extension to BitTorrent. This system performs online service-level network event detection through passive monitoring and correlation of performance in end-users' applications. Copyright 2010 ACM.",Anomaly detection; Crowdsourcing; P2P; Service-level network events,Alternative approach; Anomaly detection; Bit torrents; Cem systems; Configuration errors; Crowdsourcing; End systems; End-to-end performance; End-users; Event detection; Event monitoring; Large dataset; Network provider; Networked applications; P2P; P2P applications; Passive monitoring; Service levels; User experience; Computational electromagnetics; Internet service providers; Peer to peer networks
"Gabale V., Raman B., Chebrolu K., Kulkarni P.",4,LokVaani: Demonstrating interactive voice in Lo3,2010,0,"Dept. of Computer Science, IIT Bombay, Mumbai, Maharashtra, India",IIT Bombay,1,India,1,1,1,"In this work, we consider the goal of enabling effective voice communication in a TDMA, multi-hop mesh network, using low cost and low power platforms. We consider two primary usage scenarios: (1) enabling a local voice communication within a village-like setting, in developing regions (2) supporting an on-site local communication among a team of users e.g. during emergency response systems. While there is plentiful literature on the use of TDMA for multi-hop wireless mesh networks, a practical multi-hop TDMA system remains elusive. Our contributions in this regard are three-fold. (1) We demonstrate the working of an 802.15.4-based low-cost, low-power, local communication system (referred as Lo3) using custom made handsets and off-the-shelf platforms. (2) We show the practicability of LiT: a full-fledged TDMA-based multi-hop, multi-channel MAC protocol for real-time applications; especially on resource constrained platforms, (3) We present implementation-based evaluations results of LiT and show that our protocol achieves practical synchronization, and robust operation in the face of wireless packet errors. As the part of the demo, we showcase LokVaani: an interactive voice application for local communication with the help of Lo3 prototype.",802.15.4; TDMA-based multi-hop MAC; Voice applications,802.15.4; Developing regions; Emergency response systems; Local communications; Low costs; Low Power; Multi-channel MAC protocols; Multi-hop macs; Multi-hop mesh networks; Multi-hop wireless mesh networks; Multihop; Real-time application; Robust operation; Three folds; Usage scenarios; Voice applications; Wireless packet; Communication systems; Medium access control; Time division multiple access
"Wang G., Andersen D.G., Kaminsky M., Papagiannaki K., Ng T.S.E., Kozuch M., Ryan M.",7,c-Through: Part-time optics in data centers,2010,115,"Rice University, United States; Carnegie Mellon University, United States; Intel Labs. Pittsburgh, United States",Carnegie Mellon University;Intel;Rice University,3,USA,1,41,25,"Data-intensive applications that operate on large volumes of data have motivated a fresh look at the design of data center networks. The first wave of proposals focused on designing pure packet-switched networks that provide full bisection bandwidth. However, these proposals significantly increase network complexity in terms of the number of links and switches required and the restricted rules to wire them up. On the other hand, optical circuit switching technology holds a very large bandwidth advantage over packet switching technology. This fact motivates us to explore how optical circuit switching technology could benefit a data center network. In particular, we propose a hybrid packet and circuit switched data center network architecture (or HyPaC for short) which augments the traditional hierarchy of packet switches with a high speed, low complexity, rack-to-rack optical circuit-switched network to supply high bandwidth to applications. We discuss the fundamental requirements of this hybrid architecture and their design options. To demonstrate the potential benefits of the hybrid architecture, we have built a prototype system called c-Through. c-Through represents a design point where the responsibility for traffic demand estimation and traffic demultiplexing resides in end hosts, making it compatible with existing packet switches. Our emulation experiments show that the hybrid architecture can provide large benefits to unmodified popular data center applications at a modest scale. Furthermore, our experimental experience provides useful insights on the applicability of the hybrid architecture across a range of deployment scenarios. Copyright 2010 ACM.",Data center networking; Hybrid network; Optical circuit switching,Bandwidth advantages; Bisection bandwidth; Circuit-switched networks; Data center networkings; Data center networks; Data centers; Data-intensive application; Deployment scenarios; Design option; Design points; High bandwidth; High Speed; Hybrid architectures; Hybrid network; Large volumes; Network complexity; Optical circuit switching; Optical circuit-switching technology; Packet switches; Packet switching technology; Potential benefits; Prototype system; Traffic demands; Bandwidth; Complex networks; Packet networks; Packet switching; Switching networks; Network architecture
"Sundaresan S., Lumezanu C., Feamster N., Francois P.",4,Autonomous traffic engineering with self-configuring topologies,2010,0,"Georgia Tech., United States; Université Catholique de Louvain, Belgium",Georgia Tech;Universite Catholique de Louvain,2,Belgium;USA,2,9,8,"Network operators use traffic engineering (TE) to control the flow of traffic across their networks. Existing TE methods require manual configuration of link weights or tunnels, which is difficult to get right, or prior knowledge of traffic demands and hence may not be robust to link failures or traffic fluctuations. We present a self-configuring TE scheme, SculpTE, which automatically adapts the network-layer topology to changing traffic demands. SculpTE is responsive, stable, and achieves excellent load balancing.",Multi-path routing; Online; SculpTE; Self-configuring; Traffic engineering,Multi path routing; Online; SculpTE; Self-configuring; Traffic Engineering; Topology; Highway engineering
"Dandapat S.K., Mitra B., Ganguly N., Choudhury R.R.",4,Fair bandwidth allocation in wireless network using max-flow,2010,1,"Department of CSE, IIT Kharagpur, India; Department of ECE and CS, Duke University, United States",Duke University,1,India;USA,2,2,2,"This paper proposes a fair association scheme between clients and APs in WiFi network, exploiting the hybrid nature of the recent WLAN architecture. We show that such an association outperforms RSSI based schemes in several scenarios, while remaining practical and scalable for wide-scale deployment.",Association control; Fairness; Max flow,Association control; Association schemes; Fair bandwidth allocation; Fairness; Max flow; Wi Fi networks; WLAN architectures; Communication; Wi-Fi
"Le F., Xie G.G., Zhang H.",3,Theory and new primitives for safely connecting routing protocol instances,2010,2,"Carnegie Mellon University, United States; Naval Postgraduate School, United States",Carnegie Mellon University;Naval Postgraduate School,2,USA,1,30,23,"Recent studies have shown that the current primitives for connecting multiple routing protocol instances (OSPF 1, OSPF 2, EIGRP 10, etc.) are pervasively deployed in enterprise networks and the Internet. Furthermore, these primitives are extremely vulnerable to routing anomalies (route oscillations, forwarding loops, etc.) and at the same time too rigid to support some of today's operational objectives. In this paper, we propose a new theory to reason about routing properties across multiple routing instances. The theory directly applies to both link-state and vector routing protocols. Each routing protocol still makes independent routing decisions and may consider a combination of routing metrics, including bandwidth, delay, cost, and reliability. While the theory permits a range of solutions, we focus on a design that requires no changes to existing routing protocols. Guided by the theory, we derive a new set of connecting primitives, which are not only provably safe but also more expressive than the current version. We have implemented and validated the new primitives using XORP. The results confirm that our design can support a large range of desirable operational goals, including those not achievable today, safely and with little manual configuration. Copyright 2010 ACM.",Connecting primitives; Route redistribution; Route selection,Connecting primitives; Enterprise networks; Multiple routing; Multiple routing protocols; New theory; Route redistribution; Route Selection; Routing anomalies; Routing decisions; Routing metrics; Internet protocols; Routing protocols
"Wendell P., Jiang J.W., Freedman M.J., Rexford J.",4,DONAR: Decentralized server selection for cloud services,2010,44,"Department of Computer Science, Princeton University, United States",Princeton University,1,USA,1,46,37,"Geo-replicated services need an effective way to direct client requests to a particular location, based on performance, load, and cost. This paper presents DONAR, a distributed system that can offload the burden of replica selection, while providing these services with a sufficiently expressive interface for specifying mapping policies. Most existing approaches for replica selection rely on either central coordination (which has reliability, security, and scalability limitations) or distributed heuristics (which lead to suboptimal request distributions, or even instability). In contrast, the distributed mapping nodes in DONAR run a simple, efficient algorithm to coordinate their replica-selection decisions for clients. The protocol solves an optimization problem that jointly considers both client performance and server load, allowing us to show that the distributed algorithm is stable and effective. Experiments with our DONAR prototype - providing replica selection for CoralCDN and the Measurement Lab - demonstrate that our algorithm performs well ""in the wild."" Our prototype supports DNS- and HTTP-based redirection, IP anycast, and a secure update protocol, and can handle many customer services with diverse policy objectives. Copyright 2010 ACM.",Distributed optimization; DNS; Geo-locality; Load balancing; Replica selection,Anycast; Client request; Cloud services; Customer services; Distributed heuristics; Distributed optimization; Distributed systems; DNS; Expressive interfaces; Geo-locality; Mapping policies; Optimization problems; Policy objectives; Replica selections; Request distributions; Secure updates; Server loads; Server selection; Algorithms; Hypertext systems; Location based services; Optimization; Resource allocation; Internet protocols
"Farrington N., Porter G., Radhakrishnan S., Bazzaz H.H., Subramanya V., Fainman Y., Papen G., Vahdat A.",8,Helios: A hybrid electrical/optical switch architecture for modular data centers,2010,179,"University of California, San Diego, CA, United States",University of California San Diego,1,USA,1,37,8,"The basic building block of ever larger data centers has shifted from a rack to a modular container with hundreds or even thousands of servers. Delivering scalable bandwidth among such containers is a challenge. A number of recent efforts promise full bisection bandwidth between all servers, though with significant cost, complexity, and power consumption. We present Helios, a hybrid electrical/optical switch architecture that can deliver significant reductions in the number of switching elements, cabling, cost, and power consumption relative to recently proposed data center network architectures. We explore architectural trade offs and challenges associated with realizing these benefits through the evaluation of a fully functional HELIOS prototype. Copyright 2010 ACM.",Data center networks; Optical networks,Basic building block; Bisection bandwidth; Data center networks; Data centers; Modular data; Switch architectures; Switching elements; Trade off; Containers; Fiber optic networks; Network architecture
"Rahul H., Hassanieh H., Katabi D.",3,SourceSync: A distributed wireless architecture for exploiting sender diversity,2010,21,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,45,39,"Diversity is an intrinsic property of wireless networks. Recent years have witnessed the emergence of many distributed protocols like ExOR, MORE, SOAR, SOFT, and MIXIT that exploit receiver diversity in 802.11-like networks. In contrast, the dual of receiver diversity, sender diversity, has remained largely elusive to such networks. This paper presents SourceSync, a distributed architecture for harnessing sender diversity. SourceSync enables concurrent senders to synchronize their transmissions to symbol boundaries, and cooperate to forward packets at higher data rates than they could have achieved by transmitting separately. The paper shows that SourceSync improves the performance of opportunistic routing protocols. Specifically, SourceSync allows all nodes that overhear a packet in a wireless mesh to simultaneously transmit it to their nexthops, in contrast to existing opportunistic routing protocols that are forced to pick a single forwarder from among the overhearing nodes. Such simultaneous transmission reduces bit errors and improves throughput. The paper also shows that SourceSync increases the throughput of 802.11 last hop diversity protocols by allowing multiple APs to transmit simultaneously to a client, thereby harnessing sender diversity. We have implemented SourceSync on the FPGA of an 802.11-like radio platform. We have also evaluated our system in an indoor wireless testbed, empirically showing its benefits. Copyright 2010 ACM.",Algorithms; C.2.2 [computer systems organization]: Computer-communications networks; Design; Performance,Bit-errors; Computer systems organization; Data rates; Distributed architecture; Distributed protocols; Distributed wireless; Forward packets; Intrinsic property; Multiple aps; Opportunistic routing; Performance; Radio platforms; Receiver diversity; Simultaneous transmission; Wireless mesh; Wireless testbed; Algorithms; Design; Field programmable gate arrays (FPGA); Routing protocols; Wireless networks
"Mahimkar A., Song H.H., Ge Z., Shaikh A., Wang J., Yates J., Zhang Y., Emmons J.",8,Detecting the performance impact of upgrades in large operational networks,2010,8,"University of Texas, Austin, TX, United States; AT and T Labs. - Research, United States",AT and T Labs;University of Texas at Austin,2,USA,1,41,35,"Networks continue to change to support new applications, improve reliability and performance and reduce the operational cost. The changes are made to the network in the form of upgrades such as software or hardware upgrades, new network or service features and network configuration changes. It is crucial to monitor the network when upgrades are made because they can have a significant impact on network performance and if not monitored may lead to unexpected consequences in operational networks. This can be achieved manually for a small number of devices, but does not scale to large networks with hundreds or thousands of routers and extremely large number of different upgrades made on a regular basis. In this paper, we design and implement a novel infrastructure MERCURY for detecting the impact of network upgrades (or triggers) on performance. MERCURY extracts interesting triggers from a large number of network maintenance activities. It then identifies behavior changes in network performance caused by the triggers. It uses statistical rule mining and network configuration to identify commonality across the behavior changes. We systematically evaluate MERCURY using data collected at a large tier-1 ISP network. By comparing to operational practice, we show that MERCURY is able to capture the interesting triggers and behavior changes induced by the triggers. In some cases, MERCURY also discovers previously unknown network behaviors demonstrating the effectiveness in identifying network conditions flying under the radar. Copyright 2010 ACM.",Change detection; Network upgrades; Performance impact; Statistical data mining,Behavior change; Change detection; Design and implements; Large networks; Network condition; Network configuration; Network maintenances; Network upgrades; New applications; Operational network; Operational practices; Performance impact; Significant impacts; Statistical datas; Statistical rules; Unknown networks; Internet service providers; Network performance; Mercury (metal)
"Nascimento M.R., Rothenberg C.E., Salvador M.R., Magalhães M.F.",4,QuagFlow: Partnering Quagga with OpenFlow,2010,14,"Telecommunications Research and Development Center (CPqD), Campinas - SP, Brazil; University of Campinas (Unicamp), Campinas - SP, Brazil",University of Campinas (Unicamp),1,Brazil,1,8,4,"Computing history has shown that open, multi-layer hardware and software stacks encourage innovation and bring costs down. Only recently this trend is meeting the networking world with the availability of entire open source networking stacks being closer than ever. Towards this goal, we are working on QuagFlow, a transparent interplay between the popular Quagga open source routing suite and the low level vendor-independent OpenFlow interface. QuagFlow is a distributed system implemented as a NOX controller application and a series of slave daemons running along the virtual machines hosting the Quagga routing instances.",C.2.1 [computer-communication networks]: Network architecture and design; Design; Experimentation,Computer communication networks; Computing history; Distributed systems; Experimentation; Hardware and software; Low level; Open sources; Openflow; Virtual machines; Communication; Design; Network architecture
"Riley R.D., Ali N.M., Al-Senaidi K.S., Al-Kuwari A.L.",4,Empowering users against SideJacking attacks,2010,2,"Department of Computer Science and Engineering, Qatar University, Doha, Qatar",Qatar University,1,Qatar,1,2,1,"SideJacking occurs when an attacker intercepts a session cookie and uses it to impersonate a user and gain unauthorized access to a web-based service. To prevent SideJacking, a server should enable HTTPS and configure all session cookies to only be transmitted over a secure link. Many websites do not do this, however, and the user may be unaware. In this work we present a Firefox extension that will allow users to quickly and easily determine whether the server they are visiting is susceptible to SideJacking attacks.","C.2.0 [computer-communication networks]: General-security and protection (e.g., firewalls); K.4.4 [computers and society]: Electronic commerce-security; Security",Computer communication networks; Computers and societies; Firefox; Security; Unauthorized access; Web-based service; Computer system firewalls; Websites; Computer viruses
"Silveira F., Diot C., Taft N., Govindan R.",4,ASTUTE: Detecting a different class of traffic anomalies,2010,8,"Technicolor, France; UPMC Paris Universitas, France; Intel Labs. Berkeley, United States; University of Southern California, United States",Intel;UPMC Paris Universitas;University of Southern California,3,France;USA,2,30,23,"When many flows are multiplexed on a non-saturated link, their volume changes over short timescales tend to cancel each other out, making the average change across flows close to zero. This equilibrium property holds if the flows are nearly independent, and it is violated by traffic changes caused by several, potentially small, correlated flows. Many traffic anomalies (both malicious and benign) fit this description. Based on this observation, we exploit equilibrium to design a computationally simple detection method for correlated anomalous flows. We compare our new method to two well known techniques on three network links. We manually classify the anomalies detected by the three methods, and discover that our method uncovers a different class of anomalies than previous techniques do. Copyright 2010 ACM.",Anomaly detection; Statistical test,Anomaly detection; Detection methods; Different class; Equilibrium properties; Three networks; Time-scales; Traffic anomalies; Volume change; Communication; Statistical tests
"Lai Y.-J., Kuo W.-H., Chiu W.-T., Chang S.-T., Wei H.-Y.",5,Accelerometer-assisted 802.11 rate adaptation on mass rapid transit system,2010,1,"Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan",National Taiwan University,1,Taiwan,1,4,3,"In-station Wi-Fi AP deployment provides opportunistic Wi-Fi access in underground Mass Rapid Transit (MRT) system. But such vehicular network faces the obstacle of limited connection time from the MS on the train to the BS at the station. Therefore, maximizing the throughput during the tens of second intervals becomes crucial to overcome such hindrance. To achieve the goal, we propose Accelerometer-Assisted Rate Adaptation (AARA) to divide the motion of the train into four phases; each adopts a specific rate adaptation mechanism. The experiments show that the average throughput of AARA outperforms that of the conventional scheme.",C.2.1 [computer-communication networks]: Network architecture and design - Wireless communication; Design; Experimentation; Performance,Average throughput; Conventional schemes; Experimentation; Mass rapid transit; Mass rapid transit systems; Performance; Rate adaptation; Vehicular networks; Wireless communications; Accelerometers; Design; Experiments; Network architecture; Wi-Fi; Wireless telecommunication systems; Mass transportation
"Wang T., Chen Y., Zhang Z., Sun P., Deng B., Li X.",6,Unbiased sampling in directed social graph,2010,5,"Department of Electronic Engineering, Tsinghua University, Beijing, China; Institute of Computer Science, University of Goettingen, Goettingen, Germany; Department of Computer Science, University of California, Santa Barbara, CA, United States",Tsinghua University;University of California Santa Barbara;University of Goettingen,3,China;Germany;USA,3,4,3,"Microblogging services, such as Twitter, are among the most important online social networks(OSNs). Different from OSNs such as Facebook, the topology of microblogging service is a directed graph instead of an undirected graph. Recently, due to the explosive increase of population size, graph sampling has started to play a critical role in measurement and characterization studies of such OSNs. However, previous studies have only focused on the unbiased sampling of undirected social graphs. In this paper, we study the unbiased sampling algorithm for directed social graphs. Based on the traditional Metropolis-Hasting Random Walk (MHRW) algorithm, we propose an unbiased sampling method for directed social graphs(USDSG). Using this method, we get the first, to the best of our knowledge, unbiased sample of directed social graphs. Through extensive experiments comparing with the ""ground truth"" (UNI, obtained through uniform sampling of directed graph nodes), we show that our method can achieve excellent performance in directed graph sampling and the error to UNI is less than 10%.",Graph sampling; Online social network; Unbias,Characterization studies; Facebook; Graph samplings; Ground truth; Micro-blogging services; On-line social networks; Online social networks (OSNs); Population sizes; Random Walk; Social graphs; Unbias; Unbiased samplings; Undirected graph; Uniform sampling; Algorithms; Graphic methods; Online systems; Population statistics; Social networking (online); Topology; Directed graphs
"Han S., Jang K., Park K., Moon S.",4,PacketShader: A GPU-accelerated software router,2010,121,"Department of Computer Science, KAIST, South Korea; Department of Electrical Engineering, KAIST, South Korea",KAIST,1,South Korea,1,55,32,"We present PacketShader, a high-performance software router framework for general packet processing with Graphics Processing Unit (GPU) acceleration. PacketShader exploits the massively-parallel processing power of GPU to address the CPU bottleneck in current software routers. Combined with our high-performance packet I/O engine, PacketShader outperforms existing software routers by more than a factor of four, forwarding 64B IPv4 packets at 39 Gbps on a single commodity PC. We have implemented IPv4 and IPv6 forwarding, OpenFlow switching, and IPsec tunneling to demonstrate the flexibility and performance advantage of PacketShader. The evaluation results show that GPU brings significantly higher throughput over the CPU-only implementation, confirming the effectiveness of GPU for computation and memory-intensive operations in packet processing. Copyright 2010 ACM.",CUDA; GPU; Software router,CUDA; Evaluation results; GPU; GPU-accelerated; Graphics Processing Unit; IPSec tunneling; Openflow; Packet processing; Processing power; Software routers; Computer graphics; Internet protocols; Packet networks; Personal computers; Program processors; Computer graphics equipment
"Lee K., Rhee I., Lee J., Yi Y., Chong S.",5,Mobile data offloading: How much can WiFi deliver?,2010,6,"Department of Computer Science, North Carolina State University, Raleigh, NC 27695, United States; Department of Electrical Engineering, KAIST, Daejeon, South Korea",KAIST;North Carolina State University,2,South Korea;USA,2,1,2,"This is a quantitative study on the performance of 3G mobile data offloading through WiFi networks. We recruited about 100 iPhone users from a metropolitan area and collected statistics on their WiFi connectivity during about a two and half week period in February 2010. We find that a user is in WiFi coverage for 70% of the time on average and the distributions of WiFi connection and disconnection times have a strong heavy-tail tendency with means around 2 hours and 40 minutes, respectively. Using the acquired traces, we run trace-driven simulation to measure offloading efficiency under diverse conditions e.g. traffic types, deadlines and WiFi deployment scenarios. The results indicate that if users can tolerate a two hour delay in data transfer (e.g, video and image up-loads), the network can offload 70% of the total 3G data traffic on average. We also develop a theoretical framework that permits an analytical study of the average performance of offloading. This tool is useful for network providers to obtain a rough estimate on the average performance of offloading for a given input WiFi deployment condition.",Delayed transmission; Experimental networks; Mobile data offloading,3G mobile; Analytical studies; Data traffic; Heavy-tails; Metropolitan area; Mobile data offloading; Network provider; Quantitative study; Theoretical framework; Trace driven simulation; Wi Fi networks; Wi-Fi connections; Wi-Fi deployment; Data transfer; Digital storage; Wi-Fi
"Zhao J., Zhang X., Wang X., Xue X.",4,Achieving O(1) IP lookup on GPU-based software routers,2010,5,"School of Computer Science, Fudan University, Shanghai, China",Fudan University,1,China,1,5,3,"IP address lookup is a challenging problem due to the increasing routing table size, and higher line rate. This paper investigates a new way to build an efficient IP lookup scheme using graphics processor units(GPU). Our contribution here is to design a basic architecture for high-performance IP lookup engine with GPU, and to develop efficient algorithms for routing prefix operations such as lookup, deletion, insertion, and modification. In particular, the IP lookup scheme can achieve O(1) time complexity. Our experimental results on real-world route traces show promising 6x gains in IP lookup throughput.",GPU; IP lookup; Software router,GPU; Gpu-based; Graphics processor units; IP address lookup; IP lookup; Line rate; Lookups; Real-world; Routing table; Software routers; Time complexity; Algorithms; Program processors; Data communication systems
"Lee M., Duffield N., Kompella R.R.",3,Not all microseconds are equal: Fine-grained per-flow measurements with reference latency interpolation,2010,5,"Purdue University, United States; AT and T Labs. - Research, United States",AT and T Labs;Purdue University,2,USA,1,40,27,"New applications such as algorithmic trading and high-performance computing require extremely low latency (in microseconds). Network operators today lack sufficient fine-grain measurement tools to detect, localize and repair performance anomalies and delay spikes that cause application SLA violations. A recently proposed solution called LDA provides a scalable way to obtain latency, but only provides aggregate measurements. However, debugging application-specific problems requires per-flow measurements, since different flows may exhibit significantly different characteristics even when they are traversing the same link. To enable fine-grained per-flow measurements in routers, we propose a new scalable architecture called reference latency interpolation (RLI) that is based on our observation that packets potentially belonging to different flows that are closely spaced to each other exhibit similar delay properties. In our evaluation using simulations over real traces, we show that RLI achieves a median relative error of 12% and one to two orders of magnitude higher accuracy than previous per-flow measurement solutions with small overhead. Copyright 2010 ACM.",Active measurement; Approximation,Active measurement; Algorithmic trading; Approximation; Closely spaced; Delay spikes; Fine grains; High-performance computing; Low latency; Measurement tools; Network operator; New applications; Orders of magnitude; Performance anomaly; Real trace; Relative errors; Scalable architectures; Computer architecture; Interpolation; Measurements; Flow measurement
"Burnett S., Feamster N., Vempala S.",3,Circumventing censorship with collage,2010,0,"School of Computer Science, Georgia Tech., Atlanta, GA, United States",Georgia Tech,1,USA,1,7,6,"Oppressive regimes and even democratic governments restrict Internet access. Existing anti-censorship systems often require users to connect through proxies, but these systems are relatively easy for a censor to discover and block. We explore a possible next step in the censorship arms race: rather than relying on a single system or set of proxies to circumvent censorship firewalls, we use the vast deployment of sites that host user-generated content to breach these firewalls. We have developed Collage, which allows users to exchange messages through hidden channels in sites that host user-generated content. To send a message, a user embeds it into cover traffic and posts the content on some site, where receivers retrieve this content. Collage makes it difficult for a censor to monitor or block these messages by exploiting the sheer number of sites where users can exchange messages and the variety of ways that a message can be hidden. We have built a censorship-resistant news reader using Collage that can retrieve from behind a censorship firewall and show Collage's effectiveness with a live demonstration of its complete infrastructure.",Anti-censorship,Anti-censorship; Censorship resistants; Democratic government; Internet access; User-generated content; Communication
"Liu X., Yang X., Xia Y.",3,NetFence: Preventing internet denial of service from inside out,2010,20,"Dept. of Computer Science, Duke University, United States; Networking Systems Group, NEC Labs. China, China",Duke University,1,China;USA,2,48,40,"Denial of Service (DoS) attacks frequently happen on the Internet, paralyzing Internet services and causing millions of dollars of financial loss. This work presents NetFence, a scalable DoS-resistant network architecture. NetFence uses a novel mechanism, secure congestion policing feedback, to enable robust congestion policing inside the network. Bottleneck routers update the feedback in packet headers to signal congestion, and access routers use it to police senders' traffic. Targeted DoS victims can use the secure congestion policing feedback as capability tokens to suppress unwanted traffic. When compromised senders and receivers organize into pairs to congest a network link, NetFence provably guarantees a legitimate sender its fair share of network resources without keeping per-host state at the congested link. We use a Linux implementation, ns-2 simulations, and theoretical analysis to show that NetFence is an effective and scalable DoS solution: it reduces the amount of state maintained by a congested router from per-host to at most per-(Autonomous System). Copyright 2010 ACM.",Capability; Congestion policing; Denial of service; Internet,Access Routers; Autonomous systems; Bottleneck router; Capability; Congested links; Congestion policing; Denial of Service; Denial of service attacks; Fair share; Financial loss; Internet services; Linux implementation; Network links; Network resource; NS-2 simulations; Packet header; Unwanted traffic; Computer operating systems; Internet; Losses; Mobile telecommunication systems; Network architecture; Routers; Transmission control protocol; Traffic congestion
"Joshi A.U., Kulkarni P.",2,Vehicular WiFi access and rate adaptation,2010,0,"Department of Computer Science and Engineering, Indian Institute of Technology Bombay, Mumbai, India",IIT Bombay,1,India,1,6,6,"Vehicular WiFi access is distinct in two respects, (i) continuous mobility of clients and (ii) possibility of predictable link quality. As part of this study, we aim to comprehensively evaluate existing rate adaptation algorithms in real environments. Further, if required, we aim to develop a simple, low-overhead rate adaptation algorithm suited for vehicular WiFi access.",Mobility; Rate adaptation; WiFi,Link quality; Rate adaptation; Real environments; Algorithms; Carrier mobility; Wi-Fi
"Abu-Libdeh H., Costa P., Rowstron A., O'Shea G., Donnelly A.",5,Symbiotic routing in future data centers,2010,54,"Microsoft Research, Cambridge, United Kingdom",Microsoft,1,UK,1,31,27,"Building distributed applications that run in data centers is hard. The CamCube project explores the design of a shipping container sized data center with the goal of building an easier platform on which to build these applications. CamCube replaces the traditional switch-based network with a 3D torus topology, with each server directly connected to six other servers. As in other proposals, e.g. DCell and BCube, multi-hop routing in CamCube requires servers to participate in packet forwarding. To date, as in existing data centers, these approaches have all provided a single routing protocol for the applications. In this paper we explore if allowing applications to implement their own routing services is advantageous, and if we can support it efficiently. This is based on the observation that, due to the flexibility offered by the CamCube API, many applications implemented their own routing protocol in order to achieve specific application-level characteristics, such as trading off higher-latency for better path convergence. Using large-scale simulations we demonstrate the benefits and network-level impact of running multiple routing protocols. We demonstrate that applications are more efficient and do not generate additional control traffic overhead. This motivates us to design an extended routing service allowing easy implementation of application-specific routing protocols on CamCube. Finally, we demonstrate that the additional performance overhead incurred when using the extended routing service on a prototype CamCube is very low. Copyright 2010 ACM.",Data centers; Key-value stores; Routing protocols,Additional control; Data centers; Distributed applications; Key-value stores; Large scale simulations; Multi-hop routing; Multiple routing protocols; Packet forwarding; Routing services; Shipping containers; Switch-based networks; Application programming interfaces (API); Computer simulation; Switching circuits; Routing protocols
Wang Y.,1,SIP overload control: A backpressure-based approach,2010,6,"Department of Computer Science, North Carolina State University, Raleigh, NC 27695-8206, United States",North Carolina State University,1,USA,1,10,7,"Overload happens in Session Initiation Protocol (SIP) networks when SIP servers have insufficient resources to handle all messages they receive. Under overload, SIP networks suffer from congestion collapse due to its ineffective overload control mechanism. In this paper we propose a backpressure-based SIP overload control mechanism called Bassoon. It consists of two parts: the first part is a provably optimal load balancing algorithm that ensures full utilization of the available network resources. The second part is an end-to-end load control algorithm that intelligently throttles excessive traffic at the edge of the network. We show that, by combining optimal load balancing and end-to-end load control, Bassoon effectively controls overload in SIP networks and outperforms existing schemes in terms of goodput, fairness and responsiveness.",Goodput; Load balancing; Load control; SIP,Congestion collapse; Good put; Network resource; Optimal load balancing; Overload control; Session initiation protocol; SIP; Sip overloads; SIP server; Two parts; Algorithms; Congestion control (communication); Load limits; Optimization; Parallel architectures; Press load control; Resource allocation; Internet protocols
"Kounavis M.E., Kang X., Grewal K., Eszenyi M., Gueron S., Durham D.",6,Encrypting the internet,2010,4,"Intel Architecture Group, 2111 NE 25th Avenue, Hillsboro, OR 97124, United States; Intel Labs., 2111 NE 25th Avenue, Hillsboro, OR 97124, United States; Intel Architecture Group, Israel Development Center, Haifa, Israel",Intel;Israel Development Center,2,Israel;USA,2,48,27,"End-to-end communication encryption is considered necessary for protecting the privacy of user data in the Internet. Only a small fraction of all Internet traffic, however, is protected today. The primary reason for this neglect is economic, mainly security protocol speed and cost. In this paper we argue that recent advances in the implementation of cryptographic algorithms can make general purpose processors capable of encrypting packets at line rates. This implies that the Internet can be gradually transformed to an information delivery infrastructure where all traffic is encrypted and authenticated. We justify our claim by presenting technologies that accelerate end-to-end encryption and authentication by a factor of 6 and a high performance TLS 1.2 protocol implementation that takes advantage of these innovations. Our implementation is available in the public domain for experimentation. Copyright 2010 ACM.",AES; Cryptographic algorithm acceleration; GCM; HTTPS; RSA; Secure communications; SSL; TLS,AES; Cryptographic algorithms; GCM; HTTPS; RSA; Secure communications; SSL; TLS; Algorithms; Authentication; HTTP; Innovation; Internet; Internet protocols; Cryptography
"Anwer M.B., Motiwala M., Tariq M.B., Feamster N.",4,SwitchBlade: A platform for rapid deployment of network protocols on programmable hardware,2010,25,"School of Computer Science, Georgia Tech., United States",Georgia Tech,1,USA,1,24,16,"We present SwitchBlade, a platform for rapidly deploying custom protocols on programmable hardware. SwitchBlade uses a pipeline-based design that allows individual hardware modules to be enabled or disabled on the fly, integrates software exception handling, and provides support for forwarding based on custom header fields. SwitchBlade's ease of programmability and wire-speed performance enables rapid prototyping of custom data-plane functions that can be directly deployed in a production network. SwitchBlade integrates common packet-processing functions as hardware modules, enabling different protocols to use these functions without having to resynthesize hardware. SwitchBlade's customizable forwarding engine supports both longest-prefix matching in the packet header and exact matching on a hash value. SwitchBlade's software exceptions can be invoked based on either packet or flow-based rules and updated quickly at runtime, thus making it easy to integrate more flexible forwarding function into the pipeline. SwitchBlade also allows multiple custom data planes to operate in parallel on the same physical hardware, while providing complete isolation for protocols running in parallel. We implemented SwitchBlade using NetFPGA board, but SwitchBlade can be implemented with any FPGA. To demonstrate SwitchBlade's flexibility, we use SwitchBlade to implement and evaluate a variety of custom network protocols: we present instances of IPv4, IPv6, Path Splicing, and an OpenFlow switch, all running in parallel while forwarding packets at line rate. Copyright 2010 ACM.",NetFPGA; Network virtualization,Custom protocols; Customizable; Data planes; Data-plane; Different protocols; Exact matching; Exception handling; Hardware modules; Hash value; Line rate; Longest-prefix matching; NetFPGA; Network virtualization; On the flies; Openflow switches; Packet header; Production network; Programmability; Programmable hardware; Rapid deployments; Running-in; Runtimes; Field programmable gate arrays (FPGA); Internet protocols; Network protocols; Rapid prototyping; Hardware
"Alizadeh M., Greenberg A., Maltz D.A., Padhye J., Patel P., Prabhakar B., Sengupta S., Sridharan M.",8,Data Center TCP (DCTCP),2010,148,"Microsoft Research, India; Stanford University, United States",Microsoft;Stanford University,2,India;USA,2,34,25,"Cloud data centers host diverse applications, mixing workloads that require small predictable latency with others requiring large sustained throughput. In this environment, today's state-of-the-art TCP protocol falls short. We present measurements of a 6000 server production cluster and reveal impairments that lead to high application latencies, rooted in TCP's demands on the limited buffer space available in data center switches. For example, bandwidth hungry ""background"" flows build up queues at the switches, and thus impact the performance of latency sensitive ""foreground"" traffic. To address these problems, we propose DCTCP, a TCP-like protocol for data center networks. DCTCP leverages Explicit Congestion Notification (ECN) in the network to provide multi-bit feedback to the end hosts. We evaluate DCTCP at 1 and 10Gbps speeds using commodity, shallow buffered switches. We find DCTCP delivers the same or better throughput than TCP, while using 90% less buffer space. Unlike TCP, DCTCP also provides high burst tolerance and low latency for short flows. In handling workloads derived from operational measurements, we found DCTCP enables the applications to handle 10X the current background traffic, without impacting foreground traffic. Further, a 10X increase in foreground traffic does not cause any timeouts, thus largely eliminating incast problems. Copyright 2010 ACM.",Data center network; ECN; TCP,Background traffic; Buffer space; Cloud data centers; Data center networks; Data centers; Diverse applications; ECN; Explicit congestion notification; Limited buffer spaces; Low latency; Measurements of; Multi-bit feedback; TCP; TCP protocol; Communication; Transmission control protocol
"Goldberg S., Schapira M., Hummon P., Rexford J.",4,How secure are secure interdomain routing protocols,2010,11,"Microsoft Research, India; Yale and UC Berkeley, United States; AT and T Research, United States",AT and T Labs;Microsoft;Yale University;University of California Berkeley,4,India;USA,2,21,18,"In response to high-profile Internet outages, BGP security variants have been proposed to prevent the propagation of bogus routing information. To inform discussions of which variant should be deployed in the Internet, we quantify the ability of the main protocols (origin authentication, soBGP, S-BGP, and data-plane verification) to blunt traffic-attraction attacks; i.e., an attacker that deliberately attracts traffic to drop, tamper, or eavesdrop on packets. Intuition suggests that an attacker can maximize the traffic he attracts by widely announcing a short path that is not flagged as bogus by the secure protocol. Through simulations on an empirically-determined AS-level topology, we show that this strategy is surprisingly effective, even when the network uses an advanced security solution like S-BGP or data-plane verification. Worse yet, we show that these results underestimate the severity of attacks. We prove that finding the most damaging strategy is NP-hard, and show how counterintuitive strategies, like announcing longer paths, announcing to fewer neighbors, or triggering BGP loop-detection, can be used to attract even more traffic than the strategy above. These counterintuitive examples are not merely hypothetical; we searched the empirical AS topology to identify specific ASes that can launch them. Finally, we find that a clever export policy can often attract almost as much traffic as a bogus path announcement. Thus, our work implies that mechanisms that police export policies (e.g., defensive filtering) are crucial, even if S-BGP is fully deployed. Copyright 2010 ACM.",C.2.2 computer communication networks: Network Protocols; Security,AS topologies; Bgp securities; Computer communication networks; Data-plane; Export policy; NP-hard; Origin authentications; Routing information; Secure inter-domain routing; Secure protocols; Security; Security solutions; Short-path; Computer simulation; Internet; Network protocols; Topology; Internet protocols
"Vamanan B., Voskuilen G., Vijaykumar T.N.",3,EffiCuts: Optimizing packet classification for memory and throughput,2010,45,"School of Electrical and Computer Engineering, Purdue University, United States",Purdue University,1,USA,1,17,11,"Packet Classification is a key functionality provided by modern routers. Previous decision-tree algorithms, HiCuts and HyperCuts, cut the multi-dimensional rule space to separate a classifier's rules. Despite their optimizations, the algorithms incur considerable memory overhead due to two issues: (1) Many rules in a classifier overlap and the overlapping rules vary vastly in size, causing the algorithms' fine cuts for separating the small rules to replicate the large rules. (2) Because a classifier's rule-space density varies significantly, the algorithms' equi-sized cuts for separating the dense parts needlessly partition the sparse parts, resulting in many ineffectual nodes that hold only a few rules. We propose EffiCuts which employs four novel ideas: (1) Separable trees: To eliminate overlap among small and large rules, we separate all small and large rules. We define a subset of rules to be separable if all the rules are either small or large in each dimension. We build a distinct tree for each such subset where each dimension can be cut coarsely to separate the large rules, or finely to separate the small rules without incurring replication. (2) Selective tree merging: To reduce the multiple trees' extra accesses which degrade throughput, we selectively merge separable trees mixing rules that may be small or large in at most one dimension. (3) Equi-dense cuts: We employ unequal cuts which distribute a node's rules evenly among the children, avoiding ineffectual nodes at the cost of a small processing overhead in the tree traversal. (4) Node Co-location: To achieve fewer accesses per node than HiCuts and HyperCuts, we co-locate parts of a node and its children. Using ClassBench, we show that for similar throughput EffiCuts needs factors of 57 less memory than HyperCuts and of 4-8 less power than TCAM. Copyright 2010 ACM.",Decision-tree algorithm; Packet classification; Rule replication,Colocations; Decision-tree algorithm; Memory overheads; Mixing rules; Multiple trees; One dimension; Packet classification; Processing overhead; Rule replication; Rule-space; Tree traversal; Algorithms; Optimization; Packet networks; Separation; Ternary content adressable memory; Throughput; Forestry
"Barré S., Bonaventure O., Raiciu C., Handley M.",4,Experimenting with multipath TCP,2010,6,"Université Catholique de Louvain, B-1348 Louvain-la-Neuve, Belgium; University College of London, United Kingdom",University College London;Universite Catholique de Louvain,2,Belgium;UK,2,10,10,"It is becoming the norm for small mobile devices to have access to multiple technologies for connecting to the Internet. This gives researchers an increasing interest for solutions allowing to use efficiently several communication mediums. We propose a demonstration of our Multipath TCP implementation for Linux, that allows spreading a single TCP flow across multiple Internet paths, without requiring any change to applications. The demonstration will involve a real Internet communication with MPTCP, with simultaneous use of several paths, as well as a demonstration of MPTCP failover capability.",C.2.2 [computer systems organization]: Computer communication networks networks protocols; Experimentation,Communication medium; Computer communication networks; Experimentation; Failover; Internet communication; Internet paths; Multipath TCP; Multiple technology; Simultaneous use; TCP flows; Communication; Computer operating systems; Demonstrations; Internet; Mobile devices; Mobile telecommunication systems; Telecommunication networks; Transmission control protocol
"Chen B., Zhou Z., Zhao Y., Yu H.",4,Efficient error estimating coding: Feasibility and applications,2010,2,"National University of Singapore, Singapore, Singapore",National University of Singapore,1,Singapore,1,40,36,"Motivated by recent emerging systems that can leverage partially correct packets in wireless networks, this paper investigates the novel concept of error estimating codes (EEC). Without correcting the errors in the packet, EEC enables the receiver of the packet to estimate the packet's bit error rate, which is perhaps the most important meta-information of a partially correct packet. Our EEC algorithm provides provable estimation quality, with rather low redundancy and computational overhead. To demonstrate the utility of EEC, we exploit and implement EEC in two wireless network applications, Wi-Fi rate adaptation and real-time video streaming. Our real-world experiments show that these applications can significantly benefit from EEC. Copyright 2010 ACM.",Bit error rate; Error correcting coding; Error estimating coding; Partial packet; Partially correct packet,Computational overheads; Error estimating coding; Error-correcting coding; Estimation quality; Meta information; Network applications; Novel concept; Partial packets; Partially correct packets; Rate adaptation; Real world experiment; Real-time videostreaming; Bit error rate; Video streaming; Wireless networks
"Bayer N., Loziak K., Garcia-Saavedra A., Sengul C., Serrano P.",5,CARMEN: Resource management and abstraction in wireless heterogeneous mesh networks,2010,0,"Deutsche Telekom Labs., Germany; AGH, University of Science and Technology, Poland; Universidad Carlos III de Madrid, Spain",University Carlos III of Madrid;University of Science and Technology of China,2,Germany;Poland;Spain,3,2,1,"Even though current mesh networks are mostly WiFi-based, future networks are expected to be highly heterogeneous. Motivated by this expectation, CARMEN (CARrier grade MEsh Networks) project focuses on developing a heterogeneous mesh backhaul to provide carrier-grade (voice, video and data) services. This demo presents resource management and abstraction in CARMEN architecture, which allow meeting the challenges of heterogeneous radio access.",Heterogeneous; Resource abstraction; Wireless mesh,Carrier grades; Future networks; Heterogeneous; Mesh network; Radio access; Resource abstraction; Resource management; Video and datum; Wireless mesh; Abstracting; Natural resources management; Resource allocation; MESH networking
"Yao G., Bi J., Zhou Z.",3,Passive IP traceback: Capturing the origin of anonymous traffic through network telescopes,2010,1,"Network Research Center, Tsinghua University, Beijing 100084, China",Tsinghua University,1,China,1,6,4,"IP traceback can be used to find the origin of anonymous traffic; however, Internet-scale IP traceback systems have not been deployed due to a need for cooperation between Internet Service Providers (ISPs). This article presents an Internet-scale Passive IP Trackback (PIT) mechanism that does not require ISP deployment. PIT analyzes the ICMP messages that may scattered to a network telescope as spoofed packets travel from attacker to victim. An Internet route model is then used to help re-construct the attack path. Applying this mechanism to data collected by Cooperative Association for Internet Data Analysis (CAIDA), we found PIT can construct a trace tree from at least one intermediate router in 55.4% the fiercest packet spoofing attacks, and can construct a tree from at least 10 routers in 23.4% of attacks. This initial result shows PIT is a promising mechanism.",IP traceback; Network telescope,Attack path; Intermediate routers; Internet data; Internet routes; IP Traceback; Network telescopes; Spoofing attacks; Forestry; Internet protocols; Optical telescopes; Routers; Telescopes; Trace analysis; Trees (mathematics); Internet service providers
"Oprescu I., Meulle M., Uhlig S., Pelsser C., Maennel O., Owezarski P.",6,Rethinking iBGP routing,2010,0,"Orange Labs., CNRS-LAAS, France; Orange Labs., France; Deutsche Telekom Laboratories, TU Berlin, Germany; Internet Initiative Japan, Japan; University of Loughborough, United Kingdom; CNRS-LAAS, France",Deutsche Telekom Laboratories;TU Berlin;University of Loughborough,3,France;Germany;Japan;UK,4,5,5,"The Internet is organized as a collection of administrative domains, known as Autonomous Systems (ASes). These ASes interact through the Border Gateway Protocol (BGP) that allows them to share reachability information. Adjacent routers in distinct ASes use external BGP (eBGP), whereas in a given AS routes are propagated over internal BGP (iBGP) sessions between any pair of routers. In large ASes where a logical full-mesh is not possible, confederations or route reflectors (RRs) are used. However, these somewhat scalable alternatives have introduced their own set of unpredictable effects (persistent routing oscillations and forwarding loops causing an increase of the convergence time) addressed in the literature [1]. The solution we propose to these issues consists of a structured routing overlay holding a comprehensive view of the routes. We describe the design of a distributed entity that performs BGP route pre-computation for its clients inside a large backbone network and propagates the paths to the routers. Compared to the current iBGP routing, the advantage of the overlay approach is the separation between the responsibility of the control plane (route storage and best path computation) and the forwarding of the packets. One of the major improvements we bring is the divided routing table tackling the scalability concerns and allowing for parallel computation of paths.",C.2.3 [network operations]: Network management; Design; Management,Autonomous systems; Back-bone network; Best paths; Border gateway protocol; Control planes; Convergence time; Distributed entity; Network operations; Parallel Computation; Reachability; Route pre-computation; Route reflectors; Routing table; Design; Distributed computer systems; Internet protocols; Management; Network management; Gateways (computer networks)
"Jakubczak S., Katabi D.",2,SoftCast: One-size-fits-all wireless video,2010,19,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,12,6,"The focus of this demonstration is the performance of streaming video over the mobile wireless channel. We compare two schemes: the standard approach to video which transmits H.264/AVC-encoded stream over 802.11-like PHY, and SoftCast - a clean-slate design for wireless video where the source transmits one video stream that each receiver decodes to a video quality commensurate with its specific instantaneous channel quality.",Joint source-channel coding; Scalable video communications; Wireless networks,Channel quality; Clean slates; Joint source-channel coding; Mobile wireless channels; Scalable video; Streaming videos; Video quality; Video streams; Wireless video; Motion Picture Experts Group standards; Video streaming; Wireless networks
"Zhang J., Tan K., Xiang S., Yin Q., Luo Q., He Y., Fang J., Zhang Y.",8,Experimenting software radio with the Sora platform,2010,1,"Microsoft Research Asia, Beijing, China",Microsoft,1,China,1,5,1,"Sora is a fully programmable, high performance software radio platform based on commodity general-purpose PC. In this demonstration, we illustrate the main features of the Sora platform that provide researchers flexible and powerful means to conduct wireless experiments at different levels with various goals. Specifically, the demonstrator will show four useful applications for wireless research that are built based on the Sora platform: 1) A capture tool that allows one to take a snapshot on a wireless channel; 2) a signal generation tool that allows one to transmit arbitrary baseband wave-form over the air, from a monophonic tone to a complex modulated frame; 3) an on-line real-time receiving application that uses the Sora User-Mode Extension; and 4) a fully featured Software radio WiFi driver (SoftWiFi) that can seamlessly inter-operate with commercial WiFi cards.",Software radio; Sora; Wireless experiment,Base bands; Fully programmables; Over the airs; Signal generation; Software radio platform; Sora; Wireless channel; Experiments; Signal generators; Software radio; Wi-Fi
"Lee J., Tourrilhes J., Sharma P., Banerjee S.",4,No more middlebox: Integrate processing into network,2010,6,"Hewlett-Packard Laboratories, Palo Alto, CA, United States",HP Labs,1,USA,1,8,5,"Traditionally, in-network services like firewall, proxy, cache, and transcoders have been provided by dedicated hardware middleboxes. A recent trend has been to remove the middleboxes by deploying the network services into switch/router-integrated computing modules or separate server/blade machines. In this abstract, by using a web Ad-insertion application as an example, we demonstrate our in-network processing (INP) framework that orchestrates various computing resources and network devices and enables seamless and efficient deployments of network services.",Controller; In-network processing; Middlebox,Computing resource; Dedicated hardware; In-network processing; In-network services; InP; Middleboxes; Network devices; Network services; Recent trends; Trans-coders; Controllers; Proxy caches; Computer system firewalls
Bozakov Z.,1,An open router virtualization framework using a programmable forwarding plane,2010,2,"Institute for Communication Technology, Leibniz Universität Hannover, Germany",Leibniz Universität Hannover,1,Germany,1,5,5,"Network virtualization promises to spur innovation and add flexibility to the Future Internet infrastructure. Routers supporting virtualization allow the deployment of concurrent virtual networks, and can be employed to consolidate resources and improve energy efficiency in data centers. The closed nature of commercial router systems poses a significant problem for research in the field of virtual network architectures. On the other hand, the performance of software-based, open routing solutions is typically limited. In this work we outline an open router virtualization framework utilizing OpenFlow enabled hardware as a fast, programmable forwarding plane.",Commodity hardware; OpenFlow; Routers; Virtualization,Commercial routers; Commodity hardware; Data centers; Forwarding planes; Future internet; Network virtualization; Open router; Openflow; Software-based; Virtual networks; Virtualizations; Energy efficiency; Hardware; Network architecture; Virtual reality; Routers
"Santos T., Henke C., Schmoll C., Zseby T.",4,Multi-hop packet tracking for experimental facilities,2010,1,"Fraunhofer FOKUS, Kaiserin-Augusta-Allee 31, 10589 Berlin, Germany; Technical University Berlin, Str. des 17. Juni 135, 10623 Berlin, Germany",TU Berlin,1,Germany,1,6,5,"The Internet has become a complex system with increasing numbers of end-systems, applications, protocols and types of networks. Although we have a good understanding of how data is transferred over the network we cannot observe what happens with our data after sending and before receiving it - how packets traverse through the network and with which QoS characteristics remains unknown. Towards this objective we have developed a multi-hop packet tracking system intended to be used in experimental facilities, such as PlanetLab, where we have made our first tests. This paper describes our packet tracking realization and the results from our prototype implementation.",Hash-based packet selection; IPFIX; Multipoint measurement,End-systems; Experimental facilities; Hash-based packet selection; IPFIX; Multihop; Multipoint measurement; PlanetLab; Prototype implementations; Tracking system; Communication; Internet protocols
"Xu T., Chen Y., Fu X., Hui P.",4,Twittering by Cuckoo - Decentralized and socio-aware online microblogging services,2010,1,"Institute of Computer Science, University of Goettingen, Goettingen, Germany; State Key Lab. for Novel Software and Technology, Nanjing University, Nanjing, China; Deutsche Telekom Laboratories, TU-Berlin, Berlin, Germany",Deutsche Telekom Laboratories;Institute of Computer Science;Nanjing University;TU Berlin;University of Goettingen,5,China;Germany,2,6,5,"Online microblogging services, as exemplified by Twitter, have become immensely popular during the latest years. However, current microblogging systems severely suffer from performance bottlenecks and malicious attacks due to the centralized architecture. As a result, centralized microblogging systems may threaten the scalability, reliability as well as availability of the offered services, not to mention the high operational and maintenance cost. This demo presents a decentralized, socio-aware microblogging system named Cuckoo. The key aspects of Cuckoo's design is to take advantage of the inherent social relations while leveraging peer-to-peer (P2P) techniques in order to provide scalable, reliable microblogging services. The demo will show these aspects of Cuckoo and provide insights on the performance gain that decentralization and socio-awareness can bring for microblogging systems.",Microblogging services; Online social networking; Peer-to-peer systems,Centralized architecture; Maintenance cost; Malicious attack; Micro-blogging services; Microblogging; Online social networkings; Peer-to-Peer system; Peer-to-peer techniques; Performance bottlenecks; Performance Gain; Social relations; Communication; Social networking (online)
"Rajendra C.V., Kulkarni P.",2,Road traffic estimation using in-situ acoustic sensing,2010,1,"Department of Computer Science and Engineering, Indian Institute of Technology Bombay, United States",IIT Bombay,1,India;USA,2,5,5,"In this paper, we explore the efficacy of curb-side acoustic sensing to estimate road traffic conditions. We formulated a set of hypotheses which attempted to correlate traffic conditions with the ambient traffic noise. We present the evaluation of our hypotheses under various traffic conditions. Our threshold-based-classification yields 70-90% accuracy in distinguishing congested from free-flowing traffic.",C.3 [special-purpose and application based systems]: Signal processing systems; Design; Experimentation; Verification,Acoustic sensing; Experimentation; Free flowing; Road traffic; Signal processing systems; Traffic conditions; Traffic noise; Design; Signal processing; Verification; Noise pollution
"Xiong J., Jamieson K.",2,SecureAngle: Improving wireless security using angle-of-arrival information (poster abstract),2010,2,"University College London, United Kingdom",University College London,1,UK,1,9,6,"Wireless local area networks play an important role in our everyday lives, at the workplace and at home. However, wireless networks are also relatively vulnerable: physically located off-premises, attackers can circumvent wireless security protocols such as WEP, WPA, and even to some extent WPA2, presenting a security risk to the entire network. To address this problem, we propose SecureAngle, a system designed to operate alongside existing wireless security protocols, adding defense in depth. SecureAngle employs multiantenna APs to profile the directions at which a client's signal arrives, using this angle-of-arrival information to construct unique signatures that identify each client. With these signatures, we are currently investigating how a SecureAngle enabled AP can enable a ""virtual fence"" that drops frames injected into the network from a client physically located outside a building, and how a SecureAngle-enabled AP can prevent malicious parties from spoofing the link-layer address of legitimate clients.",802.11; Angle of arrival; SecureAngle; Wireless,802.11; Angle of arrival; Defense in depth; Multi-antenna; SecureAngle; Security risks; Wireless security; Wireless security protocols; Radio; Virtual addresses; Wireless local area networks (WLAN); Network security
"Tsiftes N., Eriksson J., Finne N., Österlind F., Höglund J., Dunkels A.",6,"A framework for low-power IPv6 routing simulation, experimentation, and evaluation",2010,15,"Swedish Institute of Computer Science, Sweden",Swedish Institute of Computer Science,1,Sweden,1,4,3,"Low-power networked devices, such as sensors and actuators, are becoming a vital part of our everyday infrastructure. Being networked, the continued development of these systems needs involvement from the networking community. We present a framework for simulation, experimentation, and evaluation of routing mechanisms for low-power IPv6 networking. The framework provides a detailed simulation environment for low-power routing mechanisms, and allows the system to be directly uploaded to a physical testbed for experimental measurements.",C.2.2 [network protocols]: Routing protocols; Experimentation; Measurement; Performance,Experimental measurements; Experimentation; Low Power; Low-power routing; Networked devices; Networking community; Performance; Physical testbeds; Routing mechanism; Routing simulation; Sensors and actuators; Simulation environment; Experiments; Internet protocols; Measurements; Network protocols; Network routing; Low power electronics
"Krishnan S., Chaporkar P.",2,Stochastic approximation algorithm for optimal throughput performance of wireless LANs,2010,0,"India-UK Centre of Excellence in Next Generation Networks Systems and Services, Indian Institute of Technology Bombay, Mumbai, India",IIT Bombay,1,India,1,4,2,"In this paper, we consider the problem of throughput maximization in an infrastructure based WLAN. We demonstrate that most of the proposed protocols though perform optimally for connected network (no hidden terminals), their performance is worse than even that of standard IEEE 802.11 in presence of hidden terminals. Here we present a stochastic approximation based algorithm that not only provide optimum throughput in a fully connected network but also when hidden nodes are present.",Hidden nodes; IEEE 802.11; Stochastic approximation; Weighted fairness,Connected networks; Fully connected networks; Hidden nodes; Hidden terminal; IEEE 802.11s; Optimal throughputs; Stochastic approximation algorithms; Stochastic approximations; Throughput maximization; Weighted fairness; Approximation algorithms; Standards; Approximation theory
"Viswanath B., Post A., Gummadi K.P., Mislove A.",4,An analysis of social network-based Sybil defenses,2010,41,"MPI-SWS, Germany; Northeastern University, United States",Northeastern University,1,Germany;USA,2,33,30,"Recently, there has been much excitement in the research community over using social networks to mitigate multiple identity, or Sybil, attacks. A number of schemes have been proposed, but they differ greatly in the algorithms they use and in the networks upon which they are evaluated. As a result, the research community lacks a clear understanding of how these schemes compare against each other, how well they would work on real-world social networks with different structural properties, or whether there exist other (potentially better) ways of Sybil defense. In this paper, we show that, despite their considerable differences, existing Sybil defense schemes work by detecting local communities (i.e., clusters of nodes more tightly knit than the rest of the graph) around a trusted node. Our finding has important implications for both existing and future designs of Sybil defense schemes. First, we show that there is an opportunity to leverage the substantial amount of prior work on general community detection algorithms in order to defend against Sybils. Second, our analysis reveals the fundamental limits of current social network-based Sybil defenses: We demonstrate that networks with well-defined community structure are inherently more vulnerable to Sybil attacks, and that, in such networks, Sybils can carefully target their links in order make their attacks more effective. Copyright 2010 ACM.",Communities; Social network-based Sybil defense; Social networks; Sybil attacks,Community detection algorithms; Community structures; Future designs; Local community; Multiple identities; Real-world; Research communities; Social network-based Sybil defense; Social Networks; Sybil attack; Ecosystems; Social networking (online); Computer crime
"Tan K., Fang J., Zhang Y., Chen S., Shi L., Zhang J., Zhang Y.",7,Fine-grained channel access in wireless LAN,2010,23,"Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing Jiaotong University, Beijing, China; Microsoft Research Asia, Beihang University, Beijing, China; Microsoft Research Asia, Tsinghua University, Beijing, China",Beihang University;Beijing Jiaotong University;Microsoft;Tsinghua University,4,China,1,30,25,"Modern communication technologies are steadily advancing the physical layer (PHY) data rate in wireless LANs, from hundreds of Mbps in current 802.11n to over Gbps in the near future. As PHY data rates increase, however, the overhead of media access control (MAC) progressively degrades data throughput efficiency. This trend reflects a fundamental aspect of the current MAC protocol, which allocates the channel as a single resource at a time. This paper argues that, in a high data rate WLAN, the channel should be divided into separate subchannels whose width is commensurate with PHY data rate and typical frame size. Multiple stations can then contend for and use subchannels simultaneously according to their traffic demands, thereby increasing overall efficiency. We introduce FICA, a fine-grained channel access method that embodies this approach to media access using two novel techniques. First, it proposes a new PHY architecture based on OFDM that retains orthogonality among subchannels while relying solely on the coordination mechanisms in existing WLAN, carrier-sensing and broadcasting. Second, FICA employs a frequency-domain contention method that uses physical layer RTS/CTS signaling and frequency domain backoff to efficiently coordinate subchannel access. We have implemented FICA, both MAC and PHY layers, using a software radio platform, and our experiments demonstrate the feasibility of the FICA design. Further, our simulation results suggest FICA can improve the efficiency ratio of WLANs by up to 400% compared to existing 802.11. Copyright 2010 ACM.",Cross-layer; Fine-grained channel access; MAC; OFDMA,802.11n; Architecture-based; Backoff; Channel access; Contention method; Coordination mechanisms; Cross-layer; Data rates; Data throughput; Efficiency ratio; Frame size; Frequency domains; High data rate; MAC; MAC protocol; Media access; Media access control; Modern Communication Technologies; Novel techniques; OFDMA; Orthogonality; Overall efficiency; Physical layers; RTS/CTS; Software radio platform; Subchannels; Traffic demands; Efficiency; Frequency domain analysis; Medium access control; Network layers; Frequency division multiple access
Yoon S.,1,Contrabass: Concurrent transmissions without coordination,2010,0,"North Carolina State University, United States",North Carolina State University,1,USA,1,7,6,"A PHY and MAC protocol for MIMO concurrent transmissions, called Contrabass, is presented. Concurrent transmissions, also referred to as multi-user MIMO, are simultaneous transmissions by multiple interfering nodes over the same carrier frequency. Concurrent transmissions technique has the potential of mitigating the overhead of MAC protocols by amortizing protocol overhead among multiple packets. However, existing proposals for concurrent transmissions could not achieve this as MIMO channel training and collision avoidance typically involve an expensive process of coordination and control message exchanges. This overhead has made MIMO concurrent transmission Impractical and thus unused in real applications. Contrabass implements simultaneous channel training and optimal transmission control without any coordination. As a result, Contrabass achieves very high aggregate throughput, low delays and scalability even under dynamic environments and outperforms the existing MIMO protocols. This is the first practical implementation of MIMO-based concurrent transmissions. We implemented Contrabass in GNU radios and also in NS-2.",IEEE 802.11n; Interference cancellation; MIMO; Multi-user transmissions; Spatial multiplexing,Aggregate throughput; Carrier frequency; Channel trainings; Concurrent transmission; Coordination and Control; Dynamic environments; GNU radio; IEEE 802.11n; Interference cancellation; Low delay; MAC protocol; MIMO channel; Multi-user; Multi-user MIMO; Optimal transmission; Practical implementation; Protocol overhead; Real applications; Simultaneous transmission; Spatial multiplexing; MIMO systems; Standards; Medium access control
"Paredes-Oliva I., Dimitropoulos X., Molina M., Barlet-Ros P., Brauckhoff D.",5,Automating root-cause analysis of network anomalies using frequent itemset mining,2010,4,"Universitat Politècnica de Catalunya (UPC), Barcelona, Spain; ETH Zurich, Zurich, Switzerland; DANTE, Cambridge, United Kingdom",ETH Zurich;Universitat Politecnica de Catalunya,2,Spain;Switzerland;UK,3,6,6,"Finding the root-cause of a network security anomaly is essential for network operators. In our recent work, we introduced a generic technique that uses frequent itemset mining to automatically extract and summarize the traffic flows causing an anomaly. Our evaluation using two different anomaly detectors (including a commercial one) showed that our approach works surprisingly well extracting the anomalous flows in most studied cases using sampled and unsampled NetFlow traces from two networks. In this demonstration, we will showcase an open-source anomaly-extraction system based on our technique, which we integrated with a commercial anomaly detector and use in the NOC of the GÉANT network since late 2009. We will report a number of detected security anomalies and will illustrate how an operator can use our system to automatically extract and summarize anomalous flows.",Anomaly extraction; Anomaly validation; Association rules,Anomaly detector; Anomaly validation; Frequent itemset mining; NetFlows; Network anomalies; Network operator; Open-source; Root cause analysis; Traffic flow; Association rules; Extraction; Network security
"Perli S.D., Ahmed N., Katabi D.",3,PixNet: LCD-camera pairs as communication links,2010,2,"CSAIL, MIT, Australia",MIT,1,Australia,1,8,8,"Given the abundance of cameras and LCDs in today's environment, there exists an untapped opportunity for using these devices for communication. Specifically, cameras can tune to nearby LCDs and use them for network access. The key feature of these LCD-camera links is that they are highly directional and hence enable a form of interference-free wireless communication. This makes them an attractive technology for dense, high contention scenarios. The main challenge, however, to enable such LCD-camera links is to maximize coverage, that is to deliver multiple Mb/s over multi-meter distances, independent of the view angle. To do so, these links need to address unique types of channel distortions, such as perspective distortion and blur. In this demo, we show how these LCD-camera links can be used to wirelessly transmit information. We present PixNet, an LCD-camera communication system. PixNet generalizes the popular OFDM transmission algorithms to address the unique properties of the LCD-camera link, including perspective distortion and blur. We have built a prototype of PixNet using off-the-shelf LCDs and cameras. In our demo, we will show our prototype communicating data from an LCD to a camera-equipped PC, over multi-meter distances and wide viewing angles.",Camera; OFDM; Optical links; Perspective distortion,Channel distortions; High contentions; Interference-free; Key feature; Network access; OFDM transmission; Perspective distortion; View angles; Wide viewing angle; Wireless communications; Communication systems; Interconnection networks; Optical links; Orthogonal frequency division multiplexing; Wireless telecommunication systems; Cameras
"Ghobadi M., Labrecque M., Salmon G., Aasaraai K., Yeganeh S.H., Ganjali Y., Steffan J.G.",7,Caliper: A tool to generate precise and closed-loop traffic,2010,2,"Department of Computer Science, University of Toronto, Canada; Department of Electrical and Computer Engineering, University of Toronto, Canada",University of Toronto,1,Canada,1,3,1,"Generating realistic and responsive traffic that reflects different network conditions is a challenging problem associated with performing valid experiments in network testbeds. In this work, we preset Caliper, a highly precise traffic generation tool, built on NetThreads, a flexible platform that we have created for developing packet processing applications on FPGA-based devices and the NetFPGA in particular. We will demonstrate the effect of ad-hoc inter-departure times on a commodity NIC compared to precisely timed inter-departures with Caliper. Both NetThreads and Caliper are available as free software to download.",NetFPGA; Soft processors; Traffic generation,Closed-loop; Flexible platforms; Free software; In networks; NetFPGA; Network condition; Packet processing; Soft processors; Traffic generation; Communication; Field programmable gate arrays (FPGA)
"Labovitz C., Iekel-Johnson S., McPherson D., Oberheide J., Jahanian F.",5,Internet inter-domain traffic,2010,81,"Arbor Networks, Ann Arbor, MI, United States; University of Michigan, Ann Arbor, MI, United States",University of Michigan at Ann Arbor,1,USA,1,46,38,"In this paper, we examine changes in Internet inter-domain traffic demands and interconnection policies. We analyze more than 200 Exabytes of commercial Internet traffic over a two year period through the instrumentation of 110 large and geographically diverse cable operators, international transit backbones, regional networks and content providers. Our analysis shows significant changes in inter-AS traffic patterns and an evolution of provider peering strategies. Specifically, we find the majority of inter-domain traffic by volume now flows directly between large content providers, data center / CDNs and consumer networks. We also show significant changes in Internet application usage, including a global decline of P2P and a significant rise in video traffic. We conclude with estimates of the current size of the Internet by inter-domain traffic volume and rate of annualized inter-domain traffic growth. Copyright 2010 ACM.",C.2 [computer communication networks]: Miscellaneous; Measurement,Cable operators; Commercial internet; Computer communication networks; Content providers; Data centers; inter-AS; Inter-domain traffic; Internet application; Regional networks; Traffic pattern; Video traffic; Measurements; Peer to peer networks; Internet
"Capelis D.J., Long D.D.E.",2,Fived: A service-based architecture implementation to innovate at the endpoints,2010,0,"Department of Computer Science, University of California, Santa Cruz, Santa Cruz, CA, United States",University of California Santa Cruz,1,USA,1,3,0,"Security functions such as access control, encryption and authentication are typically left up to applications on the modern Internet. There is no unified system to implement these critical features. The access control that does exist on the network doesn't integrate well with user authentication systems, so access control decisions are based on the network location of a computer rather than the privilege level of its user. Just about every layer of the Internet provides optional encryption, yet most data on the Internet continues to be sent in the clear. Application developers routinely make mistakes in security critical code leading to bugs that manifest in worms, malware or provide a doorway for actively malicious attackers. We propose a unified session layer that integrates trustworthiness features into the core of the network. This would reverse the fortunes of security on the Internet and lead us toward a safer, more secure global network.",C.2.1 [network architecture and design]: Network communications; C.2.2 [network protocols]: Protocol architecture (OSI model); Design; Management; Security,Access control decisions; Application developers; C.2.1 [Network Architecture and Design]: Network Communications; Critical features; Global networks; Malwares; Network location; Protocol architecture; Security; Security functions; Security on the internets; Security-critical codes; Service-based; Session layers; Unified system; User authentication systems; Authentication; Computer worms; Cryptography; Design; Internet; Management; Network security; OSI model; Network architecture
"Li Z., Xia G., Gao H., Tang Y., Chen Y., Liu B., Jiang J., Lv Y.",8,NetShield: Massive semantics-based vulnerability signature matching for high-speed networks,2010,9,"Northwestern University, United States; Tsinghua University, China",Northwestern University;Tsinghua University,2,China;USA,2,30,20,"Accuracy and speed are the two most important metrics for Network Intrusion Detection/Prevention Systems (NIDS/NIPSes). Due to emerging polymorphic attacks and the fact that in many cases regular expressions (regexes) cannot capture the vulnerability conditions accurately, the accuracy of existing regex-based NIDS/NIPS systems has become a serious problem. In contrast, the recently-proposed vulnerability signatures (a.k.a data patches) can exactly describe the vulnerability conditions and achieve better accuracy. However, how to efficiently apply vulnerability signatures to high speed NIDS/NIPS with a large ruleset remains an untouched but challenging issue. This paper presents the first systematic design of vulnerability signature based parsing and matching engine, NetShield, which achieves multi-gigabit throughput while offering much better accuracy. Particularly, we made the following contributions: (i) we proposed a candidate selection algorithm which efficiently matches thousands of vulnerability signatures simultaneously requiring a small amount of memory; (ii) we proposed an automatic lightweight parsing state machine achieving fast protocol parsing. Experimental results show that the core engine of NetShield achieves at least 1.9+Gbps signature matching throughput on a 3.8GHz single-core PC, and can scale-up to at least 11+Gbps under a 8-core machine for 794 HTTP vulnerability signatures. Copyright 2010 ACM.",Deep packet inspection; Intrusion detection; Signature matching; Vulnerability signature,Candidate selection; Core engines; Deep packet inspection; High Speed; Matching engines; Network intrusion detection; Regular expressions; Scale-up; Signature-matching; State machine; Systematic designs; Vulnerability signature; Intrusion detection; Pattern matching; Semantics
"Hajjat M., Sun X., Sung Y.-W.E., Maltz D., Rao S., Sripanidkulchai K., Tawarmalani M.",7,Cloudward bound: Planning for beneficial migration of enterprise applications to the cloud,2010,25,"Purdue University, United States; Microsoft Research, United States; IBM T.J. Watson Research Center, United States",IBM;Microsoft;Purdue University,3,USA,1,29,16,"In this paper, we tackle challenges in migrating enterprise services into hybrid cloud-based deployments, where enterprise operations are partly hosted on-premise and partly in the cloud. Such hybrid architectures enable enterprises to benefit from cloud-based architectures, while honoring application performance requirements, and privacy restrictions on what services may be migrated to the cloud. We make several contributions. First, we highlight the complexity inherent in enterprise applications today in terms of their multi-tiered nature, large number of application components, and interdependencies. Second, we have developed a model to explore the benefits of a hybrid migration approach. Our model takes into account enterprise-specific constraints, cost savings, and increased transaction delays and wide-area communication costs that may result from the migration. Evaluations based on real enterprise applications and Azure-based cloud deployments show the benefits of a hybrid migration approach, and the importance of planning which components to migrate. Third, we shed insight on security policies associated with enterprise applications in data centers. We articulate the importance of ensuring assurable reconfiguration of security policies as enterprise applications are migrated to the cloud. We present algorithms to achieve this goal, and demonstrate their efficacy on realistic migration scenarios. Copyright 2010 ACM.",Cloud computing; Enterprise applications; network configurations; Performance modeling; Security policies,Application components; Application performance; Cloud deployments; Cloud-based; Cloud-based architectures; Cost saving; Data centers; Enterprise applications; Enterprise services; Hybrid architectures; Multi-tiered; Network configuration; Performance Modeling; Privacy restrictions; Security policy; Wide-area communication; Cloud computing; Network architecture; Security systems; Industry
"Heller B., Erickson D., McKeown N., Griffith R., Ganichev I., Shenker S., Zarifis K., Moon D., Whyte S., Stuart S.",10,Ripcord: A modular platform for data center networking,2010,0,"Stanford University, Stanford, CA, United States; University of California, Berkeley, CA, United States; International Computer Science Institute, Berkeley, CA, United States; Nicira Networks, Palo Alto, CA, United States; Google, Inc., Mountain View, CA, United States",Google;Nicira Networks;Stanford University;University of California Berkeley,4,USA,1,7,6,"In this demo, we present Ripcord, a modular platform for rapidly prototyping scale-out data center networks. Ripcord enables researchers to build and evaluate new network features and topologies, using only commercially available hardware and open-source software. The Ripcord demo will show three examples of custom network functions, operating together, on top of a 160-node cluster. The first is a routing engine that isolates classes of traffic. The second is a dynamic network manager than adjusts links and switch power states to reduce energy. The third is a statistics aggregator that supports network health monitoring and automatic alerts. The demo will be interactive, with a visualization of live parameters for each link and switch, such as bandwidth, drops, and power status, as well a control panel to modify the traffic load. We feel that an interactive demo is the best way to introduce the research community to Ripcord and get their feedback.",Data center network; OpenFlow; Ripcord,Control panels; Data center networkings; Data center networks; Dynamic network; Health monitoring; Modular platform; Network features; Network functions; Open-source softwares; Openflow; Research communities; Ripcord; Switch power; Traffic loads; Communication
"Jang K., Han S., Han S., Moon S., Park K.",5,Accelerating SSL with GPUs,2010,3,"Department of Computer Science, KAIST, South Korea; NHN Corporation, South Korea; Department of Electrical Engineering, KAIST, South Korea",KAIST,1,South Korea,1,6,6,"SSL/TLS is a standard protocol for secure Internet communication. Despite its great success, today's SSL deployment is largely limited to security-critical domains. The low adoption rate of SSL is mainly due to high computation overhead on the server side. In this paper, we propose Graphics Processing Units (GPUs) as a new source of computing power to reduce the server-side overhead. We have designed and implemented an SSL proxy that opportunistically offloads cryptographic operations to GPUs. The evaluation results show that our GPU implementation of cryptographic operations, RSA, AES, and HMAC-SHA1, achieves high throughput while keeping the latency low. The SSL proxy significantly boosts the throughput of SSL transactions, handling 25.8K SSL transactions per second, and has comparable response time even when overloaded.",CUDA; GPU; SSL,Computation overheads; Computing power; Cryptographic operations; CUDA; Evaluation results; GPU; GPU implementation; Graphics processing units; High throughput; Internet communication; New sources; Security-critical; Server sides; SSL; SSL/TLS; Standard protocols; Computer graphics; Cryptography; Internet protocols; Program processors
"Nikolaidis G., Zhushi A., Jamieson K., Karp B.",4,Cone of silence: Adaptively nulling interferers in wireless networks,2010,1,"Dept. of Computer Science, University College London, London, United Kingdom",University College London,1,UK,1,3,3,"Dense 802.11 wireless networks present a pressing capacity challenge: users in proximity contend for limited unlicensed spectrum. Directional antennas promise increased capacity by improving the signal-to-interference-plus-noise ratio (SINR) at the receiver, potentially allowing successful decoding of packets at higher bit-rates. Many uses of directional antennas to date have directed high gain between two peers, thus maximizing the strength of the sender's signal reaching the receiver. But in an interference-rich environment, as in dense 802.11 deployments, directional antennas only truly come into their own when they explicitly null interference from competing concurrent senders. In this paper, we present Cone of Silence (CoS), a technique that leverages software-steerable directional antennas to improve the capacity of indoor 802.11 wireless networks by adaptively nulling interference. Using in situ signal strength measurements that account for the complex propagation environment, CoS derives custom antenna radiation patterns that maximize the strength of the signal arriving at an access point from a sender while nulling inteference from one or more concurrent interferers. CoS leverages multiple antennas, but requires only a single commodity 802.11 radio, thus avoiding the significant processing requirements of decoding multiple concurrent packets. Experiments in an indoor 802.11 deployment demonstrate that CoS improves throughput under interference.",Beam forming; Beam steering; Directional; Interference; Nulling; Phased array; Wireless,802.11 wireless networks; Access points; Beam-steering; Bitrates; Directional; Directional Antenna; High gain; Inteference; Multiple antenna; Nulling; Propagation environment; Signal strength measurements; Signal to interference plus noise ratio; Unlicensed spectrum; Antenna phased arrays; Decoding; Directive antennas; Radio; Signal interference; Signal receivers; Spurious signal noise; Transition metal compounds; Wave interference; Directional patterns (antenna)
"Isdal T., Piatek M., Krishnamurthy A., Anderson T.",4,Privacy-preserving P2P data sharing with OneSwarm,2010,18,"University of Washington, United States",University of Washington at St. Louis,1,USA,1,39,32,"Privacy - the protection of information from unauthorized disclosure - is increasingly scarce on the Internet. The lack of privacy is particularly true for popular peer-to-peer data sharing applications such as BitTorrent where user behavior is easily monitored by third parties. Anonymizing overlays such as Tor and Freenet can improve user privacy, but only at a cost of substantially reduced performance. Most users are caught in the middle, unwilling to sacrifice either privacy or performance. In this paper, we explore a new design point in this tradeoff between privacy and performance. We describe the design and implementation of a new P2P data sharing protocol, called OneSwarm, that provides users much better privacy than BitTorrent and much better performance than Tor or Freenet. A key aspect of the OneSwarm design is that users have explicit configurable control over the amount of trust they place in peers and in the sharing model for their data: the same data can be shared publicly, anonymously, or with access control, with both trusted and untrusted peers. OneSwarm's novel lookup and transfer techniques yield a median factor of 3.4 improvement in download times relative to Tor and a factor of 6.9 improvement relative to Freenet. OneSwarm is publicly available and has been downloaded by hundreds of thousands of users since its release. Copyright 2010 ACM.",C.2.4 [computer-communication networks]: Distributed systems; Design; Performance; Security,Better performance; Bit torrents; Data Sharing; Design and implementations; Distributed systems; Freenets; Lookups; New design; Peer-to-peer data-sharing; Performance; Privacy preserving; Security; Third parties; Transfer technique; Unauthorized disclosures; User behaviors; User privacy; Access control; Behavioral research; Design; Internet protocols; Network security
"Kumar A., Anand A., Akella A., Balachandran A., Sekar V., Seshan S.",6,Flexible multimedia content retrieval using InfoNames,2010,0,"University of Wisconsin-Madison, United States; Carnegie Mellon University, United States",Carnegie Mellon University;University of Wisconsin-Madison,2,USA,1,9,4,"Multimedia content is a dominant fraction of Internet usage today. At the same time, there is significant heterogeneity in video presentation modes and operating conditions of Internet-enabled devices that access such content. Users are often interested in the content, rather than the specific sources or the formats. The host-centric format of the current Internet does not support these requirements naturally. Neither do the recent data-centric naming proposals, since they rely on naming content based on raw byte-level hashing schemes. We argue that to meet these requirements, enabling content retrieval mechanisms to name and query directly for the underlying information is a good way forward. In addition to decoupling content from available sources and transfer protocols, these ""information-aware names"" or InfoNames explicitly decouple the information from content presentation factors as well. We envision an InfoName Resolution System (IRS) to resolve location based on InfoNames, while taking into account the operating conditions of devices. In this demo, we present an application to show how InfoNames can serve as presentation-invariant and portable names to fetch video content independent of device capabilities and resource constraints.",Algorithms; C.2 [computer communication networks]: Miscellaneous: 11.4 [Information systems applications]: Miscellaneous; Design,Content presentation; Content retrieval; Content-based; Data centric; Device capabilities; Information systems application; Information-aware; Internet usage; Location based; Multimedia content retrievals; Multimedia contents; Operating condition; Resolution systems; Resource Constraint; Transfer protocol; Video contents; Video presentations; Algorithms; Design; Internet; Internet protocols
"He Y., Fang J., Zhang J., Shen H., Tan K., Zhang Y.",6,MPAP: Virtualization architecture for heterogenous wireless APs,2010,4,"Microsoft Research Asia, Beijing, China",Microsoft,1,China,1,4,2,"This demonstration shows a novel virtualization architecture, called Multi-Purpose Access Point (MPAP), which can virtualize multiple heterogenous wireless standards based on software radio. The basic idea is to deploy a wide-band radio front-end to receive wireless signals from all wireless standards sharing the same spectrum band, and use separate software base-bands to demodulate information stream for each wireless standard. Based on software radio, MPAP consolidates multiple wireless devices into single hardware platform, and allows them to share the same general-purpose computing resource. Different software base-bands can easily communicate and coordinate with one another. Thus, it also provides better coexistence among heterogenous wireless standards. As an example, we demonstrate to use non-contiguous OFDM in 802.11g PHY to avoid the mutual interference with narrow-band ZigBee communication.",Software radio; Sora; Virtualization; Wireless,802.11g; Access points; General-purpose computing; Hardware platform; Information streams; Multi-purpose; Mutual interference; Narrow bands; Sora; Spectrum bands; Virtualizations; Wide-band; Wireless devices; Wireless signals; Wireless standards; ZigBee communications; Radio; Software radio; Virtual reality; Standards
"Yu M., Rexford J., Freedman M.J., Wang J.",4,Scalable flow-based networking with DIFANE,2010,169,"Princeton University, Princeton, NJ, United States; AT and T Labs. - Research, Florham Park, NJ, United States",AT and T Labs;Princeton University,2,USA,1,24,19,"Ideally, enterprise administrators could specify fine-grain policies that drive how the underlying switches forward, drop, and measure traffic. However, existing techniques for flow-based networking rely too heavily on centralized controller software that installs rules reactively, based on the first packet of each flow. In this paper, we propose DIFANE, a scalable and efficient solution that keeps all traffic in the data plane by selectively directing packets through intermediate switches that store the necessary rules. DIFANE relegates the controller to the simpler task of partitioning these rules over the switches. DIFANE can be readily implemented with commodity switch hardware, since all data-plane functions can be expressed in terms of wildcard rules that perform simple actions on matching packets. Experiments with our prototype on Click-based OpenFlow switches show that DIFANE scales to larger networks with richer policies. Copyright 2010 ACM.",Access control; Network architecture; Open flow; Scalability,Centralized controllers; Commodity switches; Data planes; Data-plane; Fine grains; Intermediate switch; Larger networks; Open flow; Openflow switches; Access control; Network architecture; Scalability; Digital storage
"Halperin D., Hu W., Sheth A., Wetherall D.",4,Predictable 802.11 packet delivery from wireless channel measurements,2010,113,"University of Washington, United States; Intel Labs. Seattle, United States",Intel;University of Washington at St. Louis,2,USA,1,31,28,"RSSI is known to be a fickle indicator of whether a wireless link will work, for many reasons. This greatly complicates operation because it requires testing and adaptation to find the best rate, transmit power or other parameter that is tuned to boost performance. We show that, for the first time, wireless packet delivery can be accurately predicted for commodity 802.11 NICs from only the channel measurements that they provide. Our model uses 802.11n Channel State Information measurements as input to an OFDM receiver model we develop by using the concept of effective SNR. It is simple, easy to deploy, broadly useful, and accurate. It makes packet delivery predictions for 802.11a/g SISO rates and 802.11n MIMO rates, plus choices of transmit power and antennas. We report testbed experiments that show narrow transition regions (<2 dB for most links) similar to the near-ideal case of narrowband, frequency-flat channels. Unlike RSSI, this lets us predict the highest rate that will work for a link, trim transmit power, and more. We use trace-driven simulation to show that our rate prediction is as good as the best rate adaptation algorithms for 802.11a/g, even over dynamic channels, and extends this good performance to 802.11n. Copyright 2010 ACM.",C.2.1 [computer-communication networks]: Network architecture and design - Wireless communication; Design; Experimentation,802.11a; 802.11n; Channel measurements; Channel state; Dynamic channels; Effective SNR; Experimentation; Model use; Narrow bands; OFDM receiver; Packet Delivery; Rate adaptation; Rate predictions; Trace driven simulation; Transition regions; Transmit power; Wireless channel; Wireless communications; Wireless link; Wireless packet; Design; Experiments; Network architecture; Orthogonal frequency division multiplexing; Wireless telecommunication systems; Signal to noise ratio
"Dvir A., Vasilakos A.V.",2,Backpressure-based routing protocol for DTNs,2010,48,"Department of Computer Science, College of Management Academic Studies, Israel; Department of Computer and Telecommunications Engineering, University of Western Macedonia, Greece",University of Western Macedonia,1,Greece;Israel;Macedonia,3,3,3,"In this paper we consider an alternative, highly agile In this paper we consider an alternative, highly agile approach called backpressure routing for Delay Tolerant Networks (DTN), in which routing and forwarding decisions are made on a per-packet basis. Using information about queue backlogs, random walk and data packet scheduling nodes can make packet routing and forwarding decisions without the notion of end-to-end routes. To the best of our knowledge, this is the first ever implementation of dynamic backpressure routing in DTNs. Simulation results show that the proposed approach has advantages in terms of DTN networks.",Backpressure approach; Delay tolerant network,Agile approaches; Back pressures; Back-pressure routing; Data packet; Packet routing; Random Walk; Routers; Wireless networks; Delay tolerant networks
"Chen K., Guo C., Wu H., Yuan J., Feng Z., Chen Y., Lu S., Wu W.",8,Generic and automatic address configuration for data center networks,2010,3,"Northwestern University, United States; Microsoft Research Asia, China; Tsinghua University, China; NUDT, China; UCLA, United States; BUAA, China",Microsoft;Northwestern University;Tsinghua University,3,China;USA,2,30,20,"Data center networks encode locality and topology information into their server and switch addresses for performance and routing purposes. For this reason, the traditional address configuration protocols such as DHCP require huge amount of manual input, leaving them error-prone. In this paper, we present DAC, a generic and automatic Data center Address Configuration system. With an automatically generated blueprint which defines the connections of servers and switches labeled by logical IDs, e.g., IP addresses, DAC first learns the physical topology labeled by device IDs, e.g., MAC addresses. Then at the core of DAC is its device-to-logical ID mapping and malfunction detection. DAC makes an innovation in abstracting the device-to-logical ID mapping to the graph isomorphism problem, and solves it with low time-complexity by leveraging the attributes of data center network topologies. Its malfunction detection scheme detects errors such as device and link failures and miswirings, including the most difficult case where miswirings do not cause any node degree change. We have evaluated DAC via simulation, implementation and experiments. Our simulation results show that DAC can accurately find all the hardest-to-detect malfunctions and can autoconfigure a large data center with 3.8 million devices in 46 seconds. In our implementation, we successfully autoconfigure a small 64-server BCube network within 300 milliseconds and show that DAC is a viable solution for data center autoconfiguration. Copyright 2010 ACM.",Address configuration; Data center networks; Graph isomorphism,Address configuration; Auto-configuration; Automatically generated; Data center networks; Data centers; Detection scheme; Error prones; Graph isomorphism; Graph isomorphism problem; IP addresss; Large data; Link failures; MAC address; Node degree; Physical topology; Topology information; Viable solutions; Electric network topology; Internet protocols; Set theory; Physical addresses
"Sharma M., Sahoo A.",2,Residual white space distribution-based opportunistic channel access for cognitive radio enabled devices,2010,1,"Dept. of Computer Science and Engineering, Indian Institute of Technology Bombay, Mumbai, India",IIT Bombay,1,India,1,3,3,"We describe an opportunistic channel access scheme for cognitive radio-enabled secondary nodes (SNs). The proposed scheme uses the residual channel idle time distribution to estimate the transmission duration in the remaining idle time, subject to an acceptable Primary User (PU) interference constraint. The SN then transmits the frames within the estimated duration without further sensing the channel, which reduces sensing overhead. The scheme does not require the SN to continuously sense the channel to keep track of the start of the idle period, thereby conserving energy.",C.2.5 [local and wide-area networks]: Access schemes; Performance; Theory,Access schemes; Channel access; Idle periods; Idle time; Idle time distribution; Interference constraints; Keep track of; Performance; Primary users; Residual white spaces; Theory; Transmission durations; Wide area networks; Cognitive radio
"Cai X., Heidemann J.",2,Understanding block-level address usage in the visible internet,2010,5,"USC/Information Sciences Institute, United States",University of Southern California,1,USA,1,31,24,"Although the Internet is widely used today, we have little information about the edge of the network. Decentralized management, firewalls, and sensitivity to probing prevent easy answers and make measurement difficult. Building on frequent ICMP probing of 1% of the Internet address space, we develop clustering and analysis methods to estimate how Internet addresses are used. We show that adjacent addresses often have similar characteristics and are used for similar purposes (61% of addresses we probe are consistent blocks of 64 neighbours or more). We then apply this block-level clustering to provide data to explore several open questions in how networks are managed. First, we provide information about how effectively network address blocks appear to be used, finding that a significant number of blocks are only lightly used (most addresses in about one-fifth of 24 blocks are in use less than 10% of the time), an important issue as the IPv4 address space nears full allocation. Second, we provide new measurements about dynamically managed address space, showing nearly 40% of 24 blocks appear to be dynamically allocated, and dynamic addressing is most widely used in countries more recent to the Internet (more than 80% in China, while less than 30% in the U.S.). Third, we distinguish blocks with low-bitrate last-hops and show that such blocks are often underutilized. Copyright 2010 ACM.",Availability; Classification; Clustering; Internet address usage; Low-bitrate; Median-up; Pattern analysis; RTT; Survey; Volatility,Clustering; Low-bitrate; Median-up; Pattern analysis; RTT; Volatility; Availability; Classification (of information); Internet protocols; Surveys; Internet
"McSherry F., Mahajan R.",2,Differentially-private network trace analysis,2010,21,"Microsoft Research, United States",Microsoft,1,USA,1,33,27,"We consider the potential for network trace analysis while providing the guarantees of ""differential privacy."" While differential privacy provably obscures the presence or absence of individual records in a dataset, it has two major limitations: analyses must (presently) be expressed in a higher level declarative language; and the analysis results are randomized before returning to the analyst. We report on our experiences conducting a diverse set of analyses in a differentially private manner. We are able to express all of our target analyses, though for some of them an approximate expression is required to keep the error-level low. By running these analyses on real datasets, we find that the error introduced for the sake of privacy is often (but not always) low even at high levels of privacy. We factor our learning into a toolkit that will be likely useful for other analyses. Overall, we conclude that differential privacy shows promise for a broad class of network analyses. Copyright 2010 ACM.",Differential privacy; Trace analysis,Approximate expressions; Declarative Languages; Differential privacies; Real data sets; Target analysis; Communication; Trace analysis
"Chiba Y., Shinohara Y., Shimonishi H.",3,Source flow: Handling millions of flows on flow-based nodes,2010,7,"System Platforms Research Laboratories, NEC Corporation, 1753 Shimonumabe, Nakahara, Kawasaki, 211-8666, Japan",System Platforms Research Laboratories,1,Japan,1,7,4,"Flow-based networks such as OpenFlow-based networks have difficulty handling a large number of flows in a node due to the capacity limitation of search engine devices such as ternary content-addressable memory (TCAM). One typical solution of this problem would be to use MPLS-like tunneling, but this approach spoils the advantage of flow-by-flow path selection for load-balancing or QoS. We demonstrate a method named ""Source Flow"" that allows us to handle a huge amount of flows without changing the granularity of flows. By using our method, expensive and power consuming search engine devices can be removed from the core nodes, and the network can grow pretty scalable. In our demo, we construct a small network that consists of small number of OpenFlow switches, a single OpenFlow controller, and end-hosts. The hosts generate more than one million flows simultaneously and the flows are controlled on a per-flow-basis. All active flows are monitored and visualized on a user interface and the user interface allows audiences to confirm if our method is feasible and deployable.",Algorithms; C.2.1 [computer-communication networks]: Network architecture and design C.2.6 [computer-communication networks]: Internetworking; Design; Experimentation; Performance,Capacity limitation; Computer communication networks; Core nodes; Experimentation; Load-Balancing; Openflow; Openflow switches; Path selection; Performance; Power consuming; Small networks; Ternary content addressable memories; Algorithms; Design; Network architecture; Search engines; User interfaces
"Turner D., Levchenko K., Snoeren A.C., Savage S.",4,California fault lines: Understanding the causes and impact of network failures,2010,26,"Department of Computer Science and Engineering, University of California, San Diego, CA, United States",University of California San Diego,1,USA,1,35,22,"Of the major factors affecting end-to-end service availability, network component failure is perhaps the least well understood. How often do failures occur, how long do they last, what are their causes, and how do they impact customers? Traditionally, answering questions such as these has required dedicated (and often expensive) instrumentation broadly deployed across a network. We propose an alternative approach: opportunistically mining ""low-quality"" data sources that are already available in modern network environments. We describe a methodology for recreating a succinct history of failure events in an IP network using a combination of structured data (router configurations and syslogs) and semi-structured data (email logs). Using this technique we analyze over five years of failure events in a large regional network consisting of over 200 routers; to our knowledge, this is the largest study of its kind. Copyright 2010 ACM.",C.2.3 [computer-communication network]: Network operations; Measurement; Reliability,Alternative approach; California; Data-sources; End-to-end service; Failure events; Fault line; IP networks; Low qualities; Major factors; Network environments; Network failure; Network operations; Regional networks; Router configuration; Semi structured data; Structured data; Syslogs; Measurements; Reliability; Routers; Telecommunication networks
Devlic A.,1,SIP-based context distribution: Does aggregation pay off?,2010,1,"Appear Networks and Royal Institute of Technology (KTH), Kista, Sweden",KTH Royal Institute of Technology,1,Sweden,1,21,19,"Context-aware applications need quickly access to current context information, in order to adapt their behavior before this context changes. To achieve this, the context distribution mechanism has to timely discover context sources that can provide a particular context type, then acquire and distribute context information from these sources to the applications that requested this type of information. This paper reviews the state-of-the-art context distribution mechanisms according to identified requirements, then introduces a resource list-based subscription/notification mechanism for context sharing. This SIP-based mechanism enables subscriptions to a resource list containing URIs of multiple context sources that can provide the same context type and delivery of aggregated notifications containing context updates from each of these sources. Aggregation of context is thought to be important as it reduces the network traffic between entities involved in context distribution. However, it introduces an additional delay due to waiting for context updates and their aggregation. To investigate if this aggregation actually pays off, we measured and compared the time needed by an application to receive context updates after subscribing to a particular resource list (using RLS) versus after subscribing to each of the individual context sources (using SIMPLE) for different numbers of context sources. Our results show that RLS aggregation outperforms the SIMPLE presence mechanism with 3 or more context sources, regardless of their context updates size. Database performance was identified as a major bottleneck during aggregation, hence we used in-memory tables & prepared statements, leading to up to 57% database time improvement, resulting in a reduction of the aggregation time by up to 34%. With this reduction and an increase in context size, we pushed the aggregation payoff threshold closer to 2 context sources.",Aggregation; Context distribution; RLS; SIMPLE; XCAP,Context aware applications; Context distribution; Context information; Context sharing; Database performance; In contexts; Multiple contexts; Network traffic; Prepared statement; RLS; SIMPLE; XCAP; Agglomeration; Semantics; Internet protocols
Ciuffoletti A.,1,Monitoring a virtual network infrastructure: An laaS perspective,2010,5,"Department of Computer Science, University of Pisa, Italy",University of Pisa,1,Italy,1,13,11,"Infrastructure as a Service (IaaS) providers keep extending with new features the computing infrastructures they offer on a pay per use basis. In this paper we explore reasons and opportunities to include networking within such features, meeting the demand of users that need composite computing architectures similar to Grids. The introduction of networking capabilities within IaaSs would further increase the potential of this technology, and also foster an evolution of Grids towards a confluence, thus incorporating the experiences matured in this environment. Network monitoring emerges as a relevant feature of such virtual architectures, which must exhibit the distinguishing properties of toe IaaS paradigm: scalability, dynamic configuration, accounting. Monitoring tools developed with the same purpose in Grids provide useful insights on problems and solutions.",GRID applications; Network-enabled IaaS,Computing architecture; Computing infrastructures; Dynamic configuration; Grid applications; Monitoring tools; Network Monitoring; Network-enabled IaaS; Pay-per-use; Problems and Solutions; Relevant features; Virtual architecture; Virtual networks; Network architecture; Infrastructure as a service (IaaS)
"Cascarano N., Rolando P., Risso F., Sisto R.",4,INFAnt: NFA pattern matching on GPGPU devices,2010,26,"PoTitecnico di Torino, Turin, Italy",Politecnico di Torino,1,Italy,1,8,8,"This paper presents iNFAnt, a parallel engine for regular expression pattern matching. In contrast with traditional approaches, iNFAnt adopts non-deterministic automata, allowing the compilation of very large and complex rule sets that are otherwise hard to treat. iNFAnt is explicitly designed and developed to run on graphical processing units that provide large amounts of concurrent threads; this parallelism is exploited to handle the non-determinism of the model and to process multiple packets at once, thus achieving high performance levels.",CUDA; GPGPU; NFA; Pattern matching; Regular expression,Concurrent threads; CUDA; GPGPU; Graphical processing unit (GPUs); Large amounts; NFA; Non-determinism; Nondeterministic automata; Parallel engines; Performance level; Regular expression pattern matching; Regular expressions; Rule set; Traditional approaches; Program processors; Pattern matching
"Gyarmati L., Trinh T.A.",2,Scafida: A scale-free network inspired data center architecture,2010,37,"Network Economics Group, Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Hungary",Budapest University of Technology and Economics,1,Hungary,1,18,14,"Data centers have a crucial role in current Internet architecture supporting content-centric networking. State-of-the-art data centers have different architectures like fat-tree (16, 10], DCell [12], or BCube [11]. However, their architectures share a common property: symmetry. Due to their symmetric nature, a tricky point with these architectures is that they are hard to be extended in small quantities. Contrary to state-of-the-art data center architectures, we propose an asymmetric data center topology generation method called Scafida inspired by scale-free networks; these data centers have not only small diameters and high fault tolerance, inherited by scale-free networks, but can also be scaled in smaller and less homogenous increments. We extend the original scale-free network generation algorithm of Barabasi and Albert [5] to meet the physical constraints of switches and routers. Despite the fact that our method artificially limits the node degrees in the network, our data center architectures keep the preferable properties of scale-free networks. Based on extensive simulations we present preliminary results that are promising regarding the error tolerance, scalability, and flexibility of the architecture.",Data center; Scale-free network,Common property; Content-centric networkings; Data center architecture; Data centers; Error tolerance; Extensive simulations; Fat trees; High fault tolerances; Internet architecture; Node degree; Physical constraints; Scale free networks; Topology generation; Complex networks; Computer simulation; Fault tolerance; Network architecture
"Maeder A., Zein N.",2,OFDMA in the field: Current and future challenges,2010,4,"NEC Network Laboratories Europe, United Kingdom",NEC,1,UK,1,20,20,"OFDMA will be the predominant technology for the air interface of broadband mobile wireless systems for the next decades. In recent years, OFDMA-based networks based on IEEE 802.16, and increasingly also on 3GPP LTE are rolled out for commercial use. This article gives an overview of the main challenges for the deployment and operation of state-of-the-art OFDMA networks, along with an outlook into future developments for 4G and beyond 4G networks.",Deployment; LTE; Network Operation; OFDMA; Radio Resource Management; Survey; WiMAX,Deployment; LTE; Network operations; OFDMA; Radio resource management; Mobile telecommunication systems; Surveys; Wimax; Frequency division multiple access
"Claffy K.C., Aben E., Auge J., Beverly R., Bustamante F., Donnet B., Friedman T., Fomenkov M., Haga P., Luckie M., Shavitt Y.",11,The 2nd workshop on active internet measurements (AIMS-2) report,2010,1,"CAIDA, China; RIPE NCC, Netherlands; UPMC Paris Universitas, France; Naval Postgraduate School, United States; Northwestern University, United States; Universite Catholique de Louvin, FNRS, Belgium; Eotvos Lorand University, Hungary; University of Waikato, New Zealand; Tel Aviv University, Israel",Eotvos Lorand University;Naval Postgraduate School;Northwestern University;Tel Aviv University;UPMC Paris Universitas;Universite Catholique de Louvain;University of Waikato,7,Belgium;China;France;Hungary;Israel;Netherlands;New Zealand;USA,8,31,26,"On February 8-10, 2010, CAIDA hosted the second Workshop on Active Internet Measurements (AIMS-2) as part of our series of Internet Statistics and Metrics Analysis (ISMA) Workshops. The goals of this workshop were to further our understanding of the potential and limitations of active measurement research and infrastructure in the wide-area Internet, and to promote cooperative solutions and coordinated strategies to addressing future data needs of the network and security research communities. The three-day workshop included presentations, group discussion and analysis, and focused interaction between participating researchers, operators, and policymakers from all over the world. This report describes the motivation and findings of the workshop, and reviews progress on recommendations developed at the 1st Active Internet Measurements Workshop in 2009 [18]. Slides """"om the workshop presentations are available at [9].",Active measurement; Codes of ethics; Codes of good practice; Management techniques; Measurement techniques; Validation,Active measurement; Codes of ethics; Good practices; Management techniques; Measurement techniques; Validation; Research; Internet
Krishnamurthy B.,1,I know what you will do next summer,2010,7,"AT and T Labs-Research, United Kingdom",AT and T Labs,1,UK,1,20,19,This is a brief journey across the Internet privacy landscape. After tying to convince you about the importance of the problem I will fry to present questions of interest and how you might be able to aPply your expertise to them.,Anonymization; Identity; Online Social Networks; Privacy,Anonymization; Identity; Internet privacy; On-line social networks; Data privacy; Communication
Allman M.,1,On building special-purpose social networks for emergency communication,2010,2,"International Computer Science Institute, Berkeley, CA, United States",University of California Berkeley,1,USA,1,13,7,"In this paper we propose a system that will allow people to communicate their status with friends and family when they find themselves caught up in a large disaster (e.g., sending ""I'm fine"" in the immediate aftermath of an earthquake). Since communication between a disaster zone and the non-affected world is often highly constrained we design the system around lightweight triggers such that people can communicate status with only crude infrastructure (or even sneaker-nets). In this paper we provide the high level system design, discuss the security aspects of the system and study the overall feasibility of a purpose-built social networking system for communication during an emergency.",Emergency communication; Social networks,Disaster zones; Emergency communication; High-level systems; Security aspects; Social networking systems; Social Networks; Social networking (online); Communication
"Rutkowski A., Rajnovic D., Kadobayashi Y., Martin R., Furey I., Takahashi T.",6,CYBEX the cybersecurity information exchange framework (X.1500),2010,14,"Yaana Technologies, United States; FIRST, United States; NAIST, Japan; MITRE, United States; DHS, United States; NICT, Japan",MIT;Yaana Technologies,2,Japan;USA,2,14,14,"The cybersecurity information exchange framework, known as CYBEX, is currently undergoing its first iteration of standardization efforts within ITU-T. The framework describes how cybersecurity information is exchanged between cybersecurity entities on a global scale and how the exchange is assured. The worldwide implementation of the framework will eventually minimize the disparate availability of cybersecurity information. This paper provides a specification overview, use cases, and the current status of CYBEX.",Cybersecurity; CYBEX; Information exchange; Security,Current status; Cyber security; CYBEX; Global scale; Information exchange framework; Information exchanges; Security; Communication
"Ganichev I., Dai B., Shenker S., Godfrey P.B.",4,YAMR: Yet another multipath routing protocol,2010,17,"Computer Science Division, Univ. of California, Berkeley, United States; School of Computer, National University of Defense Technology, China; UCB, ICSI, United States; Dept. of Computer Science, Univ. of Illinois, Urbana-Champaign, United States",National University of Defense Technology;University of California Berkeley;UIUC,3,China;USA,2,16,14,"Multipath routing is a promising technique to increase the Internet's reliability and to give users greater control over the service they receive. However, past proposals choose paths which are not guaranteed to have high diversity. In this paper, we propose yet another multipath routing scheme (YAMR) for the interdomain case. YAMR provably constructs a set of paths that is resilient to any one inter-domain link failure, thus achieving high reliability in a systematic way. Further, even though YAMR maintains more paths than BGP, it actually requires significantly less control traffic, thus alleviating instead of worsening one of the Internet's scalability problems. This reduction in churn is achieved by a novel hiding technique that automatically localizes failures leaving the greater part of the Internet completely oblivious.",Internet; Reliability; Routing Protocols,Control traffic; High reliability; Inter-domain; Link failures; Multi path routing; Multi-path routing schemes; Multipath routing protocols; Scalability problems; Reliability; Routing protocols; Internet
"Buettner M., Wetherall D.",2,"A ""Gen 2"" RFID monitor based on the USRP",2010,27,"University of Washington, United States; Intel Labs Seattle, United States",Intel;University of Washington at St. Louis,2,USA,1,19,13,"We have developed a low cost software radio based platform for monitoring EPC Gen 2 RFID traffic. The Gen 2 standard allows for a range of PHY layer configurations and does not specify exactly how to compose protocol messages to inventory tags. This has made it difficult to know how well the standard works, and how it is implemented in practice. Our platform provides much needed visibility into Gen 2 systems by capturing reader transmissions using the USRP2 and decoding them in real-time using software we have developed and released to the public. In essence, our platform delivers much of the functionality of expensive (> $ 50,000) conformance testing products, with greater extensibility at a small fraction of the cost. In this paper, we present the design and implementation of the platform and evaluate its effectiveness, showing that it has better than 99% accuracy up to 3 meters. We then use the platform to study a commercial RFID reader, showing how the Gen 2 standard is realized, and indicate avenues for research at both the PHY and MAC layers.",EPC Gen 2; RFID; Software defined radio,Conformance testing; EPC Gen 2; Know-how; Layer configuration; Low costs; MAC layer; Protocol message; RFID; RFID readers; Software Radio; Software-defined radios; Economic analysis; Real time systems; Standards; Radio
"Ali S., Ul Haq I., Rizvi S., Rasheed N., Sarfraz U., Khayam A., Mirza F.",7,On Mitigating sampling-induced accuracy loss in traffic anomaly detection systems,2010,15,"School of Electrical Engineering and Computer Science (SEECS), National University of Sciences and Technology (NUST), Sector H-12, Islamabad 44000, Pakistan",National University of Sciences and Technology (NUST),1,Pakistan,1,36,29,"Real-time Anomaly Detection Systems (ADSs) use packet sampling to realize traffic analysis at wire speeds. While recent studies have shown that a considerable loss of anomaly detection accuracy is incurred due to sampling, solutions to mitigate this loss are largely unexplored. In this paper, we propose a Progressive Security-Aware Packet Sampling (PSAS) algorithm which enables a real-time inline anomaly detector to achieve higher accuracy by sampling larger volumes of malicious traffic than random sampling, while adhering to a given sampling budget. High malicious sampling rates are achieved by deploying inline ADSs progressively on a packet's path. Each ADS encodes a binary score (malicious or benign) of a sampled packet into the packet before forwarding it to the next hop node. The next hop node then samples packets marked as malicious with a higher probability. We analytically prove that under certain realistic conditions, irrespective of the intrusion detection algorithm used to formulate the packet score, PSAS always provides higher malicious packet sampling rates. To em- pirically evaluate the proposed PSAS algorithm, we simultaneously collect an Internet traffic dataset containing DoS and portscan attacks at three di®erent deployment points in our university's network. Experimental results using four existing anomaly detectors show that PSAS, while having no extra communication overhead and extremely low complexity, allows these detectors to achieve significantly higher accuracies than those operating on random packet samples.",Anomaly detection; Denial-of-service (DoS); Packet sampling; Portscan,Accuracy loss; Anomaly detection; Anomaly detection systems; Anomaly detector; Communication overheads; Data sets; Denial of Service; In-line; Internet traffic; Intrusion detection algorithms; Low complexity; Malicious packets; Malicious traffic; Next-hop; Packet sampling; Portscan; Random sampling; Realistic conditions; Sampled packet; Sampling rates; Security-aware; Traffic analysis; Traffic anomalies; Algorithms; Data processing; Intrusion detection; Real time systems; Detectors
"Dovrolis C., Gummadi K., Kuzmanovic A., Meinrath S.D.",4,Measurement Lab: Overview and an invitation to the research community,2010,27,"Georgia Tech, United States; MPI-SWS, United States; Northwestern University, United States; New America Foundation, United States",Georgia Tech;Northwestern University,2,USA,1,4,4,"Measurement Lab (M-Lab) is an open, distributed server platform for researchers to deploy active Internet measurement tools. The goal of M-Lab is to advance network research and empower the public with useful information about their broadband connections. By enhancing Internet transparency, M-Lab helps sustain a healthy, innovative Internet. This article describes M-Labs objectives, administrative organization, software and hardware infrastructure. It also provides an overview of the currently available measurement tools and datasets, and invites the broader networking research community to participate in the project.",Broadband internet access; Network measurement; Network neutrality,Administrative organizations; Broadband connection; Broadband internet access; Data sets; Distributed servers; Internet measurement; Measurement tools; Network measurement; Network neutrality; Research communities; Internet; Laboratories; Research; Measurements
"Yin Z., Caesar M., Zhou Y.",3,Towards understanding bugs in open source router software,2010,10,"Department of Computer Science, University of Illinois, Urbana-Champaign Urbana, IL 61801, United States; Department of Computer Science, Engineering University of California, San Diego, CA 92093, United States",University of California San Diego;UIUC,2,USA,1,27,19,"Software errors and vulnerabilities in core Internet routers have led to several high-profile attacks on the Internet infrastructure and numerous outages. Building an understanding of bugs in open-source router software is a first step towards addressing these problems. In this paper, we study router bugs found in two widely-used open-source router implementations. We evaluate the root cause of bugs, ease of diagnosis and detectability, ease of prevention and avoidance, and their effect on network behavior.",Internet routing; Protocols; Router software; Software errors,Core Internet; Detectability; Internet infrastructure; Internet routing; Network behaviors; Open sources; Open-source; Protocols; Root cause; Router software; Software errors; Errors; Internet; Internet protocols; Open systems; Program diagnostics; Routers; Program debugging
"Guérin R., Hosanagar K.",2,Fostering IPv6 migration through network quality differentials,2010,15,"Elec. and Sys. Eng, U. Pennsylvania, United States; Wharton, U. Pennsylvania, United States",University Pennsylvania,1,USA,1,10,7,"Although IPv6 has been the next generation Internet protocol for nearly 15 years, new evidences indicate that transitioning from IPv4 to IPv6 is about to become a more pressing issue. This paper attempts to quantify if and how such a transition may unfold. The focus is on ""connectivity quality,"" e.g., as measured by users' experience when accessing content, as a possible incentive (or disincentive) for migrating to IPv6, and on ""translation costs"" (between IPv6 and IPv4) that Internet Service Providers will incur during this transition. The paper develops a simple model that captures some of the underlying interactions, and highlights the ambiguous role of translation gateways that can either help or discourage IPv6 adoption. The paper is an initial foray in the complex and often puzzling issue of migrating the current Internet to a new version with which it is incompatible.",Incentives; IPv6; Migration; Quality,Incentives; IPv6; Migration; Next generation Internet; Quality; Internet; Internet service providers; Internet protocols
"Dukkipati N., Refice T., Cheng Y., Chu J., Herbert T., Agarwal A., Jain A., Sutin N.",8,An argument for increasing TCP's initial congestion window,2010,100,"Google Inc., Mountain View, CA, United States",Google,1,USA,1,16,13,"TCP flows start with an initial congestion window of at most four segments or approximately 4KB of data. Because most Web transactions are short-lived, the initial congestion window is a critical TCP parameter in determining how quickly flows can finish. While the global network access speeds increased dramatically on average in the past decade, the standard value of TCP's initial congestion window has remained unchanged. In this paper, we propose to increase TCP's initial congestion window to at least ten segments (about 15KB). Through large-scale Internet experiments, we quantify the latency benefits and costs of using a larger window, as functions of network bandwidth, round-trip time (RTT), bandwidthdelay product (BDP), and nature of applications. We show that the average latency of HTTP responses improved by approximately 10% with the largest benefits being demonstrated in high RTT and BDP networks. The latency of low bandwidth networks also improved by a significant amount in our experiments. The average retransmission rate increased by a modest 0.5%, with most of the increase coming from applications that effectively circumvent TCP's slow start algorithm by using multiple concurrent connections. Based on the results from our experiments, we believe the initial congestion window should be at least ten segments and the same be investigated for standardization by the IETF.",Congestion Control; Internet Measurements; TCP; Web Latency,Bandwidth delay product; Benefits and costs; Congestion Control; Congestion window; Global networks; Internet experiments; Internet Measurements; Low-bandwidth; Network bandwidth; Retransmissions; Round-trip-time; Slow start; Standard values; TCP; TCP flows; Web Latency; Web transactions; Experiments; HTTP; Internet; Transmission control protocol
Crowcroft J.,1,FIE - Future internet enervation,2010,1,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,14,0,"I'm so Bored of the Future Internet (FI). There are so many initiatives to look at the Internets Future1, anyone would think that there was some tremendous threat like global warming, about to bring about its immediate demise, and that this would bring civilisation crashing down around our ears. The Internet has a great future behind it, of course. However, my thesis is that the Future Internet is about as relevant as Anthropogenic Global Warming (AGW), in the way it is being used to support various inappropriate activities. Remember that the start of all this was not the exhaustion of IPv4 address space, or the incredibly slow convergence time of BGP routes, or the problem of scaling router memory for FIBs. It was the US research community reacting to a minor (as in parochial) temporary problem of funding in Communications due to slow down within NSF and differing agendas within DARPA. It is not necessary to invoke all the hype and hysteria - it is both necessary and sufficient to talk about sustainable energy2, and good technical communications research, development, deployment and operations. To continue the analogy between FI and AGW, what we really do not need is yet more climatologists with dodgy data curation methodologies (or ethnographers studying Internet governance). What we do need is some solid engineering, to address a number of problems the Internet has. However, this is in fact happening, and would not stop happening if the entire Future Internet flagship was kidnapped by aliens. ""We dont need no"" government agency doing top down dictats about what to do when. It wont work and it will be a massive waste of time, energy and other resources - i.e. like AGW, it will be a load of hot air:) On the other hand, there are a number of deeper lessons from the Internet Architecture which might prove useful in other domains, and in the bulk of this opinion piece, I give examples of these, applying the Postel and End-to-end principles to transport, energy, government information/vices.",Communications systems research; The internet,Address space; Anthropogenic global warming; Communications systems; Convergence time; Data curation; Future internet; Government agencies; Hot air; Internet architecture; Internet governance; Research communities; Router memory; Technical communications; The internet; Topdown; Communication; Energy conversion; Global warming; Research; Internet
"Finucane H., Mitzenmacher M.",2,An improved analysis of the lossy difference aggregator,2010,2,"Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Israel; School of Engineering and Applied Sciences, Harvard University, United States",Harvard University;Weizmann Institute of Science,2,Israel;USA,2,5,4,"We provide a detailed analysis of the Lossy Difference Aggregator, a recently developed data structure for measuring latency in a router environment where packet losses can occur. Our analysis provides stronger performance bounds than those given originally, and leads us to a model for how to optimize the parameters for the data structure when the loss rate is not known in advance by using competitive analysis.",Competitive analysis; Hashing algorithms; Latency measurement; Lossy Difference Aggregator,Competitive analysis; Hashing algorithms; Loss rates; Lossy Difference Aggregator; Measuring latency; Performance bounds; Communication; Data structures
Haddadi H.,1,Fighting online click-fraud using bluff ads,2010,43,"Royal Veterinary College, University of London, United Kingdom",Royal Veterinary College;University of London,2,UK,1,6,4,"Online advertising is currently the richest source of revenue for many Internet giants. The increased number of online businesses, specialized websites and modern profiling techniques have all contributed to an explosion of the income of ad brokers from online advertising. The single biggest threat to this growth, is however, click-fraud. Trained botnets and individuals are hired by click-fraud specialists in order to maximize the revenue of certain users from the ads they publish on their websites, or to launch an attack between competing businesses. In this note we wish to raise the awareness of the networking research community on potential research areas within the online advertising field. As an example strategy, we present Bluff ads; a class of ads that join forces in order to increase the effort level for click-fraud spammers. Bluff ads are either targeted ads, with irrelevant display text, or highly relevant display text, with irrelevant targeting information. They act as a litmus test for the legitimacy of the individual clicking on the ads. Together with standard threshold-based methods, fake ads help to decrease click-fraud levels.",Advertising; Click-Fraud,Botnets; Click-Fraud; Litmus test; Online advertising; Online business; Research communities; Spammers; Commerce; Computer crime; Marketing; Websites; Crime
"Joumblatt D., Teixeira R., Chandrashekar J., Taft N.",4,Perspectives on tracing end-hosts: A survey summary,2010,3,"CNRS and UPMC, Paris Universitas, France; Intel Labs, India",Intel;Paris Universitas,2,France;India,2,7,6,"There is an amazing paucity of data that is collected directly from users' personal computers. One key reason for this is the perception among researchers that users are unwilling to participate in such a data collection effort. To understand the range of opinions on matters that occur with end-host data tracing, we conducted a survey of 400 computer scientists. In this paper, we summarize and share our findings.",End-host data collection; Network performance diagnosis; User experience,Computer scientists; Data collection; Paucity of data; Performance diagnosis; User experience; Data acquisition; Network performance; Personal computers; Surveys
"Trossen D., Särelä M., Sollins K.",3,Arguments for an information-centric internetworking architecture,2010,105,"Ericsson Research, Helsinki, Finland; MIT CSAIL, Cambridge, MA, United States",Ericsson Research;MIT,2,Finland;USA,2,18,16,"The current Internet architecture focuses on communicating entities, largely leaving aside the information to be ex-changed among them. However, trends in communication scenarios show that WHAT is being exchanged becoming more important than WHO are exchanging information. Van Jacobson describes this as moving from interconnecting machines to interconnecting information. Any change of this part of the Internet needs argumentation as to why it should be undertaken in the first place. In this position paper, we identify four key challenges, namely information-centrism of applications, supporting and exposing tussles, increasing accountability, and addressing attention scarcity, that we believe an information-centric internetworking architecture could address better and would make changing such crucial part worthwhile. We recognize, however, that a much larger and more systematic debate for such change is needed, underlined by factual evidence on the gain for such change.",Information-centric networking; Publish-subscribe,Information-centric networking; Internet architecture; Internetworking architecture; Position papers; Publish-subscribe; Internet; Architecture
"Choffnes D.R., Bustamante F.E.",2,Pitfalls for testbed evaluations of internet systems,2010,13,"Northwestern University, United States",Northwestern University,1,USA,1,26,21,"Today's open platforms for network measurement and distributed system research, which we collectively refer to as testbeds in this article, provide opportunities for controllable experimentation and evaluations of systems at the scale of hundreds or thousands of hosts. In this article, we identify several issues with extending results from such platforms to Internet wide perspectives. Specifically, we try to quantify the level of inaccuracy and incompleteness of testbed results when applied to the context of a large-scale peerto-peer (P2P) system. Based on our results, we emphasize the importance of measurements in the appropriate environment when evaluating Internet-scale systems.",Evaluation; Internet-scale systems; Peer-to-peer,Distributed systems; Evaluation; Internet system; Internet-scale systems; Network measurement; Peer to peer; Peer-to-Peer system; Internet; Testbeds; Peer to peer networks
"Dovrolis C., Streelman J.T.",2,Evolvable network architectures: What can we learn from biology?,2010,20,"College of Computing, Georgia Tech, United States; School of Biology, Georgia Tech, United States",Georgia Tech,1,USA,1,12,6,"There is significant research interest recently to understand the evolution of the current Internet, as well as to design clean-slate Future Internet architectures. Clearly, even when network architectures are designed from scratch, they have to evolve as their environment (i.e., technological constraints, service requirements, applications, economic conditions, etc) always changes. A key question then is: what makes a network architecture evolvable? What determines the ability of a network architecture to evolve as its environment changes? In this paper, we review some relevant ideas about evolvability from the biological literature. We examine the role of robustness and modularity in evolution, and their relation with evolvability. We also discuss evolutionary kernels and punctuated equilibria, two important concepts that may be relevant to the so-called ossification of the core Internet protocols. Finally, we examine optimality, a design objective that is often of primary interest in engineering but that does not seem to be abundant in biology.",Evolutionary Kernels; Evolvability; Internet; Modularity; Punctuated Equilibria; Robustness,Design objectives; Economic condition; Environment change; Evolutionary Kernels; Evolvability; Evolvable; Future internet architecture; Modularity; Optimality; Punctuated Equilibria; Service requirements; Technological constraints; Biology; Internet; Internet protocols; Robustness (control systems); Network architecture
Claffy K.C.,1,Workshop on internet economics (WIE2009) report,2010,1,"CAIDA/UC, San Diego, San Diego, CA, United States",University of California San Diego,1,USA,1,15,14,"On September 23, 2009, CAIDA hosted a virtual Workshop on Internet Economics [3] to bring together network technology and policy researchers, commercial Internet facilities and service providers, and communications regulators to explore a common goal: framing a concrete agenda for the emerging but empirically stunted field of Internet infrastructure economics. With participants stretching from Washington D.C. to Queensland, Australia, we used the electronic conference hosting facilities supported by the California Institute of Technology (CalTech) EVO Collaboration Network [2]. This report describes the workshop discussions and presents relevant open research questions identified by participants.",Economics; Internet; Network management,Australia; California Institute of Technology; Caltech; Collaboration network; Commercial internet; Internet economics; Internet infrastructure; Network technologies; Queensland; Research questions; Service provider; Virtual workshops; Washington; Economics; Network management; Internet
Mahajan R.,1,How to build a research system in your spare time,2010,1,"Microsoft Research, India",Microsoft,1,India,1,2,0,"This paper is based on a talk that I gave at CoNEXT 2009. Inspired by Hal Varian's paper on building economic models, 1 it describes a research method for building computer systems. I find this method useful in my work and hope that some readers will find it helpful as well.",Computer systems; Research method,Economic models; research methods; Research system; Communication; Computer systems; Research
"Carbone M., Rizzo L.",2,Dummynet revisited,2010,179,"Dip. di Ingegneria Dell'Informazione, Università di Pisa, Italy",Università di Pisa,1,Italy,1,24,15,"Dummynet is a widely used link emulator, developed long ago to run experiments in user-configurable network environments. Since its original design, our system has been extended in various ways, and has become very popular in the research community due to its features and to the ability to emulate even moderately complex network setups on unmodified operating systems. We have recently made a number of extensions to the emulator, including loadable packet schedulers, support for better MAC layer modeling, the inclusion in PlanetLab, and development of Linux and Windows versions in addition to the native FreeBSD and Mac OS X ones. The goal of this paper is to present in detail the current features of Dummynet, compare it with other emulation solutions, and discuss what operating conditions should be considered and what kind of accuracy to expect when using an emulation system.",Emulation; Network protocols; Performance evaluation; Wireless emulation,Complex networks; Dummynet; Emulation; Emulation system; FreeBSD; MAC layer; Mac OS X; Network environments; Operating condition; Original design; Packet scheduler; Performance evaluation; PlanetLab; Research communities; Windows version; Network protocols; Computer operating systems
"Cheng P.-C., Zhang B., Zhao X., Zhang L.",4,Longitudinal study of BGP monitor session failures,2010,10,"Department of Computer Science, University of California, Los Angeles, United States; Department of Computer Science, University of Arizona, United States",University of Arizona;University of California Los Angeles,2,USA,1,19,14,"BGP routing data collected by RouteViews and RIPE RIS have become an essential asset to both the network research and operation communities. However, it has long been speculated that the BGP monitoring sessions between operational routers and the data collectors fail from time to time. Such session failures lead to missing update messages as well as duplicate updates during session re-establishment, making analysis results derived from such data inaccurate. Since there is no complete record of these monitoring session failures, data users either have to sanitize the data discretionarily with respect to their specific needs or, more commonly, assume that session failures are infrequent enough and simply ignore them. In this paper, we present the first systematic assessment and documentary on BGP session failures of RouteViews and RIPE data collectors over the past eight years. Our results show that monitoring session failures are rather frequent, more than 30% of BGP monitoring sessions experienced at least one failure every month. Furthermore, we observed failures that happen to multiple peer sessions on the same collector around the same time, suggesting that the collector's local problems are a major factor in the session instability. We also developed a web site as a community resource to publish all session failures detected for RouteViews and RIPE RIS data collectors to help users select and clean up BGP data before performing their analysis.",BGP Monitoring; BGP Session Reset,Community resources; Data collectors; Data users; Local problems; Longitudinal study; Major factors; Routing data; Session Reset; Systematic assessment; Interlocking signals; Routers
"Caesar M., Rexford J., Casado M., Koponen T., Shenker S.",5,Dynamic route computation considered harmful,2010,26,"University of Illinois, Urbana-Champaign, United States; Princeton University, United States; Nicira Networks Inc., United States; University of California, Berkeley, United States",Nicira Networks;Princeton University;University of California Berkeley;UIUC,4,USA,1,24,23,"This paper advocates a different approach to reduce routing convergence-side-stepping the problem by avoiding it in the first place! Rather than recomputing paths after temporary topology changes, we argue for a separation of timescale between offline computation of multiple diverse paths and online spreading of load over these paths. We believe decoupling failure recovery from path computation leads to networks that are inherently more efficient, more scalable, and easier to manage.",Convergence; Internet architecture; Protocols; Routing,Convergence; Dynamic routes; Failure recovery; Internet architecture; Off-line computation; Path computation; Re-computing; Routing; Time-scales; Internet protocols; Network protocols; Network architecture
"Liu H., Orban D.",2,Remote network labs: An on-demand network cloud for configuration testing,2010,9,"Accenture Technology Labs, 50 W. San Fernando St., San Jose, CA 95113, United States",Accenture Technology Labs,1,USA,1,20,14,"Network equipment is difficult to configure correctly. To minimize configuration errors, network administrators typically build a smaller scale test lab replicating the production network and test out their configuration changes before rolling out the changes to production. Unfortunately, building a test lab is expensive and the test equipment is rarely utilized. In this paper, we present Remote Network Labs, which is aimed at leveraging the expensive network equipment more efficiently and reducing the cost of building a test lab. Similar to a server cloud such as Amazon EC2, a user could request network equipment remotely and connect them through a GUI or web services interface. The network equipment is geographically distributed, allowing us to reuse test equipment anywhere. Beyond saving costs, Remote Network Labs brings about many additional benefits, including the ability to fully automate network configuration testing. Copyright 2010 ACM.",Configuration testing; IP tunnels; Network cloud; Test labs,Ability testing; Chemical laboratories; Equipment testing; Laboratories; Web services; Configuration errors; Network administrator; Network configuration; Network equipment; Production network; Remote network lab; Smaller-scale tests; Test equipments; Equipment
"Hao F., Lakshman T.V., Mukherjee S., Song H.",4,Enhancing dynamic cloud-based services using network virtualization,2010,49,"Bell Labs, Alcatel-Lucent, United States",Bell Labs,1,USA,1,22,18,"It is envisaged that services and applications will migrate to a cloud-computing paradigm where thin-clients on userdevices access, over the network, applications hosted in data centers by application service providers. Examples are cloudbased gaming applications and cloud-supported virtual desktops. For good performance and efficiency, it is critical that these services are delivered from locations that are the best for the current (dynamically changing) set of users. To achieve this, we expect that services will be hosted on virtual machines in interconnected data centers and that these virtual machines will migrate dynamically to locations bestsuited for the current user population. A basic network infrastructure need then is the ability to migrate virtual machines across multiple networks without losing service continuity. In this paper, we develop mechanisms to accomplish this using a network-virtualization architecture that relies on a set of distributed forwarding elements with centralized control (borrowing on several recent proposals in a similar vein). We describe a preliminary prototype system, built using Openflow components, that demonstrates the feasibility of this architecture in enabling seamless migration of virtual machines and in enhancing delivery of cloud-based services. Copyright 2010 ACM.",Data center; Virtualization; VM migration,Cloud computing; Network architecture; Network security; Population statistics; Virtual machine; Virtual reality; Virtualization; Application service provider; Centralized control; Data centers; Gaming applications; Network infrastructure; Network virtualization; Services and applications; Vm migrations; Distributed computer systems
"Chiu D.M., Fu T.Z.J.",2,"""Publish or perish"" in the internet age - A study of publication statistics in computer networking research",2010,9,"Department of Information Engineering, CUHK, Hong Kong",Chinese University of Hong Kong,1,Hong Kong,1,17,7,"This study takes papers from a selected set of computer networking conferences and journals spanning the past twenty years (1989-2008) to produce various statistics to show how our community publishes papers, and how this process is changing over the years. We observe the rapid growth in the rate of publications, venues, citations, authors, and number of co-authors. We explain how these quantities are related, in particular explore how they are related over time and the reasons behind the changes. The widely accepted model to explain the power law distribution of paper citations is preferential attachment. We propose an extension and refinement that suggests elapsed time is also a factor to determine which papers get cited. We try to compare the selected venues based on citation count, and discuss how we might think about these comparisons, in terms of the roles played by different venues, and the ability to predict impact by venues, and citation counts. The treatment of these issues is general and can be applied to study publication patterns in other research communities. The larger goal of this study is to generate discussion about our publication system, and work towards a vision to transform our publication system for better scalability and effectiveness.",Academic publishing; Citation; Co-authorship; G-index; H-index,Indexing (of information); Paper; Academic publishing; Citation; Co-authorships; G indices; H indices; Publishing
"Krishnamurthy B., Wills C.E.",2,On the leakage of personally identifiable information via online social networks,2010,48,"AT and T Labs - Research, Florham Park, NJ, United States; Worcester Polytechnic Institute, Worcester, MA, United States",AT and T Labs;Worcester Polytechnic Institute,2,USA,1,14,6,"For purposes of this paper, we define ""Personally identifiable information"" (PII) as information which can be used to distinguish or trace an individual's identity either alone or when combined with other information that is linkable to a specific individual. The popularity of Online Social Networks (OSN) has accelerated the appearance of vast amounts of personal information on the Internet. Our research shows that it is possible for third-parties to link PII, which is leaked via OSNs, with user actions both within OSN sites and elsewhere on non-OSN sites. We refer to this ability to link PII and combine it with other information as ""leakage"". We have identified multiple ways by which such leakage occurs and discuss measures to prevent it. Copyright 2010 ACM.",Online social networks; Personally identifiable information; Privacy,Communication; Data privacy; Linkable; On-line social networks; Online social networks (OSN); Personal information; Personally identifiable information; Third parties; User action; Social networking (online)
"Bao X., Choudhury R.R.",2,VUPoints: Collaborative sensing and video recording through mobile phones,2010,5,"Department of ECE, Duke University, Durham, NC, United States",Duke University,1,USA,1,9,8,"Mobile phones are becoming a convergent platform for sensing, computation, and communication. This paper envisions VUPoints, a collaborative sensing and video-recording system that takes advantage of this convergence. Ideally, when multiple phones in a social gathering run VUPoints, the output is expected to be a short video-highlights of the occasion, created without human intervention. To achieve this, mobile phones must sense their surroundings and collaboratively detect events that qualify for recording. Short video-clips from different phones can be combined to produce the highlights of the occasion. This paper reports exploratory work towards this longer term project. We present a feasibility study, and show how social events can be sensed through mobile phones and used as triggers for video-recording. While false positives cause inclusion of some uninteresting videos, we believe that further research can significantly improve the efficacy of the system. Copyright 2010 ACM.",Activity recognition; Collaborative ambience sensing; Image processing; Mobile phones; Participatory sensing; Social networks; Video recording; Wearable devices,Activity recognition; Collaborative ambience sensing; Participatory sensing; Social Networks; Wearable devices; Image processing; Imaging systems; Mobile devices; Mobile phones; Mobile telecommunication systems; Recording instruments; Social networking (online); Telephone; Telephone sets; Video recording; Wireless networks; Image recording
"Rumble S.M., Stutsman R., Levis P., Mazières D., Zeldovich N.",5,Apprehending joule thieves with cinder,2010,4,"Stanford University, 353 Serra Mall, Stanford, CA 94305, United States; MIT, 32 Vassar Street, Cambridge, MA 02139, United States",MIT;Stanford University,2,USA,1,13,6,"Energy is the critical limiting resource to mobile computing devices. Correspondingly, an operating system must track, provision, and ration how applications consume energy. The emergence of third-party application stores and marketplaces makes this concern even more pressing. A third-party application must not deny service through excessive, unforeseen energy expenditure, whether accidental or malicious. Previous research has shown promise in tracking energy usage and rationing it to meet device lifetime goals, but such mechanisms and policies are still nascent, especially regarding user interaction. We argue for a new operating system, called Cinder, which builds on top of the HiStar OS. Cinder's energy awareness is based on hierarchical capacitors and task profiles. We introduce and explore these abstractions, paying particular attention to the ways in which policies could be generated and enforced in a dynamic system. Copyright 2010 ACM.",Capacitor; Energy; Hierarchical,Capacitors; Device lifetime; Energy; Energy awareness; Energy expenditure; Hierarchical; Mobile computing devices; Third party application (Apps); User interaction; Communication
"Chen X., Mao Y., Morley Mao Z., Van Merwe J.D.",4,DECOR: Declarative network management and operation,2010,13,"Department of EECS, University of Michigan, Ann Arbor, MI, United States; ATandT Labs - Research, Shannon Laboratory, Florham Park, NJ, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,14,9,"Network management operations are complicated, tedious and error-prone, requiring significant human involvement and expert knowledge. In this paper, we first examine the fundamental components of management operations and argue that the lack of automation is due to a lack of programmability at the right level of abstraction. To address this challenge, we present DECOR, a database-oriented, declarative framework towards automated network management. DECOR models router configuration and any generic network status as relational data in a conceptually centralized database. As such, network management operations can be represented as a series of transactional database queries, which provide the benefit of atomicity, consistency and isolation. The rulebased language in DECOR provides the flexible programmability to specify and enforce network-wide management constraints, and achieve high-level task scheduling. We describe the design rationale and architecture of DECOR and present some preliminary examples applying our approach to common network management tasks. Copyright 2010 ACM.",Declarative language; Network management,Centralized data-base; Declarative Languages; Design rationale; Error prones; Expert knowledge; Fundamental component; Generic networks; Level of abstraction; Management operation; Programmability; Relational data; Router configuration; Rule-based language; Task-scheduling; Transactional database; High level languages; Management; Query languages; Routers; Scheduling; Network management
Keys K.,1,Internet-scale IP alias resolution techniques,2010,43,"Cooperative Association for Internet Data Analysis (CAIDA), University of California, San Diego, United States",University of California San Diego,1,USA,1,22,10,"The well-known traceroute probing method discovers links between interfaces on Internet routers. IP alias resolution, the process of identifying IP addresses belonging to the same router, is a critical step in producing Internet topology maps. We compare the performance and accuracy of known alias resolution techniques, propose some enhancements, and suggest a practical combination of techniques that can produce the most accurate and complete IP-to-router mapping at macroscopic scale.",Alias resolution; Ally; APAR; DisCarte; Iffinder; Kapar; Mercator; RadarGun,Internet; Routers; Ally; APAR; DisCarte; Iffinder; Kapar; Mercator; RadarGun; Internet protocols
"Kulkarni P., Chin W.H., Farnham T.",3,Radio resource management considerations for LTE femto cells,2010,56,"Telecommunications Research Laboratory, Toshiba Research Europe Ltd., 32, Queen Square, Bristol - BS1 4ND, United Kingdom",Toshiba Research Europe Ltd.,1,UK,1,6,6,"Femtocell access points (FAPs), also popularly known as Home Base Stations, are small base stations for use within indoor environments to improve coverage and capacity, FAPs have a limited range (e,g, limited to a home or office area) but offer immense capacity improvements for the network due to the ability to reuse a frequency more often as a result of smaller coverage areas, Because there may be thousands of these devices and since the nature of deployment is adhoc, it may not be possible to carry out elaborate frequency planning like that in the traditional cellular network, This paper aims to outline the radio resource management considerations within the context of femto cells, the broader objective being to initiate a discussion and encourage research in the areas highlighted.",Algorithms; Femtocells; Interference management; LTE; Radio resource management (rrm); Survey,Algorithms; Base stations; Communication channels (information theory); Mobile telecommunication systems; Natural resources management; Radio; Radio communication; Resource allocation; Surveying; Wireless ad hoc networks; Access points; Capacity improvement; Cellular network; Femto-cells; Frequency planning; Indoor environment; Interference management; Radio resource management; Femtocell
"Hübsch C., Mayer C.R., Mies S., Bless R., Waldhorst O.R., Zitterbart M.",6,Reconnecting the internet with ariba: Self-organizing provisioning of end-to-end connectivity in heterogeneous networks,2010,5,"Institute of Telematics, Universität Karlsruhe (TH), Germany",Universität Karlsruhe (TH),1,Germany,1,4,3,"End-to-End connectivity in today's Internet can no longer be taken for granted. Middleboxes, mobility, and protocol heterogeneity complicate application development and often result in application-specific solutions. In our demo we present ariba: an overlay-based approach to handle such network challenges and to provide consistent homogeneous network primitives in order to ease application and service development.",Heterogeneity; Overlays; Peer-to-Peer networking,Distributed computer systems; Heterogeneous networks; Pavement overlays; Application development; Application specific; End-to-end connectivity; Heterogeneity; Homogeneous network; Middleboxes; Peer-to-peer networking; Service development; Mobile telecommunication systems
"Liang Y., Peng W.",2,Minimizing energy consumptions in wireless sensor networks via two-modal transmission,2010,40,"Department of Computer and Information Science, Indiana University, Purdue University Indianapolis, United States",Indiana University;Purdue University Indianapolis,2,India;USA,2,12,9,"We present a sophisticated framework to systematically explore the temporal correlation in environmental monitoring wireless sensor networks, The presented framework optimizes lossless data compression in communications given the resource constraint of sensor nodes, The insights and analyses obtained from the framework can directly lead to innovative and better design of data gathering protocols for wireless sensor networks operated in noisy environments to dramatically reduce the energy consumptions.",Energy efficiency; Lossless compression; Wireless sensor networks,Energy efficiency; Sensor nodes; Data gathering protocols; Environmental Monitoring; Lossless compression; Lossless data compression; Noisy environment; Resource Constraint; Temporal correlations; Wireless sensor networks
"Kelly J., Araujo W., Banerjee K.",3,Rapid service creation using the JUNOS SDK,2010,10,"Juniper Networks, Inc., United States",Juniper Networks,1,USA,1,6,1,The creation of services on IP networks is a lengthy process. The development time is further increased if this involves the equipment manufacturer adding third-party technology in their product. In this work we describe how the JUNOS SDK (part of Juniper Networks Partner Solution Development Platform) facilitates innovation and can be used to considerably shorten the development cycle for the creation of services based on embedding third-party software into Juniper Networks routers. We describe how the JUNOS SDK exposes programmatic interfaces to enable packet manipulation by third-party software and how it can be used as a common platform for deploying unique services through the combination of multiple components from multiple parties. Copyright 2010 ACM.,Internet protocol; JUNOS; Network operating system; Network services; Programmable routers; Rapid application development,Routers; JUNOS; Network operating system; Network services; Programmable routers; Rapid application development; Internet protocols
"Anwer M.B., Feamster N.",2,"Building a fast, virtualized data plane with programmable hardware",2010,15,"School of Computer Science, Georgia Tech, United States",Georgia Tech,1,USA,1,18,11,"Network virtualization allows many networks to share the same underlying physical topology; this technology has offered promise both for experimentation and for hosting multiple networks on a single shared physical infrastructure. Much attention has focused on virtualizing the network control plane, but, ultimately, a limiting factor in the deployment of these virtual networks is data-plane performance: Virtual networks must ultimately forward packets at rates that are comparable to native, hardware-based approaches. Aside from proprietary solutions from vendors, hardware support for virtualized data planes is limited. The advent of open, programmable network hardware promises flexibility, speed, and resource isolation, but, unfortunately, hardware does not naturally lend itself to virtualization. We leverage emerging trends in programmable hardware to design a flexible, hardware-based data plane for virtual networks. We present the design, implementation, and preliminary evaluation of this hardware-based data plane and show how the proposed design can support many virtual networks without compromising performance or isolation. Copyright 2010 ACM.",NetFPGA; Network virtualization,Virtual reality; Virtualization; Hardware-based approach; Multiple networks; NetFPGA; Network control plane; Network virtualization; Programmable hardware; Programmable network; Proprietary solutions; Hardware
"Tang J., Musolesi M., Mascolo C., Latora V.",4,Characterising temporal distance and reachability in mobile and online social networks,2010,66,"Computer Laboratory, University of Cambridge, United Kingdom; Dipartlmento di Fisica, University of Catania, Italy",University of Cambridge;University of Catania,2,Italy;UK,2,15,14,"The analysis of social and technological networks has attracted a lot of attention as social networking applications and mobile sensing devices have given us a wealth of real data. Classic studies looked at analysing static or aggregated networks, i.e., networks that do not change over time or built as the results of aggregation of information over a certain period of time. Given the soaring collections of measurements related to very large, real network traces, researchers are quickly starting to realise that connections are inherently varying over time and exhibit more dimensionality than static analysis can capture. In this paper we propose new temporal distance metrics to quantify and compare the speed (delay) of information diffusion processes taking into account the evolution of a network from a global view. We show how these metrics are able to capture the temporal characteristics of time-varying graphs, such as delay, duration and time order of contacts (interactions), compared to the metrics used in the past on static graphs. We also characterise network reachability with the concepts of in- and out-components. Then, we generalise them with a global perspective by defining temporal connected components. As a proof of concept we apply these techniques to two classes of time-varying networks, namely connectivity of mobile devices and interactions on an online social network. Copyright 2010 ACM.",Complex networks; Information diffusion; Social networks; Temporal efficiency; Temporal graphs; Temporal metrics,Complex networks; Online systems; Websites; Information diffusion; Information diffusion process; On-line social networks; Social networking applications; Technological networks; Temporal characteristics; Temporal graphs; Temporal metrics; Social networking (online)
"Yap K.-K., Kobayashi M., Sherwood R., Huang T.-Y., Chan M., Handigol N., McKeown N.",7,Open roads: Empowering research in mobile networks,2010,173,"Stanford University, United States; NEC System Platforms Research Labs, United States; Deutsche Telekom Inc., RandD Lab, United States",Deutsche Telekom Laboratories;NEC;Stanford University,3,USA,1,8,4,"We present OpenRoads, an open-source platform for innovation in mobile networks. OpenRoads enable researchers to innovate using their own production networks, through providing an wireless extension OpenFlow. Therefore, you can think of OpenRoads as ""OpenFlow Wireless"". The OpenRoads' architecture consists of three layers: flow, slicing and controller. These layers provide flexible control, virtualization and high-level abstraction. This allows researchers to implement wildly different algorithms and run them concurrently in one network. OpenRoads also incorporates multiple wireless technologies, specifically WiFi and WiMAX. We have deployed OpenRoads, and used it as our production network. Our goal here is for those to deploy OpenRoads and build their own experiments on it.",Flowvisor; Openflow; Wireless testbed,Flexible control; Flowvisor; High-level abstraction; Mobile networks; Multiple wireless technologies; Open road; Open-source; Openflow; Production network; Three-layer; Virtualizations; Wireless test beds; Research; Test facilities; Testbeds; Wi-Fi; Wimax; Wireless networks
"Carpenter B.E., Partridge C.",2,Internet requests for comments (RFCS) as scholarly publications,2010,2,"Department of Computer Science, University of Auckland, Auckland, New Zealand; BBN Technologies, United States",BBN Technologies;University of Auckland,2,New Zealand;USA,2,10,3,"This note describes the various peer review processes applied to Internet Requests for Comments (RFCs) over a number of years, and suggests that these have been up to normal scholarly standards since at least 1992. The authors believe that these documents should be considered the equivalent of scholarly publications.",Request for comments; RFC,Peer-review process; Request for comments; Scholarly publication; Communication
"Egi N., Hoerdt M., Mathy L., Papadimitriou P., Greenhalgh A., Handley M., Huici F.",7,A platform for high performance and flexible virtual routers on commodity hardware,2010,14,"Computing Dept., Lancaster University, United Kingdom; Dept. of Computer Science, University College, London, United Kingdom; NEC Europe Ltd, Germany",Lancaster University;University College London,2,Germany;UK,2,6,4,"Multi-core CPUs, along with recent advances in memory and buses, render commodity hardware a strong candidate for software router virtualization. In this context, we present the design of a new platform for virtual routers on modern PC hardware. We further discuss our design choices in order to achieve both high performance and flexibility for packet processing.",Commodity hardware; Routers; Virtualization,Program processors; Routers; Virtual reality; Virtualization; Commodity hardware; Multi-core cpus; Packet processing; PC hardware; Software routers; Virtual routers; Hardware
"Halperin D., Hu W., Sheth A., Wetherall D.",4,802.11 with multiple antennas for dummies,2010,31,"University of Washington, Intel Labs Seattle, United States",Intel;University of Washington at St. Louis,2,USA,1,9,7,"The use of multiple antennas and MIMO techniques based on them is the key feature of 802.11n equipment that sets it apart from earlier S02,11a/g equipment, It is responsible for superior performance, reliability and range, In this tutorial, we provide a brief introduction to multiple antenna techniques, We describe the two main classes of those techniques, spatial diversity and spatial multiplexing, To ground our discussion, we explain how they work in 802.11n NICs in practice.",802.11n; MIMO; Multiple antennas,MIMO systems; Multiplexing equipment; 802.11n; Key feature; MIMO techniques; Multiple antenna; Multiple antenna techniques; Spatial diversity; Spatial multiplexing; Antennas
"Benson T., Anand A., Akella A., Zhang M.",4,Understanding data center traffic characteristics,2010,258,"University of Wisconsin, Madison, WI, United States; Microsoft Research, Redmond, WA, United States",Microsoft;University of Wisconsin-Madison,2,USA,1,10,3,"As data centers become more and more central in Internet communications, both research and operations communities have begun to explore how to better design and manage them. In this paper, we present a preliminary empirical study of end-to-end traffic patterns in data center networks that can inform and help evaluate research and operational approaches. We analyze SNMP logs collected at 19 data centers to examine temporal and spatial variations in link loads and losses. We find that while links in the core are heavily utilized the ones closer to the edge observe a greater degree of loss. We then study packet traces collected at a small number of switches in one data center and find evidence of ON-OFF traffic behavior. Finally, we develop a framework that derives ON-OFF traffic parameters for data center traffic sources that best explain the SNMP data collected for the data center. We show that the framework can be used to evaluate data center traffic engineering approaches. We are also applying the framework to design network-level traffic generators for data centers. Copyright 2010 ACM.",Data center traffic; Traffic modeling,Communication; Data center networks; Data centers; Internet communication; Temporal and spatial variation; Traffic characteristics; Traffic Engineering; Traffic generators; Traffic model; Internet protocols
"Burkhart R., Schatzmann D., Trammell B., Boschi E., Plattner B.",5,The role of network trace anonymization under attack,2010,38,"ETH Zurich, Switzerland; Hitachi Europe, United Kingdom",ETH Zurich,1,Switzerland;UK,2,27,27,"In recent years, academic literature has analyzed many attacks on network trace anonymization techniques. These attacks usually correlate external information with anonymized data and successfully de-anonymize objects with distinctive signatures. However, analyses of these attacks still underestimate the real risk of publishing anonymized data, as the most powerful attack against anonymization is traffic injection. We demonstrate that performing live traffic injection attacks against anonymization on a backbone network is not difficult, and that potential countermeasures against these attacks, such as traffic aggregation, randomization or field generalization, are not particularly effective. We then discuss tradeoffs of the attacker and defender in the so-called injection attack space. An asymmetry in the attack space significantly increases the chance of a successful de-anonymization through lengthening the injected traffic pattern. This leads us to re-examine the role of network data anonymization. We recommend a unified approach to data sharing, which uses anonymization as a part of a technical, legal, and social approach to data protection in the research and operations communities.",Anonymization; Injection attacks; Privacy,Communication; Data privacy; Academic literature; Anonymization; Back-bone network; External informations; Network data anonymization; Traffic aggregation; Traffic pattern; Unified approach; Network security
"Edwards A., Fischer A., Lain A.",3,Diverter: A new approach to networking within virtualized infrastructures,2009,14,"HP Laboratories, Long Down Avenue, Stoke Gifford, Bristol BS34 8QZ, United Kingdom",HP Labs,1,UK,1,19,16,"As virtualized data-centres become the back-end platforms behind a new generation of utility and cloud computing infrastructures (such as AmazonAWS [1]) their multi-tenancy, scale and complexity introduce new challenges that especially affect the networking layer. Multiple customers' requirements for varying logical network topologies must be simultaneously accommodated on the shared, underlying network fabric in a secure manner. Diverter is a new approach to network virtualization that targets these highly flexible, large-scale, multi-tenanted environments and advances the current state-of-the-art by implementing an efficient, fully distributed virtualized routing system that allows end-to-end communication between any endpoint with just a single network ""hop"". We have implemented a prototype of this solution that, in certain network configurations, achieves a throughput improvement of at least 66 % compared to alternative approaches. Copyright 2009 ACM.",Distributed overlays; Network virtualization; Packet filtering; Routing,Alternative approach; Cloud computing; End-to-End communication; Logical network; Multi-tenanted; Network configuration; Network virtualization; New approaches; Packet filtering; Routing system; Single networks; Throughput improvement; Underlying networks; Distributed computer systems; Electric network topology; Arts computing
"Benson T., Anand A., Akella A., Zhang M.",4,Understanding data center traffic characteristics,2009,70,"UW-Madison, United States; Microsoft Research, United States",Microsoft,1,USA,1,9,3,"As data centers become more and more central in Internet communications, both research and operations communities have begun to explore how to better design and manage them. In this paper, we present a preliminary empirical study of end-to-end traffic patterns in data center networks that can inform and help evaluate research and operational approaches. We analyze SNMP logs collected at 19 data centers to examine temporal and spatial variations in link loads and losses. We find that while links in the core are heavily utilized the ones closer to the edge observe a greater degree of loss. We then study packet traces collected at a small number of switches in one data center and find evidence of ON-OFF traffic behavior. Finally, we develop a framework that derives ON-OFF traffic parameters for data center traffic sources that best explain the SNMP data collected for the data center. We show that the framework can be used to evaluate data center traffic engineering approaches. We are also applying the framework to design network-level traffic generators for data centers. Copyright 2009 ACM.",Data center traffic; Traffic modeling,Data centers; Empirical studies; Internet communication; Link Loads; Number of switches; ON-OFF traffic; Temporal and spatial variation; Traffic characteristics; Traffic Engineering; Traffic generators; Traffic modeling; Traffic pattern; Traffic sources; Internet protocols; Research; Satellite communication systems
"Chen Y., Griffith R., Liu J., Katz R.H., Joseph A.D.",5,Understanding TCP Incast throughput collapse in datacenter networks,2009,139,"RAD Lab, EECS Dept. UC Berkeley, United States; Intel Labs Berkeley, United States",University of California Berkeley;Intel,2,USA,1,11,6,"TCP Throughput Collapse, also known as Incast, is a pathological behavior of TCP that results in gross under-utilization of link capacity in certain many-to-one communication patterns. This phenomenon has been observed by others in distributed storage, MapReduce and web-search workloads. In this paper we focus on understanding the dynamics of Incast. We use empirical data to reason about the dynamic system of simultaneously communicating TCP entities. We propose an analytical model to account for the observed Incast symptoms, identify contributory factors, and explore the efficacy of solutions proposed by us and by others. Copyright 2009 ACM.",Incast; TCP; Throughput collapse; Unix,Analytical model; Communication pattern; Distributed storage; Dynamic Systems; Empirical data; Incast; Link capacities; Many-to-one; TCP throughput; Dynamical systems; Mathematical models; UNIX; World Wide Web; Throughput
"Karpilovsky E., Breslau L., Gerber A., Sen S.",4,Multicast redux: A first look at enterprise multicast traffic,2009,5,"Princeton University, United States; AT and T Labs - Research, United States",AT and T Labs;Princeton University,2,USA,1,21,14,"IP multicast, after spending much of the last 20 years as the subject of research papers, protocol design efforts and limited experimental usage, is finally seeing significant deployment in production networks. The efficiency afforded by one-to-many network layer distribution is well-suited to such emerging applications as IPTV, file distribution, conferencing, and the dissemination of financial trading information. However, it is important to understand the behavior of these applications in order to see if network protocols are appropriately supporting them. In this paper we undertake a study of enterprise multicast traffic as observed from the vantage point of a large VPN service provider. We query multicast usage information from provider edge routers for our analysis. To our knowledge, this is the first study of production multicast traffic. Our purpose is both to understand the characteristics of the traffic (in terms of flow duration, throughput, and receiver dynamics) and to gain insight as to whether the current mechanisms support multicast VPNs can be improved. Our analysis reveals several classes of multicast traffic for which changes to the underlying protocols may yield benefits. Copyright 2009 ACM.",Enterprise Networks; Multicast; VPN,Current mechanisms; Edge routers; Emerging applications; Enterprise networks; File distribution; Financial trading; First look; Flow duration; Gain insight; IP Multicast; Multicast traffic; Multicasts; Production network; Protocol design; Research papers; VPN services; Internet protocols; Network layers; Research; Multicasting
"Taylor P.J., Griffin T.G.",2,A model of configuration languages for routing protocols,2009,2,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,13,10,"The emergence of programmable routers brings opportunities to design and implement new routing protocols with expressive policy, that better meet the needs of network operators than the current range of protocols. This also introduces significant challenges in designing and understanding protocols. Algebraic routing provides a useful but highly model of networks as weighted graphs, ignoring the complex distributed configuration and computation aspects of practical routing protocols. We present an algebraic model of router configuration languages, reducing the gap between the routing theory and real implementations, as the basis for a language that can be used to specify the operation of routing protocols.",Routing algebra; Routing protocol configuration,Algebraic models; Configuration languages; Current range; Distributed configuration; Network operator; Programmable routers; Router configuration; Routing algebra; Weighted graph; Algebra; Linguistics; Query languages; Routing protocols; Routers
"Kelly J., Araujo W., Banerjee K.",3,Rapid service creation using the JUNOS SDK,2009,6,"Juniper Networks, Inc., United States",Juniper Networks,1,USA,1,6,1,The creation of services on IP networks is a lengthy process. The development time is further increased if this involves the equipment manufacturer adding third-party technology in their product. In this work we describe how the JUNOS SDK (part of Juniper Networks Partner Solution Development Platform) facilitates innovation and can be used to considerably shorten the development cycle for the creation of services based on embedding third-party software into Juniper Networks routers. We describe how the JUNOS SDK exposes programmatic interfaces to enable packet manipulation by third-party software and how it can be used as a common platform for deploying unique services through the combination of multiple components from multiple parties.,Internet protocol; JUNOS; Network operating system; Network services; Programmable routers; Rapid application development,Common platform; Development cycle; Development platform; Development time; Equipment manufacturers; IP networks; Juniper networks; Multiple components; Network operating system; Network services; Programmable routers; Rapid application development; Service creation; Computer operating systems; Internet; Internet protocols; Management information systems; Routers
"Li Q., MacY K.",2,Optimizing the BSD routing system for parallel processing,2009,1,"Blue Coat Systems, Inc., Sunnyvale, CA, United States; FreeBSD Project, Palo Alto, CA, United States",Blue Coat Systems,1,USA,1,5,4,"The routing architecture of the original 4.4BSD [3] kernel has been deployed successfully without major design modification for over 15 years. In the unified routing architecture, layer-3 (L3) IP routes are maintained with layer-2 (L2) ARP entries in the same kernel structures. This meant that a single table lookup can return both results. Today, the prevalence of multi-core CPUs and parallel processor architectures is driving the re-design of software data structures and control flows to fully exploit the parallel capabilities of commodity hardware. A common parallel TCP/IP network protocol stack design separates out L2 and L3 processing from layer-4 (L4) and layer-5 (L5) (TCP and socket) onto different CPU cores. The unified routing architecture creates data dependencies between these layers, complicating the design and causing high levels of lock contention. In this paper we will detail the routing architecture that we have implemented for the upcoming FreeBSD 8.0 kernel, which eliminates the data dependencies and facilitates better parallelization of the network protocol stacks. We will describe the impact of this design on higher layer protocols such as TCP and UDP flow processing, and provide performance comparison between the original and the new design.",ARP; Flow table; FreeBSD; IP; IPv6; MP; Neighbor Cache; Routing; Server load balancing (SLB); SMP; Synchronization,Commodity hardware; Control flows; CPU cores; Data dependencies; Design modifications; Flow table; FreeBSD; Higher-layer protocols; Kernel structure; Multi core; Network protocol stack; New design; Parallel processing; Parallel processor; Parallelizations; Performance comparison; Routing architecture; Routing system; Server loads; Software data; TCP/IP networks; UDP flows; Data structures; Design; Network architecture; Network protocols; Parallel architectures; Parallel flow; Program processors; Routers; Software design; Table lookup; Transmission control protocol; Internet protocols
"Bolla R., Bruschi R., Davoli F., Ranieri A.",4,Energy-aware performance optimization for next-generation green network equipment,2009,41,"DIST, University of Genoa, Via all'Opera Pia 13, 16139, Genoa, Italy",University of Genoa,1,Italy,1,15,12,"Besides a more widespread sensitivity to ecological issues, the interest in energy-efficient network technologies springs from heavy and critical economical needs, since both energy cost and network electrical requirements show a continuous growth, with an alarming trend over the past years. In this contribution, we explore and try to evaluate the feasibility and the impact of power management policies able to well suit a heterogeneous set of highly modular architectures, generally used for developing today's network equipment. The proposed policies aim at optimizing the power consumption of each device component with respect to its expected network performance. Finally, in order to provide an experimental evaluation of the proposed ideas, we applied such power management policies to a new generation SW router platform, and we evaluated it with real traffic traces.",Green networks; Router power management; SW Router,Energy aware; Energy cost; Energy efficient; Experimental evaluation; Green networks; Modular architectures; Network equipment; Network technologies; Performance optimizations; Power Consumption; Power managements; Real traffic; Electric power measurement; Energy management; Network performance; Optimization; Wireless sensor networks; Routers
"Ravindranath L., Bahl P., Chandra R., Maltz D.A., Padhye J., Patel P.",6,Change is hard: Adapting dependency graph models for unified diagnosis in wired/wireless networks,2009,0,"WIU, Poland; Microsoft Research, United States",Microsoft,1,Poland;USA,2,25,17,"Organizations world-wide are adopting wireless networks at an impressive rate, and a new industry has sprung up to provide tools to manage these networks. Unfortunately, these tools do not integrate cleanly with traditional wired network management tools, leading to unsolved problems and frustration among the IT staff. We explore the problem of unifying wireless and wired network management and show that simple merging of tools and strategies, and/or their trivial extension from one domain to another does not work. Building on previous research on network service dependency extraction, fault diagnosis, and wireless network management, we introduce MnM, an end-to-end network management system that unifies wired and wireless network management. MnM treats the physical location of end devices as a core component of its management strategy. It also dynamically adapts to the frequent topology changes brought about by end-node mobility. We have a prototype deployment in a large organization that shows that MnM's root-cause analysis engine out-performs systems that do not take user mobility into account when localizing faults or attributing blame. Copyright 2009 ACM.",Corporate networks; Performance; Wireless,Core components; Corporate networks; Dependency graphs; End-devices; End-to-end network; Fault diagnosis; IT staff; Large organizations; Management strategies; Network services; New industry; Node mobility; Physical locations; Prototype deployment; Root cause analysis; Unsolved problems; User mobility; Wired and wireless; Wired networks; Failure analysis; Management; Research; Telephone systems; Wireless networks
"Nayak A., Reimers A., Feamster N., Clark R.",4,Resonance: Dynamic access control for enterprise networks,2009,66,"School of Computer Science, Georgia Tech, United States",Georgia Tech,1,USA,1,20,13,"Enterprise network security is typically reactive, and it relies heavily on host security and middleboxes. This approach creates complicated interactions between protocols and systems that can cause incorrect behavior and slow response to attacks. We argue that imbuing the network layer with mechanisms for dynamic access control can remedy these ills. We propose Resonance, a system for securing enterprise networks, where the network elements themselves enforce dynamic access control policies based on both flow-level information and real-time alerts. Resonance uses programmable switches to manipulate traffic at lower layers; these switches take actions (e.g., dropping or redirecting traffic) to enforce high-level security policies based on input from both higher-level security policies and distributed monitoring and inference systems. We describe the design of Resonance, apply it to Georgia Tech's network access control system, show how it can both overcome the current shortcomings and provide new security functions, describe our proposed deployment, and discuss open research questions. Copyright 2009 ACM.",Access control; Enterprise networks; Programmable networks,Distributed monitoring; Dynamic access control; Enterprise networks; Flow-level; Georgia; Higher-level security; Inference systems; Middleboxes; Network access control; Network element; Programmable network; Programmable networks; Programmable switches; Research questions; Security functions; Security policy; Network layers; Network security; Programmed control systems; Research; Resonance; Security systems; Access control
"Naous J., Stutsman R., Mazières D., McKeown N., Zeldovich N.",5,Delegating network security with more information,2009,14,"Stanford University, CA, United States; MIT CSAIL, MA, United States",MIT;Stanford University,2,USA,1,15,11,"Network security is gravitating towards more centralized control. Strong centralization places a heavy burden on the administrator who has to manage complex security policies and be able to adapt to users' requests. To be able to cope, the administrator needs to delegate some control back to end-hosts and users, a capability that is missing in today's networks. Delegation makes administrators less of a bottleneck when policy needs to be modified and allows network administration to follow organizational lines. To enable delegation, we propose ident++ - a simple protocol to request additional information from end-hosts and networks on the path of a flow. ident++ allows users and end-hosts to participate in network security enforcement by providing information that the administrator might not have or rules to be enforced on their behalf. In this paper we describe ident++ and how it provides delegation and enables flexible and powerful policies. Copyright 2009 ACM.",Firewall; Ident; Management; Network security; Policy,Centralized control; In-network; Management networks; Network Administration; Security enforcement; Security policy; SIMPLE protocol; Network protocols; Network security
"Yu M., Rexford J.",2,"Hash, don't cache: Fast packet forwarding for enterprise edge routers",2009,2,"Princeton University, United States",Princeton University,1,USA,1,13,12,"As forwarding tables and link speeds continue to grow, fast packet forwarding becomes increasingly challenging for enterprise edge routers. Simply building routers with ever larger amounts of ever faster memory is not appealing, since high-speed memory is both expensive and power hungry. Instead, we believe future enterprise routers should leverage a hierarchical memory architecture consisting of a small, fast memory and a large, slow memory. However, the conventional approach of caching popular forwarding-table entries in the fast memory does not perform well in practice, especially under worst-case workloads with a wide range of destination IP addresses. Instead, the small memory could be used to store one Bloom filter of the address blocks associated with each outgoing link. In this paper, we present techniques to make the use of Bloom filters practical for enterprise edge routers, including optimizing the sizes of Bloom filters with limited fast memory, handling routing changes and dynamically tuning Bloom filter sizes using counting Bloom filters in slow memory, and handling the small number of false positives. Our evaluation shows that our scheme works well with less than 1 MB of fast memory. Copyright 2009 ACM.",Bloom filter; Enterprise edge routers; Packet forwarding,Bloom filters; Conventional approach; Edge routers; False positive; Fast memory; Forwarding tables; Hierarchical memory; High-speed memory; IP addresss; Link speed; Packet forwarding; Blooms (metal); Computer architecture; Routers
"Giustiniano D., Goma E., Toledo A.L., Rodriguez P.",4,WiSwitcher: An efficient client for managing multiple APs,2009,19,"Telefonica Research, Barcelona, Spain",Telefonica Research,1,Spain,1,11,8,"There has been an increasing interest on designing a single-radio client for time-division access to multiple Access Points (APs) on different radio-channels. These works have focused mainly on different scheduling policies at the client-side to allocate the percentage of time to each AP. However the performance of these systems is limited by 1) the overhead to switch between APs on different radio-channels, 2) the jitter in the switching procedure, that modifies the expected percentage of time assigned by schedulers and 3) the packet losses caused by the switching. In this paper, we introduce WiSwitcher, a client able to connect to multiple APs that i) reduces the cost of switching down to the hardware switching time and ii) increases the stability of the percentage of time assigned by schedulers, even if the station transmits in saturation mode. We implement WiSwitcher over commodity hardware and show that it achieves high aggregate throughput over the connecting APs and seamlessly transmits TCP traffic under controlled scenarios. Finally, we characterize the dependency between the switching frequency at the WiSwitcher client and the packet losses in off-the-shelf APs.",MAC; Multi-channel; TDMA; Wireless network,Aggregate throughput; Commodity hardware; Multi-channel; Multiple access points; Saturation mode; Scheduling policies; Switching time; TCP traffic; TDMA wireless networks; Agglomeration; Cost reduction; Jitter; Packet loss; Routers; Scheduling; Time division multiple access; Wireless networks; Switching
"Lu G., Guo C., Shi Y., Zhang Y.",4,CAFE: A configurable pAcket forwarding engine for data center networks,2009,15,"Microsoft Research Asia, Beijing, China; Peking University, Beijing, China",Microsoft;Peking University,2,China,1,12,10,"Recently, Data Center Networking (DCN) has attracted many research attentions and innovative DCN designs have been proposed [1, 2]. All these designs need specialized packet forwarding engines due to their special routing algorithms, which are either based on commonly used packet headers or self-defined ones. Although programmable forwarding devices are available, it is difficult to use them to prototype these DCN designs, especially when self-defined headers are introduced. In this paper, we present a hardware based Configurable pAcket Forwarding Engine (CAFE) to facilitate the prototyping process. Through simple APIs, CAFE can be easily configured to forward self-defined packets, modify, insert, and delete arbitrary packet header fields without re-designing the hardware. We have implemented CAFE using NetFPGA. Evaluation demonstrates that CAFE can be easily configured and it can forward packets at line-rate.",Configurable packet forwarding engine; Data center networking; NetFPGA,Configurable; Data centers; Forward packets; Packet forwarding engines; Packet header; Packet header fields; Prototyping process; Re-designing; Design; Routers; Engines
"Vanbever L., Quoitin B., Bonaventure O.",3,A hierarchical model for BGP routing policies,2009,4,"IP Networking Lab, Université Catholique de Louvain, B-1348 Louvain-la-Neuve, Belgium",Universite Catholique de Louvain,1,Belgium,1,23,19,"BGP routing policies are mainly used by network operators to enforce business relationships between Autonomous Systems (AS), and to prefer some routes over others. In this paper, we propose a hierarchical policy model to express each policy at the most appropriate level of abstraction. The model is structured around chains of filters that apply at a speci?c level of abstraction. To validate our approach, we implemented the model in a Java prototype and used it to reproduce several network-wide routing policies. In all studied networks, the model produced a high-level view of routing policies while preserving their semantics. Our model offers numerous advantages to network operators including, but not limited to, a better network documentation, an improved understanding of routing policies, redundancy suppression, and an easier way of managing their network.",BGP; Network configuration; Routing policies,Autonomous systems; BGP routing policies; Business relationships; Hierarchical model; Hierarchical policy models; Level of abstraction; Network configuration; Network operator; Routing policies; Abstracting; Hierarchical systems; Routing protocols; Routers
"Barman D., Chandrashekar J., Taft N., Faloutsos M., Huang L., Giroire F.",6,Impact of IT monoculture on behavioral end Host intrusion detection,2009,3,"UC Riverside, Junipei, United States; Intel Labs Berkeley, United States; UC Riverside, United States; MASCOTTE, I3S (CNRS, UNS) - INRIA, France",Intel;INRIA;University of California Riverside,3,France;USA,2,29,21,"In this paper, we study the impact of today's IT policies, defined based upon a monoculture approach, on the performance of end-host anomaly detectors. This approach leads to the uniform configuration of Host intrusion detection systems (HIDS) across all hosts in an enterprise networks. We assess the performance impact this policy has from the individual's point of view by analyzing network traces collected from 350 enterprise users. We uncover a great deal of diversity in the user population in terms of the ""tail"" behavior, i.e., the component which matters for anomaly detection systems. We demonstrate that the monoculture approach to HIDS configuration results in users that experience wildly different false positive and false negatives rates. We then introduce new policies, based upon leveraging this diversity and show that not only do they dramatically improve performance for the vast majority of users, but they also reduce the number of false positives arriving in centralized IT operation centers, and can reduce attack strength. Copyright 2009 ACM.",Anomaly detection; Enterprise management; Host intrusion detection; Measurement; User profile,Anomaly detection; Anomaly detection systems; Anomaly detector; Enterprise management; Enterprise networks; False negatives; False positive; Host intrusion detection; Host intrusion detection system; IT monoculture; IT policies; Operation center; Performance impact; Uniform configurations; User profile; Computer crime; Detectors; Intrusion detection
"Sommers J., Barford P., Crovella M.",3,Router primitives for programmable active measurement,2009,3,"Colgate University, United States; University of Wisconsin-Madison Nemean Networks, United States; Boston University, United States",Boston University;Colgate University;University of Wisconsin-Madison,3,USA,1,17,14,"Active probe-based measurements are the foundation for understanding important network path properties such as SLA compliance and available bandwidth. Well-known challenges in active probe-based measurement include the logistics of deploying and managing host-based measurement infrastructures, the load that probe packets place on network resources, the inaccuracy of resultant measurements, and the relatively limited set of features that can be measured. In this paper, we argue that these challenges can be addressed through programmable, router-based support for active measurement. While commercial routers today have some basic capabilities for emitting probe packets, these mechanisms are minimal and do not allow the necessary flexibility in the kinds of probing that can be done. We describe a set of functional primitives that enable a wide range of router-based active measurements and would improve and simplify the ability to assess and understand network structure and dynamic network state. We discuss the associated resource requirements and implications of our approach related to configuration, security and privacy. Finally, we support and illustrate the powerful potential of our approach through a series of measurement scenarios and describe our ongoing efforts toward a Click-based implementation of our framework.",Active measurement; Programmable measurement; Router programmability,Active measurement; Active probe; Available bandwidth; Commercial routers; Host-based; Network paths; Network resource; Network structures; Probe packets; Programmability; Programmable measurement; Resource requirements; Security and privacy; Bandwidth; Probes; Routers; Measurements
"Davie B., Medved J.",2,A programmable overlay router for service provider innovation,2009,7,"Cisco Systems, Inc., 1414 Massachusetts Ave., Boxborough, MA 01719, United States; Cisco Systems, Inc., 170 W Tasman Dr., San Jose, CA 95134, United States",Cisco,1,USA,1,24,17,"The threat of commoditization poses a real challenge for service providers. While the end-to-end principle is often paraphrased as ""dumb network, smart end-systems"", the original paper makes a more subtle argument about appropriate distribution of functionality among endpoints and intermediate systems. Functions may be implemented in the network for performance reasons, and when they offer value to a wide range of applications without inhibiting the correct operation of applications that do not need these functions. In this context, we describe a prototype platform for experimentation with novel, useful functions ""inside"" the network. This programmable platform allows service providers to innovate quickly and to deploy new functions within the network when it makes sense. By implementing the platform as an overlay, service providers can assist those applications that benefit from added functions such as caching and streaming support, without interfering with the correct and efficient operation of other applications that do not need them. Service providers can also leverage their detailed topological knowledge and ability to control network resources, features that would be difficult for conventional overlays. Programmability of the platform enables features to be extended or composed with other pieces of software, by either the service providers or third parties.",End-to-end argument; Overlays; Programmable routers,Commoditization; Control network; End-systems; End-to-end argument; Other applications; Programmability; Programmable platforms; Programmable routers; Service provider; Third parties; Knowledge management; Routers
"Costa P., Zahn T., Rowstron A., O'Shea G., Schubert S.",5,"Why should we integrate services, servers, and networking in a data center?",2009,13,"Microsoft Research Cambridge, United Kingdom",Microsoft,1,UK,1,33,23,"Since the early days of networks, a basic principle has been that endpoints treat the network as a black box. An end-point injects a packet with a destination address and the network delivers the packet. This principle has served us well, and allowed us to scale the Internet to billions of devices using networks owned by competing companies and devices owned by billions of individuals. However, this approach might not be optimal for large-scale Internet data centers (DCs), such as those run by Amazon, Google, Microsoft and Yahoo, that employ custom software and customized hardware to increase efficiency and to lower costs. In DCs, all the components are controlled by a single entity, and creating services for the DC that treat the network as a black box will lead to inefficiencies. In DCs, there is the opportunity to rethink the relationship between servers, services and the network. We believe that, in order to enable more efficient intra-DC services, we should close the gap between the network, services and the servers. To this end, we have been building a direct server-to-server network topology, and have been looking at whether this makes common services quicker to implement and more efficient to operate. Copyright 2009 ACM.",Data centers; Direct connection networks; Internet services,Basic principles; Black boxes; Data centers; End points; Internet data centers; Internet services; Lower cost; MicroSoft; Network topology; Electric network topology; Satellite communication systems; Servers; Internet
"Giladi R., Yemini N.",2,"A programmable, generic forwarding element approach for dynamic network functionality",2009,6,"Department of Communication Systems Engineering, Ben Gurion University, Beer-Sheva, Israel",Ben Gurion University,1,Israel,1,16,14,"Communication networks are growing exponentially, and new services and applications are being introduced unceasingly. To meet the demands of these services and applications, current network systems have to be modified, replaced or supplemented. Various technologies, such as reconfigurable devices or active networks, have attempted to address this problem. In this paper, we introduce a programmable, generic forwarding element (GFE), which can be used as a platform for a flexible and reconfigurable network system. This platform and the resulting network system enable on-the-fly definition of adaptive and dynamic network functionalities, so that the demands of new services and applications can be met. Additionally, specific service instances or traffic flows can be handled by this platform on a temporary and locality basis, according to traffic patterns, application demands, and provisioning decisions. The proposed GFE complies with today's standards and can easily be adopted for future standards. A network processor is used to implement this platform, so that frame processing is achieved at wire speed, even though each frame is analyzed and processed by a meta-program. An XML-based definition of the forwarding element is used to describe frame processing, based on the frame contents and ingress port, and on various system and network parameters.",Forwarding element; Network systems; Programmable netwroks,Communication networks; Dynamic network; Frame processing; Network parameters; Network processor; Network systems; New services; On-the-fly; Reconfigurable devices; Reconfigurable network; Service instances; Services and applications; Traffic flow; Traffic pattern; Active networks; Program processors; Traffic surveys; Routers
"Tripathi S., Droux N., Srinivasan T., Belgaied K., Iyer V.",5,Crossbow: A vertically integrated QoS stack,2009,3,"Solaris Kernel Networking, Sun Microsystems, Inc., 17 Network Circle, Menlo Park, CA 94025, United States",Sun Microsystems,1,USA,1,30,20,"This paper describes a new architecture which addresses Quality of Service (QoS) by creating unique flows for applications, services, or subnets. A flow is a dedicated and independent path from the NIC hardware to the socket layer in which the QoS layer is integrated into the protocol stack instead of being implemented as a separate layer. Each flow has dedicated hardware and software resources allowing applications to meet their specified quality of service within the host. The architecture efficiently copes with Distributed Denial of Service (DDoS) attacks by creating zero or limited bandwidth flows for the attacking traffic. The unwanted packets can be dropped by the NIC hardware itself at no cost. A collection of flows on more than one host can be assigned the same Differentiated Services Code Point (DSCP) label which forms a path dedicated to a service across the enterprise network and enables end-to-end QoS within the data center. Copyright 2009 ACM.",Classification; Crossbow; DDoS; Flows; Networking; Performance; QoS,Data centers; Dedicated hardware; Differentiated services code points; Distributed denial of service attack; End-to-end QoS; Enterprise networks; Limited bandwidth; Protocol stack; Subnets; Unwanted packets; Quality control; Telecommunication services; Quality of service
"Wu Q., Wolf T.",2,Design of a network service processing platform for data path customization,2009,2,"Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA, United States",University of Massachusetts Amherst,1,USA,1,30,26,"Custom packet processing functionality in routers is one of the key characteristics of next-generation Internet architectures. Network services have been proposed as an abstraction to describe, compose, and deploy end-to-end connections with custom communication features. We present a novel hardware architecture for high-performance processing of such network services in the data path. The design provides simple processing units to implement services and a custom hardware infrastructure to manage packets and processing context. The design allows for simple software development, flexible network service allocation, and high scalability to handle traffic at Gigabit line rates.",Network processor; Network service; Next-generation internet,Communication features; Custom hardwares; Data paths; End-to-end connections; Flexible network services; Gigabit line rates; High-performance processing; Internet architecture; Key characteristics; Network processor; Network services; Novel hardware; Packet processing; Processing platform; Processing units; Software development; Design; Internet; Nanotechnology; Routers; Software design; Data processing
"Hinrichs T.L., Gude N.S., Casado M., Mitchell J.C., Shenker S.",5,Practical declarative network management,2009,58,"University of Chicago, Computer Science, Chicago, IL, United States; Stanford University, Computer Science, Stanford, CA, United States; U.C. Berkeley and ICSI, Electrical Engineering and Computer Science, Berkeley, CA, United States",Stanford University;University of California Berkeley;University of Chicago,3,USA,1,20,15,"We present Flow-based Management Language (FML), a declarative policy language for managing the configuration of enterprise networks. FML was designed to replace the many disparate configuration mechanisms traditionally used to enforce policies within the enterprise. These include ACLs, VLANs, NATs, policy-routing, and proprietary admission control systems. FML balances the desires to express policies naturally and enforce policies efficiently. We have implemented FML and have used it to manage multiple operational enterprise networks for over a year. Copyright 2009 ACM.",Network; Performance; Policy; Security,Admission Control; Configuration mechanisms; Enterprise networks; Network; Policy language; Linguistics
"Chen X., Mao Y., Mao Z.M., Van Der Merwe J.",4,DECOR: DECLaritive network management and OpeRation,2009,0,"Department of EECS, University of Michigan, Ann Arbor, MI, United States; AT and T Labs - Research, Shannon Laboratory, Florham Park, NJ, United States",AT and T Labs;University of Michigan at Ann Arbor,2,USA,1,14,10,"Network management operations are complicated, tedious and error-prone, requiring significant human involvement and expert knowledge. In this paper, we first examine the fundamental components of management operations and argue that the lack of automation is due to a lack of programmability at the right level of abtractsion. To address this challenge, we present DECOR, a database-oriented, declarative framework towards automated network management. DECOR models router configuration and any generic network status as relational data in a conceptually centralized database. As such, network management operations can be represented as a series of transactional database queries, which provide the benefit of atomicity, consistency and isolation. The rule- based language in DECOR provides the flexible programmability to specify and enforce network-wide management constraints, and achieve high-level task scheduling. We describe the design rationale and architecture of DECOR and present some preliminary examples applying our approach to common network management tasks.",Declarative language; Network management,Centralized data-base; Common networks; Declarative Languages; Design rationale; Error prones; Expert knowledge; Fundamental component; Generic networks; Management operation; Management tasks; Programmability; Relational data; Router configuration; Rule-based language; Task-scheduling; Transactional database; Database systems; High level languages; Linguistics; Management; Routers; Scheduling
"Liu H., Orban D.",2,Remote network labs: An on-demand network cloud for configuration testing,2009,3,"Accenture Technology Labs, 50 W. San Fernando St., San Jose, CA 95113, United States",Accenture Technology Labs,1,USA,1,20,14,"Network equipment is difficult to configure correctly. To minimize configuration errors, network administrators typically build a smaller scale test lab replicating the production network and test out their configuration changes before rolling out the changes to production. Unfortunately, building a test lab is expensive and the test equipment is rarely utilized. In this paper, we present Remote Network Labs, which is aimed at leveraging the expensive network equipment more efficiently and reducing the cost of building a test lab. Similar to a server cloud such as Amazon EC2, a user could request network equipment remotely and connect them through a GUI or web services interface. The network equipment is geographically distributed, allowing us to reuse test equipment anywhere. Beyond saving costs, Remote Network Labs brings about many additional benefits, including the ability to fully automate network configuration testing. Copyright 2009 ACM.",Configuration testing; IP tunnels; Network cloud; Test labs,Configuration testing; IP tunnels; Network administrator; Network cloud; Network configuration; Network equipment; On-Demand; Production network; Remote network lab; Smaller-scale tests; Test equipments; Ability testing; Chemical laboratories; Cost reduction; Equipment; Web services; Testing
"Dhananjay A., Zhang H., Li J., Subramanian L.",4,"Practical, distributed channel assignment and routing in dual-radio mesh networks",2009,71,"New York University, United States; Tsinghua University, China",New York University;Tsinghua University,2,China;USA,2,34,31,"Realizing the full potential of a multi-radio mesh network involves two main challenges: how to assign channels to radios at each node to minimize interference and how to choose high throughput routing paths in the face of lossy links, variable channel conditions and external load. This paper presents ROMA, a practical, distributed channel assignment and routing protocol that achieves good multi-hop path performance between every node and one or more designated gateway nodes in a dual-radio network. ROMA assigns non-overlapping channels to links along each gateway path to eliminate intra-path interference. ROMA reduces inter-path interference by assigning different channels to paths destined for different gateways whenever possible. Evaluations on a 24-node dual-radio testbed show that ROMA achieves high throughput in a variety of scenarios. Copyright 2009 ACM.",Channnel assignment; Routing; Wireless,Channel conditions; Distributed channels; External loads; Gateway nodes; High throughput; Inter-path interferences; Lossy links; Mesh network; Multi-hop path; Multi-radio; Radio networks; Routing path; Convolutional codes; Mobile telecommunication systems; Network protocols; Radio links; Routing protocols; Throughput; Wireless networks; Wireless telecommunication systems; Gateways (computer networks)
"De Carli L., Pan Y., Kumar A., Estan C., Sankaralingam K.",5,PLUG: Flexible lookup modules for rapid deployment of new protocols in high-speed routers,2009,16,"University of Wisconsin-Madison, United States; NetLogic Microsystems",University of Wisconsin-Madison,1,USA,1,54,44,"New protocols for the data link and network layer are being proposed to address limitations of current protocols in terms of scalability, security, and manageability. High-speed routers and switches that implement these protocols traditionally perform packet processing using ASICs which offer high speed, low chip area, and low power. But with inflexible custom hardware, the deployment of new protocols could happen only through equipment upgrades. While newer routers use more flexible network processors for data plane processing, due to power and area constraints lookups in forwarding tables are done with custom lookup modules. Thus most of the proposed protocols can only be deployed with equipment upgrades. To speed up the deployment of new protocols, we propose a flexible lookup module, PLUG (Pipelined Lookup Grid). We can achieve generality without loosing efficiency because various custom lookup modules have the same fundamental features we retain: area dominated by memories, simple processing, and strict access patterns defined by the data structure. We implemented IPv4, Ethernet, Ethane, and SEATTLE in our dataflow-based programming model for the PLUG and mapped them to the PLUG hardware which consists of a grid of tiles. Throughput, area, power, and latency of PLUGs are close to those of specialized lookup modules. Copyright 2009 ACM.",Dataflow; Flexibility; Forwarding; High-speed routers; Lookup; Tiled architectures,Access patterns; Chip areas; Custom hardwares; Data link; Data-plane processing; Dataflow; Flexible networks; Forwarding tables; Fundamental features; High-speed routers; Lookups; Low Power; New protocol; Packet processing; Programming models; Seattle; Speed-ups; Tiled architecture; Application specific integrated circuits; Building materials; Convolutional codes; Data flow analysis; Data processing; Data structures; Ethane; Network layers; Network security; Speed; Network protocols
"Flavel A., Roughan M.",2,Stable and flexible iBGP,2009,5,"School of Mathematical Sciences, University of Adelaide, SA, Australia",University of Adelaide,1,Australia,1,38,36,"Routing oscillation is highly detrimental. It can decrease performance and lead to a high level of update churn placing unnecessary workload on router the problem is distributed between many providers. However, iBGP - the routing protocol used to distribute routes inside a single Autonomous System - has also been shown to oscillate. Despite the fact that iBGP is configured by a single provider according to apparently straight forward rules, more than eight years of research has not solved the problem of iBGP oscillation. Various solutions have been proposed but they all lack critical features: either they are complicated to implement, restrict routing flexibility, or lack guarantees of stability. In this paper we propose a very simple adaptation to the BGP decision process. Despite its simplicity and negligible cost we prove algebraically that it prevents iBGP oscillation. We extend the idea to provide routing flexibility, such as respecting the MED attribute, without sacrificing network stability. Copyright 2009 ACM.",BGP; Metarouting; Routing; Stability,Autonomous systems; Decision process; Network stability; Routing flexibility; Routing stability; Convolutional codes; Routing algorithms; System stability; Routing protocols
"Mahimkar A., Ge Z., Shaikh A., Wang J., Yates J., Zhang Y., Zhao Q.",7,Towards automated performance diagnosis in a large IPTV network,2009,45,"University of Texas, Austin, United States; AT and T Labs - Research, United States",AT and T Labs;University of Texas at Austin,2,USA,1,32,24,"IPTV is increasingly being deployed and offered as a commercial service to residential broadband customers. Compared with traditional ISP networks, an IPTV distribution network (i) typically adopts a hierarchical instead of mesh-like structure, (ii) imposes more stringent requirements on both reliability and performance, (iii) has different distribution protocols (which make heavy use of IP multicast) and traffic patterns, and (iv) faces more serious scalability challenges in managing millions of network elements. These unique characteristics impose tremendous challenges in the effective management of IPTV network and service. In this paper, we focus on characterizing and troubleshooting performance issues in one of the largest IPTV networks in North America. We collect a large amount of measurement data from a wide range of sources, including device usage and error logs, user activity logs, video quality alarms, and customer trouble tickets. We develop a novel diagnosis tool called Giza that is specifically tailored to the enormous scale and hierarchical structure of the IPTV network. Giza applies multi-resolution data analysis to quickly detect and localize regions in the IPTV distribution hierarchy that are experiencing serious performance problems. Giza then uses several statistical data mining techniques to troubleshoot the identified problems and diagnose their root causes. Validation against operational experiences demonstrates the effectiveness of Giza in detecting important performance issues and identifying interesting dependencies. The methodology and algorithms in Giza promise to be of great use in IPTV network operations. Copyright 2009 ACM.",Iptv; Network diagnosis,Broadband customers; Commercial services; Diagnosis tools; Different distributions; Distribution network; Effective management; Hierarchical structures; IP Multicast; IPTV networks; Measurement data; Multiresolution data; Network element; Operational experience; Performance diagnosis; Performance issues; Performance problems; Root cause; Statistical datas; Stringent requirement; Traffic pattern; Trouble ticket; Troubleshooting; Troubleshoots; User activity; Video quality; Convolutional codes; Data mining; Distributed parameter networks; Internet protocols; Internet service providers; Network protocols; Television broadcasting; Network management
"Raiciu C., Huici F., Handley M., Rosenblum D.S.",4,ROAR: Increasing the flexibility and performance of distributed search,2009,8,"University College London, United Kingdom; NEC Europe, Heidelberg, United States",University College London,1,UK;USA,2,26,18,"To search the web quickly, search engines partition the web index over many machines, and consult every partition when answering a query. To increase throughput, replicas are added for each of these machines. The key parameter of these algorithms is the trade-off between replication and partitioning: increasing the partitioning level improves query completion time since more servers handle the query, but may incur non-negligible startup costs for each sub-query. Finding the right operating point and adapting to it can significantly improve performance and reduce costs. We introduce Rendezvous On a Ring (ROAR), a novel distributed algorithm that enables on-the-fly re-configuration of the partitioning level. ROAR can add and remove servers without stopping the system, cope with server failures, and provide good load-balancing even with a heterogeneous server pool. We demonstrate these claims using a privacy-preserving search application built upon ROAR. Copyright 2009 ACM.",Algorithms; Design,Completion time; Distributed algorithm; Distributed search; Heterogeneous servers; Key parameters; Load-Balancing; On-the-fly; Operating points; Privacy preserving; Search application; Start-up costs; Convolutional codes; Cost reduction; Operating costs; Parallel algorithms; Search engines; Servers; World Wide Web
"Vasudevan V., Phanishayee A., Shah H., Krevat E., Andersen D.G., Ganger G.R., Gibson G.A., Mueller B.",8,Safe and effective fine-grained TCP retransmissions for datacenter communication,2009,163,"Carnegie Mellon University, United States; Panasas Inc.",Carnegie Mellon University;Panasas Inc.,2,USA,1,35,16,"This paper presents a practical solution to a problem facing high-fan-in, high-bandwidth synchronized TCP workloads in datacenter Ethernets - the TCP incast problem. In these networks, receivers can experience a drastic reduction in application throughput when simultaneously requesting data from many servers using TCP. Inbound data overfills small switch buffers, leading to TCP timeouts lasting hundreds of milliseconds. For many datacenter workloads that have a barrier synchronization requirement (e.g., filesystem reads and parallel data-intensive queries), throughput is reduced by up to 90%. For latency-sensitive applications, TCP timeouts in the datacenter impose delays of hundreds of milliseconds in networks with round-trip-times in microseconds. Our practical solution uses high-resolution timers to enable microsecond-granularity TCP timeouts. We demonstrate that this technique is effective in avoiding TCP incast collapse in simulation and in real-world experiments. We show that eliminating the minimum retransmission timeout bound is safe for all environments, including the wide-area. Copyright 2009 ACM.",Datacenter networks; Incast; Performance; Throughput,Barrier synchronization; Datacenter networks; Filesystem; High bandwidth; High-resolution timer; In-network; Parallel data; Practical solutions; Real world experiment; Retransmission timeout; Retransmissions; Sensitive application; Switch buffers; Wide area; Convolutional codes; Throughput; Transmission control protocol
"Papageorge P., McCann J., Hicks M.",3,Passive aggressive measurement with MGRP,2009,12,"Google; University of Maryland, United States",Google;University of Maryland College Park,2,USA,1,35,30,"We present the Measurement Manager Protocol (MGRP), an in-kernel service that schedules and transmits probes on behalf of active measurement tools. Unlike prior measurement services, MGRP transparently piggybacks application packets inside the often significant amounts of empty padding contained in typical probes. Using MGRP thus combines the modularity, flexibility, and accuracy of standalone active measurement tools with the lower overhead of passive measurement techniques. Microbenchmark experiments show that the resulting bandwidth savings makes it possible to measure the network accurately, but faster and more aggressively than without piggybacking, and with few ill effects to piggybacked application or competing traffic. When using MGRP to schedule measurements on behalf of MediaNet, an overlay service that adaptively schedules media streams, we show MediaNet can achieve significantly higher streaming rates under the same network conditions. Copyright 2009 ACM.",Active; Available bandwidth; Kernel module; Passive; Piggybacking; Probing; Streaming; Transport protocol,Active measurement; Available bandwidth; Bandwidth savings; Kernel modules; Media streams; MediaNet; Micro-benchmark; Network condition; Passive measurements; Prior measurement; Transport protocols; Bandwidth; Convolutional codes; Image retrieval; Probes; Measurements
"Guo C., Lu G., Li D., Wu H., Zhang X., Shi Y., Tian C., Zhang Y., Lu S.",9,"BCube: A high performance, server-centric network architecture for modular data centers",2009,637,"Microsoft Research Asia, China; Tsinghua, China; PKU, China; HUST, China; UCLA, United States",Microsoft,1,China;USA,2,25,16,"This paper presents BCube, a new network architecture specifically designed for shipping-container based, modular data centers. At the core of the BCube architecture is its server-centric network structure, where servers with multiple network ports connect to multiple layers of COTS (commodity off-the-shelf) mini-switches. Servers act as not only end hosts, but also relay nodes for each other. BCube supports various bandwidth-intensive applications by speeding-up one-to-one, one-to-several, and one-to-all traffic patterns, and by providing high network capacity for all-to-all traffic. BCube exhibits graceful performance degradation as the server and/or switch failure rate increases. This property is of special importance for shipping-container data centers, since once the container is sealed and operational, it becomes very difficult to repair or replace its components. Our implementation experiences show that BCube can be seamlessly integrated with the TCP/IP protocol stack and BCube packet forwarding can be efficiently implemented in both hardware and software. Experiments in our testbed demonstrate that BCube is fault tolerant and load balancing and it significantly accelerates representative bandwidth-intensive applications. Copyright 2009 ACM.",Modular data center; Multi-path; Server-centric network,Bandwidth-intensive applications; Data centers; Fault-tolerant; Graceful performance degradations; Hardware and software; Load-Balancing; Modular data; Multi-path; Multiple layers; Multiple networks; Network Capacity; Network structures; Packet forwarding; Relay node; Switch failure; TCP/IP protocol; Traffic pattern; Containers; Convolutional codes; Satellite communication systems; Servers; Switches; Network architecture
"Kandula S., Agarwal S., Mahajan R., Padhye J., Verkaik P., Bahl P.",6,Detailed diagnosis in enterprise networks,2009,43,"Microsoft Research; UCSD, United States",Microsoft,1,USA,1,33,22,"By studying trouble tickets from small enterprise networks, we conclude that their operators need detailed fault diagnosis. That is, the diagnostic system should be able to diagnose not only generic faults (e.g., performance-related)but also application specific faults (e.g., error codes). It should also identify culprits at a fine granularity such as a process or firewall configuration. We build a system, called NetMedic, that enables detailed diagnosis by harnessing the rich information exposed by modern operating systems and applications. It formulates detailed diagnosis as an inference problem that more faithfully captures the behaviors and interactions of fine-grained network components such as processes. The primary challenge in solving this problem is inferring when a component might be impacting another. Our solution is based on an intuitive technique that uses the joint behavior of two components in the past to estimate the likelihood of them impacting one another in the present. We find that our deployed prototype is effective at diagnosing faults that we inject in a live environment. The faulty component is correctly identified as the most likely culprit in 80% of the cases and is almost always in the list of top five culprits. Copyright 2009 ACM.",Applications; Enterprise networks; Fault diagnosis,Application specific; Diagnostic systems; Enterprise networks; Error codes; Fault diagnosis; Fine granularity; Inference problem; Joint behavior; Operating systems; Small enterprise; Trouble ticket; Two-component; Computer operating systems; Convolutional codes; Failure analysis
"Agarwal S., Lorch J.R.",2,Matchmaking for online games and other latency-sensitive P2P systems,2009,74,Microsoft Research,Microsoft,1,USA,1,37,32,"The latency between machines on the Internet can dramatically affect users' experience for many distributed applications. Particularly, in multiplayer online games, players seek to cluster themselves so that those in the same session have low latency to each other. A system that predicts latencies between machine pairs allows such matchmaking to consider many more machine pairs than can be probed in a scalable fashion while users are waiting. Using a far-reaching trace of latencies between players on over 3.5 million game consoles, we designed Htrae, a latency prediction system for game matchmaking scenarios. One novel feature of Htrae is its synthesis of geolocation with a network coordinate system. It uses geolocation to select reasonable initial network coordinates for new machines joining the system, allowing it to converge more quickly than standard network coordinate systems and produce substantially lower prediction error than state-of-the-art latency prediction systems. For instance, it produces 90th percentile errors less than half those of iPlane and Pyxida. Our design is general enough to make it a good fit for other latency-sensitive peer-to-peer applications besides game matchmaking.",Latency estimation; Matchmaking; Network coordinates; Online gaming,Distributed applications; Game consoles; Geolocations; Latency estimation; Low latency; Multi-player online games; Network coordinates; On-line games; On-line gaming; P2P system; Peer-to-peer application; Prediction errors; Prediction systems; Arts computing; Convolutional codes; Coordinate measuring machines; Distributed computer systems; Online systems
"Zhang Y., Roughan M., Willinger W., Qiu L.",4,Spatio-temporal compressive sensing and internet traffic matrices,2009,130,"University of Texas, Austin, United States; University of Adelaide, Australia; AT and T Labs - Research, United States",AT and T Labs;University of Adelaide;University of Texas at Austin,3,Australia;USA,2,34,28,"Many basic network engineering tasks (e.g., traffic engineering, capacity planning, anomaly detection) rely heavily on the availability and accuracy of traffic matrices. However, in practice it is challenging to reliably measure traffic matrices. Missing values are common. This observation brings us into the realm of compressive sensing, a generic technique for dealing with missing values that exploits the presence of structure and redundancy in many real-world systems. Despite much recent progress made in compressive sensing, existing compressive-sensing solutions often perform poorly for traffic matrix interpolation, because real traffic matrices rarely satisfy the technical conditions required for these solutions. To address this problem, we develop a novel spatio-temporal compressive sensing framework with two key components: (i) a new technique called SPARSITY REGULARIZED MATRIX FAC-TORIZATION (SRMF) that leverages the sparse or low-rank nature of real-world traffic matrices and their spatio-temporal properties, and (ii) a mechanism for combining low-rank approximations with local interpolation procedures. We illustrate our new framework and demonstrate its superior performance in problems involving interpolation with real traffic matrices where we can successfully replace up to 98% of the values. Evaluation in applications such as network tomography, traffic prediction, and anomaly detection confirms the flexibility and effectiveness of our approach. Copyright 2009 ACM.",Anomaly detection; Compressive sensing; Interpolation; Prediction; Tomography; Traffic matrix,Anomaly detection; Capacity planning; Compressive sensing; Internet traffic; Key component; Local interpolation; Low rank approximations; matrix; Missing values; Network engineering; Network tomography; Real traffic; Real-world; Real-world system; Recent progress; Spatio-temporal; Spatio-temporal properties; Technical conditions; Traffic Engineering; Traffic matrices; Traffic prediction; Availability; Convolutional codes; Interpolation; Signal reconstruction; Telecommunication traffic; Tomography; Matrix algebra
"Dutta A., Saha D., Grunwald D., Sicker D.",4,SMACK - A smart ACKnowledgment scheme for broadcast messages in wireless networks,2009,38,"Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, CO 80309-0430, United States; Department of Computer Science, University of Colorado, Boulder, CO 80309-0430, United States",University of Colorado at Boulder,1,USA,1,26,18,"Network protocol designers, both at the physical and network level, have long considered interference and simultaneous transmission in wireless protocols as a problem to be avoided. This, coupled with a tendency to emulate wired network protocols in the wireless domain, has led to artificial limitations in wireless networks. In this paper, we argue that wireless protocols can exploit simultaneous transmission to reduce the cost of reliable multicast by orders of magnitude. With an appropriate application interface, simultaneous transmission can also greatly speed up common group communication primitives, such as anycast, broadcast, leader election and others. The proposed method precisely fits into the domain of directly reachable nodes where many group communication mechanisms are commonly used in routing protocols and other physical-layer mechanisms. We demonstrate how simultaneous transmission can be used to implement a reliable broadcast for an infrastructure and peer-to-peer network using a prototype reconfigurable hardware. We also validate the notion of using simple spectrum sensing techniques to distinguish multiple transmissions. We then describe how the mechanism can be extended to solve group communication problems and the challenges inherent to build innovative protocols which are faster and reliable at the same time. Copyright 2009 ACM.",Orthogonal frequency division multiplexing; Software defined radio,Anycast; Application interfaces; Broadcast messages; Group communications; Leader election; Multiple transmission; Network level; Orders of magnitude; Peer-to-Peer networks; Reconfigurable hardwares; Reliable broadcast; Reliable Multicast; Simultaneous transmission; Software defined radio; Software-defined radios; Spectrum sensing; Speed-ups; Wired networks; Wireless protocol; Communication; Computer software; Convolutional codes; Cost reduction; Distributed computer systems; Fluorine containing polymers; Frequency allocation; Frequency division multiple access; Internet; Multiplexing; Orthogonal frequency division multiplexing; Radio; Radio broadcasting; Routing protocols; Sensors; Transmissions; Wireless telecommunication systems; Wireless networks
"Liu X., Sheth A., Kaminsky M., Papagiannaki K., Seshan S., Steenkiste P.",6,DIRC: Increasing indoor wireless capacity using directional antennas,2009,36,"Carnegie Mellon University, United States; Intel Research Seattle, United States; Intel Research Pittsburgh, United States",Carnegie Mellon University;Intel,2,USA,1,28,24,"The demand for wireless bandwidth in indoor environments such as homes and offices continues to increase rapidly. Although wireless technologies such as MIMO can reach link throughputs of 100s of Mbps (802.11n) for a single link, the question of how we can deliver high throughput to a large number of densely-packed devices remains an open problem. Directional antennas have been shown to be an effective way to increase spatial reuse, but past work has focused largely on outdoor environments where the interactions between wireless links can usually be ignored. This assumption is not acceptable in dense indoor wireless networks since indoor deployments need to deal with rich scattering and multipath effects. In this paper we introduce DIRC, a wireless network design whose access points use phased array antennas to achieve high throughput in dense, indoor environments. The core of DIRC is an algorithm that increases spatial reuse and maximizes overall network capacity by optimizing the orientations of a network of directional antennas. We implemented DIRC and evaluated it on a nine node network in an enterprise setting. Our results show that DIRC improves overall network capacity in indoor environments, while being exible enough to adapt to node mobility and changing traffic workloads. Copyright 2009 ACM.",Directional antenna; Indoor wireless capacity,802.11n; Access points; Directional Antenna; High throughput; Indoor environment; Multi-path effect; Network Capacity; Node mobility; Open problems; Outdoor environment; Phased array antennas; Single link; Spatial reuse; Wireless bandwidth; Wireless capacity; Wireless link; Wireless network design; Wireless technologies; Antenna phased arrays; Antennas; Communication channels (information theory); Convolutional codes; Directional patterns (antenna); Throughput; Wireless networks
"Kompella R.R., Levchenko K., Snoeren A.C., Varghese G.",4,Every microsecond counts: Tracking fine-grain latencies with a lossy difference aggregator,2009,26,"Purdue University, University of California, San Diego, United States",Purdue University;University of California San Diego,2,USA,1,40,31,"Many network applications have stringent end-to-end latency requirements, including VoIP and interactive video conferencing, automated trading, and high-performance computing - where even microsecond variations may be intolerable. The resulting fine-grain measurement demands cannot be met effectively by existing technologies, such as SNMP, NetFlow, or active probing. We propose instrumenting routers with a hash-based primitive that we call a Lossy Difference Aggregator (LDA) to measure latencies down to tens of microseconds and losses as infrequent as one in a million. Such measurement can be viewed abstractly as what we refer to as a coordinated streaming problem, which is fundamentally harder than standard streaming problems due to the need to coordinate values between nodes. We describe a compact data structure that efficiently computes the average and standard deviation of latency and loss rate in a coordinated streaming environment. Our theoretical results translate to an efficient hardware implementation at 40 Gbps using less than 1% of a typical 65-nm 400-MHz networking ASIC. When compared to Poisson-spaced active probing with similar overheads, our LDA mechanism delivers orders of magnitude smaller relative error; active probing requires 50-60 times as much bandwidth to deliver similar levels of accuracy. Copyright 2009 ACM.",Packet sampling; Passive measurement,Active probing; Automated trading; Compact data structure; End-to-end latency; Hardware implementations; High-performance computing; Interactive video; Loss rates; NetFlows; Network applications; Orders of magnitude; Packet sampling; Passive measurements; Relative errors; Standard deviation; Theoretical result; Application specific integrated circuits; Data structures; Hardware; Internet telephony; Video conferencing; Convolutional codes
"Sung Y.-W.E., Lund C., Lyn M., Rao S., Sen S.",5,Modeling and understanding end-to-end class of service policies in operational networks,2009,11,"Purdue University, United States; AT and T Labs - Research, United States; AT and T Inc.",AT and T Labs;Purdue University,2,USA,1,20,14,"Business and economic considerations are driving the extensive use of service differentiation in Virtual Private Networks (VPNs) operated for business enterprises today. The resulting Class of Service (CoS) designs embed complex policy decisions based on the described priorities of various applications, extent of bandwidth availability, and cost considerations. These inherently complex high-level policies are realized through low-level router configurations. The configuration process is tedious and error-prone given the highly intertwined nature of CoS configuration, the multiple router configurations over which the policies are instantiated, and the complex access control lists (ACLs) involved. Our contributions include (i) a formal approach to modeling CoS policies from router configuration files in a precise manner; (ii) a practical and computationally efficient tool that can determine the CoS treatments received by an arbitrary set of flows across multiple routers; and (iii) a validation of our approach in enabling applications such as troubleshooting, auditing, and visualization of network-wide CoS design, using router configuration data from a cross-section of 150 diverse enterprise VPNs. To our knowledge, this is the first effort aimed at modeling and analyzing CoS configurations. Copyright 2009 ACM.",Configuration modeling; Differentiated service,Access control lists; Bandwidth availability; Business enterprise; Class of service; Computationally efficient; Configuration modeling; Configuration process; Differentiated Services; Economic considerations; Error prones; Formal approach; High level policies; Operational network; Policy decisions; Router configuration; Service differentiation; Troubleshooting; Virtual private networks; Access control; Bandwidth; Computer architecture; Convolutional codes; Data visualization; Quality of service; Transition metal compounds; Routers
"Qureshi A., Weber R., Balakrishnan H., Guttag J., Maggs B.",5,Cutting the electric bill for internet-scale systems,2009,380,"MIT CSAIL, United States; Akamai Technologies, United States; Carnegie Mellon University, United States",Akamai Technologies;Carnegie Mellon University;MIT,3,USA,1,27,17,"Energy expenses are becoming an increasingly important fraction of data center operating costs. At the same time, the energy expense per unit of computation can vary significantly between two difierent locations. In this paper, we characterize the variation due to fluctuating electricity prices and argue that existing distributed systems should be able to exploit this variation for significant economic gains. Electricity prices exhibit both temporal and geographic variation, due to regional demand difierences, transmission inefficiencies, and generation diversity. Starting with historical electricity prices, for twenty nine locations in the US, and network traffic data collected on Akamai's CDN, we use simulation to quantify the possible economic gains for a realistic workload. Our results imply that existing systems may be able to save millions of dollars a year in electricity costs, by being cognizant of locational computation cost difierences. Copyright 2009 ACM.",Economics; Management; Performance,Computation costs; Data centers; Distributed systems; Economic gains; Electric bills; Electricity costs; Electricity prices; Energy expense; Existing systems; Geographic variation; Internet-scale systems; Network traffic; Per unit; Computer simulation; Convolutional codes; Economics; Internet; Operating costs
"Anand A., Sekar V., Akella A.",3,SmartRE: An architecture for coordinated network-wide redundancy elimination,2009,76,"University of Wisconsin-Madison, United States; Carnegie Mellon University, United States",Carnegie Mellon University;University of Wisconsin-Madison,2,USA,1,37,20,"Application-independent Redundancy Elimination (RE), or identifying and removing repeated content from network transfers, has been used with great success for improving network performance on enterprise access links. Recently, there is growing interest for supporting RE as a network-wide service. Such a network-wide RE service benefits ISPs by reducing link loads and increasing the effective network capacity to better accommodate the increasing number of bandwidth-intensive applications. Further, a network-wide RE service democratizes the benefits of RE to all end-to-end traffic and improves application performance by increasing throughput and reducing latencies. While the vision of a network-wide RE service is appealing, realizing it in practice is challenging. In particular, extending single-vantage-point RE solutions designed for enterprise access links to the network-wide case is inefficient and/or requires modifying routing policies. We present SmartRE, a practical and efficient architecture for network-wide RE. We show that SmartRE can enable more effective utilization of the available resources at network devices, and thus can magnify the overall benefits of network-wide RE. We prototype our algorithms using Click and test our framework extensively using several real and synthetic traces. Copyright 2009 ACM.",Caching; Redundancy elimination,Access links; Application performance; Bandwidth-intensive applications; Efficient architecture; Link Loads; Network Capacity; Network devices; Network transfers; Network-wide services; Overall benefit; Redundancy elimination; Routing policies; Service benefits; Convolutional codes; Internet service providers; Network performance; Redundancy; Systems engineering; Quality assurance
"Xie Y., Yu F., Abadi M.",3,De-anonymizing the internet using unreliable IDs,2009,12,"Microsoft Research Silicon Valley, United States",Microsoft,1,USA,1,39,31,"Today's Internet is open and anonymous. While it permits free traffic from any host, attackers that generate malicious traffic cannot typically be held accountable. In this paper, we present a system called HostTracker that tracks dynamic bindings between hosts and IP addresses by leveraging application-level data with unreliable IDs. Using a month-long user login trace from a large email provider, we show that HostTracker can attribute most of the activities reliably to the responsible hosts, despite the existence of dynamic IP addresses, proxies, and NATs. With this information, we are able to analyze the host population, to conduct forensic analysis, and also to blacklist malicious hosts dynamically. Copyright 2009 ACM.",Measurement; Security,Dynamic binding; Forensic analysis; IP addresss; Malicious host; Malicious traffic; Convolutional codes; Internet; Network security; Internet protocols
"Gollakota S., Perli S.D., Katabi D.",3,Interference alignment and cancellation,2009,126,"MIT CSAIL, United States",MIT,1,USA,1,31,28,"The throughput of existing MIMO LANs is limited by the number of antennas on the AP. This paper shows how to overcome this limitation. It presents interference alignment and cancellation (IAC), a new approach for decoding concurrent sender-receiver pairs in MIMO networks. IAC synthesizes two signal processing techniques, interference alignment and interference cancellation, showing that the combination applies to scenarios where neither interference alignment nor cancellation applies alone. We show analytically that IAC almost doubles the throughput of MIMO LANs. We also implement IAC in GNU-Radio, and experimentally demonstrate that for 2×2 MIMO LANs, IAC increases the average throughput by 1.5x on the downlink and 2x on the uplink. Copyright 2009 ACM.",Interference alignment; Interference cancellation,Average throughput; Interference alignment; Interference cancellation; New approaches; Sender-receiver pairs; Signal processing technique; Convolutional codes; Local area networks; Multiplexing; Radio interference; Signal processing; Alignment
"Bahl P., Chandra R., Moscibroda T., Murty R., Welsh M.",5,White space networking with Wi-Fi like connectivity,2009,171,"Microsoft Research, Redmond, WA, United States; Harvard University, Cambridge, MA, United States",Harvard University;Microsoft,2,USA,1,24,17,"Networking over UHF white spaces is fundamentally different from conventional Wi-Fi along three axes: spatial variation, temporal variation, and fragmentation of the UHF spectrum. Each of these differences gives rise to new challenges for implementing a wireless network in this band. We present the design and implementation of WhiteFi, the first Wi-Fi like system constructed on top of UHF white spaces. WhiteFi incorporates a new adaptive spectrum assignment algorithm to handle spectrum variation and fragmentation, and proposes a low overhead protocol to handle temporal variation. WhiteFi builds on a simple technique, called SIFT, that reduces the time to detect transmissions in variable channel width systems by analyzing raw signals in the time domain. We provide an extensive system evaluation in terms of a prototype implementation and detailed experimental and simulation results. Copyright 2009 ACM.",Channel width; Cognitive radios; Dynamic spectrum access; White spaces; Wi-Fi,Channel widths; Cognitive radio; Dynamic spectrum access; White space; White spaces; Adaptive algorithms; Convolutional codes; Radio; Software prototyping; Spectroscopy; Time domain analysis; Wi-Fi; Wireless networks
"Mysore R.N., Pamboris A., Farrington N., Huang N., Miri P., Radhakrishnan S., Subramanya V., Vahdat A.",8,PortLand: A scalable fault-tolerant layer 2 data center network fabric,2009,474,"Department of Computer Science and Engineering, University of California San Diego, United States",University of California San Diego,1,USA,1,28,20,"This paper considers the requirements for a scalable, easily manageable, fault-tolerant, and efficient data center network fabric. Trends in multi-core processors, end-host virtualization, and commodities of scale are pointing to future single-site data centers with millions of virtual end points. Existing layer 2 and layer 3 network protocols face some combination of limitations in such a setting: lack of scalability, difficult management, inflexible communication, or limited support for virtual machine migration. To some extent, these limitations may be inherent for Ethernet/IP style protocols when trying to support arbitrary topologies. We observe that data center networks are often managed as a single logical network fabric with a known baseline topology and growth model. We leverage this observation in the design and implementation of PortLand, a scalable, fault tolerant layer 2 routing and forwarding protocol for data center environments. Through our implementation and evaluation, we show that PortLand holds promise for supporting a ""plug-and-play"" large-scale, data center network. Copyright 2009 ACM.",Data center network fabric; Layer 2 routing in data centers,Arbitrary topology; Data centers; End points; Ethernet/IP; Fault-tolerant; Growth models; Layer 2; Logical network; Multi-core processor; Network fabric; Plug-and-play; Virtual machines; Virtualizations; Convolutional codes; Fabrics; Routing protocols; Satellite communication systems; Topology; Network protocols
"Greenberg A., Kandula S., Maltz D.A., Hamilton J.R., Kim C., Patel P., Jain N., Lahiri P., Sengupta S.",9,VL2: A scalable and flexible data center network,2009,765,Microsoft Research,Microsoft,1,USA,1,23,18,"To be agile and cost effective, data centers should allow dynamic resourceallocation across large server pools. In particular, the datacenter network should enable any server to be assigned to any service. Tomeet these goals, we present VL2, a practical network architecture that scales to support huge data centers with uniform highcapacity between servers, performance isolation between services, and Ethernet layer-2 semantics. VL2 uses (1) flat addressing to allowservice instances to be placed anywhere in the network, (2) Valiant Load Balancing to spread traffic uniformly across network paths, and (3) end-system based address resolution to scale to large serverpools, without introducing complexity to the network control plane. VL2's design is driven by detailed measurements of traffic and faultdata from a large operational cloud service provider. VL2's implementationleverages proven network technologies, already availableat lowcost in high-speed hardware implementations, to build a scalableand reliable network architecture. As a result, VL2 networkscan be deployed today, and we have built a working prototype. We evaluate the merits of the VL2 design using measurement, analysis, and experiments. Our VL2 prototype shuffles 2.7 TB of data among servers in 395 seconds 75 sustaining a rate that is 94% of the maximumpossible. Copyright 2009 ACM.",Commoditization; Data center network,Address resolution; Commoditization; Cost effective; Data centers; Hardware implementations; High-capacity; High-speed; Network control plane; Network paths; Network technologies; Service provider; System-based; Valiant Load-balancing; Convolutional codes; Hardware; Satellite communication systems; Servers; Network architecture
"Jokela P., Zahemszky A., Rothenberg C.E., Arianfar S., Nikander P.",5,LIPSIN: Line speed publish/subscribe inter-networking,2009,205,"Ericsson Research, NomadicLab, Finland; University of Campinas (UNICAMP), Brazil",Ericsson Research;University of Campinas (Unicamp),2,Brazil;Finland,2,45,39,"A large fraction of today's Internet applications are internally publish/subscribe in nature; the current architecture makes it cumbersome and inept to support them. In essence, supporting efficient publish/subscribe requires data-oriented naming, efficient multicast, and in-network caching. Deployment of native IP-based multicast has failed, and overlay-based multicast systems are inherently inefficient. We surmise that scalable and efficient publish/subscribe will require substantial architectural changes, such as moving from endpoint-oriented systems to information-centric architectures. In this paper, we propose a novel multicast forwarding fabric, suitable for large-scale topic-based publish/subscribe. Due to very simple forwarding decisions and small forwarding tables, the fabric may be more energy efficient than the currently used ones. To understand the limitations and potential, we provide efficiency and scalability analysis via simulations and early measurements from our two implementations. We show that the system scales up to metropolitan WAN sizes, and we discuss how to interconnect separate networks. Copyright 2009 ACM.",Bloom filters; Forwarding; Multicast; Publish/subscribe,Architectural changes; Bloom filters; Energy efficient; Forwarding tables; In-network; Internet application; Internetworking; Multicast systems; Multicasts; Native IP; Publish/subscribe; Scalability analysis; Blooms (metal); Convolutional codes; Energy efficiency; Fabrics; Internet; Internet protocols; Multicasting
"Vutukuru M., Balakrishnan H., Jamieson K.",3,Cross-layer wireless bit rate adaptation,2009,126,"MIT CSAIL, United States; University College London, United Kingdom",MIT;University College London,2,UK;USA,2,26,18,"This paper presents SoftRate, a wireless bit rate adaptation protocol that is responsive to rapidly varying channel conditions. Unlike previous work that uses either frame receptions or signal-to-noise ratio (SNR) estimates to select bit rates, SoftRate uses confidence information calculated by the physical layer and exported to higher layers via the SoftPHY interface to estimate the prevailing channel bit error rate (BER). Senders use this BER estimate, calculated over each received packet (even when the packet has no bit errors), to pick good bit rates. SoftRate's novel BER computation works across different wireless environments and hardware without requiring any retraining. SoftRate also uses abrupt changes in the BER estimate to identify interference, enabling it to reduce the bit rate only in response to channel errors caused by attenuation or fading. Our experiments conducted using a software radio prototype show that SoftRate achieves 2× higher throughput than popular frame-level protocols such as SampleRate [4] and RRAA [24]. It also achieves 20% more throughput than an SNR-based protocol trained on the operating environment, and up to 4× higher throughput than an untrained SNR-based protocol. The throughput gains using SoftRate stem from its ability to react to channel variations within a single packet-time and its robustness to collision losses. Copyright 2009 ACM.",Bit rate adaptation; Cross-layer; SoftPHY; Wireless,Abrupt change; Bit rate adaptation; Bit rates; Bit-errors; Channel conditions; Channel error; Channel variations; Computation work; Confidence information; Cross-layer; Operating environment; Physical layers; Software Radio; Wireless environment; Convolutional codes; Errors; Fading (radio); Signal to noise ratio; Software prototyping; Surface chemistry; Throughput; Wireless networks; Bit error rate
"Godfrey P.B., Ganichev I., Shenker S., Stoica I.",4,Pathlet routing,2009,61,"University of Illinois, Urbana-Champaign, United States; UC Berkeley, United States; ICSI, United States",University of California Berkeley;UIUC,2,USA,1,32,28,"We present a new routing protocol, pathlet routing, in which networks advertise fragments of paths, called pathlets, that sources concatenate into end-to-end source routes. Intuitively, the pathlet is a highly flexible building block, capturing policy constraints as well as enabling an exponentially large number of path choices. In particular, we show that pathlet routing can emulate the policies of BGP, source routing, and several recent multipath proposals. This flexibility lets us address two major challenges for Internet routing: scalability and source-controlled routing. When a router's routing policy has only ""local"" constraints, it can be represented using a small number of pathlets, leading to very small forwarding tables and many choices of routes for senders. Crucially, pathlet routing does not impose a global requirement on what style of policy is used, but rather allows multiple styles to coexist. The protocol thus supports complex routing policies while enabling and incentivizing the adoption of policies that yield small forwarding plane state and a high degree of path choice. Copyright 2009 ACM.",Design; Experimentation; Performance; Reliability,Experimentation; Flexible building; Forwarding tables; Internet routing; Multi-path; Path choice; Performance reliability; Policy constraints; Routing policies; Source routing; Convolutional codes; Internet protocols; Network protocols; Routers; Routing protocols
"Brodsky M.Z., Morris R.T.",2,In defense of wireless carrier sense,2009,21,"MIT CSAIL, United States",MIT,1,USA,1,27,17,"Carrier sense is often used to regulate concurrency in wireless medium access control (MAC) protocols, balancing interference protection and spatial reuse. Carrier sense is known to be imperfect, and many improved techniques have been proposed. Is the search for a replacement justified? This paper presents a theoretical model for average case two-sender carrier sense based on radio propagation theory and Shannon capacity. Analysis using the model shows that carrier sense performance is surprisingly close to optimal for radios with adaptive bitrate. The model suggests that hidden and exposed terminals usually cause modest reductions in throughput rather than dramatic decreases. Finally, it is possible to choose a fixed sense threshold which performs well across a wide range of scenarios, in large part due to the role of the noise floor. Experimental results from an indoor 802.11 testbed support these claims. Copyright 2009 ACM.",Analytical modeling; Carrier sense; CSMA; Medium access control,Analytical modeling; Average case; Bit rates; Carrier sense; Exposed terminal; Large parts; Noise floor; Radio propagation; Shannon capacity; Spatial reuse; Theoretical models; Wireless carriers; Wireless medium access; Carrier sense multiple access; Concurrency control; Convolutional codes; Radio waves; Security systems; Telecommunication networks; Wireless networks; Wireless telecommunication systems; Medium access control
"Gringoli F., Salgarelli L., Dusi M., Cascarano N., Risso F., Claffy K.C.",6,GT: Picking up the truth from the ground for internet traffic,2009,115,"Università di Brescia, Italy; Politecnico di Torino, Italy; CAIDA, United States",Politecnico di Torino;Università Degli Studi di Brescia,2,Italy;USA,2,14,9,"Much of Internet traffic modeling, firewall, and intrusion detection research requires traces where some ground truth regarding application and protocol is associated with each packet or flow. This paper presents the design, development and experimental evaluation of gt, an open source software toolset for associating ground truth information with Internet traffic traces. By probing the monitored host's kernel to obtain information on active Internet sessions, gt gathers ground truth at the application level. Preliminary experimental results show that gt's effectiveness comes at little cost in terms of overhead on the hosting machines. Furthermore, when coupled with other packet inspection mechanisms, gt can derive ground truth not only in terms of applications (e.g., e-mail), but also in terms of protocols (e.g., SMTP vs. POP3).",Application layer; Ground truth; Transport layer,Application layers; Application level; Experimental evaluation; Ground truth; Internet traffic; Internet traffic modeling; Open Source Software; Packet inspection; Picking up; Transport layers; Internet; Intrusion detection; Internet protocols
"Papagiannaki K., Rizzo L.",2,The ACM SIGCOMM 2009 Technical Program Committee process,2009,4,"Intel Research Pittsburgh, United States; Università di Pisa, Italy",Intel;Università di Pisa,2,Italy;USA,2,9,7,"Selecting a technical program for a conference, and running the process so that decisions are well received by authors and participants, is a challenging task. We report our experience in running the SIGCOMM 2009 Technical Program Committee (TPC). The purpose of this article is to document the process that we followed, and discuss it critically. This should let authors get a better understanding of what led to the final acceptance or rejection of their work, and hopefully let other colleagues in charge of similar tasks make use of our experience.",Documentation,Technical programs; System program documentation; Communication
Bowman D.,1,Neo-luddism and the demonisation of technology: Cultural collision on the information superhighway,2009,0,"Sandvine Incorporated, Waterloo, ON, Canada",Sandvine Incorporated,1,Canada,1,22,2,"The Internet is a primary engine of innovation, communication, and entertainment in our society. It is used by diverse and potentially conflicting interests. When these interests collide in the form of technology, should the Internet stay true to its roots and let things take their course naturally, or should regulation and legislation be enacted to control what may or may not be done. This author believes public opinion is best served by light regulation and a strong focus on allowing technological innovation to take its natural course.",Network neutrality; Network quality of service; Network security; Privacy; Quality of experience,Light regulation; Network quality of services; Public opinions; Quality of experience (QoE); Technological innovation; Data privacy; Laws and legislation; Network security; Quality of service; Social aspects; Internet
"Este A., Gringoli F., Salgarelli L.",3,On the stability of the information carried by traffic flow features at the packet level,2009,60,"DEA, Università Degli Studi di Brescia, Italy",Università Degli Studi di Brescia,1,Italy,1,15,9,"This paper presents a statistical analysis of the amount of information that the features of traffic flows observed at the packet-level carry, with respect to the protocol that generated them. We show that the amount of information of the majority of such features remain constant irrespective of the point of observation (Internet core vs. Internet edge) and to the capture time (year 2000/01 vs. year 2008). We also describe a comparative analysis of how four statistical classifiers fare using the features we studied.",Traffic classification; Transport layer,Amount of information; Capture time; Comparative analysis; Internet core; Packet level; Statistical classifier; Traffic classification; Traffic flow; Transport layers; Classification (of information); Internet; Telecommunication traffic; Internet protocols
"Damjanovic D., Welzl M.",2,MulTFRC: Providing weighted fairness for multimedia applications (and others too!),2009,11,"Institute of Computer Science, University of Innsbruck, Austria; Department of Informatics, University of Oslo, Norway",Institute of Computer Science;University of Innsbruck;University of Oslo,3,Austria;Norway,2,16,10,"When data transfers to or from a host happen in parallel, users do not always consider them to have the same importance. Ideally, a transport protocol should therefore allow its users to manipulate the fairness among flows in an almost arbitrary fashion. Since data transfers can also include real-time media streams which need to keep delay - and hence buffers - small, the protocol should also have a smooth sending rate. In an effort to satisfy the above requirements, we present MulTFRC, a congestion control mechanism which is based on the TCP-friendly Rate Control (TFRC) protocol. It emulates the behavior of a number of TFRC flows while maintaining a smooth sending rate. Our simulations and a real-life test demonstrate that MulTFRC performs significantly better than its competitors, potentially making it applicable in a broader range of settings than what TFRC is normally associated with.",TCP-friendliness; TFRC; Transport protocols,Congestion control mechanism; Media streams; Multimedia applications; Real-life test; Sending rate; TCP friendly rate control; TCP-friendliness; TFRC; Transport protocols; Weighted fairness; Congestion control (communication); Data transfer; Transmission control protocol
"Medhi D., Freeman P.A.",2,Research challenges in future networks: A report from US-Japan Workshop on Future Networks,2009,2,"Department of Computer Science and Electrical Engineering, University of Missouri, Kansas City, United States; College of Computing, Georgia Institute of Technology, United States",Georgia Tech;University of Missouri,2,USA,1,2,0,"A US-Japan Workshop on Future Networks was held in Palo Alto, CA on October 31 - November 1, 2008. This workshop brought together leading US and Japanese network researchers and network research infrastructure developers who are interested in future networks. The focus was on research issues and experimental infrastructure to support research on future generation networks. The goal was to foster cooperation and communication between peers in the two countries. Through this workshop, a number of research challenges were identified. The workshop also made recommendations to: create a new funding mechanism to foster special collaborations in networking and experimentation, extend current national testbeds with international connectivity; and urge the respective governments to exert strong leadership to ensure that collaborative research for creating future networks is carried out.",Collaborative research; Future networks; Research challenges,Collaborative research; Funding mechanisms; Future generations; Future networks; International connectivity; Research challenges; Research infrastructure; Research issues; Distributed computer systems; Research
"Kuntz R., Gallais A., Noel T.",3,Medium Access Control facing the reality of WSN deployments,2009,17,"Image Sciences, Computer Sciences and Remote Sensing Laboratory (LSIIT UMR CNRS 7005), University of Strasbourg, France",University of Strasbourg,1,France,1,34,34,"Although research on algorithms and communication protocols in Wireless Sensor Networks (WSN) has yielded a tremendous effort so far, most of these protocols are hardly used in real deployments nowadays. Several reasons have been put forward in recent publications. In this paper, we further investigate this trend from a Medium Access Control (MAC) perspective by analyzing both the reasons behind successful deployments and the characteristics of the MAC layers proposed in the literature. The effort allocated to develop suitable protocols from scratch every new deployment could however be minimized by using already existing contributions which provide code reuse and adaptive protocols. Though we advocate their use for nowadays deployments, we have identified several shortcomings in foreseen scenarios for which we provide guidelines for future researches.",Deployments; MAC; Survey; Wireless sensor networks,Adaptive protocol; Code reuse; Deployments; MAC; MAC layer; Medium access control; Surveys; Wireless sensor networks
Schulzrinne H.,1,Double submissions - Publishing misconduct or just effective dissemination?,2009,2,"Department of Computer Science, Columbia University, New York, NY, United States",Columbia University,1,USA,1,2,1,"As the community develops an ever more diverse set of venues for disseminating and discussing technical work and as the traditional resource constraints change from pages and shelf space to reviewer time, the traditional prohibition against double submission deserves closer consideration. We discuss reasons why double submissions have been frowned upon, and try to establish a set of guidelines that ensure appropriate review and dissemination, without preventing informal early discussion of research projects.",Conference organization; Conferences in computer science; Double submission; Publishing; Reviewing,Conference organization; Double submission; Resource Constraint; Reviewing; Technical work; Publishing; Communication
Carpenter B.E.,1,Observed relationships between size measures of the Internet,2009,6,"Department of Computer Science, University of Auckland, Auckland, New Zealand",University of Auckland,1,New Zealand,1,22,14,"This paper reports some observations on the relationships between three measures of the size of the Internet over more than ten years. The size of the BGP4 routing table, the number of active BGP4 Autonomous Systems, and a lower bound on the total size of the Internet, appear to have fairly simple relationships despite the Internet's growth by two orders of magnitude. In particular, it is observed that the size of the BGP4 system appears to have grown approximately in proportion to the square root of the lower-bound size of the globally addressable Internet. A simple model that partially explains this square law is described. It is not suggested that this observation and model have predictive value, since they cannot predict qualitative changes in the Internet topology. However, they do offer a new way to understand and monitor the scaling of the BGP4 system.",BGP; Inter-domain routing; Internet topology,Autonomous systems; BGP; Interdomain Routing; Internet topologies; Lower bounds; Orders of magnitude; Predictive values; Qualitative changes; Routing table; Size measures; Square roots; Topology; Internet
"Greenhalgh A., Huici F., Hoerdt M., Papadimitriou P., Handley M., Mathy L.",6,Flow processing and the rise of commodity network hardware,2009,47,"University College London, United Kingdom; NEC Europe Ltd, Germany; Lancaster University, United Kingdom",Lancaster University;University College London,2,Germany;UK,2,21,12,"The Internet has seen a proliferation of specialized middle-box devices that carry out crucial network functionality such as load balancing, packet inspection and intrusion detection. Recent advances in CPU power, memory, buses and network connectivity have turned commodity PC hardware into a powerful network platform. Furthermore, commodity switch technologies have recently emerged offering the possibility to control the switching of flows in a fine-grained manner. Exploiting these new technologies, we present a new class of network architectures which enables flow processing and forwarding at unprecedented flexibility and low cost.",Architecture; Flow processing; Internet; Virtualization,CPU power; Flow processing; Low costs; Network connectivity; Network functionality; Network platforms; Packet inspection; PC hardware; Virtualizations; Architecture; Internet; Intrusion detection; Network architecture; Personal computers; Hardware
"Vishwanath A., Sivaraman V., Thottan M.",3,Perspectives on router buffer sizing: Recent results and open problems,2009,66,"School of EE and T, University of New South Wales, Sydney, NSW 2052, Australia; Networking Research Lab, Bell Labs Alcatel-Lucent, United States",Bell Labs;University of New South Wales,2,Australia;USA,2,53,50,"The past few years have witnessed a lot of debate on how large Internet router buffers should be. The widely believed rule-of-thumb used by router manufacturers today mandates a buffer size equal to the delay-bandwidth product. This rule was first challenged by researchers in 2004 who argued that if there are a large number of long-lived TCP connections owing through a router, then the buffer size needed is equal to the delay-bandwidth product divided by the square root of the number of long-lived TCP flows. The publication of this result has since reinvigorated interest in the buffer sizing problem with numerous other papers exploring this topic in further detail - ranging from papers questioning the applicability of this result to proposing alternate schemes to developing new congestion control algorithms, etc. This paper provides a synopsis of the recently proposed buffer sizing strategies and broadly classifies them according to their desired objective: link utilisation, and per-flow performance. We discuss the pros and cons of these different approaches. These prior works study buffer sizing purely in the context of TCP. Subsequently, we present arguments that take into account both real-time and TCP traffic. We also report on the performance studies of various high-speed TCP variants and experimental results for networks with limited buffers. We conclude this paper by outlining some interesting avenues for further research.",Buffer size; Mixed real-time and TCP traffic; Optical; Survey,Buffer sizes; Buffer sizing; If there are; Internet routers; Limited buffers; Long-lived TCP connections; Optical; Performance study; Router buffer; Square roots; TCP flows; TCP traffic; TCP variants; Algorithms; Surveys; Bandwidth
"Han C., Zhan S., Yang Y.",3,Proactive attacker localization in wireless LAN,2009,4,"ECE Department, Virginia Tech, United States",Virginia Tech,1,USA,1,12,12,"This paper addresses the open problem of locating an attacker that intentionally hides or falsifies its position using advanced radio technologies. A novel attacker localization mechanism, called Access Point Coordinated Localization (APCL), is proposed for IEEE 802.11 networks. APCL actively forces the attacker to reveal its position information by combining access point (AP) coordination with the traditional range-free localization. The optimal AP coordination process is calculated by modeling it as a finite horizon discrete Markov decision process, which is efficiently solved by an approximation algorithm. The performance advantages are verified through extensive simulations.",Secure localization; Wireless LAN,Access points; Advanced radio; Coordination process; Extensive simulations; Finite horizons; IEEE 802.11 networks; Markov Decision Processes; Position information; Range free; Secure localization; Approximation algorithms; Markov processes; Standards; Wireless local area networks (WLAN)
"Bohli J.-M., Sorge C., Westhoff D.",3,"Initial observations on economics, pricing, and penetration of the Internet of Things market",2009,37,"NEC Laboratories Europe, Kurfürsten-Anlage 36, 69115 Heidelberg, Germany",NEC,1,Germany,1,10,7,"One expectation about the future Internet is the participation of billions of sensor nodes, integrating the physical with the digital world. This Internet of Things can offer new and enhanced services and applications based on knowledge about the environment and the entities within. Millions of micro-providers could come into existence, forming a highly fragmented market place with new business opportunities to offer commercial services. In the related field of Internet and Telecommunication services, the design of markets and pricing schemes has been a vital research area in itself. We discuss how these findings can be transferred to the Internet of Things. Both the appropriate market structure and corresponding pricing schemes need to be well understood to enable a commercial success of sensor-based services. We show some steps that an evolutionary establishment of this market might have to take.",Internet of things; Market; Pricing; Sensor networks,Business opportunities; Commercial services; Digital world; Future internet; Internet of Things (IOT); Market; Market place; Market structures; Pricing scheme; Sensor-based services; Services and applications; Costs; Economics; Internet; Sensor networks; Sensor nodes; Telecommunication services; Commerce
Schulzrinne H.,1,Double-blind reviewing - More placebo than miracle cure?,2009,5,"Department of Computer Science, Columbia University, New York, NY, United States",Columbia University,1,USA,1,8,8,"In double-blind reviewing (DBR), both reviewers and authors are unaware of each others' identities and affiliations. DBR is said to increase review fairness. However, DBR may only be marginally effective in combating the randomness of the typical conference review process for highly-selective conferences. DBR may also make it more difficult to adequately review conference submissions that build on earlier work of the authors and have been partially published in workshops. I believe that DBR mainly increases the perceived fairness of the reviewing process, but that may be an important benefit. Rather than waiting until the final stages, the reviewing process needs to explicitly address the issue of workshop publications early on.",Conference organization; Conferences in computer science; Double-blind reviews; Reviewing,Conference organization; DBR; Review process; Reviewing; Reviewing process; Communication
"Arkko J., Briscoe B., Eggert L., Feldmann A., Handley M.",5,Dagstuhl perspectives workshop on end-to-end protocols for the future Internet,2009,4,"Ericsson Research, United States; BT Research, United States; Nokia Research Center, United States; Technische Universitat Berlin, Deutsche Telekom Labs, Germany; Dept. of Computer Science, University College London, United Kingdom",BT Research;Ericsson Research;Nokia;TU Berlin;University College London,5,Germany;UK;USA,3,20,19,"This article summarises the presentations and discussions during a workshop on end-to-end protocols for the future Internet in June 2008. The aim of the workshop was to establish a dialogue at the interface between two otherwise fairly distinct communities working on future Internet protocols: those developing internetworking functions and those developing end-to-end transport protocols. The discussion established near-consensus on some of the open issues, such as the preferred placement of traffic engineering functionality, whereas other questions remained controversial. New research agenda items were also identified.",Architecture; Control; Cross-layer,Cross-layer; End-to-end protocol; End-to-end transport; Future internet; Internetworking; Research agenda; Traffic Engineering; Architecture; Control; Internet; Internet protocols
Allman M.,1,Comments on selecting ephemeral ports,2009,8,"International Computer Science Institute, United States",University of California Berkeley,1,USA,1,14,8,"Careless selection of the ephemeral port number portion of a transport protocol's connection identifier has been shown to potentially degrade security by opening the connection up to injection attacks from ""blind"" or ""off path"" attackers - or, attackers that cannot directly observe the connection. This short paper empirically explores a number of algorithms for choosing the ephemeral port number that attempt to obscure the choice from such attackers and hence make mounting these blind attacks more difficult.",Port numbers; TCP,Port numbers; TCP; Transport protocols; Transmission control protocol; Network security
"Hayes D.A., But J., Armitage G.",3,Issues with Network Address Translation for SCTP,2009,11,"Centre for Advanced Internet Architectures (CAIA), Swinburne University of Technology, PO Box 218, Hawthorn, VIC 3122, Australia",Centre for Advanced Internet Architectures;Swinburne University of Technology,2,Australia,1,11,10,"A Stream Control Transmission Protocol (SCTP) capable Network Address Translation (NAT) device is necessary to support the wider deployment of the SCTP protocol. The key issues for an SCTP NAT are SCTP's control chunk multiplexing and multi-homing features. Control chunk multiplexing can expose an SCTP NAT to possible Denial of Service attacks. These can be mitigated through the use of chunk and parameter processing limits. Multiple and changing IP addresses during an SCTP association, mean that SCTP NATs cannot operate in the way conventional UDP/TCP NATs operate. Tracking these multiple global IP addresses can help in avoiding lookup table conflicts, however, it can also result in circumstances that can lead to NAT state inconsistencies. Our analysis shows that tracking global IP addresses is not necessary in most expected practical installations. We use our FreeBSD SCTP NAT implementation, alias-sctp to examine the performance implications of tracking global IP addresses. We find that typical memory usage doubles and that the processing requirements are significant for installations that experience high association arrival rates. In conclusion we provide practical recommendations for a secure stable SCTP NAT installation.",FreeBSD; Libalias; Network Address Translation (NAT); Stream Control Transmission Protocol (SCTP),Arrival rates; Denial of service attacks; FreeBSD; Global IP; IP addresss; Libalias; Look up table; Memory usage; Multi-homing; Network Address Translation (NAT); Network address translations; Practical recommendation; Stream control transmission protocols; Computer crime; Multiplexing; Table lookup; Translation (languages); Internet protocols
"Alimi R., Wang Y., Yang Y.R.",3,Shadow configuration as a network management primitive,2008,21,"Laboratory of Networked Systems, Yale University, New Haven, CT, United States",Yale University,1,USA,1,56,52,"Configurations for today's IP networks are becoming increasingly complex. As a result, configuration management is becoming a major cost factor for network providers and configuration errors are becoming a major cause of network disruptions. In this paper, we present and evaluate the novel idea of shadow configurations. Shadow configurations allow configuration evaluation before deployment and thus can reduce potential network disruptions. We demonstrate using real implementation that shadow configurations can be implemented with low overhead. Copyright 2008 ACM.",Network diagnostics; Network management,Configuration managements; Cost factors; Ip networks; Low overheads; Network diagnostics; Network providers; Convolutional codes; Network management
"Goldberg S., Halevi S., Jaggard A.D., Ramachandran V., Wright R.N.",5,Rationality and traffic attraction: Incentives for honest path announcements in bgp,2008,21,"Princeton University, United States; IBM Research; Rutgers University, United States; Colgate University, United States",Colgate University;IBM;Princeton University;Rutgers University,4,USA,1,41,40,"We study situations in which autonomous systems (ASes) may have incentives to send BGP announcements differing from the AS-level paths that packets traverse in the data plane. Prior work on this issue assumed that ASes seek only to obtain the best possible outgoing path for their traffic. In reality, other factors can influence a rational AS's behavior. Here we consider a more natural model, in which an AS is also interested in attracting incoming traffic (e.g., because other ASes pay it to carry their traffic). We ask what combinations of BGP enhancements and restrictions on routing policies can ensure that ASes have no incentive to lie about their data-plane paths. We find that protocols like S-BGP alone are insufficient, but that S-BGP does suffice if coupled with additional (quite unrealistic) restrictions on routing policies. Our game-theoretic analysis illustrates the high cost of ensuring that the ASes honestly announce data-plane paths in their BGP path announcements. Copyright 2008 ACM.",Bgp; Incentives,Autonomous systems; Bgp; Data planes; High costs; Incentives; Incoming traffics; Natural models; Routing policies; Theoretic analysis; Convolutional codes; Switching; Routing protocols
"Motiwala M., Elmore M., Feamster N., Vempala S.",4,Path splicing,2008,77,"College of Computing, Georgia Tech, United States",Georgia Tech,1,USA,1,32,28,"We present path splicing, a new routing primitive that allows network paths to be constructed by combining multiple routing trees (""slices"") to each destination over a single network topology. Path splicing allows traffic to switch trees at any hop en route to the destination. End systems can change the path on which traffic is forwarded by changing a small number of additional bits in the packet header. We evaluate path splicing for intradomain routing using slices generated from perturbed link weights and find that splicing achieves reliability that approaches the best possible using a small number of slices, for only a small increase in latency and no adverse effects on traffic in the network. In the case of interdomain routing, where splicing derives multiple trees from edges in alternate backup routes, path splicing achieves near-optimal reliability and can provide significant benefits even when only a fraction of ASes deploy it. We also describe several other applications of path splicing, as well as various possible deployment paths. Copyright 2008 ACM.",Multi-path routing; Path diversity; Path splicing,Adverse effects; Backup routes; En routes; End systems; Inter-domain routing; Intra-domain routing; Link weights; Multi-path routing; Multiple routing; Multiple trees; Network paths; Optimal reliabilities; Other applications; Packet headers; Path diversity; Path splicing; Single networks; Convolutional codes; Electric network topology; Grid computing; Multipath propagation; Graph theory
"Kuo F.-C., Fu X.",2,Probe-aided MulTCP: An aggregate congestion control mechanism,2008,15,"Institute for Computer Science, University of Goettingen, Germany",University of Goettingen,1,Germany,1,29,19,"An aggregate congestion control mechanism, namely Probe-Aided MulTCP (PA-MulTCP), is proposed in this paper. It is based on MulTCP, a proposal for enabling an aggregate to emulate the behavior of multiple concurrent TCP connections. The objective of PA-MulTCP is to ensure the fair sharing of the bottleneck bandwidth between the aggregate and other TCP or TCP-friendly flows while keeping lightweightness and responsiveness. Unlike MulTCP, there are two congestion window loops in PA-MulTCP, namely the probe window loop and the adjusting window loop. The probe window loop constantly probes the congestion situation and the adjusting window loop dynamically adjusts the congestion window size for the arriving and departing flows within the aggregate. Our simulations demonstrate that PA-MulTCP is more stable and fairer than MulTCP over a wide range of the weight N in steady conditions as well as in varying congestion conditions. PA-MulTCP is also responsive to flow arrival/departure and thus reduces the latency of short-lived transfers. Furthermore, PA-MulTCP is lightweight, since it enjoys above advantages at the cost of only an extra probe window loop, which has a marginal influence on the implementation complexity. Finally, the design of PA-MulTCP decouples the congestion management from the other functionalities in the aggregate flow management. As a result, PA-MulTCP could be potentially applied to a wider range of scenarios, e.g. wireless TCP proxies, edge-to-edge overlays, QoS provisioning and mass data transport.",Aggregate flow management; Congestion control; Fairness; TCP,Bottleneck bandwidth; Congestion conditions; Congestion Control; Congestion control mechanism; Congestion management; Congestion window; Congestion window size; Edge-to-edge; Fair sharing; Fairness; Flow management; Implementation complexity; Mass data; QOS provisioning; Steady conditions; TCP; TCP connections; TCP-friendly; Wireless TCP; Aggregates; Probes; Quality of service; Transmission control protocol; Traffic congestion
"Smith R., Estan C., Jha S., Kong S.",4,Deflating the big bang: Fast and scalable deep packet inspection with extended finite automata,2008,143,"Computer Sciences Department, University of Wisconsin, Madison, United States",University of Wisconsin-Madison,1,USA,1,37,32,"Deep packet inspection is playing an increasingly important role in the design of novel network services. Regular expressions are the language of choice for writing signatures, but standard DFA or NFA representations are unsuitable for high-speed environments, requiring too much memory, too much time, or too much per-flow state. DFAs are fast and can be readily combined, but doing so often leads to state-space explosion. NFAs, while small, require large per-flow state and are slow. We propose a solution that simultaneously addresses all these problems. We start with a first-principles characterization of state-space explosion and give conditions that eliminate it when satisfied. We show how auxiliary variables can be used to transform automata so that they satisfy these conditions, which we codify in a formal model that augments DFAs with auxiliary variables and simple instructions for manipulating them. Building on this model, we present techniques, inspired by principles used in compiler optimization, that systematically reduce runtime and per-flow state. In our experiments, signature sets from Snort and Cisco Systems achieve state-space reductions of over four orders of magnitude, per-flow state reductions of up to a factor of six, and runtimes that approach DFAs. Copyright 2008 ACM.",Deep packet inspection; Regular expressions; Signature matching; Xfa,Auxiliary variables; Big bangs; Cisco systems; Compiler optimizations; Deep packet inspection; First-principles; Formal models; Four orders; High-speed; Network services; Per-flow state; Regular expressions; Run-time; Runtimes; Signature matching; Signature sets; State-space explosions; State-space reductions; Xfa; Binary sequences; Convolutional codes; Finite automata; Inspection; Nanostructured materials; Security of data; Speech recognition; Translation (languages); Packet networks
Dovrolis C.,1,What would darwin think about clean-slate architectures?,2008,27,"College of Computing, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,14,13,"As significant resources are directed towards clean-slate networking research, it is imperative to understand how cleanslate architectural research compares to the diametrically opposite paradigm of evolutionary research. This paper approaches the ""evolution versus clean-slate"" debate through a biological metaphor. We argue that evolutionary research can lead to less costly (more competitive) and more robust designs than clean-slate architectural research. We also argue that the Internet architecture is not ossified, as recently claimed, but that its core protocols play the role of ""evolutionary kernels"", meaning that they are conserved so that complexity and diversity can emerge at the lower and higher layers. We then discuss the factors that determine the deployment of new architectures or protocols, and argue, based on the notion of ""auto-catalytic sets"", that successful innovations are those that become synergistic components in closed loops of existing modules. The paper closes emphasizing the role of evolutionary Internet research.",FP7-ICT FIRE; GENI; Internet; NSF FIND,Architectural research; Closed loops; FP7-ICT FIRE; GENI; Internet architecture; Internet research; NSF FIND; Robust designs; Architecture; Biology; Internet; Network architecture; Research; Slate; Internet protocols
"Gollakota S., Katabi D.",2,Zigzag decoding: Combating hidden terminals in wireless networks,2008,211,"MIT, CSAIL, United States",MIT,1,USA,1,37,23,"This paper presents ZigZag, an 802.11 receiver design that combats hidden terminals. ZigZag's core contribution is a new form of interference cancellation that exploits asynchrony across successive collisions. Specifically, 802.11 retransmissions, in the case of hidden terminals, cause successive collisions. These collisions have different interference-free stretches at their start, which ZigZag exploits to bootstrap its decoding. ZigZag makes no changes to the 802.11 MAC and introduces no overhead when there are no collisions. But, when senders collide, ZigZag attains the same throughput as if the colliding packets were a priori scheduled in separate time slots. We build a prototype of ZigZag in GNU Radio. In a testbed of 14 USRP nodes, ZigZag reduces the average packet loss rate at hidden terminals from 72.6% to about 0.7%. Copyright 2008 ACM.",Hidden terminals; Interference cancellation; Wireless,802.11 MAC; Apriori; Asynchrony; GNU radio; Hidden terminal; Hidden terminals; Interference cancellation; New forms; Packet loss rates; Receiver design; Retransmissions; Time slots; Wireless; Convolutional codes; Decoding; Radio interference; Wireless networks
"Kim C., Caesar M., Rexford J.",3,Floodless in seattle: A scalable ethernet architecture for large enterprises,2008,94,"Princeton University, Princeton, NJ, United States; University of Illinois, Urbana-Champaign, United States",Princeton University;UIUC,2,USA,1,38,31,"IP networks today require massive effort to configure and manage. Ethernet is vastly simpler to manage, but does not scale beyond small local area networks. This paper describes an alternative network architecture called SEATTLE that achieves the best of both worlds: The scalability of IP combined with the simplicity of Ethernet. SEATTLE provides plug-and-play functionality via flat addressing, while ensuring scalability and efficiency through shortest-path routing and hash-based resolution of host information. In contrast to previous work on identity-based routing, SEATTLE ensures path predictability and stability, and simplifies network management. We performed a simulation study driven by real-world traffic traces and network topologies, and used Emulab to evaluate a prototype of our design based on the Click and XORP open-source routing platforms. Our experiments show that SEATTLE efficiently handles network failures and host mobility, while reducing control overhead and state requirements by roughly two orders of magnitude compared with Ethernet bridging. Copyright 2008 ACM.",Enterprise network; Ethernet; Routing; Scalability,Control overheads; Enterprise network; Host mobilities; Identity-based; Ip networks; Network failures; Network topologies; Open sources; Orders of magnitudes; Plug-and-play functionalities; Real-world; Routing; Seattle; Shortest-path routing; Simulation studies; Traffic traces; Convolutional codes; Electric network topology; Ethernet; Internet protocols; Local area networks; Network architecture; Scalability; Network management
"Balasubramanian A., Mahajan R., Venkataramani A., Levine B.N., Zahorjan J.",5,Interactive wifi connectivity for moving vehicles,2008,107,"University of Massachusetts, Amherst, United States; Microsoft Research; University of Washington, United States",Microsoft;University of Massachusetts Amherst;University of Washington at St. Louis,3,USA,1,39,32,"We ask if the ubiquity of WiFi can be leveraged to provide cheap connectivity from moving vehicles for common applications such as Web browsing and VoIP. Driven by this question, we conduct a study of connection quality available to vehicular WiFi clients based on measurements from testbeds in two different cities. We find that current WiFi handoff methods, in which clients communicate with one basestation at a time, lead to frequent disruptions in connectivity. We also find that clients can overcome many disruptions by communicating with multiple basestations simultaneously. These findings lead us to develop ViFi, a protocol that opportunistically exploits basestation diversity to minimize disruptions and support interactive applications for mobile clients. ViFi uses a decentralized and lightweight probabilistic algorithm for coordination between participating basestations. Our evaluation using a two-month long deployment and trace-driven simulations shows that its link-layer performance comes close to an ideal diversity-based protocol. Using two applications, VoIP and short TCP transfers, we show that the link layer performance improvement translates to better application performance. In our deployment, ViFi doubles the number of successful short TCP transfers and doubles the length of disruption-free VoIP sessions compared to an existing WiFi-style handoff protocol. Copyright 2008 ACM.",Applications; Diversity; Handoff; Vehicular networks; Wifi,Application performance; Base-station; Diversity; Handoff; Interactive applications; Link layers; Minimize disruptions; Mobile clients; Moving vehicles; Performance improvements; Probabilistic algorithms; Tcp transfers; Trace-driven simulations; Vehicular networks; Web browsing; Ad hoc networks; Applications; Base stations; Convolutional codes; Internet protocols; Internet telephony; Transmission control protocol; Voice/data communication systems; Wireless telecommunication systems; Wi-Fi
"Tariq M.B., Zeitoun A., Valancius V., Feamster N., Ammar M.",5,Answering what-if deployment and configuration questions with wise,2008,19,"School of Computer Science, Georgia Tech, Atlanta, GA, United States; Google Inc., Mountain View, CA, United States",Georgia Tech;Google,2,USA,1,26,16,"Designers of content distribution networks often need to determine how changes to infrastructure deployment and configuration affect service response times when they deploy a new data center, change ISP peering, or change the mapping of clients to servers. Today, the designers use coarse, back-of-the-envelope calculations, or costly field deployments; they need better ways to evaluate the effects of such hypothetical ""what-if"" questions before the actual deployments. This paper presents What-If Scenario Evaluator (WISE), a tool that predicts the effects of possible configuration and deployment changes in content distribution networks. WISE makes three contributions: (1) an algorithm that uses traces from existing deployments to learn causality among factors that affect service response-time distributions; (2) an algorithm that uses the learned causal structure to estimate a dataset that is representative of the hypothetical scenario that a designer may wish to evaluate, and uses these datasets to predict future response-time distributions; (3) a scenario specification language that allows a network designer to easily express hypothetical deployment scenarios without being cognizant of the dependencies between variables that affect service response times. Our evaluation, both in a controlled setting and in a real-world field deployment at a large, global CDN, shows that WISE can quickly and accurately predict service response-time distributions for many practical What-If scenarios. Copyright 2008 ACM.",Content distribution networks; Performance modeling; What-if scenario evaluation,Back-of-the-envelope calculations; Content distribution networks; Data centers; Data-sets; Deployment and configurations; Deployment scenarios; Field deployments; Future response; Network designers; Performance modeling; Real-world; Response time; Response-time distributions; Scenario specifications; What-if scenario evaluation; Convolutional codes; Design; Distribution of goods; Internet service providers; Learning algorithms; Real time systems; Specification languages; Distributed parameter networks
"Ringberg H., Soule A., Rexford J.",3,WebClass: Adding rigor to manual labeling of traffic anomalies,2008,19,"Computer Science Dept., Princeton University, United States; Thomson, France",Princeton University,1,France;USA,2,20,17,"Despite the flurry of anomaly-detection papers in recent years, effective ways to validate and compare proposed solutions have remained elusive. We argue that evaluating anomaly detectors on manually labeled traces is both important and unavoidable. In particular, it is important to evaluate detectors on traces from operational networks because it is in this setting that the detectors must ultimately succeed. In addition, manual labeling of such traces is unavoidable because new anomalies will be identified and characterized from manual inspection long before there are realistic models for them. It is well known, however, that manual labeling is slow and error-prone. In order to mitigate these challenges, we present WebClass, a web-based infrastructure that adds rigor to the manual labeling process. WebClass allows researchers to share, inspect, and label traffic timeseries through a common graphical user interface. We are releasing WebClass to the research community in the hope that it will foster greater collaboration in creating labeled traces and that the traces will be of higher quality because the entire community has access to all the information that led to a given label.",Data labeling; Data sharing; Database; Network traffic analysis,Anomaly detector; Data labeling; Data Sharing; Database; Error prones; Manual inspection; Network traffic analysis; Operational network; Realistic model; Research communities; Traffic anomalies; Web-based infrastructure; Graphical user interfaces; Detectors
"Levchenko K., Voelker G.M., Paturi R., Savage S.",4,Xl: An efficient network routing algorithm,2008,23,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,32,16,"In this paper, we present a new link-state routing algorithm called Approximate Link state (XL) aimed at increasing routing efficiency by suppressing updates from parts of the network. We prove that three simple criteria for update propagation are sufficient to guarantee soundness, completeness and bounded optimality for any such algorithm. We show, via simulation, that XL significantly outperforms standard link-state and distance vector algorithms - in some cases reducing overhead by more than an order of magnitude - while having negligible impact on path length. Finally, we argue that existing link-state protocols, such as OSPF, can incorporate XL routing in a backwards compatible and incrementally deployable fashion. Copyright 2008 ACM.",Link-state; Routing protocol,Distance vector algorithms; Link-state; Link-state routing; Optimality; Order of magnitudes; Path lengths; Routing efficiencies; Convolutional codes; Routers; Routing protocols; Routing algorithms
"Trestian I., Ranjan S., Kuzmanovi A., Nucci A.",4,Unconstrained endpoint profiling (googling the internet),2008,27,"Northwestern University, Evanston, IL, United States; Narus Inc., Mountain View, CA, United States",Narus Inc.;Northwestern University,2,USA,1,46,30,"Understanding Internet access trends at a global scale, i.e., what do people do on the Internet, is a challenging problem that is typically addressed by analyzing network traces. However, obtaining such traces presents its own set of challenges owing to either privacy concerns or to other operational difficulties. The key hypothesis of our work here is that most of the information needed to profile the Internet endpoints is already available around us - on the web. In this paper, we introduce a novel approach for profiling and classifying endpoints. We implement and deploy a Google-based profiling tool, which accurately characterizes endpoint behavior by collecting and strategically combining information freely available on the web. Our 'unconstrained endpoint profiling' approach shows remarkable advances in the following scenarios: (i) Even when no packet traces are available, it can accurately predict application and protocol usage trends at arbitrary networks; (ii) When network traces are available, it dramatically outperforms state-of-the-art classification tools; (iii) When sampled flow-level traces are available, it retains high classification capabilities when other schemes literally fall apart. Using this approach, we perform unconstrained endpoint profiling at a global scale: for clients in four different world regions (Asia, South and North America and Europe). We provide the first-of-its-kind endpoint analysis which reveals fascinating similarities and differences among these regions. Copyright 2008 ACM.",Clustering; Endpoint profiling; Google; Traffic classification; Traffic locality,Clustering; Endpoint profiling; Google; Traffic classification; Traffic locality; Arts computing; Cluster analysis; Convolutional codes; Internet protocols; Internet
"Rahul H., Kushman N., Katabi D., Sodini C., Edalat F.",5,Learning to share: Narrowband-friendly wideband networks,2008,56,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,37,29,"Wideband technologies in the unlicensed spectrum can satisfy the ever-increasing demands for wireless bandwidth created by emerging rich media applications. The key challenge for such systems, however, is to allow narrowband technologies that share these bands (say, 802.11 a/b/g/n, Zigbee) to achieve their normal performance, without compromising the throughput or range of the wideband network. This paper presents SWIFT, the first system where high-throughput wideband nodes are shown in a working deployment to coexist with unknown narrowband devices, while forming a network of their own. Prior work avoids narrowband devices by operating below the noise level and limiting itself to a single contiguous unused band. While this achieves coexistence, it sacrifices the throughput and operating distance of the wideband device. In contrast, SWIFT creates high throughput wireless links by weaving together non-contiguous unused frequency bands that change as narrowband devices enter or leave the environment. This design principle of cognitive aggregation allows SWIFT to achieve coexistence, while operating at normal power, and thereby obtaining higher throughput and greater operating range. We implement SWIFT on a wideband hardware platform, and evaluate it in the presence of 802.11 devices. In comparison to a baseline that coexists with narrowband devices by operating below their noise level, SWIFT is equally narrowband-friendly but achieves 3.6-10.5x higher throughput and 6x greater range. Copyright 2008 ACM.",Cognitive radios; Wideband radios; Wireless networks,Cognitive radios; Design principles; Hardware platforms; High throughputs; Media applications; Narrow bands; Noise levels; Operating ranges; Unlicensed spectrums; Wideband devices; Wideband radios; Wideband technologies; Wireless bandwidths; Wireless links; Zig bees; Broadband networks; Convolutional codes; Frequency bands; Radio; Throughput; Wireless networks
"Kandula S., Chandra R., Katabi D.",3,What's going on?: Learning communication rules in edge networks,2008,33,"MIT, CSAIL, United States; Microsoft Research",MIT;Microsoft,2,USA,1,26,14,"Existing traffic analysis tools focus on traffic volume. They identify the heavy-hitters - flows that exchange high volumes of data, yet fail to identify the structure implicit in network traffic - do certain flows happen before, after or along with each other repeatedly over time? Since most traffic is generated by applications (web browsing, email, p2p), network traffic tends to be governed by a set of underlying rules. Malicious traffic such as network-wide scans for vulnerable hosts (mySQLbot) also presents distinct patterns. We present eXpose, a technique to learn the underlying rules that govern communication over a network. From packet timing information, eXpose learns rules for network communication that may be spread across multiple hosts, protocols or applications. Our key contribution is a novel statistical rule mining technique to extract significant communication patterns in a packet trace without explicitly being told what to look for. Going beyond rules involving flow pairs, eXpose introduces templates to systematically abstract away parts of flows thereby capturing rules that are otherwise unidentifiable. Deployments within our lab and within a large enterprise show that eXpose discovers rules that help with network monitoring, diagnosis, and intrusion detection with few false positives. Copyright 2008 ACM.",Communication rules; Correlation; Expose; Rule mining,Communication patterns; Communication rules; Correlation; EDGE Networks; Expose; False positives; In networks; Malicious traffics; Network communications; Network Monitoring; Network traffics; Rule mining; Statistical rules; Timing informations; Traffic analysis; Traffic volumes; Web browsing; Convolutional codes; Internet; Internet protocols; Intrusion detection; Communication
"Sherwood R., Bender A., Spring N.",3,Discarte: A disjunctive internet cartographer,2008,33,"University of Maryland, United States",University of Maryland College Park,1,USA,1,46,35,"Internet topology discovery consists of inferring the inter-router connectivity (""links"") and the mapping from IP addresses to routers (""alias resolution""). Current topology discovery techniques use TTL-limited ""traceroute"" probes to discover links and use direct router probing to resolve aliases. The often-ignored record route (RR) IP option provides a source of disparate topology data that could augment existing techniques, but it is difficult to properly align with traceroute-based topologies because router RR implementations are under-standardized. Correctly aligned RR and traceroute topologies have fewer false links, include anonymous and hidden routers, and discover aliases for routers that do not respond to direct probing. More accurate and feature-rich topologies benefit overlay construction and network diagnostics, modeling, and measurement. We present DisCarte, a system for aligning and cross-validating RR and traceroute topology data using observed engineering practices DisCarte uses disjunctive logic programming (DLP), a logical inference and constraint solving technique, to intelligently merge RR and traceroute data. We demonstrate that the resultant topology is more accurate and complete than previous techniques by validating its internal consistency and by comparing to publicly-available topologies. We classify irregularities in router implementations and introduce a divide-and-conquer technique used to scale DLP to Internet-sized systems. Copyright 2008 ACM.",Alias resolution; Discarte; Disjunctive logic programming; Network topology discovery; Record route,Alias resolution; Discarte; Disjunctive logic programming; Network topology discovery; Record route; Computer programming languages; Convolutional codes; Electric network topology; Internet; Internet protocols; Logic programming; Routers
"Liu X., Yang X., Lu Y.",3,To filter or to authorize: Network-layer DoS defense against multimillion-node botnets,2008,70,"Department of Computer Science, University of California, Irvine, United States",University of California Irvine,1,USA,1,37,32,"This paper presents the design and implementation of a filter-based DoS defense system (StopIt) and a comparison study on the effectiveness of filters and capabilities. Central to the StopIt design is a novel closed-control, open-service architecture: any receiver can use StopIt to block the undesired traffic it receives, yet the design is robust to various strategic attacks from millions of bots, including filter exhaustion attacks and bandwidth flooding attacks that aim to disrupt the timely installation of filters. Our evaluation shows that StopIt can block the attack traffic from a few millions of attackers within tens of minutes with bounded router memory. We compare StopIt with existing filter-based and capability-based DoS defense systems under simulated DoS attacks of various types and scales. Our results show that StopIt outperforms existing filter-based systems, and can prevent legitimate communications from being disrupted by various DoS flooding attacks. It also outperforms capability-based systems in most attack scenarios, but a capability-based system is more effective in a type of attack that the attack traffic does not reach a victim, but congests a link shared by the victim. These results suggest that both filters and capabilities are highly effective DoS defense mechanisms, but neither is more effective than the other in all types of DoS attacks. Copyright 2008 ACM.",Capability; Denial-of-service; Filter; Internet,Attack scenarios; Attack traffics; Botnets; Capability; Comparison studies; Defense mechanisms; Defense systems; Denial-of-service; DoS attacks; Filter; Filter-based; Router memories; Service architectures; Computer crime; Convolutional codes; Internet; Telecommunication networks
"Dimitropoulos X., Hurley P., Kind A.",3,Probabilistic lossy counting: An efficient algorithm for finding heavy hitters,2008,54,"IBM Zurich Research Laboratory, Switzerland",IBM,1,Switzerland,1,35,31,"Knowledge of the largest traffic flows in a network is important for many network management applications. The problem of finding these flows is known as the heavy-hitter problem and has been the subject of many studies in the past years. One of the most efficient and well-known algorithms for finding heavy hitters is lossy counting [29]. In this work we introduce probabilistic lossy counting (PLC), which enhances lossy counting in computing network traffic heavy hitters. PLC uses on a tighter error bound on the estimated sizes of traffic flows and provides probabilistic rather than deterministic guarantees on its accuracy. The probabilistic-based error bound substantially improves the memory consumption of the algorithm. In addition, PLC reduces the rate of false positives of lossy counting and achieves a low estimation error, although slightly higher than that of lossy counting. We compare PLC with state-of-the-art algorithms for finding heavy hitters. Our experiments using real traffic traces find that PLC has 1) between 34.4% and 74% lower memory consumption, 2) between 37.9% and 40.5% fewer false positives than lossy counting, and 3) a small estimation error.",Data streams; Heavy hitters,Data stream; Deterministic guarantee; Efficient algorithm; Error bound; Estimation errors; False positive; Heavy-hitter; Management applications; Memory consumption; Network traffic; Real traffic; State-of-the-art algorithms; Traffic flow; Algorithms; Data communication systems; Traffic surveys; Network management
"Chandra R., Mahajan R., Moscibroda T., Raghavendra R., Bahl P.",5,A case for adapting channel width in wireless networks,2008,118,"Microsoft Corporation, Redmond, WA, United States; University of California Santa Barbara, CA, United States",Microsoft;University of California Santa Barbara,2,USA,1,26,17,"We study a fundamental yet under-explored facet in wireless communication - the width of the spectrum over which transmitters spread their signals, or the channel width. Through detailed measurements in controlled and live environments, and using only commodity 802.11 hardware, we first quantify the impact of channel width on throughput, range, and power consumption. Taken together, our findings make a strong case for wireless systems that adapt channel width. Such adaptation brings unique benefits. For instance, when the throughput required is low, moving to a narrower channel increases range and reduces power consumption; in fixed-width systems, these two quantities are always in conflict. We then present a channel width adaptation algorithm, called SampleWidth, for the base case of two communicating nodes. This algorithm is based on a simple search process that builds on top of existing techniques for adapting modulation. Per specified policy, it can maximize throughput or minimize power consumption. Evaluation using a prototype implementation shows that SampleWidth correctly identities the optimal width under a range of scenarios. In our experiments with mobility, it increases throughput by more than 60% compared to the best fixed-width configuration. Copyright 2008 ACM.",Channel width,Adaptation algorithms; Channel width; Maximize throughputs; Power consumption; Prototype implementations; Search process; Wireless communications; Wireless systems; Convolutional codes; Electric power utilization; Software prototyping; Throughput; Wireless networks; Spread spectrum communication
"Urvoy-Keller G., En-Najjary T., Sorniotti A.",3,Operational comparison of available bandwidth estimation tools,2008,12,"Institut Eurecom, Sophia-Antipolis, France",EURECOM,1,France,1,10,9,"The available bandwidth of a path directly impacts the performance of throughput sensitive applications, e.g., p2p content replication or podcasting. Several tools have been devised to estimate the available bandwidth. The vast majority of these tools follow either the Probe Rate Model (PRM) or the Probe Gap Model (PGM). Lao et al. [6] and Liu et al. [7] have identified biases in the PGM approach that lead to consistent underestimations of the available bandwidth. Those results were obtained under the ideal assumption of stationary cross traffic. In this note, we confirm the existence of these biases experimentally, i.e., for the case of non stationary cross traffic. To do so, we compare one representative of the PRM family, namely Pathload, and one representative of the PGM family, namely Spruce, using long term (several day long) traces collected on an example path. We first propose a methodology to compare operational results of two available bandwidth measurement tools. Based on the sanitized data obtained using the previous methodology, we next show that the biases identified by previous works are clearly observable on the long term, even with non stationary cross traffic. We further uncover the formal link that exists between the work by Liu et al. and the one by Lao et al.",Available bandwidth,Available bandwidth; Available bandwidth estimation; Available bandwidth measurement; Content replication; Cross-traffic; Long term; Nonstationary; Podcasting; Probe gap model; Rate models; Sensitive application; Probes; Telecommunication networks; Bandwidth
"Levin D., Lacurts K., Spring N., Bhattacharjee B.",4,BitTorrent is an auction: Analyzing and improving bittorrent's incentives,2008,92,"University of Maryland, United States",University of Maryland College Park,1,USA,1,30,25,"Incentives play a crucial role in BitTorrent, motivating users to upload to others to achieve fast download times for all peers. Though long believed to be robust to strategic manipulation, recent work has empirically shown that BitTorrent does not provide its users incentive to follow the protocol. We propose an auction-based model to study and improve upon BitTorrent's incentives. The insight behind our model is that BitTorrent uses, not tit-for-tat as widely believed, but an auction to decide which peers to serve. Our model not only captures known, performance-improving strategies, it shapes our thinking toward new, effective strategies. For example, our analysis demonstrates, counter-intuitively, that BitTorrent peers have incentive to intelligently under-report what pieces of the file they have to their neighbors. We implement and evaluate a modification to BitTorrent in which peers reward one another with proportional shares of bandwidth. Within our game-theoretic model, we prove that a proportional-share client is strategy-proof. With experiments on PlanetLab, a local cluster, and live downloads, we show that a proportional-share unchoker yields faster downloads against BitTorrent and BitTyrant clients, and that under-reporting pieces yields prolonged neighbor interest. Copyright 2008 ACM.",Auctions; Bittorrent; Incentive systems; Proportional share; Tit-for-tat,Auctions; Bittorrent; Incentive systems; Proportional share; Tit-for-tat; Commerce; Convolutional codes; Distributed computer systems
"Laoutaris N., Rodriguez P., Massoulie L.",3,ECHOS: Edge capacity hosting overlays of nano data centers,2008,62,"Telefonica Research, Spain; Thomson Research, Spain",Telefonica Research;Thomson Research,2,Spain,1,17,17,"In this paper we propose a radical solution to data hosting and delivery for the Internet of the future. The current data delivery architecture is ""network centric"", with content stored in data centers connected directly to Internet backbones. This approach has multiple drawbacks among which complexity of deploying data centers, power consumption, and lack of scalability are the most critical ones. We propose a totally innovative and orthogonal approach to traditional data centers, through what we call ""nano"" data centers, which are essentially boxes deployed at the edge of the network (e.g., in home gateways, set-top-boxes, etc.) that cooperate in a peer-to-peer manner. Unlike traditional peer-to-peer clients, however, our nano data centers operate under a common management authority, e.g., the ISP who installs and maintains the set-top-boxes, and can thus cooperate more effectively and achieve a higher aggregate performance. Nano data centers are, therefore, better suited for providing guaranteed quality to new emerging applications such as online gaming, interactive IPTV and VoD, and user generated content.",Data center; Peer-to-peer; Set-top-box,Aggregate performance; Current data; Data centers; Edge capacity; Emerging applications; Guaranteed quality; Home gateway; Internet backbone; Internet of the futures; Network-centric; On-line gaming; Peer to peer; Power Consumption; Set top box; User-generated content; Internet; Internet service providers; Satellite communication systems; Video on demand; Peer to peer networks
"Choffnes D.R., Bustamante F.E.",2,Taming the torrent: A practical approach to reducing cross-isp traffic in peer-to-peer systems,2008,169,"Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL, United States",Northwestern University,1,USA,1,37,31,"Peer-to-peer (P2P) systems, which provide a variety of popular services, such as file sharing, video streaming and voice-over-IP, contribute a significant portion of today's Internet traffic. By building overlay networks that are oblivious to the underlying Internet topology and routing, these systems have become one of the greatest traffic-engineering challenges for Internet Service Providers (ISPs) and the source of costly data traffic flows. In an attempt to reduce these operational costs, ISPs have tried to shape, block or otherwise limit P2P traffic, much to the chagrin of their subscribers, who consistently finds ways to eschew these controls or simply switch providers. In this paper, we present the design, deployment and evaluation of an approach to reducing this costly cross-ISP traffic without sacrificing system performance. Our approach recycles network views gathered at low cost from content distribution networks to drive biased neighbor selection without any path monitoring or probing. Using results collected from a deployment in BitTorrent with over 120,000 users in nearly 3,000 networks, we show that our lightweight approach significantly reduces cross-ISP traffic and, over 33% of the time, it selects peers along paths that are within a single autonomous system (AS). Further, we find that our system locates peers along paths that have two orders of magnitude lower latency and 30% lower loss rates than those picked at random, and that these high-quality paths can lead to significant improvements in transfer rates. In challenged settings where peers are overloaded in terms of available bandwidth, our approach provides 31% average download-rate improvement; in environments with large available bandwidth, it increases download rates by 207% on average (and improves median rates by 883%) Copyright 2008 ACM.",Cross-isp traffic; Isp; Measurement reuse; P2p; Peer selection,Cross-isp traffic; Isp; Measurement reuse; P2p; Peer selection; Bandwidth; Client server computer systems; Convolutional codes; Distributed parameter networks; Distribution of goods; Internet; Internet protocols; Internet telephony; Overlay networks; Telecommunication systems; Traffic surveys; Videotex; Voice/data communication systems; Internet service providers
"Wang Y., Keller E., Biskeborn B., Van Der Merwe J., Rexford J.",5,Virtual routers on the move: Live router migration as a network-management primitive,2008,150,"Princeton University, Princeton, NJ, United States; AT and T Labs - Research, Florham Park, NJ, United States",AT and T Labs;Princeton University,2,USA,1,35,22,"The complexity of network management is widely recognized as one of the biggest challenges facing the Internet today. Point solutions for individual problems further increase system complexity while not addressing the underlying causes. In this paper, we argue that many network-management problems stem from the same root cause - -the need to maintain consistency between the physical and logical configuration of the routers. Hence, we propose VROOM (Virtual ROuters On the Move), a new network-management primitive that avoids unnecessary changes to the logical topology by allowing (virtual) routers to freely move from one physical node to another. In addition to simplifying existing network-management tasks like planned maintenance and service deployment, VROOM can also help tackle emerging challenges such as reducing energy consumption. We present the design, implementation, and evaluation of novel migration techniques for virtual routers with either hardware or software data planes. Our evaluation shows that VROOM is transparent to routing protocols and results in no performance impact on the data traffic when a hardware-based data plane is used. Copyright 2008 ACM.",Architecture; Internet; Migration; Routing; Virtual router,Data planes; Data traffics; Logical topologies; Management problems; Management tasks; Migration; Migration techniques; Performance impacts; Physical nodes; Planned maintenances; Reducing energy consumption; Root cause; Routing; Service deployments; Software datum; System complexity; Underlying cause; Virtual router; Convolutional codes; Internet; Internet protocols; Routers; Routing protocols; Network management
"Dischinger M., Haeberlen A., Beschastnikh I., Gummadi K.P., Saroiu S.",5,Satellitelab: Adding heterogeneity to planetary-scale network testbeds,2008,14,"MPI-SWS, Germany; Rice University, United States; University of Washington, United States; University of Toronto, Canada",Rice University;University of Toronto;University of Washington at St. Louis,3,Canada;Germany;USA,3,36,24,"Planetary-scale network testbeds like PlanetLab and RON have become indispensable for evaluating prototypes of distributed systems under realistic Internet conditions. However, current testbeds lack the heterogeneity that characterizes the commercial Internet. For example, most testbed nodes are connected to well-provisioned research networks, whereas most Internet nodes are in edge networks. In this paper, we present the design, implementation, and evaluation of SatelliteLab, a testbed that includes nodes from a diverse set of Internet edge networks. SatelliteLab has a two-tier architecture, in which well-provisioned nodes called planets form the core, and lightweight nodes called satellites connect to the planets from the periphery. The application code of an experiment runs on the planets, whereas the satellites only forward network traffic. Thus, the traffic is subjected to the network conditions of the satellites, which greatly improves the testbed's network heterogeneity. The separation of code execution and traffic forwarding enables satellites to remain lightweight, which lowers the barrier to entry for Internet edge nodes. Our prototype of SatelliteLab uses PlanetLab nodes as planets and a set of 32 volunteered satellites with diverse network characteristics. These satellites consist of desktops, laptops, and handhelds connected to the Internet via cable, DSL, ISDN, Wi-Fi, Bluetooth, and cellular links. We evaluate SatelliteLab's design, and we demonstrate the benefits of evaluating applications on SatelliteLab. Copyright 2008 ACM.",Distributed systems; Internet; Network testbed,Application codes; Cellular links; Code executions; Commercial internets; Distributed systems; EDGE Networks; Edge nodes; Hand-helds; Internet nodes; Network characteristics; Network conditions; Network heterogeneities; Network testbed; Network testbeds; Network traffics; Planetlab; Planetlab nodes; Research networks; Two-tier architectures; Bluetooth; Cellular telephone systems; Convolutional codes; Internet; Laptop computers; Planets; Test facilities; Testbeds; Satellites
"Podlesny M., Gorinsky S.",2,Rd network services: Differentiation through performance incentives,2008,10,"Applied Research Laboratory, Department of Computer Science and Engineering, Washington University in St. Louis, One Brookings Drive, St. Louis, MO 63130-4899, United States",University of Washington at St. Louis,1,USA,1,40,19,"With the Internet offering a single best-effort service, there have been numerous proposals of diversified network services that align better with the divergent needs of different distributed applications. The failure of these innovative architectures to gain wide deployment is primarily due to economic and legacy issues, rather than technical shortcomings. We propose a new paradigm for network service differentiation where design principles account explicitly for the multiplicity of Internet service providers and users as well as their economic interests in environments with partly deployed new services. Our key idea is to base the service differentiation on performance itself, rather than price. The proposed RD (Rate-Delay) services enable a user to choose between a higher transmission rate or low queuing delay at a congested network link. An RD router supports the two services by maintaining two queues per output link and achieves the intended rate-delay differentiation through simple link scheduling and dynamic buffer sizing. After analytically deriving specific rules for RD router operation, we conduct extensive simulations that confirm effectiveness of the RD services geared for incremental deployment in the Internet. Copyright 2008 ACM.",Incremental deployment; Legacy infrastructure; Legacy traffic; Performance incentive; Queuing delay; Service differentiation; Transmission rate,Incremental deployment; Legacy infrastructure; Legacy traffic; Performance incentive; Queuing delay; Service differentiation; Transmission rate; Convolutional codes; Internet service providers; Queueing networks; Queueing theory; Internet
"Andersen D.G., Balakrishnan H., Feamster N., Koponen T., Moon D., Shenker S.",6,Accountable internet protocol (aip),2008,94,"Carnegie Mellon University, United States; MIT, United States; Georgia Tech, United States; ICSI and HIIT; University of California, Berkeley, United States",Carnegie Mellon University;Georgia Tech;MIT;University of California Berkeley,4,USA,1,46,41,"This paper presents AIP (Accountable Internet Protocol), a network architecture that provides accountability as a first-order property. AIP uses a hierarchy of self-certifying addresses, in which each component is derived from the public key of the corresponding entity. We discuss how AIP enables simple solutions to source spoofing, denial-of-service, route hijacking, and route forgery. We also discuss how AIP's design meets the challenges of scaling, key management, and traffic engineering. Copyright 2008 ACM.",Accountability; Address; Internet architecture; Scalability; Security,Accountability; Address; Denial of services; First orders; Internet architecture; Key managements; Public keys; Security; Traffic engineerings; Convolutional codes; Internet; Network architecture; Scalability; Internet protocols
"Zhang Z., Zhang Y., Hu Y.C., Mao Z.M., Bush R.",5,Ispy: Detecting ip prefix hijacking on my own,2008,45,"Purdue University, United States; University of Michigan, United States; IIJ, United States",Purdue University;University of Michigan at Ann Arbor,2,USA,1,37,35,"IP prefix hijacking remains a major threat to the security of the Internet routing system due to a lack of authoritative prefix ownership information. Despite many efforts in designing IP prefix hijack detection schemes, no existing design can satisfy all the critical requirements of a truly effective system: real-time, accurate, light-weight, easily and incrementally deployable, as well as robust in victim notification. In this paper, we present a novel approach that fulfills all these goals by monitoring network reachability from key external transit networks to one's own network through lightweight prefix-owner-based active probing. Using the prefix-owner's view of reachability, our detection system, iSPY, can differentiate between IP prefix hijacking and network failures based on the observation that hijacking is likely to result in topologically more diverse polluted networks and unreachability. Through detailed simulations of Internet routing, 25-day deployment in 88 ASes (108 prefixes), and experiments with hijacking events of our own prefix from multiple locations, we demonstrate that iSPY is accurate with false negative ratio below 0.45% and false positive ratio below 0.17%. Furthermore, iSPY is truly real-time; it can detect hijacking events within a few minutes. Copyright 2008 ACM.",Bgp; Detection; Hijacking; Routing,Active probing; Bgp; Detection; Detection schemes; Detection systems; False negatives; False positives; Hijacking; Internet routing; Light weights; Monitoring networks; Network failures; Prefix hijackings; Reachability; Routing; Transit networks; Convolutional codes; Internet; Internet protocols; Terminology
"Maier G., Sommer R., Dreger H., Feldmann A., Paxson V., S Hneider F.",6,Enriching network security analysis with time travel,2008,42,"TU Berlin, DT Labs, Germany; ICSI, LBNL, United States; Siemens AG Corporate Technology, Germany; ICSI, UC Berkeley, United States",TU Berlin;University of California Berkeley,2,Germany;USA,2,27,21,"In many situations it can be enormously helpful to archive the raw contents of a network traffic stream to disk, to enable later inspection of activity that becomes interesting only in retrospect. We present a Time Machine (TM) for network traffic that provides such a capability. The TM leverages the heavy-tailed nature of network flows to capture nearly all of the likely-interesting traffic while storing only a small fraction of the total volume. An initial proof-of-principle prototype established the forensic value of such an approach, contributing to the investigation of numerous attacks at a site with thousands of users. Based on these experiences, a rearchitected implementation of the system provides flexible, highperformance traffic stream capture, indexing and retrieval, including an interface between the TM and a real-time network intrusion detection system (NIDS). The NIDS controls the TM by dynamically adjusting recording parameters, instructing it to permanently store suspicious activity for offline forensics, and fetching traffic from the past for retrospective analysis. We present a detailed performance evaluation of both stand-alone and joint setups, and report on experiences with running the system live in high-volume environments. Copyright 2008 ACM.",Forensics; Intrusion detection; Packet capture,Forensics; Heavy-tailed; Indexing and retrievals; Network flows; Network security analysis; Network traffics; Offline; Packet capture; Performance evaluations; Proof of principles; Real-time networks; Recording parameters; Retrospective analysis; Stand -alone; Time machines; Time travels; Traffic streams; Computer crime; Concentration (process); Convolutional codes; Internet; Network security; Intrusion detection
"Anand A., Gupta A., Akella A., Seshan S., Shenker S.",5,Packet caches on routers: The implications of universal redundant traffic elimination,2008,85,"UW, Madison, United States; CMU, United States; UC, Berkeley, United States",University of California Berkeley;University of Wisconsin-Madison,2,USA,1,25,17,"Many past systems have explored how to eliminate redundant transfers from network links and improve network efficiency. Several of these systems operate at the application layer, while the more recent systems operate on individual packets. A common aspect of these systems is that they apply to localized settings, e.g. at stub network access links. In this paper, we explore the benefits of deploying packet-level redundant content elimination as a universal primitive on all Internet routers. Such a universal deployment would immediately reduce link loads everywhere. However, we argue that far more significant network-wide benefits can be derived by redesigning network routing protocols to leverage the universal deployment. We develop ""redundancy-aware"" intra- and inter-domain routing algorithms and show that they enable better traffic engineering, reduce link usage costs, and enhance ISPs' responsiveness to traffic variations. In particular, employing redundancy elimination approaches across redundancy-aware routes can lower intra and inter-domain link loads by 10-50%. We also address key challenges that may hinder implementation of redundancy elimination on fast routers. Our current software router implementation can run at OC48 speeds. Copyright 2008 ACM.",Routing; Traffic engineering; Traffic redundancy,Application layers; Inter domains; Inter-domain routing; Internet routers; Link loads; Link usages; Network access; Network efficiencies; Network links; Redundancy eliminations; Redundant contents; Redundant traffics; Routing; Software routers; Traffic engineering; Traffic redundancy; Convolutional codes; Internet protocols; Internet service providers; Quality assurance; Redundancy; Routers; Routing protocols; Routing algorithms
"Guo C., Wu H., Tan K., Shi L., Zhang Y., Lu S.",6,Dcell: A scalable and fault-tolerant network structure for data centers,2008,523,"Microsoft Research Asia, China; Tsinghua University, China; UCLA, United States",Microsoft;Tsinghua University,2,China;USA,2,23,15,"A fundamental challenge in data center networking is how to efficiently interconnect an exponentially increasing number of servers. This paper presents DCell, a novel network structure that has many desirable features for data center networking. DCell is a recursively defined structure, in which a high-level DCell is constructed from many low-level DCells and DCells at the same level are fully connected with one another. DCell scales doubly exponentially as the node degree increases. DCell is fault tolerant since it does not have single point of failure and its distributed fault-tolerant routing protocol performs near shortest-path routing even in the presence of severe link or node failures. DCell also provides higher network capacity than the traditional tree-based structure for various types of services. Furthermore, DCell can be incrementally expanded and a partial DCell provides the same appealing features. Results from theoretical analysis, simulations, and experiments show that DCell is a viable interconnection structure for data centers. Copyright 2008 ACM.",Data center; Fault-tolerance; Network topology; Throughput,Data center; Fault-tolerant; Fault-tolerant networks; Fault-tolerant routing; Higher networks; Interconnection structures; Network structures; Network topology; Node degrees; Node failures; Shortest-path routing; Single points; Tree-based structures; Convolutional codes; Electric network analysis; Electric network topology; Quality assurance; Routing protocols; Satellite communication systems; Fault tolerance
"Karagiannis T., Mortier R., Rowstron A.",3,Network exception handlers: Host-network control in enterprise networks,2008,2,"Microsoft Research, Cambridge, United Kingdom",Microsoft,1,UK,1,21,17,"Enterprise network architecture and management have followed the Internet's design principles despite different requirements and characteristics: enterprise hosts are administered by a single authority, which intrinsically assigns different values to traffic from different business applications. We advocate a new approach where hosts are no longer relegated to the network's periphery, but actively participate in network-related decisions. To enable host participation, network information, such as dynamic network topology and per-link characteristics and costs, is exposed to the hosts, and network administrators specify conditions on the propagated network information that trigger actions to be performed while a condition holds. The combination of a condition and its actions embodies the concept of the network exception handler, defined analogous to a program exception handler. Conceptually, network exception handlers execute on hosts with actions parameterized by network and host state. Network exception handlers allow hosts to participate in network management, traffic engineering and other operational decisions by explicitly controlling host traffic under predefined conditions. This flexibility improves overall performance by allowing efficient use of network resources. We outline several sample network exception handlers, present an architecture to support them, and evaluate them using data collected from our own enterprise network. Copyright 2008 ACM.",Enterprise networks; Management; Network exception handlers,Business applications; Design principles; Dynamic network topologies; Enterprise networks; In networks; In-network managements; Network administrators; Network controls; Network exception handlers; Network informations; Network resources; New approaches; Operational decisions; Parameterized; Traffic engineerings; Architectural design; Convolutional codes; Electric network topology; Network management
"Katti S., Katabi D., Balakrishnan H., Medard M.",4,Symbol-level network coding for wireless mesh networks,2008,114,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,30,26,"This paper describes MIXIT, a system that improves the throughput of wireless mesh networks. MIXIT exploits a basic property of mesh networks: even when no node receives a packet correctly, any given bit is likely to be received by some node correctly. Instead of insisting on forwarding only correct packets, MIXIT routers use physical layer hints to make their best guess about which bits in a corrupted packet are likely to be correct and forward them to the destination. Even though this approach inevitably lets erroneous bits through, we find that it can achieve high throughput without compromising end-to-end reliability. The core component of MIXIT is a novel network code that operates on small groups of bits, called symbols. It allows the nodes to opportunistically route groups of bits to their destination with low overhead. MIXIT's network code also incorporates an end-to-end error correction component that the destination uses to correct any errors that might seep through. We have implemented MIXIT on a software radio platform running the Zigbee radio protocol. Our experiments on a 25-node indoor testbed show that MIXIT has a throughput gain of 2.8x over MORE, a state-of-the-art opportunistic routing scheme, and about 3.9x over traditional routing using the ETX metric. Copyright 2008 ACM.",Cooperative diversity; Network coding; Wireless networks,Basic properties; Cooperative diversity; Core components; Erroneous bits; High throughputs; Low overheads; Mesh networks; Network codes; Network coding; Opportunistic routing; Physical layers; Small groups; Software radio platforms; Test beds; Wireless meshes; Zig bees; Ad hoc networks; Convolutional codes; Routing algorithms; Wireless local area networks (WLAN); Wireless telecommunication systems; Error correction
"Le F., Xie G.G., Pei D., Wang J., Zhang H.",5,Shedding light on the glue logic of the internet routing architecture,2008,14,"Carnegie Mellon University, United States; Naval Postgraduate School, United States; AT and T Labs - Research, United States",AT and T Labs;Carnegie Mellon University;Naval Postgraduate School,3,USA,1,24,18,"Recent studies reveal that the routing structures of operational networks are much more complex than a simple BGP/IGP hierarchy, highlighted by the presence of many distinct instances of routing protocols. However, the glue (how routing protocol instances interact and exchange routes among themselves) is still little understood or studied. For example, although Route Redistribution (RR), the implementation of the glue in router software, has been used in the Internet for more than a decade, it was only recently shown that RR is extremely vulnerable to anomalies similar to the permanent route oscillations in BGP. This paper takes an important step toward understanding how RR is used and how fundamental the role RR plays in practice. We developed a complete model and associated tools for characterizing interconnections between routing instances based on analysis of router configuration data. We analyzed and characterized the RR usage in more than 1600 operational networks. The findings are: (i) RR is indeed widely used; (ii) operators use RR to achieve important design objectives not realizable with existing routing protocols alone; (iii) RR configurations can be very diverse and complex. These empirical discoveries not only confirm that the RR glue constitutes a critical component of the current Internet routing architecture, but also emphasize the urgent need for more research to improve its safety and flexibility to support important design objectives. Copyright 2008 ACM.",Route redistribution; Route selection; Routing glue logic,Associated tools; Critical components; Design objectives; Internet routing; Operational networks; Route redistribution; Route selection; Router configurations; Router softwares; Routing glue logic; Routing structures; Shedding lights; Convolutional codes; Glues; Gluing; Internet; Internet protocols; Routers; Routing protocols
"Huang Y., Fu T.Z.J., Chiu D.-M., Lui J.C.S., Huang C.",5,"Challenges, design and analysis of a large-scale p2p-vod system",2008,282,"Shanghai Synacast Media Tech., China; Chinese University of Hong Kong, Hong Kong",Chinese University of Hong Kong,1,China;Hong Kong,2,22,15,"P2P file downloading and streaming have already become very popular Internet applications. These systems dramatically reduce the server loading, and provide a platform for scalable content distribution, as long as there is interest for the content. P2P-based video-on-demand (P2P-VoD) is a new challenge for the P2P technology. Unlike streaming live content, P2P-VoD has less synchrony in the users sharing video content, therefore it is much more difficult to alleviate the server loading and at the same time maintaining the streaming performance. To compensate, a small storage is contributed by every peer, and new mechanisms for coordinating content replication, content discovery, and peer scheduling are carefully designed. In this paper, we describe and discuss the challenges and the architectural design issues of a large-scale P2P-VoD system based on the experiences of a real system deployed by PPLive. The system is also designed and instrumented with monitoring capability to measure both system and component specific performance metrics (for design improvements) as well as user satisfaction. After analyzing a large amount of collected data, we present a number of results on user behavior, various system performance metrics, including user satisfaction, and discuss what we observe based on the system design. The study of a real life system provides valuable insights for the future development of P2P-VoD technology. Copyright 2008 ACM.",Content distribution; Peer-to-peer/overlay networks; Video-on-demand,Content distribution; Content replications; Design improvements; File downloading; Internet applications; Monitoring capabilities; New mechanisms; P2P-based; Peer-to-peer/overlay networks; Performance metrics; Real systems; Real-life systems; System designs; System-based; User behaviors; User satisfactions; Video contents; Architectural design; Behavioral research; Convolutional codes; Internet; Large scale systems; Visual communication; Video on demand
"Li Y., Qiu L., Zhang Y., Mahajan R., Rozner E.",5,Predictable performance optimization for wireless networks,2008,24,"University of Texas, Austin, United States",University of Texas at Austin,1,USA,1,35,31,"We present a novel approach to optimize the performance of IEEE 802.11-based multi-hop wireless networks. A unique feature of our approach is that it enables an accurate prediction of the resulting throughput of individual flows. At its heart lies a simple yet model of the network that captures interference, traffic, and MAC-induced dependencies. Unless properly accounted for, these dependencies lead to unpredictable behaviors. For instance, we show that even a simple network of two links with one flow is vulnerable to severe performance degradation. We design algorithms that build on this model to optimize the network for fairness and throughput. Given traffic demands as input, these algorithms compute rates at which individual flows must send to meet the objective. Evaluation using a multi-hop wireless testbed as well as simulations show that our approach is very effective. When optimizing for fairness, our methods result in close to perfect fairness. When optimizing for throughput, they lead to 100-200% improvement for UDP traffic and 10-50% for TCP traffic. Copyright 2008 ACM.",Interference; Modeling; Multi-hop wireless networks; Optimization,Accurate predictions; Ieee 802.11; Interference; Modeling; Multi hops; Multi-hop wireless networks; Performance degradations; Performance optimizations; Simple networks; Tcp traffics; Traffic demands; Two links; Udp traffics; Unique features; Wireless testbed; Convolutional codes; Optimization; Standards; Wireless networks
"Bharambe A., Douceur J.R., Lorch J.R., Moscibroda T., Pang J., Seshan S., Zhuang X.",7,"Donnybrook: Enabling large-scale, high-speed, peer-to-peer games",2008,83,"Carnegie Mellon University, Pittsburgh, PA, United States; Microsoft Research, Redmond, WA, United States",Carnegie Mellon University;Microsoft,2,USA,1,42,36,"Without well-provisioned dedicated servers, modern fast-paced action games limit the number of players who can interact simultaneously to 16-32. This is because interacting players must frequently exchange state updates, and high player counts would exceed the bandwidth available to participating machines. In this paper, we describe Donnybrook, a system that enables epic-scale battles without dedicated server resources, even in a fast-paced game with tight latency bounds. It achieves this scalability through two novel components. First, it reduces bandwidth demand by estimating what players are paying attention to, thereby enabling it to reduce the frequency of sending less important state updates. Second, it overcomes resource and interest heterogeneity by disseminating updates via a multicast system designed for the special requirements of games: that they have multiple sources, are latency-sensitive, and have frequent group membership changes. We present user study results using a prototype implementation based on Quake III that show our approach provides a desirable user experience. We also present simulation results that demonstrate Donnybrook's efficacy in enabling battles of up to 900 players. Copyright 2008 ACM.",Computer games; Doppelgängers; Interest sets,Bandwidth demands; Computer games; Dedicated servers; Group memberships; High-speed; Interest sets; Latency bounds; Multicast systems; Multiple sources; Novel components; Peer-to-peer games; Prototype implementations; Simulation results; User experiences; User studies; Convolutional codes; Distributed computer systems; Servers; Software prototyping; Telecommunication systems; Game theory
"Al-Fares M., Loukissas A., Vahdat A.",3,"A scalable, commodity data center network architecture",2008,1237,"Department of Computer Science and Engineering, University of California, San Diego, San Diego, CA 92093-0404, United States",University of California San Diego,1,USA,1,33,19,"Today's data centers may contain tens of thousands of computers with significant aggregate bandwidth requirements. The network architecture typically consists of a tree of routing and switching elements with progressively more specialized and expensive equipment moving up the network hierarchy. Unfortunately, even when deploying the highest-end IP switches/routers, resulting topologies may only support 50% of the aggregate bandwidth available at the edge of the network, while still incurring tremendous cost. Non-uniform bandwidth among data center nodes complicates application design and limits overall system performance. In this paper, we show how to leverage largely commodity Ethernet switches to support the full aggregate bandwidth of clusters consisting of tens of thousands of elements. Similar to how clusters of commodity computers have largely replaced more specialized SMPs and MPPs, we argue that appropriately architected and interconnected commodity switches may deliver more performance at less cost than available from today's higher-end solutions. Our approach requires no modifications to the end host network interface, operating system, or applications; critically, it is fully backward compatible with Ethernet, IP, and TCP. Copyright 2008 ACM.",Data center topology; Equal-cost routing,Application designs; Backward compatible; Bandwidth requirements; Commodity ethernets; Data center topology; Equal-cost routing; Network hierarchies; Network interfaces; Non-uniform; Operating systems; Switching elements; Bandwidth; Convolutional codes; Costs; Ethernet; Internet protocols; Satellite communication systems; Shape memory effect; Topology; Network architecture
"Eriksson B., Barford P., Nowak R.",3,Network discovery from passive measurements,2008,12,"UW, Madison, United States",University of Wisconsin-Madison,1,USA,1,34,31,"Understanding the Internet's structure through empirical measurements is important in the development of new topology generators, new protocols, traffic engineering, and troubleshooting, among other things. While prior studies of Internet topology have been based on active (traceroute-like) measurements, passive measurements of packet traffic offer the possibility of a greatly expanded perspective of Internet structure with much lower impact and management overhead. In this paper we describe a methodology for inferring network structure from passive measurements of IP packet traffic. We describe algorithms that enable 1) traffic sources that share network paths to be clustered accurately without relying on IP address or autonomous system information, 2) topological structure to be inferred accurately with only a small number of active measurements, 3) missing information to be recovered, which is a serious challenge in the use of passive packet measurements. We demonstrate our techniques using a series of simulated topologies and empirical data sets. Our experiments show that the clusters established by our method closely correspond to sources that actually share paths. We also show the trade-offs between selectively applied active probes and the accuracy of the inferred topology between sources. Finally, we characterize the degree to which missing information can be recovered from passive measurements, which further enhances the accuracy of the inferred topologies. Copyright 2008 ACM.",Embedding; Imputation; Inference; Measurement; Topology,Active measurements; Active probes; Autonomous systems; Embedding; Empirical datum; Empirical measurements; Imputation; Inference; Internet structures; Internet topologies; IP address; Ip packets; Missing informations; Network discoveries; Network paths; Network structures; New protocols; Packet measurements; Packet traffics; Passive measurements; Simulated topologies; Topological structures; Traceroute; Traffic engineerings; Traffic sources; Troubleshooting; Cellular radio systems; Convolutional codes; Internet; Internet protocols; Structural optimization; Topology; Measurements
"Xie Y., Yu F., Achan K., Panigrahy R., Hulten G., Osipkov I.",6,Spamming botnets: Signatures and characteristics,2008,134,"Microsoft Research, Silicon Valley, United States; Microsoft Corporation, United States",Microsoft,1,USA,1,25,23,"In this paper, we focus on characterizing spamming botnets by leveraging both spam payload and spam server traffic properties. Towards this goal, we developed a spam signature generation framework called AutoRE to detect botnet-based spam emails and botnet membership. AutoRE does not require pre-classified training data or white lists. Moreover, it outputs high quality regular expression signatures that can detect botnet spam with a low false positive rate. Using a three-month sample of emails from Hotmail, AutoRE successfully identified 7,721 botnet-based spam campaigns together with 340,050 unique botnet host IP addresses. Our in-depth analysis of the identified botnets revealed several interesting findings regarding the degree of email obfuscation, properties of botnet IP addresses, sending patterns, and their correlation with network scanning traffic. We believe these observations are useful information in the design of botnet detection schemes. Copyright 2008 ACM.",Botnet; Regular expression; Signature generation; Spam,Botnet; Botnets; Detection schemes; False positive rates; High qualities; Hotmail; In-depth analysis; IP address; Network scanning; Regular expression; Signature generation; Spam; Spam emails; Training datum; Convolutional codes; Internet; Internet protocols; Packet switching; Spamming
"Xie H., Yang Y.R., Krishnamurthy A., Liu Y.G., Silberschatz A.",5,P4p: Provider portal for applications,2008,268,"Yale University, United States; University of Washington, United States; IBM TJ Watson, United States",IBM;University of Washington at St. Louis;Yale University,3,USA,1,37,30,"As peer-to-peer (P2P) emerges as a major paradigm for scalable network application design, it also exposes significant new challenges in achieving efficient and fair utilization of Internet network resources. Being largely network-oblivious, many P2P applications may lead to inefficient network resource usage and/or low application performance. In this paper, we propose a simple architecture called P4P to allow for more effective cooperative traffic control between applications and network providers. We conducted extensive simulations and real-life experiments on the Internet to demonstrate the feasibility and effectiveness of P4P. Our experiments demonstrated that P4P either improves or maintains the same level of application performance of native P2P applications, while, at the same time, it substantially reduces network provider cost compared with either native or latency-based localized P2P applications. Copyright 2008 ACM.",Network application; Network architecture; P2p,Application performance; Extensive simulations; Network application; Network providers; Network resources; P2p; P2p applications; Peer to peers; Scalable networks; Applications; Convolutional codes; Internet; Network architecture
Henderson T.,1,Sharing is caring - So where are your data?,2008,0,"School of Computer Science, University of St. Andrews, St. Andrews, Fife KY16 9SX, United Kingdom",University of St. Andrews,1,UK,1,27,9,"The networking research community lacks a tradition of sharing experimental data, or using such data for reproducing results. But are we really that bad? Are we worse than researchers in other fields? And if so, how can we do better?.",Data archiving; Experimental method; Measurement; Network data,Data archiving; Experimental data; Experimental methods; Network data; Research communities
"Joseph D.A., Tavakoli A., Stoica I.",3,A policy-aware switching layer for data centers,2008,80,"University of California, Berkeley, United States",University of California Berkeley,1,USA,1,33,22,"Data centers deploy a variety of middleboxes (e.g., firewalls, load balancers and SSL offloaders) to protect, manage and improve the performance of applications and services they run. Since existing networks provide limited support for middleboxes, administrators typically overload path selection mechanisms to coerce traffic through the desired sequences of middleboxes placed on the network path. These ad-hoc practices result in a data center network that is hard to configure and maintain, wastes middlebox resources, and cannot guarantee middlebox traversal under network churn. To address these issues, we propose the policy-aware switching layer or PLayer, a new layer-2 for data centers consisting of inter-connected policy-aware switches or pswitches. Unmodified middleboxes are placed off the network path by plugging them into pswitches. Based on policies specified by administrators, pswitches explicitly forward different types of traffic through different sequences of middleboxes. Experiments using our prototype software pswitches suggest that the PLayer is flexible, uses middleboxes efficiently, and guarantees correct middlebox traversal under churn. Copyright 2008 ACM.",Data center; Indirection; Layer-2; Middlebox; Policies; Switching,Data center; Indirection; Layer-2; Middlebox; Policies; Convolutional codes; Software prototyping; Switching; Satellite communication systems
"Ficara D., Giordano S., Procissi G., Vitucci F., Antichi G., Pietro A.D.",6,An Improved DFA for fast regular expression matching,2008,105,"Department of Information Engineering, University of Pisa, via G.Caruso 16, Pisa, Italy",University of Pisa,1,Italy,1,28,11,"Modern network devices need to perform deep packet inspection at high speed for security and application-specific services. Finite Automata (FAs) are used to implement regular expressions matching, but they require a large amount of memory. Many recent works have proposed improvements to address this issue. This paper presents a new representation for deterministic finite automata (orthogonal to previous solutions), called Delta Finite Automata (δFA), which considerably reduces states and transitions and requires a transition per character only, thus allowing fast matching. Moreover, a new state encoding scheme is proposed and the comprehensive algorithm is tested for use in the packet classification area.",Deep packet inspection; DFA; Intrusion prevention; Packet classification; Regular expressions,Deep packet inspection; DFA; Intrusion prevention; Packet classification; Regular expressions; Finite automata; Packet networks; Pattern matching
"Armitage G., Stewart L., Welzl M., Healy J.",4,An independent H-TCP implementation under FreeBSD 7.0 - Description and observed behaviour,2008,8,"Swinburne University of Technology, Melbourne, Australia; University of Innsbruck, Austria",Swinburne University of Technology;University of Innsbruck,2,Australia;Austria,2,36,32,"A key requirement for IETF recognition of new TCP algorithms is having an independent, interoperable implementation. This paper describes our BSD-licensed implementation of H-TCP within FreeBSD 7.0, publicly available as a dynamically loadable kernel module. Based on our implementation experience we provide a summary description of the H-TCP algorithm to assist other groups build further interoperable implementations. Using data from our live testbed we demonstrate that our version exhibits expected H-TCP behavior, and describe a number of implementation-specific issues that influence H-TCP's dynamic behavior. Finally, we illustrate the actual collateral impact on path latency of using H-TCP instead of NewReno. In particular we illustrate how, compared to NewReno, H-TCP's cwnd growth strategy can cause faster fluctuations in queue sizes at, yet lower median latency through, congestion points. We believe these insights will prove valuable predictors of H-TCP's potential impact if deployed in consumer end-hosts in addition to specialist, high-performance network environments.",Congestion control; FreeBSD; H-TCP; TCP,Congestion points; Dynamic behaviors; FreeBSD; Growth strategy; H-TCP; High performance networks; Loadable kernel modules; NewReno; Potential impacts; Queue size; TCP; Algorithms; Dynamic loads; Transmission control protocol
"Haddadi H., Uhlig S., Moore A., Mortier R., Rio M.",5,Modeling internet topology dynamics,2008,20,"University College London, United Kingdom; Delft University of Technology, Netherlands; University of Cambridge, United Kingdom; Vipadia Ltd., United Kingdom",Delft University of Technology;University College London;University of Cambridge,3,Netherlands;UK,2,21,20,"Despite the large number of papers on network topology modeling and inference, there still exists ambiguity about the real nature of the Internet AS and router level topology. While recent findings have illustrated the inaccuracies in maps inferred from BGP peering and traceroute measurements, existing topology models still produce static topologies, using simplistic assumptions about power law observations and preferential attachment. Today, topology generators are tightly bound to the observed data used to validate them. Given that the actual properties of the Internet topology are not known, topology generators should strive to reproduce the variability that characterizes the evolution of the Internet topology over time. Future topology generators should be able to express the variations in local connectivity that makes today's Internet: peering relationships, internal AS topology and routing policies each changing over time due to failures, maintenance, upgrades and business strategies of the network. Topology generators should capture those dimensions, by allowing a certain level of randomness in the outcome, rather than enforcing structural assumptions as the truths about Internet's evolving structure, which may never be discovered.",Internet; Topology generation,Internet; Business strategy; Internet topologies; Local connectivity; Network topology; Preferential attachments; Routing policies; Structural assumption; Topology generation; Topology
"Turner J., Heller B., Lu J., Crowley P., Kuhns F., Wilson M., DeHart J., Kumar S., Wiseman C., Freestone A., Lockwood J., Zar D.",12,"Supercharging PlanetLab - A high performance, multi-application, overlay network platform",2007,6,"Washington University, United States",University of Washington at St. Louis,1,USA,1,23,12,"In recent years, overlay networks have become an important vehicle for delivering Internet applications. Overlay network nodes are typically implemented using general purpose servers or clusters. We investigate the performance benefits of more integrated architectures, combining general-purpose servers with high performance Network Processor (NP) subsystems. We focus on PlanetLab as our experimental context and report on the design and evaluation of an experimental PlanetLab platform capable of much higher levels of performance than typical system configurations. To make it easier for users to port applications, the system supports a fast path/slow path application structure that facilitates the mapping of the most performance-critical parts of an application onto an NP subsystem, while allowing the more complex control and exception-handling to be implemented within the programmer-friendly environment provided by conventional servers. We report on implementations of two sample applications, an IPv4 router, and a forwarding application for the Internet Indirection Infrastructure. We demonstrate an 80× improvement in packet processing rates and comparable reductions in latency. Copyright 2007 ACM.",Global Environment for Network Innovation (GENI); Network processors; Overlay networks; PlanetLab,Application structure; Design and evaluations; High performance networks; Integrated architecture; Network innovations; Network processor; PlanetLab; System configurations; Complex networks; Internet; Overlay networks
"Katti S., Gollakota S., Katabi D.",3,Embracing wireless interference: Analog network coding,2007,167,"MIT CSAIL, United States",MIT,1,USA,1,35,27,"Traditionally, interference is considered harmful. Wireless networks strive to avoid scheduling multiple transmissions at the same time in order to prevent interference. This paper adopts the opposite approach; it encourages strategically picked senders to interfere. Instead of forwarding packets, routers forward the interfering signals. The destination leverages network-level information to cancel the interference and recover the signal destined to it. The result is analog network coding because it mixes signals not bits. So, what if wireless routers forward signals instead of packets? Theoretically, such an approach doubles the capacity of the canonical 2-way relay network. Surprisingly, it is also practical. We implement our design using software radios and show that it achieves significantly higher throughput than both traditional wireless routing and prior work on wireless network coding. Copyright 2007 ACM.",Cooperative transmission; Network coding; Wireless networks,Analog network coding; Cooperative transmission; Interfering signals; Multiple transmission; Relay network; Wireless interference; Wireless routers; Wireless routing; Routers; Wireless networks; Network coding
"Ballani H., Francis P.",2,CONMan: A step towards network manageability,2007,9,"Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,51,36,"Networks are hard to manage and in spite of all the so called holistic management packages, things are getting worse. We argue that the difficulty of network management can partly be attributed to a fundamental flaw in the existing architecture: protocols expose all their internal details and hence, the complexity of the ever-evolving data plane encumbers the management plane. Guided by this observation, in this paper we explore an alternative approach and propose Complexity Oblivious Network Management (CONMan), a network architecture in which the management interface of data-plane protocols includes minimal protocol-specific information. This restricts the operational complexity of protocols to their implementation and allows the management plane to achieve high level policies in a structured fashion. We built the CON-Man interface of a few protocols and a management tool that can achieve high-level configuration goals based on this interface. Our preliminary experience with applying this tool to real world VPN configuration indicates the architecture's potential to alleviate the difficulty of configuration management. Copyright 2007 ACM.",Abstraction; Configuration; Management,Abstraction; Alternative approach; Configuration; Configuration management; Existing architectures; High level policies; Management interfaces; Operational complexity; Complex networks; Management; Network architecture; Network management; Information management
"Lakshminarayanan K., Caesar M., Rangan M., Anderson T., Shenker S., Stoica I.",6,Achieving convergence-free routing using failure-carrying packets,2007,22,"University of California, Berkeley, United States; University of Washington, United States",University of California Berkeley;University of Washington at St. Louis,2,USA,1,35,31,"Current distributed routing paradigms (such as link-state, distance-vector, and path-vector) involve a convergence process consisting of an iterative exploration of intermediate routes triggered by certain events such as link failures. The convergence process increases router load, introduces outages and transient loops, and slows reaction to failures. We propose a new routing paradigm where the goal is not to reduce the convergence times but rather to eliminate the convergence process completely. To this end, we propose a technique called Failure-Carrying Packets (FCP) that allows data packets to autonomously discover a working path without requiring completely up-to-date state in routers. Our simulations, performed using real-world failure traces and Rocketfuel topologies, show that: (a) the overhead of FCP is very low, (b) unlike traditional link-state routing (such as OSPF), FCP can provide both low lossrate as well as low control overhead, (c) compared to prior work in backup path precomputations, FCP provides better routing guarantees under failures despite maintaining lesser state at the routers. Copyright 2007 ACM.",Convergence; Internet routing; Protocols,Control overhead; Convergence; Convergence process; Convergence time; Distributed routing; Internet routing; Link-state routing; Routing paradigm; Internet protocols; Iterative methods; Network protocols; Routers
"Bhandarkar S., Reddy A.L.N., Zhang Y., Loguinov D.",4,Emulating AQM from end hosts,2007,4,"Texas A and M University, College Station, TX 77843, United States; Currently with Motorola Inc., Austin, TX, United States",Motorola;Texas A and M University,2,USA,1,32,26,"In this paper, we show that end-host based congestion prediction is more accurate than previously characterized. However, it may not be possible to entirely eliminate the uncertainties in congestion prediction. To address these uncertainties, we propose Probabilistic Early Response TCP (PERT). PERT emulates the behavior of AQM/ECN, in the congestion response function of end-hosts. We present fluid-flow analysis of PERT/RED and PERT/PI, versions of PERT that emulate router-based RED and PI controllers. Our analysis shows that PERT/RED has better stability behavior than router-based RED. We also present results from ns-2 simulations to show the practical feasibility of PERT. The scheme presented here is general and can be used for emulating other AQM algorithms. Copyright 2007 ACM.",Congestion avoidance; Delay-based congestion response; Early congestion response,AQM algorithms; Congestion avoidance; Congestion prediction; Congestion response; Fluid-flow; NS-2 simulations; PI Controller; Stability behavior; Communication
"Oliveira R., Zhang B., Zhang L.",3,Observing the evolution of internet AS topology,2007,15,"University of California, Los Angeles, CA, United States; University of Arizona, Tucson, AZ, United States",University of Arizona;University of California Los Angeles,2,USA,1,34,27,"Characterizing the evolution of Internet topology is important to our understanding of the Internet architecture and its interplay with technical, economic and social forces. A major challenge in obtaining empirical data on topology evolution is to identify real topology changes from the observed topology changes, since the latter can be due to either topology changes or transient routing dynamics. In this paper, we formulate the topology liveness problem and propose a solution based on the analysis of BGP data. We find that the impact of transient routing dynamics on topology observation decreases exponentially over time, and that the real topology dynamics consist of a constant-rate birth process and a constant-rate death process. Our model enables us to infer real topology changes from observation data with a given confidence level. We demonstrate the usefulness of the model by applying it to three applications: providing more accurate views of the topology, evaluating theoretical evolution models, and empirically characterizing the trends of topology evolution. We find that customer networks and provider networks have distinct evolution trends, which can provide an important input to the design of future Internet routing architecture. Copyright 2007 ACM.",Internet topology; Topology evolution,Confidence levels; Customer networks; Evolution models; Internet architecture; Internet topologies; Routing dynamics; Topology evolution; Topology observation; Dynamics; Internet; Network architecture; Topology
"Bonfiglio D., Mellia M., Meo M., Rossi D., Tofanelli P.",5,Revealing skype traffic: When randomness plays with you,2007,36,"Politecnico di Torino, Dipartimento di Elettronica, Italy; ENST Télécom Paris, Informatique et Réseaux, Italy; Motorola Inc., Torino, Italy",Motorola;Politecnico di Torino,2,Italy,1,17,12,"Skype is a very popular VoIP software which has recently attracted the attention of the research community and network operators. Following a closed source and proprietary design, Skype protocols and algorithms are unknown. Moreover, strong encryption mechanisms are adopted by Skype, making it very difficult to even glimpse its presence from a traffic aggregate. In this paper, we propose a framework based on two complementary techniques to reveal Skype traffic in real time. The first approach, based on Pearson's Chi-Square test and agnostic to VoIP-related traffic characteristics, is used to detect Skype's fingerprint from the packet framing structure, exploiting the randomness introduced at the bit level by the encryption process. Conversely, the second approach is based on a stochastic characterization of Skype traffic in terms of packet arrival rate and packet length, which are used as features of a decision process based on Naive Bayesian Classifiers. In order to assess the effectiveness of the above techniques, we develop an off-line cross-checking heuristic based on deep-packet inspection and flow correlation, which is interesting per se. This heuristic allows us to quantify the amount of false negatives and false positives gathered by means of the two proposed approaches: results obtained from measurements in different networks show that the technique is very effective in identifying Skype traffic. While both Bayesian classifier and packet inspection techniques are commonly used, the idea of leveraging on randomness to reveal traffic is novel. We adopt this to identify Skype traffic, but the same methodology can be applied to other classification problems as well. Copyright 2007 ACM.",Deep packet inspection; Naïve Bayesian classification; Passive measurement; Pearson chi-square test; Traffic identification,Bayesian classification; Chi-square tests; Deep packet inspection; Passive measurements; Traffic identification; Cryptography; Internet telephony; Statistical tests; Voice/data communication systems; Random processes
"Guo S., Falaki M.H., Oliver E.A., Rahman S.U., Seth A., Zaharia M.A., Keshav S.",7,Very low-cost internet access using KioskNet,2007,48,"David R. Cheriton School of Computer Science, University of Waterloo, Canada",University of Waterloo,1,Canada,1,16,14,"Rural Internet kiosks in developing regions can cost-effectively provide communication and e-governance services to the poorest sections of society. A variety of technical and nontechnical issues have caused most kiosk deployments to be economically unsustainable [1]. KioskNet addresses the key technical problems underlying kiosk failure by using robust 'mechanical backhaul' for connectivity [2], and by using low-cost and reliable kiosk-controllers to support services delivered from one or more recycled PCs. KioskNet also addresses related issues such as security, user management, and log collection. In this paper, we describe the KioskNet system, outlining its hardware, software, and security architecture. We describe a pilot deployment, and how we used lessons from this deployment to re-design our initial prototype.",Delay tolerant networks; Low cost; Mechanical backhaul; Rural communication; System design,Developing regions; Internet access; Low costs; Mechanical backhaul; Rural communications; Security Architecture; Support services; User management; Communication; Delay tolerant networks; Internet; Systems analysis; Telemedicine; Costs
"Balasubramanian A., Levine B.N., Venkataramani A.",3,DTN routing as a resource allocation problem,2007,162,"Dept. of Computer Science, University of Massachusetts Amherst, Amherst, MA, United States",University of Massachusetts Amherst,1,USA,1,37,32,"Routing protocols for disruption-tolerant networks (DTNs) use a variety of mechanisms, including discovering the meeting probabilities among nodes, packet replication, and network coding. The primary focus of these mechanisms is to increase the likelihood of finding a path with limited information, and so these approaches have only an incidental effect on routing such metrics as maximum or average delivery delay. In this paper, we present rapid, an intentional DTN routing protocol that can optimize a specific routing metric such as the worst-case delivery delay or the fraction of packets that are delivered within a deadline. The key insight is to treat DTN routing as a resource allocation problem that translates the routing metric into per-packet utilities which determine how packets should be replicated in the system. We evaluate rapid rigorously through a prototype deployed over a vehicular DTN testbed of 40 buses and simulations based on real traces. To our knowledge, this is the first paper to report on a routing protocol deployed on a real DTN at this scale. Our results suggest that rapid significantly outperforms existing routing protocols for several metrics. We also show empirically that for small loads RAPID is within 10% of the optimal performance. Copyright 2007 ACM.",Deployment; DTN; Mobility; Routing; Utility,Deployment; Disruption tolerant networks; DTN; Optimal performance; Packet replications; Resource allocation problem; Routing; Utility; Carrier mobility; Maximum likelihood; Optimization; Resource allocation; Routing protocols; Delay tolerant networks
"Mudigonda J., Vin H.M., Keckler S.W.",3,Reconciling performance and programmability in networking systems,2007,1,"Department of Computer Sciences, University of Texas, Austin TX 78712, United States; Hewlett-Packard Labs, Palo Alto CA, United States",University of Texas at Austin,1,USA,1,38,24,"Challenges in addressing the memory bottleneck have made it difficult to design a packet processing platform that simultaneously achieves both ease-of-programming and high performance. Today's commercial processors support two architectural mechanisms-namely, hardware multithreading and caching-to overcome the memory bottleneck. The configurations of these mechanisms (e.g., cache capacity, number of threads per processor core) are fixed at processor-design time. The relative effectiveness of these mechanisms, however, varies significantly with application, traffic, and system characteristics. Thus, programmers often struggle to achieve high performance from a processor that is not well-suited to a particular deployment. To address this challenge, we first make a case for, and then develop a malleable processor architecture that facilitates the dynamic reconfiguration of cache capacity and number of threads to best-suit the needs of each deployment. We then present an algorithm that can determine the optimal thread-cache balance at run-time. The combination of these two allows us to simultaneously achieve the goals of ease-of-programming and high performance. We demonstrate that our processor outperforms a processor similar to Intel's IXP2800-a state-of-the-art commercial Network Processor-in about 89% of the deployments we consider. Further, in about 30% of the deployments our platform improves the throughput by as much as 300%. Copyright 2007 ACM.",Data cache; Memory bottleneck; Multithreading; Packet processing; Processor architectures; Reconfigurable architectures; Routers,Data caches; Memory bottleneck; Multi-threading; Packet processing; Processor architectures; Dynamic models; Network architecture; Packet networks; Reconfigurable architectures; Routers; Multitasking
"Ballani H., Francis P., Zhang X.",3,A study of prefix hijacking and interception in the internet,2007,52,"Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,53,49,"There have been many incidents of prefix hijacking in the Internet. The hijacking AS can blackhole the hijacked traffic. Alternatively, it can transparently intercept the hijacked traffic by forwarding it onto the owner. This paper presents a study of such prefix hijacking and interception with the following contributions: (1). We present a methodology for prefix interception, (2). We estimate the fraction of traffic to any prefix that can be hijacked and intercepted in the Internet today, (3). The interception methodology is implemented and used to intercept real traffic to our prefix, (4). We conduct a detailed study to detect ongoing prefix interception. We find that: Our hijacking estimates are in line with the impact of past hijacking incidents and show that ASes higher up in the routing hierarchy can hijack a significant amount of traffic to any prefix, including popular prefixes. A less apparent result is that the same holds for prefix interception too. Further, our implementation shows that intercepting traffic to a prefix in the Internet is almost as simple as hijacking it. Finally, while we fail to detect ongoing prefix interception, the detection exercise highlights some of the challenges posed by the prefix interception problem. Copyright 2007 ACM.",BGP; Hijacking; Interception; Routing,BGP; Black holes; Hijacking; Interception problem; Prefix hijacking; Real traffic; Routing; Communication; Satellite interception; Internet
Ford B.,1,Structured streams: A new transport abstraction,2007,9,"Massachusetts Institute of Technology, United States",MIT,1,USA,1,56,30,"Internet applications currently have a choice between stream and datagram transport abstractions. Datagrams efficiently support small transactions and streams are suited for long-running conversations, but neither abstraction adequately supports applications like HTTP that exhibit a mixture of transaction sizes, or applications like FTP and SIP that use multiple transport instances. Structured Stream Transport (SST) enhances the traditional stream abstraction with a hierarchical hereditary structure, allowing applications to create lightweight child streams from any existing stream. Unlike TCP streams, these lightweight streams incur neither 3-way handshaking delays on startup nor TIME-WAIT periods on close. Each stream offers independent data transfer and flow control, allowing different transactions to proceed in parallel without head-of-line blocking, but all streams share one congestion control context. SST supports both reliable and best-effort delivery in a way that semantically unifies datagrams with streams and solves the classic ""large datagram"" problem, where a datagram's loss probability increases exponentially with fragment count. Finally, an application can prioritize its streams relative to each other and adjust priorities dynamically through out-of-band signaling. A user-space prototype shows that SST is TCP-friendly to within 2%, and performs comparably to a user-space TCP and to within 10% of kernel TCP on a WiFi network. Copyright 2007 ACM.",Best-effort; Datagram; Fairness; Mobility; Multimedia; Reliable; SST; Stream; TCP; Transport protocols; Web transport,Best-effort; Datagrams; Fairness; Multimedia; Reliable; SST; Stream; TCP; Transport protocols; Web transport; Abstracting; Carrier mobility; Data transfer; HTTP; Wi-Fi; Transmission control protocol
"Wang H., Yang Y.R., Liu P.H., Wang J., Gerber A., Greenberg A.",6,Reliability as an interdomain service,2007,1,"AT and T Labs - Research, United States; Microsoft Research, United States; Yale University, United States",AT and T Labs;Microsoft;Yale University,3,USA,1,43,37,"Reliability is a critical requirement of the Internet. The availability and resilience of the Internet under failures can have significant global effects. However, in the current Internet routing architecture, achieving the high level of reliability demanded by many mission-critical activities can be costly. In this paper, we first propose a novel solution framework called reliability as an interdomain service (REIN) that can be incrementally deployed in the Internet and may improve the redundancy of IP networks at low cost. We then present robust algorithms to efficiently utilize network redundancy to improve reliability. We use real IP network topologies and traffic traces to demonstrate the effectiveness of our framework and algorithms. Copyright 2007 ACM.",Fast rerouting; Reliability; Traffic engineering,Fast rerouting; Framework and algorithms; Global effects; Internet routing; Network redundancy; Robust algorithm; Traffic Engineering; Traffic traces; Algorithms; Electric network topology; Internet; Reliability; Redundancy
"Douceur J.R., Moscibroda T.",2,Lottery trees: Motivational deployment of networked systems,2007,7,"Microsoft Research, Redmond WA 98052, United States",Microsoft,1,USA,1,36,28,"We address a critical deployment issue for network systems, namely motivating people to install and run a distributed service. This work is aimed primarily at peer-to-peer systems, in which the decision and effort to install a service falls to individuals rather than to a central planner. This problem is relevant for bootstrapping systems that rely on the network effect, wherein the benefits are not felt until deployment reaches a significant scale, and also for deploying asymmetric systems, wherein the set of contributors is different than the set of beneficiaries. Our solution is the lottery tree (lottree), a mechanism that probabilistically encourages both participation in the system and also solicitation of new participants. We define the lottree mechanism and formally state seven properties that encourage contribution, solicitation, and fair play. We then present the Pachira lottree scheme, which satisfies five of these seven properties, and we prove this to be a maximal satisfiable subset. Using simulation, we determine optimal parameters for the Pachira lot-tree scheme, and we determine how to configure a lottree system for achieving various deployment scales based on expected installation effort. We also present extensive sensitivity analyses, which bolster the generality of our conclusions. Copyright 2007 ACM.",Bootstrapping; Deployment; Desiderata; Impossibility results; Incentive systems; Lotteries; Networked systems; Prospect theory,Bootstrapping; Deployment; Desiderata; Impossibility results; Incentive systems; Lotteries; Networked systems; Prospect theory; Distributed computer systems; Forestry
"Steiner M., En-Najjary T., Biersack E.W.",3,Exploiting KAD: Possible uses and misuses,2007,72,"Institut Eurecom, Sophia-Antipolis, France",EURECOM,1,France,1,28,22,"Peer-to-peer systems have seen a tremendous growth in the last few years and peer-to-peer traffic makes a major fraction of the total traffic seen in the Internet. The dominating application for peer-to-peer is file sharing. Some of the most popular peer-to-peer systems for file sharing have been Napster, FastTrack, BitTorrent, and eDonkey, each one counting a million or more users at their peak time. We got interested in KAD, since it is the only DHT that has been part of very popular peer-to-peer system with several million simultaneous users. As we have been studying KAD over the course of the last 18 months we have been both, fascinated and frightened by the possibilities KAD offers. Mounting a Sybil attack is very easy in KAD and allows to compromise the privacy of KAD users, to compromise the correct operation of the key lookup and to mount DDOS with very little resources. In this paper, we will relate some of our findings and point out how KAD can be used and misused.",Distributed hash table; Peer-to-peer system; Sybil attack,Bit torrents; Distributed Hash Table; Fast tracks; File Sharing; Peer to peer; Peer-to-Peer system; Peer-to-peer traffic; Sybil attack; Peer to peer networks; Distributed computer systems
"Saif U., Chudhary A.L., Butt S., Butt N.F.",4,Poor man's broadband: Peer-to-peer dialup networking,2007,6,"LUMS, Computer Science Department, Pakistan",LUMS Pakistan,1,Pakistan,1,15,8,"In this paper we present a peer-to-peer dialup architecture for accelerated ""Internet access"" in the developing world. Our proposed architecture provides a mechanism for multiplexing the scarce and expensive international Internet bandwidth over higher bandwidth p2p dialup connections within a developing country. Our system combines a number of architectural components, such as incentive-driven p2p data transfer, intelligent connection interleaving and content-prefetching. This paper presents a detailed design, implementation and evaluation of our dialup p2p data transfer architecture inspired by Bittorrent.",Bandwidth; Bittorrent; Developing world ICT; Dialup; Peer-to-peer,Architectural components; Bit torrents; Developing world; Dial-up; Dialup connection; Internet access; Peer to peer; Proposed architectures; Architecture; Bandwidth; Data transfer; Developing countries; Internet; Distributed computer systems
"Kaafar M.A., Mathy L., Barakat C., Salamatian K., Turletti T., Dabbous W.",6,Securing internet coordinate embedding systems,2007,2,"INRIA, Sophia Antipolis, France; Lancaster University, United Kingdom; LIP6, FR and EPFL, China","EPFL,Switzerland;INRIA;Lancaster University",3,China;France;UK,3,24,16,"This paper addresses the issue of the security of Internet Coordinate Systems, by proposing a general method for malicious behavior detection during coordinate computations. We first show that the dynamics of a node, in a coordinate system without abnormal or malicious behavior, can be modeled by a Linear State Space model and tracked by a Kalman filter. Then we show that the obtained model can be generalized in the sense that the parameters of a filter calibrated at a node can be used effectively to model and predict the dynamic behavior at another node, as long as the two nodes are not too far apart in the network. This leads to the proposal of a Surveyor infrastructure: Surveyor nodes are trusted, honest nodes that use each other exclusively to position themselves in the coordinate space, and are therefore immune to malicious behavior in the system. During their own coordinate embedding, other nodes can then use the filter parameters of a nearby Surveyor as a representation of normal, clean system behavior to detect and filter out abnormal or malicious activity. A combination of simulations and PlanetLab experiments are used to demonstrate the validity, generality, and effectiveness of the proposed approach for two representative coordinate embedding systems, namely Vivaldi and NPS. Copyright 2007 ACM.",Internet Coordinates-embedding systems; Kalman filter; Malicious behavior detection; Network positioning systems; Security,Co-ordinate system; Dynamic behaviors; Internet Coordinate Systems; Linear state space model; Malicious activities; Malicious behavior; Network positioning systems; Security; Kalman filters; State space methods; Surveying; Internet
"Chachulski S., Jennings M., Katti S., Katabi D.",4,Trading structure for randomness in wireless opportunistic routing,2007,94,"MIT CSAIL, United States",MIT,1,USA,1,36,33,"Opportunistic routing is a recent technique that achieves high throughput in the face of lossy wireless links. The current opportunistic routing protocol, ExOR, ties the MAC with routing, imposing a strict schedule on routers' access to the medium. Although the scheduler delivers opportunistic gains, it misses some of the inherent features of the 802.11 MAC. For example, it prevents spatial reuse and thus may underutilize the wireless medium. It also eliminates the layering abstraction, making the protocol less amenable to extensions to alternate traffic types such as multicast. This paper presents MORE, a MAC-independent opportunistic routing protocol. MORE randomly mixes packets before forwarding them. This randomness ensures that routers that hear the same transmission do not forward the same packets. Thus, MORE needs no special scheduler to coordinate routers and can run directly on top of 802.11. Experimental results from a 20-node wireless testbed show that MORE's median unicast throughput is 22% higher than ExOR, and the gains rise to 45% over ExOR when there is a chance of spatial reuse. For multicast, MORE's gains increase with the number of destinations, and are 35-200% greater than ExOR. Copyright 2007 ACM.",Network coding; Wireless networks,802.11 MAC; High throughput; Multicasts; Opportunistic routing; Spatial reuse; Wireless link; Wireless medium; Wireless testbed; Multicasting; Network coding; Routing protocols; Scheduling; Wireless networks; Random processes
"Lan K.-C., Wang Z., Hassan M., Moors T., Berriman R., Libman L., Ott M., Landfeldt B., Zaidi Z.",9,Experiences in deploying a wireless mesh network testbed for traffic control,2007,14,"National Cheng Kung University, Taiwan; University of New South Wales, Australia; National ICT Australia, Australia",National Cheng Kung University;University of New South Wales,2,Australia;Taiwan,2,17,10,"Wireless mesh networks (WMN) have attracted considerable interest in recent years as a convenient, flexible and low-cost alternative to wired communication infrastructures in many contexts. However, the great majority of research on metropolitan-scale WMN has been centered around maximization of available bandwidth, suitable for non-real-time applications such as Internet access for the general public. On the other hand, the suitability of WMN for mission-critical infrastructure applications remains by and large unknown, as protocols typically employed in WMN are, for the most part, not designed for real-time communications. In this paper, we describe the Smart Transport and Roads Communications (STaRComm) project at National ICT Australia (NICTA), which sets a goal of designing a wireless mesh network architecture to solve the communication needs of the traffic control system in Sydney, Australia. This system, known as SCATS (Sydney Coordinated Adaptive Traffic System) and used in over 100 cities around the world, connects a hierarchy of several thousand devices - from individual traffic light controllers to regional computers and the central Traffic Management Centre (TMC) - and places stringent requirements on the reliability and latency of the data exchanges. We discuss our experience in the deployment of an initial testbed consisting of 7 mesh nodes placed at intersections with traffic lights, and share the results and insights learned from our measurements and initial trials in the process.",Deployment; Traffic control; Wireless mesh network,Available bandwidth; Deployment; Individual traffic; Infrastructure applications; Real-time communication; Stringent requirement; Wired communication; Wireless mesh network testbed; Adaptive control systems; Electronic data interchange; Information management; Internet protocols; Network architecture; Street traffic control; Testbeds; Traffic control; Wireless mesh networks (WMN); MESH networking
"Guha S., Francis P.",2,An end-middle-end approach to connection establishment,2007,5,"Cornell University, Ithaca, United States",Cornell University,1,USA,1,64,52,"We argue that the current model for flow establishment in the Internet: DNS Names, IP addresses, and transport ports, is inadequate due to problems that go beyond the small IPv4 address space and resulting NAT boxes. Even where global addresses exist, firewalls cannot glean enough information about a flow from packet headers, and so often err, typically by being over-conservative: disallowing flows that might otherwise be allowed. This paper presents a novel architecture, protocol design, and implementation, for flow establishment in the Internet. The architecture, called NUTSS, takes into account the combined policies of endpoints and network providers. While NUTSS borrows liberally from other proposals (URI-like naming, signaling to manage ephemeral IPv4 or IPv6 data flows), NUTSS is unique in that it couples overlay signaling with data-path signaling. NUTSS requires no changes to existing network protocols, and combined with recent NAT traversal techniques, works with IPv4 and existing NAT/firewalls. This paper describes NUTSS and shows how it satisfies a wide range of ""end-middle-end"" network requirements, including access control, middlebox steering, multi-homing, mobility, and protocol negotiation. Copyright 2007 ACM.",End-middle-end; NUTSS; Off-path; On-path; Signaling,End-middle-end; Network provider; Network requirements; Novel architecture; NUTSS; Off-path; On-path; Protocol design; Access control; Internet; Network architecture; Network protocols; Signaling; Internet protocols
"Bahl P., Chandra R., Greenberg A., Kandula S., Maltz D.A., Zhang M.",6,Towards highly reliable enterprise network services via inference of multi-level dependencies,2007,47,"Microsoft Research, United States",Microsoft,1,USA,1,21,14,"Localizing the sources of performance problems in large enterprise networks is extremely challenging. Dependencies are numerous, complex and inherently multi-level, spanning hardware and software components across the network and the computing infrastructure. To exploit these dependencies for fast, accurate problem localization, we introduce an Inference Graph model, which is well-adapted to user-perceptible problems rooted in conditions giving rise to both partial service degradation and hard faults. Further, we introduce the Sherlock system to discover Inference Graphs in the operational enterprise, infer critical attributes, and then leverage the result to automatically detect and localize problems. To illuminate strengths and limitations of the approach, we provide results from a prototype deployment in a large enterprise network, as well as from testbed emulations and simulations. In particular, we find that taking into account multi-level structure leads to a 30% improvement in fault localization, as compared to two-level approaches. Copyright 2007 ACM.",Dependencies; Fault localization; Network & service management; Probabilistic inference,Computing infrastructures; Dependencies; Fault localization; Hardware and software components; Multi-level structures; Performance problems; Probabilistic inference; Service management; Complex networks; Computer software selection and evaluation; Industry; Computer simulation
"Parno B., Wendlandt D., Shi E., Perrig A., Maggs B., Hu Y.-C.",6,Portcullis: Protecting connection setup from denial-of-capability attacks,2007,20,"Carnegie Mellon University, United States; Carnegie Mellon University, Akamai Technologies, United States; University of Illinois, Urbana-Champaign, United States",Akamai Technologies;Carnegie Mellon University;UIUC,3,USA,1,32,28,"Systems using capabilities to provide preferential service to selected flows have been proposed as a defense against large-scale network denial-of-service attacks. While these systems offer strong protection for established network flows, the Denial-of-Capability (DoC) attack, which prevents new capability-setup packets from reaching the destination, limits the value of these systems. Portcullis mitigates DoC attacks by allocating scarce link bandwidth for connection establishment packets based on per-computation fairness. We prove that a legitimate sender can establish a capability with high probability regardless of an attacker's resources or strategy and that no system can improve on our guarantee. We simulate full and partial deployments of Portcullis on an Internetscale topology to confirm our theoretical results and demonstrate the substantial benefits of using per-computation fairness. Copyright 2007 ACM.",Network capability; Per-computation fairness,Denial of capabilities; Denial of service attacks; Established networks; Large-scale network; Network capability; Partial deployment; Per-computation fairness; Theoretical result; Communication
"Salyers D., Jiang Y., Striegel A., Poellabauer C.",4,JumboGen: Dynamic jumbo frame generation for network performance scalability,2007,4,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556, United States",University of Notre Dame,1,USA,1,26,22,"Network line speeds have increased at a significant rate. Unfortunately, network performance has not been able to keep pace with increases in line speed. This is due to the majority of packets being less than or equal to 100 bytes in addition to network routers not being able to scale well with the increased number of packets. In this paper we present our solution, JumboGen, an approach that will allow for a higher utilization of larger packet sizes on a domain-wise basis. Through simulations and experimentation, we show that the dynamic creation of jumbo packets decreases the number of packets processed by core routers and does not have an adverse impact on link utilization or fairness. The final result of JumboGen is a reduction in the number of packets seen by core routers which directly improves network scalability.",Dynamic jumbo frames; JumboGen; Router scalability,Core routers; JumboGen; Link utilization; Network routers; Network scalability; Packet size; Performance scalability; Network performance; Scalability; Routers
"Papadopoulos F., Psounis K.",2,Efficient identification of uncongested internet links for topology downscaling,2007,6,"University of Southern California, United States",University of Southern California,1,USA,1,44,29,"It has been recently suggested that uncongested links could be completely ignored when evaluating Internet's performance. In particular, based on the observation that only the congested links along the path of each flow introduce sizable queueing delays and dependencies among flows, it has been shown that one can infer the performance of the larger Internet by creating and observing a suitably scaled-down replica, consisting of the congested links only. Given that the majority of Internet links are uncongested, it has been demonstrated that this approach can be used to greatly simplify and expedite performance prediction. However, an important open problem, directly related to the practicability of such an approach, is whether there exist efficient and scalable ways for identifying uncongested links, in large and complex Internet-like networks. Of course, such a question is not only very important for scaling down Internet's topology, but also in many other contexts, e.g. such as in traffic engineering and capacity planning. In this paper we present simple rules that can be used to efficiently identify uncongested Internet links. In particular, we first identify scenarios under which one can easily deduce whether a link is uncongested by inspecting the network topology. Then, we identify scenarios in which this is not possible, and propose an efficient methodology, based on the large deviations theory and flow-level statistics, to approximate the queue length distribution, and in turn, to deduce the congestion level of a link. We also demonstrate how simple commonly used metrics, such as the link utilization, can be quite misleading in classifying an Internet link.",Topology downscaling; Uncongested link identification,Capacity planning; Down-scaling; Large deviations theory; Link utilization; Network topology; Performance prediction; Queue length distribution; Traffic Engineering; Complex networks; Electric network topology; Queueing networks; Topology; Internet
"Shen Y., Cai Y., Xu X.",3,A shortest-path-based topology control algorithm in wireless multihop networks,2007,25,"Dept. of Computer Science and Engineering, Shanghai Jiaotong Univ., Shanghai 200240, China; Dept. of Automation, Shanghai Jiaotong Univ., Shanghai 200240, China",Shanghai Jiaotong University,1,China,1,11,10,"In this paper, we present a shortest-path-based algorithm, called local shortest path(LSP), for topology control in wireless multihop networks. In this algorithm, each node locally computes the shortest paths connecting itself to nearby nodes based on some link weight function, and then it selects all the second nodes on the shortest paths as its logical neighbors in the final topology. Any energy model can be employed in LSP to design the link weight function whose value represents the power consumption required in the transmission along a link. We analytically prove that such a simple algorithm maintains network connectivity and guarantees that the minimal energy path between any two nodes is preserved in the final topology. Simulation results show that LSP can reduce the energy consumption, especially in heterogenous networks.",Connectivity; Minimal energy path; Topology control; Wireless multihop network,Connectivity; Heterogenous network; Minimal energy; Network connectivity; SIMPLE algorithm; Topology control; Topology control algorithms; Wireless multi-hop network; Energy utilization; Graph theory; Heterogeneous networks; Wireless ad hoc networks; Wireless networks; Algorithms
"Jamieson K., Balakrishnan H.",2,PPR: Partial packet recovery for wireless networks,2007,33,"MIT Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,35,18,"Bit errors occur in wireless communication when interference or noise overcomes the coded and modulated transmission. Current wireless protocols may use forward error correction (FEC) to correct some small number of bit errors, but generally retransmit the whole packet if the FEC is insufficient. We observe that current wireless mesh network protocols retransmit a number of packets and that most of these retransmissions end up sending bits that have already been received multiple times, wasting network capacity. To overcome this inefficiency, we develop, implement, and evaluate a partial packet recovery (PPR) system. PPR incorporates two new ideas: (1) SoftPHY, an expanded physical layer (PHY) interface that provides PHY-independent hints to higher layers about the PHY's confidence in each bit it decodes, and (2) a postamble scheme to recover data even when a packet preamble is corrupted and not decodable at the receiver. Finally, we present PP-ARQ, an asynchronous link-layer ARQ protocol built on PPR that allows a receiver to compactly encode a request for retransmission of only those bits in a packet that are likely in error. Our experimental results from a 31-node Zigbee (802.15.4) testbed that includes Telos motes with 2.4 GHz Chipcon radios and GNU Radio nodes implementing the 802.15.4 standard show that PP-ARQ increases end-to-end capacity by a factor of 2× under moderate load. Copyright 2007 ACM.",802.11; ARQ; Layering; Synchronization; Wireless; Zigbee,802.11; ARQ; End-to-end capacity; Layering; Network Capacity; Retransmissions; Wireless communications; Wireless protocol; Network layers; Network protocols; Radio; Synchronization; Wireless networks; Wireless telecommunication systems; Zigbee; Recovery
"Koponen T., Chawla M., Chun B.-G., Ermolinskiy A., Kim K.H., Shenker S., Stoica I.",7,A data-oriented (and Beyond) network architecture,2007,250,"International Computer Science Institute (ICSI), United States; Helsinki Institute for Information Technology (HIIT), Finland; UC Berkeley, Computer Science Division, United States",Helsinki Institute of Information Technology;University of California Berkeley,2,Finland;USA,2,43,38,"The Internet has evolved greatly from its original incarnation. For instance, the vast majority of current Internet usage is data retrieval and service access, whereas the architecture was designed around host-to-host applications such as telnet and ftp. Moreover, the original Internet was a purely transparent carrier of packets, but now the various network stakeholders use middleboxes to improve security and accelerate applications. To adapt to these changes, we propose the Data-Oriented Network Architecture (DONA), which involves a clean-slate redesign of Internet naming and name resolution. Copyright 2007 ACM.",Data; Internet architecture; Middleboxes; Name resolution; Naming,Data; Internet architecture; Middleboxes; Name resolution; Naming; Internet; Internet protocols; Network architecture
"Huang C., Li J., Ross K.W.",3,Can internet video-on-demand be profitable?,2007,31,"Microsoft Research, Redmond, WA 98052, United States; Polytechnic University, Brooklyn, NY 11201, United States","Microsoft;Polytechnic University,Brooklyn",2,USA,1,22,18,"Video-on-demand in the Internet has become an immensely popular service in recent years. But due to its high bandwidth requirements and popularity, it is also a costly service to provide. We consider the design and potential benefits of peer-assisted video-on-demand, in which participating peers assist the server in delivering VoD content. The assistance is done in such a way that it provides the same user quality experience as pure client-server distribution. We focus on the single-video approach, whereby a peer only redistributes a video that it is currently watching. Using a nine-month trace from a client-server VoD deployment for MSN Video, we assess what the 95 percentile server bandwidth costs would have been if a peer-assisted employment had been instead used. We show that peer-assistance can dramatically reduce server bandwidth costs, particularly if peers prefetch content when there is spare upload capacity in the system. We consider the impact of peer-assisted VoD on the cross-traffic among ISPs. Although this traffic is significant, if care is taken to localize the P2P traffic within the ISPs, we can eliminate the ISP cross traffic while still achieving important reductions in server bandwidth. We also develop a simple analytical model which captures many of the critical features of peer-assisted VoD, including its operational modes. Copyright 2007 ACM.",ISP-friendly; Peer-to-peer; Video-on-demand,Client server; Critical features; Cross-traffic; High bandwidth; ISP-friendly; Operational modes; Peer to peer; Potential benefits; Bandwidth; Distributed computer systems; Profitability; Video on demand; Internet service providers
"Casado M., Freedman M.J., Pettit J., Luo J., McKeown N., Shenker S.",6,Ethane: Taking control of the enterprise,2007,127,"Stanford University, United States; U.C. Berkeley and ICSI, United States",Stanford University;University of California Berkeley,2,USA,1,25,16,"This paper presents Ethane, a new network architecture for the enterprise. Ethane allows managers to define a single network-wide fine-grain policy, and then enforces it directly. Ethane couples extremely simple flow-based Ethernet switches with a centralized controller that manages the admittance and routing of flows. While radical, this design is backwards-compatible with existing hosts and switches. We have implemented Ethane in both hardware and software, supporting both wired and wireless hosts. Our operational Ethane network has supported over 300 hosts for the past four months in in Stanford University's network, and this deployment experience has significantly affected Ethane's design. Copyright 2007 ACM.",Architecture; Management; Network; Security,Centralized controllers; Ethernet switches; Fine grains; Hardware and software; Security; Stanford University; Wired and wireless; Architecture; Industry; Management; Network architecture; Networks (circuits); Ethane
"Terpstra W.W., Kangasharju J., Leng C., Buchmann A.P.",4,"BubbleStorm: Resilient, probabilistic, and exhaustive peer-to-peer search",2007,23,"Technische Universitat Darmstadt, Germany; University of Helsinki, Finland",TU Darmstadt;University of Helsinki,2,Finland;Germany,2,21,20,"Peer-to-peer systems promise inexpensive scalability, adaptability, and robustness. Thus, they are an attractive platform for file sharing, distributed wikis, and search engines. These applications often store weakly structured data, requiring sophisticated search algorithms. To simplify the search problem, most scalable algorithms introduce structure to the network. However, churn or violent disruption may break this structure, compromising search guarantees. This paper proposes a simple probabilistic search system, BubbleStorm, built on random multigraphs. Our primary contribution is a flexible and reliable strategy for performing exhaustive search. BubbleStorm also exploits the heterogeneous bandwidth of peers. However, we sacrifice some of this bandwidth for high parallelism and low latency. The provided search guarantees are tunable, with success probability adjustable well into the realm of reliable systems. For validation, we simulate a network with one million low-end peers and show BubbleStorm handles up to 90% simultaneous peer departure and 50% simultaneous crash. Copyright 2007 ACM.",Exhaustive search; Peer-to-peer; Resilience; Simulation,Exhaustive search; Peer to peer; Peer-to-Peer system; Primary contribution; Probabilistic search; Resilience; Simulation; Weakly-structured datum; Algorithms; Bandwidth; Distributed computer systems; Search engines; Peer to peer networks
"Mahadevan P., Hubble C., Krioukov D., Huffaker B., Vahdat A.",5,Orbis: Rescaling degree correlations to generate annotated internet topologies,2007,30,"UC San Diego, United States; CAIDA, United States",University of California San Diego,1,USA,1,34,25,"Researchers involved in designing network services and protocols rely on results from simulation and emulation environments to evaluate correctness, performance and scalability. To better understand the behavior of these applications and to predict their performance when deployed across the Internet, the generated topologies that serve as input to simulated and emulated environments must closely match real network characteristics, not just in terms of graph structure (node interconnectivity) but also with respect to various node and link annotations. Relevant annotations include link latencies, AS membership and whether a router is a peering or internal router. Finally, it should be possible to rescale a given topology to a variety of sizes while still maintaining its essential characteristics. In this paper, we propose techniques to generate annotated, Internet router graphs of different sizes based on existing observations of Internet characteristics. We find that our generated graphs match a variety of graph properties of observed topologies for a range of target graph sizes. While the best available data of Internet topology currently remains imperfect, the quality of our generated topologies will improve with the fidelity of available measurement techniques or next generation architectures that make Internet structure more transparent. Copyright 2007 ACM.",Degree correlations; Network topology,Degree correlation; Essential characteristic; Interconnectivity; Internet structure; Internet topologies; Measurement techniques; Network topology; Performance and scalabilities; Computer simulation; Electric network topology; Internet; Internet protocols; Topology
"Mühlbauer W., Uhlig S., Fu B., Meulle M., Maennel O.",5,In search for an appropriate granularity to model routing policies,2007,4,"TU Berlin, T-Labs, United States; Delft University of Technology, Netherlands; France Telecom R and D, France; University of Adelaide, Australia",Delft University of Technology;France Telecom R and D;TU Berlin;University of Adelaide,4,Australia;France;Netherlands;USA,4,27,23,"Routing policies are typically partitioned into a few classes that capture the most common practices in use today [1]. Unfortunately, it is known that the reality of routing policies [2] and peering relationships is far more complex than those few classes [1,3]. We take the next step of searching for the appropriate granularity at which policies should be modeled. For this purpose, we study how and where to configure per-prefix policies in an AS-level model of the Internet, such that the selected paths in the model are consistent with those observed in BGP data from multiple vantage points. By comparing business relationships with per-prefix filters, we investigate the role and limitations of business relationships as a model for policies. We observe that popular locations for filtering correspond to valleys where no path should be propagated according to inferred business relationships. This result reinforces the validity of the valley-free property used for business relationships inference. However, given the sometimes large path diversity ASs have, business relationships do not contain enough information to decide which path will be chosen as the best. To model how individual ASs choose their best paths, we introduce a new abstraction: next-hop atoms. Next-hop atoms capture the different sets of neighboring ASs an AS uses for its best routes. We show that a large fraction of next-hop atoms correspond to per-neighbor path choices. A non-negligible fraction of path choices, however, correspond to hot-potato routing and tie-breaking within the BGP decision process, very detailed aspects of Internet routing. Copyright 2007 ACM.",BGP; Inter-domain routing; Routing policies,BGP; Business relationships; Decision process; Hot-potato routing; Interdomain Routing; Internet routing; Multiple vantage points; Routing policies; Internet; Atoms
"Gummadi R., Wetherall D., Greenstein B., Seshan S.",4,Understanding and mitigating the impact of RF interference on 802.11 networks,2007,47,"USC, United States; Intel Research, United States; University of Washington, United States; CMU, United States",Intel;University of Southern California;University of Washington at St. Louis,3,USA,1,31,7,"We study the impact on 802.11 networks of RF interference from devices such as Zigbee and cordless phones that increasingly crowd the 2.4GHz ISM band, and from devices such as wireless camera jammers and non-compliant 802.11 devices that seek to disrupt 802.11 operation. Our experiments show that commodity 802.11 equipment is surprisingly vulnerable to certain patterns of weak or narrow-band interference. This enables us to disrupt a link with an interfering signal whose power is 1000 times weaker than the victim's 802.11 signals, or to shut down a multiple AP, multiple channel managed network at a location with a single radio interferer. We identify several factors that lead to these vulnerabilities, ranging from MAC layer driver implementation strategies to PHY layer radio frequency implementation strategies. Our results further show that these factors are not overcome by simply changing 802.11 operational parameters (such as CCA threshold, rate and packet size) with the exception of frequency shifts. This leads us to explore rapid channel hopping as a strategy to withstand RF interference. We prototype a channel hopping design using PRISM NICs, and find that it can sustain throughput at levels of RF interference well above that needed to disrupt unmodified links, and at a reasonable cost in terms of switching overheads. Copyright 2007 ACM.",802.11; Channel hopping; Jamming; RF interference; SINR,802.11; Channel hopping; Implementation strategies; Interfering signals; Narrow band interference; Operational parameters; RF interference; SINR; Jamming; Spurious signal noise; Signal interference
"Raghavan B., Vishwanath K., Ramabhadran S., Yocum K., Snoeren A.C.",5,Cloud control with distributed rate limiting,2007,31,"Department of Computer Science and Engineering, University of California, San Diego, United States",University of California San Diego,1,USA,1,41,26,"Today's cloud-based services integrate globally distributed resources into seamless computing platforms. Provisioning and accounting for the resource usage of these Internet-scale applications presents a challenging technical problem. This paper presents the design and implementation of distributed rate limiters, which work together to enforce a global rate limit across traffic aggregates at multiple sites, enabling the coordinated policing of a cloud-based service's network traffic. Our abstraction not only enforces a global limit, but also ensures that congestion-responsive transport-layer flows behave as if they traversed a single, shared limiter. We present two designs-one general purpose, and one optimized for TCP-that allow service operators to explicitly trade off between communication costs and system accuracy, efficiency, and scalability. Both designs are capable of rate limiting thousands of flows with negligible overhead (less than 3% in the tested configuration). We demonstrate that our TCP-centric design is scalable to hundreds of nodes while robust to both loss and communication delay, making it practical for deployment in nationwide service providers. Copyright 2007 ACM.",CDN; Rate limiting; Token bucket,CDN; Communication delays; Design and implementations; Distributed resources; Rate limiting; Seamless computing; Token bucket; Traffic aggregates; Design; Transmission control protocol
"Xie Y., Yu F., Achan K., Gillum E., Goldszmidt M., Wobber T.",6,How dynamic are IP addresses?,2007,16,"Microsoft Research, Silicon Valley, United States; Microsoft Corporation, United States",Microsoft,1,USA,1,33,23,"This paper introduces a novel algorithm, UDmap, to identify dynamically assigned IP addresses and analyze their dynamics pattern. UDmap is fully automatic, and relies only on application-level server logs. We applied UDmap to a month-long Hotmail user-login trace and identified a significant number of dynamic IP addresses - more than 102 million. This suggests that the fraction of IP addresses that are dynamic is by no means negligible. Using this information in combination with a three-month Hotmail email server log, we were able to establish that 95.6% of mail servers setup on the dynamic IP addresses in our trace sent out solely spam emails. Moreover, these mail servers sent out a large amount of spam - amounting to 42.2% of all spam emails received by Hotmail. These results highlight the importance of being able to accurately identify dynamic IP addresses for spam filtering. We expect similar benefits to arise for phishing site identification and botnet detection. To our knowledge, this is the first successful attempt to automatically identify and understand IP address dynamics. Copyright 2007 ACM.",DHCP; Dynamic IP addresses; Entropy; IP volatility; Spam detection,Botnet detections; DHCP; Dynamic ip; Dynamics patterns; IP volatility; Novel algorithm; Site identification; Spam detection; Algorithms; Electronic mail; Entropy; Internet
"Karsten M., Keshav S., Prasad S., Beg M.",4,An axiomatic basis for communication,2007,6,"David R. Cheriton School of Computer Science, University of Waterloo, Canada; Department of Computer Science and Engineering, IIT Delhi, India",University of Waterloo,1,Canada;India,2,25,15,"The de facto service architecture of today's communication networks, in particular the Internet, is heterogeneous, complex, ad hoc, and not particularly well understood. With layering as the only means for functional abstraction, and even this violated by middle-boxes, the diversity of current technologies can barely be expressed, let alone analyzed. As a first step to remedying this problem, we present an axiomatic formulation of fundamental forwarding mechanisms in communication networks. This formulation allows us to express precisely and abstractly the concepts of naming and addressing and to specify a consistent set of control patterns and operational primitives, from which a variety of communication services can be composed. Importantly, this framework can be used to (1) formally analyze network protocols based on structural properties, and also to (2) derive working prototype implementations of these protocols. The prototype is implemented as a universal forwarding engine, a general framework and runtime environment based on the Click router. Copyright 2007 ACM.",Addressing; Concepts; Definitions; Naming; Protocols; Routing,Addressing; Concepts; Definitions; Naming; Routing; Internet protocols; Network protocols; Communication
"Zheng C., Ji L., Pei D., Wang J., Francis P.",5,A light-weight distributed scheme for detecting IP prefix hijacks in real-time,2007,13,"AT and T Labs - Research, Florham Park, NJ, United States; Dept. of Computer Science, Cornell University, Ithaca, NY, United States",AT and T Labs;Cornell University,2,USA,1,36,27,"As more and more Internet IP prefix hijacking incidents are being reported, the value of hijacking detection services has become evident. Most of the current hijacking detection approaches monitor IP prefixes on the control plane and detect inconsistencies in route advertisements and route qualities. We propose a different approach that utilizes information collected mostly from the data plane. Our method is motivated by two key observations: when a prefix is not hijacked, 1) the hop count of the path from a source to this prefix is generally stable; and 2) the path from a source to this prefix is almost always a super-path of the path from the same source to a reference point along the previous path, as long as the reference point is topologically close to the prefix. By carefully selecting multiple vantage points and monitoring from these vantage points for any departure from these two observations, our method is able to detect prefix hijacking with high accuracy in a light-weight, distributed, and real-time fashion. Through simulations constructed based on real Internet measurement traces, we demonstrate that our scheme is accurate with both false positive and false negative ratios below 0.5%. Copyright 2007 ACM.",BGP; Detection; Hijacking; Interception; Routing,BGP; Distributed schemes; False positive and false negatives; Hijacking; Internet measurement; Ip prefix hijackings; Multiple vantage points; Routing; Communication; Error detection; Satellite interception; Internet protocols
"Yuan L., Chuah C.-N., Mohapatra P.",3,ProgME: Towards programmable network measurement,2007,6,"University of California, Davis, United States",University of California Davis,1,USA,1,38,28,"Traffic measurements provide critical input for a wide range of network management applications, including traffic engineering, accounting, and security analysis. Existing measurement tools collect traffic statistics based on some predetermined, inflexible concept of ""flows"". They do not have sufficient built-in intelligence to understand the application requirements or adapt to the traffic conditions. Consequently, they have limited scalability with respect to the number of flows and the heterogeneity of monitoring applications. We present ProgME, a Programmable MEasurement architecture based on a novel concept of flowset - arbitrary set of flows defined according to application requirements and/or traffic conditions. Through a simple flowset composition language, ProgME can incorporate application requirements, adapt itself to circumvent the challenges on scalability posed by the large number of flows, and achieve a better application-perceived accuracy. ProgME can analyze and adapt to traffic statistics in real-time. Using sequential hypothesis test, ProgME can achieve fast and scalable heavy hitter identification. Copyright 2007 ACM.",Flowset; Flowset composition language; Multi-resolution tiling; Programmable measurement; Traffic measurement,Application requirements; Composition languages; Flowset; Management applications; Monitoring applications; Multi-resolutions; Programmable network; Traffic measurements; Highway engineering; Scalability; Traffic surveys; Measurements
"Sommers J., Barford P., Duffield N., Ron A.",4,Accurate and efficient SLA compliance monitoring,2007,12,"University of Wisconsin, Madison, United States; AT and T Labs - Research, United States",AT and T Labs;University of Wisconsin-Madison,2,USA,1,42,38,"Service level agreements (SLAs) define performance guarantees made by service providers, e.g, in terms of packet loss, delay, delay variation, and network availability. In this paper, we describe a new active measurement methodology to accurately monitor whether measured network path characteristics are in compliance with performance targets specified in SLAs. Specifically, (1) we describe a new methodology for estimating packet loss rate that significantly improves accuracy over existing approaches; (2) we introduce a new methodology for measuring mean delay along a path that improves accuracy over existing methodologies, and propose a method for obtaining confidence intervals on quantiles of the empirical delay distribution without making any assumption about the true distribution of delay; (3) we introduce a new methodology for measuring delay variation that is more robust than prior techniques; and (4) we extend existing work in network performance tomography to infer lower bounds on the quantiles of a distribution of performance measures along an unmeasured path given measurements from a subset of paths. We unify active measurements for these metrics in a discrete time-based tool called SLAM. The unified probe stream from SLAM consumes lower overall bandwidth than if individual streams are used to measure path properties. We demonstrate the accuracy and convergence properties of SLAM in a controlled laboratory environment using a range of background traffic scenarios and in one-and two-hop settings, and examine its accuracy improvements over existing standard techniques. Copyright 2007 ACM.",Active measurement; Network congestion; Network delay; Network jitter; Packet loss; Service-level agreements; SLAM,Active measurement; Network congestions; Network delays; Network jitter; Service Level Agreements; SLAM; Network performance; Outsourcing; Packet loss; Time delay
"Cheng Y.-C., Afanasyev M., Verkaik P., Benkö P., Chiang J., Snoeren A.C., Savage S., Voelker G.M.",8,Automating cross-layer diagnosis of enterprise wireless networks,2007,3,"Department of Computer Science and Engineering, University of California, San Diego, United States; Traffic Analysis and Network Performance Laboratory (TrafficLab), Ericsson Research, Budapest, Hungary",Ericsson Research;University of California San Diego,2,Hungary;USA,2,23,23,"Modern enterprise networks are of sufficient complexity that even simple faults can be difficult to diagnose - let alone transient outages or service degradations. Nowhere is this problem more apparent than in the 802.11-based wireless access networks now ubiquitous in the enterprise. In addition to the myriad complexities of the wired network, wireless networks face the additional challenges of shared spectrum, user mobility and authentication management. Not surprisingly, few organizations have the expertise, data or tools to decompose the underlying problems and interactions responsible for transient outages or performance degradations. In this paper, we present a set of modeling techniques for automatically characterizing the source of such problems. In particular, we focus on data transfer delays unique to 802.11 networks - media access dynamics and mobility management latency. Through a combination of measurement, inference and modeling we reconstruct sources of delay - from the physical layer to the transport layer - as well as the interactions among them. We demonstrate our approach using comprehensive traces of wireless activity in the UCSD Computer Science building. Copyright 2007 ACM.",802.11; Measurement; Modeling; Wireless networks,802.11; Data transfer delays; Enterprise networks; Enterprise wireless network; Mobility management; Performance degradation; Service degradation; Wireless access networks; Authentication; Complex networks; Industry; Measurements; Models; Network layers; Wireless networks
"Elmeleegy K., Cox A.L., Ng T.S.E.",3,EtherFuse: An ethernet watchdog,2007,1,"Department of Computer Science, Rice University, United States",Rice University,1,USA,1,22,13,"Ethernet is pervasive. This is due in part to its ease of use. Equipment can be added to an Ethernet network with little or no manual configuration. Furthermore, Ethernet is self-healing in the event of equipment failure or removal. However, there are scenarios where a local event can lead to network-wide packet loss and congestion due to slow or faulty reconfiguration of the spanning tree. Moreover, in some cases the packet loss and congestion may persist indefinitely. To address these problems, we introduce the EtherFuse, a new device that can be inserted into an existing Ethernet to speed the reconfiguration of the spanning tree and prevent congestion due to packet duplication. EtherFuse is backward compatible and requires no change to the existing hardware, software, or protocols. We describe a prototype EtherFuse implementation and experimentally demonstrate its effectiveness. Specifically, we characterize how quickly it responds to network failures, its ability to reduce packet loss and duplication, and its benefits on the end-to-end performance of common applications. Copyright 2007 ACM.",Count to infinity; Ethernet; Forwarding loop; Network watchdog; Reliability,Backward compatible; Count to infinities; End-to-end performance; Equipment failures; Ethernet networks; Forwarding loop; Network failure; Packet duplications; Packet loss; Parallel architectures; Reliability; Ethernet
"Ee C.T., Chun B.-G., Ramachandran V., Lakshminarayanan K., Shenker S.",5,Resolving inter-domain policy disputes,2007,5,"Department of Computer Science, University of California, Berkeley, Berkeley, CA 94720, United States; Department of Computer Science, Colgate University, Hamilton, NY 13346, United States; Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai 600036, India; International Computer Science Institute (ICSI), University of California, Berkeley, Berkeley, CA 94704, United States",Colgate University;IIT Madras;University of California Berkeley,3,India;USA,2,17,16,"The Border Gateway Protocol (BGP) allows each autonomous system (AS) to select routes to destinations based on se-mantically rich and locally determined policies. This autonomously exercised policy freedom can cause instability, where unresolvable policy-based disputes in the network result in interdomain route oscillations. Several recent works have established that such instabilities can only be eliminated by enforcing a globally accepted preference ordering on routes (such as shortest path). To resolve this conflict between policy autonomy and system stability, we propose a distributed mechanism that enforces a preference ordering only when disputes resulting in oscillations exist. This preserves policy freedom when possible, and imposes stability when required. Copyright 2007 ACM.",BGP; Convergence; Inter-domain routing; Policy disputes,Autonomous systems; BGP; Border gateway protocol; Convergence; Inter-domain; Inter-domain policies; Interdomain Routing; Shortest path; System stability; Gateways (computer networks)
Papagiannaki K.,1,Author feedback experiment at PAM 2007,2007,3,"Intel Research Pittsburgh, United States",Intel,1,USA,1,3,1,"This editorial article is put together to disseminate the experience gained through the author feedback experiment, performed at the 2007 Passive and Active Measurement (PAM) conference.",Author feedback; Review quality,Active measurement; Review quality; Communication; Experiments
Keshav S.,1,How to read a paper,2007,16,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada",University of Waterloo,1,Canada,1,4,0,"Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.",Hints; Paper; Reading,Hints; Literature survey; Reading; Research papers; Three-pass; Research; Paper
"Aggarwal V., Feldmann A., Scheideler C.",3,Can ISPs and P2P users cooperate for improved performance?,2007,286,"Deutsche Telekom Laboratories, TU Berlin, Berlin, Germany; TU München, Munich, Germany",Deutsche Telekom Laboratories;TU Berlin;TU Munich,3,Germany,1,45,34,"Peer-to-peer (P2P) systems, which are realized as overlays on top of the underlying Internet routing architecture, contribute a significant portion of today's Internet traffic. While the P2P users are a good source of revenue for the Internet Service Providers (ISPs), the immense P2P traffic also poses a significant traffic engineering challenge to the ISPs. This is because P2P systems either implement their own routing in the overlay topology or may use a P2P routing underlay [1], both of which are largely independent of the Internet routing, and thus impedes the ISP's traffic engineering capabilities. On the other hand, P2P users are primarily interested in finding their desired content quickly, with good performance. But as the P2P system has no access to the underlying network, it either has to measure the path performance itself or build its overlay topology agnostic of the underlay. This situation is disadvantageous for both the ISPs and the P2P users. To overcome this, we propose and evaluate the feasibility of a solution where the ISP offers an ""oracle"" to the P2P users. When the P2P user supplies the oracle with a list of possible P2P neighbors, the oracle ranks them according to certain criteria, like their proximity to the user or higher bandwidth links. This can be used by the P2P user to choose appropriate neighbors, and therefore improve its performance. The ISP can use this mechanism to better manage the immense P2P traffic, e.g., to keep it inside its network, or to direct it along a desired path. The improved network utilization will also enable the ISP to provide better service to its customers.",Biased neighbor selection; Cooperation; ISP; P2P; Routing,Cooperation; ISP; Neighbor selection; P2P; Routing; Distributed computer systems; Internet service providers; Peer to peer networks
"He J., Rexford J., Chiang M.",3,"Don't optimize existing protocols, design optimizable protocols",2007,4,"Princeton University, Princeton, NJ, United States",Princeton University,1,USA,1,12,10,"As networks grow in size and complexity, network management has become an increasingly challenging task. Many protocols have tunable parameters, and optimization is the process of setting these parameters to optimize an objective. In recent years, optimization techniques have been widely applied to network management problems, albeit with mixed success. Realizing that optimization problems in network management are induced by assumptions adopted in protocol design, we argue that instead of optimizing existing protocols, protocols should be designed with optimization in mind from the beginning. Using examples from our past research on traffic management, we present principles that guide how changes to existing protocols and architectures can lead to optimizable protocols. We also discuss the trade-offs between making network optimization easier and the overhead these changes impose.",Design; Management; Performance,In-network management; Management problems; Network optimization; Optimization problems; Optimization techniques; Performance; Traffic management; Tunable parameter; Complex networks; Design; Management; Network management; Optimization; Network architecture
"Lee D., Brownlee N.",2,Passive measurement of one-way and two-way flow lifetimes,2007,28,"Department of Computer Science, University of Auckland, New Zealand",University of Auckland,1,New Zealand,1,24,15,"Flow based analysis has been considered a simple and effective approach in network analysis. 5-tuple (unidirectional) flows are used in many network traffic, however, often these analyses require bidirectional packet matching to observe the interactions. Separating the flows into two categories as one-way (packets in one direction only) and two-way (packets in both directions) flows can yield further insight. We have examined traces of Auckland traffic for 2000, 2003 and 2006, and analyzed their one-way and two-way flows. We observed several behaviors and the changes in flow sizes and their lifetimes over time. In our traces, we observe that one-way flows are mostly malicious, re-transmissions, and some are long-lived. Two-way flows are mostly normal end-to-end transmissions with their lifetimes/RTTs decreasing, their sizes increasing, and many short-lived flows mostly depict errors in TCP. Also, we observe similarity between one-way and two-way flow sizes for their lifetimes.",Flow lifetime; One-way flow; Passive measurement; Traffic meter; Two-way flow,Effective approaches; End-to-end transmission; Flow lifetime; Flow-based analysis; In-network analysis; One-way flow; Passive measurements; Two-way flow; Communication
"Krioukov D., Claffy K., Fall K., Brady A.",4,On compact routing for the internet,2007,88,"CAIDA, United States; Intel Research Berkeley, United States; Tufts University, United States",Intel;Tufts University,2,USA,1,49,38,"The Internet's routing system is facing stresses due to its poor fundamental scaling properties. Compact routing is a research field that studies fundamental limits of routing scalability and designs algorithms that try to meet these limits. In particular, compact routing research shows that shortest-path routing, forming a core of traditional routing algorithms, cannot guarantee routing table (RT) sizes that on all network topologies grow slower than linearly as functions of the network size. However, there are plenty of compact routing schemes that relax the shortest-path requirement and allow for improved, sublinear RT size scaling that is mathematically provable for all static network topologies. In particular, there exist compact routing schemes designed for grids, trees, and Internet-like topologies that offer RT sizes that scale logarithmically with the network size. In this paper, we demonstrate that in view of recent results in compact routing research, such logarithmic scaling on Internet-like topologies is fundamentally impossible in the presence of topology dynamics or topology-independent (flat) addressing. We use analytic arguments to show that the number of routing control messages per topology change cannot scale better than linearly on Internet-like topologies. We also employ simulations to confirm that logarithmic RT size scaling gets broken by topology-independent addressing, a cornerstone of popular locator-identifier split proposals aiming at improving routing scaling in the presence of network topology dynamics or host mobility. These pessimistic findings lead us to the conclusion that a fundamental re-examination of assumptions behind routing models and abstractions is needed in order to find a routing architecture that would be able to scale ""indefinitely"".",Compact routing; Internet routing; Routing scalability,Compact routing; Internet routing; Internet-like topology; Routing architecture; Routing control messages; Routing scalability; Shortest path routing; Topology-independent; Electric network topology; Research; Routing protocols; Scalability; Topology; Internet
"Gavras A., Karila A., Fdida S., May M., Potts M.",5,Future internet research and experimentation: The FIRE initiative,2007,87,"Eurescom, Germany; Helsinki Institute of Information Technology, Finland; University P and M Curie, France; ETHZ, Switzerland; Martel, Switzerland",Helsinki Institute of Information Technology;University Pierre and Marie Curie,2,Finland;France;Germany;Switzerland,4,9,1,"The research community worldwide has increasingly drawn its attention to the weaknesses of the current Internet. Many proposals are addressing the perceived problems, ranging from new enhanced protocols to fix specific problems up to the most radical proposal to redesign and deploy a fully new Internet. Most of the problems in the current Internet are rooted in the tremendous pace of increase of its use. As a consequence there was little time to address the deficiencies of the Internet from an architectural point of view. Within FP7, the European Commission has facilitated the creation of European expert groups around the theme FIRE ""Future Internet Research and Experimentation"". FIRE has two related dimensions: on one hand, promoting experimentally-driven long-term, visionary research on new paradigms and networking concepts and architectures for the future Internet; on the other hand, building a large-scale experimentation facility supporting both medium- and long-term research on networks and services by gradually federating existing and new testbeds for emerging or future Internet technologies. By addressing future challenges for the Internet such as mobility, scalability, security and privacy, this new experimentally-driven approach is challenging the mainstream perceptions for future Internet development. This new initiative is intended to complement the more industrially-driven approaches which are addressed under the FP7 Objective ""The Network of the Future"" within the FP7-ICT Workprogramme 2007-08. FIRE is focused on exploring new and radically better technological solutions for the future Internet, while preserving the ""good"" aspects of the current Internet, in terms of openness, freedom of expression and ubiquitous access. The FIRE activities are being launched in the 2nd ICT call, which closes in October 2007, under the FP7-ICT Objective 1.6 ""New Paradigms and Experimental Facilities"" (budget €40m). Projects are envisaged to start in early 2008.",Experimentation; Future internet; Network architecture; Network neutrality; Situated and autonomic communications; Testbed,Autonomic communications; Experimental facilities; Experimentation; Future internet; Large-scale experimentations; Network neutralities; Security and privacy; Technological solution; Fires; Information technology; Internet; Internet protocols; Network architecture; Testbeds; Experiments
"Landström S., Larzon L.-A.",2,Reducing the TCP acknowledgment frequency,2007,12,"Luleå University of Technology, Sweden; Uppsala University, Sweden",Luleå University of Technology;Uppsala University,2,Sweden,1,30,21,"Delayed acknowledgments were introduced to conserve network and host resources. Further reduction of the acknowledgment frequency can be motivated in the same way. However, reducing the dependency on frequent acknowledgments in TCP is difficult because acknowledgments support reliable delivery, loss recovery, clock out new segments, and serve as input when determining an appropriate sending rate. Our results show that in scenarios where there are no obvious advantages of reducing the acknowledgment frequency, performance can be maintained although fewer acknowledgments are sent. Hence, there is a potential for reducing the acknowledgment frequency more than is done through delayed acknowledgments today. Advancements in TCP loss recovery is one of the key reasons that the dependence on frequent acknowledgments has decreased. We propose and evaluate an end-to-end solution, where four acknowledgments per send window are sent. The sender compensates for the reduced acknowledgment frequency using a form of Appropriate Byte Counting. The proposal also includes a modification of fast loss recovery to avoid frequent timeouts.",Acknowledgments; TCP,Acknowledgments; End-to-end solutions; Loss recovery; Reliable delivery; Sending rate; TCP; Communication; Recovery
Mhatre V.,1,Enhanced wireless mesh networking for ns-2 simulator,2007,28,"Thomson, 46 Quai Alphonse Le Gallo, Boulogne-Billancourt, 92100, France",Thomson Research,1,France,1,20,11,"The ns-2 simulator has limited support for simulating 802.11-based wireless mesh networks. We have added the following new features at the MAC and PHY layer of ns-2: (i) cumulative interference in SINR (Signal to Interference and Noise Ratio) computation, (ii) an accurate and combined shadow-fading module, (iii) multi-SINR and multi-rate link support, (iv) auto rate fallback (ARF) for rate adaptation, and (v) a framework for link probing and link quality estimation as required by most mesh routing protocols. We have made these modules publicly available. In this paper, we present an overview of these new features.",802.11; Mesh network; Network simulation; Wi-Fi; Wireless network,802.11; Auto rate fallbacks; Cumulative interference; Link quality estimations; Mesh network; Network simulation; Signal-to-interference and noise ratios; Wireless mesh networking; Computer simulation; MESH networking; Signal interference; Spurious signal noise; Wireless networks; Wi-Fi
Feldmann A.,1,Internet clean-slate design: What and why?,2007,204,"Deutsche Telekom Laboratories, TU Berlin, Germany",TU Berlin,1,Germany,1,30,5,"Many believe that it is impossible to resolve the challenges facing today's Internet without rethinking the fundamental assumptions and design decisions underlying its current architecture. Therefore, a major research effort has been initiated on the topic of Clean Slate Design of the Internet's architecture. In this paper we first give an overview of the challenges that a future Internet has to address and then discuss approaches for finding possible solutions, including Clean Slate Design. Next, we discuss how such solutions can be evaluated and how they can be retrofitted into the current Internet. Then, we briefly outline the upcoming research activities both in Europe and the U.S. Finally, we end with a perspective on how network and service operators may benefit from such an initiative.",Clean-slate; Internet; Network architecture; Post-IP,Clean slates; Design decisions; Future internet; Post-IP; Research activities; Research efforts; Design; Internet; Network architecture; Slate; Internet protocols
"Kushman N., Kandula S., Katabi D.",3,Can you hear me now?!: It must be BGP,2007,43,"MIT - CSAIL, United States",MIT,1,USA,1,47,38,"Industry observers expect VoIP to eventually replace most of the existing land-line telephone connections. Currently however, quality and reliability concerns largely limit VoIP usage to either personal calls on cross-domain services such as Skype and Vonage, or to single-domain services such as trunking, where a core ISP carries long-distance voice as VoIP only within its backbone, to save cost with a unified voice/data infrastructure. This paper investigates the factors that prevent cross-domain VoIP deployments from achieving the quality and reliability of existing land-line telephony (PSTN). We ran over 50,000 VoIP phone calls between 24 locations in US and Europe for a three-week period. Our results indicate that VoIP usability is hindered as much by BGP's slow convergence as network congestion. In fact, about half of the unintelligible VoIP samples in our data occur within 10 minutes of a BGP update.",BGP; Burst Losses; MOS; PESQ; VoIP,BGP; Burst loss; MOS; PESQ; VoIP; Voice/data communication systems; Internet telephony
"Raghavan B., Panjwani S., Mityagin A.",3,Analysis of the SPV secure routing protocol: Weaknesses and lessons,2007,13,"University of California, San Diego, United States",University of California San Diego,1,USA,1,25,20,"We analyze a secure routing protocol, Secure Path Vector (SPV), proposed in SIGCOMM 2004. SPV aims to provide authenticity for route announcements in the Border Gateway Protocol (BGP) using an efficient alternative to ordinary digital signatures, called constant-time signatures. Today, SPV is often considered the best cryptographic defense for BGP. We find subtle flaws in the design of SPV which lead to attacks that can be mounted by 60% of Autonomous Systems in the Internet. In addition, we study several of SPV's design decisions and assumptions and highlight the requirements for security of routing protocols. In light of our analysis, we reexamine the need for constant-time signatures and find that certain standard digital signature schemes can provide the same level of efficiency for route authenticity.",BGP; Routing; Secure Path Vector,Autonomous systems; BGP; Border gateway protocol; Design decisions; Digital signature schemes; Routing; Secure path vectors; Secure routing protocols; Electronic document identification systems; Internet protocols; Network security; Routing protocols; Gateways (computer networks)
"Naicken S., Livingston B., Basu A., Rodhetbhai S., Wakeman I., Chalmers D.",6,The state of peer-to-peer simulators and simulations,2007,81,"Department of Informatics, University of Sussex, Brighton, United Kingdom",University of Sussex,1,UK,1,13,14,"In this paper, we discuss the current situation with respect to simulation usage in P2P research, testing the available P2P simulators against a proposed set of requirements, and surveying over 280 papers to discover what simulators are already being used. We found that no simulator currently meets all our requirements, and that simulation results are generally reported in the literature in a fashion that precludes any reproduction of results. We hope that this paper will give rise to further discussion and knowledge sharing among those of the P2P and network simulation research communities, so that a simulator that meets the needs of rigorous P2P research can be developed.",Peer-to-peer; Simulator evaluation; Simulator usage,Current situation; Knowledge-sharing; Network simulation; P2P research; P2p simulators; Peer to peer; Research; Simulators; Peer to peer networks
"Pope S., Riddoch D.",2,10Gb/s Ethernet performance and retrospective,2007,7,"Solarflare Communications Inc., United States",Solarflare Communications Inc.,1,USA,1,40,8,"This paper presents both a retrospective of the development of network interface architecture, and performance and conformance data from a range of contemporary devices sporting various performance enhancing technologies. The data shows that 10Gb/s networking is now possible without statefull offload and while consuming less than one CPU core on a contemporary commodity server.",10Gb/s; Ethernet; Performance,10 Gb/ S; CPU cores; Network interface architecture; Performance; Performance enhancing; Microprocessor chips; Ethernet
"Li J., Guidero M., Wu Z., Purpus E., Ehrenkranz T.",5,BGP routing dynamics revisited,2007,42,"Dept. of Computer and Information Science, University of Oregon, Eugene, OR, United States",University of Oregon,1,USA,1,30,19,"Understanding BGP routing dynamics is critical to the solid growth and maintenance of the Internet routing infrastructure. However, while the most extensive study on BGP dynamics is nearly a decade old, many factors that could affect BGP dynamics have changed considerably. We revisit this important topic in this paper, focusing on not only comparing with the previous results, but also issues not well explored before. We have found that, compared to almost a decade ago, although certain characteristics remain unchanged (such as some temporal properties), BGP dynamics are now ""busier,"" and more importantly, now have much less pathological behavior and are ""healthier""; for example, forwarding dynamics are now not only dominant, but also more consistent across different days. Contributions to BGP dynamics by different BGP peers-which are not proportional to the size of a peer's AS-are also more stable, and dynamics due to policy changes or duplicate announcements are usually from specific peers.",BGP; Network measurement; Routing dynamics; Routing instability,BGP; Internet routing; Network measurement; Policy changes; Routing dynamics; Routing instability; Solid growth; Temporal property; Critical infrastructures; Routing protocols; Dynamics
"Huici F., Handley M.",2,An edge-to-edge filtering architecture against DoS,2007,10,"Dept. of Computer Science, University College London, London, United Kingdom",University College London,1,UK,1,35,28,"Defending against large, distributed Denial-of-Service attacks is challenging, with large changes to the network core or to end-hosts often suggested. To make matters worse, spoofing adds to the difficulty, since defenses must resist attempts to trigger filtering of other people's traffic. Further, any solution has to provide incentives for deployment, or it will never see the light of day. We present a simple and effective architectural defense against distributed DoS attacks that requires no changes to the end-hosts, minimal changes to the network core, is robust to spoofing, provides incentives for initial deployment, and can be built with off-the-shelf hardware.",Denial-of-service; Internet architecture,Denial of Service; Distributed denial of service attack; Distributed DoS; Edge-to-edge; Filtering architectures; Initial deployments; Internet architecture; Off-the-shelf hardwares; Network security; Network architecture
"Machiraju S., Veitch D., Baccelli F., Bolot J.",4,Adding definition to active probing,2007,18,"Sprint ATL, CA, United States; Dept. of E and E Engineering, University of Melbourne, Australia; INRIA-ENS, Ecole Normale Superieure, France",INRIA;University of Melbourne,2,Australia;France;USA,3,18,15,"Active probing techniques have overwhelmingly been based on a few key heuristics. To progress to the next level a more powerful approach is needed, which is capable of filtering noise effectively, designing (and defining) optimal probing strategies, and understanding fundamental limitations. We provide a probabilistic, queueing-theoretic treatment that contributes to this program in the single hop case. We provide an exact inversion method for cross traffic distributions, rigorous system identifiability results to help determine what active probing can and can't achieve, a new approach for treating queueing theoretic 'noise' based on conditioning, and cross traffic estimators with enhanced properties.",Active measurement; Conditioning; Cross traffic; Probing,Active measurement; Active probing techniques; Cross-traffic; Enhanced properties; Exact inversions; Fundamental limitations; Probing; Probing strategies; Communication; Natural gas conditioning; Telecommunication networks
Briscoe B.,1,Flow rate fairness: Dismantling a religion,2007,79,"BT Research, UCL, United States",BT Research,1,USA,1,34,23,"Resource allocation and accountability keep reappearing on every list of requirements for the Internet architecture. The reason we never resolve these issues is a broken idea of what the problem is. The applied research and standards communities are using completely unrealistic and impractical fairness criteria. The resulting mechanisms don't even allocate the right thing and they don't allocate it between the right entities. We explain as bluntly as we can that thinking about fairness mechanisms like TCP in terms of sharing out flow rates has no intellectual heritage from any concept of fairness in philosophy or social science, or indeed real life. Comparing flow rates should never again be used for claims of fairness in production networks. Instead, we should judge fairness mechanisms on how they share out the 'cost' of each user's actions on others.",Accountability; Congestion control; Fairness; Identity; Resource allocation,Accountability; Applied research; Fairness; Fairness criteria; Flow rate fairness; Identity; Internet architecture; Production network; Congestion control (communication); Resource allocation; Flow rate
"Spyropoulos T., Fdida S., Kirkpatrick S.",3,Future internet: Fundamentals and measurement,2007,8,"INRIA, Sophia-Antipolis, 2004, route des Lucioles, 06902 Sophia Antipolis, France; LIP6 Laboratory, University Pierre and Marie Curie, 75015 Paris, France; Benin School of Engineering and Computer Science, Hebrew University of Jerusalem, 91904 Jerusalem, Israel",Hebrew University of Jerusalem;INRIA;University Pierre and Marie Curie,3,Benin;France;Israel,3,19,9,"While the Internet is hardly ""broken"", it has proved unable to integrate new ideas, new architectures, and provide paths for future integration of data, voice, rich media and higher reliability. The reason is that the basic concept of the Internet as an end-to-end packet delivery service has made its middle layer, networking services through TCP/IP, untouchable. If we wish to see any disruptive enhancements to security, routing flexibility and reliability, and robust quality of service guarantees in coming years, we will need to move towards an Internet in which networking environments offering differing strengths can coexist on a permanent basis. This view is gaining currency in the US, advocated by the FIND/GENI initiative [7, 6] and in Europe, where it forms the heart of the activities reviewed by ARCADIA. The ARCADIA activity, sponsored by COST[1] has been chartered to look at critical areas in which research on fundamentals in the Internet's architecture and protocols, supported by accurate experiment, can unlock some of the Internet impasses. This paper attempts to describes the insight gained and conclusions drawn from the first ARCADIA workshop on the Future of the Internet, organized around the main themes of Virtualization, Federation and Monitoring/Measurement.",Arcadia; COST; Federation; Future internet; Monitoring; Testbeds; Virtualization,Arcadia; Federation; Future internet; Networking environment; Networking services; Quality of service guarantees; Routing flexibility; Virtualizations; Costs; Internet; Monitoring; Network architecture; Network layers; Quality of service; Testbeds; Virtual reality; Internet protocols
"Kandula S., Katabi D., Sinha S., Berger A.",4,Dynamic load balancing without packet reordering,2007,203,"MIT, United States; Microsoft, United States; MIT/Akamai, United States",MIT;Microsoft,2,USA,1,35,30,"Dynamic load balancing is a popular recent technique that protects ISP networks from sudden congestion caused by load spikes or link failures. Dynamic load balancing protocols, however, require schemes for splitting traffic across multiple paths at a fine granularity. Current splitting schemes present a tussle between slicing granularity and packet reordering. Splitting traffic at the granularity of packets quickly and accurately assigns the desired traffic share to each path, but can reorder packets within a TCP flow, confusing TCP congestion control. Splitting traffic at the granularity of a flow avoids packet reordering but may overshoot the desired shares by up to 60% in dynamic environments, resulting in low end-to-end network goodput. Contrary to popular belief, we show that one can systematically split a single flow across multiple paths without causing packet reordering. We propose FLARE, a new traffic splitting algorithm that operates on bursts of packets, carefully chosen to avoid reordering. Using a combination of analysis and trace-driven simulations, we show that FLARE attains accuracy and responsiveness comparable to packet switching without reordering packets. FLARE is simple and can be implemented with a few KB of router state.",FLARE; Packet reordering; Traffic splitting,Dynamic environments; Dynamic load balancing protocol; End-to-end network; FLARE; Packet reordering; TCP congestion control; Trace driven simulation; Traffic splitting; Trace analysis; Transmission control protocol
"Crowcroft J., Key P.",2,Report from the clean slate network research post-SIGCOMM 2006 workshop,2007,4,"University of Cambridge, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom; Microsoft Research Cambridge, 7 JJ Thomson Avenue, Cambridge CB3 0FB, United Kingdom",Microsoft;University of Cambridge,2,UK,1,22,22,"Europe has often followed in the footsteps of US research, but here we are trying to lead in Clean Slate networking research, rather than Cleans late networking. This is a report from a recent workshop on this topic.",Data Communications; Review,Clean slates; Data-communication; Reviews; Slate; Research
"Vu-Brugier G., Stanojevic R.S., Leith D.J., Shorten R.N.",4,A critique of recently proposed buffer-sizing strategies,2007,34,"Hamilton Institute, NUI, Maynooth, Ireland",Hamilton Institute,1,Ireland,1,12,11,"Internet router buffers are used to accommodate packets that arrive in bursts and to maintain high utilization of the egress link. Such buffers can lead to large queueing delays. Recently, several papers have suggested that it may, under general circumstances, be possible to achieve high utilisation with small network buffers. In this paper we review these recommendations. A number of issues are reported that question the utility of these recommendations.",Buffer provisioning; Link utilisation; TCP,Buffer provisioning; High utilizations; Internet routers; Link utilisation; Queueing delays; Small networks; TCP; Communication
"Dimitropoulos X., Krioukov D., Fomenkov M., Huffaker B., Hyun Y., Claffy K.C., Riley G.",7,AS relationships: Inference and validation,2007,185,"Georgia Tech., United States; CAIDA, United States",Georgia Tech,1,USA,1,30,22,"Research on performance, robustness, and evolution of the global Internet is fundamentally handicapped without accurate and thorough knowledge of the nature and structure of the contractual relationships between Autonomous Systems (ASs). In this work we introduce novel heuristics for inferring AS relationships. Our heuristics improve upon previous works in several technical aspects, which we outline in detail and demonstrate with several examples. Seeking to increase the value and reliability of our inference results, we then focus on validation of inferred AS relationships. We perform a survey with ASs' network administrators to collect information on the actual connectivity and policies of the surveyed ASs. Based on the survey results, we find that our new AS relationship inference techniques achieve high levels of accuracy: we correctly infer 96.5% customer to provider (c2p), 82.8% peer to peer (p2p), and 90.3% sibling to sibling (s2s) relationships. We then cross-compare the reported AS connectivity with the AS connectivity data contained in BGP tables. We find that BGP tables miss up to 86.2% of the true adjacencies of the surveyed ASs. The majority of the missing links are of the p2p type, which highlights the limitations of present measuring techniques to capture links of this type. Finally, to make our results easily accessible and practically useful for the community, we open an AS relationship repository where we archive, on a weekly basis, and make publicly available the complete Internet AS-level topology annotated with AS relationship information for every pair of AS neighbors.",As relationships; Inference; Routing policies,AS relationships; Autonomous system (ASs); Contractual relationships; Inference; Inference techniques; Measuring technique; Network administrator; Routing policies; Communication; Surveys
"Malone D., Duffy K., King C.",3,Some remarks on LD plots for heavy-tailed traffic,2007,3,"Hamilton Institute, NUI, Maynooth, Ireland; Department of Mathematics, Northeastern University, United States",Hamilton Institute;Northeastern University,2,Ireland;USA,2,7,3,"Ricciato [6] poses several questions, including why a particular LD (log-diagram) plot does not give the Hurst parameter predicted by theory? We offer an explanation of his observation and highlight other unusual aspects of LD plots.",Heavy-tails; Hurst parameter; LD plots; Wavelet estimator,Heavy-tailed traffic; Heavy-tails; Hurst parameter; LD plots; Wavelet estimators; Communication
"Crotti M., Dusi M., Gringoli F., Salgarelli L.",4,Traffic classification through simple statistical fingerprinting,2007,243,"DEA, Università degli Studi di Brescia, Italy",Università Degli Studi di Brescia,1,Italy,1,17,13,"The classification of IP flows according to the application that generated them is at the basis of any modern network management platform. However, classical techniques such as the ones based on the analysis of transport layer or application layer information are rapidly becoming ineffective. In this paper we present a flow classification mechanism based on three simple properties of the captured IP packets: their size, inter-arrival time and arrival order. Even though these quantities have already been used in the past to define classification techniques, our contribution is based on new structures called protocol fingerprints, which express such quantities in a compact and efficient way, and on a simple classification algorithm based on normalized thresholds. Although at a very early stage of development, the proposed technique is showing promising preliminary results from the classification of a reduced set of protocols.",Traffic classification; Transport layer,Internet protocols; Classical techniques; Classification algorithm; Classification technique; Flow classification; Inter-arrival time; Management platforms; Traffic classification; Transport layers; Telecommunication traffic
"Bürklin H., Schäfer R., Westerkamp D.",3,DVB: From broadcasting to IP delivery,2007,6,"Thomson R and D France 1, Avenue Belle-Fontaine - CS17616, 35576 Cesson-Sévigné, France; Deutsche Thomson, Karl-Wiechert-Allee 74, 30625 Hannover, Germany",Thomson Research,1,France;Germany,2,17,5,"This paper gives a brief overview of the Digital Video Broadcasting (DVB) project. Starting in 1993, this project produced standards for digital broadcasting in all media (satellite, cable, terrestrial) using return channels of various kinds. In the current phase, DVB has also embraced Internet Protocol (IP) based delivery on telco and cable.",Dvb; H.264; IPDC; IPTV; MPEG2-TS,Current phase; Digital Broadcasting; Dvb; H.264; IPDC; MPEG2-TS; Return channels; Cables; Internet protocols; IPTV; Digital video broadcasting (DVB)
"Krioukov D., Chung F., Claffy K.C., Fomenkov M., Vespignani A., Willinger W.",6,The Workshop on Internet Topology (WIT) Report,2007,41,"CAIDA, United States; UCSD, United States; Indiana University, United States; AT and T Research, United States",AT and T Labs;Indiana University,2,India;USA,2,28,22,"Internet topology analysis has recently experienced a surge of interest in computer science, physics, and the mathematical sciences. However, researchers from these different disciplines tend to approach the same problem from different angles. As a result, the field of Internet topology analysis and modeling must untangle sets of inconsistent findings, conflicting claims, and contradicting statements. On May 10-12, 2006, CAIDA hosted the Workshop on Internet topology (WIT). By bringing together a group of researchers spanning the areas of computer science, physics, and the mathematical sciences, the workshop aimed to improve communication across these scientific disciplines, enable interdisciplinary cross-fertilization, identify commonalities in the different approaches, promote synergy where it exists, and utilize the richness that results from exploring similar problems from multiple perspectives. This report describes the findings of the workshop, outlines a set of relevant open research problems identified by participants, and concludes with recommendations that can benefit all scientific communities interested in Internet topology research.",Internet topology,Internet topologies; Mathematical science; Research problems; Scientific community; Scientific discipline; Computer science; Internet; Research; Topology
"Neumann C., Prigent N., Varvello M., Suh K.",4,Challenges in peer-to-peer gaming,2007,22,"Thomson Research Lab., Paris, France; Thomson Security Research Lab., Rennes, France; Eurecom, Sophia-Antipolis, France; University of Massachusetts, Amherst, United States",EURECOM;Thomson Research;University of Massachusetts Amherst,3,France;USA,2,15,12,"While multi-player online games are very successful, their fast deployment suffers from their server-based architecture. Indeed, servers both limit the scalability of the games and increase deployment costs. However, they make it easier to control the game (e.g. by preventing cheating and providing support for billing). Peer-to-peer, i.e. transfer of the game functions on each each player's machine, is an attractive communication model for online gaming. We investigate here the challenges of peer-to-peer gaming, hoping that this discussion will generate a broader interest in the research community.",Overlay Online-gaming; Peer-to-Peer; Security,Communication models; Deployment costs; Fast deployments; Multi-player online games; Overlay Online-gaming; Peer to peer; Research communities; Security; Communication; Information theory
Jiang S.,1,An addressing independent networking structure favorable for all-optical packet switching,2007,7,"School of Electronic and Information Engineering, South China University of Technology, China",South China University of Technology,1,China,1,45,28,"All-optical packet switching (AOPS) technology is essential to fully utilize the tremendous bandwidth provided by advanced optical communication techniques through forwarding packets in optical domain for the next generation network. However, long packet headers and other complex operations such as table lookup and packet header re-writing still have to be processed electronically for lack of cost-effective optical processing techniques. This not only increases system complexity but also limits packet forwarding speed due to optical-electronic-optical conversion. Lots of work of improving optical processing techniques to realize AOPS is reported in the literature. Differently, this paper proposes a new networking structure to facilitate AOPS realization and support various existing networks through simplifying networking operations. This structure only requires an AOPS node to process a short packet header to forward packets across it with neither table lookup nor header re-writing. Furthermore, it moves high layer addressing issues from packet forwarding mechanisms of routers. Consequently, any changes in addressing schemes such as address space extension do not require changes in the AOPS nodes. It can also support both connection-oriented and connectionless services to carry various types of traffic such as ATM and IP traffic. This structure is mainly based on the hierarchical source routing approach. The analytical results show that average packet header sizes are still acceptable even for long paths consisting of many nodes each of which has a large number of output ports.",All-optical packet switching (AOPS); Hierarchical source routing and addressing transparency; Networking structure,All optical packet switching; Analytical results; Communication techniques; Complex operations; Networking structure; Optical processing; Optical-electronic-optical conversion; Source routing; Advanced traffic management systems; Air traffic control; Complex networks; Table lookup; Optical communication
"Feamster N., Gao L., Rexford J.",3,How to lease the internet in your spare time,2007,428,"Georgia Tech., United States; University of Massachusetts, United States; Princeton University, United States",Georgia Tech;Princeton University;University of Massachusetts Amherst,3,USA,1,14,12,"Today's Internet Service Providers (ISPs) serve two roles: managing their network infrastructure and providing (arguably limited) services to end users. We argue that coupling these roles impedes the deployment of new protocols and architectures, and that the future Internet should support two separate entities: infrastructure providers (who manage the physical infrastructure) and service providers (who deploy network protocols and offer end-to-end services). We present a high-level design for Cabo, an architecture that enables this separation; we also describe challenges associated with realizing this architecture.",Design; Management,End users; End-to-end service; Future internet; High-level design; Infrastructure providers; Network infrastructure; New protocol; Service provider; Architecture; Design; Internet protocols; Management; Network architecture; Network protocols; Separation; Internet service providers
"Salgarelli L., Gringoli F., Karagiannis T.",3,Comparing traffic classifiers,2007,26,"DEA, Università degli Studi, Brescia, Italy; Microsoft Research, Cambridge, United Kingdom",Microsoft;Università Degli Studi di Brescia,2,Italy;UK,2,10,7,"Many reputable research groups have published several interesting papers on traffic classification, proposing mechanisms of different nature. However, it is our opinion that this community should now find an objective and scientific way of comparing results coming out of different groups. We see at least two hurdles before this can happen. A major issue is that we need to find ways to share full-payload data sets, or, if that does not prove to be feasible, at least anonymized traces with complete application layer meta-data. A relatively minor issue refers to finding an agreement on which metric should be used to evaluate the performance of the classifiers. In this note we argue that these are two important issues that the community should address, and sketch a few solutions to foster the discussion on these topics.",Measurement; Traffic classification; Transport layer,Communication; Measurements; Application layers; Payload data; Research groups; Traffic classification; Traffic classifiers; Transport layers; Telecommunication traffic
"Xu W., Rexford J.",2,MIRO: Multi-path interdomain ROuting,2006,91,"Department of Computer Science, Princeton University, United States",Princeton University,1,USA,1,30,27,"The Internet consists of thousands of independent domains with different, and sometimes competing, business interests. However, the current interdomain routing protocol (BGP) limits each router to using a single route for each destination prefix, which may not satisfy the diverse requirements of end users. Recent proposals for source routing offer an alternative where end hosts or edge routers select the end-to-end paths. However, source routing leaves transit domains with very little control and introduces difficult scalability and security challenges. In this paper, we present a multi-path interdomain routing protocol called MIRO that offers substantial flexibility, while giving transit domains control over the flow of traffic through their infrastructure and avoiding state explosion in disseminating reachability information. In MIRO, routers learn default routes through the existing BGP protocol, and arbitrary pairs of domains can negotiate the use of additional paths (bound to tunnels in the data plane) tailored to their special needs. MIRO retains the simplicity of BGP for most traffic, and remains backwards compatible with BGP to allow for incremental deployability. Experiments with Internet topology and routing data illustrate that MIRO offers tremendous flexibility for path selection with reasonable overhead. Copyright 2006 ACM.",BGP; Flexibility; Inter-domain routing; Multipath routing; Scalability,Edge routers; Internet topology; Routing protocol; Source routing; Information dissemination; Internet; Multipath propagation; Security systems; Telecommunication traffic; User interfaces; Routers
"Yu H., Kaminsky M., Gibbons P.B., Flaxman A.",4,SybilGuard: Defending against sybil attacks via social networks,2006,332,"Intel Research Pittsburgh, United States; Carnegie Mellon University, United States",Carnegie Mellon University;Intel,2,USA,1,27,27,"Peer-to-peer and other decentralized, distributed systems are known to be particularly vulnerable to sybil attacks. In a sybil attack, a malicious user obtains multiple fake identities and pretends to be multiple, distinct nodes in the system. By controlling a large fraction of the nodes in the system, the malicious user is able to ""out vote"" the honest users in collaborative tasks such as Byzantine failure defenses. This paper presents SybilGuard, a novel protocol for limiting the corruptive influences of sybil attacks. Our protocol is based on the ""social network"" among user identities, where an edge between two identities indicates a human-established trust relationship. Malicious users can create many identities but few trust relationships. Thus, there is a disproportionately-small ""cut"" in the graph between the sybil nodes and the honest nodes. SybilGuard exploits this property to bound the number of identities a malicious user can create. We show the effectiveness of SybilGuard both analytically and experimentally. Copyright 2006 ACM.",Social networks; Sybil attack; Sybil identity; SybilGuard,Social networks; Sybil attack; Sybil Guard; Sybil identity; Computer crime; Computer supported cooperative work; Distributed computer systems; Identification (control systems); Network protocols; User interfaces; Telecommunication networks
"Reis C., Mahajan R., Rodrig M., Wetherall D., Zahorjan J.",5,Measurement-based models of delivery and interference in static wireless networks,2006,146,"University of Washington, United States; Microsoft Research",Microsoft;University of Washington at St. Louis,2,USA,1,20,17,"We present practical models for the physical layer behaviors of packet reception and carrier sense with interference in static wireless networks. These models use measurements of a real network rather than abstract RF propagation models as the basis for accuracy in complex environments. Seeding our models requires N trials in an N node network, in which each sender transmits in turn and receivers measure RSSI values and packet counts, both of which are easily obtainable. The models then predict packet delivery and throughput in the same network for different sets of transmitters with the same node placements. We evaluate our models for the base case of two senders that broadcast packets simultaneously. We find that they are effective at predicting when there will be significant interference effects. Across many predictions, we obtain an RMS error for 802.11a and 802.11b of a half and a third, respectively, of a measurement-based model that ignores interference. Copyright 2006 ACM.",Interference; Modeling; RSSI,Packet delivery; RF propagation; RMS error; Static wireless networks; Computer simulation; Electromagnetic wave propagation; Error analysis; Mathematical models; Signal interference; Signal receivers; Wireless telecommunication systems
"Caesar M., Castro M., Nightingale E.B., O'Shea G., Rowstron A.",5,Virtual ring routing: Network routing inspired by DHTs,2006,155,"Microsoft Research, Cambridge, United Kingdom; University of California Berkeley, Berkeley, United States; University of Michigan, Ann Arbor, United States",Microsoft;University of California Berkeley;University of Michigan at Ann Arbor,3,UK;USA,2,44,38,"This paper presents Virtual Ring Routing (VRR), a new network routing protocol that occupies a unique point in the design space. VRR is inspired by overlay routing algorithms in Distributed Hash Tables (DHTs) but it does not rely on an underlying network routing protocol. It is implemented directly on top of the link layer. VRR provides both traditional point-to-point network routing and DHT routing to the node responsible for a hash table key. VRR can be used with any link layer technology but this paper describes a design and several implementations of VRR that are tuned for wireless networks. We evaluate the performance of VRR using simulations and measurements from a sensor network and an 802.11a testbed. The experimental results show that VRR provides robust performance across a wide range of environments and workloads. It performs comparably to, or better than, the best wireless routing protocol in each experiment. VRR performs well because of its unique features: it does not require network flooding or translation between fixed identifiers and location-dependent addresses. Copyright 2006 ACM.",Distributed hash table; Network routing; Wireless,Algorithms; Computer aided design; Computer simulation; Network protocols; Telecommunication links; Telecommunication networks; Wireless telecommunication systems; Distributed hash tables (DHT); Network routing; Virtual ring routing; Wireless networks; Routers
"Ganjali Y., McKeown N.",2,Update on buffer sizing in internet routers,2006,48,"Dept. of Electrical Engineering, Stanford University, Stanford, CA 94305, United States",Stanford University,1,USA,1,17,14,"In the past two years, several papers have proposed rules that suggest two to five orders of magnitude reduction in Internet core router buffers. Others present scenarios where buffer sizes need to be significantly increased. So why the different rules? In this paper we briefly compare the different results and proposals, and summarize some recent preliminary experiments to validate the proposals. We'll see that different results apply to different parts of the network, and depend on several assumptions. For example, we believe that buffers can be safely reduced by an order of magnitude in the routers in service provider backbone networks; but it would be premature to reduce them in routers closer to the edge.",All-optical routers; Buffer size; Congestion control; Tcp,Congestion control (communication); Internet; Routers; Telecommunication networks; Buffer sizing; Internet core router buffers; Service provider; Buffer storage
"Chan H., Dash D., Perrig A., Zhang H.",4,Modeling adoptability of secure BGP protocols,2006,20,"Carnegie Mellon University, United States",Carnegie Mellon University,1,USA,1,22,20,"Despite the existence of several secure BGP routing protocols, there has been little progress to date on actual adoption. Although feasibility for widespread adoption remains the greatest hurdle for BGP security, there has been little quantitative research into what properties contribute the most to the adoptability of a security scheme. In this paper, we provide a model for assessing the adoptability of a secure BGP routing protocol. We perform this evaluation by simulating incentives compatible adoption decisions of ISPs on the Internet under a variety of assumptions. Our results include: (a) the existence of a sharp threshold, where, if the cost of adoption is below the threshold, complete adoption takes place, while almost no adoption takes place above the threshold; (b) under a strong attacker model, adding a single hop of path authentication to origin authentication yields similar adoptability characteristics as a full path security scheme; (c) under a weaker attacker model, adding full path authentication (e.g., via S-BGP [9]) significantly improves the adoptability of BGP security over weaker path security schemes such as soBGP [16]. These results provide insight into the development of more adoptable secure BGP protocols and demonstrate the importance of studying adoptability of protocols. Copyright 2006 ACM.",Adoptability; Adoption dynamics; Incentives-compatibility,Adoptability; Adoption dynamics; BGP security; Incentives compatibility; Computer crime; Computer simulation; Decision theory; Mathematical models; Routers; Security systems; Network protocols
"Cheng Y.-C., Bellardo J., Benkö P., Snoeren A.C., Voelker G.M., Savage S.",6,Jigsaw: Solving the puzzle of enterprise 802.11 analysis,2006,105,"Department of Computer Science and Engineering, University of California, San Diego, United States; Traffic Analyis and Network Performance Laboratory (TrafficLab), Ericsson Research, Budapest, Hungary",Ericsson Research;University of California San Diego,2,Hungary;USA,2,26,23,"The combination of unlicensed spectrum, cheap wireless interfaces and the inherent convenience of untethered computing have made 802.11-based networks ubiquitous in the enterprise. Modern universities, corporate campuses and government offices routinely deploy scores of access points to blanket their sites with wireless Internet access. However, while the fine-grained behavior of the 802.11 protocol itself has been well studied, our understanding of how large 802.11 networks behave in their full empirical complexity is surprisingly limited. In this paper, we present a system called Jigsaw that uses multiple monitors to provide a single unified view of all physical, link, network and transport-layer activity on an 802.11 network. To drive this analysis, we have deployed an infrastructure of over 150 radio monitors that simultaneously capture all 802.11b and 802.11g activity in a large university building (1M+cubic feet). We describe the challenges posed by both the scale and ambiguity inherent in such an architecture, and explain the algorithms and inference techniques we developed to address them. Finally, using a 24-hour distributed trace containing more than 1.5 billion events, we use Jigsaw's global cross-layer viewpoint to isolate performance artifacts, both explicit, such as management inefficiencies, and implicit, such as co-channel interference. We believe this is the first analysis combining this scale and level of detail for a production 802.11 network. Copyright 2006 ACM.","Measurement; Monitoring; Wireless networks, 802.11",Co-channel interference; Global cross-layer; Wireless interfaces; Wireless Internet access; Algorithms; Interfaces (computer); Network protocols; Signal interference; Telecommunication links; Wireless telecommunication systems; Problem solving
"Caesar M., Condie T., Kannan J., Lakshminarayanan K., Stoica I., Shenker S.",6,ROFL: Routing on flat labels,2006,127,"University of California, Berkeley, United States",University of California Berkeley,1,USA,1,48,40,"It is accepted wisdom that the current Internet architecture conflates network locations and host identities, but there is no agreement on how a future architecture should distinguish the two. One could sidestep this quandary by routing directly on host identities themselves, and eliminating the need for network-layer protocols to include any mention of network location. The key to achieving this is the ability to route on flat labels. In this paper we take an initial stab at this challenge, proposing and analyzing our ROFL routing algorithm. While its scaling and efficiency properties are far from ideal, our results suggest that the idea of routing on flat labels cannot be immediately dismissed. Copyright 2006 ACM.",Internet architecture; Naming; Routing,Internet architecture; Naming; ROFL routing algorithms; Routing; Algorithms; Communication systems; Computer architecture; Internet; Network protocols; Telecommunication networks; Routers
"Su A.-J., Kuzmanovic A., Choffnes D.R., Bustamante F.E.",4,Drafting behind Akamai (travelocity-based detouring),2006,73,"Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL 60208, United States",Northwestern University,1,USA,1,36,27,"To enhance web browsing experiences, content distribution networks (CDNs) move web content ""closer"" to clients by caching copies of web objects on thousands of servers worldwide. Additionally, to minimize client download times, such systems perform extensive network and server measurements, and use them to redirect clients to different servers over short time scales. In this paper, we explore techniques for inferring and exploiting network measurements performed by the largest CDN, Akamai; our objective is to locate and utilize quality Internet paths without performing extensive path probing or monitoring. Our contributions are threefold. First, we conduct a broad measurement study of Akamai's CDN. We probe Akamai's network from 140 PlanetLab vantage points for two months. We find that Akamai redirection times, while slightly higher than advertised, are sufficiently low to be useful for network control. Second, we empirically show that Akamai redirections overwhelmingly correlate with network latencies on the paths between clients and the Akamai servers. Finally, we illustrate how large-scale overlay networks can exploit Akamai redirections to identify the best detouring nodes for one-hop source routing. Our research shows that in more than 50% of investigated scenarios, it is better to route through the nodes ""recommended"" by Akamai, than to use the direct paths. Because this is not the case for the rest of the scenarios, we develop low-overhead pruning algorithms that avoid Akamai-driven paths when they are not beneficial. Copyright 2006 ACM.",Akamai; CDN; DNS; Edge server; Measurement reuse; One-hop source routing,Algorithms; Internet; Routers; Servers; Telecommunication networks; World Wide Web; Akamai; Content distribution networks (CDN); DNS; Edge servers; Measurement reuse; One hop source routing; Web browsers
"Wang H., Xie H., Qiu L., Yang R., Zhang Y., Greenberg A.",6,COPE: Traffic engineering in dynamic networks,2006,68,"AT and T Labs - Research, United States; Univ. of Texas at Austin, United States; Yale University, United States",AT and T Labs;University of Texas at Austin;Yale University,3,USA,1,54,47,"Traffic engineering plays a critical role in determining the performance and reliability of a network. A major challenge in traffic engineering is how to cope with dynamic and unpredictable changes in traffic demand. In this paper, we propose COPE, a class of traffic engineering algorithms that optimize for the expected scenarios while providing a worst-case guarantee for unexpected scenarios. Using extensive evaluations based on real topologies and traffic traces, we show that COPE can achieve efficient resource utilization and avoid network congestion in a wide variety of scenarios. Copyright 2006 ACM.",COPE; Oblivious routing; Optimization; Traffic engineering; Unpredictable traffic,COPE; Oblivious routing; Traffic engineering; Unpredictable traffic; Algorithms; Congestion control (communication); Optimization; Reliability; Topology; Telecommunication traffic
"Gkantsidis C., Karagiannis T., Rodriguez P., Vojnović M.",4,Planet scale software updates,2006,39,"Microsoft Research, Cambridge, United Kingdom; UC Riverside, Riverside, CA, United States",Microsoft;University of California Riverside,2,UK;USA,2,27,17,"Fast and effective distribution of software updates (a.k.a. patches) to millions of Internet users has evolved into a critical task over the last years. In this paper, we characterize ""Windows Update"", one of the largest update services in the world, with the aim to draw general guidelines on how to best design and architect a fast and effective planet-scale patch dissemination system. To this end, we analyze an extensive set of data traces collected over the period of a year, consisting of billions of queries from over 300 million computers. Based on empirical observations and analytical results, we identify interesting properties of today's update traffic and user behavior. Building on this analysis, we consider alternative patch delivery strategies such as caching and peer-to-peer and evaluate their performance. We identify key factors that determine the effectiveness of these schemes in reducing the server workload and the network traffic, and in speeding-up the patch delivery. Most of our findings are invariant properties induced by either user behavior or architectural characteristics of today's Internet, and thus apply to the general problem of Internet-wide dissemination of software updates. Copyright 2006 ACM.",Caching; Peer-to-peer; Software updates,Computer architecture; Distributed computer systems; Information dissemination; Internet; Telecommunication networks; Telecommunication traffic; User interfaces; Caching; Network traffic; Peer to peer; Software updates; Software engineering
"Kohler E., Handley M., Floyd S.",3,Designing DCCP: Congestion control without reliability,2006,69,"UCLA, United States; University College London, United Kingdom; ICSI Center for Internet Research, United States",University of California Berkeley;University College London,2,UK;USA,2,48,39,"Fast-growing Internet applications like streaming media and telephony prefer timeliness to reliability, making TCP a poor fit. Unfortunately, UDP, the natural alternative, lacks congestion control. High-bandwidth UDP applications must implement congestion control themselves - a difficult task - or risk rendering congested networks unusable. We set out to ease the safe deployment of these applications by designing a congestion-controlled unreliable transport protocol. The outcome, the Datagram Congestion Control Protocol or DCCP, adds to a UDP-like foundation the minimum mechanisms necessary to support congestion control. We thought those mechanisms would resemble TCP's, but without reliability and, especially, cumulative acknowledgements, we had to reconsider almost every aspect of TCP's design. The resulting protocol sheds light on how congestion control interacts with unreliable transport, how modern network constraints impact protocol design, and how TCP's reliable bytestream semantics intertwine with its other mechanisms, including congestion control. Copyright 2006 ACM.",Congestion control; DCCP; Internet telephony; Streaming media; TCP; Transport protocols; Unreliable transfer,DCCP; Streaming media; Transport protocols; Unreliable transfer; Congestion control (communication); Constraint theory; Network protocols; Semantics; Internet telephony
"Ratnasamy S., Ermolinskiy A., Shenker S.",3,Revisiting IP multicast,2006,58,"Intel Research; U.C. Berkeley, United States; U.C. Berkeley, ICSI, United States",Intel;University of California Berkeley,2,USA,1,47,33,This paper revisits a much explored topic in networking - the search for a simple yet fully- general multicast design. The many years of research into multicast routing have led to a generally pessimistic view that the complexity of multicast routing - and inter-domain multicast routing in particular - can only be overcome by restricting the service model (as in single-source) multicast. This paper proposes a new approach to implementing IP multicast that we hope leads to a reevaluation of this commonly held view. Copyright 2006 ACM.,Multicast; Routing,Multicast design; Multicast routing; Computational complexity; Internet; Mathematical models; Network protocols; Routers; Multicasting
"Sung Y.-W., Bishop M., Rao S.",3,Enabling contribution awareness in an overlay broadcasting system,2006,14,"Department of Electrical and Computer Engineering, Purdue University, United States",Purdue University,1,USA,1,27,25,"We consider the design of bandwidth-demanding broadcasting applications using overlays in environments characterized by hosts with limited and asymmetric bandwidth, and significant heterogeneity in outgoing bandwidth. Such environments are critical to consider to extend the applicability of overlay multicast to mainstream Internet environments where insufficient bandwidth exists to support all hosts, but have not received adequate attention from the research community. We leverage the multi-tree framework and design heuristics to enable it to consider host contribution and operate in bandwidth-scarce environments. Our extensions seek to simultaneously achieve good utilization of system resources, performance to hosts commensurate to their contributions, and consistent performance. We have implemented the system and conducted an Internet evaluation on Planet-Lab using real traces from previous operational deployments of an overlay broadcasting system. Our results indicate for these traces, our heuristics can improve the performance of high contributors by 10-240% and facilitate equitable band-width distribution among hosts with similar contributions. Copyright 2006 ACM.",Incentive; Multi-tree; Overlay multicast,Broadcasting systems; Incentives; Multi tree; Overlay multicasts; Bandwidth; Communication systems; Computer aided design; Heuristic methods; Internet; Multicasting; Broadcasting
"Varghese G., Andrew Fingerhut J., Bonomi F.",3,Detecting evasion attacks at high speeds without reassembly,2006,19,"Cisco Systems, UCSD, United States; Cisco Systems",Cisco;University of California San Diego,2,USA,1,17,12,"Ptacek and Newsham [14] showed how to evade signature detection at Intrusion Prevention Systems (IPS) using TCP and IP Fragmentation. These attacks are implemented in tools like FragRoute, and are institutionalized in IPS product tests. The classic defense is for the IPS to reassemble TCP and IP packets, and to consistently normalize the output stream. Current IPS standards require keeping state for 1 million connections. Both the state and processing requirements of reassembly and normalization are barriers to scalability for an IPS at speeds higher than 10 Gbps. In this paper, we suggest breaking with this paradigm using an approach we call Split-Detect. We focus on the simplest form of signature, an exact string match, and start by splitting the signature into pieces. By doing so the attacker is either forced to include at least one piece completely in a packet, or to display potentially abnormal behavior (e.g., several small TCP fragments or out-of-order packets) that cause the attacker's flow to be diverted to a slow path. We prove that under certain assumptions this scheme can detect all byte-string evasions. We also show using real traces that the processing and storage requirements of this scheme can be 10% of that required by a conventional IPS, allowing reasonable cost implementations at 20 Gbps. While the changes required by Split-Detect may be a barrier to adoption, this paper exposes the assumptions that must be changed to avoid normalization and reassembly in the fast path. Copyright 2006 ACM.",Evasion attacks; Normalization; TCP reassembly,Evasion attacks; Intrusion Prevention Systems (IPS); Normalization; TCP reassembly; Computer crime; Cost accounting; Data processing; Packet networks; Routers; Security systems; Demodulation
"Rangwala S., Gummadi R., Govindan R., Psounis K.",4,Interference-aware fair rate control in wireless sensor networks,2006,166,"University of Southern California, United States",University of Southern California,1,USA,1,35,4,"In a wireless sensor network of N nodes transmitting data to a single base station, possibly over multiple hops, what distributed mechanisms should be implemented in order to dynamically allocate fair and efficient transmission rates to each node? Our interference-aware fair rate control (IFRC) detects incipient congestion at a node by monitoring the average queue length, communicates congestion state to exactly the set of potential interferers using a novel low-overhead congestion sharing mechanism, and converges to a fair and efficient rate using an AIMD control law. We evaluate IFRC extensively on a 40-node wireless sensor network testbed. IFRC achieves a fair and efficient rate allocation that is within 20-40% of the optimal fair rate allocation on some network topologies. Its rate adaptation mechanism is highly effective: we did not observe a single instance of queue overflow in our many experiments. Finally, IFRC can be extended easily to support situations where only a subset of the nodes transmit, where the network has multiple base stations, or where nodes are assigned different transmission weights. Copyright 2006 ACM.",Congestion control; Fairness; IFRC; Rate control; Sensor network; Wireless,Interference-aware fair rate control (IFRC); Rate control; Sensor network; Congestion control (communication); Data communication systems; Distributed computer systems; Queueing networks; Signal interference; Wireless telecommunication systems
"Mahajan R., Rodrig M., Wetherall D., Zahorjan J.",4,Analyzing the MAC-level behavior of wireless networks in the wild,2006,60,"Microsoft Research; University of Washington, United States",Microsoft;University of Washington at St. Louis,2,USA,1,29,28,"We present Wit, a non-intrusive tool that builds on passive monitoring to analyze the detailed MAC-level behavior of operational wireless networks. Wit uses three processing steps to construct an enhanced trace of system activity. First, a robust merging procedure combines the necessarily incomplete views from multiple, independent monitors into a single, more complete trace of wireless activity. Next, a novel inference engine based on formal language methods reconstructs packets that were not captured by any monitor and determines whether each packet was received by its destination. Finally, Wit derives network performance measures from this enhanced trace; we show how to estimate the number of stations competing for the medium. We assess Wit with a mix of real traces and simulation tests. We find that merging and inference both significantly enhance the originally captured trace. We apply Wit to multi-monitor traces from a live network to show how it facilitates 802.11 MAC analyses that would otherwise be difficult or rely on less accurate heuristics. Copyright 2006 ACM.",802.11 MAC; Measurement tool; Passive monitoring,802.11 MAC; Measurement tool; Passive monitoring; Formal languages; Heuristic methods; Robustness (control systems); Signal interference; Wireless telecommunication systems; Network protocols
"Fournié L., Hong D., Perisse F.",3,NetScale: Scalable time-stepped hybrid simulation of large IP networks,2006,3,"N2NSoft, 11 bd Sébastopol, 75001, Paris, France","N2NSoft,France",1,France,1,11,10,"This paper presents a scalable time-stepped hybrid simulation algorithm which is well adapted to the simulation of large IP networks (up to one million of competing flows and network elements), while tracking reactive traffic behaviour and packet-level phenomena e.g. timeout trigger or packet burstiness. This simulation paradigm allows one to gain several orders of magnitude of computation time compared to traditional discrete event simulation approaches. The accuracy of this simulation method is evaluated by comparison to other simulation methodologies. Examples of large scale network simulations are also presented.",Congestion control; Discrete event simulation; Scheduling; TCP/UDP traffic; Time-stepped hybrid simulation,Algorithms; Computer simulation; Congestion control (communication); Internet; Network protocols; Telecommunication traffic; Discrete event simulation; TCP/UDP traffic; Time-stepped hybrid simulation; Telecommunication networks
"Yang X., Wetherall D.",2,Source selectable path diversity via routing deflections,2006,79,"University of California, Irvine, United States; University of Washington, United States",University of California Irvine;University of Washington at St. Louis,2,USA,1,28,21,"We present the design of a routing system in which end-systems set tags to select non-shortest path routes as an alternative to explicit source routes. Routers collectively generate these routes by using tags as hints to independently deflect packets to neighbors that lie off the shortest-path. We show how this can be done simply, by local extensions of the shortest path machinery, and safely, so that loops are provably not formed. The result is to provide end-systems with a high-level of path diversity that allows them to bypass undesirable locations within the network. Unlike explicit source routing, our scheme is inherently scalable and compatible with ISP policies because it derives from the deployed Internet routing. We also suggest an encoding that is compatible with common IP usage, making our scheme incrementally deployable at the granularity of individual routers. Copyright 2006 ACM.",Path diversity; Routing deflections; Source routing,End systems; ISP policies; Routing deflections; Source routing; Source selectable path diversity; Communication systems; Computer aided design; Computer systems; Internet; Network protocols; Packet switching; Routers
"Kumar S., Dharmapurikar S., Yu F., Crowley P., Turner J.",5,Algorithms to accelerate multiple regular expressions matching for deep packet inspection,2006,297,"Washington University, Computer Science and Engineering, St. Louis, MO 63130-4899, United States; University of California, Berkeley, Department of Computer Science, Berkeley, CA 94720, United States",University of California Berkeley;University of Washington at St. Louis,2,USA,1,39,16,"There is a growing demand for network devices capable of examining the content of data packets in order to improve network security and provide application-specific services. Most high performance systems that perform deep packet inspection implement simple string matching algorithms to match packets against a large, but finite set of strings. However, there is growing interest in the use of regular expression-based pattern matching, since regular expressions offer superior expressive power and flexibility. Deterministic finite automata (DFA) representations are typically used to implement regular expressions. However, DFA representations of regular expression sets arising in network applications require large amounts of memory, limiting their practical application. In this paper, we introduce a new representation for regular expressions, called the Delayed Input DFA (D 2FA), which substantially reduces space requirements as compared to a DFA. A D 2FA is constructed by transforming a DFA via incrementally replacing several transitions of the automaton with a single default transition. Our approach dramatically reduces the number of distinct transitions between states. For a collection of regular expressions drawn from current commercial and academic systems, a D 2FA representation reduces transitions by more than 95%. Given the substantially reduced space requirements, we describe an efficient architecture that can perform deep packet inspection at multi-gigabit rates. Our architecture uses multiple on-chip memories in such a way that each remains uniformly occupied and accessed over a short duration, thus effectively distributing the load and enabling high throughput. Our architecture can provide cost-effective packet content scanning at OC-192 rates with memory requirements that are consistent with current ASIC technology. Copyright 2006 ACM.",Deep packet inspection; DFA; Regular expressions,Deep packet inspection; Delayed Input DFA; Deterministic finite automata (DFA); Regular expressions; Computer architecture; Microprocessor chips; Packet networks; Pattern matching; Security systems; Telecommunication networks; Algorithms
"Bonomi F., Mitzenmacher M., Panigrahy R., Singh S., Varghese G.",5,Beyond bloom filters: From approximate membership checks to approximate state machines,2006,83,"Cisco Systems, Inc.; Harvard University, United States; Stanford University, United States; Cisco Systems, Inc., UCSD, United States",Harvard University;Stanford University,2,USA,1,24,19,"Many networking applications require fast state lookups in a concurrent state machine, which tracks the state of a large number of flows simultaneously. We consider the question of how to compactly represent such concurrent state machines. To achieve compactness, we consider data structures for Approximate Concurrent State Machines (ACSMs) that can return false positives, false negatives, or a ""don't know"" response. We describe three techniques based on Bloom filters and hashing, and evaluate them using both theoretical analysis and simulation. Our analysis leads us to an extremely efficient hashing-based scheme with several parameters that can be chosen to trade off space, computation, and the impact of errors. Our hashing approach also yields a simple alternative structure with the same functionality as a counting Bloom filter that uses much less space. We show how ACSMs can be used for video congestion control. Using an ACSM, a router can implement sophisticated Active Queue Management (AQM) techniques for video traffic (without the need for standards changes to mark packets or change video formats), with a factor of four reduction in memory compared to full-state schemes and with very little error. We also show that ACSMs show promise for real-time detection of P2P traffic. Copyright 2006 ACM.",Bloom filters; Network flows; State machines,Bloom filters; Network flows; State machines; Video traffic; Computational methods; Computer networks; Computer simulation; Congestion control (communication); Error analysis; Routers; Telecommunication traffic; Concurrent engineering
"Godfrey P.B., Shenker S., Stoica I.",3,Minimizing churn in distributed systems,2006,85,"UC Berkeley, Computer Science Division, United States",University of California Berkeley,1,USA,1,39,34,"A pervasive requirement of distributed systems is to deal with churn - change in the set of participating nodes due to joins, graceful leaves, and failures. A high churn rate can increase costs or decrease service quality. This paper studies how to reduce churn by selecting which subset of a set of available nodes to use. First, we provide a comparison of the performance of a range of different node selection strategies in five real-world traces. Among our findings is that the simple strategy of picking a uniform-random replacement whenever a node fails performs surprisingly well. We explain its performance through analysis in a stochastic model. Second, we show that a class of strategies, which we call ""Preference List"" strategies, arise commonly as a result of optimizing for a metric other than churn, and produce high churn relative to more randomized strategies under realistic node failure patterns. Using this insight, we demonstrate and explain differences in performance for designs that incorporate varying degrees of randomization. We give examples from a variety of protocols, including anycast, overlay multicast, and distributed hash tables. In many cases, simply adding some randomization can go a long way towards reducing churn. Copyright 2006 ACM.",Churn; DHT; Multicast; Node selection,Churn; Node selection; Realistic node failure patterns; Stochastic models; Uniform random replacement; Computational methods; Computer aided design; Mathematical models; Multicasting; Optimization; Quality of service; Distributed computer systems
"Qiu L., Bahl P., Rao A., Zhou L.",4,Troubleshooting wireless mesh networks,2006,36,"Univ. of Texas, Austin, United States; Microsoft Research; UC Berkely, United States",Microsoft;University of California Berkeley;University of Texas at Austin,3,USA,1,21,10,"Effective network troubleshooting is critical for maintaining efficient and reliable network operation. Troubleshooting is especially challenging in multi-hop wireless networks because the behavior of such networks depends on complicated interactions between many factors such as RF noise, signal propagation, node interference, and traffic flows. In this paper we propose a new direction for research on fault diagnosis in wireless mesh networks. Specifically, we present a diagnostic system that employs trace-driven simulations to detect faults and perform root cause analysis. We apply this approach to diagnose performance problems caused by packet dropping, link congestion, external noise, and MAC misbehavior. In a 25 node mesh network, we are able to diagnose over 10 simultaneous faults of multiple types with more than 80% coverage.",Fault diagnosis; Mesh networks; Simulation,External noise; Fault diagnosis; Link congestion; Mesh networks; Acoustic noise; Fault tolerant computer systems; Natural frequencies; Problem solving; Signal interference; Signal processing; Telecommunication links; Wireless telecommunication systems
"Zhao Y., Chen Y., Bindel D.",3,Towards unbiased end-to-end network diagnosis,2006,26,"Northwestern University, United States; University of California, Berkeley, United States",Northwestern University;University of California Berkeley,2,USA,1,28,24,"Internet fault diagnosis is extremely important for end users, overlay network service providers (like Akamai [1]) and even Internet service providers (ISPs). However, because link-level properties cannot be uniquely determined from end-to-end measurements, the accuracy of existing statistical diagnosis approaches is subject to uncertainty from statistical assumptions about the network. In this paper, we propose a novel Least-biased End-to-end Network Diagnosis (in short, LEND) system for inferring link-level properties like loss rate. We define a minimal identifiable link sequence (MILS) as a link sequence of minimal length whose properties can be uniquely identified from end-to-end measurements. We also design efficient algorithms to find all the MILSes and infer their loss rates for diagnosis. Our LEND system works for any network topology and for both directed and undirected properties, and incrementally adapts to network topology and property changes. It gives highly accurate estimates of the loss rates of MILSes, as indicated by both extensive simulations and Internet experiments. Furthermore, we demonstrate that such diagnosis can be achieved with fine granularity and in near real-time even for reasonably large overlay networks. Finally, LEND can supplement existing statistical inference approaches and provide smooth tradeoff between diagnosis accuracy and granularity. Copyright 2006 ACM.",Internet diagnosis; Linear algebra; Network measurement,Internet fault diagnosis; Internet service providers (ISP); Minimal identifiable link sequence (MILS); Network measurement; Algorithms; Computer aided design; Computer simulation; Network protocols; Telecommunication links; User interfaces; Internet
"Menth M., Martin R., Charzinski J.",3,Capacity overprovisioning for networks with resilience requirements,2006,14,"Department of Distributed Systems, Institute of Computer Science, University of Würzburg, Germany; Siemens AG, Munich, Germany",Institute of Computer Science;University of Wurzburg,2,Germany,1,42,34,"This work focuses on capacity overprovisioning (CO) as an alternative to admission control (AC) to implement quality of service (QoS) in packet-switched communication networks. CO prevents potential overload while AC protects the QoS of the traffic during overload situations. Overload may be caused, e.g., by fluctuations of the traffic rate on a link due to its normal stochastic behavior (a), by traffic shifts within the network due to popular contents (b), or by redirected traffic due to network failures (c). Capacity dimensioning methods for CO need to take into account all potential sources of overload while AC can block excess traffic caused by (a) and (b) if the capacity does not suffice. The contributions of this paper are (1) the presentation of a capacity dimensioning method for networks with resilience requirements and changing traffic matrices, (2) the investigation of the impact of the mentioned sources of overload (a-c) on the required capacity for CO in networks with and without resilience requirements, and (3) a comparison of this required capacity with the one for AC. Our results show that in the presence of strong traffic shifts CO requires more capacity than AC. However, if resilience against network failures is required, both CO and AC need additional backup capacity for the redirected traffic. In this case, CO can use the backup capacity to absorb other types of overload. As a consequence, CO and AC have similar bandwidth requirements. These findings are robust against the network size. Copyright 2006 ACM.",Admission control; Capacity overprovisioning; QoS,Bandwidth; Computer system recovery; Packet networks; Quality of service; Telecommunication networks; Telecommunication traffic; Admission control; Capacity overprovisioning; Network failures; Traffic shifts; Channel capacity
"Chen K.-T., Huang C.-Y., Polly H., Lei C.-L.",4,Quantifying Skype user satisfaction,2006,92,"Department of Electrical Engineering, National Taiwan University, Taiwan; Institute of Information Science, Academia Sinica, Taiwan; Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan",National Taiwan University,1,Taiwan,1,13,7,"The success of Skype has inspired a generation of peer-to-peer-based solutions for satisfactory real-time multimedia services over the Internet. However, fundamental questions, such as whether VoIP services like Skype are good enough in terms of user satisfaction, have not been formally addressed. One of the major challenges lies in the lack of an easily accessible and objective index to quantify the degree of user satisfaction. In this work, we propose a model, geared to Skype, but generalizable to other VoIP services, to quantify VoIP user satisfaction based on a rigorous analysis of the call duration from actual Skype traces. The User Satisfaction Index (USI) derived from the model is unique in that 1) it is composed by objective source- and network-level metrics, such as the bit rate, bit rate jitter, and round-trip time, 2) unlike speech quality measures based on voice signals, such as the PESQ model standardized by ITU-T, the metrics are easily accessible and computable for real-time adaptation, and 3) the model development only requires network measurements, i.e., no user surveys or voice signals are necessary. Our model is validated by an independent set of metrics that quantifies the degree of user interaction from the actual traces. Copyright 2006 ACM.",Human perception; Internet measurement; Quality of service; Survival analysis; VoIP; Wavelet denoising,Human perception; Internet measurement; Survival analysis; VoIP; Wavelet denoising; Customer satisfaction; Internet; Mathematical models; Multimedia systems; Network protocols; Real time systems; Telecommunication networks; User interfaces; Distributed computer systems
"Baccelli F., Machiraju S., Veitch D., Bolot J.",4,The role of PASTA in network measurement,2006,46,"INRIA-ENS, Ecole Normale Supérieure, France; Sprint ATL, CA, United States; Dept. of E and E Engineering, University of Melbourne, Australia; ARC Special Research Centre on Ultra-Broadband Information Networks, CUBIN, National ICT Australia (NICTA), Australia",INRIA;NICTA;University of Melbourne,3,Australia;France;USA,3,23,12,"Poisson Arrivals See Time Averages (PASTA) is a well known property applicable to many stochastic systems. In active probing, PASTA is invoked to justify the sending of probe packets (or trains) at Poisson times in a variety of contexts. However, due to the diversity of aims and analysis techniques used in active probing, the benefits of Poisson based measurement, and the utility and role of PASTA, are unclear. Using a combination of rigorous results and carefully constructed examples and counter-examples, we map out the issues involved, and argue that PASTA is of very limited use in active probing. In particular, Poisson probes are not unique in their ability to sample without bias. Furthermore, PASTA ignores the issue of estimation variance, and the central need for an inversion phase to estimate the quantity of interest based on what is directly observable. We give concrete examples of when Poisson probes should not be used, and explain why, and offer initial guidelines on suitable alternative sending processes. Copyright 2006 ACM.",Active measurement; NIMASTA; PASTA; Probing,Active measurement; NIMASTA; Poisson Arrivals See Time Averages (PASTA); Poisson probes; Computer system firewalls; Packet networks; Parameter estimation; Poisson distribution; Probes; Stochastic programming; Computer networks
"Laskowski P., Chuang J.",2,Network monitors and contracting systems: Competition and innovation,2006,10,"UC Berkeley, United States",University of California Berkeley,1,USA,1,13,9,"Today's Internet industry suffers from several well-known pathologies, but none is as destructive in the long term as its resistance to evolution. Rather than introducing new services, ISPs are presently moving towards greater commoditization. It is apparent that the network's primitive system of contracts does not align incentives properly. In this study, we identify the network's lack of accountability as a fundamental obstacle to correcting this problem: Employing an economic model, we argue that optimal routes and innovation are impossible unless new monitoring capability is introduced and incorporated with the contracting system. Furthermore, we derive the minimum requirements a monitoring system must meet to support first-best routing and innovation characteristics. Our work does not constitute a new protocol; rather, we provide practical and specific guidance for the design of monitoring systems, as well as a theoretical framework to explore the factors that influence innovation. Copyright 2006 ACM.",Commoditization; Contracts; Incentives; Innovation; Monitoring,Commoditization; Contracting systems; Incentives; Innovation; Contracts; Internet; Mathematical models; Monitoring; Network protocols; Problem solving; Routers; Computer systems
"Katti S., Rahul H., Hu W., Katabi D., Médard M., Crowcroft J.",6,XORs in the air: Practical wireless network coding,2006,718,"MIT CSAIL, United States; Univ. of Cambridge, United Kingdom",MIT;University of Cambridge,2,UK;USA,2,39,31,"This paper proposes COPE, a new architecture for wireless mesh networks. In addition to forwarding packets, routers mix (i.e., code) packets from different sources to increase the information content of each transmission. We show that intelligently mixing packets increases network throughput. Our design is rooted in the theory of network coding. Prior work on network coding is mainly theoretical and focuses on multicast traffic. This paper aims to bridge theory with practice; it addresses the common case of unicast traffic, dynamic and potentially bursty flows, and practical issues facing the integration of network coding in the current network stack. We evaluate our design on a 20-node wireless network, and discuss the results of the first testbed deployment of wireless network coding. The results show that COPE largely increases network throughput. The gains vary from a few percent to several folds depending on the traffic pattern, congestion level, and transport protocol. Copyright 2006 ACM.",Network coding; Wireless networks,Multicast traffic; Network coding; Network throughput; Wireless networks; Packet networks; Routers; Signal encoding; Telecommunication traffic; Throughput; Wireless telecommunication systems; Telecommunication networks
"Bavier A., Feamster N., Huang M., Peterson L., Rexford J.",5,In VINI veritas: Realistic and controlled network experimentation,2006,217,"Princeton University, United States; Georgia Tech, United States",Georgia Tech;Princeton University,2,USA,1,28,16,"This paper describes VINI, a virtual network infrastructure that allows network researchers to evaluate their protocols and services in a realistic environment that also provides a high degree of control over network conditions. VINI allows researchers to deploy and evaluate their ideas with real routing software, traffic loads, and network events. To provide researchers flexibility in designing their experiments, VINI supports simultaneous experiments with arbitrary network topologies on a shared physical infrastructure. This paper tackles the following important design question: What set of concepts and techniques facilitate flexible, realistic, and controlled experimentation (e.g., multiple topologies and the ability to tweak routing algorithms) on a fixed physical infrastructure? We first present VINI's high-level design and the challenges of virtualizing a single network. We then present PL-VINI, an implementation of VINI on PlanetLab, running the ""Internet In a Slice"". Our evaluation of PL-VINI shows that it provides a realistic and controlled environment for evaluating new protocols and services. Copyright 2006 ACM.",Architecture; Experimentation; Internet; Routing; Virtualization,High-level design; Physical infrastructure; Traffic loads; Virtual network infrastructure; Computer software; Electric network topology; Network protocols; Telecommunication networks; Telecommunication traffic; Virtual reality
"Cho K., Fukuda K., Esaki H., Kato A.",4,The impact and implications of the growth in residential user-to-user traffic,2006,63,"IIJ, United States; NII; Univ. of Tokyo, Japan",University of Tokyo,1,Japan;USA,2,29,20,"It has been reported worldwide that peer-to-peer traffic is taking up a significant portion of backbone networks. In particular, it is prominent in Japan because of the high penetration rate of fiber-based broadband access. In this paper, we first report aggregated traffic measurements collected over 21 months from seven ISPs covering 42% of the Japanese backbone traffic. The backbone is dominated by symmetric residential traffic which increased 37% in 2005. We further investigate residential per-customer traffic in one of the ISPs by comparing DSL and fiber users, heavy-hitters and normal users, and geographic traffic matrices. The results reveal that a small segment of users dictate the overall behavior; 4% of heavy-hitters account for 75% of the inbound volume, and the fiber users account for 86% of the inbound volume. About 63% of the total residential volume is user-to-user traffic. The dominant applications exhibit poor locality and communicate with a wide range and number of peers. The distribution of heavy-hitters is heavy-tailed without a clear boundary between heavy-hitters and normal users, which suggests that users start playing with peer-to-peer applications, become heavy-hitters, and eventually shift from DSL to fiber. We provide conclusive empirical evidence from a large and diverse set of commercial backbone data that the emergence of new attractive applications has drastically affected traffic usage and capacity engineering requirements. Copyright 2006 ACM.",ISP backbone traffic; Residential broadband; Traffic growth,Fiber based broadband access; Fiber users; ISP; Residential user to user traffic; Boundary value problems; Broadband networks; Channel capacity; Communication systems; Distributed computer systems; User interfaces; Telecommunication traffic
"Vishwanath K.V., Vahdat A.",2,Realistic and responsive network traffic generation,2006,33,"University of California, San Diego, 9500 Oilman Drive, San Diego, CA 92093, United States",University of California San Diego,1,USA,1,45,38,"This paper presents Swing, a closed-loop, network-responsive traffic generator that accurately captures the packet interactions of a range of applications using a simple structural model. Starting from observed traffic at a single point in the network, Swing automatically extracts distributions for user, application, and network behavior. It then generates live traffic corresponding to the underlying models in a network emulation environment running commodity network protocol stacks. We find that the generated traces are statistically similar to the original traces. Further, to the best of our knowledge, we are the first to reproduce burstiness in traffic across a range of timescales using a model applicable to a variety of network settings. An initial sensitivity analysis reveals the importance of capturing and recreating user, application, and network characteristics to accurately reproduce such burstiness. Finally, we explore Swing's ability to vary user characteristics, application properties, and wide-area network conditions to project traffic characteristics into alternate scenarios. Copyright 2006 ACM.",Burstiness; Energy plot; Generator; Internet; Modeling; Structural model; Traffic; Wavelets,Burstiness; Energy plot; Structural model; Closed loop control systems; Internet; Mathematical models; Packet networks; Statistical methods; Telecommunication traffic
"Ramachandran A., Feamster N.",2,Understanding the network-level behavior of spammers,2006,185,"College of Computing, Georgia Tech., United States",Georgia Tech,1,USA,1,31,31,"This paper studies the network-level behavior of spammers, including: IP address ranges that send the most spam, common spamming modes (e.g., BGP route hijacking, bots), how persistent across time each spamming host is, and characteristics of spamming botnets. We try to answer these questions by analyzing a 17-month trace of over 10 million spam messages collected at an Internet ""spam sinkhole"", and by correlating this data with the results of IP-based blacklist lookups, passive TCP fingerprinting information, routing information, and botnet ""command and control"" traces. We find that most spam is being sent from a few regions of IP address space, and that spammers appear to be using transient ""bots"" that send only a few pieces of email over very short periods of time. Finally, a small, yet non-negligible, amount of spam is received from IP addresses that correspond to short-lived BGP routes, typically for hijacked prefixes. These trends suggest that developing algorithms to identify botnet membership, filtering email messages based on network-level properties (which are less variable than email content), and improving the security of the Internet routing infrastructure, may prove to be extremely effective for combating spam. Copyright 2006 ACM.",BGP; Botnet; Network management; Security; Spam,BGP; Botnets; Network management; Spam; Computer crime; Computer networks; Data reduction; Routers; Security of data; Security systems; Spamming
"Mahadevan P., Krioukov D., Fall K., Vahdat A.",4,Systematic topology analysis and generation using degree correlations,2006,109,"UC San Diego, United States; CAIDA, United States; Intel Research",Intel;University of California San Diego,2,USA,1,32,24,"Researchers have proposed a variety of metrics to measure important graph properties, for instance, in social, biological, and computer networks. Values for a particular graph metric may capture a graph's resilience to failure or its routing efficiency. Knowledge of appropriate metric values may influence the engineering of future topologies, repair strategies in the face of failure, and understanding of fundamental properties of existing networks. Unfortunately, there are typically no algorithms to generate graphs matching one or more proposed metrics and there is little understanding of the relationships among individual metrics or their applicability to different settings. We present a new, systematic approach for analyzing network topologies. We first introduce the dK-series of probability distributions specifying all degree correlations within d-sized subgraphs of a given graph G. Increasing values of d capture progressively more properties of G at the cost of more complex representation of the probability distribution. Using this series, we can quantitatively measure the distance between two graphs and construct random graphs that accurately reproduce virtually all metrics proposed in the literature. The nature of the dK-series implies that it will also capture any future metrics that may be proposed. Using our approach, we construct graphs for d = 0, 1, 2, 3 and demonstrate that these graphs reproduce, with increasing accuracy, important properties of measured and modeled Internet topologies. We find that the d = 2 case is sufficient for most practical purposes, while d = 3 essentially reconstructs the Internet AS- and router-level topologies exactly. We hope that a systematic method to analyze and synthesize topologies offers a significant improvement to the set of tools available to network topology and protocol researchers. Copyright 2006 ACM.",Degree correlations; Network topology,Degree correlations; DK-series; Graph metric; Internet topologies; Algorithms; Graph theory; Internet; Network protocols; Probability distributions; Routers; Electric network topology
"Kamra A., Misra V., Feldman J., Rubenstein D.",4,Growth codes: Maximizing sensor network data persistence,2006,132,"Columbia University, NY, United States; Google Inc., NY, United States",Columbia University;Google,2,USA,1,36,30,"Sensor networks are especially useful in catastrophic or emergency scenarios such as floods, fires, terrorist attacks or earthquakes where human participation may be too dangerous. However, such disaster scenarios pose an interesting design challenge since the sensor nodes used to collect and communicate data may themselves fail suddenly and unpredictably, resulting in the loss of valuable data. Furthermore, because these networks are often expected to be deployed in response to a disaster, or because of sudden configuration changes due to failure, these networks are often expected to operate in a ""zero-configuration"" paradigm, where data collection and transmission must be initiated immediately, before the nodes have a chance to assess the current network topology. In this paper, we design and analyze techniques to increase ""persistence"" of sensed data, so that data is more likely to reach a data sink, even as network nodes fail. This is done by replicating data compactly at neighboring nodes using novel ""Growth Codes"" that increase in efficiency as data accumulates at the sink. We show that Growth Codes preserve more data in the presence of node failures than previously proposed erasure resilient techniques. Copyright 2006 ACM.",LDPC codes; Network Resilience,Codes (symbols); Computer aided design; Computer networks; Data acquisition; Data transfer; Telecommunication links; LDPC codes; Network Resilience; Sensor networks; Sensor nodes; Telecommunication networks
"Crowcroft J., Kreibich C.",2,Only 365 days left until the sigcomm deadline,2006,0,"University of Cambridge, Computer Laboratory, United Kingdom",University of Cambridge,1,UK,1,3,3,Only three hundred sixty four days left until the Sigcomm deadline. Only three hundred sixty three days left until the Sigcomm deadline. Only three hundred sixty two days left until the Sigcomm deadline. Only three hundred sixty one days left until the Sigcomm deadline. Only three hundred sixty days left until the Sigcomm deadline. Only three hundred fifty nine days left until the Sigcomm deadline. Only three hundred fifty eight days left until the Sigcomm dead-line. Only three hundred fifty seven days left until the Sigcomm deadline. Only three hundred fifty six days left until the Sigcomm deadline. Only three hundred fifty five days left until the Sigcomm deadline.,1 - 365; Days; Deadline; Left; Only; Sigcomm; The; Until,Sigcomm deadline; Communication channels (information theory); Wireless telecommunication systems; Signal processing
"Mühlbauer W., Feldmann A., Maennel O., Roughan M., Uhlig S.",5,Building an AS-topology model that captures route diversity,2006,39,"TU München, Germany; University of Adelaide, Australia; Université Catholique de Louvain, Belgium",TU Munich;University of Adelaide;Universite Catholique de Louvain,3,Australia;Belgium;Germany,3,48,44,"An understanding of the topological structure of the Internet is needed for quite a number of networking tasks, e.g., making decisions about peering relationships, choice of upstream providers, inter-domain traffic engineering. One essential component of these tasks is the ability to predict routes in the Internet. However, the Internet is composed of a large number of independent autonomous systems (ASes) resulting in complex interactions, and until now no model of the Internet has succeeded in producing predictions of acceptable accuracy. We demonstrate that there are two limitations of prior models: (i) they have all assumed that an Autonomous System (AS) is an atomic structure - it is not, and (ii) models have tended to over-simplify the relationships between ASes. Our approach uses multiple quasi-routers to capture route diversity within the ASes, and is deliberately agnostic regarding the types of relationships between ASes. The resulting model ensures that its routing is consistent with the observed routes. Exploiting a large number of observation points, we show that our model provides accurate predictions for unobserved routes, a first step towards developing structural models of the Internet that enable real applications. Copyright 2006 ACM.",BGP; Inter-domain routing; Route diversity; Routing policies,Autonomous systems (AS); Inter domain traffic engineering; Quasi routers; Route diversity; Adaptive systems; Decision making; Distributed computer systems; Mathematical models; Network protocols; Routers; Internet
"Wang F., Mao Z.M., Wang J., Gao L., Bush R.",5,A measurement study on the impact of routing events on end-to-end Internet path performance,2006,54,"University of Mass., Amherst, United States; University of Michigan, United States; AT and T Labs-Research, United States; Internet Initiative Japan, Japan",AT and T Labs;University of Massachusetts Amherst;University of Michigan at Ann Arbor,3,Japan;USA,2,27,25,"Extensive measurement studies have shown that end-to-end Internet path performance degradation is correlated with routing dynamics. However, the root cause of the correlation between routing dynamics and such performance degradation is poorly understood. In particular, how do routing changes result in degraded end-to-end path performance in the first place? How do factors such as topological properties, routing policies, and iBGP configurations affect the extent to which such routing events can cause performance degradation? Answers to these questions are critical for improving network performance. In this paper, we conduct extensive measurement that involves both controlled routing updates through two tier-1 ISPs and active probes of a diverse set of end-to-end paths on the Internet. We find that routing changes contribute to end-to-end packet loss significantly. Specifically, we study failover events in which a link failure leads to a routing change and recovery events in which a link repair causes a routing change. In both cases, it is possible to experience data plane performance degradation in terms of increased long loss burst as well as forwarding loops. Furthermore, we find that common routing policies and iBGP configurations of ISPs can directly affect the end-to-end path performance during routing changes. Our work provides new insights into potential measures that network operators can undertake to enhance network performance. Copyright 2006 ACM.",Active probing; BGP; Failover event; Packet loss; Packet reordering; Recovery event; Routing dynamics,Active probing; BGP; Failover events; Packet losses; Packet reordering; Recovery events; Routing dynamics; Correlation methods; Internet; Packet networks; Probes; Telecommunication networks; Topology; Routers
Jiang Y.,1,A basic stochastic network calculus,2006,103,"Department of Telematics, Norwegian University of Science and Technology, Norway",Norwegian University of Science and Technology,1,Norway,1,40,26,"A basic calculus is presented for stochastic service guarantee analysis in communication networks. Central to the calculus are two definitions, maximum-(virtual)-backlog-centric (m.b.c) stochastic arrival curve and stochastic service curve, which respectively generalize arrival curve and service curve in the deterministic network calculus framework. With m.b.c stochastic arrival curve and stochastic service curve, various basic results are derived under the (min, +) algebra for the general case analysis, which are crucial to the development of stochastic network calculus. These results include (i) superposition of flows, (ii) concatenation of servers, (iii) output characterization, (iv) per-flow service under aggregation, and (v) stochastic backlog and delay guarantees. In addition, to perform independent case analysis, stochastic strict server is defined, which uses an ideal service process and an impairment process to characterize a server. The concept of stochastic strict server not only allows us to improve the basic results (i) - (v) under the independent case, but also provides a convenient way to find the stochastic service curve of a serve. Moreover, an approach is introduced to find the m.b.c stochastic arrival curve of a flow and the stochastic service curve of a server. Copyright 2006 ACM.",Independent case analysis; Stochastic arrival curve; Stochastic network calculus; Stochastic quality of service guarantee; Stochastic service curve; Stochastic strict server,Independent case analysis; Stochastic arrival curve; Stochastic network calculus; Stochastic quality of service guarantee; Stochastic service curve; Stochastic strict server; Quality of service; Servers; Signal processing; Telecommunication networks; Random processes
"Williams N., Zander S., Armitage G.",3,A preliminary performance comparison of five machine learning algorithms for practical IP traffic flow classification,2006,346,"Centre for Advanced Internet Architectures (CAIA), Swinburne University of Technology, Melbourne, Australia",Centre for Advanced Internet Architectures;Swinburne University of Technology,2,Australia,1,20,18,"The identification of network applications through observation of associated packet traffic flows is vital to the areas of network management and surveillance. Currently popular methods such as port number and payload-based identification exhibit a number of shortfalls. An alternative is to use machine learning (ML) techniques and identify network applications based on per-flow statistics, derived from payload-independent features such as packet length and inter-arrival time distributions. The performance impact of feature set reduction, using Consistency-based and Correlation-based feature selection, is demonstrated on Naïve Bayes, C4.5, Bayesian Network and Naïve Bayes Tree algorithms. We then show that it is useful to differentiate algorithms based on computational performance rather than classification accuracy alone, as although classification accuracy between the algorithms is similar, computational performance can differ significantly.",Machine learning; Traffic classification,Classification (of information); Computation theory; Identification (control systems); Learning systems; Packet networks; Statistical methods; Consistency-based feature selection; Network management; Packet traffic flows; Traffic classification; Telecommunication traffic
"Walfish M., Vutukuru M., Balakrishnan H., Karger D., Shenker S.",5,DDoS defense by offense,2006,50,"MIT, United States; UC Berkeley, ICSI, United States",MIT;University of California Berkeley,2,USA,1,52,44,"This paper presents the design, implementation, analysis, and experimental evaluation of speak-up, a defense against application-level distributed denial-of-service (DDoS), in which attackers cripple a server by sending legitimate-looking requests that consume computational resources (e.g., CPU cycles, disk). With speak-up, a victimized server encourages all clients, resources permitting, to automatically send higher volumes of traffic. We suppose that attackers are already using most of their upload bandwidth so cannot react to the encouragement. Good clients, however, have spare upload bandwidth and will react to the encouragement with drastically higher volumes of traffic. The intended outcome of this traffic inflation is that the good clients crowd out the bad ones, thereby capturing a much larger fraction of the server's resources than before. We experiment under various conditions and find that speak-up causes the server to spend resources on a group of clients in rough proportion to their aggregate upload bandwidth. This result makes the defense viable and effective for a class of real attacks. Copyright 2006 ACM.",Bandwidth; Currency; DoS attack,Computational resources; Currency; Distributed denial of service (DDoS); DoS attack; Bandwidth; Computer aided design; Computer crime; Distributed computer systems; Servers; Telecommunication traffic; Security of data
Chau C.-K.,1,Policy-based routing with non-strict preferences,2006,7,"Computer Laboratory, University of Cambridge, United Kingdom",University of Cambridge,1,UK,1,10,7,"Traditional studies of routing problems often assumed strict preferences on paths, by eliminating ambiguity in path comparisons, or imposing a priori deterministic tie-breaking. Such an assumption is outpaced by today's common practice of non-deterministic, multi-path routing, which is crucial to traffic engineering, QoS routing, multicasting and virtual private networking. A pair of paths may be incomparable or equally preferred. In the presence of ambiguous preferences at pairs, or even multiple collections of paths, a challenge is to ensure robustness in the complex and sophisticated situations of policy-based routing where heterogeneous routing policies are allowed among routing systems. This paper presents an extensive study of policy-based routing with non-strict preferences, deriving sufficient conditions that ensure the existence, optimality and asynchronous convergence of stable routings. Copyright 2006 ACM.",Policy-based routing; Robustness,Multipath routing; Non strict preferences; Policy based routing; Traffic engineering; Multicasting; Problem solving; Quality of service; Robustness (control systems); Telecommunication networks; Telecommunication traffic; Routers
"Li L., Dovrolis C., Sanadidi M.Y.",3,The probe gap model can underestimate the available bandwidth of multihop paths,2006,38,"Google Inc., Santa Monica, CA, United States; Georgia Tech, Atlanta, GA, United States; UCLA, Los Angeles, CA, United States",Georgia Tech;Google,2,USA,1,10,10,"The Probe Gap Model (PGM) was proposed as a lightweight and fast available bandwidth estimation method. Measurement tools such as Delphi and Spruce are based on PGM. Compared to estimation methods that require multiple iterations with different probing rates, PGM uses a single probing rate and it infers the available bandwidth from a direct relation between the input and output rates of measurement packet pairs. An important assumption behind the PGM model is that the measured path has a single bottleneck link that determines the available bandwidth of the end-to-end path. In this letter, we show that, even though PGM is accurate in the case of a single queue, it cannot estimate the available bandwidth of multi-hop paths, even if there is a single bottleneck in the path. Whether PGM is accurate or not depends on the routing of cross traffic relative to the measurement traffic. PGM is accurate when the cross traffic follows the same path with the measurement traffic. In the general case, however, PGM can significantly underestimate the available bandwidth of an end-to-end path.",Available bandwidth; Network capacity; Packet pair dispersion; Probe gap model,Available bandwidth; Network capacity; Packet pair dispersion; Probe gap model; Bandwidth; Iterative methods; Mathematical models; Parameter estimation; Telecommunication traffic; Wireless telecommunication systems
"Alyfantis G., Hadjiefthymiades S., Merakos L.",3,A cooperative uplink power control scheme for elastic data services in wireless CDMA systems,2006,9,"Communication Networks Laboratory, Department of Informatics and Telecommunications, University of Athens, Athens 15784, Greece",University of Athens,1,Greece,1,22,13,"We consider the uplink power control problem in a single cell CDMA wireless data system. Each user specifies upper and lower QoS bounds. We formulate the considered problem as a game, and first examine the non-cooperative case. We then compare it to its cooperative counterpart (through the Nash bargaining solution). The use of the cooperative scheme shows significant reduction in the transmission power of the mobile terminals, while the achieved QoS is slightly compromised, compared to the non-cooperative scheme.",CDMA; Game theory; Nash Bargaining Solution; Optimization; Power control,Game theory; Mobile telecommunication systems; Optimization; Power control; Power transmission; Quality of service; Telecommunication services; Cooperative scheme; Elastic data service; Nash Bargaining Solution; Uplink power control problem; Code division multiple access
"Abrantes F., Ricardo M.",2,XCP for shared-access multi-rate media,2006,27,"INESC Porto, Faculdade de Engenharia, Univ. do Porto, Poland",University do Porto,1,Poland,1,20,15,"The eXplicit Control Protocol (XCP) was developed to overcome some of the limitations of TCP, such as low utilization in high bandwidth delay product networks, unstable throughput, large queue build-up, and limited fairness. XCP, however, requires that each queue controller in a path knows the exact capacity of its link. In shared access media, e.g. EEEE 802.11, knowing the actual capacity of the channel is a difficult task. In this paper we propose modifications to the XCP algorithm that enable the utilization of XCP even when the capacity of a link is unknown. These modifications are validated through simulation. We also present the results of a comparison between the performance of the modified XCP and TCP, where XCP controlled flows result more stable, fairness increases, and the network delay becomes lower. In addition, as the bandwidth delay product increases, XCP is able to maintain near-maximum utilization while TCP decreases utilization.",Congestion control; Dynamic bandwidth; XCP; XCP-b,Congestion control; Dynamic bandwidth; XCP; XCP-b; Algorithms; Bandwidth; Capacitance; Computer simulation; Electric power utilization; Networks (circuits); Queueing networks; Throughput; Network protocols
"Weigle M.C., Adurthi P., Hernández-Campos F., Jeffay K., Smith F.D.",5,Tmix: A tool for generating realistic TCP application workloads in ns-2,2006,82,"Clemson University, United States; University of North Carolina, Chapel Hill, United States",Clemson University;University of North Carolina,2,USA,1,30,23,"In order to perform realistic network simulations, one needs a traffic generator that is capable of generating realistic synthetic traffic in a closed-loop fashion that ""looks like"" traffic found on an actual network. We describe such a traffic generation system for the widely used ns-2 simulator. The system takes as input a packet header trace taken from a network link of interest. The trace is ""reverse compiled"" into a source-level characterization of each TCP connection present in the trace. The characterization, called a connection vector, is then used as input to an ns module called tmix that emulates the socket-level behavior of the source application that created the corresponding connection in the trace. This emulation faithfully reproduces the essential pattern of socket reads and writes that the original application performed without knowledge of what the original application actually was. When combined with a network path emulation component we have constructed called DelayBox, the resulting traffic generated in the simulation is statistically representative of the traffic measured on the real link. This approach to synthetic traffic generation allows one to automatically repro-duce in ns the full range of TCP connections found on an arbitrary link. Thus with our tools, researchers no longer need make arbitrary decisions on how traffic is generated in simulations and can instead easily generate TCP traffic that represents the use of a net-work by the full mix of applications measured on actual network links of interest. The method is evaluated by applying it to packet header traces taken from campus and wide-area networks and comparing the statistical properties of traffic on the measured links with traffic generated by tmix in ns.",ns; Source-level modeling; Synthetic traffic generation,Ns; Source-level modeling; Synthetic traffic generation; Tmix; Computer simulation; Electric connectors; Electric network analysis; Electric variables measurement; Telecommunication links; Telecommunication traffic; Network protocols
"Minshall G., Minden B., Hoffman E., Liaw F.C., Lyon T., Newman P.",6,Flow labelled IP over ATM: Design and rationale,2006,2,"Ipsilon Networks, Inc., United States",Ipsilon Networks,1,USA,1,44,0,"We describe a system in which layer 2 switching is placed directly under the control of layer 3 routing protocols on a hop-by-hop basis. Specifically, ATM switching is controlled by EP. We couple each ATM switch with a general purpose computer running IP routing and management protocols. We define a default ATM virtual channel identifier (VCI) to be used for transmitting IP packets over ATM links. We then define mechanisms which allow specific flows to be transmitted on specific ATM VCIs. The resulting system obeys IP's semantics for routing and forwarding, and takes advantage of ATM's switching hardware to accelerate the forwarding of packets. While this system takes advantage of ATM hardware, the ATM signalling, routing, and management architecture (as specified by the ATM Forum) is replaced by the protocols and practices currently in use for IP routing and management.",ATM; Flow Labelled IP; GSMP; IFMP; IP; IP switching; Ipsilon,Flow Labelled IP; GSMP; IFMP; IP; IP switching; Ipsilon; Computer hardware; Coupled circuits; Network protocols; Routers; Semantics; Switching networks; Telecommunication links; Asynchronous transfer mode
Bauer C.,1,"Low complexity, stable scheduling algorithms for networks of input queued switches with no or very low speed-up",2006,0,"Dolby Laboratories, 100 Potrero Avenue, San Francisco, 94103, United States",Dolby Laboratories,1,USA,1,19,16,"The delay and throughput characteristics of a packet switch depend mainly on the queueing scheme and the scheduling algorithm deployed at the switch. Early research on scheduling algorithms has mainly focused on maximum weight matching scheduling algorithms. It is known that maximum weight matching algorithms guarantee the stability of input-queued switches, but are impractical due to their high computational complexity. Later research showed that the less complex maximal matching algorithms can stabilize input-queued switches when they are deployed with a speed-up of two. For practical purposes, neither a high computational complexity nor a speed-up of two is desirable. In this paper, we investigate the application of matching algorithms that approximate maximum weight matching algorithms to scheduling problems. We show that while having a low computational complexity, they guarantee the stability of input queued switches when they are deployed with a moderate speed-up. In particular, we show that the improve_matching algorithm stabilizes input-queued switches when it is deployed with a speed-up of 3/2 + ε. In a second step, we further improve on these results by proposing a class of maximal weight matching algorithms that stabilize an input-queued switch without any speed-up. Whereas initial research has only focused on scheduling algorithms that guarantee the stability of a single switch, recent work has shown how scheduling algorithms for single switches can be modified in order to design distributed scheduling algorithms that stabilize networks of input-queued switches. Using those results, we show that the switching algorithms proposed in this paper do not only stabilize a single switch, but also networks of input-queued switches.",Scheduling algorithms; Stability,Algorithms; Computational complexity; Queueing networks; Scheduling; Speed control; Stability; Input-queued switch; Low complexity; Maximum weight matching; Scheduling algorithms; Switches
"Broido A., Shang H., Fomenkov M., Hyun Y., Claffy K.",5,The windows of private DNS updates,2006,2,"CAIDA, SDSC, United States; Google, Inc., United States",Google,1,USA,1,28,21,"This work is motivated by the observation of one particular type of unwanted traffic - dynamic DNS updates for private (RFC 1918) addreuei, which leaks to global network. This spurious traffic not only wastes network resources but also jeopardizes security and privacy of users. We first look at the magnitude of these updates on two independent AS112 [1] servers. We then analyze which operating systems are responsible for these updates by using three levels of signature techniques and find that over 97% of updates come from Windows systems. While newer versions of Windows OSes are more stringent in sending private DNS updates, we did not observe an overall decreasing trend due to this evolution. Users, software vendors, and system administrators can take steps to reduce this RFC1918 traffic. However, since most end users are unlikely to interfere with vendor default settings, it should be the responsibility of software vendor and system administrators to take positive action to fix this problem.",Domain Name System; Dynamic updates; Misconfiguration; OS fingerprinting; Private addresses,Domain Name System; Dynamic updates; Misconfiguration; OS fingerprinting; Private addresses; Computer operating systems; Computer software; Problem solving; Security systems; Servers; Telecommunication traffic; Computer networks
"Rewaskar S., Kaur J., Smith F.D.",3,A passive state-machine approach for accurate analysis of TCP out-of-sequence segments,2006,15,"Department of Computer Science, University of North Carolina, Chapel Hill, United States",University of North Carolina,1,USA,1,32,21,"In this paper we describe a new tool being made available to the networking research community for passive analysis of TCP segment traces. The purpose of the tool is to provide more complete and accurate classification of out-of-sequence segments than those provided by prior tools. One of the crucial factors that limits the accuracy of prior tools is that these do not incorporate variations across TCP implementations (for different operating systems) that have different parameters (e.g., timer granularity, minimum RTO, duplicate ACK thresholds, etc.) or algorithms that influence what can be inferred about out-of-sequence segments. Our tool explicitly accounts for implementation- specific details in four prominent TCP stacks (Windows, Linux, FreeBSD/Mac OS-X, and Solaris). We validate our tool through several controlled experiments with instances of all four OS-specific implementations used in the analysis. We then run this tool on packet traces of 52 million Internet TCP connections collected from 5 different locations and present the results. We also include comparisons with results from running selected prior tools on the same traces.",Loss; Passive; State Machine; TCP Analysis,Loss; Passive; State Machine; TCP Analysis; Algorithms; Computer operating systems; Image segmentation; Internet; Societies and institutions; Network protocols
"Sharma P., Xu Z., Banerjee S., Lee S.-J.",4,Estimating network proximity and latency,2006,52,"Hewlett-Packard Labs, Palo Alto, CA, United States; Yahoo Inc., Sunnyvale, CA, United States",Yahoo Inc.,1,USA,1,28,24,"Network proximity and latency estimation is an important component in discovering and locating services and applications. With the growing number of services and service providers in the large-scale Internet, accurately estimating network proximity/latency with minimal probing overhead becomes essential for scalable deployment Although there exist a number of network distance estimation schemes, they either rely on extensive infrastructure support, require the IP address of the potential targets, falsely cluster distant nodes, or perform poorly with even few measurement errors. We propose Netvigator, a scalable network proximity and latency estimation tool that uses information obtained from probing a small number of landmark nodes and intermediate routers (termed milestones) that are discovered en route to the landmarks, to identify the closest nodes. With very little additional probing overhead, Netvigator uses distance information to the milestones to accurately locate the closest nodes. We developed a Netvigator prototype and report our performance evaluation on PlanetLab and in the intranet of a large enterprise. Netvigator is a running service on PlanetLab as a part of HP Labs' S 3 (Scalable Sensing Service).",Network distance estimation; Network measurement,Cluster distant node; Latency estimation tool; Network distance estimation; Network measurement; Information retrieval systems; Internet; Measurement errors; Proximity indicators; Routers; Computer networks
"Jiang Y., Striegel A.",2,A distributed traffic control scheme based on edge-centric resource management,2006,2,"Dept. of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN 46556, United States",University of Notre Dame,1,USA,1,20,18,"The correct admission of flows in the Differentiated Services (DiffServ) environment is critical to provide stable and predictable quality of service (QoS) to the end user. Without a scalable and precise admission control scheme, the service provider is faced with either over-provisioning the network or accepting periods of best-effort like behavior. In this paper, we propose a novel approach for admission control that exploits the unique architectural aspects of DiffServ. Through the use of periodic heartbeats emanating from edge routers to probe the network state on the available egress paths, edge routers are able to quickly conduct admission control with a tunable degree of precision. In this paper, we detail our approach, Edge-centric Resource Management (ERM), and conduct detailed simulation studies regarding the effectiveness of the approach.",Admission control; Differentiated services; QoS; Traffic engineering,Computer architecture; Computer simulation; Quality of service; Resource allocation; Routers; Traffic control; Admission control; Differentiated services; Traffic engineering; Distributed computer systems
"Claffy K.C., Crovella M., Friedman T., Shannon C., Spring N.",5,Community-Oriented Network Measurement Infrastructure (CONMI) workshop report,2006,14,"San Diego Supercomputer Center, University of California, San Diego, San Diego, CA, United States; Department of Computer Science, Boston University, Boston, MA, United States; Networks and Performance Analysis, Laboratoire LiP6-CNRS, Paris, France; Department of Computer Science, University of Maryland, College Park, MD, United States",Boston University;San Diego Supercomputer Center;University of California San Diego;University of Maryland College Park,4,France;USA,2,27,24,"This report summarizes issues discussed at the first CONMI workshop held on 30 March 2005 in Boston, Massachusetts. Sponsored by the National Science Foundation's Office of Cyberinfrastructure (OCI-0532233), the workshop was intended to begin a discussion regarding the viability and utility of a community-oriented network measurement infrastructure. This report was published 20 December 2005 online at: http://www.caida.org/workahops/ conmi/.",Annotations; Community; Data sharing; Internet; Measurement; Metadata; Monitoring; Performance; Routing; Topology; Workload,Cybernetics; Data acquisition; Metadata; Online systems; Technical presentations; Topology; Annotations; Community; Workload; Computer networks
"Ali M., Voigt T., Saif U., Römer K., Dunkels A., Langendoen K., Polastre J., Uzmi Z.A.",8,Medium access control issues in sensor networks,2006,68,"LUMS, CS Department, DHA, Opposite Sector U, Lahore - 54792, Pakistan; SICS, Box 1263, SE-164 29 Kista, Sweden; MIT, CSAIL, Stata Center, 32G-780, Cambridge, MA 02139, United States; ETH Zurich, Department of CS, CH-8092 Zürich, Switzerland; TU Delft, Mekelweg 4, 2628 CD Delft, Netherlands; Moteiv Corporation, 55 Hawthorne St, San Francisco, CA 94105, United States",ETH Zurich;LUMS Pakistan;MIT;TU Delft,4,Netherlands;Pakistan;Sweden;Switzerland;USA,5,20,19,"Medium access control for wireless sensor networks has been a very active research area for the past couple of years. The sensor networks literature presents an alphabet soup of medium access control protocols with almost all of the works focusing only on energy efficiency. There is much more innovative work to be done at the MAC layer, but current efforts are not addressing the hard unsolved problems. Majority of the works appearing in the literature are ""least publishable incremental improvements"" over the popular S-MAC [1] protocol. In this paper we present research directions for future medium access research. We identify some open issues and discuss possible solutions.",Medium Access Control; Wireless Sensor Networks,Control systems; Energy efficiency; Network protocols; Problem solving; Medium Access Control; Wireless Sensor Networks; Wireless telecommunication systems
Sestinim F.,1,Situated and autonomic communication an EC FET european initiative,2006,13,"European Commission; SAC Project, United States; Future and Emerging Technologies, European Commission DG Information Society and Media, Belgium",Future and Emerging Technologies,1,Belgium;USA,2,13,13,"A proactive initiative titled ' Situated and Autonomic Communications' was defined in the Future and Emerging Technologies (FET) part of the IST research program funded by the European Commission. The vision behind this initiative is that of a world pervaded by ubiquitous communication facilities, offering their services to the users and capable of self-organizing and self-preserving their functionalities without any direct human intervention. These new communication paradigms can be situated in multiple and dynamic contexts, and are expected to be autonomously controlled, self-organizing, technology independent and scale free. The key concerns regarding this initiative is security and trustworthiness, overall stability and resilience of the evolving networks, and positive interactions of new communication paradigms with human, social and commercial aspects.",Ad-hoc; Always best connected; Autonomic communication; New networking paradigms; Nomadism,Computer networks; Control systems; Security of data; Social aspects; Ad-hoc; Autonomic communication; Future and Emerging Technologies (FET); Nomadism; The IST research program; Communication systems
"Bernaille L., Teixeira R., Akodkenou I., Soule A., Salamatian K.",5,Traffic classification on the fly,2006,359,"LIP6, Université Pierre et Marie Curie, Paris, France; Thomson Paris Lab, Paris, France",University Pierre and Marie Curie,1,France,1,10,7,"The early detection of applications associated with TCP flows is an essential step for network security and traffic engineering. The classic way to identify flows, i.e. looking at port numbers, is not effective anymore. On the other hand, state-of-the-art techniques cannot determine the application before the end of the TCP flow. In this editorial, we propose a technique that relies on the observation of the first five packets of a TCP connection to identify the application. This result opens a range of new possibilities for online traffic classification.",Applications; Machine learning; Traffic classification,Computer networks; Learning systems; Online systems; Packet networks; Security of data; Telecommunication traffic; State-of-the-art techniques; Traffic classification; Traffic engineering; Network protocols
"Bhandarkar S., Jain S., Reddy A.L.N.",3,LTCP: Improving the performance of TCP in highspeed networks,2006,15,"Dept. of Electrical Engineering, Texas A and M University, United States",Texas A and M University,1,USA,1,35,28,"In this paper, we propose Layered TCP (LTCP for short), a set of simple modifications to the congestion window response of TCP to make it more scalable in highspeed networks. LTCP modifies the TCP flow to behave as a collection of virtual flows to achieve more efficient bandwidth probing. The number of virtual flows emulated is determined based on the dynamic network conditions by using the concept of virtual layers, such that the convergence properties and RTT-unfairness behavior is maintained similar to that of TCP. In this paper, we provide the intuition and the design for the LTCP protocol modifications and evaluation results based on ns-2 simulations and Linux implementation. Our results show that LTCP has promising convergence properties, is about an order of magnitude faster than TCP in utilizing high bandwidth links, employs few parameters and retains AIMD characteristics.",AIMD; Congestion control; Highspeed networks; Protocol design,Highspeed networks; Linux implementation; Protocol design; Virtual flows; Bandwidth; Computer operating systems; Computer simulation; Congestion control (communication); Network protocols; Virtual reality; Telecommunication networks
"Fragouli C., Le Boudec J.-Y., Widmer J.",3,Network coding: An instant primer,2006,462,"EPFL - IC, Switzerland; DoCoMo Labs, United States","EPFL,Switzerland",1,Switzerland;USA,2,30,27,"Network coding is a new research area that may have interesting applications in practical networking systems. With network coding, intermediate nodes may send out packets that are linear combinations of previously received information. There are two main benefits of this approach: potential throughput improvements and a high degree of robustness. Robustness translates into loss resilience and facilitates the design of simple distributed algorithms that perform well, even if decisions are based only on partial information. This paper is an instant primer on network coding: we explain what network coding does and how it does it. We also discuss the implications of theoretical results on network coding for realistic settings and show how network coding can be used in practice.",Network coding,Distributed algorithms; Linear combinations; Network coding; Throughput improvements; Algorithms; Distributed computer systems; Information retrieval; Linear systems; Robustness (control systems); Telecommunication networks; Signal encoding
"Uhlig S., Quoitin B., Lepropre J., Balon S.",4,Providing public intradomain traffic matrices to the research community,2006,205,"Computing Science and Engineering Department, University of Louvain-la-Neuve, Belgium; Research Unit in Networking, University of Liege, Belgium",University of Liege;University of Louvain-la-Neuve,2,Belgium,1,20,15,"This paper presents a new publicly available dataset from GANT, the European Research and Educational Network. This dataset consists of traffic matrices built using full IGP routing information, sampled Netflow data and BGP routing information of the GANT network, one per 15 minutes interval for several months. Potential benefits of publicly available traffic matrices comprise improving our understanding of real traffic matrices, their dynamics, and to make possible the benchmarking of intradomain traffic engineering methods.",Intra-domain traffic matrices; Traffic statistics,Benchmarking; Data structures; Information retrieval; Matrix algebra; Routers; Telecommunication networks; Dataset; Intra domain traffic matrices; Real traffic matrices; Traffic statistics; Telecommunication traffic
"Mahadevan P., Krioukov D., Fomenkov M., Huffaker B., Dimitropoulos X., Claffy K.C., Vahdat A.",7,The internet AS-level topology: Three data sources and one definitive metric,2006,203,"UCSD, United States; CAIDA, United States; Georgia Tech, United States",Georgia Tech,1,USA,1,42,31,"We calculate an extensive set of characteristics for Internet AS topologies extracted from the three data sources most frequently used by the research community: traceroutes, BGP, and WHOIS. We discover that traceroute and BGP topologies are similar to one another but differ substantially from the WHOIS topology. Among the widely considered metrics, we find that the joint degree distribution appears to fundamentally characterize Internet AS topologies as well as narrowly define values for other important metrics. We discuss the interplay between the specifics of the three data collection mechanisms and the resulting topology views. In particular, we how how the data collection peculiarities explain differences in the resulting joint degree distributions of the respective topologies. Finally, we release to the community the input topology datasets, along with the scripts and output of our calculations. This supplement hould enable researchers to validate their models against real data and to make more informed election of topology data sources for their specific needs.",Internet topology,Internet topology; Joint degree distribution; Traceroutes; Data acquisition; Data structures; Matrix algebra; Routers; Topology; Internet
Calvert K.,1,Reflections on network architecture: An active networking perspective,2006,17,"Laboratory for Advanced Networking, University of Kentucky, United States",University of Kentucky,1,USA,1,20,17,"After a long period when networking research seemed to be focused mainly on making the existing Internet work better, interest in ""clean slate"" approaches to network architecture seems to be growing. Beginning with the DARPA program in the mid-1990's, researchers working on active networks explored such an approach, based on the idea of a programming interface as the basic interoperability mechanism of the network. This note draws on the author's experiences in that effort and attempts to extract some observations or ""lessons learned"" that may be relevant to more general network architecture research.",Design; Experimentation,Computer programming; Interoperability; Research and development management; User interfaces; DARPA program; Experimentation; Computer architecture
"Roughan M., Zhang Y.",2,Secure distributed data-mining and its application to large-scale network measurements,2006,22,"School of Mathematical Science, University of Adelaide, SA 5005, Australia; Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712, United States",University of Adelaide;University of Texas at Austin,2,Australia;USA,2,34,29,"The rapid growth of the Internet over the last decade has been startling. However, efforts to track its growth have often fallen afoul of bad data - - for instance, how much traffic does the Internet now carry? The problem is not that the data is technically hard to obtain, or that it does not exist, but rather that the data is not shared. Obtaining an overall picture requires data from multiple sources, few of whom are open to sharing such data, either because it violates privacy legislation, or exposes business secrets. Likewise, detection of global Internet health problems is hampered by a lack of data sharing. The approaches used so far in the Internet, e.g. trusted third parties, or data anonymization, have been only partially successful, and are not widely adopted.The paper presents a method for performing computations on shared data without any participants revealing their secret data. For example, one can compute the sum of traffic over a set of service providers without any service provider learning the traffic of another. The method is simple, scalable, and flexible enough to perform a wide range of valuable operations on Internet data.",Network management; Network measurement; Secure distributed data-mining; Secure distributed summation,Distributed database systems; Information management; Internet; Problem solving; Security of data; Telecommunication networks; Telecommunication traffic; Network management; Network measurement; Secure distributed data mining; Secure distributed summation; Data mining
Ernst T.,1,The information technology era of the vehicular industry,2006,35,"Jun Murai Lab., Keio University, Japan",Keio University,1,Japan,1,18,18,"In this note, we discuss the emerging era of information technology in the vehicular industry. After reviewing the motivations leading to the use of information technology in vehicles, we investigate the networking requirements of the necessary communication system based on IP (Internet Protocol). Existing work that could meet these requirements is highlighted together with some existing projects. We also briefly introduce some research and deployment issues that will have to be considered.",In-vehicle network; Intelligent Transportation Systems (ITS); IPv6; Network Mobility (NEMO),Intelligent networks; Network protocols; Project management; Telecommunication networks; In-vehicle network; Intelligent Transportation Systems (ITS); IPv6; Network Mobility (NEMO); Automotive industry
Crowcroft J.,1,10 Networking papers: Recommended reading,2006,2,"University of Cambridge, Computer Laboratory, William Gates Building, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,14,7,"Ten networking papers discussed in ACM Computer Communication Review were recommended by Christophe Diot, the Editor-in-Chief for reading. Experience with grapevine: the growth of a distributed system is one such paper that has many ideas in how to actually do things right and includes some things people have forgotten. The synchronization of periodic routing messages uses an idea from physics and an approach to observe, and then to come up with a system design to eliminate a problem. Analysis of the parallel packet switch architecture is a mix of fundamental algorithms and hardware structures. How to build a gateway is a paper that pre-dates all the post-hoc rationalism of the IP world, while approximate aggregation techniques for sensor databases is a very good example of why research groups should not remain stovepiped.",Data Communications; Review,Database systems; Distributed computer systems; Packet networks; Routers; Synchronization; Systems analysis; Telecommunication networks; Periodic routing messages; Review; Sensor databases; Computer networks
"Rodriguez P., Tan S.-M., Gkantsidis C.",3,"On the feasibility of commercial, legal P2P content distribution",2006,73,"Microsoft Research, Cambridge, United Kingdom; Microsoft Corporation, Redmond, WA, United States",Microsoft,1,UK;USA,2,19,9,"A spirited panel was recently held at the 10th International Web Caching and Content Distribution workshop on the future of P2P in content distribution [1]. After more than ten years of content distribution research and technology efforts, P2P is emerging as an alternative solution to solve the mass distribution of large digital content. However, using P2P for commercial content distribution faces a number of serious challenges. Issues such as content protection, impact on ISPs, security, end-to-end connectivity, and business models need careful consideration before P2P can be used as an effi-cient tool by content providers. In this paper, we summarize the issues brought up in discussion, and delve deeper into the feasibility of commercial, legal P2P content distribution solutions.",Content distribution; P2P,Cryptography; Distributed database systems; Problem solving; Security of data; Technical presentations; World Wide Web; Content distribution; Content protection; Feasibility; P2P; Distributed computer systems
Ricciato F.,1,Unwanted traffic in 3G networks,2006,30,"Forschungszentrum Telekommunikation Wien, EU, Donau City Straße 1, Vienna, Austria","FTW,Austria",1,Austria,1,18,16,"The presence of ""unwanted"" (or background) traffic in the Internet is a well-known fact. In principle any network that has been engineered without taking its presence into account might experience troubles during periods of massive exposure to unwanted traffic, e.g. during large-scale infections. A concrete example was provided by the spreading of Code-Red-II in 2001, which caused several routers crashes worldwide. Similar events might take place in 3G networks as well, with further potential complications arising from their high functional complexity and the scarcity of radio resources. For example, under certain hypothetical network configuration settings unwanted traffic, and specifically scanning traffic from infected Mobile Stations, can cause large-scale wastage of logical resources, and in extreme cases even starvation. Unwanted traffic is present nowdays also in GPRS/UMTS, mainly due to the widespread use of 3G connect cards for laptops. We urge the research community and network operators to consider the issue of 3G robustness to unwanted traffic as a prominent research area.",3G; Cellular networks; Unwanted traffic,Computational complexity; Computer networks; Ground penetrating radar systems; Large scale systems; Robustness (control systems); Routers; 3G; Cellular networks; Unwanted traffic; Telecommunication traffic
Crowcroft J.,1,"The privacy and safety impact of technology choices for command, communications and control of the public highway",2006,4,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,6,5,"Monitoring, and command,communications and control of private vehicles on the public highway is now high on the political agenda. This is both because it is becoming feasible, and because it may be desirable. From the economic perspective, more efficient se of road resources may be achievable. From a safety perspective, it would clearly be good to reduce road injury and death statistics below the current ""9/11""'s-worth per year in the UK (and other similar sized European countries).Various prototypes, proposals and projects are being undertaken. There are a number of technologies that interact as well as numerous legal, political and economic stakeholders. In this note, we pay particular attention to the impact on privacy and safety of di .erent approaches to the overall problem.The purpose is to draw attention to the potential unintended consequences that result from decisions being made at the time of writing, in this arena.",Policy; Privacy; Safety; Transport,Communication systems; Data privacy; Highway systems; Problem solving; Security of data; Software prototyping; Economic stakeholders; Public highway; Road injury; Road resources; Command and control systems
"Xia Y., Subramanian L., Stoica I., Kalyanaraman S.",4,One more bit is enough,2005,65,"ECSE Department, Rensselaer Polytechnic Institute, United States; EECS Department, University of California, Berkeley, United States",Rensselaer Polytechnic Institute;University of California Berkeley,2,USA,1,70,51,"Achieving efficient and fair bandwidth allocation while minimizing packet loss in high bandwidth-delay product networks has long been a daunting challenge. Existing end-to-end congestion control (eg TCP) and traditional congestion notification schemes (eg TCP+AQM/ECN) have significant limitations in achieving this goal. While the recently proposed XCP protocol addresses this challenge, XCP requires multiple bits to encode the congestion-related information exchanged between routers and end-hosts. Unfortunately, there is no space in the IP header for these bits, and solving this problem involves a non-trivial and time-consuming standardization process.In this paper, we design and implement a simple, low-complexity protocol, called Variable-structure congestion Control Protocol (VCP), that leverages only the existing two ECN bits for network congestion feedback, and yet achieves comparable performance to XCP, ie high utilization, low persistent queue length, negligible packet loss rate, and reasonable fairness. On the downside, VCP converges significantly slower to a fair allocation than XCP. We evaluate the performance of VCP using extensive ns2 simulations over a wide range of network scenarios. To gain insight into the behavior of VCP, we analyze a simple fluid model, and prove a global stability result for the case of a single bottleneck link shared by flows with identical round-trip times. Copyright 2005 ACM.",AQM; Congestion control; ECN; Protocol; TCP; XCP,AQM; Congestion control; ECN; TCP; XCP; Channel capacity; Computational complexity; Network protocols; Packet networks; Problem solving; Signal encoding; Frequency allocation
"Yang X., Wetherall D., Anderson T.",3,A DoS-limiting network architecture,2005,84,"University of California, Irvine, United States; University of Washington, United States",University of California Irvine;University of Washington at St. Louis,2,USA,1,25,21,"We present the design and evaluation of TVA, a network architecture that limits the impact of Denial of Service (DoS) floods from the outset. Our work builds on earlier work on capabilities in which senders obtain short-term authorizations from receivers that they stamp on their packets. We address the full range of possible attacks against communication between pairs of hosts, including spoofed packet floods, network and host bottlenecks, and router state exhaustion. We use simulation to show that attack traffic can only degrade legitimate traffic to a limited extent, significantly outperforming previously proposed DoS solutions. We use a modified Linux kernel implementation to argue that our design can run on gigabit links using only inexpensive off-the-shelf hardware. Our design is also suitable for transition into practice, providing incremental benefit for incremental deployment. Copyright 2005 ACM.",Denial-of-service; Internet,Authorizations; Denial of service (DOS); Linux kernel implementation; Router state exhaustion; Computer simulation; Internet; Packet networks; Routers; Signal receivers; Telecommunication traffic; Telecommunication services
"Kandula S., Katabi D., Davie B., Charny A.",4,Walking the tightrope: Responsive yet stable traffic engineering,2005,106,"MIT CSAIL, United States; Cisco Systems",MIT,1,USA,1,42,31,"Current intra-domain Traffic Engineering (TE) relies on offline methods, which use long term average traffic demands. It cannot react to realtime traffic changes caused by BGP reroutes, diurnal traffic variations, attacks, or flash crowds. Further, current TE deals with network failures by pre-computing alternative routings for a limited set of failures. It may fail to prevent congestion when unanticipated or combination failures occur, even though the network has enough capacity to handle the failure.This paper presents TeXCP, an online distributed TE protocol that balances load in realtime, responding to actual traffic demands and failures. TeXCP uses multiple paths to deliver demands from an ingress to an egress router, adaptively moving traffic from over-utilized to under-utilized paths. These adaptations are carefully designed such that, though done independently by each edge router based on local information, they balance load in the whole network without oscillations. We model TeXCP, prove the stability of the model, and show that it is easy to implement. Our extensive simulations show that, for the same traffic demands, a network using TeXCP supports the same utilization and failure resilience as a network that uses traditional offline TE, but with half or third the capacity. Copyright 2005 ACM.",Distributed; Online; Responsive; Stable; TeXCP; Traffic engineering,Failure resilience; TeXCP; Traffic demands; Traffic engineering; Channel capacity; Computer system recovery; Online systems; Real time systems; Routers; Telecommunication traffic
"Lakshminarayanan K., Rangarajan A., Venkatachary S.",3,Algorithms for advanced packet classification with ternary CAMs,2005,147,"Univ. of California, Berkeley, United States; Cypress Semiconductor, United States",University of California Berkeley;,2,USA,1,25,19,"Ternary content-addressable memories (TCAMs) have gained wide acceptance in the industry for storing and searching Access Control Lists (ACLs). In this paper, we propose algorithms for addressing two important problems that are encountered while using TCAMs: reducing range expansion and multi-match classification.Our first algorithm addresses the problem of expansion of rules with range fields¿to represent range rules in TCAMs, a single range rule is mapped to multiple TCAM entries, which reduces the utilization of TCAMs. We propose a new scheme called Database Independent Range PreEncoding (DIRPE) that, in comparison to earlier approaches, reduces the worst-case number of TCAM entries a single rule maps on to. DIRPE works without prior knowledge of the database, scales when a large number of ranges is present, and has good incremental update properties.Our second algorithm addresses the problem of finding multiple matches in a TCAM. When searched, TCAMs return the first matching entry; however, new applications require either the first few or all matching entries. We describe a novel algorithm, called Multi-match Using Discriminators (MUD), that finds multiple matches without storing any per-search state information in the TCAM, thus making it suitable for multi-threaded environments. MUD does not increase the number of TCAM entries needed, and hence scales to large databases.Our algorithms do not require any modifications to existing TCAMs and are hence relatively easy to deploy. We evaluate the algorithms using real-life and random databases. Copyright 2005 ACM.",Multi-match; Packet classification; Range; Ternary CAMs,Access Control Lists (ACL); Multi-match Using Discriminators (MUD); Packet classification; Ternary CAM; Algorithms; Associative storage; Database systems; Pattern recognition; Problem solving; Packet networks
"Shavitt Y., Shir E.",2,DIMES: Let the internet measure itself,2005,279,"School of Electrical Engineering, Tel Aviv University, Israel",Tel Aviv University,1,Israel,1,17,14,"Today's Internet maps, which are all collected from a small number of vantage points, are falling short of being accurate. We suggest here a paradigm shift for this task. DIMES is a distributed measurement infrastructure for the Internet that is based on the deployment of thousands of light weight measurement agents around the globe. We describe the rationale behind DIMES deployment, discuss its design trade-offs and algorithmic challenges, and analyze the structure of the Internet as it seen with DIMES.",Distributed measurements; Internet topology,Algorithms; Computational complexity; Computer architecture; Data reduction; Distributed computer systems; Topology; Distributed measurements; Internet maps; Internet topology; Internet
"Griffin T.G., Sobrinho J.L.",2,Metarouting,2005,46,"Computer Laboratory, University of Cambridge, Cambridge, United Kingdom; Instituto de Telecomunicações, Instituto Superior Téécnico, Lisbon, Portugal",University of Cambridge,1,Portugal;UK,2,28,20,"There is a shortage of routing protocols that meet the needs of network engineers. This has led to BGP being pressed into service as an IGP, despite its lack of convergence guarantees. The development, standardization, and deployment of routing protocols, or even minor changes to existing protocols, are very difficult tasks. We present an approach called Metarouting that defines routing protocols using a high-level and declarative language. Once an interpreter for a metarouting language is implemented on a router, a network operator would have the freedom to implement and use any routing protocol definable in the language. We enforce a clean separation of protocol mechanisms (link-state, path-vector, adjacency maintenance, and so on) from routing policy (how routes are described and compared). The Routing Algebra framework of Sobrinho [25] is used as the theoretical basis for routing policy languages. We define the Routing Algebra Meta-Language (RAML) that allows for the construction of a large family of routing algebras and has the key property that correctness conditions - - guarantees of convergence with respect to the chosen mechanisms - - can be derived automatically for each expression defining a new routing algebra. Copyright 2005 ACM.",Algebraic routing; Path algebras; Routing protocols,Algebra; Computer programming languages; Convergence of numerical methods; Metadata; Routers; Algebraic routing; Network engineers; Path algebras; Routing protocols; Network protocols
"Ratnasamy S., Shenker S., McCanne S.",3,Towards an evolvable internet architecture,2005,22,"Intel Research, Berkeley, United States; U.C. Berkeley, ICSI, United States; Riverbed Technology",Intel;University of California Berkeley,2,USA,1,60,52,"There is widespread agreement on the need for architectural change in the Internet, but very few believe that current ISPs will ever effect such changes. In this paper we ask what makes an architecture evolvable, by which we mean capable of gradual change led by the incumbent providers. This involves both technical and economic issues, since ISPs have to be able, and incented, to offer new architectures. Our study suggests that, with very minor modifications, the current Internet architecture could be evolvable. Copyright 2005 ACM.",Anycast; Network architecture,Anycast; Network architecture; Computer architecture; Information theory; Internet
"Chawathe Y., Ramabhadran S., Ratnasamy S., LaMarca A., Shenker S., Hellerstein J.",6,A case study in building layered DHT applications,2005,73,"Intel Research Seattle, United States; UC San Diego, United States; ICSI, UC Berkeley, United States; Intel Research Berkeley, United States",Intel;University of California Berkeley;University of California San Diego,3,USA,1,35,32,"Recent research has shown that one can use Distributed Hash Tables (DHTs) to build scalable, robust and efficient applications. One question that is often left unanswered is that of simplicity of implementation and deployment. In this paper, we explore a case study of building an application for which ease of deployment dominated the need for high performance. The application we focus on is Place Lab, an end-user positioning system. We evaluate whether it is feasible to use DHTs as an application-independent building block to implement a key component of Place Lab: its ""mapping infrastructure."" We present Prefix Hash Trees, a data structure used by Place Lab for geographic range queries that is built entire on top of a standard DHT. By strictly layering Place Lab's data structures on top of a generic DHT service, we were able to decouple the deployment and management of Place Lab from that of the underlying DHT. We identify the characteristics of Place Lab that made it amenable for deploying in this layered manner, and comment on its effect on performance. Copyright 2005 ACM.",DHTs; Layering; Range queries,Distributed Hash Tables (DHT); Layering; Place Lab; Range queries; Data structures; Information management; Query languages; Robustness (control systems); Information theory
"Teixeira R., Agarwal S., Rexford J.",3,BGP routing changes: Merging views from two ISPs,2005,16,"UC San Diego, San Diego, CA, United States; Microsoft Research, Redmond, WA, United States; Princeton University, Princeton, NJ, United States",Microsoft;Princeton University;University of California San Diego,3,USA,1,16,16,"Large ISPs experience millions of BGP routing changes a day. In this paper, we discuss the impact of BGP routing changes on the flow of trafffic, summarizing and reconciling the results from six measurement studies of the Sprint and AT&T backbone networks.",BGP; Hot-potato routing; Traffic demands; Traffic matrix,BGP; Hot-potato routing; Traffic demands; Traffic matrix; Data communication systems; Internet; Telecommunication traffic; Routers
"Vergetis E., Guérin R., Sarkar S.",3,Realizing the benefits of user-level channel diversity,2005,11,"University of Pennsylvania, 200 South 33rd Street, Philadelphia, PA 19104, United States",University of Pennsylvania,1,USA,1,30,24,"Channel or path diversity is known to improve performance in physical layer designs, channel access strategies, path switching mechanisms, etc. In this paper, we focus on ""user-level"" mechanisms that operate simply by distributing packet transmissions across multiple channels. We seek to understand when, why, and to what extent this can be of benefit, and equally important, whether these benefits can be realized with as little of an added cost as possible. In that context, our main contribution is not so much in identifying optimal policies for leveraging channel diversity, but in introducing the concept of channel ""equivalence"" and demonstrating that channel diversity yields substantial benefits mostly when channels are approximately equivalent. We build on this finding to investigate the robustness of these improvements against errors in the characterization of the available channels or changes in their characteristics. We also explore the sensitivity of the results as the number of available channels varies. The findings of the paper demonstrate that by allowing packet transmissions from multiple users to intelligently share channels, it is possible to improve overall performance and robustness through simple and portable user-level mechanisms.",Channel diversity; Cross-layer designs; Open-loop control; Robustness,Approximation theory; Distributed computer systems; Error analysis; Packet networks; Robustness (control systems); User interfaces; Channel diversity; Cross-layer designs; Open-loop control; Communication channels (information theory)
"Feamster N., Johari R., Balakrishnan H.",3,Implications of autonomy for the expressiveness of policy routing,2005,18,"MIT, United States; Stanford University, United States",MIT;Stanford University,2,USA,1,18,17,"Thousands of competing autonomous systems must cooperate with each other to provide global Internet connectivity. Each autonomous system (AS) encodes various economic, business, and performance decisions in its routing policy. The current interdomain routing system enables each AS to express policy using rankings that determine how each router inthe AS chooses among different routes to a destination, and filters that determine which routes are hidden from each neighboring AS. Because the Internet is composed of many independent, competing networks, the interdomain routing system should provide autonomy, allowing network operators to set their rankings independently, and to have no constraints on allowed filters. This paper studies routing protocol stability under these conditions. We first demonstrate that certain rankings that are commonly used in practice may not ensure routing stability. We then prove that, when providers can set rankings and filters autonomously, guaranteeing that the routing system will converge to a stable path assignment essentially requires ASes to rank routes based on AS-path lengths. We discuss the implications of these results for the future of interdomain routing. Copyright 2005 ACM.",Autonomy; BGP; Internet; Policy; Protocol; Routing; Safety; Stability,Autonomous system (AS); Autonomy; BGP; Routing; Constraint theory; Electronic commerce; Internet; Network protocols; Routers; Signal filtering and prediction; System stability; Autonomous agents
"Bishop S., Fairbairn M., Norrish M., Sewell P., Smith M., Wansbrough K.",6,"Rigorous specification and conformance testing techniques for network protocols, as applied to TCP, UDP, and sockets",2005,19,"University of Cambridge, Computer Laboratory, United Kingdom; NICTA, Canberra, Australia",NICTA;University of Cambridge,2,Australia;UK,2,40,30,"Network protocols are hard to implement correctly. Despite the existence of RFCs and other standards, implementations often have subtle differences and bugs. One reason for this is that the specifications are typically informal, and hence inevitably contain ambiguities. Conformance testing against such specifications is challenging.In this paper we present a practical technique for rigorous protocol specification that supports specification-based testing. We have applied it to TCP, UDP, and the Sockets API, developing a detailed 'post-hoc' specification that accurately reflects the behaviour of several existing implementations (FreeBSD 4.6, Linux 2.4.20-8, and Windows XP SP1). The development process uncovered a number of differences between and infelicities in these implementations.Our experience shows for the first time that rigorous specification is feasible for protocols as complex as TCP. We argue that the technique is also applicable 'pre-hoc', in the design phase of new protocols. We discuss how such a design-for-test approach should influence protocol development, leading to protocol specifications that are both unambiguous and clear, and to high-quality implementations that can be tested directly against those specifications. Copyright 2005 ACM.",API; Conformance testing; Higher-order logic; HOL; Network protocols; Operational semantics; Sockets; Specification; TCP/IP,API; Conformance testing; Higher-order logic; HOL; Operational semantics; Sockets; TCP/IP; Computer operating systems; Electric connectors; Logic design; Specifications; Network protocols
"Biswas S., Morris R.",2,ExOR: Opportunistic multi-hop routing for wireless networks,2005,718,"M.I.T. Computer Science and Artifical Intelligence Laboratory, United States",MIT,1,USA,1,21,18,"This paper describes ExOR,an integrated routing and MAC protocol that increases the throughput of large unicast transfers in multi-hop wireless networks. ExOR chooses each hop of a packet's route after the transmission for that hop, so that the choice can reflect which intermediate nodes actually received the transmission. This deferred choice gives each transmission multiple opportunities to make progress. As a result ExOR can use long radio links with high loss rates, which would be avoided by traditional routing. ExOR increases a connection's throughput while using no more network capacity than traditional routine.ExOR's design faces the following challenges. The nodes that receive each packet must agree on their identities and choose one forwarder.The agreement protocol must have low overhead, but must also be robust enough that it rarely forwards a packet zero times or more than once. Finally, ExOR must choose the forwarder with the lowest remaining cost to the ultimate destination.Measurements of an implementation on a 38-node 802.11b test-bed show that ExOR increases throughput for most node pairs when compared with traditional routing. For pairs between which traditional routing uses one or two hops, ExOR's robust acknowledgments prevent unnecessary retransmissions, increasing throughput by nearly 35%. For more distant pairs, ExOR takes advantage of the choice of forwarders to provide throughput gains of a factor of two to four. Copyright 2005 ACM.",802.11; Mesh; Wireless,802.11; Integrated routing; Intermediate nodes; Retransmissions; Carrier communication; Network protocols; Packet networks; Routers; Wireless telecommunication systems; Computer networks
"Heusse M., Rousseau F., Guillier R., Duda A.",4,Idle sense: An optimal access method for high throughput and fairness in rate diverse wireless LANs,2005,248,"LSR-IMAG Laboratory, Grenoble, France","IMAG Laboratory,France",1,France,1,30,26,"We consider wireless LANs such as IEEE 802.11 operating in the unlicensed radio spectrum. While their nominal bit rates have increased considerably, the MAC layer remains practically unchanged despite much research effort spent on improving its performance. We observe that most proposals for tuning the access method focus on a single aspect and disregard others. Our objective is to define an access method optimized for throughput and fairness, able to dynamically adapt to physical channel conditions, to operate near optimum for a wide range of error rates, and to provide equal time shares when hosts use different bit rates.We propose a novel access method derived from 802.11 DCF [2] (Distributed Coordination Function) in which all hosts use similar values of the contention window CW to benefit from good short-term access fairness. We call our method Idle Sense, because each host observes the mean number of idle slots between transmission attempts to dynamically control its contention window. Unlike other proposals, Idle Sense enables each host to estimate its frame error rate, which can be used for switching to the right bit rate. We present simulations showing how the method leads to high throughput, low collision overhead, and low delay. The method also features fast reactivity and time-fair channel allocation. Copyright 2005 ACM.",802.11; Access methods; Fairness; Wireless LANs,Carrier communication; Communication channels (information theory); Computer simulation; Optimization; Radio communication; 802.11; Access methods; Fairness; Wireless LAN; Local area networks
Kuzmanovic A.,1,The power of explicit congestion notification,2005,26,"Department of Computer Science, Northwestern University, United States",Northwestern University,1,USA,1,33,25,"Despite the fact that Explicit Congestion Notification (ECN) demonstrated a clear potential to substantially improve network performance, recent network measurements reveal an extremely poor usage of this option in today's Internet. In this paper, we analyze the roots of this phenomenon and develop a set of novel incentives to encourage network providers, end-hosts, and web servers to apply ECN.Initially, we examine a fundamental drawback of the current ECN specification, and demonstrate that the absence of ECN indications in TCP control packets can dramatically hinder system performance. While security reasons primarily prevent the usage of ECN bits in TCP SYN packets, we show that applying ECN to TCP SYN ACK packets can significantly improve system performance without introducing any novel security or stability side-effects. Our network experiments on a cluster of web servers show a dramatic performance improvement over the existing ECN specification: throughput increases by more than 40%, while the average web response-time simultaneously decreases by nearly an order of magnitude.In light of the above finding, using large-scale simulations, modeling, and network experiments, we re-investigate the relevance of ECN, and provide a set of practical recommendations and insights: (i) ECN systematically improves the performance of all investigated AQM schemes; contrary to common belief, this particularly holds for RED. (ii) The impact of ECN is highest for web-only traffic mixes such that even a generic AQM algorithm with ECN support outperforms all non-ECN-enabled AQM schemes that we investigated. (iii) Primarily due to moderate queuing levels, the superiority of ECN over other AQM mechanisms largely holds for high-speed backbone routers, even in more general traffic scenarios. (iv) End-hosts that apply ECN can exercise the above performance benefits instantly, without waiting for the entire Internet community to support the option. Copyright 2005 ACM.",Active queue management; Congestion control; Explicit congestion notification,Active queue management; Congestion control; Explicit Congestion Notification (ECN); Algorithms; Internet; Packet networks; Queueing networks; Security of data; System stability; Telecommunication traffic; Channel capacity
"Song H., Dharmapurikar S., Turner J., Lockwood J.",4,Fast hash table lookup using extended bloom filter: An aid to network processing,2005,161,"Applied Research Lab., Washington University in Saint Louis, Saint Louis, MO 63130, United States",University of Washington at St. Louis,1,USA,1,29,21,"Hash tables are fundamental components of several network processing algorithms and applications, including route lookup, packet classification, per-flow state management and network monitoring. These applications, which typically occur in the data-path of high-speed routers, must process and forward packets with little or no buffer, making it important to maintain wire-speed throughout. A poorly designed hash table can critically affect the worst-case throughput of an application, since the number of memory accesses required for each lookup can vary. Hence, high throughput applications require hash tables with more predictable worst-case lookup performance. While published papers often assume that hash table lookups take constant time, there is significant variation in the number of items that must be accessed in a typical hash table search, leading to search times that vary by a factor of four or more.We present a novel hash table data structure and lookup algorithm which improves the performance over a naive hash table by reducing the number of memory accesses needed for the most time-consuming lookups. This allows designers to achieve higher lookup performance for a given memory bandwidth, without requiring large amounts of buffering in front of the lookup engine. Our algorithm extends the multiple-hashing Bloom Filter data structure to support exact matches and exploits recent advances in embedded memory technology. Through a combination of analysis and simulations we show that our algorithm is significantly faster than a naive hash table using the same amount of memory, hence it can support better throughput for router applications that use hash tables. Copyright 2005 ACM.",Forwarding; Hash table,Algorithms; Data structures; Packet networks; Pattern recognition; Routers; Storage allocation (computer); Bloom filters; Forwarding; Hash table; Network processing; Signal filtering and prediction
"Al Hamra A., Felber P.A.",2,Design choices for content distribution in P2P networks,2005,12,"IUT of Nice, GTR Departement, Sophia Antipolis, France; Université de Neuchâtel, Institut d'Informatique, Switzerland",Université de Neuchâtel,1,France;Switzerland,2,7,6,"Content distribution using the P2P paradigm has become one of the most dominant services in the Internet today. Most of the research effort in this area focuses on developing new distribution architectures. However, little work has gone into identifying the principle design choices that draw the behavior of the system. In this paper, we identify these design choices and show how they in uence the performance of different P2P architectures. For example, we discuss how clients should organize and cooperate in the network. We believe that our findings can serve as guidelines in the design of efficient future architectures.",Content distribution; Peer to peer networks; Performance evaluation,Client server computer systems; Codes (standards); Computer architecture; Logic design; Content distribution; Peer to peer networks; Performance evaluation; Internet
"DeHart J., Kuhns F., Parwatikar J., Turner J., Wiseman C., Wong K.",6,The open network laboratory: A resource for networking research and education,2005,9,"Applied Research Laboratory, Department of Computer Science and Engineering, Washington University in St. Louis, St. Louis, MO 63130, United States",University of Washington at St. Louis,1,USA,1,6,4,"The Open Network Laboratory (ONL) is a remotely accessible network testbed designed to enable networking faculty, students and researchers to conduct experiments using high performance routers and applications. The system is built around a set of extensible, high-performance routers and has a graphical interface that enables users to easily configure and run experiments remotely. ONL's Remote Laboratory Interface (RLI) allows users to easily configure a network topology, configure routes and packet filters in the routers, assign flows or flow aggregates to separate queues with configurable QoS and attach hardware monitoring points to real-time charts. The remote visualization features of the RLI make it easy to directly view the effects of traffic as it moves through a router, allowing the user to gain better insight into system behavior and create compelling demonstrations. Each port of the router is equipped with an embedded processor that provides a simple environment for software plugins allowing users to extend the system's functionality. This paper describes the general facilties and some networking experiments that can be carried out. We hope that you and your collegues and students will check out the facility and register for an account at our web site onl.arl.wustl.edu.",Education; Experimental testbed; Real-time displays,Experimental testbeds; Real-time displays; Remote laboratory interface (RLI); Education; Interfaces (computer); Research and development management; Resource allocation; Routers; Students; Computer networks
"Xu K., Zhang Z.-L., Bhattacharyya S.",3,Profiling internet backbone traffic: Behavior models and applications,2005,150,"Computer Science Dept., University of Minnesota, Minneapolis, MN, United States; Sprint ATL, One Adrian Court, Burlingame, CA, United States",University of Minnesota,1,USA,1,30,23,"Recent spates of cyber-attacks and frequent emergence of applications affecting Internet traffic dynamics have made it imperative to develop effective techniques that can extract, and make sense of, significant communication patterns from Internet traffic data for use in network operations and security management. In this paper, we present a general methodology for building comprehensive behavior profiles of Internet backbone traffic in terms of communication patterns of end-hosts and services. Relying on data mining and information-theoretic techniques, the methodology consists of significant cluster extraction, automatic behavior classification and structural modeling for in-depth interpretive analyses. We validate the methodology using data sets from the core of the Internet. The results demonstrate that it indeed can identify common traffic profiles as well as anomalous behavior patterns that are of interest to network operators and security analysts. Copyright 2005 ACM.",Behavior profiles; Network monitoring; Traffic measurement,Computer crime; Data mining; Internet; Mathematical models; Pattern recognition; Security of data; Behavior profiles; Cluster extraction; Network monitoring; Traffic measurement; Telecommunication traffic
"Li J., Dou D., Wu Z., Kim S., Agarwal V.",5,An internet routing forensics framework for discovering rules of abnormal BGP events,2005,30,"University of Oregon, United States",University of Oregon,1,USA,1,34,30,"Abnormal BGP events such as attacks, misconfigurations, electricity failures, can cause anomalous or pathological routing behavior at either global level or prefix level, and thus must be detected in their early stages. Instead of using ad hoc methods to analyze BGP data, in this paper we introduce an Internet Routing Forensics framework to systematically process BGP routing data, discover rules of abnormal BGP events, and apply these rules to detect the occurrences of these events. In particular, we leverage data mining techniques to train the framework to learn rules of abnormal BGP events, and our results from two case studies show that these rules are effective. In one case study, rules of worm events discovered from the BGP data during the outbreaks of the CodeRed and Nimda worms were able to successfully detect worm impact on BGP when an independent worm, the Slammer, subsequently occurred. Similarly, in another case study, rules of electricity blackout events obtained using BGP data from the 2003 East Coast blackout were able to detect the BGP impact from the Florida blackout caused by Hurricane Frances in 2004.",Abnormal BGP events; Blackout; Data mining; Internet worms; Routing forensics,Abnormal BGP events; Blackout; Internet worms; Routing forensics; Computer simulation; Computer worms; Data mining; Internet; Routers; Computer architecture
"Wong B., Slivkins A., Sirer E.G.",3,Meridian: A lightweight network location service without virtual coordinates,2005,146,"Dept. of Computer Science, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,61,58,"This paper introduces a lightweight, scalable and accurate framework, called Meridian, for performing node selection based on network location. The framework consists of an overlay network structured around multi-resolution rings, query routing with direct measurements, and gossip protocols for dissemination. We show how this framework can be used to address three commonly encountered problems, namely, closest node discovery, central leader election, and locating nodes that satisfy target latency constraints in large-scale distributed systems without having to compute absolute coordinates. We show analytically that the framework is scalable with logarithmic convergence when Internet latencies are modeled as a growth-constrained metric, a low-dimensional Euclidean metric, or a metric of low doubling dimension. Large scale simulations, based on latency measurements from 6.25 million node-pairs as well as an implementation deployed on PlanetLab show that the framework is accurate and effective. Copyright 2005 ACM.",Nearest neighbor; Network locality; Node selection,Computer simulation; Convergence of numerical methods; Network protocols; Query languages; Routers; Virtual reality; Nearest neighbors; Network locality; Node selection; Overlay networks; Telecommunication services
"Sommers J., Barford P., Duffield N., Ron A.",4,Improving accuracy in end-to-end packet loss measurement,2005,52,"University of Wisconsin, Madison, United States; AT and T Labs-Research, United States",AT and T Labs;University of Wisconsin-Madison,2,USA,1,39,34,"Measurement and estimation of packet loss characteristics are challenging due to the relatively rare occurrence and typically short duration of packet loss episodes. While active probe tools are commonly used to measure packet loss on end-to-end paths, there has been little analysis of the accuracy of these tools or their impact on the network. The objective of our study is to understand how to measure packet loss episodes accurately with end-to-end probes. We begin by testing the capability of standard Poisson-modulated end-to-end measurements of loss in a controlled laboratory environment using IP routers and commodity end hosts. Our tests show that loss characteristics reported from such Poisson-modulated probe tools can be quite inaccurate over a range of traffic conditions. Motivated by these observations, we introduce a new algorithm for packet loss measurement that is designed to overcome the deficiencies in standard Poisson-based tools. Specifically, our method creates a probe process that (1) enables an explicit trade-off between accuracy and impact on the network, and (2) enables more accurate measurements than standard Poisson probing at the same rate. We evaluate the capabilities of our methodology experimentally by developing and implementing a prototype tool, called BADABING. The experiments demonstrate the trade-offs between impact on the network and measurement accuracy. We show that BADABING reports loss characteristics far more accurately than traditional loss measurement tools. Copyright 2005 ACM.",Active measurement; BADABING; Network congestion; Network probes; Packet loss,Active measurement; BADABING; Network congestion; Network probes; Packet loss; Algorithms; Congestion control (communication); Network protocols; Poisson distribution; Routers; Telecommunication traffic; Packet networks
"Loo B.T., Hellerstein J.M., Stoica I., Ramakrishnan R.",4,Declarative routing: Extensible routing with declarative queries,2005,57,"UC Berkeley, United States; Intel Research, United States; University of Wisconsin, Madison, United States",Intel;University of California Berkeley;University of Wisconsin-Madison,3,USA,1,28,13,"The Internet's core routing infrastructure, while arguably robust and efficient, has proven to be difficult to evolve to accommodate the needs of new applications. Prior research on this problem has included new hard-coded routing protocols on the one hand, and fully extensible Active Networks on the other. In this paper, we explore a new point in this design space that aims to strike a better balance between the extensibility and robustness of a routing infrastructure. The basic idea of our solution, which we call declarative routing, is to express routing protocols using a database query language. We show that our query language is a natural fit for routing, and can express a variety of well-known routing protocols in a compact and clean fashion. We discuss the security of our proposal in terms of its computational expressive power and language design. Via simulation, and deployment on PlanetLab, we demonstrate that our system imposes no fundamental limits relative to traditional protocols, is amenable to query optimizations, and can sustain long-lived routes under network churn and congestion. Copyright 2005 ACM.",Declarative queries; Extensible routing; Routing languages,Declarative queries; Design space; Extensible routing; Routing languages; Active networks; Internet; Network protocols; Optimization; Query languages; Robustness (control systems); Security of data; Routers
"Briscoe B., Jacquet A., Di Cairano-Gilfedder C., Salvatori A., Soppera A., Koyabe M.",6,Policing congestion response in an internetwork using re-feedback,2005,20,"BT Research, UCL, United Kingdom; BT Research, United Kingdom; Eurécom, BT Research",BT Research,1,UK,1,21,20,"This paper introduces a novel feedback arrangement, termed re-feedback. It ensures metrics in data headers such as time to live and congestion notification will arrive at each relay carrying a truthful prediction of the remainder of their path. We propose mechanisms at the network edge that ensure the dominant selfish strategy of both network domains and end-points will be to set these headers honestly and to respond correctly to path congestion and delay, despite conflicting interests. Although these mechanisms influence incentives, they don't involve tampering with end-user pricing. We describe a TCP rate policer as a specific example of this new capability. We show it can be generalised to police various qualities of service. We also sketch how a limited form of re-feedback could be deployed incrementally around unmodified routers without changing IP. Copyright 2005 ACM.",Characterisation; Congestion; Incentives; Policing; QoS,Congestion notification; Network domains; Network edges; Path congestion; Characterization; Data reduction; Internet; Quality of service; Routers; Channel capacity
"He Q., Dovrolis C., Ammar M.",3,On the predictability of large transfer TCP throughput,2005,55,"Georgia Tech., United States",Georgia Tech,1,USA,1,24,20,"Predicting the throughput of large TCP transfers is important for a broad class of applications. This paper focuses on the design, empirical evaluation, and analysis of TCP throughput predictors. We first classify TCP throughput prediction techniques into two categories: Formula-Based (FB) and History-Based (HB). Within each class, we develop representative prediction algorithms, which we then evaluate empirically over the RON testbed. FB prediction relies on mathematical models that express the TCP throughput as a function of the characteristics of the underlying network path. It does not rely on previous TCP transfers in the given path, and it can be performed with non-intrusive network measurements. We show, however, that the FB method is accurate only if the TCP transfer is window-limited to the point that it does not saturate the underlying path, and explain the main causes of the prediction errors. HB techniques predict the throughput of TCP flows from a time series of previous TCP throughput measurements on the same path, when such a history is available. We show that even simple HB predictors, such as Moving Average and Holt-Winters, using a history of few and sporadic samples, can be quite accurate. On the negative side, HB predictors are highly path-dependent. We explain the cause of such path dependencies based on two key factors: the load on the path and the degree of statistical multiplexing. Copyright 2005 ACM.",Network measurement; Performance evaluation; TCP modeling; Time series forecasting,Network measurements; Performance evaluation; TCP modeling; Time series forecasting; Algorithms; Error analysis; Function evaluation; Mathematical models; Signal filtering and prediction; Time series analysis; Data transfer
"Shannon C., Moore D., Keys K., Fomenkov M., Huffaker B., Claffy K.",6,The internet measurement data catalog,2005,20,"CAIDA, San Diego Supercomputer Center, University of California, San Diego, United States",University of California San Diego,1,USA,1,7,4,"Internet data remains one of the basic components of computer science network research. Despite its necessity, available data is limited by legal, social, and technical constraints on its collection and distribution. Thus, optimal distribution of knowledge about available data is a valuable service to the research community. To this end, CAIDA has developed the Internet Measurement Data Catalog to:provide a searchable index of available dataenhance documentation of datasets via a public annotation systemadvance network science by promoting reproducible researchThis paper describes the impetus, design, and planned deployment of the Internet Measurement Data Catalog.",Annotations; Data sharing; Database; Internet; Measurement; Metadata; Monitoring,Annotations; Data sharing; Datasets; Network science; Computer science; Engineering research; Internet; Measurement theory; Metadata; Monitoring; Database systems
"Hasan J., Vijaykumar T.N.",2,Dynamic pipelining: Making IP-lookup truly scalable,2005,29,"School of Electrical and Computer Engineering, Purdue University, United States",Purdue University,1,USA,1,19,13,"A truly scalable IP-lookup scheme must address five challenges of scalability, namely: routing-table size, lookup throughput, implementation cost, power dissipation, and routing-table update cost. Though several IP-lookup schemes have been proposed in the past, none of them do well in all the five scalability requirements. Previous schemes pipeline tries by mapping trie levels to pipeline stages. We make the fundamental observation that because this mapping is static and oblivious of the prefix distribution, the schemes do not scale well when worst-case prefix distributions are considered. This paper is the first to meet all the five requirements in the worst case. We propose scalable dynamic pipelining (SDP) which includes three key innovations: (1) We map trie nodes to pipeline stages based on the node height. Because the node height is directly determined by the prefix distribution, the node height succinctly provides sufficient information about the distribution. Our mapping enables us to prove a worst-case per-stage memory bound which is significantly tighter than those of previous schemes. (2) We exploit our mapping to propose a novel scheme for incremental route-updates. In our scheme a route-update requires exactly and only one write dispatched into the pipeline. This route-update cost is obviously the optimum and our scheme achieves the optimum in the worst case. (3) We achieve scalability in throughput by simultaneously pipelining at the data-structure level and the hardware level. SDP naturally scales in power and implementation cost. We not only present a theoretical analysis but also evaluate SDP and a number of previous schemes using detailed hardware simulation. Compared to previous schemes, we show that SDP is the only scheme that scales well in all the five requirements. Copyright 2005 ACM.",IP-lookup; Longest prefix matching; Pipelined; Scalable; Tries,IP-lookup; Longest prefix matching; Scalable dynamic pipelining (SDP); Worst case prefix distributions; Conformal mapping; Data structures; Internet; Routers; Storage allocation (computer); Network protocols
"Subramanian L., Caesar M., Ee C.T., Handley M., Mao M., Shenker S., Stoica I.",7,HLP: A next generation inter-domain routing protocol,2005,56,"University of California, Berkeley, United States; University College London, United Kingdom; University of Michigan, United States",University College London;University of California Berkeley;University of Michigan at Ann Arbor,3,UK;USA,2,32,26,"It is well-known that BGP, the current inter-domain routing protocol, has many deficiencies. This paper describes a hybrid link-state and path-vector protocol called HLP as an alternative to BGP that has vastly better scalability, isolation and convergence properties. Using current BGP routing information, we show that HLP, in comparison to BGP, can reduce the churn-rate of route updates by a factor 400 as well as isolate the effect of routing events to a region 100 times smaller than that of BGP. For a majority of Internet routes, HLP guarantees worst-case linear-time convergence. We also describe a prototype implementation of HLP on top of the XORP router platform. HLP is not intended to be a finished and final proposal for a replacement for BGP, but is instead offered as a starting point for debates about the nature of the next-generation inter-domain routing protocol. Copyright 2005 ACM.",BGP; Convergence; Inter-domain routing; Scalability,BGP; Interdomain routing; Routing protocol; Scalability; Convergence of numerical methods; Internet; Motion planning; Routers; Vectors; Network protocols
Roughan M.,1,Simplifying the synthesis of internet traffic matrices,2005,54,"School of Mathematical Sciences, University of Adelaide, Adelaide, 5005, Australia",University of Adelaide,1,Australia,1,17,13,"A recent paper [8] presented methods for several steps along the road to synthesis of realistic traffic matrices. Such synthesis is needed because traffic matrices are a crucial input for testing many new networking algorithms, but traffic matrices themselves are generally kept secret by providers. Furthermore, even given traffic matrices from a real network, it is difficult to realistically adjust these to generate a range of scenarios (for instance for different network sizes). This note is concerned with the first step presented in [8]: generation of a matrix with similar statistics to that of a real traffic matrix. The method applied in [8] is based on fitting a large number of distributions, and finding that the log-normal distribution appears to fit most consistently. Best fits (without some intuitive explanation for the fit) are fraught with problems. How general are the results? How do the distribution parameters relate? This note presents a simpler approach based on a gravity model. Its simplicity provides us with a better understanding of the origins of the results of [8], and this insight is useful, particularly because it allows one to adapt the synthesis process to different scenarios in a more intuitive manner. Additionally, [8] measures the quality of its fit to the distribution's body. This note shows that the tails of the distributions are less heavy than the log-normal distribution (a counterintuitive result for Internet traffic), and that the gravity model replicates these tails more accurately.",Topology; Traffic characterization; Traffic matrices,Algorithms; Computer networks; Distributed computer systems; Normal distribution; Real time systems; Topology; Log-normal distribution; Traffic characterization; Traffic matrices; Telecommunication traffic
"Karagiannis T., Papagiannaki K., Faloutsos M.",3,BLINC: Multilevel traffic classification in the dark,2005,532,"UC Riverside, United States; Intel Research, Cambridge",Intel;University of California Riverside,2,USA,1,23,17,"We present a fundamentally different approach to classifying traffic flows according to the applications that generate them. In contrast to previous methods, our approach is based on observing and identifying patterns of host behavior at the transport layer. We analyze these patterns at three levels of increasing detail (i) the social, (ii) the functional and (iii) the application level. This multilevel approach of looking at traffic flow is probably the most important contribution of this paper. Furthermore, our approach has two important features. First, it operates in the dark, having (a) no access to packet payload, (b) no knowledge of port numbers and (c) no additional information other than what current flow collectors provide. These restrictions respect privacy, technological and practical constraints. Second, it can be tuned to balance the accuracy of the classification versus the number of successfully classified traffic flows. We demonstrate the effectiveness of our approach on three real traces. Our results show that we are able to classify 80%-90% of the traffic with more than 95% accuracy. Copyright 2005 ACM.",Host behavior; Traffic classification; Transport layer,Host behavior; Traffic classification; Traffic flows; Transport layers; Computer privacy; Constraint theory; Packet networks; Pattern recognition; Telecommunication traffic
"Lakhina A., Crovella M., Diot C.",3,Mining anomalies using traffic feature distributions,2005,512,"Dept. of Computer Science, Boston University, United States; Intel Research, Cambridge, United Kingdom",Boston University;Intel,2,UK;USA,2,36,27,"The increasing practicality of large-scale flow capture makes it possible to conceive of traffic analysis methods that detect and identify a large and diverse set of anomalies. However the challenge of effectively analyzing this massive data source for anomaly diagnosis is as yet unmet. We argue that the distributions of packet features (IP addresses and ports) observed in flow traces reveals both the presence and the structure of a wide range of anomalies. Using entropy as a summarization tool, we show that the analysis of feature distributions leads to significant advances on two fronts: (1) it enables highly sensitive detection of a wide range of anomalies, augmenting detections by volume-based methods, and (2) it enables automatic classification of anomalies via unsupervised learning. We show that using feature distributions, anomalies naturally fall into distinct and meaningful clusters. These clusters can be used to automatically classify anomalies and to uncover new anomaly types. We validate our claims on data from two backbone networks (Abilene and Geant) and conclude that feature distributions show promise as a key element of a fairly general network anomaly diagnosis framework. Copyright 2005 ACM.",Anomaly classification; Anomaly detection; Network-wide traffic analysis,Anomaly classification; Anomaly detection; Data sources; Network wide traffic analysis; Data structures; Feature extraction; Packet networks; Telecommunication traffic; Data mining
"Rhea S., Godfrey B., Karp B., Kubiatowicz J., Ratnasamy S., Shenker S., Stoica I., Yu H.",8,OpenDHT: A public DHT service and its uses,2005,143,"UC Berkeley, Intel Research, United States",Intel;University of California Berkeley,2,USA,1,35,30,"Large-scale distributed systems are hard to deploy, and distributed hash tables (DHTs) are no exception. To lower the barriers facing DHT-based applications, we have created a public DHT service called OpenDHT. Designing a DHT that can be widely shared, both among mutually untrusting clients and among a variety of applications, poses two distinct challenges. First, there must be adequate control over storage allocation so that greedy or malicious clients do not use more than their fair share. Second, the interface to the DHT should make it easy to write simple clients, yet be sufficiently general to meet a broad spectrum of application requirements. In this paper we describe our solutions to these design challenges. We also report our early deployment experience with OpenDHT and describe the variety of applications already using the system. Copyright 2005 ACM.",Distributed hash table; Peer-to-peer; Resource allocation,Distributed hash table (DHT); Distributed systems; OpenDHT; Distributed computer systems; Interfaces (computer); Resource allocation; Storage allocation (computer); Telecommunication services
"Deegan T., Crowcroft J., Warfield A.",3,The main name system: An exercise in centralized computing,2005,15,"University of Cambridge, Computer Laboratory, 15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,34,24,"Naming is a critical component of the internet architecture, and one whose complexity is often overlooked. As a global system, the DNS must satisfy millions of requests per second, while allowing distributed, delegated administration and maintenance. In this paper, we consider the design of the DNS and the widely distributed manner in which DNS records are published. We propose that the robustness and performance of the existing DNS could be dramatically improved by moving towards a centralized architecture while maintaining the existing client interface and delegated administration.",DNS,Computational complexity; Distributed computer systems; Interfaces (computer); Preventive maintenance; Robustness (control systems); Centralized architecture; Client interface; DNS; Computer architecture
"Rhee I., Xu L.",2,Limitations of equation-based congestion control,2005,16,"Department of Computer Science, North Carolina State University, Raleigh, NC 27695-7534, United States; Department of Computer Sci. and Eng., University of Nebraska, Lincoln, NE 68588-0115, United States",North Carolina State University;University of Nebraska,2,USA,1,21,17,"We study limitations of an equation-based congestion control protocol, called TFRC (TCP Friendly Rate Control). It examines how the three main factors that determine TFRC throughput, namely, the TCP friendly equation, loss event rate estimation and delay estimation, can influence the long-term throughput imbalance between TFRC and TCP. Especially, we show that different sending rates of competing flows cause these flows to experience different loss event rates. There are several fundamental reasons why TFRC and TCP flows have different average sending rates, from the first place. Earlier work shows that the convexity of the TCP friendly equation used in TFRC causes the sending rate difference. We report two additional reasons in this paper: (1) the convexity of 1/x where x is a loss event period and (2) different RTO (retransmission timeout period) estimations of TCP and TFRC. These factors can be the reasons for TCP and TFRC to experience initially different sending rates. But we find that the loss event rate difference due to the differing sending rates greatly amplifies the initial throughput difference; in some extreme cases, TFRC uses around 20 times more, or sometimes 10 times less, bandwidth than TCP. Copyright 2005 ACM.",Congestion control; Equation-based rate control,Data transfer; Frequency allocation; Network protocols; Congestion control; Delay estimation; Equation based rate control; Channel capacity
"Jain S., Demmer M., Patra R., Fall K.",4,Using redundancy to cope with failures in a delay tolerant network,2005,108,"University of Washington, United States; University of California, Berkeley, United States; Intel Research, Berkeley, United States",Intel;University of California Berkeley;University of Washington at St. Louis,3,USA,1,25,22,"We consider the problem of routing in a delay tolerant network (DTN) in the presence of path failures. Previous work on DTN routing has focused on using precisely known network dynamics, which does not account for message losses due to link failures, buffer overruns, path selection errors, unscheduled delays, or other problems. We show how to split, replicate, and erasure code message fragments over multiple delivery paths to optimize the probability of successful message delivery. We provide a formulation of this problem and solve it for two cases: a 0/1 (Bernoulli) path delivery model where messages are either fully lost or delivered, and a Gaussian path delivery model where only a fraction of a message may be delivered. Ideas from the modern portfolio theory literature are borrowed to solve the underlying optimization problem. Our approach is directly relevant to solving similar problems that arise in replica placement in distributed file systems and virtual node placement in DHTs. In three different simulated DTN scenarios covering a wide range of applications, we show the effectiveness of our approach in handling failures. Copyright 2005 ACM.",Delay tolerant network; Routing,Delay tolerant network (DTN); Distributed file systems; Gaussian path; Routing; Delay control systems; Error analysis; File organization; Optimization; Probability; Problem solving; Routers; Telecommunication links; Computer system recovery
"Ballani H., Francis P.",2,Towards a global IP anycast service,2005,47,"Cornell University, Ithaca, NY, United States",Cornell University,1,USA,1,41,34,"IP anycast, with its innate ability to find nearby resources in a robust and efficient fashion, has long been considered an important means of service discovery. The growth of P2P applications presents appealing new uses for IP anycast. Unfortunately, IP anycast suffers from serious problems: it is very hard to deploy globally, it scales poorly by the number of anycast groups, and it lacks important features like load-balancing. As a result, its use is limited to a few critical infrastructure services such as DNS root servers. The primary contribution of this paper is a new IP anycast architecture, PIAS, that overcomes these problems while largely maintaining the strengths of IP anycast. PIAS makes use of a proxy overlay that advertises IP anycast addresses on behalf of group members and tunnels anycast packets to those members. The paper presents a detailed design of PIAS and evaluates its scalability and efficiency through simulation. We also present preliminary measurement results on anycasted DNS root servers that suggest that IP anycast provides good affinity. Finally, we describe how PIAS supports two important P2P and overlay applications. Copyright 2005 ACM.",Anycast; Architecture; Overlay; Proxy; Routing,Distributed computer systems; Internet; Network protocols; Packet networks; Robustness (control systems); Servers; Anycast; Overlay; Proxy; Routing; Telecommunication services
"Enachescu M., Goel A., Ganjali Y., McKeown N., Roughgarden T.",5,Part III: Routers with very small buffers,2005,118,"Department of Computer Science, Stanford University, United States; Dept of Management Sci. and Eng., Stanford University, United States; Department of Electrical Engineering, Stanford University, United States",Stanford University,1,USA,1,15,10,"Internet routers require buffers to hold packets during times of congestion. The buffers need to be fast and so ideally they should be small enough to use fast memory technologies such as SRAM or all-optical buffering. Unfortunately, a widely used rule-of-thumb says we need a bandwidth-delay product of buffering at each router so as not to lose link utilization. This can be prohibitively large. In a recent paper, Appenzeller et al. challenged this rule-of-thumb and showed that for a backbone network, the buffer size can be divided by √N without sacrificing throughput, where N is the number of flows sharing the bottleneck. In this paper, we explore how buffers in the backbone can be significantly reduced even more, to as little as a few dozen packets, if we are willing to sacrifice a small amount of link capacity. We argue that if the TCP sources are not overly bursty, then fewer than twenty packet buffers are sufficient for high throughput. Specifically, we argue that O(log W) buffers are sufficient, where W is the window size of each flow. We support our claim with analysis and a variety of simulations. The change we need to make to TCP is minimal - each sender just needs to pace packet injections from its window. Moreover, there is some evidence that such small buffers are sufficient even if we don't modify the TCP sources so long as the access network is much slower than the backbone, which is true today and likely to remain true in the future. We conclude that buffers can be made small enough for all-optical routers with small integrated optical buffers.",All-optical routers; Buffer size; Congestion control; TCP,All-optical routers; Buffer size; Congestion control; TCP; Bandwidth; Buffer storage; Computer networks; Computer simulation; Network protocols; Routers; Telecommunication traffic; Communication systems
"Raina G., Towsley D., Wischik D.",3,Part II: Control theory for buffer sizing,2005,94,"Judge Institute, Cambridge, United Kingdom; Computer Science, UMass, United States; Computer Science, UCL, United Kingdom",Judge Institute,1,UK;USA,2,14,14,"This article describes how control theory has been used to address the question of how to size the buffers in core Internet routers. Control theory aims to predict whether the network is stable, i.e. whether TCP flows are desynchronized. If flows are desynchronized then small buffers are sufficient [14]; the theory here shows that small buffers actually promote desynchronization - a virtuous circle.",Buffer size; Congestion control; Control theory; Fluid model; Synchronization; TCP,Buffer size; Congestion control; Fluid models; TCP; Communication systems; Internet; Network protocols; Routers; Synchronization; Control theory
"Brunner M., Eggert L., Fall K., Ott J., Wolf L.",5,Dagstuhl seminar on disruption tolerant networking,2005,5,"NEC Europe Ltd., Network Laboratory, Germany; Intel Research Berkeley, United States; Helsinki University of Technology, Networking Laboratory, Finland; TU Braunschweig, Institut für Betriebssysteme und Rechnerverbund, Germany",Helsinki University of Technology;Intel;TU Braunschweig,3,Finland;Germany;USA,3,3,1,"Disruption Tolerant Networking (DTN) is a new area of research to improve network communication when connectivity is periodic, intermittent, and/or prone to disruptions. A seminar on DTN was held at at Schloß Dagstuhl, Germany, from 3 to 6 April 2005. Researchers from different fields discussed their approaches to dealing with delays, intermittent connectivity, and the potential non-existence of an end-to-end path in a number of different environments. The two major areas identified were: (1) dealing with delay and disruption in the present Internet in the context of wireless, mobile, and nomadic communications, supporting existing applications and (2) addressing new applications with a focus on exploiting discontinuous connectivity and opportunistic contacts for asynchronous communications. This article briefly reviews the seminar presentations and discussions.",Ad-hoc networks; Delay-tolerant networking; Disconnected operation; Interplanetary internet; Mobility; Sensor networks,Ad-hoc networks; Delay-tolerant networking; Disconnected operations; Interplanetary Internet; Mobility; Sensor networks; Communication systems; Computer networks; Engineering research; Internet; Radio communication; Technical presentations
"Lazowska E.D., Patterson D.A.",2,Computing research: A looming crisis,2005,0,"Computer Science and Engineering, University of Washington, Seattle, WA 98195-2350, United States; Computer Science Division, University of California, Berkeley, CA 94720-1776, United States",University of California Berkeley;University of Washington at St. Louis,2,USA,1,6,6,"On June 11, Vint Cerf and Bob Kahn received computing's highest prize, the A.M. Turing Award, from the Association for Computing Machinery. Their Transmission Control Protocol (TCP), created in 1973, became the language of the Internet. In the May 6 issue of Science [1], we used this as the ""news hook"" for an invited editorial on the current state of computer science research in the United States. ""Where will the next generation of groundbreaking innovations in IT arise?"" we asked. ""Where will the Turing Awardees 30 years hence reside?"" Our conclusion: ""Given current trends, the answers to both questions will likely be 'not in the United States.'"" We take this opportunity to explore in greater depth the issues we raised in that editorial. What are the trends that concern us? What can all of us, as computer scientists, do to reverse them?",Computing research; Innovation,Computing research; Innovation; Transmission Control Protocol (TCP); Computer science; Engineering research; Information technology; Internet; Network protocols; Communication systems
"Wischik D., McKeown N.",2,Part I: Buffer sizes for core routers,2005,116,"Computer Science, UCL, United Kingdom; Computer Science, Stanford, United Kingdom",Stanford University,1,UK,1,12,11,"In this article we describe recent work on buffer sizing for core Internet routers. This work suggests that the widely-used rule of thumb leads to buffers which are much larger than they need to be. For example, the buffer in a backbone router could be reduced from 1,000,000 packets to 10,000 without loss in performance. It could be reduced even further, perhaps to 10-20 packets, at the cost of a small amount of bandwidth utilization. This tradeoff is worth considering, for example for a possible future all-optical router.",Bandwidth delay product; Buffer size; Internet router; Multiplexing; Synchronization; TCP,Bandwidth delay products; Buffer size; Internet routers; TCP; Bandwidth; Costs; Multiplexing; Network protocols; Routers; Synchronization; Communication systems
"Francois P., Filsfils C., Evans J., Bonaventure O.",4,Achieving sub-second IGP convergence in large IP networks,2005,188,"Dept. CSE, Université Catholique de Louvain (UCL), Belgium; Cisco Systems",Universite Catholique de Louvain,1,Belgium,1,26,16,"We describe and analyse in details the various factors that influence the convergence time of intradomain link state routing protocols. This convergence time reflects the time required by a network to react to the failure of a link or a router. To characterise the convergence process, we first use detailed measurements to determine the time required to perform the various operations of a link state protocol on currently deployed routers. We then build a simulation model based on those measurements and use it to study the convergence time in large networks. Our measurements and simulations indicate that sub-second link-state IGP convergence can be easily met on an ISP network without any compromise on stability.",Convergence time; Intradomain routing; IS-IS; OSPF,Computer networks; Computer simulation; Convergence of numerical methods; Mathematical models; Network protocols; Routers; Convergence time; Intradomain routing; IS-IS; OSPF; Communication systems
"Xu Y., Guérin R.",2,On the robustness of router-based Denial-of-Service (DoS) defense systems,2005,22,"Multimedia and Networking Lab, Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, United States",University of Pennsylvania,1,USA,1,28,23,"This paper focuses on ""router-based"" defense mechanisms, and whether they can provide effective solutions to network Denialof-Service (DoS) attacks. Router-based defenses operate either on traffic aggregates or on individual flows, and have been shown, either alone or in combination with other schemes, e.g., traceback, to be reasonably effective against certain types of basic attacks. Those attacks are, however, relatively brute-force, and usually accompanied by either significant increases in congestion, and/or traffic patterns that are easily identified. It is, therefore, unclear if router-based solutions are viable in the presence of more diverse or sophisticated attacks. As a result, even if incorporating defense mechanisms in the routers themselves has obvious advantages, such schemes have not seen wide deployments. Our ultimate goal is to determine whether it is possible to build router-based defense mechanisms that are effective against a wide range of attacks. This paper describes a first phase of this effort aimed at identifying weaknesses in existing systems. In particular, the paper demonstrates that aggregate defense systems can be readily circumvented, even by a single attacker, through minor modifications of its flooding patterns. Flow-based defenses fare slightly better, but can still be easily fooled by a small number of attackers generating transient flooding patterns. The findings of the paper provide insight into possible approaches for designing better and more robust router-based defense systems.",Denial-of-Service; Router-based Defense,Computer networks; Robustness (control systems); Routers; Security systems; Telecommunication traffic; Congestions; Denial-of-Services (DoS); Flooding patterns; Router-based Defense; Communication systems
"Seneviratne A., Percival T.",2,National ICT Australia (NICTA),2005,1,"Sydney Research Laboratory, National ICT Australia, Australian Technology Park, Eveleigh, NSW 1430, Australia; Sydney Research Laboratory at Kensington, National ICT Australia, Kensington NSW 2057, Australia",Sydney Research Laboratory at Kensington,1,Australia,1,10,7,Information and Communications Technology (ICT) has had a profound impact on the world's social and economic development. National ICT Australia's (NICTA) has been established to ensure that Australia continues to capitalize on the massive opportunities that ICT research delivers and to create a vibrant ICT industry that boosts Australia's competitive advantage and builds the overall wealth of nation.,Center of excellence; Information communication technologies,Communication systems; Economic and social effects; Engineering research; Industrial economics; Center of excellence; ICT research; Information communication technologies; Overall wealth of nation; Information technology
"Nucci A., Sridharan A., Taft N.",3,The problem of synthetically generating IP traffic matrices: Initial recommendations,2005,113,"Narus Inc., Mountain View, CA, United States; Sprint ATL, Burlingame, CA, United States; Intel Research, Berkeley, CA, United States",Intel;Narus Inc.,2,USA,1,24,22,"There exist a wide variety of network design problems that require a traffic matrix as input in order to carry out performance evaluation. The research community has not had at its disposal any information about how to construct realistic traffic matrices. We introduce here the two basic problems that need to be addressed to construct such matrices. The first is that of synthetically generating traffic volume levels that obey spatial and temporal patterns as observed in realistic traffic matrices. The second is that of assigning a set of numbers (representing traffic levels) to particular node pairs in a given topology. This paper provides an in-depth discussion of the many issues that arise when addressing these problems. Our approach to the first problem is to extract statistical characteristics for such traffic from real data collected inside two large IP backbones. We dispel the myth that uniform distributions can be used to randomly generate numbers for populating a traffic matrix. Instead, we show that the lognormal distribution is better for this purpose as it describes well the mean rates of origin-destination flows. We provide estimates for the mean and variance properties of the traffic matrix flows from our datasets. We explain the second problem and discuss the notion of a traffic matrix being well-matched to a topology. We provide two initial solutions to this problem, one using an ILP formulation that incorporates simple and well formed constraints. Our second solution is a heuristic one that incorporates more challenging constraints coming from carrier practices used to design and evolve topologies.",Distribution Fitting; Hypothesis Testing; Internet Traffic Matrices; Topology; Traffic Characterization,Distribution Fitting; Hypothesis Testing; Internet Traffic Matrices; Traffic Characterization; Computer networks; Data acquisition; Internet; Network protocols; Problem solving; Statistical methods; Telecommunication traffic; Topology; Communication systems
Stephens A.,1,"802.11 ""decrypted""",2005,1,"Intel Corporation, 15 JJ Thompson Ave., Cambridge CB3 OFD, United Kingdom",Intel,1,UK,1,4,0,This short paper introduces wireless IEEE 802 standards and activities with a focus on explaining the purpose of the many 802.11 amendments.,TBD,Computer systems; Design; Internet; Standards; IEEE 802 standards; TBD; Wireless standards; Wireless telecommunication systems
"Bagnulo M., García-Martínez A., Azcorra A.",3,Efficient security for IPv6 multihoming,2005,8,"Universidad Carlos III de Madrid, Av. Universidad, 30, Leganés, Madrid, Spain",Av. University;University Carlos III of Madrid,2,Spain,1,17,16,"In this note, we propose a security mechanism for protecting IPv6 networks from possible abuses caused by the malicious usage of a multihoming protocol. In the presented approach, each multihomed node is assigned multiple prefixes from its upstream providers, and it creates the interface identifier part of its addresses by incorporating a cryptographic one-way hash of the available prefix set. The result is that the addresses of each multihomed node form an unalterable set of intrinsically bound IPv6 addresses. This allows any node that is communicating with the multihomed node to securely verify that all the alternative addresses proposed through the multihoming protocol are associated to the address used for establishing the communication. The verification process is extremely efficient because it only involves hash operations.",Hijacking protection; IPv6; Multihoming,Communication systems; Cryptography; Network protocols; Security of data; Hijacking protection; IPv6; Multihoming; Computer networks
"Wallerich J., Dreger H., Feldmann A., Krishnamurthy B., Willinger W.",5,A methodology for studying persistency aspects of Internet flows,2005,35,"Technische Universität München, Germany; AT and T Labs Research, Florham Park, NJ, United States",AT and T Labs;TU Munich,2,Germany;USA,2,22,19,"We focus in this paper on Internet flows, consider their contributions to the overall traffic per time unit or bin, and perform a multi-scale and multi-protocol analysis to explore the persistency properties of those flows that contribute the most (also known as ""heavy hitters"" or ""elephants""). Knowing the persistency features (or a lack thereof) of the heavy hitters and understanding their underlying causes is crucial when developing traffic engineering tools that focus primarily on optimizing system performance for elephant flows. The main difficulty when studying the persistency properties of flows is that the available measurements are either too fine-grained to perform large-scale studies (i.e., packet-level traces) or too coarse-grained to extract the detailed information necessary for the purpose at hand (i.e., Netflow traces, SNMP). We deal with this problem by assuming that flows have constant throughput through their lifetime. We then check the validity of this assumption by comparing our Netflow-derived findings against those obtained from directly studying the corresponding detailed packet-level traces. By considering different time aggregations (e.g., bin sizes between 1-10 minutes) and flow abstractions (e.g., raw IP flows, prefix flows), varying the definition of what constitutes an ""elephant"", and slicing by different protocols and applications, we present a methodology for studying persistency aspects exhibited by Internet flows. For example, we find that raw IP flows that are elephant flows for at least once (i.e., one bin or time unit) in their lifetimes tend to show a remarkable persistence to be elephants for much of their lifetimes, but certain aggregate flows exhibit more intricate persistency properties.",Elephants vs. Mice; Flow-abstraction; Large flows; Netflow; Protocol use; Reservations; Time-scales; Zipf's law,Flow-abstraction; Large flows; Netflow; Protocol use; Time-scales; Zipf's law; Abstracting; Computer networks; Network protocols; Optimization; Problem solving; Telecommunication traffic; Internet
"Medina A., Allman M., Floyd S.",3,Measuring the evolution of transport protocols in the Internet,2005,112,"BBN Technologies, United States; ICSI Center for Internet Research, United States",BBN Technologies;University of California Berkeley,2,USA,1,50,37,"In this paper we explore the evolution of both the Internet's most heavily used transport protocol, TCP, and the current network environment with respect to how the network's evolution ultimately impacts end-to-end protocols. The traditional end-to-end assumptions about the Internet are increasingly challenged by the introduction of intermediary network elements (middleboxes) that intentionally or unintentionally prevent or alter the behavior of end-to-end communications. This paper provides measurement results showing the impact of the current network environment on a number of traditional and proposed protocol mechanisms (e.g., Path MTU Discovery, Explicit Congestion Notification, etc.). In addition, we investigate the prevalence and correctness of implementations using proposed TCP algorithmic and protocol changes (e.g., selective acknowledgment-based loss recovery, congestion window growth based on byte counting, etc.). We present results of measurements taken using an active measurement framework to study web servers and a passive measurement survey of clients accessing information from our web server. We analyze our results to gain further understanding of the differences between the behavior of the Internet in theory versus the behavior we observed through measurements. In addition, these measurements can be used to guide the definition of more realistic Internet modeling scenarios. Finally, we present several lessons that will benefit others taking Internet measurements.",Evolution; Internet; Middleboxes; TCP,Evolution; Middleboxes; TCP; Communication systems; Computer networks; Internet; Servers; World Wide Web; Network protocols
Jiang S.,1,Granular differentiated queueing services for QoS: Structure and cost model,2005,16,"School of Electronic and Information Engineering, South China University of Technology, China",South China University of Technology,1,China,1,42,33,"One weakness of DiffServ is the lack of granularity for QoS guaranteed services, which makes it difficult to cost-effectively support end-to-end (e2e) QoS according to the e2e situation (e.g., path lengths) of applications. With the conventional packet-level QoS mechanisms for the regulated traffic, i.e., buffer admission control plus output schedulers in general, increasing service granularity may inevitably complicate implementation and/or impact scalability since sophisticated output schedulers seem necessary in this case. In this paper, a new structure, Differentiated Queueing Services (DQS), is discussed to handle the above issue. DQS tries to provide granular and scalable QoS guaranteed services to be selected by users according to their QoS requirements and e2e situation. Its basic idea is to convert packet delay guarantee into packet loss ratio guarantee with either dropping or marking the packets whose ele delays are perceived unable to be guaranteed. Packets are queued according to their e2e delay requirements so that various delay bounds can be guaranteed without using sophisticated output schedulers while different packet loss ratios are mainly controlled by call admission control (CAC). To this end, the e2e QoS requirement is carried by each packet to avoid storing such information in network units for scalability. On the other hand, differentiated services should also be accomplished with a differentiated cost model for pricing, not only for the profits of both the service provider and the user, but also to prevent good services from being abused. So, a cost model for differentiated QoS services provided by DQS is also discussed with a possible CAC based on the exponentially bounded burstiness traffic.",Differentiated Queueing Services (DQS); End-to-end QoS; Service Granularity,Differentiated Queueing Services (DQS); End-to-end QoS; Service Granularity; Computational complexity; Computer networks; Costs; Mathematical models; Packet networks; Telecommunication traffic; Quality of service
"Allman M., Blanton E.",2,Notes on burst mitigation for transport protocols,2005,9,"ICSI/ICIR; Purdue University, United States",Purdue University,1,USA,1,23,19,In this note we explore the various causes of micro-bursting in TCP connections and also the behavior of several mitigations that have been suggested in the literature along with extensions we develop herein. This note methodically sketches the behavior of the mitigations and presents the tradeoffs of various schemes as a data point in the ongoing discussion about preventing bursting in transport protocols.,Bursting; TCP,Bursting; TCP; Communication systems; Computer networks; Internet; World Wide Web; Network protocols
"Kelly F., Voice T.",2,Stability of end-to-end algorithms for joint routing and rate control,2005,180,"Statistical Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,29,21,"Dynamic multi-path routing has the potential to improve the reliability and performance of a communication network, but carries a risk. Routing needs to respond quickly to achieve the potential benefits, but not so quickly that the network is destabilized. This paper studies how rapidly routing can respond, without compromising stability. We present a sufficient condition for the local stability of end-to-end algorithms for joint routing and rate control. The network model considered allows an arbitrary interconnection of sources and resources, and heterogeneous propagation delays. The sufficient condition we present is decentralized: the responsiveness of each route is restricted by the round-trip time of that route alone, and not by the round-trip times of other routes. Our results suggest that stable, scalable load-sharing across paths, based on end-to-end measurements, can be achieved on the same rapid time-scale as rate control, namely the time-scale of round-trip times.",Dynamic routing; Internet; Scalable TCP,Communication systems; Computer networks; Network protocols; Performance; Reliability; Stability; Dynamic routing; Rate control; Scalable TCP; Algorithms
"Feamster N., Jung J., Balakrishnan H.",3,"An empirical study of ""bogon"" route advertisements",2005,17,"MIT, Computer Science and Artificial Intelligence Laboratory, United States",MIT,1,USA,1,24,12,"An important factor in the robustness of the interdomain routing system is whether the routers in autonomous systems (ASes) filter routes for ""bogon"" address space - i.e., private address space and address space that has not been allocated by the Internet Assigned Numbers Authority (IANA). This paper presents an empirical study of bogon route announcements, as observed at eight vantage points on the Internet. On average, we observe several bogon routes leaked every few days; a small number of ASes also temporarily leak hundreds of bogon routes. About 40% of these bogon routes are not withdrawn for at least a day. We observed 110 different ASes originating routes for bogon prefixes and a few ASes that were responsible for advertising a disproportionate number of these routes. We also find that some ASes that do filter unallocated prefixes continue to filter them for as long as five months after they have been allocated, mistakenly filtering valid routes. Both of these types of delinquencies have serious implications: the failure to filter valid prefixes can could make nefarious activities such as denial of service attacks difficult to trace; failure to update filters when new prefixes are allocated prevents legitimate routes from being globally visible.",Anomalies; BGP; Bogon prefixes,Anomalies; BGP; Bogon prefixes; Computational complexity; Computer system recovery; Internet; Network protocols; Robustness (control systems); Computer networks
"Arlitt M., Williamson C.",2,An analysis of TCP reset behaviour on the Internet,2005,38,"Department of Computer Science, University of Calgary, 2500 University Drive NW, Calgary, Alta. T2N 1N4, Canada",University of Calgary,1,Canada,1,14,9,"This paper presents a one-year study of Internet packet traffic from a large campus network, showing that 15-25% of TCP connections have at least one TCP RST (reset). Similar results have also been observed from measurements of other Internet links. The results in this paper show that reset connections arise from local events such as network outages, attacks, or reconfigurations, as well as from global trends in TCP usage. In particular, we identify application-level Web behaviour as the primary contributor to the global trend in reset TCP connections. The most prevalent anomaly is the absence of the normal connection termination hand-shake. Instead, connections are often reset by the client. We believe that particular implementations of HTTP/TCP connection management cause this global trend.",Network Traffic Measurement; TCP; Web; Workload Characterization,Computer networks; Integrated circuits; Internet; Telecommunication links; Telecommunication traffic; World Wide Web; Network Traffic Measurement; TCP; Workload Characterization; Network protocols
Savola P.,1,Observations of IPv6 traffic on a 6to4 relay,2005,9,"CSC, FUNET, Finland","FUNET, Finland",1,Finland,1,10,8,"FUNET has been operating a public, globally-used 6to4 (RFC 3056) relay router since November 2001. The traffic has been logged and is now analyzed to gather information of 6to4 and IPv6 deployment. Among other figures, we note that the number of 6to4 capable nodes has increased by an order of magnitude in half a year: in April 2004, there are records of about 2 million different 6to4 nodes using this particular relay. Vast majority of this is just testing the availability of the relay, done by the Microsoft Windows systems, but the real traffic has also increased over time. While the observed 6to4 traffic has typically consisted of relatively simple system-level applications, or applications by power users, the emergence of peer-to-peer applications such as BitTorrent was also observed.",6to4; IPv6; IPv6 transition,Computer networks; Computer operating procedures; Computer software; Graph theory; Network protocols; 6to4; IPv6; IPv6 transition; Telecommunication traffic
"Li J., Sollins K., Lim D.-Y.",3,Implementing aggregation and broadcast over distributed hash tables,2005,40,"MIT, Computer Science and Artificial Intelligence Laboratory, 32 Vassar Street, Cambridge, MA 02139, United States",MIT,1,USA,1,26,23,"Peer-to-peer (P2P) networks represent an effective way to share information, since there are no central points of failure or bottleneck. However, the flip side to the distributive nature of P2P networks is that it is not trivial to aggregate and broadcast global information efficiently. We believe that this aggregation/broadcast functionality is a fundamental service that should be layered over existing Distributed Hash Tables (DHTs), and in this work, we design a novel algorithm for this purpose. Specifically, we build an aggregation/broadcast tree in a bottom-up fashion by mapping nodes to their parents in the tree with a parent function. The particular parent function family we propose allows the efficient construction of multiple interior-node-disjoint trees, thus preventing single points of failure in tree structures. In this way, we provide DHTs with an ability to collect and disseminate information efficiently on a global scale. Simulation results demonstrate that our algorithm is efficient and robust.",Aggregation; Broadcast; Distributed Hash Table; Peer-to-peer; Tree,Broadcast; Distributed Hash Table; Peer-to-peer; Tree; Agglomeration; Algorithms; Broadcasting; Computer simulation; Computer system recovery; Congestion control (communication); Data structures
"Schütz S., Eggert L., Schmid S., Brunner M.",4,Protocol enhancements for intermittently connected hosts,2005,32,"NEC Europe Ltd, Network Laboratories, Kurfürsten-Anlage 36, 69115 Heidelberg, Germany",NEC,1,Germany,1,45,40,"Internet users are increasingly mobile. Their hosts are often only intermittently connected to the Internet, due to using multiple access networks, gaps in wireless coverage or explicit user choice. When such hosts communicate using the current Internet protocols, intermittent connectivity can significantly decrease performance and even cause connections to fail altogether. This paper experimentally measures the behavior of Internet communication across a dynamically changing, intermittently connected path. An analysis of the experimental results finds that address changes together with transport-layer timeout and retransmission behaviors are the main limiting factors. Based on these experimental results, this paper proposes a solution that combines the Host Identity Protocol (HIP) with two new protocol enhancements, the TCP User Timeout Option and the TCP Retransmission Trigger. Detailed experiments with HIP and a prototype implementation of these protocol enhancements show that they tolerate address changes and arbitrary-length disconnections while significantly increasing performance under intermittent connectivity to within 86-96% of a scenario with constant connectivity.",Communication system performance; Disruption tolerance; Intermittent connectivity; Internet; Mobile communication; Transport protocols,Data transfer; Internet; Mobile computing; Network protocols; Communication system performance; Disruption tolerance; Intermittent connectivity; Mobile communication; Transport protocols; Communication systems
"Meng X., Xu Z., Zhang B., Huston G., Lu S., Zhang L.",6,IPv4 address allocation and the BGP routing table evolution,2005,83,"Computer Science Dept., UCLA, Los Angeles, CA 90095, United States; APNIC, Brisbane, Australia",University of California Los Angeles,1,Australia;USA,2,11,7,"The IP address consumption and the global routing table size are two of the vital parameters of the Internet growth. In this paper we quantitatively characterize the IPv4 address allocations made over the past six years and the global BGP routing table size changes during the same period of time. About 63,000 address blocks have been allocated since the beginning of the Internet, of which about 18,000 address blocks were allocated during our study period, from November 1997 to August 2004. Among these 18,000 allocations, 90% of them started being announced into the BGP routing table within 75 days after the allocation, while 8% of them has not been used up to now. Among all the address blocks that have ever been used, 45% of them were split into fragments smaller than the original allocated blocks; without these fragmentations, the current BGP table would have been about half of its current size. Furthermore, we found that the evolution of BGP routing table consists of both the appearance of new prefixes and the disappearance of old prefixes. While the change of the BGP routing table size only reflects the combined results of the two processes, the dynamics of either process is much higher than that of the BGP table size. Finally, we classify routing prefixes into covering and covered ones, and examine their evolution separately. For the covered prefixes, which account for almost half of the BGP table size, we infer their practical motives such as multihoming, load balancing, and traffic engineering, etc., via a classification method.",BGP; IPv4 address allocation,BGP; IP address consumption; IPv4 address allocation; Computer networks; Internet; Resource allocation; Storage allocation (computer); Telecommunication traffic; World Wide Web; Network protocols
"Chen Y., Bindel D., Song H., Katz R.H.",4,An algebraic approach to practical and scalable overlay network monitoring,2004,79,"Department of Computer Science, Northwestern University, United States; Division of Computer Science, University of California, Berkeley, United States",Northwestern University;University of California Berkeley,2,USA,1,35,31,"Overlay network monitoring enables distributed Internet applications to detect and recover from path outages and periods of degraded performance within seconds. For an overlay network with n end hosts, existing systems either require O(n 2) measurements, and thus lack scalability, or can only estimate the latency but not congestion or failures. Our earlier extended abstract [1] briefly proposes an algebraic approach that selectively monitors k linearly independent paths that can fully describe all the O(n 2) paths. The loss rates and latency of these k paths can be used to estimate the loss rates and latency of all other paths. Our scheme only assumes knowledge of the underlying IP topology, with links dynamically varying between lossy and normal. In this paper, we improve, implement and extensively evaluate such a monitoring system. We further make the following contributions: i) scalability analysis indicating that for reasonably large n (e.g., 100), the growth of k is bounded as O(n log n), ii) efficient adaptation algorithms for topology changes, such as the addition or removal of end hosts and routing changes, iii) measurement load balancing schemes, and iv) topology measurement error handling. Both simulation and Internet experiments demonstrate we obtain highly accurate path loss rate estimation while adapting to topology changes within seconds and handling topology errors. Copyright 2004 ACM.",Dynamics; Load balancing; Network measurement and monitoring; Numerical linear algebra; Overlay; Scalability,Load balancing; Network measurement and monitoring; Numerical linear algebra; Overlay; Scalability; Algorithms; Congestion control (communication); Error analysis; Internet; Linear algebra; Network protocols; Servers; Topology; Computer networks
"Zhang Y., Kang S.-R., Loguinov D.",3,Delayed stability and performance of distributed congestion control,2004,25,"Texas A and M University, College Station, TX 77843, United States",Texas A and M University,1,USA,1,31,28,"Recent research efforts to design better Internet transport protocols combined with scalable Active Queue Management (AQM) have led to significant advances in congestion control. One of the hottest topics in this area is the design of discrete congestion control algorithms that are asymptotically stable under heterogeneous feedback delay and whose control equations do not explicitly depend on the RTTs of end-flows. In this paper, we show that max-min fair congestion control methods with a stable symmetric Jacobian remain stable under arbitrary feedback delay (including heterogeneous directional delays) and that the stability condition of such methods does not involve any of the delays. To demonstrate the practicality of the obtained result, we change the original controller in Kelly's work [14] to become robust under random feedback delay and fixed constants of the control equation. We call the resulting framework Maxmin Kelly Control (MKC) and show that it offers smooth sending rate, exponential convergence to efficiency, and fast convergence to fairness, all of which make it appealing for future high-speed networks. Copyright 2004 ACM.",Discrete Congestion Control; Heterogenous Delay; Stability,Active queue management (AQM); Discrete congestion control; Heterogeneous delay; Transport protocols; Algorithms; Congestion control (communication); Delay circuits; Feedback; Internet; Network protocols; Queueing networks; System stability; Distributed computer systems
"Bharambe A.R., Agrawal M., Seshan S.",3,Mercury: Supporting scalable multi-attribute range queries,2004,335,"Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213, United States",Carnegie Mellon University,1,USA,1,25,25,"This paper presents the design of Mercury, a scalable protocol for supporting multi-attribute range-based searches. Mercury differs from previous range-based query systems in that it supports multiple attributes as well as performs explicit load balancing. To guarantee efficient routing and load balancing, Mercury uses novel light-weight sampling mechanisms for uniformly sampling random nodes in a highly dynamic overlay network. Our evaluation shows that Mercury is able to achieve its goals of logarithmic-hop routing and near-uniform load balancing. We also show that Mercury can be used to solve a key problem for an important class of distributed applications: distributed state maintenance for distributed games. We show that the Mercury-based solution is easy to use, and that it reduces the game's messaging overheard significantly compared to a naïve approach. Copyright 2004 ACM.",Distributed hash tables; Load balancing; Peer-to-peer systems; Random sampling; Range queries,Distributed hash tables; Load balancing; Peer-to-peer systems; Random sampling; Range queries; Data structures; Distributed computer systems; Electric load management; Mercury (metal); Routers; Sampling; Query languages
"Kapoor R., Chen L.-J., Lao L., Gerla M., Sanadidi M.Y.",5,CapProbe: A simple and accurate capacity estimation technique,2004,101,"Qualcomm, United States; UCLA, United States",Qualcomm;University of California Los Angeles,2,USA,1,16,9,"We present a new capacity estimation technique, called CapProbe. CapProbe combines delay as well as dispersion measurements of packet pairs to filter out samples distorted by cross-traffic. CapProbe algorithms include convergence tests and convergence speed-up techniques by varying probing parameters. Our study of CapProbe includes a probability analysis to determine the time it takes CapProbe to converge on the average. Through simulations and measurements, we found CapProbe to be quick and accurate across a wide range of traffic scenarios. We also compared CapProbe with two previous well-known techniques, pathchar and pathrate. We found CapProbe to be much more accurate than pathchar and similar in accuracy to pathrate, while providing faster estimation than both. Another advantage of CapProbe is its lower computation cost, since no statistical post processing of probing data is required. Copyright 2004 ACM.",Bottleneck bandwidth; Network capacity; Packet pair dispersion,Bottleneck bandwidth; Network capacity; Packet bunch modes (PBM); Packet pair dispersion; Algorithms; Bandwidth; Computer simulation; Data transfer; Internet; Packet networks; Problem solving; Telecommunication traffic; Computer networks
"Aguayo D., Bicket J., Biswas S., Judd G., Morris R.",5,Link-level measurements from an 802.11b mesh network,2004,397,"M.I.T. Computer Science and Artificial Intelligence Laboratory, United States; Carnegie Mellon University, United States",Carnegie Mellon University;MIT,2,USA,1,15,12,"This paper analyzes the causes of packet loss in a 38-node urban multi-hop 802.11b network. The patterns and causes of loss are important in the design of routing and error-correction protocols, as well as in network planning. The paper makes the following observations. The distribution of inter-node loss rates is relatively uniform over the whole range of loss rates; there is no clear threshold separating ""in range"" and ""out of range."" Most links have relatively stable loss rates from one second to the next, though a small minority have very bursty losses at that time scale. Signal-to-noise ratio and distance have little predictive value for loss rate. The large number of links with intermediate loss rates is probably due to multi-path fading rather than attenuation or interference. The phenomena discussed here are all well-known. The contributions of this paper are an understanding of their relative importance, of how they interact, and of the implications for MAC and routing protocol design. Copyright 2004 ACM.",802.11b; Mesh; Wireless,802.11b; Link-level measurements; Mesh; Mesh networks; Attenuation; Error correction; Fading (radio); Measurement theory; Network protocols; Signal interference; Signal to noise ratio; Wireless telecommunication systems
"Feldmann A., Maennel O., Mao Z.M., Berger A., Maggs B.",5,Locating Internet routing instabilities,2004,60,"TU-München, Germany; Univ of Michigan, United States; MIT/Akamai Technologies; CMU/Akamai Technologies, United States",Carnegie Mellon University;Akamai Technologies;MIT;TU Munich;University of Michigan at Ann Arbor,5,Germany;USA,2,29,27,"This paper presents a methodology for identifying the autonomous system (or systems) responsible when a routing change is observed and propagated by BGP. The origin of such a routing instability is deduced by examining and correlating BGP updates for many prefixes gathered at many observation points. Although interpreting BGP updates can be perplexing, we find that we can pinpoint the origin to either a single AS or a session between two ASes in most cases. We verify our methodology in two phases. First, we perform simulations on an AS topology derived from actual BGP updates using routing policies that are compatible with inferred peering/customer/provider relationships. In these simulations, in which network and router behavior are ""ideal"", we inject inter-AS link failures and demonstrate that our methodology can effectively identify most origins of instability. We then develop several heuristics to cope with the limitations of the actual BGP update propagation process and monitoring infrastructure, and apply our methodology and evaluation techniques to actual BGP updates gathered at hundreds of observation points. This approach of relying on data from BGP simulations as well as from measurements enables us to evaluate the inference quality achieved by our approach under ideal situations and how it is correlated with the actual quality and the number of observation points. Copyright 2004 ACM.",BGP; Instability origin; Root cause analysis; Routing instability,BGP; Instability origin; Root cause analysis; Routing instability; Computer simulation; Data reduction; Internet; Network protocols; System stability; Topology; Routers
"Li L., Alderson D., Willinger W., Doyle J.",4,A first-principles approach to understanding the internet's router-level topology,2004,161,"California Institute of Technology, United States; AT and T Labs Research, United States",AT and T Labs;California Institute of Technology,2,USA,1,48,40,"A detailed understanding of the many facets of the Internet's topological structure is critical for evaluating the performance of networking protocols, for assessing the effectiveness of proposed techniques to protect the network from nefarious intrusions and attacks, or for developing improved designs for resource provisioning. Previous studies of topology have focused on interpreting measurements or on phenomenological descriptions and evaluation of graph-theoretic properties of topology generators. We propose a complementary approach of combining a more subtle use of statistics and graph theory with a first-principles theory of router-level topology that reflects practical constraints and tradeoffs. While there is an inevitable tradeoff between model complexity and fidelity, a challenge is to distill from the seemingly endless list of potentially relevant technological and economic issues the features that are most essential to a solid understanding of the intrinsic fundamentals of network topology. We claim that very simple models that incorporate hard technological constraints on router and link bandwidth and connectivity, together with abstract models of user demand and network performance, can successfully address this challenge and further resolve much of the confusion and controversy that has surrounded topology generation and evaluation. Copyright 2004 ACM.",Degree-based generators; Heuristically optimal topology; Network topology; Topology metrics,Degree-based generators; Heuristically optimal topology; Network topology; Topology metrics; Bandwidth; Computer networks; Graph theory; Heuristic methods; Internet; Mathematical models; Network protocols; Probability; Topology; Routers
"Lakhina A., Crovella M., Diot C.",3,Diagnosing network-wide traffic anomalies,2004,472,"Dept. of Computer Science, Boston University, United States; Intel Research, Cambridge, United Kingdom",Boston University;Intel,2,UK;USA,2,25,17,"Anomalies are unusual and significant changes in a network's traffic levels, which can often span multiple links. Diagnosing anomalies is critical for both network operators and end users. It is a difficult problem because one must extract and interpret anomalous patterns from large amounts of high-dimensional, noisy data. In this paper we propose a general method to diagnose anomalies. This method is based on a separation of the high-dimensional space occupied by a set of network traffic measurements into disjoint subspaces corresponding to normal and anomalous network conditions. We show that this separation can be performed effectively by Principal Component Analysis. Using only simple traffic measurements from links, we study volume anomalies and show that the method can: (1) accurately detect when a volume anomaly is occurring; (2) correctly identify the underlying origin-destination (OD) flow which is the source of the anomaly; and (3) accurately estimate the amount of traffic involved in the anomalous OD flow. We evaluate the method's ability to diagnose (i.e., detect, identify, and quantify) both existing and synthetically injected volume anomalies in real traffic from two backbone networks. Our method consistently diagnoses the largest volume anomalies, and does so with a very low false alarm rate. Copyright 2004 ACM.",Anomaly Detection; Network Traffic Analysis,Detection; Network traffic analysis; Noisy data; Traffic anomalies; Congestion control (communication); Data reduction; Measurement theory; Principal component analysis; Spurious signal noise; Telecommunication links; Wireless telecommunication systems; Telecommunication traffic
"Qiu D., Srikant R.",2,Modeling and performance analysis of BitTorrent-like peer-to-peer networks,2004,457,"Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL 61801, United States",UIUC,1,USA,1,25,17,"In this paper, we develop simple models to study the performance of BitTorrent, a second generation peer-to-peer (P2P) application. We first present a simple fluid model and study the scalability, performance and efficiency of such a file-sharing mechanism. We then consider the built-in incentive mechanism of BitTorrent and study its effect on network performance. We also provide numerical results based on both simulations and real traces obtained from the Internet. Copyright 2004 ACM.",Fluid Model; Game Theory; Peer-to-Peer Networks,File sharing efficiency; Fluid models; Peer evolution; Peer-to-peer networks; Bandwidth; Client server computer systems; Computer simulation; Game theory; Internet; Mathematical models; Network protocols; Distributed computer systems
"Wang H.J., Guo C., Simon D.R., Zugenmaier A.",4,Shield: Vulnerability-driven network filters for preventing known vulnerability exploits,2004,79,Microsoft Research,Microsoft,1,USA,1,49,37,"Software patching has not been effective as a first-line defense against large-scale worm attacks, even when patches have long been available for their corresponding vulnerabilities. Generally, people have been reluctant to patch their systems immediately, because patches are perceived to be unreliable and disruptive to apply. To address this problem, we propose a first-line worm defense in the network stack, using shields - vulnerability-specific, exploit-generic network filters installed in end systems once a vulnerability is discovered, but before a patch is applied. These filters examine the incoming or outgoing traffic of vulnerable applications, and correct traffic that exploits vulnerabilities. Shields are less disruptive to install and uninstall, easier to test for bad side effects, and hence more reliable than traditional software patches. Further, shields are resilient to polymorphic or metamorphic variations of exploits. In this paper, we show that this concept is feasible by describing a prototype Shield framework implementation that filters traffic above the transport layer. We have designed a safe and restrictive language to describe vulnerabilities as partial state machines of the vulnerable application. The expressiveness of the language has been verified by encoding the signatures of several known vulnerabilites. Our evaluation provides evidence of Shield's low false positive rate and small impact on application throughput. An examination of a sample set of known vulnerabilities suggests that Shield could be used to prevent exploitation of a substantial fraction of the most dangerous ones. Copyright 2004 ACM.",Generic Protocol Analyzer; Network Filter; Patching; Vulnerability Signature; Worm Defense,Computer software; Computer worms; Encoding (symbols); Network protocols; Problem solving; Security of data; Telecommunication traffic; Generic protocol analyzers; Network filters; Patches; Vulnerability signature; Worm defense; Digital filters
"Sripanidkulchai K., Ganjam A., Maggs B., Zhang H.",4,The feasibility of supporting large-scale live streaming applications with dynamic application end-points,2004,87,"Carnegie Mellon University, United States; Akamai Technologies, United States",Akamai Technologies;Carnegie Mellon University,2,USA,1,25,22,"While application end-point architectures have proven to be viable solutions for large-scale distributed applications such as distributed computing and file-sharing, there is little known about its feasibility for more bandwidth-demanding applications such as live streaming. Heterogeneity in bandwidth resources and dynamic group membershi inherent properties of application end-points, may adversely affect the construction of a usable and efficient overlay. At large scales, the problems become even more challenging. In this paper, we study one of the most prominent architectural issues in overlay multicast: the feasibility of supporting large-scale groups using an application end-point architecture. We look at three key requirements for feasibility: (i) are there enough resources to construct an overlay, (ii) can a stable and connected overlay be maintained in the presence of group dynamics, and (iii) can an efficient overlay be constructed? Using traces from a large content delivery network, we characterize the behavior of users watching live audio and video streams. We show that in many common real-world scenarios, all three requirements are satisfied. In addition, we evaluate the performance of several design alternatives and show that simple algorithms have the potential to meet these requirements in practice. Overall, our results argue for the feasibility of supporting large-scale live streaming using an application end-point architecture. Copyright 2004 ACM.",Application-level multicast; Live streaming; Overlay multicast; Peer-to-peer,Application-level multicast; Live streaming; Overlay multicast; Peer-to-peer; Algorithms; Broadcasting; Computer applications; Large scale systems; Multicasting; Network protocols; Signal encoding; Telecommunication traffic; Computer networks
"Dabek F., Cox R., Kaashoek F., Morris R.",4,Vivaldi: A decentralized network coordinate system,2004,441,"MIT CSAIL, Cambridge, MA, United States",MIT,1,USA,1,31,25,"Large-scale Internet applications can benefit from an ability to predict round-trip times to other hosts without having to contact them first. Explicit measurements are often unattractive because the cost of measurement can outweigh the benefits of exploiting proximity information. Vivaldi is a simple, light-weight algorithm that assigns synthetic coordinates to hosts such that the distance between the coordinates of two hosts accurately predicts the communication latency between the hosts. Vivaldi is fully distributed, requiring no fixed network infrastructure and no distinguished hosts. It is also efficient: a new host can compute good coordinates for itself after collecting latency information from only a few other hosts. Because it requires little communication, Vivaldi can piggy-back on the communication patterns of the application using it and scale to a large number of hosts. An evaluation of Vivaldi using a simulated network whose latencies are based on measurements among 1740 Internet hosts shows that a 2-dimensional Euclidean model with height vectors embeds these hosts with low error (the median relative error in round-trip time prediction is 11 percent). Copyright 2004 ACM.",Internet topology; Network coordinates; Vivaldi,Internet topology; Network coordinates; Vivaldi; Wireless nets; Algorithms; Error analysis; Internet; Large scale systems; Local area networks; Mathematical models; Network protocols; Topology; Vectors; Computer networks
"Estan C., Keys K., Moore D., Varghese G.",4,Building a better NetFlow,2004,146,"CSE Dept., University of California, San Diego, United States; CAIDA, University of California, San Diego, United States",University of California San Diego,1,USA,1,29,19,"Network operators need to determine the composition of the traffic mix on links when looking for dominant applications, users, or estimating traffic matrices. Cisco's NetFlow has evolved into a solution that satisfies this need by reporting flow records that summarize a sample of the traffic traversing the link. But sampled NetFlow has shortcomings that hinder the collection and analysis of traffic data. First, during flooding attacks router memory and network bandwidth consumed by flow records can increase beyond what is available; second, selecting the right static sampling rate is difficult because no single rate gives the right tradeoff of memory use versus accuracy for all traffic mixes; third, the heuristics routers use to decide when a flow is reported are a poor match to most applications that work with time bins; finally, it is impossible to estimate without bias the number of active flows for aggregates with non-TCP traffic. In this paper we propose Adaptive NetFlow, deployable through an update to router software, which addresses many shortcomings of NetFlow by dynamically adapting the sampling rate to achieve robustness without sacrificing accuracy. To enable counting of non-TCP flows, we propose an optional Flow Counting Extension that requires augmenting existing hardware at routers. Both our proposed solutions readily provide descriptions of the traffic of progressively smaller sizes. Transmitting these at progressively higher levels of reliability allows graceful degradation of the accuracy of traffic reports in response to network congestion on the reporting path. Copyright 2004 ACM.",Data summarization; Network monitoring; Traffic measurement,Data summarizations; Network monitoring; Router memory; Traffic measurement; Computer software; Congestion control (communication); Data reduction; Routers; Storage allocation (computer); Telecommunication links; Telecommunication traffic; Telecommunication networks
"Hu N., Li L., Mao Z.M., Steenkiste P., Wang J.",5,"Locating internet bottlenecks: Algorithms, measurements, and implications",2004,62,"Carnegie Mellon University, United States; Bell Laboratories, United States; University of Michigan, United States; AT and T Labs - Research, United States",AT and T Labs;Bell Labs;Carnegie Mellon University;University of Michigan at Ann Arbor,4,USA,1,37,27,"The ability to locate network bottlenecks along end-to-end paths on the Internet is of great interest to both network operators and researchers. For example, knowing where bottleneck links are, network operators can apply traffic engineering either at the interdomain or intradomain level to improve routing. Existing tools either fail to identify the location of bottlenecks, or generate a large amount of probing packets. In addition, they often require access to both end points. In this paper we present Pathneck, a tool that allows end users to efficiently and accurately locate the bottleneck link on an Internet path. Pathneck is based on a novel probing technique called Recursive Packet Train (RPT) and does not require access to the destination. We evaluate Pathneck using wide area Internet experiments and trace-driven emulation. In addition, we present the results of an extensive study on bottlenecks in the Internet using carefully selected, geographically diverse probing sources and destinations. We found that Pathneck can successfully detect bottlenecks for almost 80% of the Internet paths we probed. We also report our success in using the bottleneck location and bandwidth bounds provided by Pathneck to infer bottlenecks and to avoid bottlenecks in multihoming and overlay routing. Copyright 2004 ACM.",Active probing; Available band-width; Bottleneck location; Packet train,Active probing; Available bandwidth; Bottleneck location; Packet train; Algorithms; Bandwidth; Computer networks; Packet networks; Routers; Telecommunication traffic; Throughput; Internet
"Maltz D.A., Xie G., Zhan J., Zhang H., Hjátmtýsson G., Greenberg A.",6,Routing design in operational networks: A look from the inside,2004,27,"Carnegie Mellon University, United States; AT and T Labs-Research, United States; Reykjavík University, Iceland",AT and T Labs;Carnegie Mellon University;Reykjavík University,3,Iceland;USA,2,28,18,"In any IP network, routing protocols provide the intelligence that takes a collection of physical links and transforms them into a network that enables packets to travel from one host to another. Though routing design is arguably the single most important design task for large IP networks, there has been very little systematic investigation into how routing protocols are actually used in production networks to implement the goals of network architects. We have developed a methodology for reverse engineering a coherent global view of a network's routing design from the static analysis of dumps of the local configuration state of each router. Starting with a set of 8,035 configuration files, we have applied this method to 31 production networks. In this paper we present a detailed examination of how routing protocols are used in operational networks. In particular, the results show the conventional model of ""interior"" and ""exterior"" gateway protocols is insufficient to describe the diverse set of mechanisms used by architects. We provide examples of the more unusual designs and examine their trade-offs. We discuss the strengths and weaknesses of our methodology, and argue that it opens paths towards new understandings of network behavior and design. Copyright 2004 AM.",Network modeling; Reverse engineering; Routing design; Static configuration analysis,Network modeling; Routing design; Routing protocols; Static configuration analysis; Computer architecture; Mathematical models; Program compilers; Reduced instruction set computing; Reverse engineering; Routers; Telecommunication traffic; Network protocols
"Balakrishnan H., Lakshminarayanan K., Ratnasamy S., Shenker S., Stoica I., Walfish M.",6,A layered naming architecture for the internet,2004,125,"MIT Computer Science and Artificial Intelligence Lab, United States; UC Berkeley, Computer Science Division, United States; Intel Research, Berkeley, United States; International Computer Science Institute (ICSI), United States",Intel;MIT;University of California Berkeley,3,USA,1,63,53,"Currently the Internet has only one level of name resolution, DNS, which converts user-level domain names into IP addresses. In this paper we borrow liberally from the literature to argue that there should be three levels of name resolution: from user-level descriptors to service identifiers; from service identifiers to endpoint identifiers; and from endpoint identifiers to IP addresses. These additional levels of naming and resolution (1) allow services and data to be first class Internet objects (in that they can be directly and persistently named), (2) seamlessly accommodate mobility and multihoming and (3) integrate middleboxes (such as NATs and firewalls) into the Internet architecture. We further argue that flat names are a natural choice for the service and endpoint identifiers. Hence, this architecture requires scalable resolution of flat names, a capability that distributed hash tables (DHTs) can provide. Copyright 2004 ACM.",Distributed hash tables; Global identifiers; Internet architecture; Middleboxes; Name resolution; Naming,Distributed hash tables (DHT); Global identifiers; Internet architecture; Middleboxes; Name resolution; Naming; Computer architecture; Data reduction; Distributed computer systems; Internet; Network protocols; User interfaces; Servers
"Teixeira R., Shaikh A., Griffin T., Voelker G.M.",4,Network sensitivity to hot-potato disruptions,2004,17,"UC San Diego, San Diego, CA, United States; AT and T Labs-Research, Florham Park, NJ, United States; Intel Research, Cambridge, United Kingdom",AT and T Labs;Intel;University of California San Diego,3,UK;USA,2,20,18,"Hot-potato routing is a mechanism employed when there are multiple (equally good) interdomain routes available for a given destination. In this scenario, the Border Gateway Protocol (BGP) selects the interdomain route associated with the closest egress point based upon intradomain path costs. Consequently, intradomain routing changes can impact interdomain routing and cause abrupt swings of external routes, which we call hot-potato disruptions. Recent work has shown that hot-potato disruptions can have a substantial impact on large ISP backbones and thereby jeopardize the network robustness. As a result, there is a need for guidelines and tools to assist in the design of networks that minimize hot-potato disruptions. However, developing these tools is challenging due to the complex and subtle nature of the interactions between exterior and interior routing. In this paper, we address these challenges using an analytic model of hot-potato routing that incorporates metrics to evaluate network sensitivity to hot-potato disruptions. We then present a methodology for computing these metrics using measurements of real ISP networks. We demonstrate the utility of our model by analyzing the sensitivity of a large AS in a tier 1 ISP network. Copyright 2004 ACM.",BGP; Hot-potato routing; IGP; Network robustness; OSPF; Sensitivity analysis,Border gateway protocol (BGP); Hot-potato routing; IGP; Network robustness; OSPF; Gateways (computer networks); Mathematical models; Robustness (control systems); Routers; Sensitivity analysis; Wireless telecommunication systems; Network protocols
"Appenzeller G., Keslassy I., McKeown N.",3,Sizing router buffers,2004,272,"Stanford University, United States",Stanford University,1,USA,1,33,23,"All Internet routers contain buffers to hold packets during times of congestion. Today, the size of the buffers is determined by the dynamics of TCP's congestion control algorithm. In particular, the goal is to make sure that when a link is congested, it is busy 100% of the time; which is equivalent to making sure its buffer never goes empty. A widely used rule-of-thumb states that each link needs a buffer of size B = RTT × C, where RTT is the average round-trip time of a flow passing across the link, and C is the data rate of the link. For example, a 10Gb/s router linecard needs approximately 250ms × 10Gb/s = 2.5Gbits of buffers; and the amount of buffering grows linearly with the line-rate. Such large buffers are challenging for router manufacturers, who must use large, slow, off-chip DRAMs. And queueing delays can be long, have high variance, and may destabilize the congestion control algorithms. In this paper we argue that the rule-of-thumb (B = RTT × C) is now outdated and incorrect for backbone routers. This is because of the large number of flows (TCP connections) multiplexed together on a single backbone link. Using theory, simulation and experiments on a network of real routers, we show that a link with n flows requires no more than B = (RTT × C)/√n, for long-lived or short-lived TCP flows. The consequences on router design are enormous: A 2.5Gb/s link carrying 10,000 flows could reduce its buffers by 99% with negligible difference in throughput; and a 10Gb/s link carrying 50,000 flows requires only 10Mbits of buffering, which can easily be implemented using fast, on-chip SRAM. Copyright 2004 ACM.",Bandwidth delay product; Buffer size; Internet router; TCP,Bandwidth delay product; Buffer size; Internet routers; TCP; Algorithms; Buffer storage; Congestion control (communication); Dynamic random access storage; Internet; Network protocols; Packet networks; Static random access storage; Telecommunication links; Routers
"Akella A., Pang J., Maggs B., Seshan S., Shaikh A.",5,A comparison of overlay routing and multihoming route control,2004,41,"Carnegie Mellon University, United States; IBM T.J. Watson Research Center, United States",Carnegie Mellon University;IBM,2,USA,1,34,30,"The limitations of BGP routing in the Internet are often blamed for poor end-to-end performance and prolonged connectivity interruptions. Recent work advocates using overlays to effectively bypass BGP's path selection in order to improve performance and fault tolerance. In this paper, we explore the possibility that intelligent control of BGP routes, coupled with ISP multihoming, can provide competitive end-to-end performance and reliability. Using extensive measurements of paths between nodes in a large content distribution network, we compare the relative benefits of overlay routing and multihoming route control in terms of round-trip latency, TCP connection throughput, and path availability. We observe that the performance achieved by route control together with multihoming to three ISPs (3-multihoming), is within 5-15% of overlay routing employed in conjunction 3-multihoming, in terms of both end-to-end RTT and throughput. We also show that while multihoming cannot offer the nearly perfect resilience of overlays, it can eliminate almost all failures experienced by a singly-homed end-network. Our results demonstrate that, by leveraging the capability of multihoming route control, it is not necessary to circumvent BGP routing to extract good wide-area performance and availability from the existing routing system. Copyright 2004 ACM.",Multihoming; Overlay routing; Route control,Multihoming; Overlay routing; Resilient overlay network (RON); Route control; Artificial intelligence; Computer architecture; Computer networks; Computer systems; Internet; Network protocols; Reliability; Throughput; Routers
"Draves R., Padhye J., Zill B.",3,Comparison of routing metrics for static multi-hop wireless networks,2004,377,Microsoft Research,Microsoft,1,USA,1,29,21,"Routing protocols for wireless ad hoc networks have traditionally focused on finding paths with minimum hop count. However, such paths can include slow or lossy links, leading to poor throughput. A routing algorithm can select better paths by explicitly taking the quality of the wireless links into account. In this paper, we conduct a detailed, empirical evaluation of the performance of three link-quality metrics-ETX, per-hop RTT, and per-hop packet pair-and compare them against minimum hop count. We study these metrics using a DSR-based routing protocol running in a wireless testbed. We find that the ETX metric has the best performance when all nodes are stationary. We also find that the per-hop RTT and per-hop packet-pair metrics perform poorly due to self-interference. Interestingly, the hop-count metric outperforms all of the link-quality metrics in a scenario where the sender is mobile. Copyright 2004 ACM.",Routing; Wireless multi-hop networks,Algorithms; Metric system; Network protocols; Packet networks; Routers; Telecommunication links; Expected transmission count (ETX); Link-quality metrics; Routing; Wireless multi-hop networks; Wireless telecommunication systems
"Goldenberg D.K., Qiu L., Xie H., Yang Y.R., Zhang Y.",5,Optimizing cost and performance for multihoming,2004,78,"AT and T Labs - Research, United States; Microsoft Research; Yale University, United States",AT and T Labs;Microsoft;Yale University,3,USA,1,33,22,"Multihoming is often used by large enterprises and stub ISPs to connect to the Internet, In this paper, we design a series of novel smart routing algorithms to optimize cost and performance for multihomed users. We evaluate our algorithms through both analysis and extensive simulations based on realistic charging models, traffic demands, performance data, and network topologies. Our results suggest that these algorithms are very effective in minimizing cost and at the same time improving performance. We further examine the equilibrium performance of smart routing in a global setting and show that a smart routing user can improve its performance without adversely affecting other users. Copyright 2004 ACM.",Algorithms; Multihoming; Optimization; Smart Routing,ISP; Multihoming; Smart routing; Virtual private network (VPN); Algorithms; Internet; Mathematical models; Optimization; Quality of service; Routers; Telecommunication traffic; Topology; Computer networks
"Jain S., Fall K., Patra R.",3,Routing in a delay tolerant network,2004,774,"University of Washington, United States; Intel Research, Berkeley, United States; University of California, Berkeley, United States",Intel;University of California Berkeley;University of Washington at St. Louis,3,USA,1,25,14,"We formulate the delay-tolerant networking routing problem, where messages are to be moved end-to-end across a connectivity graph that is time-varying but whose dynamics may be known in advance. The problem has the added constraints of finite buffers at each node and the general property that no contemporaneous end-to-end path may ever exist. This situation limits the applicability of traditional routing approaches that tend to treat outages as failures and seek to find an existing end-to-end path. We propose a framework for evaluating routing algorithms in such environments. We then develop several algorithms and use simulations to compare their performance with respect to the amount of knowledge they require about network topology. We find that, as expected, the algorithms using the least knowledge tend to perform poorly. We also find that with limited additional knowledge, far less than complete global knowledge, efficient algorithms can be constructed for routing in such environments. To the best of our knowledge this is the first such investigation of routing issues in DTNs. Copyright 2004 ACM.",Delay Tolerant Network; Routing,Delay tolerant network (DTN); Routing; Routing algorithms; Routing problems; Algorithms; Constraint theory; Delay circuits; Fault tolerant computer systems; Knowledge based systems; Mathematical models; Problem solving; Routers
"Pappu P., Turner J., Wong K.",3,Work-conserving distributed schedulers for terabit routers,2004,6,"Washington University, Computer Science and Engineering, St. Louis, MO 63130-4899, United States",University of Washington at St. Louis,1,USA,1,13,3,"Buffered multistage interconnection networks offer one of the most scalable and cost-effective approaches to building high capacity routers. Unfortunately, the performance of such systems has been difficult to predict in the presence of the extreme traffic conditions that can arise in the Internet. Recent work introduced distributed scheduling, to regulate the flow of traffic in such systems. This work demonstrated, using simulation and experimental measurements, that distributed scheduling can deliver robust performance for extreme traffic. Here, we show that distributed schedulers can be provably work-conserving for speedups of 2 or more. Two of the three schedulers we describe were inspired by previously published crossbar schedulers. The third has no direct counterpart in crossbar scheduling. In our analysis, we show that distributed schedulers based on blocking flows in small-depth acyclic flow graphs can be work-conserving, just as certain crossbar schedulers based on maximal bipartite matchings have been shown to be work-conserving. We also study the performance of practical variants of these schedulers when the speedup is less than 2, using simulation. Copyright 2004 ACM.",CIOQ switches; Crossbar scheduling; Distributed scheduling; High performance routers,CIOQ switches; Crossbar scheduling; Distributed scheduling; High performance routers; Computer simulation; Cost effectiveness; Distributed computer systems; Packet networks; Scheduling; Telecommunication traffic; Routers
"Kim M.S., Kim T., Shin Y., Lam S.S., Powers E.J.",5,A wavelet-based approach to detect shared congestion,2004,22,"Dept. of Computer Sciences, University of Texas, Austin, United States; Dept. of Electrical and Computer Engineering, University of Texas, Austin, United States",University of Texas at Austin,1,USA,1,19,13,"Per-flow congestion control helps endpoints fairly and efficiently share network resources. Better utilization of network resources can be achieved, however, if congestion management algorithms can determine when two different flows share a congested link. Such knowledge can be used to implement cooperative congestion control or improve the overlay topology of a P2P system. Previous techniques to detect shared congestion either assume a common source or destination node, drop-tail queueing, or a single point of congestion. We propose in this paper a novel technique, applicable to any pair of paths on the Internet, without such limitations. Our technique employs a signal processing method, wavelet denoising, to separate queueing delay caused by network congestion from various other delay variations. Our wavelet-based technique is evaluated through both simulations and Internet experiments. We show that, when detecting shared congestion of paths with a common endpoint, our technique provides faster convergence and higher accuracy while using fewer packets than previous techniques, and that it also accurately determines when there is no shared congestion. Furthermore, we show that our technique is robust and accurate for paths without a common endpoint or synchronized clocks; more specifically, it can tolerate a synchronization offset of up to one second between two packet flows. Copyright 2004 ACM.",Shared congestion; Wavelet denoising,Delay variations; Network resorces; Shared congestion; Wavelet denoising; Computer simulation; Internet; Packet networks; Queueing networks; Signal processing; Telecommunication networks; Wavelet transforms; Congestion control (communication)
"Raghavan B., Snoeren A.C.",2,A system for authenticated policy-compliant routing,2004,14,"University of California, San Diego, United States",University of California San Diego,1,USA,1,41,36,"Internet end users and ISPs alike have little control over how packets are routed outside of their own AS, restricting their ability to achieve levels of performance, reliability, and utility that might otherwise be attained. While researchers have proposed a number of source-routing techniques to combat this limitation, there has thus far been no way for independent ASes to ensure that such traffic does not circumvent local traffic policies, nor to accurately determine the correct party to charge for forwarding the traffic. We present Platypus, an authenticated source routing system built around the concept of network capabilities. Network capabilities allow for accountable, fine-grained path selection by cryptographically attesting to policy compliance at each hop along a source route. Capabilities can be composed to construct routes through multiple ASes and can be delegated to third parties. Platypus caters to the needs of both end users and ISPs: users gain the ability to pool their resources and select routes other than the default, while ISPs maintain control over where, when, and whose packets traverse their networks. We describe how Platypus can be used to address several well-known issues in wide-area routing at both the edge and the core, and evaluate its performance, security, and interactions with existing protocols. Our results show that incremental deployment of Platypus can achieve immediate gains. Copyright 2004 ACM.",Authentication; Capabilities; Overlay networks; Source routing,Authentication; Capabilities; Overlay networks; Source routing; Internet; Network protocols; Packet networks; Reliability theory; Telecommunication traffic; User interfaces; Routers
"Yalagandula P., Dahlin M.",2,A scalable distributed information management system,2004,89,"Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712, United States",University of Texas at Austin,1,USA,1,46,40,"We present a Scalable Distributed Information Management System (SDIMS) that aggregates information about large-scale networked systems and that can serve as a basic building block for a broad range of large-scale distributed applications by providing detailed views of nearby information and summary views of global information. To serve as a basic building block, a SDIMS should have four properties: scalability to many nodes and attributes, flexibility to accommodate a broad range of applications, administrative isolation for security and availability, and robustness to node and network failures. We design, implement and evaluate a SDIMS that (1) leverages Distributed Hash Tables (DHT) to create scalable aggregation trees, (2) provides flexibility through a simple API that lets applications control propagation of reads and writes, (3) provides administrative isolation through simple extensions to current DHT algorithms, and (4) achieves robustness to node and network reconfigurations through lazy reaggregation, on-demand reaggregation, and tunable spatial replication. Through extensive simulations and micro-benchmark experiments, we observe that our system is an order of magnitude more scalable than existing approaches, achieves isolation properties at the cost of modestly increased read latency in comparison to flat DHTs, and gracefully handles failures. Copyright 2004 ACM.",Distributed Hash Tables; Information Management System; Networked System Monitoring,Control propagation; Distributed hash tables (DHT); Information management systems; Networked system monitoring; Block codes; Computer simulation; Database systems; Information management; Large scale systems; Robustness (control systems); Distributed computer systems
"Pappas V., Xu Z., Terzis A., Lu S., Zhang L., Massey D.",6,Impact of configuration errors on DNS robustness,2004,30,"UCLA, Computer Science, United States; Johns Hopkins University, United States; Colorado State University, United States",Colorado State University;Johns Hopkins University,2,USA,1,27,24,"During the past twenty years the Domain Name System (DNS) has sustained phenomenal growth while maintaining satisfactory performance. However, the original design focused mainly on system robustness against physical failures, and neglected the impact of operational errors such as misconfigurations. Our recent measurement effort revealed three specific types of misconfigurations in DNS today: lame delegation, diminished server redundancy, and cyclic zone dependency. Zones with configuration errors suffer from reduced availability and increased query delays up to an order of magnitude. Furthermore, while the original DNS design assumed that redundant DNS servers fail independently, our measurements show that operational choices made at individual zones can severely affect the availability of other zones. We found that, left unchecked, DNS configuration errors are widespread, with lame delegation affecting 15% of the DNS zones, diminished server redundancy being even more prevalent, and cyclic dependency appearing in 2% of the zones. We also noted that the degrees of misconfiguration vary from zone to zone, with most popular zones having the lowest percentage of errors. Our results indicate that DNS, as well as any other truly robust large-scale system, must include systematic checking mechanisms to cope with operational errors. Copyright 2004 ACM.",DNS; Misconfigurations; Resiliency,Cyclic dependency; Domain name systems (DNS); Misconfiguration; Resiliency; Error analysis; Internet; Large scale systems; Redundancy; Reliability theory; Robustness (control systems); Servers
"Ramasubramanian V., Sirer E.G.",2,The design and implementation of a next generation name service for the internet,2004,121,"Dept. of Computer Science, Cornell University, Ithaca, NY 14853, United States",Cornell University,1,USA,1,43,38,"Name services are critical for mapping logical resource names to physical resources in large-scale distributed systems. The Domain Name System (DNS) used on the Internet, however, is slow, vulnerable to denial of service attacks, and does not support fast updates. These problems stem fundamentally from the structure of the legacy DNS. This paper describes the design and implementation of the Cooperative Domain Name System (CoDoNS), a novel name service, which provides high lookup performance through proactive caching, resilience to denial of service attacks through automatic load-balancing, and fast propagation of updates. CoDoNS derives its scalability, decentralization, self-organization, and failure resilience from peer-to-peer overlays, while it achieves high performance using the Beehive replication framework. Cryptographic delegation, instead of host-based physical delegation, limits potential malfeasance by names-pace operators and creates a competitive market for names-pace management. Backwards compatibility with existing protocols and wire formats enables CoDoNS to serve as a backup for legacy DNS, as well as a complete replacement. Performance measurements from a real-life deployment of the system in PlanetLab shows that CoDoNS provides fast lookups, automatically reconfigures around faults without manual involvement and thwarts distributed denial of service attacks by promptly redistributing load across nodes. Copyright 2004 ACM.",DNS; Peer to peer; Proactive caching,Domain name systems (DNS); Load-balancing; Peer to peer; Proactive caching; Cache memory; Cryptography; Gateways (computer networks); Internet; Problem solving; Telecommunication networks; Servers
Valente P.,1,"Exact GPS simulation with logarithmic complexity, and its application to an optimally fair scheduler",2004,15,"Dipartimento di Ingegneria dell'Informazione, Università di Pisa, Via Diotisalvi, 2, Italy",Università di Pisa,1,Italy,1,24,15,"Generalized Processor Sharing (GPS) is a fluid scheduling policy providing perfect fairness. The minimum deviation (lead/lag) with respect to the GPS service achievable by a packet scheduler is one packet size. To the best of our knowledge, the only packet scheduler guaranteeing such minimum deviation is Worst-case Fair Weighted Fair Queueing (WF2Q), that requires on-line GPS simulation. Existing algorithms to perform GPS simulation have O(N) complexity per packet transmission (N being the number of competing flows). Hence WF2Q has been charged for O(N) complexity too. Schedulers with lower complexity have been devised, but at the price of at least O(N) deviation from the GPS service, which has been shown to be detrimental for real-time adaptive applications and feedback based applications. Furthermore, it has been proven that the lower bound complexity to guarantee O(1) deviation is Ω(log N, yet a scheduler achieving such result has remained elusive so far. In this paper we present an algorithm that performs exact GPS simulation with O(log N) worst-case complexity and small constants. As such it improves the complexity of all the packet schedulers based on GPS simulation. In particular, using our algorithm within WF2Q, we achieve the minimum deviation from the GPS service with O(log N) complexity, thus matching the aforementioned lower bound. Furthermore, we assess the effectiveness of the proposed solution by simulating real-world scenarios. Copyright 2004 ACM.",Computational Complexity; Data Structures; Packet Scheduling; Quality of Service,Computational complexity; Computer simulation; Data structures; Logarithmic amplifiers; Packet networks; Program processors; Quality of service; Real time systems; Scheduling; Generalized processor sharing (GPS); Logarithmic complexity; Packet scheduling; Real-time adaptive application; Queueing networks
"Wang R.Y., Sobti S., Garg N., Ziskind E., Lai J., Krishnamurthy A.",6,Turning the postal system into a generic digital communication mechanism,2004,20,"Department of Computer Science, Princeton University, United States; Department of Computer Science, Yale University, United States",Princeton University;Yale University,2,USA,1,24,18,"The phenomenon that rural residents and people with low incomes lag behind in Internet access is known as the ""digital divide."" This problem is particularly acute in developing countries, where most of the world's population lives. Bridging this digital divide, especially by attempting to increase the accessibility of broadband connectivity, can be challenging. The improvement of wide-area connectivity is constrained by factors such as how quickly we can dig ditches to bury fibers in the ground; and the cost of furnishing ""last-mile"" wiring can be prohibitively high. In this paper, we explore the use of digital storage media transported by the postal system as a general digital communication mechanism. While some companies have used the postal system to deliver software and movies, none of them has turned the postal system into a truly generic digital communication medium supporting a wide variety of applications. We call such a generic system a Postmanet. Compared to traditional wide-area connectivity options, the Postmanet has several important advantages, including wide global reach, great bandwidth potential and low cost. Manually preparing mobile storage devices for shipment may appear deceptively simple, but with many applications, communicating parties and messages, manual management becomes infeasible, and systems support at several levels becomes necessary. We explore the simultaneous exploitation of the Internet and the Postmanet, so we can combine their latency and bandwidth advantages to enable sophisticated bandwidth-intensive applications. Copyright 2004 ACM.",Network architecture; Postal network; Storage devices,Bandwidth advantages; Network architecture; Postal networks; Storage devices; Bandwidth; Broadband networks; Computer architecture; Data storage equipment; Internet; Network protocols; Routers; Telecommunication networks
"Hu Y.-C., Perrig A., Sirbu M.",3,SPV: Secure path vector routing for securing BGP,2004,62,"UC Berkeley, United States; Carnegie Mellon University, United States",Carnegie Mellon University;University of California Berkeley,2,USA,1,59,47,"As our economy and critical infrastructure increasingly relies on the Internet, the insecurity of the underlying border gateway routing protocol (BGP) stands out as the Achilles heel. Recent misconfigurations and attacks have demonstrated the brittleness of BGP. Securing BGP has become a priority. In this paper, we focus on a viable deployment path to secure BGP. We analyze security requirements, and consider tradeoffs of mechanisms that achieve the requirements. In particular, we study how to secure BGP update messages against attacks. We design an efficient cryptographic mechanism that relies only on symmetric cryptographic primitives to guard an ASPATH from alteration, and propose the Secure Path Vector (SPV) protocol. In contrast to the previously proposed S-BGP protocol, SPY is around 22 times faster. With the current effort to secure BGP, we anticipate that SPY will contribute several alternative mechanisms to secure BGP, especially for the case of incremental deployments. Copyright 2004 ACM.",BGP; Border Gateway Protocol; Interdomain routing; Routing; Security,Border gateway protocol (BGP); Interdomain routing; Secure path vectors (SPV); Security; Cryptography; Packet networks; Routers; Security of data; Telecommunication networks; Vectors; Network protocols
"Li Z., Mohapatra P.",2,QoS-aware multicasting in DiffServ domains,2004,8,"Department of Computer Science, 2063 Engineering II, University of California at Davis, Davis, CA 95616, United States",University of California Davis,1,USA,1,32,27,"QoS-aware multicasting is becoming more and more desirable with the expanding usage of group-based applications, especially those involving multimedia objects. Until now, most of the proposed QoS-aware multicasting routing protocols adopt per-flow based resource reservation. Although these schemes can be adopted in integrated services (IntServ) Internet, they are not suitable for more scalable Differentiated Services (DiffServ) Internet. A new QoS-aware multicast routing protocol called QMD is proposed for DiffServ environments in this paper. Based on the design philosophy of DiffServ, the complex multicasting control plane functionalities are removed from the core routers. In addition, for each multicast group, only a limited set of on-tree routers (termed as key nodes) maintain multicast routing states and forward multicast data traffic. The key nodes of a multicast group uniquely identify a QoS-satisfied multicast tree connecting the group members. Although the other on-tree routers between any two key nodes do not maintain any multicast routing states and QoS reservation information, the group members' QoS requirements can still be satisfied. Through simulation experiments based on both random and real intra-domain topologies, we have also demonstrated that QMD can provide higher QoS-satisfaction rate while maintaining the simplicity of core routers.",Differentiated Services (DiffServ); Multicasting; QMD; QoS-aware Multicast Routing,Differentiated Services (DiffServ); Multicast tree; QMD; QoS-aware Multicast Routing; Internet; Multicasting; Quality of service; Resource allocation; Routers; Telecommunication systems; Telecommunication services
"Corndorf E., Liang C., Kanter G.S., Kumar P., Yuen H.P.",5,Quantum-noise - Protected data encryption for WDM fiber-optic networks,2004,3,"Center for Photonic Communication and Computing, Department of Electrical and Computer Engineering, Northwestern University, 2145 Sheridan Road, Evanston, IL 60208, United States",Center for Photonic Communication and Computing;Northwestern University,2,USA,1,20,13,"We demonstrate high data-rate quantum-noise - protected data encryption through optical fibers using coherent states of light. Specifically, we demonstrate 650Mbps data encryption through a 10Gbps data-bearing, in-line amplified 200km-long line. In our protocol, legitimate users (who share a short secret-key) communicate using an M-ry signal set while an attacker (who does not share the secret-key) is forced to contend with the fundamental and irreducible quantum-measurement noise of coherent states. Implementations of our protocol using both polarization-encoded signal sets as well as polarization-insensitive phase-keyed signal sets are experimentally and theoretically evaluated. Different from the performance criteria of the cryptographic objective of key generation (quantum key generation), the performance criteria of data encryption are established and carefully considered.",Data encryption; Quantum cryptography,Coherent states; Data encryption; Fiber-optic networks; Communication systems; Computer networks; Fiber optics; Network protocols; Performance; Security of data; Quantum cryptography
"Uhlig S., Bonaventure O.",2,Designing BGP-based outbound traffic engineering techniques for stub ASes,2004,23,"Computer Science and Engineering Department, Université Catholique de Louvain, Belgium",Universite Catholique de Louvain,1,Belgium,1,67,56,"Today, most multi-connected autonomous systems (AS) need to control the flow of their interdomain traffic for both performance and economical reasons. This is usually done by manually tweaking the BGP configurations of the routers on an error-prone trial-and-error basis. In this paper, we demonstrate that designing systematic BGP-based traffic engineering techniques for stub ASes are possible. Our approach to solve this traffic engineering problem is to allow the network operator to define objective functions on the interdomain traffic. Those objective functions are used by an optimization box placed inside the AS that controls the interdomain traffic by tuning the iBGP messages distributed inside the AS. We show that the utilization of an efficient evolutionary algorithm allows to both optimize the objective function and limit the number of iBGP messages. By keeping a lifetime on the tweaked routes, we also show that providing stability to the interdomain path followed by the traffic is possible. We evaluate the performance of solution based on traffic traces from two stub ASes of different sizes. Our simulations show that the interdomain traffic can be efficiently engineered by using not more than a few iBGP advertisements per minute. Our contribution in this paper is to demonstrate that by carefully thinking the design of the interdomain traffic engineering technique, stub ASes can engineer their outbound traffic over relatively short timescales, by exclusively tweaking their BGP routes, and with a minimal burden on BGP. Systematic BGP-based traffic engineering for stub ASes is thus possible at a very limited cost in terms of iBGP messages.",BGP; Interdomain traffic engineering; Multiple-objectives optimization,Error analysis; Stability; Telecommunication services; Telecommunication systems; BGP; Interdomain traffic engineering; Multiple-objectives optimization; Traffic engineering; Telecommunication traffic
"Lloyd S., Shapiro J.H., Wong F.N.C., Kumar P., Shahriar S.M., Yuen H.P.",6,Infrastructure for the quantum Internet,2004,29,"Massachusetts Institute of Technology, Research Laboratory of Electronics, 77 Massachusetts Avenue, Cambridge, MA 02139, United States; Northwestern University, Department of Electrical and Computer Engineering, Center for Photonic Communication and Computing, 2145 North Sheridan Road, Evanston, IL 60208, United States; Department of Mechanical Engineering, United States; Department of Electrical Engineering and Computer Science, United States",MIT;Northwestern University,2,USA,1,28,16,"A team of researchers from the Massachusetts Institute of Technology (MIT) and Northwestern University (NU) is developing a system for long-distance, high-fidelity qubit teleportation. Such a system will be required if future quantum computers are to be linked together into a quantum Internet. This paper presents recent progress that the MIT/NU team has made, beginning with a review of the teleportation architecture and its loss-limited performance analysis.",Entanglement; Quantum communication; Quantum memory; Qubits; Teleportation,Entanglement; Quantum communication; Quantum memory; Qubits; Teleportation; Computer architecture; Computer networks; Performance; Quantum theory; Societies and institutions; World Wide Web; Internet
"Gaynor M., Bradner S.",2,"A real options framework to value network, protocol, and service architecture",2004,17,"Boston Universty, United States; Harvard University, United States",Boston University;Harvard University,2,USA,1,15,11,"This paper proposes a real options framework for evaluating architectural choices and the economic value of these alternative choices of networks, protocols, and services. Using proven financial techniques of real options, our model explores the value of distributed architecture compared to the benefits of centralized control. Voice and email case studies that agree with our theory and model are presented. We apply our model to illustrate the value of end-to-end structure, why SIP-based VoIP is winning, and the value of open garden service business models allowing third parties to provide network services/applications. This work illustrates the potential of real options to help quantify the economic value of network, protocol, and service architectures.",End-to-end; Network architecture; Network services; Real options,End-to-end; Network architecture; Network services; Real options; Computer architecture; Computer networks; Distributed computer systems; Electronic mail; Information services; Mathematical models; Network protocols
"Akella A., Chawla S., Kannan A., Seshan S.",4,On the scaling of congestion in the internet graph,2004,8,"Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States",Carnegie Mellon University,1,USA,1,23,19,"As the Internet grows in size, it becomes crucial to understand how the speeds of links in the network must improve in order to sustain the pressure of new end-nodes being added each day. Although the speeds of links in the core and at the edges improve roughly according to Moore's law, this improvement alone might not be enough. Indeed, the structure of the Internet graph and routing in the network might necessitate much faster improvements in the speeds of key links in the network. In this paper, using a combination of analysis and extensive simulations, we show that the worst congestion in the Internet AS-level graph in fact scales poorly with the network size (n 1+Ω(1), where n is the number of nodes), when shortestpath routing is used to route traffic between ASes. We also show, somewhat surprisingly, that policy-based routing does not exacerbate the maximum congestion when compared to shortest-path routing. Our results show that it is crucial to identify ways to alleviate this congestion to avoid some links from being perpetually congested. To this end, we show that the congestion scaling properties of Internet-like graphs can be improved dramatically by introducing moderate amounts of redundancy in the graph in terms of parallel edges between pairs of adjacent nodes.",Congestion; Power-law graphs; Shortest path routing,Congestion; Power-law graphs; Shortest path routing; Computational complexity; Computer networks; Computer simulation; Graph theory; Internet; Problem solving; Congestion control (communication)
Voice T.,1,A global stability result for primal-dual congestion control algorithms with routing,2004,10,"Statistical Laboratory, University of Cambridge, Cambridge, United Kingdom",University of Cambridge,1,UK,1,16,13,We prove a global stability result for a fluid approximation of a class of Internet-like communications networks operating a form of congestion control with routing. The network consists of an arbitrary interconnection of sources and links with negligible propagation delays. The model here allows for arbitrary strictly concave utility functions and the presence of dynamics at both sources and links.,Global stability,Algorithms; Communication systems; Functions; Stability; Telecommunication traffic; Global stability; Internet-like communications; Propagation delays; Computer networks
"Bai F., Bhaskara G., Helmy A.",3,Building the blocks of protocol design and analysis challenges and lessons learned from case studies on mobile ad hoc routing and micro-mobility protocols,2004,16,"Dept. of Electrical Engineering, Univ. of Southern California, Los Angeles, CA 90089, United States",University of Southern California,1,USA,1,18,13,"With the emergence of new application-specific sensor and Adhoc networks, increasingly complex and custom protocols will be designed and deployed. We propose a framework to systematically design and evaluate networking protocols based on a 'building block' approach. In this approach, each protocol is broken down into a set of parameterized modules called ""building blocks"", each having its own specific functionality. The properties of these building blocks and their interaction define the overall behavior of the protocol. In this paper, we aim to identify the major research challenges and questions in the building block approach. By addressing some of those questions, we point out potential directions to analyze and understand the behavior of networking protocols systematically. We discuss two case studies on utilizing the building block approach for analyzing Ad-hoc routing protocols and IP mobility protocols in a systematic manner.",Building Block; Micro-Mobility; Mobile Ad Hoc Network; Protocol Analysis; Protocol Design,Building Block; Micro-Mobility; Mobile Ad Hoc Network; Protocol Analysis; Protocol Design; Communication systems; Computer networks; Internet; Parameter estimation; Systems analysis; Network protocols
"Agarwal A., Kumar P.R.",2,Capacity bounds for ad hoc and hybrid wireless networks,2004,149,"Department of Computer Science, University of Illinois, 1308 West Main St., Urbana, IL 61801-2307, United States; Coordinated Science Laboratory, University of Illinois, 1308 West Main St., Urbana, IL 61801-2307, United States",UIUC,1,USA,1,11,8,"We study the capacity of static wireless networks, both ad hoc and hybrid, under the Protocol and Physical Models of communication, proposed in [1]. For ad hoc networks with n nodes, we show that under the Physical Model, where signal power is assumed to attenuate as 1/rα, α &gt; 2, the transport capacity scales as ⊖(√n) bit-meters/sec. The same bound holds even when the nodes are allowed to approach arbitrarily close to each other and even under a more generalized notion of the Physical Model wherein the data rate is Shannon's logarithmic function of the SINK at the receiver. This result is sharp since it closes the gap that existed between the previous best known upper bound of O(n α - 1/α) and lower bound of Ω(√n). We also show that any spatio-temporal scheduling of transmissions and their ranges that is feasible under the Protocol Model can also be realized under the Physical Model by an appropriate choice of power levels for appropriate thresholds. This allows the generalization of various lower bound constructions from the Protocol Model to the Physical Model. In particular, this provides a better lower bound on the best case transport capacity than in [1]. For hybrid networks, we consider an overlay of μn randomly placed wired base stations. It has previously been shown in [6] that if all nodes adopt a common power level, then each node can be provided a throughput of at most ⊖(1/log n) to randomly chosen destinations. Here we show that by allowing nodes to perform power control and properly choosing μ, it is further possible to provide a throughput of ⊖(1) to any fraction f, 0 &lt; f &lt; 1, of nodes. This result holds under both the Protocol and Physical models of communication. On the one hand, it shows that that the aggregate throughput capacity, measured as the sum of individual throughputs, can scale linearly in the number of nodes. On the other hand, the result underscores the importance of choosing minimum power levels for communication and suggests that simply communicating with the closest node or base station could yield good capacity even for multihop hybrid wireless networks.",Ad hoc networks; Hybrid networks; Physical model; Protocol model; Throughput capacity; Transport capacity; Wireless networks,Communication systems; Computational complexity; Network protocols; Optimization; Throughput; Wireless telecommunication systems; Ad hoc networks; Hybrid networks; Physical model; Protocol model; Transport capacity; Wireless networks; Computer networks
"Bestavros A., Bradley A., Kfoury A., Matta I.",4,Safe compositional specification of networking systems,2004,4,"Computer Science Department, Boston University, United States",Boston University,1,USA,1,19,17,"The science of network service composition has emerged as one of the grand themes of networking research [17] as a direct result of the complexity and sophistication of emerging networked systems and applications. By ""service composition"" we mean that the performance and correctness properties local to the various constituent components of a service can be readily composed into global (end-to-end) properties without re-analyzing any of the constituent components in isolation, or as part of the whole composite service. The set of laws that govern such composition is what will constitute that new science of composition. The heterogeneity and open nature of network systems make composition quite challenging, and thus programming network services has been largely inaccessible to the average user. We identify (and outline) a research agenda in which we aim to develop a specification language that is expressive enough to describe different components of a network service, and that will include type hierarchies inspired by type systems in general programming languages that enable the safe composition of software components. We envision this new science of composition to be built upon several theories, possibly including control theory, network calculus, scheduling theory, and game theory. In essence, different theories may provide different languages by which certain properties of system components can be expressed and composed into larger systems. We then seek to lift these lower-level specifications to a higher level by abstracting away details that are irrelevant for safe composition at the higher level, thus making theories scalable and useful to the average user. In this paper we focus on services built upon an overlay traffic management architecture, and we use control theory and QoS theory as example theories from which we lift up compositional specifications.",Control Theory; QoS Theory; Service Composition; Type Systems,QoS Theory; Service Composition; Type Systems; Abstracting; Computer programming languages; Control theory; Laws and legislation; Performance; Quality of service; Computer networks
"Challal Y., Bettahar H., Bouabdallah A.",3,SAKM: A scalable and adaptive key management approach for multicast communications,2004,40,"Compiegne University of Technology, Heudiasyc Lab., France",Compiegne University of Technology,1,France,1,33,28,"Multicasting is increasingly used as an efficient communication mechanism for group-oriented applications in the Internet. In order to offer secrecy for multicast applications, the traffic encryption key has to be changed whenever a user joins or leaves the system. Such a change has to be communicated to all the current users. The bandwidth used for such rekeying operation could be high when the group size is large. The proposed solutions to cope with this limitation, commonly called 1 affects n phenomenon, consist of organizing group members into subgroups that use independent traffic encryption keys. This kind of solutions introduce a new challenge which is the requirement of decrypting and reencrypting multicast messages whenever they pass from one subgroup to another. This is a serious drawback for applications that require real-time communication such as video-conferencing. In order to avoid the systematic decryption / reencryption of messages, we propose in this paper an adaptive solution which structures group members into clusters according to the application requirements in term of synchronization and the membership change behavior in the secure session. Simulation results show that our solution is efficient and typically adaptive compared to other schemes.",Key Management; Multicat; Scalability; Security,Adaptive systems; Computer networks; Cryptography; Internet; Security of data; Synchronization; Telecommunication traffic; Key Management; Multicat; Scalability; Security; Multicasting
Uhlig S.,1,Non-stationarity and high-order scaling in TCP flow arrivals: A methodological analysis,2004,22,"Computer Science and Engineering Department, Université Catholique de Louvain, Belgium",Universite Catholique de Louvain,1,Belgium,1,37,28,"The last decade has been a very fruitful period in important discoveries in network traffic modeling, uncovering various scaling behaviors. Self-similarity, long-range dependence, multifractal behavior and finally cascades have been studied and convincingly matched to real traffic. The first purpose of this paper is to provide a methodology to go beyond the naive analysis of the second-order wavelet-based estimators of scaling, by performing non-stationarity checks and relying on the information contained in the high-order properties of the wavelet coefficients. Then, we apply this methodology to study the scaling properties of the TCP flow arrivals based on several traffic traces spanning the years from 1993 to early 2002. Our study reveals that the second-order scaling properties of this process describe its dynamics quite well. However, our analysis also provides evidence that high-order scaling in this process appears due to pathological behaviors like rate limitation and non-stationarity.",Long-range dependence; Multiscaling; Non-stationarity; Scaling processes; TCP flow arrivals,Computer networks; Pathology; Performance; Telecommunication traffic; Wavelet transforms; Long-range dependence; Multiscaling; Non-stationarity; Scaling processes; TCP flow arrivals; Network protocols
"Kreibich C., Crowcroft J.",2,Honeycomb - Creating intrusion detection signatures using honeypots,2004,138,"University of Cambridge, Computer Laboratory, JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom",University of Cambridge,1,UK,1,13,9,This paper describes a system for automated generation of attack signatures for network intrusion detection systems. Our system applies pattern-matching techniques and protocol conformance checks on multiple levels in the protocol hierarchy to network traffic captured a honeypot system. We present results of running the system on an unprotected cable modem connection for 24 hours. The system successfully created precise traffic signatures that otherwise would have required the skills and time of a security officer to inspect the traffic manually.,Honeypots; Longest-common-substring algorithms; Network intrusion detection; Pattern detection; Protocol analysis; Suffix trees; Traffic signatures,Automation; Modems; Network protocols; Pattern matching; Security of data; Systems engineering; Telecommunication traffic; Honeypots; Longest-common-substring algorithms; Network intrusion detection; Pattern detection; Protocol analysis; Suffix trees; Traffic signatures; Computer networks
"Feamster N., Borkenhagen J., Rexford J.",3,Guidelines for interdomain traffic engineering,2003,104,"Laboratory for Computer Science, Massachusetts Institute of Technology, Cambridge, MA 02139, United States; AT and T IP Services, AT and T Labs., Middletown, NJ 07748, United States; Internet and Networking Systems, AT and T Labs. - Research, Florham Park, NJ 07932, United States",AT and T Labs;MIT,2,USA,1,31,24,"Network operators must have control over the flow of traffic into, out of, and across their networks. However, the Border Gateway Protocol (BGP) does not facilitate common traffic engineering tasks, such as balancing load across multiple links to a neighboring AS or directing traffic to a different neighbor. Solving these problems is difficult because the number of possible changes to routing policies is too large to exhaustively test all possibilities, some changes in routing policy can have an unpredictable effect on the flow of traffic, and the BGP decision process implemented by router vendors limits an operator's control over path selection. We propose fundamental objectives for interdomain traffic engineering and specific guidelines for achieving these objectives within the context of BGP. Using routing and traffic data from the AT&T backbone we show how certain BGP policy changes can move traffic in a predictable fashion, despite limited knowledge about the routing policies in neighboring AS's. Then, we show how operators can gain greater flexibility by relaxing some steps in the BGP decision process and ensuring that neighboring AS's send consistent advertisements at each peering location. Finally, we show that an operator can manipulate traffic efficiently by changing the routes for a small number of prefixes (or groups of related prefixes) that consistently receive a large amount of traffic.",Measurement; Performance,Border Gateway Protocol (BGP); Network operators; Policy changes; Computer networks; Decision making; Measurements; Network protocols; Performance; Process control; Public policy; Telecommunication traffic
"Jamjoom H., Shin K.G.",2,Persistent Dropping: An Efficient Control of Traffic Aggregates,2003,13,"University of Michigan, United States",University of Michigan at Ann Arbor,1,USA,1,36,27,"Flash crowd events (FCEs) present a real threat to the stability of routers and end-servers. Such events are characterized by a large and sustained spike in client arrival rates, usually to the point of service failure. Traditional rate-based drop policies, such as Random Early Drop (RED), become ineffective in such situations since clients tend to be persistent, in the sense that they make multiple retransmission attempts before aborting their connection. As it is built into TCP's congestion control, this persistence is very widespread, making it a major stumbling block to providing responsive aggregate traffic controls. This paper focuses on analyzing and building a coherent model of the effects of client persistence on the controllability of aggregate traffic. Based on this model, we propose a new drop strategy called persistent dropping to regulate the arrival of SYN packets and achieves three important goals: (1) it allows routers and end-servers to quickly converge to their control targets without sacrificing fairness, (2) it minimizes the portion of client delay that is attributed to the applied controls, and (3) it is both easily implementable and computationally tractable. Using a real implementation of this controller in the Linux kernel, we demonstrate its efficacy, up to 60% delay reduction for drop probabilities less than 0.5.",Flash Crowd Events; Modeling; Optimization; Queue Management,Flash crowd events; Queue management; Congestion control (communication); Packet switching; Routers; Servers; Telecommunication traffic; Internet
"Le L., Aikat J., Jeffay K., Smith F.D.",4,The Effects of Active Queue Management on Web Performance,2003,40,"Department of Computer Science, University of North Carolina, Chapel Hill, United States",University of North Carolina,1,USA,1,14,13,"We present an empirical study of the effects of active queue management (AQM) on the distribution of response times experienced by a population of web users. Three prominent AQM schemes are considered: the Proportional Integrator (PI) controller, the Random Exponential Marking (REM) controller, and Adaptive Random Early Detection (ARED). The effects of these AQM schemes were studied alone and in combination with Explicit Congestion Notification (ECN). Our major results are: 1. For offered loads up to 80% of bottleneck link capacity, no AQM scheme provides better response times than simple drop-tail FIFO queue management. 2. For loads of 90% of link capacity or greater when ECN is not used, PI results in a modest improvement over drop-tail and the other AQM schemes. 3. With ECN, both PI and REM provide significant response time improvement at offered loads above 90% of link capacity. Moreover, at a load of 90% PI and REM with ECN provide response times competitive to that achieved on an unloaded network. 4. ARED with recommended parameter settings consistently resulted in the poorest response times which was unimproved by the addition of ECN. We conclude that without ECN there is little end-user performance gain to be realized by employing the AQM designs studied here. However, with ECN, response times can be significantly improved. In addition it appears likely that provider links may be operated at near saturation levels without significant degradation in user-perceived performance.",Active queue management; Congestion control; Web performance,Active queue management; Web performance; Algorithms; Congestion control (communication); Network protocols; Packet switching; Routers; World Wide Web
"Gummadi K., Gummadi R., Gribble S., Ratnasamy S., Shenker S., Stoica I.",6,The Impact of DHT Routing Geometry on Resilience and Proximity,2003,175,"University of Washington, United States; USC, Los Angelas, United States; Intel Research, Berkeley, United States; ICSI, Berkeley, United States; UC Berkeley, United States",Intel;University of California Berkeley;University of Southern California;University of Washington at St. Louis,4,USA,1,30,29,"The various proposed DHT routing algorithms embody several different underlying routing geometries. These geometries include hypercubes, rings, tree-like structures, and butterfly networks. In this paper we focus on how these basic geometric approaches affect the resilience and proximity properties of DHTs. One factor that distinguishes these geometries is the degree of flexibility they provide in the selection of neighbors and routes. Flexibility is an important factor in achieving good static resilience and effective proximity neighbor and route selection. Our basic finding is that, despite our initial preference for more complex geometries, the ring geometry allows the greatest flexibility, and hence achieves the best resilience and proximity performance.",DHT; Flexibility; Routing Geometry,Distributed hash tables (DHT); Flexibility; Proximity performance; Routing geometry; Algorithms; Computational geometry; Computer crime; Computer simulation; Distributed computer systems; Electric network topology; Interfaces (computer); Network protocols; Problem solving; Routers; Computer networks
"Heying Z., Baohong L., Wenhua D.",3,Design of a Robust Active Queue Management Algorithm Based on Feedback Compensation,2003,15,"School of Computer Science, Natl. Univ. of Defense Technology, Changsha 410073, China; Institute of Automation, Natl. Univ. of Defense Technology, Changsha 410073, China",National University of Defense Technology,1,China,1,16,11,"Active Queue Management (AQM) is a very active research area in networking. The main objective of an AQM mechanism is to provide low delay and low loss service in best-effort service networks. In this paper we propose a new AQM algorithm based on the feedback compensation technique in control theory. The algorithm is called Proportional Integral based series compensation, and Position feedback compensation (PIP). By choosing the appropriate feedback compensation element and its parameters, the properties of the corrected system become dependent, to a great extent, on the series and feedback compensatory elements. Thus, PIP can eliminate the error incurred by the inaccuracy in the linear system model as well as eliminate the sensitivity to the changes in system parameters like load level, propagation delay, etc. The performance of PIP is compared to PI using ns simulations. From the experiments and analysis we conclude that PIP is more responsive to and robust under time-varying network conditions than PI.",Active Queue Management; Congestion Control; Feedback Compensation; Queue Length; Robustness,Algorithms; Computer simulation; Congestion control (communication); Network protocols; Packet switching; Active queue management; Feedback compensation; Queue length; Internet
Sobrinho J.L.,1,Network Routing with Path Vector Protocols: Theory and Applications,2003,55,"Inst. de Telecom., Instituto Superior Técnico, Portugal","Instituto Superior Técnico, Portugal",1,Portugal,1,17,16,"Path vector protocols are currently in the limelight, mainly because the inter-domain routing protocol of the Internet, BGP (Border Gateway Protocol), belongs to this class. In this paper, we cast the operation of path vector protocols into a broad algebraic framework and relate the convergence of the protocol, and the characteristics of the paths to which it converges, with the monotonicity and isotonicity properties of its path compositional operation. Here, monotonicity means that the weight of a path cannot decrease when it is extended, and isotonicity means that the relationship between the weights of any two paths with the same origin is preserved when both are extended to the same node. We show that path vector protocols can be made to converge for every network if and only if the algebra is monotone, and that the resulting paths selected by the nodes are optimal if and only if the algebra is isotone as well. Many practical conclusions can be drawn from instances of the generic algebra. For performance-oriented routing, typical in intra-domain routing, we conclude that path vector protocols can be made to converge to widest or widest-shortest paths, but that the composite metric of IGRP (Interior Gateway Protocol), for example, does not guarantee convergence to optimal paths. For policy-based routing, typical in inter-domain routing, we formulate existing guide-lines as instances of the generic algebra and we propose new ones. We also show how a particular instance of the algebra yields a sufficient condition for signaling correctness of internal BGP.",Algebra; BGP; Border Gateway Protocol; Path Vector Protocols,Algebra; Algorithms; Graphic methods; Mathematical models; Network protocols; Problem solving; Robustness (control systems); Signaling; Topology; Vectors; Border gateway protocol (BGP); Path vector protocols; Routing protocol; Internet
"Gupta M., Singh S.",2,Greening of the Internet,2003,482,"Department of Computer Science, Portland State University, Portland, OR 97207, United States",Portland State University,1,USA,1,16,16,"In this paper we examine the somewhat controversial subject of energy consumption of networking devices in the Internet, motivated by data collected by the U.S. Department of Commerce. We discuss the impact on network protocols of saving energy by putting network interfaces and other router & switch components to sleep. Using sample packet traces, we first show that it is indeed reasonable to do this and then we discuss the changes that may need to be made to current Internet protocols to support a more aggressive strategy for sleeping. Since this is a position paper, we do not present results but rather suggest interesting directions for core networking research. The impact of saving energy is huge, particularly in the developing world where energy is a precious resource whose scarcity hinders widespread Internet deployment.",Energy; Internet; Protocols,Multi exit discriminator (MED); Networking devices; Algorithms; Cooling; Costs; Economics; Energy utilization; Interfaces (computer); Network protocols; Problem solving; Telecommunication; Topology; Uninterruptible power systems; Internet
"Basu A., Lin A., Ramanathan S.",3,Routing Using Potentials: A Dynamic Traffic-Aware Routing Algorithm,2003,54,"Bell Laboratories, United States; MIT, United States",Bell Labs;MIT,2,USA,1,30,19,"We present a routing paradigm called PB-routing that utilizes steepest gradient search methods to route data packets. More specifically, the PB-routing paradigm assigns scalar potentials to network elements and forwards packets in the direction of maximum positive force. We show that the family of PB-routing schemes are loop free and that the standard shortest path routing algorithms are a special case of the PB-routing paradigm. We then show how to design a potential function that accounts for traffic conditions at a node. The resulting routing algorithm routes around congested areas while preserving the key desirable properties of IP routing mechanisms including hop-by-hop routing, local route computations and statistical multiplexing. Our simulations using the ns simulator indicate that the traffic aware routing algorithm shows significant improvements in end-to-end delay and jitter when compared to standard shortest path routing algorithms. The simulations also indicate that our algorithm does not incur too much control overheads and is fairly stable even when traffic conditions are dynamic.",Congestion; Potential; Routing; Steepest Gradient; Traffic Aware,Potential; Routings; Steepest gradient; Traffic aware; Algorithms; Bandwidth; Computational methods; Computer simulation; Costs; Network protocols; Optimization; Packet networks; Problem solving; Theorem proving; Internet
"Griffin T.G., Jaggard A.D., Ramachandran V.",3,Design Principles of Policy Languages for Path Vector Protocols,2003,31,"AT and T Labs - Research, Florham Park, NJ, United States; Dept. of Mathematics, Tulane University, New Orleans, LA, United States; Dept. of Computer Science, Yale University, New Haven, CT, United States",AT and T Labs;Tulane University;Yale University,3,USA,1,26,26,"BGP is unique among IP-routing protocols in that routing is determined using semantically rich routing policies. However, this expressiveness has come with hidden risks. The interaction of locally defined routing policies can lead to unexpected global routing anomalies, which can be very difficult to identify and correct in the decentralized and competitive Internet environment. These risks increase as the complexity of local policies increase, which is precisely the current trend. BGP policy languages have evolved in a rather organic fashion with little effort to avoid policy-interaction problems. We believe that researchers should start to consider how to design policy languages for path-vector protocols that avoid such risks and yet retain other desirable features. We take a few steps in this direction by identifying the important dimensions of this design space and characterizing some of the inherent design trade-offs. We attempt to do this in a general way that is not constrained by the details of BGP.",Border Gateway Protocol (BGP); Interdomain routing; Path-vector protocols; Routing-policy languages; Stable Paths Problem (SPP),Computer programming languages; Internet; Problem solving; Public policy; Robustness (control systems); Semantics; Telecommunication; Theorem proving; Vectors; Border gateway protocol (BGP); Interdomain routings; Path vector protocols; Routing policy languages; Stable path problems (SPP); Network protocols
"Narayan H., Govindan R., Varghese G.",3,The Impact of Address Allocation and Routing on the Structure and Implementation of Routing Tables,2003,6,"University of California, San Diego, United States; University of Southern California, United States",University of California San Diego;University of Southern California,2,USA,1,46,22,"The recent growth in the size of the routing table has led to an interest in quantitatively understanding both the causes (e.g., multihoming) as well as the effects (e.g., impact on router lookup implementations) of such routing table growth. In this paper, we describe a new model called ARAM that defines the structure of routing tables of any given size. Unlike simpler empirical models that work backwards from effects (e.g., current prefix length distributions), ARAM approximately models the causes of table growth (allocation by registries, assignment by ISPs, multihoming and load balancing). We show that ARAM models with high fidelity three abstract measures (prefix distribution, prefix depth, and number of nodes in the tree) of the shape of the prefix tree - as validated against 20 snapshots of backbone routing tables from 1997 to the present. We then use ARAM for evaluating the scalability of IP lookup schemes, and studying the effects of multihoming and load balancing on their scaling behavior. Our results indicate that algorithmic solutions based on multibit tries will provide more prefixes per chip than TCAMs (as table sizes scale toward a million) unless TCAMs can be engineered to use 8 transistors per cell. By contrast, many of today's SRAM-based TCAMs use 14-16 transistors per cell.",IP lookups; Modeling; Routing tables,Internet protocol (IP) lookups; Routing tables; Associative storage; Network protocols; Packet switching; Random access storage; Telecommunication traffic; Internet
"Ji P., Ge Z., Kurose J., Towsley D.",4,A Comparison of Hard-state and Soft-state Signaling Protocols,2003,24,"Computer Science Department, University of Massachusetts, Amherst, United States",University of Massachusetts Amherst,1,USA,1,20,14,"One of the key infrastructure components in all telecommunication networks, ranging from the telephone network, to VC-oriented data networks, to the Internet, is its signaling system. Two broad approaches towards signaling can be identified: so-called hard-state and soft-state approaches. Despite the fundamental importance of signaling, our understanding of these approaches - their pros and cons and the circumstances in which they might best be employed - is mostly anecdotal (and occasionally religious). In this paper, we compare and contrast a variety of signaling approaches ranging from a ""pure"" soft state, to soft-state approaches augmented with explicit state removal and/or reliable signaling, to a ""pure"" hard state approach. We develop an analytic model that allows us to quantify state inconsistency in single- and multiple-hop signaling scenarios, and the ""cost"" (both in terms of signaling overhead, and application-specific costs resulting from state inconsistency) associated with a given signaling approach and its parameters (e.g., state refresh and removal timers). Among the class of soft-state approaches, we find that a soft-state approach coupled with explicit removal substantially improves the degree of state consistency while introducing little additional signaling message overhead. The addition of reliable explicit setup/update/removal allows the soft-state approach to achieve comparable (and sometimes better) consistency than that of the hard-state approach.",Hard-state; Signaling; Soft-state,Signaling protocols; Signaling systems; Information analysis; Mathematical models; Network protocols; Signal systems; Telecommunication services; Telecommunication networks
"Chawathe Y., Ratnasamy S., Breslau L., Lanham N., Shenker S.",5,Making Gnutella-like P2P Systems Scalable,2003,401,"AT and T Labs. - Research, United States; Intel Research; UC Berkeley, United States; ICSI, United States",AT and T Labs;Intel;University of California Berkeley,3,USA,1,27,27,"Napster pioneered the idea of peer-to-peer file sharing, and supported it with a centralized file search facility. Subsequent P2P systems like Gnutella adopted decentralized search algorithms. However, Gnutella's notoriously poor scaling led some to propose distributed hash table solutions to the wide-area file search problem. Contrary to that trend, we advocate retaining Gnutella's simplicity while proposing new mechanisms that greatly improve its scalability. Building upon prior research [1, 12, 22], we propose several modifications to Gnutella's design that dynamically adapt the overlay topology and the search algorithms in order to accommodate the natural heterogeneity present in most peer-to-peer systems. We test our design through simulations and the results show three to five orders of magnitude improvement in total system capacity. We also report on a prototype implementation and its deployment on a testbed.",Distributed hash tables; Gnutella; Peer-to-peer,Distributed hash tables (DHT); Gnutella; Peer-to-peer file sharing; Algorithms; Bandwidth; Computer simulation; Computer system recovery; Data transfer; Distributed computer systems; Electric network topology; File organization; Network protocols; Problem solving; Servers; Computer networks
"Coulson G., Blair G., Hutchison D., Joolia A., Lee K., Ueyama J., Gomes A., Ye Y.",8,NETKIT: A software component-based approach to programmable networking,2003,13,"Computing Dept., Lancaster University, Lancaster LA1 4YR, United Kingdom",Lancaster University,1,UK,1,48,41,"While there has already been significant research in support of openness and programmability in networks, this paper argues that there remains a need for generic support for the integrated development, deployment and management of programmable networking software. We further argue that this support should explicitly address the management of run-time reconfiguration of systems, and should be independent of any particular programming paradigm (e.g. active networking or open signaling), programming language, or hardware/ operating system platform. In line with these aims, we outline an approach to the structuring of programmable networking software in terms of a ubiquitously applied software component model that can accommodate all levels of a programmable networking system from low-level system support, to in-band packet handling, to active networking execution environments to signaling and coordination.",Components; Middleware; Programmable networking; Reflection,Components; Computer hardware; Computer networks; Middleware; Packet networks; Reflection; Programmable networking; Run-time reconfiguration; Software components; Computer software
"Keslassy I., Chuang S.-T., Yu K., Miller D., Horowitz M., Solgaard O., McKeown N.",7,Scaling Internet Routers Using Optics,2003,98,"Stanford University, United States",Stanford University,1,USA,1,33,28,"Routers built around a single-stage crossbar and a centralized scheduler do not scale, and (in practice) do not provide the throughput guarantees that network operators need to make efficient use of their expensive long-haul links. In this paper we consider how optics can be used to scale capacity and reduce power in a router. We start with the promising load-balanced switch architecture proposed by C-S. Chang. This approach eliminates the scheduler, is scalable, and guarantees 100% throughput for a broad class of traffic. But several problems need to be solved to make this architecture practical: (1) Packets can be mis-sequenced, (2) Pathological periodic traffic patterns can make throughput arbitrarily small, (3) The architecture requires a rapidly configuring switch fabric, and (4) It does not work when linecards are missing or have failed. In this paper we solve each problem in turn, and describe new architectures that include our solutions. We motivate our work by designing a 100Tb/s packet-switched router arranged as 640 linecards, each operating at 160Gb/s. We describe two different implementations based on technology available within the next three years.",Internet router; Load-balancing; Packet-switch,Electrooptic routers; Load balancing; Crossbar equipment; Electrooptical effects; Optical links; Optical switches; Packet switching; Routers; Internet
"Zhang Y., Roughan M., Lund C., Donoho D.",4,An Information-Theoretic Approach to Traffic Matrix Estimation,2003,89,"AT and T Labs - Research, United States; Stanford University, United States",AT and T Labs;Stanford University,2,USA,1,28,18,"Traffic matrices are required inputs for many IP network management tasks: for instance, capacity planning, traffic engineering and network reliability analysis. However, it is difficult to measure these matrices directly, and so there has been recent interest in inferring traffic matrices from link measurements and other more easily measured data. Typically, this inference problem is ill-posed, as it involves significantly more unknowns than data. Experience in many scientific and engineering fields has shown that it is essential to approach such ill-posed problems via ""regularization"". This paper presents a new approach to traffic matrix estimation using a regularization based on ""entropy penalization"". Our solution chooses the traffic matrix consistent with the measured data that is information-theoretically closest to a model in which source/destination pairs are stochastically independent. We use fast algorithms based on modern convex optimization theory to solve for our traffic matrices. We evaluate the algorithm with real backbone traffic and routing data, and demonstrate that it is fast, accurate, robust, and flexible.",Information Theory; Minimum Mutual Information; Regularization; SNMP; Traffic Engineering; Traffic Matrix Estimation,Minimum mutual information; Regularization; SNMP; Traffic engineering; Traffic matrix estimation; Algorithms; Channel capacity; Congestion control (communication); Information theory; Network protocols; Packet switching; Telecommunication traffic; Internet
"Gorinsky S., Jain S., Vin H., Zhang Y.",4,Robustness to Inflated Subscription in Multicast Congestion Control,2003,4,"Lab. for Advanced Systems Research, Department of Computer Sciences, University of Texas, Austin, United States; HRL Laboratories, LLC, Malibu, CA, United States",HRL Laboratories;University of Texas at Austin,2,Mali;USA,2,29,27,"Group subscription is a useful mechanism for multicast congestion control: RLM, RLC, FLID-DL, and WEBRC form a promising line of multi-group protocols where receivers provide no feedback to the sender but control congestion via group membership regulation. Unfortunately, the group subscription mechanism also offers receivers an opportunity to elicit self-beneficial bandwidth allocations. In particular, a misbehaving receiver can ignore guidelines for group subscription and choose an unfairly high subscription level in a multi-group multicast session. This poses a serious threat to fairness of bandwidth allocation. In this paper, we present the first solution for the problem of inflated subscription. Our design guards access to multicast groups with dynamic keys and consists of two independent components: DELTA (Distribution of Eligibility To Access) - a novel method for in-band distribution of group keys to receivers that are eligible to access the groups according to the congestion control protocol, and SIGMA (Secure Internet Group Management Architecture) - a generic architecture for key-based group access at edge routers.",Congestion Control; Fair Bandwidth Allocation; Misbehaving Receivers; Multicast; Robustness,Congestion control; Fair bandwidth allocation; Misbehaving receiver; Multicast; Robustness; Bandwidth; Computer aided design; Internet; Mathematical models; Network protocols; Problem solving; Security of data; Robustness (control systems)
"Tang C., Xu Z., Dwarkadas S.",3,Peer-to-Peer Information Retrieval Using Self-Organizing Semantic Overlay Networks,2003,212,"Dept. of Computer Science, Univ. of Rochester, Rochester, NY 14627-0226, United States; HP Laboratories, 1501 Page Mill Rd., Palo Alto, CA 94304-1126, United States",HP Labs;University of Rochester,2,USA,1,28,22,"Content-based full-text search is a challenging problem in Peer-to-Peer (P2P) systems. Traditional approaches have either been centralized or use flooding to ensure accuracy of the results returned. In this paper, we present pSearch, a decentralized non-flooding P2P information retrieval system. pSearch distributes document indices through the P2P network based on document semantics generated by Latent Semantic Indexing (LSI). The search cost (in terms of different nodes searched and data transmitted) for a given query is thereby reduced, since the indices of semantically related documents are likely to be co-located in the network. We also describe techniques that help distribute the indices more evenly across the nodes, and further reduce the number of nodes accessed using appropriate index distribution as well as using index samples and recently processed queries to guide the search. Experiments show that pSearch can achieve performance comparable to centralized information retrieval systems by searching only a small number of nodes. For a system with 128,000 nodes and 528,543 documents (from news, magazines, etc.), pSearch searches only 19 nodes and transmits only 95.5KB data during the search, whereas the top 15 documents returned by pSearch and LSI have a 91.7% intersection.",Information Retrieval; Overlay Network; Peer-to-Peer System,Overlay networks; Peer-to-peer system; HTML; Indexing (of information); Information retrieval; Search engines; Semantics; Internet
"Loguinov D., Kumar A., Rai V., Ganesh S.",4,Graph-Theoretic Analysis of Structured Peer-to-Peer Systems: Routing Distances and Fault Resilience,2003,109,"Department of Computer Science, Texas A and M University, College Station, TX 77843, United States",Texas A and M University,1,USA,1,44,37,"This paper examines graph-theoretic properties of existing peer-to-peer architectures and proposes a new infrastructure based on optimal-diameter de Bruijn graphs. Since generalized de Bruijn graphs possess very short average routing distances and high resilience to node failure, they are well suited for structured peer-to-peer networks. Using the example of Chord, CAN, and de Bruijn, we first study routing performance, graph expansion, and clustering properties of each graph. We then examine bisection width, path overlap, and several other properties that affect routing and resilience of peer-to-peer networks. Having confirmed that de Bruijn graphs offer the best diameter and highest connectivity among the existing peer-to-peer structures, we offer a very simple incremental building process that preserves optimal properties of de Bruijn graphs under uniform user joins/departures. We call the combined peer-to-peer architecture ODRI - Optimal Diameter Routing Infrastructure.",de Bruijn; DHT; Graph Theory; Modeling; Peer-to-peer,Content-addressable network (CAN); De Bruijn; Distributed hash tables (DHT); Modeling; Optimal-diameter graphs; Peer-to-peer structures; Asymptotic stability; Computer architecture; Computer system recovery; Distributed computer systems; Graph theory; Hamiltonians; Heuristic methods; Internet; Probability distributions; Problem solving; Routers; Fault tolerant computer systems
"Estan C., Savage S., Varghese G.",3,Automatically Inferring Patterns of Resource Consumption in Network Traffic,2003,91,"Comp. Sci./Engineering Department, University of California, San Diego, United States",University of California San Diego,1,USA,1,15,11,"The Internet service model emphasizes flexibility - any node can send any type of traffic at any time. While this design has allowed new applications and usage models to flourish, it also makes the job of network management significantly more challenging. This paper describes a new method of traffic characterization that automatically groups traffic into minimal clusters of conspicuous consumption. Rather than providing a static analysis specialized to capture flows, applications, or network-to-network traffic matrices, our approach dynamically produces hybrid traffic definitions that match the underlying usage. For example, rather than report five hundred small flows, or the amount of TCP traffic to port 80, or the ""top ten hosts"", our method might reveal that a certain percent of traffic was used by TCP connections between AOL clients and a particular group of Web servers. Similarly, our technique can be used to automatically classify new traffic patterns, such as network worms or peer-to-peer applications, without knowing the structure of such traffic a priori. We describe a series of algorithms for constructing these traffic clusters and minimizing their representation. In addition, we describe the design of our prototype system, AutoFocus and our experiences using it to discover the dominant and unusual modes of usage on several different production networks.",Data mining; Network monitoring; Traffic measurement,Network monitoring; Traffic measurement; Algorithms; Data mining; Network protocols; Telecommunication traffic; Internet
"Singh S., Baboescu F., Varghese G., Wang J.",4,Packet Classification Using Multidimensional Cutting,2003,233,"UC San Diego, 9500 Gilman Drive, San Diego, CA 92093-0114, United States; AT and T Labs-Research, Florham Park, NJ 07932-0971, United States",AT and T Labs;University of California San Diego,2,USA,1,15,14,"This paper introduces a classification algorithm called HyperCuts. Like the previously best known algorithm, HiCuts, HyperCuts is based on a decision tree structure. Unlike HiCuts, however, in which each node in the decision tree represents a hyperplane, each node in the HyperCuts decision tree represents a k-dimensional hypercube. Using this extra degree of freedom and a new set of heuristics to find optimal hypercubes for a given amount of storage, HyperCuts can provide an order of magnitude improvement over existing classification algorithms. HyperCuts uses 2 to 10 times less memory than HiCuts optimized for memory, while the worst case search time of HyperCuts is 50 - 500% better than that of HiCuts optimized for speed. Compared with another recent scheme, EGT-PC, HyperCuts uses 1.8 - 7 times less memory space while the worst case search time is up to 5 times smaller. More importantly, unlike EGT-PC, HyperCuts can be fully pipelined to provide one classification result every packet arrival time, and also allows fast updates.",Firewalls; Packet Classification; QoS,Packet classification; Virtual private networks (VPN); Algorithms; Computer system firewalls; Information retrieval; Network protocols; Packet switching; Quality of service; Internet
"Chuah C.-N., Subramanian L., Katz R.H.",3,DCAP: Detecting misbehaving flows via collaborative aggregate policing,2003,2,"ECE Department, University of California, Davis, CA 95616, United States; EECS Department, University of California, Berkeley, CA 94720, United States",University of California Berkeley;University of California Davis,2,USA,1,37,24,"This paper proposes a detection mechanism called DCAP for a network provider to monitor incoming traffic and identify misbehaving flows without having to keep per-flow accounting at any of its routers. Misbehaving flows refer to flows that exceed their stipulated bandwidth limit. Through collaborative aggregate policing at both ingress and egress nodes, DCAP is able to quickly narrow the search to a candidate group that contains the misbehaving flows, and eventually identify the individual culprits. In comparison to per-flow policing, the amount of state maintained at an edge router is reduced from O(n) to O(√n), where n is the number of admitted flows. Simulation results show that DCAP can successfully detect a majority (64-83%) of the misbehaving flows with almost zero false alarms. Packet losses suffered by innocent flows due to undetected misbehaving activity are insignificant (0.02-0.9%). We also successfully build a prototype that demonstrates how DCAP can be deployed with minimal processing overhead in a soft-QoS architecture.",Flow-level accounting; Misbehaving flow detection; Traffic policing,Computational complexity; Computer simulation; Detectors; Monitoring; Network protocols; Quality of service; Telecommunication traffic; Flow-level accounting; Misbehaving flow detection; Traffic policing; Computer networks
"Qiu L., Yang Y.R., Zhang Y., Shenker S.",4,On Selfish Routing in Internet-Like Environments,2003,69,"Microsoft Research; Yale University, United States; AT and T Labs - Research, United States; ICSI",AT and T Labs;Microsoft;Yale University,3,USA,1,44,37,"A recent trend in routing research is to avoid inefficiencies in network-level routing by allowing hosts to either choose routes themselves (e.g., source routing) or use overlay routing networks (e.g., Detour or RON). Such approaches result in selfish routing, because routing decisions are no longer based on system-wide criteria but are instead designed to optimize host-based or overlay-based metrics. A series of theoretical results showing that selfish routing can result in suboptimal system behavior have cast doubts on this approach. In this paper, we use a game-theoretic approach to investigate the performance of selfish routing in Internet-like environments. We focus on intra-domain network environments and use realistic topologies and traffic demands in our simulations. We show that in contrast to theoretical worst cases, selfish routing achieves close to optimal average latency in such environments. However, such performance benefit comes at the expense of significantly increased congestion on certain links. Moreover, the adaptive nature of selfish overlays can significantly reduce the effectiveness of traffic engineering by making network traffic less predictable.",Game Theory; Optimization; Overlay; Relaxation; Selfish Routing; Traffic Engineering; Traffic Equilibrium,Overlay; Selfish routing; Traffic engineering; Traffic equilibrium; Computer simulation; Game theory; Network protocols; Packet switching; Telecommunication traffic; Internet
"Ramabhadran S., Pasquale J.",2,Stratified Round Robin: A Low Complexity Packet Scheduler with Bandwidth Fairness and Bounded Delay,2003,57,"Dept. of Comp. Sci. and Engineering, University of California, San Diego, 9500 Gilman Drive, San Diego, CA 92093-0114, United States",University of California San Diego,1,USA,1,35,25,"Fair queuing is a well-studied problem in modern computer networks. However, there remains a gap between scheduling algorithms that have provably good performance, and those that are feasible and practical to implement in high-speed routers. In this paper, we propose a novel packet scheduler called Stratified Round Robin, which has low complexity, and is amenable to a simple hardware implementation. Stratified Robin Robin exhibits good fairness and delay properties that are demonstrated through both analytical results and simulations. In particular, it provides a single packet delay bound that is independent of the number of flows. This property is unique to Stratified Round Robin among all other schedulers of comparable complexity.",Fair queuing; Output scheduling; Quality of service,Algorithms; Bandwidth; Packet switching; Quality of service; Fair queuing; Output scheduling; Internet
"Nakao A., Peterson L., Bavier A.",3,A Routing Underlay for Overlay Networks,2003,61,"Department of Computer Science, Princeton University, United States",Princeton University,1,USA,1,34,25,"We argue that designing overlay services to independently probe the Internet-with the goal of making informed application-specific routing decisions-is an untenable strategy. Instead, we propose a shared routing underlay that overlay services query. We posit that this underlay must adhere to two high-level principles. First, it must take cost (in terms of network probes) into account. Second, it must be layered so that specialized routing services can be built from a set of basic primitives. These principles lead to an underlay design where lower layers expose large-scale, coarse-grained static information already collected by the network, and upper layers perform more frequent probes over a narrow set of nodes. This paper proposes a set of primitive operations and three library routing services that can be built on top of them, and describes how such libraries could be useful to overlay services.",Infrastructure; Overlay Networks; Routing,Infrastructures; Overlay networks; Routing; Algorithms; Autonomous agents; Bandwidth; Costs; Decision making; Embedded systems; Graphic methods; Problem solving; Product design; Topology; Internet
"Scott J., Mapp G.",2,Link layer-based TCP optimisation for disconnecting networks,2003,10,"Intel Research Cambridge, 15 JJ Thomson Avenue, Cambridge CB3 OFD, United Kingdom; Middlesex University, Bounds Green Road, London N11 2NQ, United Kingdom",Intel;Middlesex University,2,UK,1,23,19,"This paper discusses a link layer approach to improving TCP performance in the face of periodic network disconnections. Network disconnections are encountered in many scenarios, including being out-of-range in a wireless network, during network handoff, and also in the case of Networked Surfaces, a novel LAN technology which provides the motivation for this work. A ""smart link layer"" employing repetition of selected packets at reconnection time is shown to improve TCP's utilisation of a disconnecting network to nearly 100%. This solution is also demonstrated in the context of a Networked Surface prototype, improving TCP performance for both bulk transfers and interactive traffic. The smart link layer solution is lightweight, requiring little processing and buffering only one packet per TCP connection. It is therefore easily retro-fitted to existing TCP-capable devices, without modifying the internal operation of those devices.",Disconnection; Link Layer; Mobile Networking; TCP,Disconnection; Link Layer; Mobile Networking; TCP; Local area networks; Mobile computing; Motivation; Packet networks; Performance; Wireless telecommunication systems; Network protocols
"Mao Z.M., Rexford J., Wang J., Katz R.H.",4,Towards an Accurate AS-Level Traceroute Tool,2003,79,"UC, Berkeley, United States; AT and T Labs-Research, United States",AT and T Labs,1,USA,1,28,18,"Traceroute is widely used to detect routing problems, characterize end-to-end paths, and discover the Internet topology. Providing an accurate list of the Autonomous Systems (ASes) along the forwarding path would make traceroute even more valuable to researchers and network operators. However, conventional approaches to mapping traceroute hops to AS numbers are not accurate enough. Address registries are often incomplete and out-of-date. BGP routing tables provide a better IP-to-AS mapping, though this approach has significant limitations as well. Based on our extensive measurements, about 10% of the traceroute paths have one or more hops that do not map to a unique AS number, and around 15% of the traceroute AS paths have an AS loop. In addition, some traceroute AS paths have extra or missing AS hops due to Internet exchange Points, sibling ASes managed by the same institution, and ASes that do not advertise routes to their infrastructure. Using the BGP tables as a starting point, we propose techniques for improving the IP-to-AS mapping as an important step toward an AS-level traceroute tool. Our algorithms draw on analysis of traceroute probes, reverse DNS lookups, BGP routing tables, and BGP update messages collected from multiple locations. We also discuss how the improved IP-to-AS mapping allows us to home in on cases where the BGP and traceroute AS paths differ for legitimate reasons.",AS-level path; Border Gateway Protocol; Internet topology; Network measurements,AS-level path; Autonomous systems (AS); Border gateway protocol (BGP); Internet topology; Network measurements; Routing anomalies; Traceroute tools; Algorithms; Computer system recovery; Data transfer; Electric network topology; Heuristic methods; Interfaces (computer); Internet; Network protocols; Packet switching; Problem solving; Real time systems; Routers; World Wide Web; Autonomous agents
Armitage G.J.,1,"Revisiting IP QoS: Why do we care, what have we learned? ACM SIGCOMM 2003 RIPQOS workshop report",2003,11,"Swinburne University of Technology, Melbourne, Australia",Swinburne University of Technology,1,Australia,1,9,9,"ACM SIGCOMM 2003 included a number of workshops, including the all-day workshop ""Revisiting IP QoS: Why do we care, what have we learned? (RIPQOS)."" The goal of RIPQOS was to critique the evolution and deployment of IP quality of service (QoS) mechanisms, from both the research and operational community perspectives. The workshop's name was a challenge to all interested communities to reflect on whether IP QoS has lived up to the hype or whether it is simply misunderstood. The workshop saw 6 papers, 2 short papers, a discussion panel, a range of opinions and lots of questions. This report attempts to capture the essence of our workshop's discussions, presentations and experiences.",IP; RIPQOS; Sigcomm; Workshop,Communication systems; Computer networks; Internet; Network protocols; Technical presentations; IP; RIPQOS; Sigcomm; Workshop; Quality of service
"Clark D.D., Partridge C., Christopher Ramming J., Wroclawski J.T.",4,A Knowledge Plane for the Internet,2003,198,"M.I.T. Lab for Computer Science, 200 Technology Square, Cambridge, MA 02139, United States; BBN Technologies, 10 Moulton St, Cambridge, MA 02138, United States; SRI International, 333 Ravenswood Avenue, Menlo Park, CA 94205, United States",BBN Technologies,1,USA,1,24,15,"We propose a new objective for network research: to build a fundamentally different sort of network that can assemble itself given high level instructions, reassemble itself as requirements change, automatically discover when something goes wrong, and automatically fix a detected problem or explain why it cannot do so. We further argue that to achieve this goal, it is not sufficient to improve incrementally on the techniques and algorithms we know today. Instead, we propose a new construct, the Knowledge Plane, a pervasive system within the network that builds and maintains high-level models of what the network is supposed to do, in order to provide services and advice to other elements of the network. The knowledge plane is novel in its reliance on the tools of AI and cognitive systems. We argue that cognitive techniques, rather than traditional algorithmic approaches, are best suited to meeting the uncertainties and complexity of our objective.",Cognition; Knowledge plane; Network applications; Network configuration,Cognition; Knowledge plane; Network application; Network configuration; Abstracting; Algorithms; Cognitive systems; Computational complexity; Decentralized control; Interoperability; Knowledge acquisition; Network protocols; Internet
"Elliott C., Pearson D., Troxel G.",3,Quantum Cryptography in Practice,2003,48,"BBN Technologies, 10 Moulton Street, Cambridge, MA 02138, United States",BBN Technologies,1,USA,1,21,14,"BBN, Harvard, and Boston University are building the DARPA Quantum Network, the world's first network that delivers end-to-end network security via high-speed Quantum Key Distribution, and testing that Network against sophisticated eavesdropping attacks. The first network link has been up and steadily operational in our laboratory since December 2002. It provides a Virtual Private Network between private enclaves, with user traffic protected by a weak-coherent implementation of quantum cryptography. This prototype is suitable for deployment in metro-size areas via standard telecom (dark) fiber. In this paper, we introduce quantum cryptography, discuss its relation to modern secure networks, and describe its unusual physical layer, its specialized quantum cryptographic protocol suite (quite interesting in its own right), and our extensions to IPsec to integrate it with quantum cryptography.",Cryptographic protocols; Error correction; IPsec; Key agreement protocols; Privacy amplification; Quantum cryptography; Quantum key distribution; Secure networks,Cryptographic protocols; IPsec; Key agreement protocols; Privacy amplification; Quantum key distribution; Secure networks; Algorithms; Data privacy; Network protocols; Public key cryptography; Security of data; Quantum cryptography
"Carzaniga A., Wolf A.L.",2,Forwarding in a Content-Based Network,2003,149,"Department of Computer Science, University of Colorado, Boulder, CO 80309-0430, United States",University of Colorado at Boulder,1,USA,1,21,19,"This paper presents an algorithm for content-based forwarding, an essential function in content-based networking. Unlike in traditional address-based unicast or multicast networks, where messages are given explicit destination addresses, the movement of messages through a content-based network is driven by predicates applied to the content of the messages. Forwarding in such a network amounts to evaluating the predicates stored in a router's forwarding table in order to decide to which neighbor routers the message should be sent. We are interested in finding a forwarding algorithm that can make this decision as quickly as possible in situations where there are numerous, complex predicates and high volumes of messages. We present such an algorithm and give the results of studies evaluating its performance.",Content-based network; Forwarding; Matching; Overlay; Publish/subscribe,Algorithms; Network protocols; Packet switching; Routers; Content based networks; Forwarding table; Overlay networks; Internet
"Kuzmanovic A., Knightly E.W.",2,Low-Rate TCP-Targeted Denial of Service Attacks,2003,191,"ECE Department, Rice University, Houston, TX 77005, United States",Rice University,1,USA,1,31,27,"Denial of Service attacks are presenting an increasing threat to the global inter-networking infrastructure. While TCP's congestion control algorithm is highly robust to diverse network conditions, its implicit assumption of end-system cooperation results in a well-known vulnerability to attack by high-rate non-responsive flows. In this paper, we investigate a class of low-rate denial of service attacks which, unlike high-rate attacks, are difficult for routers and counter-DoS mechanisms to detect. Using a combination of analytical modeling, simulations, and Internet experiments, we show that maliciously chosen low-rate DoS traffic patterns that exploit TCP's retransmission time-out mechanism can throttle TCP flows to a small fraction of their ideal rate while eluding detection. Moreover, as such attacks exploit protocol homogeneity, we study fundamental limits of the ability of a class of randomized time-out mechanisms to thwart such low-rate DoS attacks.",Denial of Service; Retransmission timeout; TCP,Algorithms; Bandwidth; Congestion control (communication); Data reduction; Mathematical models; Network protocols; Robustness (control systems); Telecommunication; Denial of service (DoS); Retransmission timeout; TCP; Internet
"Akella A., Maggs B., Seshan S., Shaikh A., Sitaraman R.",5,A Measurement-Based Analysis of Multihoming,2003,67,"Carnegie Mellon University, United States; IBM T.J. Watson Research Center, United States; Univ. of Massachusetts, United States; Akamai Technologies, United States",Akamai Technologies;Carnegie Mellon University;IBM;University of Massachusetts Amherst,4,USA,1,17,16,"Multihoming has traditionally been employed by stub networks to enhance the reliability of their network connectivity. With the advent of commercial ""intelligent route control"" products, stubs now leverage multihoming to improve performance. Although multihoming is widely used for reliability and, increasingly for performance, not much is known about the tangible benefits that multihoming can offer, or how these benefits can be fully exploited. In this paper, we aim to quantify the extent to which multihomed networks can leverage performance and reliability benefits from connections to multiple providers. We use data collected from servers belonging to the Akamai content distribution network to evaluate performance benefits from two distinct perspectives of multihoming: high-volume content-providers which transmit large volumes of data to many distributed clients, and enterprises which primarily receive data from the network. In both cases, we find that multihoming can improve performance significantly and that not choosing the right set of providers could result in a performance penalty as high as 40%. We also find evidence of diminishing returns in performance when more than four providers are considered for multihoming. In addition, using a large collection of measurements, we provide an analysis of the reliability benefits of multihoming. Finally, we provide guidelines on how multihomed networks can choose ISPs, and discuss practical strategies of using multiple upstream connections to achieve optimal performance benefits.",Measurement; Performance,Akamai Technologies (CO); Handshake round-trip time (HRRT); Internet service provider (ISP); Multihoming; Network address translation (NAT); Performance benefit analysis; Stub networks; Cost effectiveness; Data acquisition; Data transfer; Fault tolerant computer systems; Intelligent control; Quality of service; Servers; World Wide Web; Computer networks
"Applegate D., Cohen E.",2,Making Infra-Domain Routing Robust to Changing and Uncertain Traffic Demands: Understanding Fundamental Tradeoffs,2003,103,"AT and T Labs-Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,21,19,"Intra-domain traffic engineering can significantly enhance the performance of large IP backbone networks. Two important components of traffic engineering are understanding the traffic demands and configuring the routing protocols. These two components are inter-linked, as it is widely believed that an accurate view of traffic is important for optimizing the configuration of routing protocols and through that, the utilization of the network. This basic premise, however, never seems to have been quantified - How important is accurate knowledge of traffic demands for obtaining good utilization of the network? Since traffic demand values are dynamic and illusive, is it possible to obtain a routing that is ""robust"" to variations in demands? Armed with enhanced recent algorithmic tools we explore these questions on a diverse collection of ISP net-works. We arrive at a surprising conclusion: it is possible to obtain a robust routing that guarantees a nearly optimal utilization with a fairly limited knowledge of the applicable traffic demands.",Demand-oblivious routing; Routing; TM estimation,Algorithms; Network protocols; Packet switching; Telecommunication traffic; Demand oblivious routing; Routing protocols; Traffic matrice (TM) estimation; Internet
"Duffield N., Lund C., Thorup M.",3,Estimating Flow Distributions from Sampled Flow Statistics,2003,81,"AT and T Labs - Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,24,12,"Passive traffic measurement increasingly employs sampling at the packet level. Many high-end routers form flow statistics from a sampled substream of packets. Sampling is necessary in order to control the consumption of resources by the measurement operations. However, knowledge of the statistics of flows in the unsampled stream remains useful, for understanding both characteristics of source traffic, and consumption of resources in the network. This paper provide methods that use flow statistics formed from sampled packet stream to infer the absolute frequencies of lengths of flows in the unsampled stream. A key part of our work is inferring the numbers and lengths of flows of original traffic that evaded sampling altogether. We achieve this through statistical inference, and by exploiting protocol level detail reported in flow records. The method has applications to detection and characterization of network attacks: we show how to estimate, from sampled flow statistics, the number of compromised hosts that are sending attack traffic past the measurement point. We also investigate the impact on our results of different implementations of packet sampling.",IP Flows; Maximum Likelihood Estimation; Packet Sampling,Algorithms; Maximum likelihood estimation; Network protocols; Packet switching; Telecommunication traffic; Internet protocol (IP) flows; Packet sampling; Internet
"Hussain A., Heidemann J., Papadopoulos C.",3,A Framework for Classifying Denial of Service Attacks,2003,183,"USC, Information Sciences Institute, United States",University of Southern California,1,USA,1,39,29,"Launching a denial of service (DoS) attack is trivial, but detection and response is a painfully slow and often a manual process. Automatic classification of attacks as single-or multi-source can help focus a response, but current packet-header-based approaches are susceptible to spoofing. This paper introduces a framework for classifying DoS attacks based on header content, transient ramp-up behavior and novel techniques such as spectral analysis. Although headers are easily forged, we show that characteristics of attack ramp-up and attack spectrum are more difficult to spoof. To evaluate our framework we monitored access links of a regional ISP detecting 80 live attacks. Header analysis identified the number of attackers in 67 attacks, while the remaining 13 attacks were classified based on ramp-up and spectral analysis. We validate our results through monitoring at a second site, controlled experiments, and simulation. We use experiments and simulation to understand the underlying reasons for the characteristics observed. In addition to helping understand attack dynamics, classification mechanisms such as ours are important for the development of realistic models of DoS traffic, can be packaged as an automated tool to aid in rapid response to attacks, and can also be used to estimate the level of DoS activity on the Internet.",Denial of Service Attacks; Measurement; Security; Time Series Analysis,Denial of service (DoS) attacks; Security measurement; Data privacy; Internet; Telecommunication traffic; Time series analysis; Security of data
"Dharmapurikar S., Krishnamurthy P., Taylor D.E.",3,Longest Prefix Matching Using Bloom Filters,2003,110,"Washington University in Saint Louis, 1 Brookings Drive, Saint Louis, MO 63130-4899, United States",University of Washington at St. Louis,1,USA,1,21,17,"We introduce the first algorithm that we are aware of to employ Bloom filters for Longest Prefix Matching (LPM). The algorithm performs parallel queries on Bloom filters, an efficient data structure for membership queries, in order to determine address prefix membership in sets of prefixes sorted by prefix length. We show that use of this algorithm for Internet Protocol (IP) routing lookups results in a search engine providing better performance and scalability than TCAM-based approaches. The key feature of our technique is that the performance, as determined by the number of dependent memory accesses per lookup, can be held constant for longer address lengths or additional unique address prefix lengths in the forwarding table given that memory resources scale linearly with the number of prefixes in the forwarding table. Our approach is equally attractive for Internet Protocol Version 6 (IPv6) which uses 128-bit destination addresses, four times longer than IPv4. We present a basic version of our approach along with optimizations leveraging previous advances in LPM algorithms. We also report results of performance simulations of our system using snapshots of IPv4 BGP tables and extend the results to IPv6. Using less than 2Mb of embedded RAM and a commodity SRAM device, our technique achieves average performance of one hash probe per lookup and a worst case of two hash probes and one array access per lookup.",Forwarding; IP Lookup; Longest Prefix Matching,Algorithms; Data structures; Information retrieval; Network protocols; Packet switching; Search engines; Static random access storage; Forwarding table; Internet protocol (IP) lookup; Longest prefix matching; Internet
Fall K.,1,A Delay-Tolerant Network Architecture for Challenged Internets,2003,1499,"Intel Research, Berkeley, United States",Intel,1,USA,1,22,16,"The highly successful architecture and protocols of today's Internet may operate poorly in environments characterized by very long delay paths and frequent network partitions. These problems are exacerbated by end nodes with limited power or memory resources. Often deployed in mobile and extreme environments lacking continuous connectivity, many such networks have their own specialized protocols, and do not utilize IP. To achieve interoperability between them, we propose a network architecture and application interface structured around optionally-reliable asynchronous message forwarding, with limited expectations of end-to-end connectivity and node resources. The architecture operates as an overlay above the transport layers of the networks it interconnects, and provides key services such as in-network data storage and retransmission, interoperable naming, authenticated forwarding and a coarse-grained class of service.",Algorithms; Design; Security,Network architectures; Terrestrial mobile networks; Bandwidth; Computer aided design; Data storage equipment; Electric power systems; Interfaces (computer); Mathematical models; Network protocols; Quality of service; Satellite communication systems; Semantics; Internet
"Baumgartner F., Braun T., Kurt E., Weyland A.",4,Virtual routers: A tool for networking research and education,2003,11,"Universität Bern, Neubrückstrasse 10, 3012 Bern, Switzerland",University of Bern,1,Switzerland,1,23,23,"Virtual routers are software entities, i.e. user space processes, emulating IP routers on one or several (Linux) computers. Virtual routers can be used for both networking research and education. In contrast to simulation, virtual routers process packets in real-time and the virtual router code is similar to code in real routers. In the case of research, larger network test-beds can be built using a relatively small number of computers. New functionalities such as new queuing mechanisms are supported by a modular software architecture and can be tested in a rather safe environment compared to kernel space implementations. Virtual routers can also be used as a tool aiming to allow students to perform virtual experiments within a computer networks course. Students can create and experiment with arbitrary virtual IP network topologies. The web-based user interface allows students to interact remotely with the emulated routers, but simultaneously it is very similar to commonly available configuration interfaces of network devices in reality. This enables students to configure routers like in the real world but also to experiment in a much more robust and safe environment.",Distance Learning; Network Emulation; Networking; Performance Evaluation,Distance Learning; Network Emulation; Networking; Performance Evaluation; Computer software; Distance education; Network protocols; Real time systems; Telecommunication networks; User interfaces; Routers
"Welzl M., Mühlhäuser M.",2,CAVT - A Congestion Avoidance Visualization Tool,2003,2,"Leopold Franzens University of Innsbruck, Institute of Computer Science, Technikeretr. 25/7, A-6020 Innsbruck, Austria; Darmstadt University of Technology, Dpt. of Computer Science, Telecooperation, Alexanderstr. 6, D-64283 Darmstadt, Germany",TU Darmstadt;Leopold Franzens University of Innsbruck,2,Austria;Germany,2,12,10,"We present CAVT, a simple yet powerful tool to visualize the behavior of congestion control mechanisms. Essentially being a simulator that builds upon the well-known Chiu/Jain vector diagrams, CAVT provides researchers, teachers and students with a new abstraction level that has already shown its value in practice.",AIMD; Congestion Control; Protocol Design; Stability; TCP; Vector Diagrams,Network protocols; Stability; Students; Vectors; AIMD; Congestion Control; Protocol Design; TCP; Vector Diagrams; Congestion control (communication)
"Lockwood J.W., Neely C., Zuver C., Lim D.",4,Automated tools to implement and test internet systems in reconfigurable hardware,2003,3,"Applied Research Laboratory, Department of Computer Science and Engineering, Washington University, 1 Brookings Drive, Saint Louis, MO 63130, United States",University of Washington at St. Louis,1,USA,1,30,29,"Tools have been developed to automatically integrate and test networking systems in reconfigurable hardware. These tools dynamically generate circuits for Field Programmable Gate Arrays (FPGAs). A library of hardware-accelerated modules has been developed that processes Internet Protocol (IP) packets, performs header rule matching, scans packet payloads, and implements per-flow queueing. Other functions can be added to the library as extensible modules. An integration tool was developed to enable a network administrator to specify how a customized system should examine, drop, buffer, and/or modify packets. This tool joins together modules from the library to create a composite circuit that performs multiple functions. The tool allows additional modules to be quickly added to the library and integrated into systems. The integration tool has been used to create circuits that perform Internet firewall, network intrusion detection, network intrusion prevention, and Denial of Service (DoS) attack protection functions. A test tool was developed to automatically verify that circuits created by the integration tool run properly in reconfigurable hardware. Circuits created by the integration tool are deployed into a Field-programmable Port Extender (FPX) platform. As new modules were added to the library, the test tool reconfigured the logic on the FPX, injected traffic, and monitored the resulting packets. By using hardware, not software, networking system can process millions of packets per second. Together, the integration and test tools simplify the otherwise difficult task of developing reconfigurable hardware for networking systems and testing them at Gigabit per second rates.",Field Programmable Gate Array (FPGA); Firewall; Internet; Network intrusion detection and prevention,Denial of Service (DoS); Firewall; Network intrusion detection and prevention; Networking systems; Field programmable gate arrays; Internet; Network protocols; Packet networks; Telecommunication traffic; Computer aided software engineering
Armitage G.,1,Maximising student exposure to networking using freeBSD virtual hosts,2003,4,"Centre for Advanced Internet Architectures, Swinburne University of Technology, Melbourne, Australia",Centre for Advanced Internet Architectures;Swinburne University of Technology,2,Australia,1,15,15,"A Remote Unix Lab Environment (RULE) is being developed that allows student access to networked hosts for their coursework and research projects. This paper describes our first generation solution using FreeBSD's ""jail"" functionality to emulate many FreeBSD hosts on a small handful of physical machines. Our primary constraint is to minimise the incremental infrastructure cost to the Univeristy. Students access the RULE hosts through pre-existing PC labs scattered around campus and 802.11-equipped laptops. The FreeBSD hosts themselves are rackmounted in a small back room, minimising their impact on scarce University lab space. This paper describes our requirements, trade-offs, available tools, and how specific FreeBSD features are being utilized to create multiple virtual hosts for teaching purposes.",FreeBSD; IP; Networking; Students; Teaching; Unix; Virtual Hosts,Engineering education; Network protocols; Students; Teaching; UNIX; FreeBSD; IP; Networking; Virtual Hosts; Software engineering
"Yaun G.R., Bauer D., Bhutada H.L., Carothers C.D., Yuksel M., Kalyanaraman S.",6,Large-scale network simulation techniques: Examples of TCP and OSPF models,2003,29,"Department of Computer Science, 110 8th Street, Troy, NY 12180, United States; Department of Electrical and Computer Systems Engineering, 110 8th Street, Troy, NY 12180, United States",Rensselaer Polytechnic Institute,1,USA,1,29,24,"Simulation of large-scale networks remains to be a challenge, although various network simulators are in place. In this paper, we identify fundamental issues for large-scale network simulation, and propose new techniques that address them. First, we exploit optimistic parallel simulation techniques to enable fast execution on inexpensive hyper-threaded, multiprocessor systems. Second, we provide a compact, light-weight implementation framework that greatly reduces the amount of state required to simulate large-scale network models. Based on the proposed techniques, we provide sample simulation models for two networking protocols: TCP and OSPF. We implement these models in a simulation environment ROSSNet, which is an extension to the previously developed optimistic simulator ROSS. We perform validation experiments for TCP and OSPF and present performance results of our techniques by simulating OSPF and TCP on a large and realistic topology, such as AT&T's US network based on Rocketfuel data. The end result of these innovations is that we are able to simulate million node network topologies using inexpensive commercial off-the-shelf hyper-threaded multiprocessor systems consuming less than 1.4 GB of RAM in total.",Large-Scale Network Simulation; Optimistic synchronization protocol; OSPF; TCP,Large-Scale Network Simulation; Optimistic synchronization protocols; OSPF; TCP; Computer simulation; Interconnection networks; Mathematical models; Network protocols; Synchronization; Topology; Telecommunication networks
"Zimmerli S., Steinemann M.-A., Braun T.",3,Resource management portal for laboratories using real devices on the internet,2003,8,"University of Bern, Neubrückstr. 10, CH-3012 Bern, Switzerland",University of Bern,1,Switzerland,1,12,6,"Internet-based distance learning is slowly gaining new territories and substituting current teaching methodologies. However, distance learning not only consists of transferring documents to web pages, but also of developing new concepts, methods, and implementation architectures. This article presents concepts and implementation issues for an example remote hands-on networking laboratory. The described course gives access to real network hardware via the Internet In particular, authentication, authorization, scheduling, and error recovery issues had to be solved.",Computer networks laboratory; Distance learning; Hands-on training; Resource management,Computer networks laboratory; Distance learning; Hands-on training; Resource management; Distance education; Engineering education; Internet; Real time systems; Resource allocation; Scheduling; Portals
"Waddington D.G., Chang F., Viswanathan R., Yao B.",4,Topology discovery for public IPv6 networks,2003,26,"Networking Research Laboratory, Bell Laboratories, 101 Crawford's Corner Road, Holmdel, NJ 07733, United States",Bell Labs,1,USA,1,27,24,"In just three decades the Internet has grown from a small experimental research network into a complex network of routers, switches, and hosts. Understanding the topology of such large scale networks is essential to the procurement of good architectural design decisions, particularly with respect to address allocation and distribution schemes. A number of techniques for IPv4 network topology already exist. Of these ICMP-based probing has shown to be most useful in determining router-level topologies of public networks. However, many of these techniques cannot be readily applied to IPv6 because of changes in the addressing scheme and ICMP behaviour. Furthermore, increases in the proliferation of equal-cost multi-path routing, and other forms of transient routing, indicate that traditional traceroute-based topology discovery approaches are becoming less effective in the Internet. This paper presents Atlas, a system that facilitates the automated capture of IPv6 network topology information from a single probing host. It describes the Atlas infrastructure and its data collection processes and discusses IPv6 network phenomena mat must to be taken into account by the probing scheme. We also present some initial results from our probing of the 6Bone, currently the largest public IPv6 network. The results illustrate the effectiveness of the probing algorithm and also identify some trends in prefix allocation and routing policy.",IPv6; Network measurement; Network probing; Topology inference,IPv6; Network measurement; Network probing; Topology inference; Algorithms; Decision theory; Routers; Switches; Topology; Telecommunication networks
Mills D.L.,1,A brief history of NTP time: Memoirs of an Internet timekeeper,2003,52,"ACM, United States; IEEE, United States; Electrical and Computer Engineering Department, University of Delaware, Newark, DE 19716, United States",University of Delaware,1,USA,1,67,22,"This paper traces the origins and evolution of the Network Time Protocol (NTP) over two decades of continuous operation. The technology has been continuously improved from hundreds of milliseconds in the rowdy Internet of the early 1980s to tens of nanoseconds in the Internet of the new century. It includes a blend of history lessons, technology milestones and series of experiments that shape, define and record the early history of the Internet and NTP. This narrative is decidedly personal, since the job description for an Internet timekeeper is highly individualized and invites very few applicants. There is no attempt here to present a comprehensive tutorial, only a almanac of personal observations, eclectic minutiae and fireside chat. Many souls have contributed to the technology, some of which are individually acknowledged in this paper, the rest too numerous left to write their own memoirs.",Algorithmic memoirs; Computer network; Technical history; Time synchronization,Algorithmic memoirs; Technical history; Time synchronization; Algorithms; Computer networks; Internet; Professional aspects; Network protocols
"Mishra A., Shin M., Arbaugh W.",3,An empirical analysis of the IEEE 802.11 MAC layer handoff process,2003,576,"Dept. of Computer Science, University of Maryland, College Park, MD, United States",University of Maryland College Park,1,USA,1,18,14,"IEEE 802.11 based wireless networks have seen rapid growth and deployment in the recent years. Critical to the 802.11 MAC operation, is the handoff function which occurs when a mobile node moves its association from one access point to another. In this paper, we present an empirical study of this handoff process at the link layer, with a detailed breakup of the latency into various components. In particular, we show that a MAC layer function - probe is the primary contributor to the overall handoff latency. In our study, we observe that the latency is significant enough to affect the quality of service for many applications (or network connections). Further we find variations in the latency from one handoff to another as well as with APs and STAs used from different vendors. Finally, we discuss optimizations on the probe phase which can potentially reduce the probe latency by as much as 98% (and a minimum of 12% in our experiments). Based on the study, we draw some guidelines for future handoff schemes.",Association; Authentication; Handoff; IEEE 802.11; Latency; Performance; Probe; Scanning,Computer architecture; Copyrights; Optimization; Scanning; Association; Authentication; Handoff; IEEE 802.11; Latency; Wireless telecommunication systems
"Braden R., Faber T., Handley M.",3,From protocol stack to protocol heap - Role-based architecture,2003,122,"USC Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA, United States; International Computer Science Institute, 1947 Center St, Berkeley, CA 94704, United States",University of California Berkeley;University of Southern California,2,USA,1,10,3,"Questioning whether layering is still an adequate foundation for networking architectures, this paper investigates non-layered approaches to the design and implementation of network protocols. The goals are greater flexibility and control with fewer feature interaction problems. The paper further proposes a specific non-layered paradigm called role-based architecture.",Metadata; Modularity; Non-layered architecture; Processing rules; Role-based; Signaling,Interaction problems; Modularity; Networking architectures; Non-layered architecture; Processing rules; Role-based architecture; Computer architecture; Data reduction; Metadata; Problem solving; Network protocols
"Nath B., Niculescu D.",2,Routing on a curve,2003,54,"Department of Computer Science, Rutgers University, Piscataway, NJ 08854, United States",Rutgers University,1,USA,1,16,14,"Relentless progress in hardware technology and recent advances in sensor technology, and wireless networking have made it feasible to deploy large scale, dense ad-hoc networks. These networks together with sensor technology can be considered as the enablers of emerging models of computing such as embedded computing, ubiquitous computing, or pervasive computing. In this paper, we propose a new paradigm called trajectory based forwarding (or TBF), which is a generalization of source based routing and Cartesian routing. We argue that TBF is an ideal technique for routing in dense ad-hoc networks. Trajectories are a natural namespace for describing route paths when the topology of the network matches the topography of the physical surroundings in which it is deployed which by very definition is embedded computing. We show how simple trajectories can be used in implementing important networking protocols such as flooding, discovery, and network management. Trajectory routing is very effective in implementing many networking functions in a quick and approximate way, as it needs very few support services. We discuss several research challenges in the design of network protocols that use specific trajectories for forwarding packets.",Ad hoc networks; Routing; Trajectory based forwarding,Ad hoc networks; Embedded computing; Routing; Trajectory based forwarding; Computation theory; Network protocols; Sensors; Telecommunication networks; Topology; Routers
"Elson J., Römer K.",2,Wireless sensor networks: A new regime for time synchronization,2003,233,"Department of Computer Science, University of California, Los Angeles, Los Angeles, CA, United States; Department of Computer Science, ETH Zurich, 8092 Zurich, Switzerland",ETH Zurich;University of California Los Angeles,2,Switzerland;USA,2,34,25,"Wireless sensor networks (WSNs) consist of large populations of wirelessly connected nodes, capable of computation, communication, and sensing. Sensor nodes cooperate in order to merge individual sensor readings into a high-level sensing result, such as integrating a time series of position measurements into a velocity estimate. The physical time of sensor readings is a key element in this process called data fusion. Hence, time synchronization is a crucial component of WSNs. We argue that time synchronization schemes developed for traditional networks such as NTP [23] are ill-suited for WSNs and suggest more appropriate approaches.",Time synchronization; Wireless sensor network,Computation theory; Data reduction; Network protocols; Sensors; Synchronization; Telecommunication networks; Data fusion; Sensor nodes; Time synchronization; Wireless sensor network; Wireless telecommunication systems
"Molinero-Fernández P., McKeown N., Zhang H.",3,Is IP going to take over the world (of communications)?,2003,11,"Stanford University, United States; Turin Networks Carnegie, Mellon University, United States",Carnegie Mellon University;Stanford University,2,USA,1,31,29,"While it is technically pleasing to believe that IP will dominate all forms of communication, our delight in its elegance is making us overlook its shortcomings. IP is an excellent means to exchange data, which explains its success. It remains ill suited as a means to provide many other types of service; and is too crude to form the transport infrastructure in its own right. To allow the continued success of IP, we must be open-minded to it living alongside, and co-operating with other techniques (such as circuit switching) and protocols that are optimized to different needs. In this position paper, we question some of the folklore surrounding IP and packet switching. We conclude that while packet-switched IP will continue to dominate best-effort data services at the edge of the network, the core of the network will use optical circuit switching as a platform for multiple services.",Circuit switching; IP; Packet switching,Circuit switching; Data services; IP; Transport infrastructure; Internet; Optimization; Packet networks; Packet switching; Telecommunication networks; Network protocols
"Alderson D., Doyle J., Govindan R., Willinger W.",4,Toward an optimization-driven framework for designing and generating realistic Internet topologies,2003,25,"Management Science and Engineering, Stanford University, United States; Control and Dynamical Systems, California Institute of Technology, United States; Computer Science, USC, United States; AT and T Labs-Research, United States",AT and T Labs;California Institute of Technology;Stanford University;University of Southern California,4,USA,1,33,28,"We propose a novel approach to the study of Internet topology in which we use an optimization framework to model the mechanisms driving incremental growth. While previous methods of topology generation have focused on explicit replication of statistical properties, such as node hierarchies and node degree distributions, our approach addresses the economic tradeoffs, such as cost and performance, and the technical constraints faced by a single ISP in its network design. By investigating plausible objectives and constraints in the design of actual networks, observed network properties such as certain hierarchical structures and node degree distributions can be expected to be the natural by-product of an approximately optimal solution chosen by network designers and operators. In short, we advocate here essentially an approach to network topology design, modeling, and generation that is based on the concept of Highly Optimized Tolerance (HOT). In contrast with purely descriptive topology modeling, this opens up new areas of research that focus on the causal forces at work in network design and aim at identifying the economic and technical drivers responsible for the observed large-scale network behavior. As a result, the proposed approach should have significantly more predictive power than currently pursued efforts and should provide a scientific foundation for the investigation of other important problems, such as pricing, peering, or the dynamics of routing protocols.",Com-plex systems; Highly optimized tolerance; Internet topology; Network optimization; Robustness,Highly optimized tolerance; Internet topology; Network optimization; Routing protocols; Approximation theory; Hierarchical systems; Optimization; Statistical methods; Topology; Internet
"Wang J., Nahrstedt K.",2,Hop-by-hop routing algorithms for premium traffic,2002,6,"Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, United States; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, United States",UIUC,1,USA,1,28,23,"In Differentiated Service (DiffServ) networks, the routing algorithms used by the premium class traffic, due to the high priority afforded to that traffic, may have a significant impact not only on the premium class traffic itself, but on all other classes of traffic as well. The shortest hop-count routing scheme, used in current Internet, turns out to be no longer sufficient in DiffServ networks. This paper studies the problem of finding optimal routes for the premium-class traffic in a DiffServ domain, such that (1) no forwarding loop exists in the entire network in the context of hop-by-hop routing; and (2) the residual bandwidth on bottleneck links is maximized. This problem is called the Optimal Premium-class Routing (OPR) problem. We prove in this paper that the OPR problem is NP-hard. To handle the OPR problem, first, we analyze the strength and weaknesses of two existing algorithms (Widest-Shortest-Path algorithm and Bandwidth-inversion Shortest-Path algorithm). Second, we propose a novel heuristic algorithm, called the Enhanced Bandwidth-inversion Shortest-Path (EBSP) algorithm. We prove theoretically the correctness of the EBSP algorithm, i.e., we show that it is consistent and loop-free. Our extensive simulations in different network environments show clearly that the EBSP algorithm performs better when routing the premium traffic in complex, heterogeneous networks.",Differentiated Service; Hop-by-hop Routing; Premium Class; Saturate Bandwidth,Differentiated Service; Hop-by-hop Routing; Premium Class; Saturate Bandwidth; Algorithms; Bandwidth; Heuristic methods; Telecommunication networks; Telecommunication traffic; Routers
"Kouadio M., Pooch U.",2,A taxonomy and design considerations for internet accounting,2002,5,"Dept. of Computer Science, Texas A and M University, 501B Harvey Bright Bldg., College Station, TX 77843-3112, United States",Texas A and M University,1,USA,1,46,45,"Economic principles are increasingly being suggested for addressing some complex issues related to distributed resource allocation for QoS (Quality of Service) enhancement. Many proposals have been put forth, including various strategies from Pricing Theory and market-based insights for security in the Internet. A central need of these endeavors lies in the design of efficient accounting architecture for collecting, storing, processing and communicating relevant technical information to parties involved in transactions. This paper proceeds to a systematic classification of the major characteristics of accounting models with the aim of highlighting important features to optimize for building effective architectures.",Accounting Architecture; Classification; Pricing,Accounting Architecture; Classification; Pricing; Technical information; Classification (of information); Cost accounting; Marketing; Mathematical models; Quality of service; Resource allocation; Internet
Kalmanek C.,1,A retrospective view of ATM,2002,2,"AT and T Labs. Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,25,12,"ATM was the focus of active research and significant investment in the early to mid 1990's. This paper discusses several visions for ATM prevalent at the time, and analyzes how ATM evolved during this period. The paper also considers the implications of this history for current connection-oriented technologies, such as optical transport networks and MPLS.",ATM; Flow switching; MPLS; Transport networks,Flow switching; MPLS; Optical transport networks; Transport networks; Investments; Optical systems; Research; Telecommunication networks; Asynchronous transfer mode
"Liljenstam M., Ogielski A.T.",2,Crossover scaling effects in aggregated TCP traffic with congestion losses,2002,2,"Institute for Security Technology Studies, Dartmouth College, 45 Lyme Rd., Hanover, NH 03755, United States; Renesys Corporation, Hanover, NH 03755, United States",Dartmouth College,1,USA,1,30,28,"We critically examine the claims that TCP congestion control contributes to the observed self-similar traffic rate correlations. A simulation model is designed to analyze aggregated traffic of many TCP file transfers, with network topologies large enough so that each transfer has independent packet losses due to competition with other TCP traffic. To separate the effects of session-level variability from network-level variability we examine traffic consisting of small fixed-size files, and of heavy-tailed distribution of file sizes, with small variance of inter-session periods. We find that, with increasing packet loss rate, traffic rate scaling crosses over from the regime dominated by file size distribution to another scaling regime that is independent of file sizes. That loss-dominated scaling stretches over the timescales from RTT to the longest consecutive TCP time-outs (hundreds of seconds), and is not asymptotic. Analysis at the flow level exposes the mechanism of the crossover, from scaling dominated by variability of the flow ON-periods to that dominated by variability of the OFF-periods. However, it is unlikely that TCP timeouts contribute much to observed Internet traffic correlation structure, as they would matter only if widespread congestion losses exceeding 10% dominated the typical behavior of the Internet.",Self-similarity; TCP,Packet loss rates; Self-similarity; TCP; Traffic rate correlations; Congestion control (communication); Correlation methods; Internet; Network protocols; Packet networks; Telecommunication traffic
"Luby M., Goyal V.K., Skaria S., Horn G.B.",4,Wave and equation based rate control using multicast round trip time,2002,25,"Digital Fountain, Inc., United States; Univ. of California, Irvine, United States; Pulsent Corporation, United States",University of California Berkeley;,2,USA,1,19,18,"This paper introduces Wave and Equation Based Rate Control (WEBRC), the first multiple rate multicast congestion control protocol to be equation based. The equation-based approach enforces fairness to TCP with the benefit that fluctuations in the flow rate are small in comparison to TCP. This paper also introduces the multicast round trip time (MRTT), a multicast analogue of the unicast round trip time (RTT). The MRTT is fundamental to the equation-based protocol that each receiver uses to adjust its reception rate. Each receiver independently measures its own MRTT without placing any added messaging burden on the receiver, the sender or the intermediate network elements. Benefits provided by the MRTT include those that the RTT provides to TCP, e.g., reduced reception rates in reaction to buffer filling and fair sharing of bottleneck links. In addition, the use of MRTT is shown to synchronize and equalize the reception rates of proximate receivers and to cause reception rates to increase as the density of receivers increases. Another innovation of WEBRC is the idea of transmitting data with waves: the transmission rate on a channel is periodic, with an exponentially decreasing form during an active period followed by a quiescent period. Benefits of using waves include insensitivity to large IGMP leave latency; a frequency of joins and leaves by each receiver that is small and independent of the receiver reception rate; the use of a small number of multicast channels; fine-grained control over the receiver reception rate; and minimal, at times nonexistent, losses due to buffer overflow. Copyright 2002 ACM.",Congestion control; Multicast; Multiple-rate; TCP-friendliness,Equation based rate control; Equation Based Rate Control (WEBRC); Multiple-rate; TCP-friendliness; Congestion control (communication); Control systems; Multicasting; Synchronization; Network protocols
"Cohen E., Shenker S.",2,Replication strategies in unstructured peer-to-peer networks,2002,268,"AT and T Labs-Research, 180 Park Avenue, Florham Park, NJ 07932, United States; ICSI, Berkeley, CA 94704, United States",AT and T Labs,1,USA,1,15,13,"The Peer-to-Peer (P2P) architectures that are most prevalent in today's Internet are decentralized and unstructured. Search is blind in that it is independent of the query and is thus not more effective than probing randomly chosen peers. One technique to improve the effectiveness of blind search is to proactively replicate data. We evaluate and compare different replication strategies and reveal interesting structure: Two very common but very different replication strategies - uniform and proportional - yield the same average performance on successful queries, and are in fact worse than any replication strategy which lies between them. The optimal strategy lies between the two and can be achieved by simple distributed algorithms. These fundamental results offer a new understanding of replication and show that currently deployed replication strategies are far from optimal and that optimal replication is attainable by protocols that resemble existing ones in simplicity and operation. Copyright 2002 ACM.",Peer-to-peer; Random search; Replication,Algorithms; Computer architecture; Internet; Optimal systems; Peer-to-peer; Random search; Replication; Network protocols
"Vojnović M., Le Boudec J.-Y.",2,On the long-run behavior of equation-based rate control,2002,13,"EPFL, CH-1015, Lausanne, Switzerland","EPFL,Switzerland",1,Switzerland,1,20,17,"We consider unicast equation-based rate control, where a source estimates the loss event ratio p, and, primarily at loss events, adjusts its send rate to f(p). Function f is assumed to represent the loss-throughput relation that TCP would experience. When no loss occurs, the rate may also be increased according to some additional mechanism. We assume that the loss event interval estimator is non-biased. If the loss process is deterministic, the control is TCP-friendly in the long-run, i.e, the average throughput does not exceed that of TCP. If, in contrast, losses are random, it is a priori not clear whether this holds, due to the non-linearity of f, and a phenomenon similar to Feller's paradox. Our goal is to identify the key factors that drive whether, and how far, the control is TCP friendly (in the long run). As TCP and our source may experience different loss event intervals, we distinguish between TCP-friendliness and conservativeness (throughput does not exceed f(p)). We give a representation of the long term throughput, and derive that conservativeness is primarily influenced by various convexity properties of f, the variability of loss events, and the correlation structure of the loss process. In many cases, these factors lead to conservativeness, but we show reasonable experiments where the control is clearly non-conservative. However, our analysis also suggests that our source should experience a higher loss event ratio than TCP, which would make non-TCP friendliness less likely. Our findings provide guidelines that help understand when an equation base control is indeed TCP-friendly in the long-run, and in some cases, excessively so. The effects of round trip time and its variations are not included in this study. Copyright 2002 ACM.",Congestion control; Equation-based rate control; Internet; Palm calculus; Point processes; TCP-friendly,Congestion control (communication); Control system analysis; Process control; Telecommunication networks; Congestion control; Equation-based rate control; Palm calculus; Point processes; TCP-friendly; Internet
"Clark D.D., Sollins K.R., Wroclawski J., Braden R.",4,Tussle in cyberspace: Defining tomorrow's Internet,2002,102,"MIT Lab for Computer Science, United States; USC Information Sciences Institute, United States",MIT;University of Southern California,2,USA,1,11,9,"The architecture of the Internet is based on a number of principles, including the self-describing datagram packet, the end to end arguments, diversity in technology and global addressing. As the Internet has moved from a research curiosity to a recognized component of mainstream society, new requirements have emerged that suggest new design principles, and perhaps suggest that we revisit some old ones. This paper explores one important reality that surrounds the Internet today: different stakeholders that are part of the Internet milieu have interests that may be adverse to each other, and these parties each vie to favor their particular interests. We call this process ""the tussle"". Our position is that accommodating this tussle is crucial to the evolution of the network's technical architecture. We discuss some examples of tussle, and offer some technical design principles that take it into account. Copyright 2002 ACM.",Competition; Design Principles; Economics; Network Architecture; Trust; Tussle,Cyberspace; Design Principles; Network Architecture; Trust; Tussle; Competition; Computer architecture; Computer networks; Cybernetics; Data structures; Economics; Packet networks; Professional aspects; Internet
"Basu A., Ong C.-H.L., Rasala A., Shepherd F.B., Wilfong G.",5,Route oscillations in I-BGP with route reflection,2002,34,"Bell Laboratories, United States; Oxford University, United Kingdom; MIT, United States",Bell Laboratories;MIT;Oxford University,3,UK;USA,2,23,23,"We study the route oscillation problem [16, 19] in the Internal Border Gateway Protocol (I-BGP) [18] when route reflection is used. We propose a formal model of I-BGP and use it to show that even deciding whether an I-BGP configuration with route reflection can converge is an NP-Complete problem. We then propose a modification to I-BGP and show that route reflection cannot cause the modified protocol to diverge. Moreover, we show that the modified protocol converges to the same stable routing configuration regardless of the order in which messages are sent or received. Copyright 2002 ACM.",I-BGP; Route Oscillations; Route Reflection; Stability,Internal Border Gateway Protocol (I-BGP); Route oscillations; Route reflection; Routing configuration; Computer architecture; Convergence of numerical methods; Gateways (computer networks); Mathematical models; Network protocols; Problem solving; Computer networks
"Beck M., Moore T., Plank J.S.",3,An end-to-end approach to globally scalable network storage,2002,16,"Logistical Computing and Internetworking Laboratory, Computer Science Department, University of Tennessee, United States",University of Tennessee,1,USA,1,21,11,"This paper discusses the application of end-to-end design principles, which are characteristic of the architecture of the Internet, to network storage. While putting storage into the network fabric may seem to contradict end-to-end arguments, we try to show not only that there is no contradiction, but also that adherence to such an approach is the key to achieving true scalability of shared network storage. After discussing end-to-end arguments with respect to several properties of network storage, we describe the Internet Backplane Protocol and the exNode, which are tools that have been designed to create a network storage substrate that adheres to these principles. The name for this approach is Logistical Networking, and we believe its use is fundamental to the future of truly scalable communication. Copyright 2002 ACM.",Asynchronous communications; End-to-end design; exNode; IBP; Internet Backplane Protocol; Logistical Networking; Network storage; Scalability; Store and forward network; Wide area storage,Asynchronous communications; End-to-end design; exNode; Internet Backplane Protocol; Internet Backplane Protocol (IBP); Logistical Networking; Network storage; Scalability; Store and forward network; Wide area storage; Asynchronous transfer mode; Client server computer systems; Computer architecture; Internet; Network protocols; Storage allocation (computer); Computer networks
"Banerjee S., Bhattacharjee B., Kommareddy C.",3,Scalable application layer multicast,2002,487,"Department of Computer Science, University of Maryland, College Park, MD 20742, United States",University of Maryland College Park,1,USA,1,24,23,"We describe a new scalable application-layer multicast protocol, specifically designed for low-bandwidth, data streaming applications with large receiver sets. Our scheme is based upon a hierarchical clustering of the application-layer multicast peers and can support a number of different data delivery trees with desirable properties. We present extensive simulations of both our protocol and the Narada application-layer multicast protocol over Internet-like topologies. Our results show that for groups of size 32 or more, our protocol has lower link stress (by about 25%), improved or similar end-to-end latencies and similar failure recovery properties. More importantly, it is able to achieve these results by using orders of magnitude lower control traffic. Finally, we present results from our wide-area testbed in which we experimented with 32-100 member groups distributed over 8 different sites. In our experiments, average group members established and maintained low-latency paths and incurred a maximum packet loss rate of less than 1% as members randomly joined and left the multicast group. The average control overhead during our experiments was less than 1 Kbps for groups of size 100. Copyright 2002 ACM.",Application layer multicast; Hierarchy; Overlay networks; Peer-to-peer systems; Scalability,Bandwidth; Computer applications; Computer simulation; Data processing; Network protocols; Application layer multicast; Hierarchy; Overlay networks; Peer-to-peer systems; Scalability; Multicasting
"Mao Z.M., Govindan R., Varghese G., Katz R.H.",4,Route flap damping exacerbates Internet routing convergence,2002,56,"UC Berkeley, United States; ICSI, United States; UC San Diego, United States",University of California Berkeley;University of California San Diego,2,USA,1,21,14,"Route flap damping is considered to be a widely deployed mechanism in core routers that limits the widespread propagation of unstable BGP routing information. Originally designed to suppress route changes caused by link flaps, flap damping attempts to distinguish persistently unstable routes from routes that occasionally fail. It is considered to be a major contributor to the stability of the Internet routing system. We show in this paper that, surprisingly, route flap damping can significantly exacerbate the convergence times of relatively stable routes. For example, a route to a prefix that is withdrawn exactly once and re-announced can be suppressed for up to an hour (using the current RIPE recommended damping parameters). We show that such abnormal behavior fundamentally arises from the interaction of flap damping with BGP path exploration during route withdrawal. We study this interaction using a simple analytical model and understand the impact of various BGP parameters on its occurrence using simulations. Finally, we outline a preliminary proposal to modify route flap damping scheme that removes the undesired interaction in all the topologies we studied. Copyright 2002 ACM.",BGP; Border gateway protocol; Interdomain routing protocol; Route flap damping; Routing convergence; Routing dynamics,BGP; Border gateway protocol; Interdomain routing protocol; Route flap damping; Routing convergence; Routing dynamics; Computer simulation; Damping; Information analysis; Routers; Topology; Internet
"Medina A., Taft N., Salamatian K., Bhattacharyya S., Diot C.",5,Traffic matrix estimation: Existing techniques and new directions,2002,156,"Sprint Advanced Technology Labs., Burlingame, CA, United States; Department of Computer Science, Boston University, Boston, MA, United States; University of Paris VI, Paris, France",Boston University;University of Paris VI,2,France;USA,2,12,8,"Very few techniques have been proposed for estimating traffic matrices in the context of Internet traffic. Our work on POP-to-POP traffic matrices (TM) makes two contributions. The primary contribution is the outcome of a detailed comparative evaluation of the three existing techniques. We evaluate these methods with respect to the estimation errors yielded, sensitivity to prior information required and sensitivity to the statistical assumptions they make. We study the impact of characteristics such as path length and the amount of link sharing on the estimation errors. Using actual data from a Tier-1 backbone, we assess the validity of the typical assumptions needed by the TM estimation techniques. The secondary contribution of our work is the proposal of a new direction for TM estimation based on using choice models to model POP fanouts. These models allow us to overcome some of the problems of existing methods because they can incorporate additional data and information about POPs and they enable us to make a fundamentally different kind of modeling assumption. We validate this approach by illustrating that our modeling assumption matches actual Internet data well. Using two initial simple models we provide a proof of concept showing that the incorporation of knowledge of POP features (such as total incoming bytes, number of customers, etc.) can reduce estimation errors. Our proposed approach can be used in conjunction with existing or future methods in that it can be used to generate good priors that serve as inputs to statistical inference techniques. Copyright 2002 ACM.",Statistical Inference; Traffic Matrix Estimation,Statistical Inference; Traffic Matrix Estimation; Error analysis; Information analysis; Mathematical models; Matrix algebra; Statistical mechanics; Telecommunication traffic
"Katabi D., Handley M., Rohrs C.",3,Congestion control for high bandwidth-delay product networks,2002,339,"MIT-LCS, United States; ICSI, United States; Tellabs, United States",MIT,1,USA,1,29,23,"Theory and experiments show that as the per-flow product of bandwidth and latency increases, TCP becomes inefficient and prone to instability, regardless of the queuing scheme. This failing becomes increasingly important as the Internet evolves to incorporate very high-bandwidth optical links and more large-delay satellite links. To address this problem, we develop a novel approach to Internet congestion control that outperforms TCP in conventional environments, and remains efficient, fair, scalable, and stable as the bandwidth-delay product increases. This new eXplicit Control Protocol, XCP, generalizes the Explicit Congestion Notification proposal (ECN). In addition, XCP introduces the new concept of decoupling utilization control from fairness control. This allows a more flexible and analytically tractable protocol design and opens new avenues for service differentiation. Using a control theory framework, we model XCP and demonstrate it is stable and efficient regardless of the link capacity, the round trip delay, and the number of sources. Extensive packet-level simulations show that XCP outperforms TCP in both conventional and high bandwidth-delay environments. Further, XCP achieves fair bandwidth allocation, high utilization, small standing queue size, and near-zero packet drops, with both steady and highly varying traffic. Additionally, the new protocol does not maintain any per-flow state in routers and requires few CPU cycles per packet, which makes it implementable in high-speed routers. Copyright 2002 ACM.",Congestion control; High-speed networks; Large bandwidth-delay product,Congestion control; High-speed networks; Large bandwidth-delay product; Bandwidth; Internet; Optical communication; Queueing networks; Routers; Network protocols
"Jain M., Dovrolis C.",2,"End-to-end available bandwidth: Measurement methodology, dynamics, and relation with TCP throughput",2002,132,"Computer and Information Sciences, University of Delaware, Newark, DE 19716, United States; College of Computing, GATech, United States",University of Delaware,1,USA,1,39,33,"The available bandwidth (avail-bw) in a network path is of major importance in congestion control, streaming applications, QoS verification, server selection, and overlay networks. We describe an end-to-end methodology, called Self-Loading Periodic Streams (SLoPS), for measuring avail-bw. The basic idea in SLoPS is that the one-way delays of a periodic packet stream show an increasing trend when the stream's rate is higher than the avail-bw. We implemented SLoPS in a tool called pathload. The accuracy of the tool has been evaluated with both simulations and experiments over real-world Internet paths. Pathload is non-intrusive, meaning that it does not cause significant increases in the network utilization, delays, or losses. We used pathload to evaluate the variability ('dynamics') of the avail-bw in some paths that cross USA and Europe. The avail-bw becomes significantly more variable in heavily utilized paths, as well as in paths with limited capacity (probably due to a lower degree of statistical multiplexing). We finally examine the relation between avail-bw and TCP throughput. A persistent TCP connection can be used to roughly measure the avail-bw in a path, but TCP saturates the path, and increases significantly the path delays and jitter. Copyright 2002 ACM.",Active probing; Bottleneck bandwidth; Bulk transfer capacity; Network capacity; Packet pair dispersion,Active probing; Bottleneck bandwidth; Bulk transfer capacity; Network capacity; Overlay networks; Packet pair dispersion; Bandwidth; Congestion control (communication); Multiplexing; Network protocols; Packet networks; Quality of service; Throughput; Client server computer systems
"Keromytis A.D., Misra V., Rubenstein D.",3,SOS: Secure overlay services,2002,169,"Department of Computer Science, Columbia University, New York, NY, United States; Department of Electrical Engineering, Columbia University, New York, NY, United States",Columbia University,1,USA,1,26,23,"Denial of service (DoS) attacks continue to threaten the reliability of networking systems. Previous approaches for protecting networks from DoS attacks are reactive in that they wait for an attack to be launched before taking appropriate measures to protect the network. This leaves the door open for other attacks that use more sophisticated methods to mask their traffic. We propose an architecture called Secure Overlay Services (SOS) that proactively prevents DoS attacks, geared toward supporting Emergency Services or similar types of communication. The architecture is constructed using a combination of secure overlay tunneling, routing via consistent hashing, and filtering. We reduce the probability of successful attacks by (i) performing intensive filtering near protected network edges, pushing the attack point perimeter into the core of the network, where high-speed routers can handle the volume of attack traffic, and (ii) introducing randomness and anonymity into the architecture, making it difficult for an attacker to target nodes along the path to a specific SOS-protected destination. Using simple analytical models, we evaluate the likelihood that an attacker can successfully launch a DoS attack against an SOS-protected network. Our analysis demonstrates that such an architecture reduces the likelihood of a successful attack to minuscule levels. Copyright 2002 ACM.",Denial of Service Attacks; Network Security; Overlay Networks,Denial of Service Attacks; Network Security; Overlay Networks; Computer architecture; Probability; Reliability; Telecommunication networks; Telecommunication traffic; Network protocols
"Tangmunarunkit H., Govindan R., Jamin S., Shenker S., Willinger W.",5,Network topology generators: Degree-based vs. structural,2002,128,"USC-ISI, United States; ICSI, United States; Univ. of Michigan, United States; AT and T Research, United States",AT and T Labs;University of Michigan at Ann Arbor;University of Southern California,3,USA,1,51,40,"Following the long-held belief that the Internet is hierarchical, the network topology generators most widely used by the Internet research community, Transit-Stub and Tiers, create networks with a deliberately hierarchical structure. However, in 1999 a seminal paper by Faloutsos et al. revealed that the Internet's degree distribution is a power-law. Because the degree distributions produced by the Transit-Stub and Tiers generators are not power-laws, the research community has largely dismissed them as inadequate and proposed new network generators that attempt to generate graphs with power-law degree distributions. Contrary to much of the current literature on network topology generators, this paper starts with the assumption that it is more important for network generators to accurately model the large-scale structure of the Internet (such as its hierarchical structure) than to faithfully imitate its local properties (such as the degree distribution). The purpose of this paper is to determine, using various topology metrics, which network generators better represent this large-scale structure. We find, much to our surprise, that network generators based on the degree distribution more accurately capture the large-scale structure of measured topologies. We then seek an explanation for this result by examining the nature of hierarchy in the Internet more closely; we find that degree-based generators produce a form of hierarchy that closely resembles the loosely hierarchical nature of the Internet. Copyright 2002 ACM.",Degree-based generators; Hierarchy; Large-scale structure; Network topology; Structural generators; Topology characterization; Topology generators; Topology metrics,Degree-based generators; Hierarchy; Large-scale structure; Network topology; Structural generators; Topology characterization; Topology generators; Topology metrics; Graph theory; Hierarchical systems; Internet; Metric system; Topology; Network protocols
"Griffin T.G., Wilfong G.",2,On the correctness of IBGP configuration,2002,62,"AT and T Research, United States; Bell Labs., Lucent Technologies",AT and T Labs;Bell Labs;Lucent Technologies,3,USA,1,22,20,"The Border Gateway Protocol (BGP) has two distinct modus of operation. External BGP (EBGP) exchanges reachability information between autonomous systems, while Internal BGP (IBGP) exchanges external reachability information within an autonomous system. We study several routing anomalies that are unique to IBGP because, unlike EBGP, forwarding paths and signaling paths are not always symmetric. In particular, we focus on anomalies that can cause the protocol to diverge, and those that can cause a router's chosen forwarding path to an egress point to be deflected by another router on that path. Deflections can greatly complicate the debugging of routing problems, and in the worst case multiple deflections can combine to form persistent forwarding loops. We define a correct IBGP configuration to be one that is anomaly free for every possible set of routes sent by neighboring autonomous systems. We show that determination of IBGP configuration correctness is NP-hard. However, we give simple sufficient conditions on network configurations that guarantee correctness. Copyright 2002 ACM.",BGP; BGP Configuration; Border Gateway Protocol; Internal BGP,BGP; BGP Configuration; Border Gateway Protocol; Internal BGP; Gateways (computer networks); Information analysis; Problem solving; Routers; Network protocols
"Estan C., Varghese G.",2,New directions in traffic measurement and accounting,2002,154,"Computer Science and Engineering Department, University of California, San Diego, 9500 Gilman Drive, San Diego, CA 92093-0114, United States",University of California San Diego,1,USA,1,22,19,"Accurate network traffic measurement is required for accounting, bandwidth provisioning and detecting DoS attacks. These applications see the traffic as a collection of flows they need to measure. As link speeds and the number of flows increase, keeping a counter for each flow is too expensive (using SRAM) or slow (using DRAM). The current state-of-the-art methods (Cisco's sampled NetFlow) which log periodically sampled packets are slow, inaccurate and resource-intensive. Previous work showed that at different granularities a small number of ""heavy hitters"" accounts for a large share of traffic. Our paper introduces a paradigm shift for measurement by concentrating only on large flows - those above some threshold such as 0.1% of the link capacity. We propose two novel and scalable algorithms for identifying the large flows: sample and hold and multistage filters, which take a constant number of memory references per packet and use a small amount of memory. If M is the available memory, we show analytically that the errors of our new algorithms are proportional to 1/M; by contrast, the error of an algorithm based on classical sampling is proportional to 1/√M, thus providing much less accuracy for the same amount of memory. We also describe further optimizations such as early removal and conservative update that further improve the accuracy of our algorithms, as measured on real traffic traces, by an order of magnitude. Our schemes allow a new form of accounting called threshold accounting in which only flows above a threshold are charged by usage while the rest are charged a fixed fee. Threshold accounting generalizes usage-based and duration based pricing. Copyright 2002 ACM.",Identifying large flows; Network traffic measurement; On-line algorithms; Sealability; Usage based accounting,Cisco (CO); Identifying large flows; Network traffic measurement; On line algorithms; Sealability; Usage based accounting; Algorithms; Bandwidth; Error analysis; Optimization; Packet networks; Real time systems; Storage allocation (computer); Telecommunication traffic
"Calvert K.L., Griffioen J., Wen S.",3,Lightweight network support for scalable end-to-end services,2002,10,"Laboratory for Advanced Networking, University of Kentucky, United States",University of Kentucky,1,USA,1,31,29,"Some end-to-end network services benefit greatly from network support in terms of utility and scalability. However, when such support is provided through service-specific mechanisms, the proliferation of one-off solutions tend to decrease the robustness of the network over time. Programmable routers, on the other hand, offer generic support for a variety of end-to-end services, but face a different set of challenges with respect to performance, scalability, security, and robustness. Ideally, router-based support for end-to-end services should exhibit the kind of generality, simplicity, scalability, and performance that made the Internet Protocol (IP) so successful. In this paper we present a router-based building block called ephemeral state processing (ESP), which is designed to have IP-like characteristics. ESP allows packets to create and manipulate small amounts of temporary state at routers via short, predefined computations. We discuss the issues involved in the design of such a service and describe three broad classes of problems for which ESP enables robust solutions. We also present performance measurements from a network-processor-based implementation. Copyright 2002 ACM.",End-to-end services; Ephemeral state; Programmable network; Router achitecture,End-to-end services; Ephemeral state processing (ESP); Network processor; Programmable routers; Client server computer systems; Computer programming; Internet; Network protocols; Packet networks; Problem solving; Program processors; Robustness (control systems); Routers; Computer networks
"Xu J., Lipton R.J.",2,On fundamental tradeoffs between delay bounds and computational complexity in packet scheduling algorithms,2002,9,"College of Computing, Georgia Institute of Technology, United States",Georgia Tech,1,USA,1,22,10,"In this work, we clarify, extend and solve an open problem concerning the computational complexity for packet scheduling algorithms to achieve tight end-to-end delay bounds. We first focus on the difference between the time a packet finishes service in a scheduling algorithm and its virtual finish time under a GPS (General Processor Sharing) scheduler, called GPS-relative delay. We prove that, under a slightly restrictive but reasonable computational model, the lower bound computational complexity of any scheduling algorithm that guarantees O(1) GPS-relative delay bound is ω(log 2n) (widely believed as a ""folklore theorem"" but never proved). We also discover that, surprisingly, the complexity lower bound remains the same even if the delay bound is relaxed to O(n a) for 0 &lt; a &lt; 1. This implies that the delay-complexity tradeoff curve is ""flat"" in the ""interval"" [O(1), O(n)). We later extend both complexity results (for O(1) or O(n a) delay) to a much stronger computational model. Finally, we show that the same complexity lower bounds are conditionally applicable to guaranteeing tight end-to-end delay bounds. This is done by untangling the relationship between the GPS-relative delay bound and the end-to-end delay bound. Copyright 2002 ACM.",Computational complexity; Decision tree; Delay bound; Packet scheduling; Quality of Service,Decision tree; Delay bounds; General Processor Sharing (GPS); Packet scheduling; Packet scheduling algorithms; Algorithms; Client server computer systems; Computational complexity; Decision theory; Problem solving; Quality of service; Theorem proving; Trees (mathematics); Packet networks
"Spring N., Mahajan R., Wetherall D.",3,Measuring ISP topologies With rocketfuel,2002,362,"Computer Science and Engineering, University of Washington, Seattle, WA 98195-2350, United States",University of Washington at St. Louis,1,USA,1,26,21,"To date, realistic ISP topologies have not been accessible to the research community, leaving work that depends on topology on an uncertain footing. In this paper, we present new Internet mapping techniques that have enabled us to directly measure router-level ISP topologies. Our techniques reduce the number of required traces compared to a brute-force, all-to-all approach by three orders of magnitude without a significant loss in accuracy. They include the use of BGP routing tables to focus the measurements, exploiting properties of IP routing to eliminate redundant measurements, better alias resolution, and the use of DNS to divide each map into POPs and backbone. We collect maps from ten diverse ISPs using our techniques, and find that our maps are substantially more complete than those of earlier Internet mapping efforts. We also report on properties of these maps, including the size of POPs, distribution of router outdegree, and the inter-domain peering structure. As part of this work, we release our maps to the community. Copyright 2002 ACM.",Measurement,Internet mapping; ISP topologies; Research community; Graphic methods; Mapping; Measurement theory; Routers; Internet
"Iyer S., Zhang R., McKeown N.",3,Routers with a single stage of buffering,2002,38,"Computer Systems Laboratory, Stanford University, Stanford, CA 94305-9030, United States",Stanford University,1,USA,1,29,20,"Most high performance routers today use combined input and output queueing (CIOQ). The CIOQ router is also frequently used as an abstract model for routers: at one extreme is input queueing, at the other extreme is output queueing, and in-between there is a continuum of performance as the speedup is increased from 1 to N (where N is the number of linecards). The model includes architectures in which a switch fabric is sandwiched between two stages of buffering. There is a rich and growing theory for CIOQ routers, including algorithms, throughput results and conditions under which delays can be guaranteed. But there is a broad class of architectures that are not captured by the CIOQ model, including routers with centralized shared memory, and load-balanced routers. In this paper we propose an abstract model called Single-Buffered (SB) routers that includes these architectures. We describe a method called Constraint Sets to analyze a number of SB router architectures. The model helped identify previously unstudied architectures, in particular the Distributed Shared Memory router. Although commercially deployed, its performance is not widely known. We find conditions under which it can emulate an ideal shared memory router, and believe it to be a promising architecture. Questions remain about its complexity, but we find that the memory bandwidth, and potentially the power consumption of the router is lower than for a CIOQ router. Copyright 2002 ACM.",Buffers; Constraint Sets; Routers; Switching,Buffers; Combined input and output queuing (CIOQ); Constraint Sets; Memory bandwidth; Shared Memory routers; Single-Buffered (SB); Buffer storage; Computational complexity; Computer architecture; Constraint theory; Distributed computer systems; Energy utilization; Input output programs; Mathematical models; Queueing networks; Storage allocation (computer); Switching; Routers
"Byers J., Considine J., Mitzenmacher M., Rost S.",4,Informed content delivery across adaptive overlay networks,2002,58,"Dept. of Computer Science, Boston University, Boston, MA, United States; EECS, Harvard University, Cambridge, MA, United States; MIT Laboratory for Computer Science, Cambridge, MA, United States",Boston University;Harvard University;MIT,3,USA,1,34,24,"Overlay networks have emerged as a powerful and highly flexible method for delivering content. We study how to optimize throughput of large transfers across richly connected, adaptive overlay networks, focusing on the potential of collaborative transfers between peers to supplement ongoing downloads. First, we make the case for an erasure-resilient encoding of the content. Using the digital fountain encoding approach, end-hosts can efficiently reconstruct the original content of size n from a subset of any n symbols drawn from a large universe of encoded symbols. Such an approach affords reliability and a substantial degree of application-level flexibility, as it seamlessly accommodates connection migration and parallel transfers while providing resilience to packet loss. However, since the sets of encoded symbols acquired by peers during downloads may overlap substantially, care must be taken to enable them to collaborate effectively. Our main contribution is a collection of useful algorithmic tools for efficient estimation, summarization, and approximate reconciliation of sets of symbols between pairs of collaborating peers, all of which keep message complexity and computation to a minimum. Through simulations and experiments on a prototype implementation, we demonstrate the performance benefits of our informed content delivery mechanisms and how they complement existing overlay network architectures. Copyright 2002 ACM.",Bloom filter; Collaboration; Content delivery; Digital fountain; Erasure correcting code; Min-wise summary; Overlay; Peer-to-peer; Reconciliation,Bloom filter; Collaboration; Content delivery; Digital fountain; Erasure correcting code; Min-wise summary; Overlay; Peer-to-peer; Reconciliation; Approximation theory; Codes (symbols); Computation theory; Computer applications; Computer architecture; Telecommunication networks
"Akella A., Seshan S., Karp R., Shenker S., Papadimitriou C.",5,Selfish behavior and stability of the internet: A game-theoretic analysis of TCP,2002,59,"CMU; ICSI/UC Berkeley, United States",University of California Berkeley,1,USA,1,24,14,"For years, the conventional wisdom [7, 22] has been that the continued stability of the Internet depends on the widespread deployment of ""socially responsible"" congestion control. In this paper, we seek to answer the following fundamental question: If network end-points behaved in a selfish manner, would the stability of the Internet be endangered? We evaluate the impact of greedy end-point behavior through a game-theoretic analysis of TCP. In this ""TCP Game"" each flow attempts to maximize the throughput it achieves by modifying its congestion control behavior. We use a combination of analysis and simulation to determine the Nash Equilibrium of this game. Our question then reduces to whether the network operates efficiently at these Nash equilibria. Our findings are twofold. First, in more traditional environments - where end-points use TCP Reno-style loss recovery and routers use drop-tail queues - the Nash Equilibria are reasonably efficient. However, when endpoints use more recent variations of TCP (e.g., SACK) and routers employ either RED or drop-tail queues, the Nash equilibria are very inefficient. This suggests that the Internet of the past could remain stable in the face of greedy end-user behavior, but the Internet of today is vulnerable to such behavior. Second, we find that restoring the efficiency of the Nash equilibria in these settings does not require heavy-weight packet scheduling techniques (e.g., Fair Queuing) but instead can be done with a very simple stateless mechanism based on CHOKe [21]. Copyright 2002 ACM.",Design; Performance,Game-theoretic analysis; Nash Equilibrium; Packet scheduling techniques; Congestion control (communication); Game theory; Logic design; Packet networks; Performance; Queueing networks; User interfaces; Virtual reality; Internet
"Mahajan R., Wetherall D., Anderson T.",3,Understanding BGP misconfiguration,2002,152,"Computer Science and Engineering, University of Washington, Seattle, WA 98195-2350, United States",University of Washington at St. Louis,1,USA,1,41,27,"It is well-known that simple, accidental BGP configuration errors can disrupt Internet connectivity. Yet little is known about the frequency of misconfiguration or its causes, except for the few spectacular incidents of widespread outages. In this paper, we present the first quantitative study of BGP misconfiguration. Over a three week period, we analyzed routing table advertisements from 23 vantage points across the Internet backbone to detect incidents of misconfiguration. For each incident we polled the ISP operators involved to verify whether it was a misconfiguration, and to learn the cause of the incident. We also actively probed the Internet to determine the impact of misconfiguration on connectivity. Surprisingly, we find that configuration errors are pervasive, with 200-1200 prefixes (0.2-1.0% of the BGP table size) suffering from misconfiguration each day. Close to 3 in 4 of all new prefix advertisements were results of misconfiguration. Fortunately, the connectivity seen by end users is surprisingly robust to misconfigurations. While misconfigurations can substantially increase the update load on routers, only one in twenty five affects connectivity. While the causes of misconfiguration are diverse, we argue that most could be prevented through better router design. Copyright 2002 ACM.",Human Factors; Management; Reliability,Configuration errors; Human Factors; Error analysis; Management; Reliability; Routers; User interfaces; Internet
"Zhang Y., Breslau L., Paxson V., Shenker S.",4,On the characteristics and origins of Internet flow rates,2002,100,"AT and T Labs-Research, United States; International Computer Science Institute, United States",AT and T Labs;University of California Berkeley,2,USA,1,21,17,"This paper considers the distribution of the rates at which flows transmit data, and the causes of these rates. First, using packet level traces from several Internet links, and summary flow statistics from an ISP backbone, we examine Internet flow rates and the relationship between the rate and other flow characteristics such as size and duration. We find, as have others, that while the distribution of flow rates is skewed, it is not as highly skewed as the distribution of flow sizes. We also find that for large flows the size and rate are highly correlated. Second, we attempt to determine the cause of the rates at which flows transmit data by developing a tool, T-RAT, to analyze packet-level TCP dynamics. In our traces, the most frequent causes appear to be network congestion and receiver window limits. Copyright 2002 ACM.",Flow rates; Network measurement; TCP,Flow rates; Network congestion; Network measurement; TCP; Congestion control (communication); Correlation methods; Data communication systems; Data transfer; Packet networks; Internet
"Stoica I., Adkins D., Zhuang S., Shenker S., Surana S.",5,Internet indirection infrastructure,2002,189,"University of California, Berkeley, United States; ICSI Center for Internet Research (ICIR), Berkeley, United States",University of California Berkeley,1,USA,1,39,28,"Attempts to generalize the Internet's point-to-point communication abstraction to provide services like multicast, anycast, and mobility have faced challenging technical problems and deployment barriers. To ease the deployment of such services, this paper proposes an overlay-based Internet Indirection Infrastructure (i3) that offers a rendezvous-based communication abstraction. Instead of explicitly sending a packet to a destination, each packet is associated with an identifier; this identifier is then used by the receiver to obtain delivery of the packet. This level of indirection decouples the act of sending from the act of receiving, and allows i3 to efficiently support a wide variety of fundamental communication services. To demonstrate the feasibility of this approach, we have designed and built a prototype based on the Chord lookup protocol. Copyright 2002 ACM.",Abstraction; Communication; Indirection; Internet; Scalable,Abstraction; Indirection; Scalable; Multicasting; Network protocols; Packet networks; Telecommunication networks; Internet
"Maennel O., Feldmann A.",2,Realistic BGP traffic for test labs,2002,3,"Saarland University, Saarbrücken, Germany",Saarland University,1,Germany,1,58,50,"This paper examines the possibility of generating realistic routing tables of arbitrary size along with realistic BGP updates of arbitrary frequencies via an automated tool deployable in a small-scale test lab. Such a tool provides the necessary foundations to study such questions as: The limits of BGP scalability, the reasons behind routing instability, and the extent to which routing instability influences the forwarding performance of a router. We find that the answer is affirmative. In this paper we identify important characteristics/metrics of routing tables and updates which provide the foundation of the proposed BGP workload model. Based on the insights of an extensive characterization of BGP traffic according to such metrics as prefix length distributions, fanout, amount of nesting of routing table prefixes, AS path length, number and times between BGP update bursts and number and times between BGP session resets, etc., we introduce our prototype tool, RTG. RTG realizes the workload model and is capable of generating realistic BGP traffic. Through its flexibility and parameterization RTG enables us to study the sensibilities of test systems in a repeatable and consistent manner while still providing the possibility of capturing the different characteristics from different vantage points in the network. Copyright 2002 ACM.",BGP; Workload,BGP scalability; BGP workload models; Routing instability; Mathematical models; Metric system; Parameter estimation; Routers; Software prototyping; Telecommunication traffic
"Garg R., Kamra A., Khurana V.",3,A game-theoretic approach towards congestion control in communication networks,2002,39,"IBM India Research Lab, Hauz Khas, New Delhi - 110016, India; Indian Institute of Technology, Delhi, Hauz Khas, New Delhi - 110016, India; Network Appliance, CA, United States",IBM;IIT Bombay,2,India;USA,2,34,25,"Most of the end-to-end congestion control schemes are ""voluntary"" in nature and critically depend on end-user cooperation. We show that in the presence of selfish users, all such schemes will inevitably lead to a congestion collapse. Router and switch mechanisms such as service disciplines and buffer management policies determine the sharing of resources during congestion. We show, using a game-theoretic approach, that all currently proposed mechanisms, either encourage the behaviour that leads to congestion or are oblivious to it. We propose a class of service disciplines called the Diminishing Weight Schedulers (DWS) that punish misbehaving users and reward congestion avoiding well behaved users. We also propose a sample service discipline called the Rate Inverse Scheduling (RIS) from the class of DWS schedulers. With DWS schedulers deployed in the network, max-min fair rates constitute a unique Nash and Stackelberg Equilibrium. We show that RIS solves the problems of excessive congestion due to unresponsive flows, aggressive versions of TCP, multiple parallel connections and is also fair to TCP. Copyright 2001 ACM.",Congestion Control; DWS; Fairness; Game Theory; Generalized Processor Sharing; GPS; Nash Equilibrium; RIS; Scheduling; Stackelberg Equilibrium; TCP,Buffer storage; Congestion control (communication); Global positioning system; Routers; Scheduling; Telecommunication networks; Congestion Control; DWS; Fairness; Generalized Processor Sharing; Nash Equilibrium; RIS; Stackelberg Equilibrium; TCP; Game theory
"Chu H.-H., Qiao L., Nahrstedt K.",3,A secure multicast protocol with copyright protection,2002,55,"Department of Computer Science, University of Illinois at Urbana-Champaign, 1304 West Springfield Avenue, Urbana, IL 61801, United States",UIUC,1,USA,1,57,49,"We present a simple, efficient, and secure multicast protocol with copyright protection in an open and insecure network environment. There is a wide variety of multimedia applications that can benefit from using our secure multicast protocol, e.g., the commercial pay-per-view video multicast, or highly secure military intelligence video conference. Our secure multicast protocol is designed to achieve the following goals. (1) It can run in any open network environment. It does not rely on any security mechanism on intermediate network switches or routers. (2) It can be built on top of any existing multicast architecture. (3) Our key distribution protocol is both secure and robust in the presence of long delay or membership message. (4) It can support dynamic group membership, e.g., JOIN/LEAVE/EXPEL operations, in a network bandwidth efficient manner. (5) It can provide copyright protection for the information provider. (6) It can help to identify insiders in the multicast session who are leaking information to the outside world. We have implemented a prototype system which validates our secure multicast protocol and evaluated it against various performance matrices. The experimental results are very encouraging, but also show where new engineering approaches need to be deployed to conform fully to the design goals.",Copyright protection; Key distribution; Multicast security; Watermark,Copyrights; Multimedia systems; Network protocols; Routers; Video conferencing; Watermarking; Copyright protection; Key distribution; Multicast security; Watermark; Multicasting
"Bianchi G., Borgonovo F., Capone A., Fratta L., Petrioli C.",5,Endpoint Admission Control with delay variation measurements for QoS in IP networks,2002,25,"Universitá di Palermo, Viale delle Scienze, 90128 Palermo, Italy; Politecnico di Milano, Piazza Leonardo da Vinci 32, 20133 Milano, Italy; Rome University la Sapienza, via Salaria, 113, 00198 Roma, Italy",Politecnico di Milano;Rome University la Sapienza;Universitá di Palermo,3,Italy,1,21,19,"In this paper we describe a novel Endpoint Admission Control scheme (EAC) for IP telephony. EAC mechanisms are driven by independent measurements taken by the edge nodes on a flow of packets injected in the network to probe the source to destination path. Our scheme is characterized by two fundamental features. First, it does not rely on any additional procedure in internal network routers other than the capability to apply different service priorities to probing and data packets. Second, the connection admission decision is based on the analysis of the probing flow delay variation statistics. Simulation results, which focus on a IP telephony scenario, show that, despite the lack of core routers cooperation, toll-quality performance figures (99th delay percentiles not greater than few ms per router) can be obtained even in severe overload conditions. Finally, a comparison with an EAC scheme driven by probe losses only, shows that the use of delay variation statistics as endpoint decision criterion is a key factor for EAC effectiveness.",Admission control; Diffserv; IP; Quality of service,Computer simulation; Control systems; Data processing; Internet; Network protocols; Quality of service; Statistical methods; Data packets; Delay variation statistics; Endpoint Admission Control scheme (EAC); Toll-quality performance; Computer networks
"Ma H., Shin K.G.",2,Multicast video-on-demand services,2002,84,"College of Computer Science and Technology, Beijing University of Posts and Telecomm, Beijing 100876, China; Real-Time Computing Laboratory, Department of EECS, University of Michigan, Ann Arbor, MI 48109-2122, United States",Beijing University of Posts and Telecommunications;University of Michigan at Ann Arbor,2,China;USA,2,88,79,"The server's storage I/O and network I/O bandwidths are the main bottleneck of VoD service. Multicast offers an efficient means of distributing a video program to multiple clients, thus greatly improving the VoD performance. However, there are many problems to overcome before development of multicast VoD systems. This paper critically evaluates and discusses the recent progress in developing multicast VoD systems. We first present the concept and architecture of multicast VoD, and then introduce the techniques used in multicast VoD systems. We also analyze and evaluate problems related to multicast VoD service. Finally, we present open issues on multicast VoD as possible future research directions.",Multicast; Quality-of-Service (QoS); Scheduling; VCR-like interactivity; Video-on-Demand (VoD),Bandwidth; Multicasting; Problem solving; Quality of service; Research and development management; Scheduling; Multicast VoD services; Multicast VoD systems; Multiple clients; VCR-like interactivity; Video on demand
"Widmer J., Handley M.",2,Extending equation-based congestion control to multicast applications,2001,77,"University of Mannheim, Mannheim, Germany; AT and T Center for Internet Research, ICSI, ACIRI, United States",AT and T Labs;University of Mannheim,2,Germany;USA,2,21,19,"In this paper we introduce TFMCC, an equation-based multicast congestion control mechanism that extends the TCP-friendly TFRC protocol from the unicast to the multicast domain. The key challenges in the design of TFMCC lie in scalable round-trip time measurements, appropriate feedback suppression, and in ensuring that feedback delays in the control loop do not adversely affect fairness towards competing flows. A major contribution is the feedback mechanism, the key component of end-to-end multicast congestion control schemes. We improve upon the well-known approach of using exponentially weighted random timers by biasing feedback in favor of low-rate receivers while still preventing a response implosion. We evaluate the design using simulation, and demonstrate that TFMCC is both TCP-friendly and scales well to multicast groups with thousands of receivers. We also investigate TFMCC's weaknesses and scaling limits to provide guidance as to application domains for which it is well suited.",Congestion control; Feedback suppression; Multicast; Single-rate; TCP-friendliness,Feedback suppression; Friendly Multicast Congestion Control; Pragmatic General Multicast Congestion Control; Round-trip time measurement; Transmission control protocol friendliness; Computer simulation; Interference suppression; Mathematical models; Multicasting; Network protocols; Packet networks; Signal receivers; Telecommunication links; Congestion control (communication)
Chuanxiong G.,1,SRR: An O(1) time complexity packet scheduler for flows in multi-service packet networks,2001,49,"Inst. of Comm. Eng., P.O.Box 110, 2 Biaoying, Yudao St., Nanjing, 210016, China","Inst. of Comm. Eng.,UK",1,China,1,31,25,"In this paper, we present a novel fair queueing scheme, which we call Smoothed Round Robin (SRR). Ordinary round robin schedulers are well known for their burstiness in the scheduling output. In order to overcome this problem, SRR codes the weights of the flows into binary vectors to form a Weight Matrix, then uses a Weight Spread Sequence (WSS), which is specially designed to distribute the output more evenly, to schedule packets by scanning the Weight Matrix. By using the WSS and the Weight Matrix, SRR can emulate the Generalized Processor Sharing (GPS) well. It possesses better short-term fairness and schedule delay properties in comparison with various round robin schedulers. At the same time, it preserves O(1) time complexity by avoiding the time-stamp maintenance employed in various Fair Queueing schedulers. Simulation and implementation experiments show that SRR can provide good average end-to-end delay for soft real-time services. SRR can also be implemented in highspeed networks to provide QoS for its simplicity and low time complexity.",End-to-end delay; Fair queueing; High-speed networks; Packet scheduler; QoS; Time complexity,Computational complexity; Computer simulation; Data flow analysis; Encoding (symbols); Matrix algebra; Multiprocessing systems; Packet networks; Quality of service; Real time systems; Time sharing systems; Vector quantization; Binary vectors; End-to-end delay; Fair queueing scheme; Generalized processor sharing; High speed networks; Multiservice packet networks; Smoothed round robin; Time complexity packet scheduler; Weight matrix; Weight spread sequence; Queueing networks
Barán B.,1,Improved AntNet routing,2001,14,"National Computer Center, National University of Asuncion, P.O.Box 1439, San Lorenzo, Paraguay",National University of Asuncion,1,Paraguay,1,14,12,"AntNet is a new algorithm for packet routing in communication networks. In AntNet, a group of mobile agents (artificial ants) build paths between pair of nodes, exploring the network concurrently and exchanging data to update routing tables. This work, based in a previous work of the author [3], analyzes AntNet algorithms and proposes improvements, comparing their performance with respect to the original AntNet and other commercial algorithms. Simulation results indicate a better throughput of the improved proposals. So, AntNet and its variant here proposed are promising options for routing in large public networks such as Internet.",AntNet; Delay; Routing; Trhoughput,Algorithms; Intelligent agents; Routers; Telecommunication traffic; Mobile agents; Packet networks
"Magaña E., Izkue E., Villadangos J.",3,Review of traffic scheduler features on general purpose platforms [Análisis de prestaciones de un planificador de tráfico sobre plataformas de propósito general],2001,2,"Universidad Publica de Navarra, Depto. de Automatica y Computacion, Campus de Arrosadía, 31006 Pamplona, Spain",Universidad Publica de Navarra,1,Spain,1,16,15,"In this study, we review the features of a traffic scheduler running on a general-purpose platform, specifically a PC with a Linux operating system. The traffic scheduler was configured to manage a CBQ (Class Based Queueing) queue discipline, and by means of a series of experiments, we proved that the limitations of the system are due to the accuracy of the clock. After we modified this factor, we reviewed the features of the scheduler again. We were able to prove that the features of the scheduler improve greatly at the expense of a very small increase (around 10%) in the use of the system's CPU.",Accuracy of clock; CBQ; Congestion window; DiffServ; Linux; Quality of service; TBF; Traffic scheduler,Computer networks; Packet networks; Quality of service; Queueing networks; UNIX; Traffic scheduler; Telecommunication traffic
Sobrado I.,1,Evaluation of two security schemes for mobile agents [Evaluación de dos esquemas de seguridad para agentes móviles],2001,1,"Facultad de Ciencias, Universidad de Oviedo, Avda. Calvo Sotelo 18, E-33007 Oviedo (Asturias), Spain",Universidad de Oviedo,1,Spain,1,14,13,"In this article, we submit and compare two different but complementary approaches to the problem of protecting mobile agents in untrusted computing environments. The first alternative, a technique for protection of mobile agents built upon an asymmetric cryptographic system resistant to conventional cryptoanalysis techniques, is based on the application of one-time keys. The second solution, geared towards computing environments supporting public-key cryptographic systems, permits the simultaneous protection of the code and data areas of mobile agents that travel in an information network. This latter protection mechanism can be implemented using any asymmetric cryptosystem. We believe the protection strategies we have developed in our investigation are the first complete solution for the protection of mobile agents in distributed computing environments.",Assurance; Code protection; Cryptography; Data protection; Integrity of information; Keys exchange; Secure distributed systems,Algorithms; Cryptography; Distributed computer systems; Network protocols; Security of data; Mobile agents; Intelligent agents
"Rocha C.A.C., Braga A.P., De Souza J.N.",3,An open approach for deploying programming nodes into communication networks,2001,0,"Computer Science Department, Federal University of Ceará, Campus do Pict, sn Bloco 910, Fortaleza, Brazil",Federal University of Ceará,1,Brazil,1,13,7,"Nowadays, we are facing in the computer network research community new challenges related to the concepts of programmable and active networks. Great efforts have been spent to make current data communication networks more flexible and dynamic. Unfortunately, such efforts are followed by complexity and, therefore, the process of deploying the mechanisms has been committed. In order to make this process simpler, this work presents an open approach for having programmable nodes that make computer networks more dynamic in terms of adding new services without increasing complexity. This approach presents SNPI (Simple Network Programming Interface), which is a group of skeletons and data structures resources that make possible to the programmers and developers a fast deployment of new services into the network. The mechanism presented allows the access to internal mechanisms of data flow processing in the network nodes.",Active networks; Network services; Programmable networks,Data structures; Interfaces (computer); Packet networks; Routers; Telecommunication traffic; Simple network programming interface (SNPI); Computer networks
"Ardaiz O., Freitag F., Navarro L.",3,Estimating the service time of web clients using server logs [Estimación de tiempo de servicio en un cliente web a partir de los logs del servidor],2001,1,"Dep. Arquitectura de Computadores, Universidad Poltecnica de Catalunya, Jordi Girona, 1-3, Barcelona, Spain",Universidad Poltecnica de Catalunya,1,Spain,1,26,25,"This article proposes and evaluates measures for estimating the service time of a web client using server logs, only from the server side without introducing traffic into the network. The HTTP protocol is described as well as the different interactions between the web server, the communication components, and the web client application. The first measure is based on the time it takes for the web server application to deliver an object to its operating system, keeping in mind the buffer effect of the server network. The second measure also considers the inter-arrival times to the server application of the GET requests for the objects that are part of a web page. We propose formulas, validated experimentally, that relate the proposed measurements in the server with the different components that take part in a web transaction and the service time experienced by clients. We have carried out several experiments to evaluate the validity of the proposed measurements and the best measure estimates the service ti me of the client with an error below 20% for 90% of the requests. We observed a cyclic component in the measurements of the server that can simplify the estimation of future values. For this reason, the proposed measures may be used to know what is the service time the client perceives in each visit to a server. It can also be used by content distribution networks to choose between several replica located in different places in the Internet.",Metrics; Server selection; Web,Client server computer systems; HTTP; Telecommunication traffic; Web clients; World Wide Web
"Magalhaes L., Kravets R.",2,MMTP - Multimedia multiplexing transport protocol [MMTP - Protocolo de transporte multimedia multiplexado],2001,17,"Department of Computer Science, Univ. of Illinois, 1304 W Springfield Avenue, Urbana, IL 61801, United States",UIUC,1,USA,1,16,14,"Multimedia data has special requirements that are hard to be met on mobile hosts due to potentially low bandwidth and disruptions due to host mobility. Such limited communication capabilities of mobile hosts can be offset by the simultaneous use of multiple link layer technologies. MMTP is a member of a suite of protocols that share the novel characteristic of aggregating bandwidth from multiple linklayer channels. The use of multiple channels to transport user data provides five key benefits: (1) a fatter pipe,(2) a fast feedback path, (3) the retransmission of selected lost messages, without delaying the playout of the data stream, (4) less sensitivity to minor bandwidth fluctuations on any one individual channel, and (5) smooth vertical handoffs for active data streams. MMTP is a rate-based protocol designed for transferring multimedia data on mobile systems, and makes simultaneous use of every communication channel available to send data at the required rate. Transmission in MMTP is governed by two m echanisms. The first is a set of rate control protocols associated with each outgoing channel. The second is a scheduling algorithm that places incoming packets on the appropriate channel. MMTP is link-layer aware protocol that uses bandwidth estimation for congestion control, and relays to the application information needed for rate adaptation. In this paper, we show that the quality of data transmission can be improved through the use of MMTP through experimental comparisons with data transmitted via UDP. We also demonstrate the economy of bandwidth: MMTP only sends packets that it estimates will arrive within the packet deadline, thus decreasing the number of late packets that will be discarded at the receiver.",Low bandwidth link; Multimedia transport protocols; Wireless communication,Bandwidth; Communication channels (information theory); Data transfer; Multimedia systems; Multiplexing; Packet networks; Multimedia multiplexing transport protocol (MMTP); Network protocols
"Katabi D., Wroclawski J.",2,A framework for scalable global IP-anycast (GIA) [Un marco para IP global de difusión ilimitada (GIA) escalable],2001,6,"MIT Laboratory for Computer Science, 545 Technology Square, Cambridge, MA 02139, United States",MIT,1,USA,1,28,25,"This paper proposes GIA, a scalable architecture for global IP-anycast. Existing designs for providing IP-anycast must either globally distribute mutes to individual anycast groups, or confine each anycast group to a pre-configured topological region. The first approach does not scale because of excessive growth in the routing tables, whereas the second one severely limits the utility of the service. Our design scales by dividing inter-domain anycast routing into two components. The first component builds inexpensive default anycast routes that consume no bandwidth or storage space. The second component, controlled by the edge domains, generates enhanced anycast routes that are customized according to the beneficiary domain's interests. We evaluate the performance of our design using simulation, and prove its practicality by implementing it in the Multi-threaded Routing Toolkit.",Anycast; Architecture; Interact; Routing; Scalable,Bandwidth; Computer architecture; Network protocols; Routers; Multi-threaded routing; Internet
"Cerpa A., Elson J., Estrin D., Girod L., Hamilton M., Zhao J.",6,Habitat monitoring: Application driver for wireless communications technology [Monitoreo del hábitat: Controlador de aplicación para tecnología de comunicación inalámbrica],2001,430,"James San Jacinto Mountains Reserve, Idyllwild, CA, United States; USC Information Sciences Institute, Marina del Rey, CA, United States",University of Southern California,1,USA,1,17,15,"As new fabrication and integration technologies reduce the cost and size of micro-sensors and wireless interfaces, it becomes feasible to deploy densely distributed wireless networks of sensors and actuators. These systems promise to revolutionize biological, earth, and environmental monitoring applications, providing data at granularities unrealizable by other means. In addition to the challenges of miniaturization, new system architectures and new network algorithms must be developed to transform the vast quantity of raw sensor data into a manageable stream of high-level data. To address this, we propose a tiered system architecture in which data collected at numerous, inexpensive sensor nodes is filtered by local processing on its way through to larger, more capable and more expensive nodes. We briefly describe Habitat monitoring as our motivating application and introduce initial system building blocks designed to support this application. The remainder of the paper presents details of our experiment al platform.",Applications; Low-power wireless; Sensor networks; Testbeds,Computer architecture; Data processing; Embedded systems; Sensors; Habitat monitoring; Wireless telecommunication systems
"Koodli R., Perkins C.E.",2,Fast handovers and context transfers in mobile networks,2001,68,"Nokia Research Center, 313 Fairchild Drive, Mountain View, CA 94043, United States",Nokia,1,USA,1,25,17,"We describe recent work enabling fast handovers and context transfer between access routers offering Internet connectivity for mobile (often wireless) nodes. We present our framework for engineering general context transfer solutions, and a protocol which uses the framework to provide a simple yet general mechanism for carrying out context transfers during handovers. Since our mechanism operates at the network level, we expect that it will be the most expedient way to provide for seamless handovers between heterogeneous networks. We report our results which show that fast handovers with context transfer at the network layer can support uninterrupted voice over IP (VoIP). Thus, our context transfer framework will catalyze the arrival of a unified wireless telecommunications network, with voice and data connectivity anytime, anywhere. Towards that end, we describe how our results and context transfer framework relate to other work within the IETF.",Context transfer; Fast handover; IPv6; Mobile IP; Mobile network,Context transfer; Fast handovers; IPv6; Mobile IP; Mobile networks; Network protocols; Routers; Speech transmission; Wireless telecommunication systems; Mobile telecommunication systems
"Barenco C.J., Saloña A.A., Moreno J.I.",3,A QoS service for IP video applications on demand over DTM [Un servicio QoS para aplicaciones IP de video bajo demanda sobre DTM],2001,0,"Univ. Politécnica de Madrid, E.T.S.I. Telecomunicación, Ciudad Univ. S/N, 28040 Madrid, Spain; Univ. Carlos III, Av. Univ., 30, 28911 - Leganés Madrid, Spain",Av. University;Ciudad University S/N;University Carlos III of Madrid;University Politécnica de Madrid,4,Spain,1,19,17,"The Differentiated Services model (DiffServ) provides a great flexibility in defining a variety of services through PHBs (Per Hop Behaviors) and traffic conditioners. It fits in well with the Integrated Services model (IntServ), jointly offering features such as: QoS signaling; admission control; channel management; assignment of resources (buffer and bandwidth); sorter configuration; and establishment of traffic agreements. With this integration you can have a scalable, flexible, and dynamic QoS environment in networks of the Internet core. This article describes and analyzes the DGF (DTM Guaranteed Forwarding) service that guarantees a minimum rate of retransmission of packets, based on RSVP signaling and traffic agreements (SLA), as well as losses close to the error rate of the physical medium, which are ideal features for video applications on demand. When this service is provided, the aforementioned QoS models are integrated with the transport and switching solution called DTM (Dynamic Synchronous T ransfer Mode), a fast circuit switching technology. DTM is simple, cost-effective, provides QoS features, and is naturally dynamic in supplying bandwidth as well as flexible in fitting in with other IETF QoS models. Thus in the proposed architecture, IPoDQoS (IP over DTM QoS), we make use of the dynamism of network protocols and we offer managed VBR traffic in the IP layer (i.e.: DGF service) not originally offered in DTM technology.",DiffServ; DTM; IntServ; QoS; Video on demand,Internet; Network protocols; Switching; Telecommunication traffic; Video on demand; Dynamic synchronous transfer mode (DTM); Quality of service
"Raju J., Garcia-Luna-Aceves J.J.",2,Scenario-based comparison of source-tracing and dynamic source routing protocols for ad hoc networks,2001,3,"Computer Science Department, University of California, Santa Cruz, CA 95064, United States; Computer Engineering Department, University of California, Santa Cruz, CA 95064, United States",University of California Santa Cruz,1,USA,2,20,18,"We present source tracing as a new viable approach to routing in ad hoc networks in which routers communicate the second-to-last hop and distance in preferred paths to destinations. We introduce a table-driven protocol (BEST) in which routers maintain routing information for all destinations, and an on-demand routing protocol (DST) in which routers maintain routing information for only those destinations to whom they need to forward data. Simulation experiments are used to compare these protocols with DSR, which has been shown to incur less control overhead that other on-demand routing protocols. The simulations show that DST requires far less control packets to achieve comparable or better average delays and percentage of packet delivered than DSR, and that BEST achieves comparable results to DSR while maintaining routing information for all destinations.",Ad hoc networks; On-demand routing; Wireless routing,Ad hoc networks; On-demand routing; Wireless routing; Computer simulation; Network protocols; Packet networks; Routers; Neural networks
Mills D.L.,1,A brief history of NTP time: Memoirs of an Internet timekeeper,2000,52,"ACM, United States; IEEE, United States; Electrical and Computer Engineering Department, University of Delaware, Newark, DE 19716, United States",University of Delaware,1,USA,1,67,22,"This paper traces the origins and evolution of the Network Time Protocol (NTP) over two decades of continuous operation. The technology has been continuously improved from hundreds of milliseconds in the rowdy Internet of the early 1980s to tens of nanoseconds in the Internet of the new century. It includes a blend of history lessons, technology milestones and series of experiments that shape, define and record the early history of the Internet and NTP. This narrative is decidedly personal, since the job description for an Internet timekeeper is highly individualized and invites very few applicants. There is no attempt here to present a comprehensive tutorial, only a almanac of personal observations, eclectic minutiae and fireside chat. Many souls have contributed to the technology, some of which are individually acknowledged in this paper, the rest too numerous left to write their own memoirs.",Algorithmic memoirs; Computer network; Technical history; Time synchronization,Algorithmic memoirs; Technical history; Time synchronization; Algorithms; Computer networks; Internet; Professional aspects; Network protocols
"Mishra A., Shin M., Arbaugh W.",3,An empirical analysis of the IEEE 802.11 MAC layer handoff process,2000,576,"Dept. of Computer Science, University of Maryland, College Park, MD, United States",University of Maryland College Park,1,USA,1,18,14,"IEEE 802.11 based wireless networks have seen rapid growth and deployment in the recent years. Critical to the 802.11 MAC operation, is the handoff function which occurs when a mobile node moves its association from one access point to another. In this paper, we present an empirical study of this handoff process at the link layer, with a detailed breakup of the latency into various components. In particular, we show that a MAC layer function - probe is the primary contributor to the overall handoff latency. In our study, we observe that the latency is significant enough to affect the quality of service for many applications (or network connections). Further we find variations in the latency from one handoff to another as well as with APs and STAs used from different vendors. Finally, we discuss optimizations on the probe phase which can potentially reduce the probe latency by as much as 98% (and a minimum of 12% in our experiments). Based on the study, we draw some guidelines for future handoff schemes.",Association; Authentication; Handoff; IEEE 802.11; Latency; Performance; Probe; Scanning,Computer architecture; Copyrights; Optimization; Scanning; Association; Authentication; Handoff; IEEE 802.11; Latency; Wireless telecommunication systems
"Braden R., Faber T., Handley M.",3,From protocol stack to protocol heap - Role-based architecture,2000,122,"USC Information Sciences Institute, 4676 Admiralty Way, Marina del Rey, CA, United States; International Computer Science Institute, 1947 Center St, Berkeley, CA 94704, United States",University of California Berkeley;University of Southern California,2,USA,1,10,3,"Questioning whether layering is still an adequate foundation for networking architectures, this paper investigates non-layered approaches to the design and implementation of network protocols. The goals are greater flexibility and control with fewer feature interaction problems. The paper further proposes a specific non-layered paradigm called role-based architecture.",Metadata; Modularity; Non-layered architecture; Processing rules; Role-based; Signaling,Interaction problems; Modularity; Networking architectures; Non-layered architecture; Processing rules; Role-based architecture; Computer architecture; Data reduction; Metadata; Problem solving; Network protocols
"Nath B., Niculescu D.",2,Routing on a curve,2000,54,"Department of Computer Science, Rutgers University, Piscataway, NJ 08854, United States",Rutgers University,1,USA,1,16,14,"Relentless progress in hardware technology and recent advances in sensor technology, and wireless networking have made it feasible to deploy large scale, dense ad-hoc networks. These networks together with sensor technology can be considered as the enablers of emerging models of computing such as embedded computing, ubiquitous computing, or pervasive computing. In this paper, we propose a new paradigm called trajectory based forwarding (or TBF), which is a generalization of source based routing and Cartesian routing. We argue that TBF is an ideal technique for routing in dense ad-hoc networks. Trajectories are a natural namespace for describing route paths when the topology of the network matches the topography of the physical surroundings in which it is deployed which by very definition is embedded computing. We show how simple trajectories can be used in implementing important networking protocols such as flooding, discovery, and network management. Trajectory routing is very effective in implementing many networking functions in a quick and approximate way, as it needs very few support services. We discuss several research challenges in the design of network protocols that use specific trajectories for forwarding packets.",Ad hoc networks; Routing; Trajectory based forwarding,Ad hoc networks; Embedded computing; Routing; Trajectory based forwarding; Computation theory; Network protocols; Sensors; Telecommunication networks; Topology; Routers
"Elson J., Römer K.",2,Wireless sensor networks: A new regime for time synchronization,2000,233,"Department of Computer Science, University of California, Los Angeles, Los Angeles, CA, United States; Department of Computer Science, ETH Zurich, 8092 Zurich, Switzerland",ETH Zurich;University of California Los Angeles,2,Switzerland;USA,2,34,25,"Wireless sensor networks (WSNs) consist of large populations of wirelessly connected nodes, capable of computation, communication, and sensing. Sensor nodes cooperate in order to merge individual sensor readings into a high-level sensing result, such as integrating a time series of position measurements into a velocity estimate. The physical time of sensor readings is a key element in this process called data fusion. Hence, time synchronization is a crucial component of WSNs. We argue that time synchronization schemes developed for traditional networks such as NTP [23] are ill-suited for WSNs and suggest more appropriate approaches.",Time synchronization; Wireless sensor network,Computation theory; Data reduction; Network protocols; Sensors; Synchronization; Telecommunication networks; Data fusion; Sensor nodes; Time synchronization; Wireless sensor network; Wireless telecommunication systems
"Molinero-Fernández P., McKeown N., Zhang H.",3,Is IP going to take over the world (of communications)?,2000,11,"Stanford University, United States; Turin Networks Carnegie, Mellon University, United States",Carnegie Mellon University;Stanford University,2,USA,1,31,29,"While it is technically pleasing to believe that IP will dominate all forms of communication, our delight in its elegance is making us overlook its shortcomings. IP is an excellent means to exchange data, which explains its success. It remains ill suited as a means to provide many other types of service; and is too crude to form the transport infrastructure in its own right. To allow the continued success of IP, we must be open-minded to it living alongside, and co-operating with other techniques (such as circuit switching) and protocols that are optimized to different needs. In this position paper, we question some of the folklore surrounding IP and packet switching. We conclude that while packet-switched IP will continue to dominate best-effort data services at the edge of the network, the core of the network will use optical circuit switching as a platform for multiple services.",Circuit switching; IP; Packet switching,Circuit switching; Data services; IP; Transport infrastructure; Internet; Optimization; Packet networks; Packet switching; Telecommunication networks; Network protocols
"Alderson D., Doyle J., Govindan R., Willinger W.",4,Toward an optimization-driven framework for designing and generating realistic Internet topologies,2000,25,"Management Science and Engineering, Stanford University, United States; Control and Dynamical Systems, California Institute of Technology, United States; Computer Science, USC, United States; AT and T Labs-Research, United States",AT and T Labs;California Institute of Technology;Stanford University;University of Southern California,4,USA,1,33,28,"We propose a novel approach to the study of Internet topology in which we use an optimization framework to model the mechanisms driving incremental growth. While previous methods of topology generation have focused on explicit replication of statistical properties, such as node hierarchies and node degree distributions, our approach addresses the economic tradeoffs, such as cost and performance, and the technical constraints faced by a single ISP in its network design. By investigating plausible objectives and constraints in the design of actual networks, observed network properties such as certain hierarchical structures and node degree distributions can be expected to be the natural by-product of an approximately optimal solution chosen by network designers and operators. In short, we advocate here essentially an approach to network topology design, modeling, and generation that is based on the concept of Highly Optimized Tolerance (HOT). In contrast with purely descriptive topology modeling, this opens up new areas of research that focus on the causal forces at work in network design and aim at identifying the economic and technical drivers responsible for the observed large-scale network behavior. As a result, the proposed approach should have significantly more predictive power than currently pursued efforts and should provide a scientific foundation for the investigation of other important problems, such as pricing, peering, or the dynamics of routing protocols.",Com-plex systems; Highly optimized tolerance; Internet topology; Network optimization; Robustness,Highly optimized tolerance; Internet topology; Network optimization; Routing protocols; Approximation theory; Hierarchical systems; Optimization; Statistical methods; Topology; Internet
"Wang J., Nahrstedt K.",2,Hop-by-hop routing algorithms for premium traffic,2000,6,"Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, United States; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, United States",UIUC,1,USA,1,28,23,"In Differentiated Service (DiffServ) networks, the routing algorithms used by the premium class traffic, due to the high priority afforded to that traffic, may have a significant impact not only on the premium class traffic itself, but on all other classes of traffic as well. The shortest hop-count routing scheme, used in current Internet, turns out to be no longer sufficient in DiffServ networks. This paper studies the problem of finding optimal routes for the premium-class traffic in a DiffServ domain, such that (1) no forwarding loop exists in the entire network in the context of hop-by-hop routing; and (2) the residual bandwidth on bottleneck links is maximized. This problem is called the Optimal Premium-class Routing (OPR) problem. We prove in this paper that the OPR problem is NP-hard. To handle the OPR problem, first, we analyze the strength and weaknesses of two existing algorithms (Widest-Shortest-Path algorithm and Bandwidth-inversion Shortest-Path algorithm). Second, we propose a novel heuristic algorithm, called the Enhanced Bandwidth-inversion Shortest-Path (EBSP) algorithm. We prove theoretically the correctness of the EBSP algorithm, i.e., we show that it is consistent and loop-free. Our extensive simulations in different network environments show clearly that the EBSP algorithm performs better when routing the premium traffic in complex, heterogeneous networks.",Differentiated Service; Hop-by-hop Routing; Premium Class; Saturate Bandwidth,Differentiated Service; Hop-by-hop Routing; Premium Class; Saturate Bandwidth; Algorithms; Bandwidth; Heuristic methods; Telecommunication networks; Telecommunication traffic; Routers
"Kouadio M., Pooch U.",2,A taxonomy and design considerations for internet accounting,2000,5,"Dept. of Computer Science, Texas A and M University, 501B Harvey Bright Bldg., College Station, TX 77843-3112, United States",Texas A and M University,1,USA,1,46,45,"Economic principles are increasingly being suggested for addressing some complex issues related to distributed resource allocation for QoS (Quality of Service) enhancement. Many proposals have been put forth, including various strategies from Pricing Theory and market-based insights for security in the Internet. A central need of these endeavors lies in the design of efficient accounting architecture for collecting, storing, processing and communicating relevant technical information to parties involved in transactions. This paper proceeds to a systematic classification of the major characteristics of accounting models with the aim of highlighting important features to optimize for building effective architectures.",Accounting Architecture; Classification; Pricing,Accounting Architecture; Classification; Pricing; Technical information; Classification (of information); Cost accounting; Marketing; Mathematical models; Quality of service; Resource allocation; Internet
Kalmanek C.,1,A retrospective view of ATM,2000,2,"AT and T Labs. Research, 180 Park Avenue, Florham Park, NJ 07932, United States",AT and T Labs,1,USA,1,25,12,"ATM was the focus of active research and significant investment in the early to mid 1990's. This paper discusses several visions for ATM prevalent at the time, and analyzes how ATM evolved during this period. The paper also considers the implications of this history for current connection-oriented technologies, such as optical transport networks and MPLS.",ATM; Flow switching; MPLS; Transport networks,Flow switching; MPLS; Optical transport networks; Transport networks; Investments; Optical systems; Research; Telecommunication networks; Asynchronous transfer mode
"Liljenstam M., Ogielski A.T.",2,Crossover scaling effects in aggregated TCP traffic with congestion losses,2000,2,"Institute for Security Technology Studies, Dartmouth College, 45 Lyme Rd., Hanover, NH 03755, United States; Renesys Corporation, Hanover, NH 03755, United States",Dartmouth College,1,USA,1,30,28,"We critically examine the claims that TCP congestion control contributes to the observed self-similar traffic rate correlations. A simulation model is designed to analyze aggregated traffic of many TCP file transfers, with network topologies large enough so that each transfer has independent packet losses due to competition with other TCP traffic. To separate the effects of session-level variability from network-level variability we examine traffic consisting of small fixed-size files, and of heavy-tailed distribution of file sizes, with small variance of inter-session periods. We find that, with increasing packet loss rate, traffic rate scaling crosses over from the regime dominated by file size distribution to another scaling regime that is independent of file sizes. That loss-dominated scaling stretches over the timescales from RTT to the longest consecutive TCP time-outs (hundreds of seconds), and is not asymptotic. Analysis at the flow level exposes the mechanism of the crossover, from scaling dominated by variability of the flow ON-periods to that dominated by variability of the OFF-periods. However, it is unlikely that TCP timeouts contribute much to observed Internet traffic correlation structure, as they would matter only if widespread congestion losses exceeding 10% dominated the typical behavior of the Internet.",Self-similarity; TCP,Packet loss rates; Self-similarity; TCP; Traffic rate correlations; Congestion control (communication); Correlation methods; Internet; Network protocols; Packet networks; Telecommunication traffic
"Luby M., Goyal V.K., Skaria S., Horn G.B.",4,Wave and equation based rate control using multicast round trip time,2000,25,"Digital Fountain, Inc., United States; Univ. of California, Irvine, United States; Pulsent Corporation, United States",University of California Berkeley;,2,USA,1,19,18,"This paper introduces Wave and Equation Based Rate Control (WEBRC), the first multiple rate multicast congestion control protocol to be equation based. The equation-based approach enforces fairness to TCP with the benefit that fluctuations in the flow rate are small in comparison to TCP. This paper also introduces the multicast round trip time (MRTT), a multicast analogue of the unicast round trip time (RTT). The MRTT is fundamental to the equation-based protocol that each receiver uses to adjust its reception rate. Each receiver independently measures its own MRTT without placing any added messaging burden on the receiver, the sender or the intermediate network elements. Benefits provided by the MRTT include those that the RTT provides to TCP, e.g., reduced reception rates in reaction to buffer filling and fair sharing of bottleneck links. In addition, the use of MRTT is shown to synchronize and equalize the reception rates of proximate receivers and to cause reception rates to increase as the density of receivers increases. Another innovation of WEBRC is the idea of transmitting data with waves: the transmission rate on a channel is periodic, with an exponentially decreasing form during an active period followed by a quiescent period. Benefits of using waves include insensitivity to large IGMP leave latency; a frequency of joins and leaves by each receiver that is small and independent of the receiver reception rate; the use of a small number of multicast channels; fine-grained control over the receiver reception rate; and minimal, at times nonexistent, losses due to buffer overflow. Copyright 2002 ACM.",Congestion control; Multicast; Multiple-rate; TCP-friendliness,Equation based rate control; Equation Based Rate Control (WEBRC); Multiple-rate; TCP-friendliness; Congestion control (communication); Control systems; Multicasting; Synchronization; Network protocols
"Cohen E., Shenker S.",2,Replication strategies in unstructured peer-to-peer networks,2000,268,"AT and T Labs-Research, 180 Park Avenue, Florham Park, NJ 07932, United States; ICSI, Berkeley, CA 94704, United States",AT and T Labs,1,USA,1,15,13,"The Peer-to-Peer (P2P) architectures that are most prevalent in today's Internet are decentralized and unstructured. Search is blind in that it is independent of the query and is thus not more effective than probing randomly chosen peers. One technique to improve the effectiveness of blind search is to proactively replicate data. We evaluate and compare different replication strategies and reveal interesting structure: Two very common but very different replication strategies - uniform and proportional - yield the same average performance on successful queries, and are in fact worse than any replication strategy which lies between them. The optimal strategy lies between the two and can be achieved by simple distributed algorithms. These fundamental results offer a new understanding of replication and show that currently deployed replication strategies are far from optimal and that optimal replication is attainable by protocols that resemble existing ones in simplicity and operation. Copyright 2002 ACM.",Peer-to-peer; Random search; Replication,Algorithms; Computer architecture; Internet; Optimal systems; Peer-to-peer; Random search; Replication; Network protocols
"Vojnović M., Le Boudec J.-Y.",2,On the long-run behavior of equation-based rate control,2000,13,"EPFL, CH-1015, Lausanne, Switzerland","EPFL,Switzerland",1,Switzerland,1,20,17,"We consider unicast equation-based rate control, where a source estimates the loss event ratio p, and, primarily at loss events, adjusts its send rate to f(p). Function f is assumed to represent the loss-throughput relation that TCP would experience. When no loss occurs, the rate may also be increased according to some additional mechanism. We assume that the loss event interval estimator is non-biased. If the loss process is deterministic, the control is TCP-friendly in the long-run, i.e, the average throughput does not exceed that of TCP. If, in contrast, losses are random, it is a priori not clear whether this holds, due to the non-linearity of f, and a phenomenon similar to Feller's paradox. Our goal is to identify the key factors that drive whether, and how far, the control is TCP friendly (in the long run). As TCP and our source may experience different loss event intervals, we distinguish between TCP-friendliness and conservativeness (throughput does not exceed f(p)). We give a representation of the long term throughput, and derive that conservativeness is primarily influenced by various convexity properties of f, the variability of loss events, and the correlation structure of the loss process. In many cases, these factors lead to conservativeness, but we show reasonable experiments where the control is clearly non-conservative. However, our analysis also suggests that our source should experience a higher loss event ratio than TCP, which would make non-TCP friendliness less likely. Our findings provide guidelines that help understand when an equation base control is indeed TCP-friendly in the long-run, and in some cases, excessively so. The effects of round trip time and its variations are not included in this study. Copyright 2002 ACM.",Congestion control; Equation-based rate control; Internet; Palm calculus; Point processes; TCP-friendly,Congestion control (communication); Control system analysis; Process control; Telecommunication networks; Congestion control; Equation-based rate control; Palm calculus; Point processes; TCP-friendly; Internet